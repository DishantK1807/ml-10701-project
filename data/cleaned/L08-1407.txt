<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>S Abney</author>
</authors>
<title>Parsing by chunks. In Principle-Based Parsing: Computation and Psycholinguistics</title>
<date>1991</date>
<pages>257--278</pages>
<publisher>Kluwer Academic Publishers</publisher>
<location>Boston</location>
<contexts>
<context>ed to be the preprocessing stage that may facilitate the full parsing of sentences of a certain language. This task has already been proven using different methods: rule-based (Ramshaw &amp; Marcus 1995, Abney 1991, Villain &amp; Day 2000, Johansson 2000, Déjean 2000), memory-based (Veenstra &amp; Van Den Bosch 2000), statistical (Pla et al. 2000, Osborne 2000, Koeling 2000, Zhou et al. 2000) and combined systems (Tjon</context>
</contexts>
<marker>Abney, 1991</marker>
<rawString>Abney, S. (1991). Parsing by chunks. In Principle-Based Parsing: Computation and Psycholinguistics. Kluwer Academic Publishers, Boston, 1991, pp. 257-278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Buitelaar</author>
<author>T Declerck</author>
<author>B Sacaleanu</author>
<author>Š Vintar</author>
<author>D Raileanu</author>
<author>C Crispi</author>
</authors>
<title>A Multi-Layered, XML-Based Approach to the Integration of Linguistic and Semantic Annotations</title>
<date>2003</date>
<booktitle>In Proceedings of the EACL2003 Conference, Workshop on NLP and XML Language Technology and the Semantic Web, EACL</booktitle>
<pages>9--16</pages>
<location>Budapest</location>
<contexts>
<context>red to resources available for some other highly inflectional Central and Eastern European languages. Although we could have used other types of annotating scheme featuring stand-off annotation (e.g. Buitelaar et al, 2003), we decided against it since the NooJ environment, that we selected for the sake of simplicity of developing and adapting local grammars, does not handle stand-off type of annotation well. 2.2. NooJ</context>
</contexts>
<marker>Buitelaar, Declerck, Sacaleanu, Vintar, Raileanu, Crispi, 2003</marker>
<rawString>Buitelaar, P., Declerck, T., Sacaleanu, B., Vintar, Š., Raileanu, D., Crispi, C. (2003). A Multi-Layered, XML-Based Approach to the Integration of Linguistic and Semantic Annotations. In Proceedings of the EACL2003 Conference, Workshop on NLP and XML Language Technology and the Semantic Web, EACL, Budapest, 2003, pp. 9-16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Déjean</author>
</authors>
<title>Learning syntactic structures with xml</title>
<date>2000</date>
<contexts>
<context>tate the full parsing of sentences of a certain language. This task has already been proven using different methods: rule-based (Ramshaw &amp; Marcus 1995, Abney 1991, Villain &amp; Day 2000, Johansson 2000, Déjean 2000), memory-based (Veenstra &amp; Van Den Bosch 2000), statistical (Pla et al. 2000, Osborne 2000, Koeling 2000, Zhou et al. 2000) and combined systems (Tjong Kim Sang 2000, Van Halteren 2000, Kudoh &amp; Matsu</context>
</contexts>
<marker>Déjean, 2000</marker>
<rawString>Déjean, H. (2000). Learning syntactic structures with xml.</rawString>
</citation>
<citation valid="true">
<date>2000</date>
<booktitle>In Proceedings o/ CoNLL-2000 and LLL-2000</booktitle>
<pages>127--132</pages>
<location>Lisbon, Portugal</location>
<marker>2000</marker>
<rawString>In Proceedings o/ CoNLL-2000 and LLL-2000. Lisbon, Portugal, 2000, pp 127-132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Erjavec</author>
</authors>
<title>MULTEXT-East Version 3: Multilingual Morphosyntactic Specifications, Lexicons and Corpora</title>
<date>2004</date>
<booktitle>In Proceedings of the Fourth International Conference on Language Resources and Evaluation. ELRA</booktitle>
<pages>1535--1538</pages>
<location>Paris-Lisbon</location>
<contexts>
<context>(CW corpus) described in detail in (Tadić, 2000). The CW100 corpus was pre-tagged using the MULTEXT-East version 3 (MTE v3) morphosyntactic specifications on the top of XCES corpus encoding standard (Erjavec, 2004): &lt;w lemma=&amp;quot;ipak&amp;quot; ana=&amp;quot;Rn&amp;quot;&gt;ipak&lt;/w&gt; &lt;w lemma=&amp;quot;početi&amp;quot; ana=&amp;quot;Vmps-sfa&amp;quot;&gt;počela&lt;/w&gt; &lt;w lemma=&amp;quot;Hrvatska&amp;quot; ana=&amp;quot;Npfsd&amp;quot;&gt;Hrvatskoj&lt;/w&gt; Figure 1: Excerpt from the XML encoding of CW100 corpus The whole CW corp</context>
</contexts>
<marker>Erjavec, 2004</marker>
<rawString>Erjavec, T. (2004). MULTEXT-East Version 3: Multilingual Morphosyntactic Specifications, Lexicons and Corpora. In Proceedings of the Fourth International Conference on Language Resources and Evaluation. ELRA, Paris-Lisbon 2004, pp. 1535-1538.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Van Halteren</author>
</authors>
<title>Chunking with wpdv models</title>
<date>2000</date>
<booktitle>In Proceedings o/ CoNLL-2000 and LLL-2000</booktitle>
<pages>154--156</pages>
<location>Lisbon, Portugal</location>
<marker>Van Halteren, 2000</marker>
<rawString>Van Halteren, H. (2000). Chunking with wpdv models. In Proceedings o/ CoNLL-2000 and LLL-2000. Lisbon, Portugal, 2000, pp. 154-156.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Johansson</author>
</authors>
<title>A context sensitive maximum likelihood approach to chunking</title>
<date>2000</date>
<booktitle>In Proceedings of CoNLL-2000 and LLL-2000</booktitle>
<pages>136--138</pages>
<location>Lisbon, Portugal</location>
<contexts>
<context> that may facilitate the full parsing of sentences of a certain language. This task has already been proven using different methods: rule-based (Ramshaw &amp; Marcus 1995, Abney 1991, Villain &amp; Day 2000, Johansson 2000, Déjean 2000), memory-based (Veenstra &amp; Van Den Bosch 2000), statistical (Pla et al. 2000, Osborne 2000, Koeling 2000, Zhou et al. 2000) and combined systems (Tjong Kim Sang 2000, Van Halteren 2000, </context>
</contexts>
<marker>Johansson, 2000</marker>
<rawString>Johansson, C. (2000). A context sensitive maximum likelihood approach to chunking. In Proceedings of CoNLL-2000 and LLL-2000. Lisbon, Portugal, 2000, pp. 136-138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Koeling</author>
</authors>
<title>Chunking with maximum entropy models</title>
<date>2000</date>
<booktitle>In Proceedings of CoNLL-2000 and LLL-2000</booktitle>
<contexts>
<context>ent methods: rule-based (Ramshaw &amp; Marcus 1995, Abney 1991, Villain &amp; Day 2000, Johansson 2000, Déjean 2000), memory-based (Veenstra &amp; Van Den Bosch 2000), statistical (Pla et al. 2000, Osborne 2000, Koeling 2000, Zhou et al. 2000) and combined systems (Tjong Kim Sang 2000, Van Halteren 2000, Kudoh &amp; Matsumoto 2000). However, when developing a chunker for a new language, statistical and machine learning metho</context>
</contexts>
<marker>Koeling, 2000</marker>
<rawString>Koeling, R. (2000). Chunking with maximum entropy models. In Proceedings of CoNLL-2000 and LLL-2000.</rawString>
</citation>
<citation valid="false">
<date>2000</date>
<pages>139--141</pages>
<location>Lisbon, Portugal</location>
<marker>2000</marker>
<rawString>Lisbon, Portugal 2000, pp. 139-141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kudoh</author>
<author>Y Matsumoto</author>
</authors>
<title>Use of support vector learning for chunk identification</title>
<date>2000</date>
<booktitle>In Proceedings of CoNLL-2000 and LLL-2000</booktitle>
<pages>142--144</pages>
<location>Lisbon, Portugal</location>
<contexts>
<context>, Déjean 2000), memory-based (Veenstra &amp; Van Den Bosch 2000), statistical (Pla et al. 2000, Osborne 2000, Koeling 2000, Zhou et al. 2000) and combined systems (Tjong Kim Sang 2000, Van Halteren 2000, Kudoh &amp; Matsumoto 2000). However, when developing a chunker for a new language, statistical and machine learning methods require an already preprocessed corpus which is not always available. In our case, such a corpus for </context>
</contexts>
<marker>Kudoh, Matsumoto, 2000</marker>
<rawString>Kudoh, T., Matsumoto, Y. (2000). Use of support vector learning for chunk identification. In Proceedings of CoNLL-2000 and LLL-2000. Lisbon, Portugal, 2000, pp. 142-144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Osborne</author>
</authors>
<title>Shallow parsing as part-of speech tagging</title>
<date>2000</date>
<booktitle>In Proceedings of CoNLL-2000 and LLL-2000</booktitle>
<contexts>
<context>n using different methods: rule-based (Ramshaw &amp; Marcus 1995, Abney 1991, Villain &amp; Day 2000, Johansson 2000, Déjean 2000), memory-based (Veenstra &amp; Van Den Bosch 2000), statistical (Pla et al. 2000, Osborne 2000, Koeling 2000, Zhou et al. 2000) and combined systems (Tjong Kim Sang 2000, Van Halteren 2000, Kudoh &amp; Matsumoto 2000). However, when developing a chunker for a new language, statistical and machine </context>
</contexts>
<marker>Osborne, 2000</marker>
<rawString>Osborne, M. (2000). Shallow parsing as part-of speech tagging. In Proceedings of CoNLL-2000 and LLL-2000.</rawString>
</citation>
<citation valid="false">
<date>2000</date>
<pages>145--147</pages>
<location>Lisbon, Portugal</location>
<marker>2000</marker>
<rawString>Lisbon, Portugal, 2000, pp. 145-147.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Pla</author>
<author>A Molina</author>
<author>N Prieto</author>
</authors>
<title>Improving chunking by means of lexical-contextual information in statistical language models</title>
<date>2000</date>
<booktitle>In Proceedings of CoNLL-2000 and LLL-2000</booktitle>
<pages>148--150</pages>
<location>Lisbon, Portugal</location>
<contexts>
<context>lready been proven using different methods: rule-based (Ramshaw &amp; Marcus 1995, Abney 1991, Villain &amp; Day 2000, Johansson 2000, Déjean 2000), memory-based (Veenstra &amp; Van Den Bosch 2000), statistical (Pla et al. 2000, Osborne 2000, Koeling 2000, Zhou et al. 2000) and combined systems (Tjong Kim Sang 2000, Van Halteren 2000, Kudoh &amp; Matsumoto 2000). However, when developing a chunker for a new language, statistica</context>
</contexts>
<marker>Pla, Molina, Prieto, 2000</marker>
<rawString>Pla, F., Molina, A., Prieto, N. (2000). Improving chunking by means of lexical-contextual information in statistical language models. In Proceedings of CoNLL-2000 and LLL-2000. Lisbon, Portugal, 2000, pp. 148-150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L A Ramshaw</author>
<author>M P Marcus</author>
</authors>
<title>Text chunking using transformation-based learning</title>
<date>1995</date>
<booktitle>In Proceedings of the Third ACL Workshop on Very Large Corpora. ACL</booktitle>
<pages>82--94</pages>
<contexts>
<context>nking is today considered to be the preprocessing stage that may facilitate the full parsing of sentences of a certain language. This task has already been proven using different methods: rule-based (Ramshaw &amp; Marcus 1995, Abney 1991, Villain &amp; Day 2000, Johansson 2000, Déjean 2000), memory-based (Veenstra &amp; Van Den Bosch 2000), statistical (Pla et al. 2000, Osborne 2000, Koeling 2000, Zhou et al. 2000) and combined s</context>
</contexts>
<marker>Ramshaw, Marcus, 1995</marker>
<rawString>Ramshaw, L. A., Marcus, M. P. (1995). Text chunking using transformation-based learning. In Proceedings of the Third ACL Workshop on Very Large Corpora. ACL, pp. 82-94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Silberztein</author>
</authors>
<date>2006</date>
<note>NooJ’ Manual. . http://www.nooj4nlp.net/NooJ%20Manual.pdf</note>
<contexts>
<context>at we selected for the sake of simplicity of developing and adapting local grammars, does not handle stand-off type of annotation well. 2.2. NooJ development environment In this project we used NooJ (Silberztein, 2006 and at http://www.nooj4nlp.net) as a tool for natural language processing using formalized descriptions of inflectional and derivational morphology, lexicon, regular grammars, and CF grammars. NooJ u</context>
</contexts>
<marker>Silberztein, 2006</marker>
<rawString>Silberztein, M. (2006). NooJ’ Manual. . http://www.nooj4nlp.net/NooJ%20Manual.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tjong Kim Sang</author>
<author>E F</author>
</authors>
<title>Text chunking by system combination</title>
<date>2000</date>
<booktitle>In Proceedings of CoNLL-2000 and LLL2000</booktitle>
<pages>151--153</pages>
<location>Lisbon, Portugal</location>
<marker>Sang, F, 2000</marker>
<rawString>Tjong Kim Sang, E. F. (2000). Text chunking by system combination. In Proceedings of CoNLL-2000 and LLL2000. Lisbon, Portugal, 2000, pp. 151-153.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tjong Kim Sang</author>
<author>E F</author>
<author>S Buchholz</author>
</authors>
<title>Introduction to the CoNLL-2000 Shared Task: Chunking</title>
<date>2000</date>
<booktitle>In Proceedings of CoNLL-2000 and LLL-2000</booktitle>
<pages>127--132</pages>
<location>Lisbon, Portugal</location>
<marker>Sang, F, Buchholz, 2000</marker>
<rawString>Tjong Kim Sang, E. F., Buchholz, S. (2000) Introduction to the CoNLL-2000 Shared Task: Chunking. In Proceedings of CoNLL-2000 and LLL-2000, Lisbon, Portugal, 2000, pp. 127-132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tadić</author>
</authors>
<title>Building the Croatian-English Parallel Corpus</title>
<date>2000</date>
<booktitle>In Proceedings of the Second International Conference on Language Resources and Evaluation</booktitle>
<contexts>
<context>om 1998 to 2000 by the Croatian Institute for Information and Culture (HIKZ). This 100 Kw corpus is a part of Croatian side of the Croatian-English Parallel Corpus (CW corpus) described in detail in (Tadić, 2000). The CW100 corpus was pre-tagged using the MULTEXT-East version 3 (MTE v3) morphosyntactic specifications on the top of XCES corpus encoding standard (Erjavec, 2004): &lt;w lemma=&amp;quot;ipak&amp;quot; ana=&amp;quot;Rn&amp;quot;&gt;ipak&lt;/</context>
<context>ela&lt;/w&gt; &lt;w lemma=&amp;quot;Hrvatska&amp;quot; ana=&amp;quot;Npfsd&amp;quot;&gt;Hrvatskoj&lt;/w&gt; Figure 1: Excerpt from the XML encoding of CW100 corpus The whole CW corpus was in fact built in two separate processing stages, as described in (Tadić, 2000): firstly, the raw text data was automatically converted into XML format and afterwards tokenized in order to be semi-automatically tagged using the full MTE v3 MSD tagset by matching the CW100 corpu</context>
</contexts>
<marker>Tadić, 2000</marker>
<rawString>Tadić, M. (2000). Building the Croatian-English Parallel Corpus. In Proceedings of the Second International Conference on Language Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paris-Athens ELRA</author>
</authors>
<date>2000</date>
<pages>523--530</pages>
<marker>ELRA, 2000</marker>
<rawString>ELRA, Paris-Athens 2000, pp. 523-530.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tadić</author>
</authors>
<title>Jezične tehnologije i hrvatski jezik</title>
<date>2003</date>
<marker>Tadić, 2003</marker>
<rawString>Tadić, M. (2003). Jezične tehnologije i hrvatski jezik.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Exlibris</author>
</authors>
<date>2003</date>
<location>Zagreb</location>
<marker>Exlibris, 2003</marker>
<rawString>Exlibris, Zagreb 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tadić</author>
</authors>
<title>The Croatian Lemmatization Server</title>
<date>2006</date>
<booktitle>In Proceedings of the FASSBL5 Conference. Sofia 2006, Bulgarian Academy of Sciences</booktitle>
<pages>140--146</pages>
<contexts>
<context>d in order to be semi-automatically tagged using the full MTE v3 MSD tagset by matching the CW100 corpus and the Croatian Morphological Lexicon at unigram level via the Croatian Lemmatization Server (Tadić, 2006 and at http://hml.ffzg.hr). Croatian language in general implements 12 out of 14 different PoS categories defined in the MTE v3 specification: Adjective (A), Conjunction (C), Interjection (I), Numera</context>
</contexts>
<marker>Tadić, 2006</marker>
<rawString>Tadić, M. (2006). The Croatian Lemmatization Server. In Proceedings of the FASSBL5 Conference. Sofia 2006, Bulgarian Academy of Sciences, pp. 140-146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Veenstra</author>
<author>A Bosch</author>
</authors>
<title>Single-classifier memorybased phrase chunking</title>
<date>2000</date>
<booktitle>In Proceedings of CoNLL-2000 and LLL-2000</booktitle>
<pages>157--159</pages>
<location>Lisbon, Portugal</location>
<marker>Veenstra, Bosch, 2000</marker>
<rawString>Veenstra, J., Bosch, A. (2000). Single-classifier memorybased phrase chunking. In Proceedings of CoNLL-2000 and LLL-2000. Lisbon, Portugal, 2000, pp. 157-159.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Vilain</author>
<author>D Day</author>
</authors>
<title>Phrase parsing with rule sequence processors: an application to the shared CoNLL task</title>
<date>2000</date>
<booktitle>In Proceedings of the Conference on Natural Language Learning of CoNLL-2000</booktitle>
<pages>160--162</pages>
<location>Lisbon, Portugal</location>
<marker>Vilain, Day, 2000</marker>
<rawString>Vilain, M., Day, D. (2000). Phrase parsing with rule sequence processors: an application to the shared CoNLL task. In Proceedings of the Conference on Natural Language Learning of CoNLL-2000, Lisbon, Portugal, 2000, pp. 160-162.</rawString>
</citation>
</citationList>
</algorithm>

