Proceedings of NAACL HLT 2009: Short Papers, pages 129–132,
Boulder, Colorado, June 2009. c 2009 Association for Computational Linguistics
Extending Pronunciation Lexicons via Non-phonemic Respellings  
 
 
 Lucian Galescu 
 Florida Instiute for Human d Machine Cogniton 
 40 S Alcaniz St., Pescola FL 32502, USA 
lgalescu@ihmc.us 
 
 
Abstract 
This paer describes work in progres towards 
uing no-phonmic respelis a an i-
tioal surce f iforation beides peling 
in the pros f extdig pronuciatio 
lexicons fr pech rcogniton ad text-to-
sph ystems. Prelimiary exprimntal 
dat indicat that h aproch is likely to be 
sucesful. Te jor benfit of th aprach 
i that it maks xtendig prnucition lexi-
cons cesible to avrae users. 
1 Introduction

Spech recogniton (SR) sytems use pronucia-
tion lxis t map word into th hem-like 
uits used for coustic melig. Text-to-spech 
(TS) ytes al ak us of pronuciation 
lexicons, both internaly nd a “exceti ditin-
aris” meant to verie th sytms’ internal 
grphe-to-phnm (G2P) convertor. Thr re 
many situatios wher users might want o aug-
et he prnuciation lxicons of SR d TS 
syts, ragi frm ir fixe, such as ing 
a few new ords or alternat pronitions for 
existig ords, t ignifct devlpment efrts, 
such as apting a speh sytm to a spcialized 
domin, or devloing pech syte for nw 
languages by tsraping fro al amuts of 
dt (Kominek t l., 208). 
Unfrtuatly, extndig the pronuciation lexi-
co (PL) is not an asy task. Gtig expert hlp is 
usaly impractil, et uer have litl or no sup-
port if they want to tackl t job themelvs. 
Wher avilable, the user has to either know how 
to transcrie  word’ pronuciatin it the apli-
cati’ undrlying he st, or, i rae cs, use 
pronuciatio-by-ortography, wherby word pro-
ciatins are rspeld using otr rs (e.g., 
“Thild” is pronunce like “tie land”). The 
former method reqirs a crtain skil that is 
clarly byn th capbilties of the average uer; 
the lter is extremly limitd in scp. 
What i nd is a etho that would make it 
easy for the users to pcify prnuciatins thm-
lves, witot rquirng them to be or becoe 
exprt phneticans. I tis paer w il argu – 
with backing from soe preliminary experiments – 
tat no-phoeic rlings ight b an acs-
sible itermdiate represtaion tat wil low 
pch sytes to larn prucitions directly 
from uer input faster d more arately. 
2 Extending
pronunciation lexicons 
Automatic G2P conversion sems the ideal tol to 
help sers with L xpai. T usr wuld be 
sown a rnked list of utoaticaly derive pro-
nucitios a wuld have to pick th corect 
one. T mke such a sytm ore user-friendly, a 
synthesized waveform could als b prsted 
(Davl an Brnrd, 204; lso Kominek et al., 
208). This aproach as  majr drawbac: if the 
sytem’s coices re l wrong – hic is, in fact, 
to b xpetd, if th nuber f coie i ml – 
the user woul ave to provide their wn pronun-
ciation by sing th sytem’s pontic alhabet. I 
our piio this precluds the arah from ing 
sed by n-ecialist. 
Other sytms try to learn pronuciations only 
from ur-provide audi smles, vi spech rec-
gniton/alignnt (Befay t al., 203; s also 
Basal et l., 209 ad Chung et l., 4). In uch 
sytems GP conversion may b used to cstrain 
choic, therby rcig the notriusly por 
phone-levl rcogniton perforace. For examle, 
Beaufays t al. (203) fcusd n  directry sis-
tnc SR tsk, with many ot-of-vocabular proer 
ames. Their procedure wrks by initlizng a hy-
pothi by G2P nvrsion, and therafter efin-
ing it with pothes frm the joint lignmnt of 
phoe latices btaind fro audi samples ad the 
curnt bt hypothesi. Sevral trnfortion 
rles wer emld to xpand the sarch space f 
altrnativ pronuciatins. 
While audi-bsed prounciation learnig may 
apear to be mor ur-friedly, it actuly sufers 
from being a slw aproach, with man adio 
sapls i nede t iev reasoble per-
forance (the stuis cited usd up t 15 sals). 
It is lso unclear whter the ronucition 
learned are i ft corect, sinc t aprah was 
mostly usd to help inrae the performnce of  
SR tem. T SR performanc iprovmnts 
(rangi fro 40% to 74%) ust be due t betr 
129
pronuciations, but we are not awre of the xis-
tece of y crectns vlutins.  
3 Non-phonemic respellings 
The method prosed her is aimed at lowing 
usrs t irectly inicat the pronucitin f a 
word via non-phoemi resligs (NPRs). With 
NPRs,  word’s rnuciation i reprented ac-
cording t the ordiary spelig ruls of Eglish, 
withut atmpting to rersnt each und wit a 
uniqe sybol. Fr xample, th pronciation f 
the word phnem could b indicated as \FO-neem\, 
r caitalizatin iicates trs (boldface, un-
derlinig, nd the apostroph are als usd as 
strs markers). It is ften sibl to cme p with 
difernt rpling, ad, ided, sytaticty is 
not a goal her; rather, the goal i to cnvey infor-
mtin bout pronuciatin using familar spell-
ing-to-snd rles, with o pecil trinig or 
table of ufamilar ymbls. 
NPRs are used to indicate the pronuciation f 
unfamilr or ificult wors by nws rgniztis 
(ostly fr freign ame), the Uited Staes Phar-
acpoeia (for dru ns), as wl s countles 
interst grups (astroy, horticultre, philoo-
phy, tc.) Lately, Meriam-Webster Onlie
1
 has 
started using NPRs in their poular Word of te 
Dy
2
 fatre. Her i a rcnt example: 
girandole •\JEER-un-dohl\ 
While NPRs em to be used by a fairly wide 
rang of audincs, w mtn’t asume that most 
people re filar ith te. Wht w do knw, 
hwvr, is tht people can larn e prucia-
tions faster and with fwr erors from NPRs than 
frm phomic transcriptions and this hold true 
whetr they re liguiticly-traine r not 
(Frasr, 197). W conted, based o prlimiary 
obervations, that t ly r NPRs easily de-
cd, but people sem to be able to produce rla-
tively acrat NPR, t. 
4 Our
Approach 
Our vison is that spech aplications would em-
ploy uer-provide NPRs s n ditnal sourc 
f informatin bsides orthography, ad ue dei-
cated NPR-to-pronuciatin (N2P) mols to e-
riv hypothes abt he corect prnuciatin. 
Howevr, before mbarking on this project, we 
ought  answr thr questios: 
1. Is geric knowldg about graphem-to-
phonm apigs in English sficnt o de-
cde pronucitio respeli? Or, i techni-
                                                 
1
 http://w.merriam-webster.com 
2
 http:// -ebster.com/cgi-bin/mwwod.pl 
cal terms, are genric G2P models going to 
work a N2P modls? 
2. Are pronuciatin respelings useful in obtain-
ing the cret prounciatio f a word eynd 
the capbiltis f a G2P nvertr? 
3. Sin we don’t require that rage users learn 
a resplig sytm, ar novice r abl to 
gnrate useful respeligs? 
In the folwing we try to answer xperimentaly 
te tchnical countrparts f th first two ques-
tions, ad reprt results of a smal tudy esignd 
t awer th third one. 
4.1 Dat
and models 
We colectd a corpus of 2730 words with a to-
tal of 2847 NPR trncriptins (sme ords ve 
multiple s) from Natioal Cancr Intiut’s 
Dictionary of Cancer Terms.
3
 The ditioary con-
tains ver 40 dical tr. Hr are  uple 
of etris (without he finitons): 
lactoferin (LAK-toh-fayr-in) 
valpric aid (val-PROH-ik A-sid) 
Of the 2730 words, 183 apear in the CMU 
dictionary (Weid, 19) – we’l cl tis te ID 
set. Of ot, about 80 words wer not ruly in-
dictionary; fr example, Ved (a drg brad 
name), pronuncd \V ER0 S EH1 D\, is ifernt 
fro the i-ditionary word versed, pronucd 
\V ER1 S T\. We mul aligned al NPRs i the 
ID set with t phonetic trnscriptions. 
W transcribed phonetialy ather 928 of the 
words – we’l al tis th OD set – not fund in 
the CMU dictionry; we vrifed th phetic tran-
scriptions agist th Meriam-Webstr Onlie 
edical Dictionary and th Nw Oxford American 
Ditionry (MKe, 205). 
Fr G2P convrsion we used a joint 4-gram 
model (alesu, 201) train  autotic 
alignnts for al entries in the CMU dictinary. 
We ote that joit -gram odls em to be 
amng t best G2P odels avilabl (Polyakva 
d Boafont, 06; Bisani nd Ney, 208). 
4.2 Adequacy
of genric G2P models 
To answer the first question above, we loked at 
whetr t gneric joit 4-grm G2P ml is 
adquate for covrting NPRs into phones. 
At first, it apeard that he aswr ould be 
negative. We foun out t NPR ue GP cre-
spondncs that d t exist or are xtrmely rae 
i the CMU ictionary. Fr exmple, th <[ih], 
\IH\> corespondece is vry infrqunt in the 
                                                 
3
 http://w.cancer.gov 
130
CMU dictionary (and apears only in proer 
names, e.g., Stihl), but is vry frequetly used in 
NPR. Threfore, for the [ih] graphm th G2P 
convertr prfrs \IH HH\ to te intede \IH\. 
Similar roblem hapen becaus of th way some 
diphones ar transcribd. Two ter peculirits 
of t trnscriptio acounted fr othr rors: a) 
always prefring /S/ in plrals wher /Z/ wuld be 
required, and b) usig [y] to transcribe \EH R\, 
whic uses the very rae <[ay], \EH\> maping. 
Tes dviations from ordinary GP coreson-
dnc ocur with regularity d therfre w er 
able t fix them ith four post-procsing ruls. 
W are confidnt at es rule ature specifc 
choics mae urig th compiltion of th Dic-
tinary of Cncr Terms, t reduce ambiguity, and 
icrese csitency, with th xpectaion tht 
radr would larn to mak th crect 
phonlogical choices when reding te rspelings. 
Ather isue a tat h set of GP mapi 
used in NPR was extremly mal (1) coared 
to th G corepondnce set obtined autti-
caly from th CMU itionary (130, mny of 
them curing only in prer mes). Howevr, it 
turns ot hat 47524 etris in th CMU dictionary 
(abut 45%) use xclusively GP apings fud 
in NPRs! Thi gest that, while the eric G2P 
model may not b adqute for t N2P task, the 
GP pigs use in NPRs are suficently com-
on that  mor adequate N2P modl could be 
built fro genric ictionry entries by selcting 
only relvat tries fr taiig. Ufortunatly we 
d’t he  ful acount of al “extic” etries in 
the CMU dictionry, bt we xpct hat by simply 
rmoving frm the trainig dat the proxiatel 
54K kown pror mes wil yild a reasnbl 
starting pit fr building N2P moels. 
4.3 NPR-to-pronuciation conversion 
To ases the contribution of NPR information to 
prnuciation predicti, we cmpare the prfrm-
ace of spelig-to-pronuiation convrsion (the 
bsline) to that of NPR-to-pruiation cvr-
io, as wel s t that of a combined spelig and 
NPR-bd conversin, whi is our n goal. 
For the N2P tak, e trained tw jit 4-gram 
mdels: on based on th lig NPRs, and  sec-
ond baed  th 47K CMU dictionary etrie that 
use only GP mapings foun i NPRs. Thn, we 
intrplated the two mdels to btain a NPR-
specifc mol (t eight wer nt optimized for 
thse experients), wic ’l cal th N2P 
modl. Th combined, speling nd NPR-based 
el was n racl combiatio f the G2 n 
th N2P model. Phone rr tes (PER) and word 
eror ates (WER) fr both t ID et and the OD 
st r hown i Figures 1 and 2, rspectivly. We 
obtained n-best pronuciations with n from 1 to 10 
fr th thr models onsiderd. 
As expect, G2P performance is very god on 
the ID st, since the tst dt w ud in traiig 
t G2P modl. Signifcantly, evn though te N2P 
model is nt as od itself, th cmbined model 
shws arked err at rdutions: for the tp 
ypothesi it cuts the PER by ver 57%, and the 
WER by over 47% wn compard to the G2P pr-
formance n speling ale. 
Si th OD set rprsnts dat unsen by ei-
ther the speling-bad model or the NPR-asd 
modl, al models’ perfrance is verly e-
grae copar to that on th ID et. But hre we 
se that NPR-bsed pruciations ar already bt-
tr tn speling-based ones. Fr the top hpothe-
si, comard to th prformanc f te G2P 
odel lne, the N2P mdel shows almost 19% 
betr PER, and alost 5% bter WER, wheras 
th combine moel achievs 49% betr PER nd 
clse t 31% betr WER. 
4. User-genrated NPs 
To answer the third question, we colectd user-
gertd NPRs from fiv subjts. Th sbjcts 
wr al computer-savy, with at leat a BS de-
gre. Only n sbject expresd som fmilarity 
with NPRs (but din’t gnrate betr NPRs thn 
 
Figure 1. Phone and word eror ates on the ID set. 
 
Figure 2. Phone and word eror ates for the OD set. 
0% 
2% 
4% 
6% 
8% 
10% 
1 2 3 4 5 6 7 8 9 10 
PER 
spelling NPR combined 
0% 
10% 
20% 
30% 
40% 
50% 
1 2 3 4 5 6 7 8 9 10 
WER 
0% 
2% 
4% 
6% 
8% 
10% 
12% 
14% 
16% 
1 2 3 4 5 6 7 8 9 10 
PER 
spelling NPR combined 
0% 
10% 
20% 
30% 
40% 
50% 
60% 
70% 
80% 
1 2 3 4 5 6 7 8 9 10 
WER 
131
other subjects). 
T jt wer shown four examples of 
NPRs; two f thm er rect Wrd of th Day 
entrie, and ad audio athd to the. Te other 
two re selcte fr te OD st. With nly 
fur ord and two difernt source we anted to 
ensre tht users ul ot be abl to tri thm-
elvs to a pcifc sytem. Sujcts understod te 
problem esily and raly if evr lok back at h 
exapls durig the ctual tst. 
The tt invold gnerting NPRs for 20 of the 
most dificult wrs for ur enric GP mdl 
fr the OD set (e.g., bochospe, paren-
chyma, tc.) Th words turned ut o b ostly 
unfilar to users as el (th average familarit 
score ws jt nder 1.9 on  4-point scle. No 
audi and o feback wer given. 
Users varid gretly in th choices they made. 
For th wor acupsure, te first wo slbls 
wer transcribed s AK-YO in the Dictinary of 
Cancer Terms, and users cam up with ACK-
YOU, AK-U,  AK-YOU. This nderscores that 
a god N2P odel would have to acunt fr fr 
mre G mapings than te 1 fund i or dat. 
Soeties uer d trouble asiging conso-
nats t sylabls (sylabifcation w’t required, 
but ubject tried anwy),  casion spliting 
them aros sylble boundaries (e.g., \BIL-IH-
RUE-BEN\ fr ilruin), whic guarntes an in-
sertion eror. It is qite likely tht som eror 
mdel might be ruird to dal wit uch isus. 
Nontels, evn thugh imperfct, the 
resultig NPR showd excelnt prois. Loking 
jt at the top ypthsi, wheras the averae 
PER on tse 20 word as about 45% for th 
G2 mdel, pronuciation otined from NPRs 
using th same G2P mdel (ew GP mapings pre-
clde te us of the N2P modl described i the 
prvious ctin) ad only arun 36% (+/-5%) 
hne ror ate. The cbined model showed an 
ev bter prformane of abut 3 (+/-5) 
PER. Ful rsults fr -bst list p to n=10 are 
shown i igre 3. 
5 Conclusions
and Further Work  
The xperiments we conducted are preliminary, 
and most of th ork remains to b don. More 
t ned t be clectd d alyze efre gd 
NPR-to-pronuiation oels cn b traind. Fur-
ther investigations ed t b oducted to ases 
t ara user’ abilty to genrat NPR nd 
how they tend to devite frm th genral graph-
em-to-pome ruls of Englis. 
Nonethles, w belive the experiments give 
strg idications that NPRs would b a xcelnt 
ource of infrmtion to imprve the quality of 
prniatio hypthes genratd from speling. 
Morever, it aear tat ovice users dn’t have 
much dificulty gnerting usfl NPR o tir 
own; e xpet hat hir skil would increase with 
use. Particularly useful would be fr th ytm to 
b ble to provid fdback, including enrating 
NPRs; we hae starte investigati this rvers 
problem, of btainig NPR from pronuciation, 
and ar ncurged by the inital results. 
References  
D. Bansal, N. air, R. Singh, and B. Raj. 209. A Joint 
ecoding Algorithm for Multiple-Example-Based 
Adit of Wrds to a Prnciation Leicon. Proc. 
ICSP’209, p. 2104-2107. 
F. Beaufays, et al. 3. Learnig Linguisticaly Valid 
Proncition From Acoustic Dat. Proc. Eu-
speh’03, Genva, p. 2593-2596. 
M. Biani and H. Ny. 208. Joint-Sequence Models for 
Grphem-to-Phonem Cversion. Sph Cmu-
nication, 50():43-451. 
G. Chug, C. Wang, S. enf, E. Filsko, and M. Tang. 
204. ombii Liguistic Knowledge  Acous-
tic Infration i Atomati Prunciation Lexin 
Geration. Prc. Interspech'04, Jej Isld, Korea. 
M. Davel d E. Barard. 20. Th Eficent Genera-
tion of Pronucition Dictionaries: Huma Factors 
durig Btsrapig. Pr. INTERSPECH 204, 
Korea. 
H. Frsr. 197. Dictionary pronuciation guides for 
Englih. Internatil Jual of Lexicoraphy, 
10(3), 18-208. 
L. Galescu and J. Alen. 201. Bi-directional Conver-
sion Betwe Graphmes an Phonmes Usig a 
Jit N-gram Model. Proc. 4t ISCA Tutorial nd 
Resarch Workshp on Speh Synthesi, Sctl. 
J. Kominek, S. Badskar, T. cultz, and A. Black. 
208. Iproving Spech Systems Built from Very 
Litle Dat. Pc. INTERPECH 208, Australi. 
E. McKn (ed.). 205. he New Oxford meicn Dic-
tionary (2 .). Oxford University Prs. 
T. Plkova nd A. Bnafot, 206. Learnig from 
Erors in Graphem-to-Phnem Convrsio. Pc. 
ISCLP’206. Pitsburg, USA. 
R.L. Weid. 198. The CM pronuciation dictionary, 
relas 0.6. tp:/w.seh.s.cmu.edu/cgi-
bin/cmudict. 
 
Figure 3. Phone ror ates for user-genrated NPRs. 
 
0% 
10% 
20% 
30% 
40% 
50% 
1 2 3 4 5 6 7 8 9 10 
PER 
Spelling NPR Combined 
132

