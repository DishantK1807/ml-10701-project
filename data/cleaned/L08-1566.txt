<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Adam Kilgarriff</author>
</authors>
<title>Large linguistically-processed Web corpora for multiple languages</title>
<date>2006</date>
<booktitle>In Companion Volume to Proceedings of the European Association of Computational Linguistics</booktitle>
<pages>87--90</pages>
<location>Trento</location>
<marker>Baroni, Kilgarriff, 2006</marker>
<rawString>Marco Baroni and Adam Kilgarriff. 2006. Large linguistically-processed Web corpora for multiple languages. In Companion Volume to Proceedings of the European Association of Computational Linguistics, pages 87–90, Trento.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Motoko Ueyama</author>
</authors>
<title>Building generaland special-purpose corpora by web crawling</title>
<date>2006</date>
<booktitle>In Proceedings of the 13th NIJL International Symposium, Language Corpora: Their Compilation and Application</booktitle>
<pages>31--40</pages>
<marker>Baroni, Ueyama, 2006</marker>
<rawString>Marco Baroni and Motoko Ueyama. 2006. Building generaland special-purpose corpora by web crawling. In Proceedings of the 13th NIJL International Symposium, Language Corpora: Their Compilation and Application, pages 31–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andr´as Bodrogligeti</author>
</authors>
<title>An academic reference grammar of modern literary Uzbek</title>
<date>2003</date>
<publisher>LINCOM Europa</publisher>
<location>Munich</location>
<contexts>
<context>rial was practically nonexistent on the web, and had to be created based on the BBC and Harakat materials by a dedicated translation effort.4 Fortunately, detailed descriptive grammars (in particular Bodrogligeti 2003) and a sizeable online dictionary (http://uzbek.firespeaker.org) already exist for the language. Kurdish, by resource density, is in the bottom quartile of MRDLs. While it is clearly Indo-European (b</context>
</contexts>
<marker>Bodrogligeti, 2003</marker>
<rawString>Andr´as Bodrogligeti. 2003. An academic reference grammar of modern literary Uzbek. LINCOM Europa, Munich.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlos Castillo</author>
<author>Ricardo Baeza-Yates</author>
</authors>
<title>Wire: an open-source web information retrieval environment</title>
<date>2005</date>
<booktitle>In Workshop on Open Source Web Information Retrieval (OSWIR</booktitle>
<contexts>
<context>d3, but for the general MRDL case the stability of the crawler is an important factor. After similar experiences with two other widely used crawlers, nutch and larbin, we settled on the WIRE crawler (Castillo and Baeza-Yates, 2005), which has high throughput and is very parallelizable. Results on our own crawler, nut, are reported in a companion paper, (Kornai and Hal´acsy, 2008). Offline, language identification is best perfo</context>
</contexts>
<marker>Castillo, Baeza-Yates, 2005</marker>
<rawString>Carlos Castillo and Ricardo Baeza-Yates. 2005. Wire: an open-source web information retrieval environment. In Workshop on Open Source Web Information Retrieval (OSWIR).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiang Chen</author>
<author>Jian-Yun Nie</author>
</authors>
<title>Web parallel text mining for chinese-english cross-language information retrieval</title>
<date>2000</date>
<booktitle>In NAACL-ANLP, Seattle</booktitle>
<pages>21--28</pages>
<contexts>
<context>driving CL/NLP/IR work (Resnik 1999) is attractive for major languages, finding sufficient material for MRDLs is still challenging. Even for major languages, automatic recognition of URL parallelism (Chen and Nie 2000) can have a surprisingly low yield, and to create a significant parallel corpus one needs to include resources such as literary text, religious texts, international laws, movie captioning, software i</context>
</contexts>
<marker>Chen, Nie, 2000</marker>
<rawString>Jiang Chen and Jian-Yun Nie. 2000. Web parallel text mining for chinese-english cross-language information retrieval. In NAACL-ANLP, Seattle, pages 21–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernard Comrie</author>
<author>editor</author>
</authors>
<title>The World’s Major Languages</title>
<date>1990</date>
<publisher>Oxford University Press</publisher>
<marker>Comrie, editor, 1990</marker>
<rawString>Bernard Comrie, editor. 1990. The World’s Major Languages. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara F Grimes</author>
<author>Joseph E Grimes</author>
</authors>
<title>Ethnologue: Languages of the World. SIL, fourteenth edition</title>
<date>2000</date>
<contexts>
<context> German, Spanish), the CJK languages (Chinese, Japanese, Korean), official languages of former colonial empires (Dutch, Portuguese, Russian), and a few dozen other major languages.1 As is well known (Grimes and Grimes, 2000) the majority (56%) of the world’s people speak neither one of the really large languages (100m speakers or more, accounting for about 40% of the world population) nor one of the 5,000 or so really s</context>
</contexts>
<marker>Grimes, Grimes, 2000</marker>
<rawString>Barbara F. Grimes and Joseph E. Grimes. 2000. Ethnologue: Languages of the World. SIL, fourteenth edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P´eter Hal´acsy</author>
<author>Andr´as Kornai</author>
<author>L´aszl´o N´emeth</author>
<author>Andr´as Rung</author>
<author>Istv´an Szakad´at</author>
<author>Viktor Tr´on</author>
</authors>
<title>Creating open language resources for Hungarian</title>
<date>2004</date>
<booktitle>In Proceedings of Language Resources and Evaluation Conference (LREC04). European Language Resources Association</booktitle>
<marker>Hal´acsy, Kornai, N´emeth, Rung, Szakad´at, Tr´on, 2004</marker>
<rawString>P´eter Hal´acsy, Andr´as Kornai, L´aszl´o N´emeth, Andr´as Rung, Istv´an Szakad´at, and Viktor Tr´on. 2004. Creating open language resources for Hungarian. In Proceedings of Language Resources and Evaluation Conference (LREC04). European Language Resources Association.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andr´as Kornai</author>
<author>P´eter Hal´acsy</author>
</authors>
<title>Google for the linguist on a budget</title>
<date>2008</date>
<booktitle>In LREC 2008 Web as Corpus Workshop proceedings</booktitle>
<pages>page</pages>
<note>to appear</note>
<marker>Kornai, Hal´acsy, 2008</marker>
<rawString>Andr´as Kornai and P´eter Hal´acsy. 2008. Google for the linguist on a budget. In LREC 2008 Web as Corpus Workshop proceedings, page to appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andr´as Kornai</author>
</authors>
<title>P´eter Hal´acsy, Viktor Nagy, Csaba Oravecz, Viktor Tr´on, and</title>
<date>2006</date>
<booktitle>In Proceedings of the EACL 2006 Workshop on Web as a Corpus</booktitle>
<marker>Kornai, 2006</marker>
<rawString>Andr´as Kornai, P´eter Hal´acsy, Viktor Nagy, Csaba Oravecz, Viktor Tr´on, and D´aniel Varga. 2006. Webbased frequency dictionaries for medium density languages. In Proceedings of the EACL 2006 Workshop on Web as a Corpus.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>Empirical Methods for Exploiting Parallel Texts</title>
<date>2001</date>
<publisher>MIT Press</publisher>
<marker>Melamed, 2001</marker>
<rawString>I. Dan Melamed. 2001. Empirical Methods for Exploiting Parallel Texts. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katharina Probst</author>
<author>Ralf Brown</author>
<author>Jaime Carbonell</author>
<author>Alon Lavie</author>
<author>Lori Levin</author>
<author>Erik Peterson</author>
</authors>
<title>Design and implementation of controlled elicitation for machine translation of low-density languages</title>
<date>2001</date>
<booktitle>In Proc. MT 2010 Workshop, 8th MT Summit</booktitle>
<location>Santiago de Compostela, Spain</location>
<contexts>
<context>e TLD, as would be 2Composed of 175k words manually translated from the target LCTL to English, plus 75k words of English text that is kept fixed across LCTLs: 30k news, a 20k Elicitation Corpus (see Probst et al 2001), and 25k words of text other than news. for Oriya in .in, this needs to be separated from a large amount of other material within the same TLD. Since the easiest way to limit a crawl is by TLD, our </context>
</contexts>
<marker>Probst, Brown, Carbonell, Lavie, Levin, Peterson, 2001</marker>
<rawString>Katharina Probst, Ralf Brown, Jaime Carbonell, Alon Lavie, Lori Levin, and Erik Peterson. 2001. Design and implementation of controlled elicitation for machine translation of low-density languages. In Proc. MT 2010 Workshop, 8th MT Summit, Santiago de Compostela, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Mining the web for bilingual text</title>
<date>1999</date>
<booktitle>In Proc. 37th ACL,pages527–534, UniversityofMaryland</booktitle>
<contexts>
<context>annoord/TextCat) both because we found it to be best of breed, and because it has the same permissive license, GNU LGPL, as the HUN* tools. While using the web as a corpus for driving CL/NLP/IR work (Resnik 1999) is attractive for major languages, finding sufficient material for MRDLs is still challenging. Even for major languages, automatic recognition of URL parallelism (Chen and Nie 2000) can have a surpr</context>
<context>arch reports eager to declare victory. First, automated collection of parallel corpora for MRD languages is not on the 5-10 year horizon, even though the method had been proposed nearly a decade ago (Resnik 1999), and has given rise to a whole cottage industry of web-based language resource building. Clearly, material must be collected from outside the TLD, even where there is a single TLD that offers good c</context>
</contexts>
<marker>Resnik, 1999</marker>
<rawString>Philip Resnik. 1999. Mining the web for bilingual text. In Proc. 37th ACL,pages527–534, UniversityofMaryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D´aniel Varga</author>
<author>Eszter Simon</author>
</authors>
<title>Hungarian named entity recognition with a maximum entropy approach</title>
<date>2007</date>
<journal>Acta Cybernetica</journal>
<volume>18</volume>
<contexts>
<context>of accuracy on 10k words that is more than sufficient for bootstrapping the process, see http://code.google.com/p/hunpos/wiki/ RelatedPapers. Named entity recognition, using the hunner maxent tagger (Varga and Simon 2007), similarly proceeds from a small, entirely manually created training corpus to larger, bootstrapped NER-tagged corpora. 4. Uzbek and Kurdish For the major languages it is generally trivial to find n</context>
</contexts>
<marker>Varga, Simon, 2007</marker>
<rawString>D´aniel Varga and Eszter Simon. 2007. Hungarian named entity recognition with a maximum entropy approach. Acta Cybernetica, 18(2):293–301.</rawString>
</citation>
</citationList>
</algorithm>

