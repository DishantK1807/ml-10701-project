of our method from (Shen et al., 2008) is that we
P08-1066
Zhongjun He, Qun Liu, and Shouxun Lin. 2008. Im-
C08-1041
to (Nivre and Scholz, 2004). Then we use the
C04-1010
(Koehn et al., 2003) introduced the concept of
N03-1017
according to (Chiang, 2007)’s extraction method.
J07-2003
gorithm (Hasan et al., 2008) or maximum entropy
D08-1039
Shen et al. (2008) propose the well-formed de-
P08-1066
(Shen et al., 2008), we just use the dependency
P08-1066
rameters involved. Besides, He et al. (2008) built
C08-1041
Hasan and Ney (2009) introduced a second word
N09-2005
table. He et al. (2009) just used the key phrases
P09-2031
trigger-based approach (Hasan and Ney, 2009).
N09-2005
Liang Huang, Wenbin Jiang, and Qun Liu. 2009.
D09-1127
Joakim Nivre and Mario Scholz. 2004. Determinis-
C04-1010
IBM model 1 (Brown et al., 1993), i.e. p(e|f),
J93-2003
David Chiang. 2005. A hierarchical phrase-based
P05-1033
become larger. Similarly, In (Shen et al., 2009),
D09-1008
training (Och, 2003).
P03-1021
David Chiang. 2007. Hierarchical phrase-based trans-
J07-2003
Chris Quirk, Arul Menezes, and Colin Cherry. 2005.
P05-1034
Libin Shen, Jinxi Xu, and Ralph Weischedel. 2008. A
P08-1066
rule table quality. Shen et al. (2008) discarded
P08-1066
on Test05. Besides, we also used Shen et al.(2008)’s WF structure to filter both sides. Al-
P08-1066
Franz Josef Och. 2003. Minimum error rate training
P03-1021
same method suggested in (Chiang, 2005) to
P05-1033
(He et al., 2008).
C08-1041
monolingual parser, i.e. (Huang et al., 2009).
D09-1127
Yuan Ding and Martha Palmer. 2005. Machine trans-
P05-1067
erable interest in SMT (Ding and Palmer, 2005;
P05-1067
Saˇsa Hasan and Hermann Ney. 2009. Comparison of
N09-2005 P09-2031
Quirk et al., 2005; Shen et al., 2008). Depen-
P05-1034 P08-1066
