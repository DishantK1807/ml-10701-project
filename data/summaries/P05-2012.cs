Brants. 2000.
A00-1031
Among these models, the basic ones are a translation model Pr(e|f) and a target language model Pr(e), which can be complemented by reordering models (if the language pairs presents very long alignments in training), word penalty to avoid favoring short sentences, class-based target-language models, etc (Och and Ney, 2004).
J04-4002
71 6 Related Work The approach to deal with inflected forms presented in (Ueffing and Ney, 2003) is similar in that it also tackles verbs in an English – Spanish task.
E03-1007
Several strategies to compute these probabilities have been proposed (Zens et al., 2004; Crego et al., 2004), but none of them takes into account the fact that, when it comes to translation, many different inflected forms of words share the same translation.
N04-1033
An improvement in translation using IBM model 1 in an Arabic – English task can be found in (Lee, 2004).
N04-4015
alignment results In order to assess the quality of the word alignment, we randomly selected from the training corpus 350 sentences, and a manual gold standard alignment has been done with the criterion of Sure and Possible links, in order to compute Alignment Error Rate (AER) as described in (Och and Ney, 2000) and widely used in literature, together with appropriately redefined Recall and Precision measures.
P00-1056
wouldn’t = would not, we’ve = we have) • English POS-tagging using freely-available TnT tagger (Brants, 2000), and lemmatization using wnmorph, included in the WordNet package (Miller et al., 1991).
A00-1031
