Curran and Moens (2002) experimented with corpus size and complexity of proximity features in building automatic thesauri.
P02-1030
Applying a POS tagger (Brill 1995) gives the following output: Surface Platinum is a precious metal . POS NNP VBZ DT JJ NN . Surface Molybdenum is a metal . POS NNP VBZ DT NN . A very good pattern to generalize from the alignment of these two strings would be Surface is a metal . POS NNP . We use the following notation to denote this alignment: “_NNP is a (*s*) metal.”, where “_NNP represents the POS tag NNP”.
J95-4004
Mann (2002) and Fleischman et al.(2003) used part of speech patterns to extract a subset of hyponym relations involving proper nouns.
P03-1001 W02-1111
Some of these patterns are similar to the ones discovered by Hearst (1992) while other patterns are similar to the ones used by Fleischman et al.(2003). 4.3 Time complexity To extract hyponym relations, we use a fixed number of patterns across a corpus.
C92-2082 P03-1001
We present an algorithm for extracting is-a relations, designed for the terascale, and compare it to a state of the art method that employs deep analysis of text (Pantel and Ravichandran 2004).
N04-1041
For the co-occurrence model, we used Minipar (Lin 1994), a broad coverage parser, to parse each data set.
C94-1079
Caraballo (1999) was the first to use clustering for labeling is-a relations using conjunction and apposition features to build noun clusters.
P99-1016
771 Riloff and Shepherd (1997) used a semiautomatic method for discovering similar words using a few seed examples by using pattern-based techniques and human supervision.
W97-0313
Our co-occurrence model (Pantel and Ravichandran 2004) makes use of semantic classes like those generated by CBC.
N04-1041
The syntactical co-occurrence approach has worst-case time complexity O(n 2 k), where n is the number of words in the corpus and k is the featurespace (Pantel and Ravichandran 2004).
N04-1041
For the pattern-based approach, we use Brill’s POS tagger (1995) to tag each data set.
J95-4004
With the increased size of the Web, more and more training data is becoming available, and as Banko and Brill (2001) showed, even rather simple learning algorithms can perform well when given enough data.
H01-1052
2.2 Co-occurrence-based approaches The second class of algorithms uses cooccurrence statistics (Hindle 1990, Lin 1998).
P90-1034 P98-2127
Berland and Charniak (1999) used similar pattern-based techniques and other heuristics to extract meronymy (part-whole) relations.
P99-1008
Recently, Pantel and Ravichandran (2004) extended this approach by making use of all syntactic dependency features for each noun.
N04-1041
2.1 Pattern-based approaches Marti Hearst (1992) was the first to use a pattern-based approach to extract hyponym relations from a raw corpus.
C92-2082
questions Following Fleischman et al.(2003), we select the 50 definition questions from the TREC2003 (Voorhees 2003) question set.
P03-1001
We apply the log likelihood principle (Dunning 1993) to compute this score.
J93-1003
These relationships, automatically learned in (Pantel and Ravichandran 2004), include appositions, nominal subjects, such as relationships, and like relationships.
N04-1041
Algorithms light in linguistic theories but rich in available training data have been successfully applied to several applications such as machine translation (Och and Ney 2002), information extraction (Etzioni et al.2004), and question answering (Brill et al.2001). In the last decade, we have seen an explosion in the amount of available digital text resources.
P02-1038
