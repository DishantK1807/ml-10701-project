<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>S Abrilian</author>
<author>J-C Martin</author>
<author>L Devillers</author>
</authors>
<title>A Corpus-Based Approach for the Modeling of Multimodal Emotional Behaviors for the Specification of Embodied Agents</title>
<date>2005</date>
<publisher>HCI International</publisher>
<location>Las Vegas, USA</location>
<contexts>
<context> temporal relationships? The main difficult point of this representation is to find the useful levels of description in term of granularity and temporality. We have collected two audio-video corpora (Abrilian et al., 2005) (Zara et al, 2007), one is extracted from TV news (naturalistic corpus), the other is the record of a two-players game designed in order to induce emotions. The first corpus contains monologues, and</context>
</contexts>
<marker>Abrilian, Martin, Devillers, 2005</marker>
<rawString>Abrilian, S., Martin, J-C., Devillers, L. (2005). A Corpus-Based Approach for the Modeling of Multimodal Emotional Behaviors for the Specification of Embodied Agents.  HCI International 2005, Las Vegas, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cowie</author>
<author>Cornelius</author>
</authors>
<title>Describing the emotional states expressed in speech</title>
<date>2003</date>
<journal>Speech Communication</journal>
<pages>40--1</pages>
<contexts>
<context>types. Natural databases highlighted a descriptive challenge: the expressions of emotions that they contain are not adequately described by a few theoretically derived labels, such as basic emotions (Cowie and Cornelius 2003, Devillers, Vidrascu &amp; Lamel 2005, Devillers et al., 2006). There is indeed a significant gap between the affective states observed in artificial data (acted data or induced data) and those observed </context>
</contexts>
<marker>Cowie, Cornelius, 2003</marker>
<rawString>Cowie &amp; Cornelius (2003). Describing the emotional states expressed in speech. Speech Communication, 40(1-2), pp. 5-32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Devillers</author>
<author>S Abrilian</author>
<author>J-C Martin</author>
</authors>
<title>Representing real life emotions in audiovisual data with non basic emotional patterns and context features</title>
<date>2005</date>
<contexts>
<context>e coding of emotional behavior features multiple types of descriptor – verbal labels, abstract dimensions and contextual annotations such as a plain text annotation of the global emotional situation (Devillers et al. 2005). The aim of the current study was to consolidate our expertise on annotation by defining and evaluating a scheme for coding. The main goal was to find out the most promising descriptors for describi</context>
</contexts>
<marker>Devillers, Abrilian, Martin, 2005</marker>
<rawString>Devillers, L., Abrilian, S. and Martin, J.-C. (2005) Representing real life emotions in audiovisual data with non basic emotional patterns and context features.</rawString>
</citation>
<citation valid="true">
<date></date>
<booktitle>1st International Conference on Affective Computing &amp; Intelligent Interaction (ACII'2005</booktitle>
<pages>22--24</pages>
<location>Beijing, China</location>
<marker></marker>
<rawString>1st International Conference on Affective Computing &amp; Intelligent Interaction (ACII'2005) Beijing, China, October 22-24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vidrascu Devillers</author>
<author>Lamel</author>
</authors>
<title>Challenges in real-life emotion annotation and machine learning based detection</title>
<date>2005</date>
<journal>Neural Networks</journal>
<volume>18</volume>
<pages>407--422</pages>
<marker>Devillers, Lamel, 2005</marker>
<rawString>Devillers, Vidrascu &amp; Lamel, (2005). “Challenges in real-life emotion annotation and machine learning based detection”, Neural Networks 18, pp. 407-422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Devillers</author>
<author>L Vidrascu</author>
</authors>
<title>Emotion recognition, «Speaker</title>
<date>2007</date>
<editor>characterization », Christian Müller, Susanne Schötz (eds</editor>
<publisher>Springer-Verlag</publisher>
<contexts>
<context>nal behaviour is needed for various applications in multimodal human-machine interaction such as the design of emotional conversational agents (Martin et al., 2005) or of emotional detection systems (Devillers and Vidrascu, 2007). Yet, building such models requires appropriate definition of various levels for representing the emotions themselves but also some contextual information such as the events that elicit these emotio</context>
</contexts>
<marker>Devillers, Vidrascu, 2007</marker>
<rawString>Devillers, L., Vidrascu, L. (2007), Emotion recognition, «Speaker characterization », Christian Müller, Susanne Schötz (eds.), Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Devillers</author>
<author>R Cowie</author>
<author>J-C Martin</author>
<author>E Douglas-Cowie</author>
<author>S Abrilian</author>
<author>M McRorie</author>
</authors>
<title>Real life emotions in French and English TV video clips: an integrated annotation protocol combining continuous and discrete approaches</title>
<date>2006</date>
<journal>LREC</journal>
<location>Genoa, Italy</location>
<contexts>
<context>: the expressions of emotions that they contain are not adequately described by a few theoretically derived labels, such as basic emotions (Cowie and Cornelius 2003, Devillers, Vidrascu &amp; Lamel 2005, Devillers et al., 2006). There is indeed a significant gap between the affective states observed in artificial data (acted data or induced data) and those observed with “real-life spontaneous data in situ”. This difference</context>
<context>e been used to predict major modal emotions. We already used the appraisal dimensions in emotion perception investigation for describing complex blended emotional behaviour of the video-taped person (Devillers et al. 2006). This previous study also pointed out some difficulties in the manual labelling of appraisal dimensions. One of the main difficulties with the appraisal categories is that they are inherently linked</context>
<context> term „everyday labels‟ (to describe words of the kind listed in Table 1 above. Table 1 aggregates the labels that were observed as being relevant to the annotation of naturalistic TV clips material (Devillers et al., 2006). 3.4. Events annotation We defined a first scheme of annotation and tested it on a subset of EmoTV (28 clips). Our annotation strategy is to proceed in two steps. First we identify and annotate the </context>
</contexts>
<marker>Devillers, Cowie, Martin, Douglas-Cowie, Abrilian, McRorie, 2006</marker>
<rawString>Devillers, L., Cowie, R., Martin, J.-C., Douglas-Cowie, E., Abrilian, S., McRorie, M. (2006) Real life emotions in French and English TV video clips: an integrated annotation protocol combining continuous and discrete approaches. (LREC 2006), Genoa, Italy, 24-27 may.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Gratch</author>
<author>S Marsella</author>
</authors>
<title>A domain independent framework for modeling emotion</title>
<date>2004</date>
<journal>Journal of Cognitive Systems Research</journal>
<volume>5</volume>
<pages>269--306</pages>
<contexts>
<context>l maps characteristics of these disparate processes into a common set of intermediate terms (intermediate between stimuli and response, between organism and environment) called „appraisal variables‟ (Gratch and Marsella, 2004). Scherer‟s appraisal dimensions (Sherer et al., 2001) have been studied in emotion recall experiments and have been used to predict major modal emotions. We already used the appraisal dimensions in </context>
</contexts>
<marker>Gratch, Marsella, 2004</marker>
<rawString>Gratch, J., Marsella, S., (2004)  A domain independent framework for modeling emotion. Journal of Cognitive Systems Research, 5 (4), 269-306.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-C Martin</author>
<author>S Abrilian</author>
<author>L Devillers</author>
<author>M Lamolle</author>
<author>M Mancini</author>
<author>C Pelachaud</author>
</authors>
<title>Levels of Representation in the Annotation of Emotion for the Specification of Expressivity in ECAs</title>
<date></date>
<booktitle>5th International Working Conference On Intelligent Virtual Agents (IVA'2005</booktitle>
<pages>12--14</pages>
<location>Kos, Greece</location>
<marker>Martin, Abrilian, Devillers, Lamolle, Mancini, Pelachaud, </marker>
<rawString>Martin, J.-C., Abrilian, S., Devillers, L., Lamolle, M., Mancini, M. and Pelachaud, C. Levels of Representation in the Annotation of Emotion for the Specification of Expressivity in ECAs. 5th International Working Conference On Intelligent Virtual Agents (IVA'2005) Kos, Greece, Sept 12-14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ortony</author>
<author>G L Clore</author>
<author>A Collins</author>
</authors>
<title>The cognitive structure of emotions</title>
<date>1988</date>
<publisher>Cambridge, U.K., Cambridge University Press</publisher>
<contexts>
<context>on event to all clips. For all the other emotional events, a list of events assessed as being relevant to our set of clips, was defined. Three groups of emotional events are defined in the OCC model (Ortony, Clore, &amp; Collins, 1988) depending on what is evaluated: the consequences of events for oneself or for others, the actions of others and the perception of objects. In our corpus, we only observed events that are being evalu</context>
</contexts>
<marker>Ortony, Clore, Collins, 1988</marker>
<rawString>Ortony, A., Clore, G.L., Collins, A. (1988). The cognitive structure of emotions. Cambridge, U.K., Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Sander</author>
<author>D Grandjean</author>
<author>K Scherer</author>
</authors>
<title>A sytsems approach to appraisal mechanisms in emotion Neural Networks 18</title>
<date>2005</date>
<pages>317--352</pages>
<contexts>
<context>ions in terms of the „appraisals‟ that they involve. Appraisals are perceptual evaluations of emotion-relevant aspects of the situation on a set of dimensions suggested by Scherer and his colleagues (Sander et al 2005). The following set of labels was used to describe the protagonist‟s appraisal of one event E at the focus of his/her emotional state. These items are grouped under four broader headings.  Relevance</context>
</contexts>
<marker>Sander, Grandjean, Scherer, 2005</marker>
<rawString>Sander, D., Grandjean, D., &amp; Scherer, K. (2005) A sytsems approach to appraisal mechanisms in emotion Neural Networks 18, pp 317-352.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K R Scherer</author>
<author>A Schorr</author>
<author>T Johnstone</author>
<author>eds</author>
</authors>
<date>2001</date>
<booktitle>Appraisal Processes in Emotion</booktitle>
<publisher>University Press</publisher>
<location>New York: Oxford</location>
<marker>Scherer, Schorr, Johnstone, eds, 2001</marker>
<rawString>Scherer, K. R., Schorr, A. and Johnstone, T., eds. (2001). Appraisal Processes in Emotion. New York: Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Schroeder</author>
<author>L Devillers</author>
<author>K Karpouzis</author>
<author>JC Martin</author>
<author>C Pelachaud</author>
<author>Ch Peter</author>
<author>H Pirker</author>
<author>B Schuller</author>
<author>J Tao</author>
<author>I Wilson</author>
</authors>
<title>What should a generic emotion markup language be able to represent</title>
<date>2007</date>
<booktitle>ACII07, 2nd International Conference on Affective Computing &amp; Intelligent Interaction</booktitle>
<marker>Schroeder, Devillers, Karpouzis, Martin, Pelachaud, Peter, Pirker, Schuller, Tao, Wilson, 2007</marker>
<rawString>Schroeder, M., Devillers, L., Karpouzis, K., Martin, JC., Pelachaud, C., Peter, Ch., Pirker, H., Schuller, B., Tao, J. and Wilson I. (2007): What should a generic emotion markup language be able to represent?, ACII07, 2nd  International Conference on Affective Computing &amp; Intelligent Interaction.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Wilhelm</author>
<author>D Schoebi</author>
<author>M Perrez</author>
</authors>
<title>Frequency estimates of emotions in everyday life from a diary method's perspective: a comment on Scherer et al.'s survey-study &amp;quot;Emotions in everyday life</title>
<date>2004</date>
<journal>Social Science Information</journal>
<volume>43</volume>
<pages>647--665</pages>
<marker>Wilhelm, Schoebi, Perrez, 2004</marker>
<rawString>Wilhelm, P., Schoebi, D., Perrez, M. (2004). Frequency estimates of emotions in everyday life from a diary method's perspective: a comment on Scherer et al.'s survey-study &amp;quot;Emotions in everyday life&amp;quot;. Social Science Information 43: 647-665.</rawString>
</citation>
</citationList>
</algorithm>

