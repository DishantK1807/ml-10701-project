<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<title>A german sign language corpus of the domain weather report</title>
<date>2006</date>
<booktitle>In Fifth International Conference on Language Resources and Evaluation</booktitle>
<pages>2000--2003</pages>
<location>Genoa, Italy</location>
<marker>2006</marker>
<rawString>2006. A german sign language corpus of the domain weather report. In Fifth International Conference on Language Resources and Evaluation, pages 2000–2003, Genoa, Italy, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>DESIRE</author>
</authors>
<title>Aachener Glossenumschrift. Technical report, RWTH Aachen. ¨Ubersicht ¨uber die Aachener Glossennotation</title>
<date>2004</date>
<contexts>
<context>nual annotation of sign language videos is a difficult task, so notation variations within one corpusareoftenacommonproblem. Basically, inthiswork the specifications of the Aachener Glossenumschrift (DESIRE, 2004) are followed in this work. However, due to different groups that worked on the different translations, variations in the gloss notation style occur. As an example, the sentences in Table 2 in Englis</context>
</contexts>
<marker>DESIRE, 2004</marker>
<rawString>DESIRE. 2004. Aachener Glossenumschrift. Technical report, RWTH Aachen. ¨Ubersicht ¨uber die Aachener Glossennotation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philippe Dreuw</author>
<author>David Rybach</author>
<author>Thomas Deselaers</author>
<author>Morteza Zahedi</author>
<author>Hermann Ney</author>
</authors>
<title>Speech recognition techniques for a sign language recognition system</title>
<date>2007</date>
<booktitle>In Interspeech</booktitle>
<pages>2513--2516</pages>
<location>Antwerp, Belgium</location>
<contexts>
<context> weather reports, a corpus of 2468 sentences in German and DGS was reported by (Bungeroth et al., 2006). It is particularly used for SMT and sign language recognition. • The RWTH-BOSTON-104 Database (Dreuw et al., 2007) contains 201 sentences in American sign language with English annotations. This corpus is mainly used for automatic sign language recognition. 3. Corpus Setup and Notation The sentences from the ori</context>
</contexts>
<marker>Dreuw, Rybach, Deselaers, Zahedi, Ney, 2007</marker>
<rawString>Philippe Dreuw, David Rybach, Thomas Deselaers, Morteza Zahedi, and Hermann Ney. 2007. Speech recognition techniques for a sign language recognition system. In Interspeech, pages 2513–2516, Antwerp, Belgium, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C T Hemphill</author>
<author>J J Godfrey</author>
<author>G R Doddington</author>
</authors>
<title>The atis spoken language systems pilot corpus</title>
<date>1990</date>
<booktitle>In Proceedings of DARPA Speech and Natural Language Workshop</booktitle>
<pages>96--101</pages>
<location>Hidden Valley, PA</location>
<contexts>
<context>ing quality. We therefore introduce a sign language corpus suitable for basic SMT and sign language analysis, the ATIS corpus. The corpus is based on the Air Travel Information System (ATIS) dataset (Hemphill et al., 1990). It contains transcribed English phrases and sentences of an information service for booking flights and travel information. Of this dataset, 595 sentences were chosen as a base. The corpus was tran</context>
</contexts>
<marker>Hemphill, Godfrey, Doddington, 1990</marker>
<rawString>C.T. Hemphill, J.J. Godfrey, and G.R. Doddington. 1990. The atis spoken language systems pilot corpus. In Proceedings of DARPA Speech and Natural Language Workshop, pages 96–101, Hidden Valley, PA., June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Leeson</author>
<author>J Saeed</author>
<author>A Macduff</author>
<author>D Byrne-Dunne</author>
<author>C Leonard</author>
</authors>
<title>Moving Heads and Moving Hands: Developing a Digital Corpus of Irish Sign Language</title>
<date>2006</date>
<booktitle>In Proceedings of Information Technology and Telecommunications Conference</booktitle>
<location>Carlow, Ireland</location>
<contexts>
<context>005) published results on sign language recognition for this corpus. The corpus has focus on linguistic topics, though. • The Signs of Ireland corpus developed at the Centre for Deaf Studies, Dublin (Leeson et al., 2006) contains video data of approximately 40 Deaf ISL users collected over 3 years. Participants tell personal narrative, a children’s story and sign elicited sentences. The corpus is hand annotated. • (</context>
</contexts>
<marker>Leeson, Saeed, Macduff, Byrne-Dunne, Leonard, 2006</marker>
<rawString>L. Leeson, J. Saeed, A. Macduff, D. Byrne-Dunne, and C. Leonard. 2006. Moving Heads and Moving Hands: Developing a Digital Corpus of Irish Sign Language. In Proceedings of Information Technology and Telecommunications Conference 2006, Carlow, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Morrissey</author>
<author>A Way</author>
<author>D Stein</author>
<author>J Bungeroth</author>
<author>H Ney</author>
</authors>
<title>Towards a hybrid data-driven mt system for sign languages</title>
<date>2007</date>
<booktitle>In Proc. of the 11th Machine Translation Summit</booktitle>
<pages>329--335</pages>
<location>Sk¨ovde, Sweden</location>
<contexts>
<context> ATIS corpus was used in a number of experiments for automaticstatisticalmachinetranslationandautomaticsign language recognition. For the translation part, experiments were reported on the corpus by (Morrissey et al., 2007) and (Morrissey, 2008) for the language pairs ISL–English, ISL–German, DGS– English and DGS–German. First experiments on the language pairs SASL–German and SASL–English show similar baseline results </context>
</contexts>
<marker>Morrissey, Way, Stein, Bungeroth, Ney, 2007</marker>
<rawString>S. Morrissey, A. Way, D. Stein, J. Bungeroth, and H. Ney. 2007. Towards a hybrid data-driven mt system for sign languages. In Proc. of the 11th Machine Translation Summit, pages 329–335, Sk¨ovde, Sweden, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Morrissey</author>
</authors>
<title>An Exploration of Data-driven Machine Translation for Sign Languages</title>
<date>2008</date>
<tech>Ph.D. thesis</tech>
<institution>Dublin City University</institution>
<location>Dublin</location>
<contexts>
<context>mber of experiments for automaticstatisticalmachinetranslationandautomaticsign language recognition. For the translation part, experiments were reported on the corpus by (Morrissey et al., 2007) and (Morrissey, 2008) for the language pairs ISL–English, ISL–German, DGS– English and DGS–German. First experiments on the language pairs SASL–German and SASL–English show similar baseline results as for the already rep</context>
</contexts>
<marker>Morrissey, 2008</marker>
<rawString>S. Morrissey. 2008. An Exploration of Data-driven Machine Translation for Sign Languages. Ph.D. thesis, Dublin City University, Dublin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Neidle</author>
<author>J Kegl</author>
<author>D MacLaughlin</author>
<author>B Bahan</author>
<author>R G Lee</author>
</authors>
<title>The Syntax of American Sign Language</title>
<date>2000</date>
<contexts>
<context> difficult. • The American Sign Language Linguistic Research group at Boston University created a set of videos in American sign language which is partly available on their website3 and described in (Neidle et al., 2000). All videos are annotated and recorded from three different perspectives. (Zahedi et al., 2005) published results on sign language recognition for this corpus. The corpus has focus on linguistic top</context>
</contexts>
<marker>Neidle, Kegl, MacLaughlin, Bahan, Lee, 2000</marker>
<rawString>C. Neidle, J. Kegl, D. MacLaughlin, B. Bahan, and R. G. Lee. 2000. The Syntax of American Sign Language.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Stein</author>
<author>P Dreuw</author>
<author>H Ney</author>
<author>S Morrissey</author>
<author>A Way</author>
</authors>
<title>Hand in hand: Automatic sign language to speech translation</title>
<date>2007</date>
<booktitle>In 11th Conference on Theoretical and Methodological Issues in MachineTranslation (TMI-07</booktitle>
<pages>214--220</pages>
<publisher>MIT Press</publisher>
<location>Cambridge, MA</location>
<contexts>
<context>ents on the language pairs SASL–German and SASL–English show similar baseline results as for the already reported ones. This provides feedback information of the continuous quality of the corpus. In (Stein et al., 2007) the corpus is additionaly used in the context of a data-driven sign-language-to-speech system. Here, automatic sign language recognition was applied to the ISL videos. This is a more demanding task </context>
</contexts>
<marker>Stein, Dreuw, Ney, Morrissey, Way, 2007</marker>
<rawString>MIT Press, Cambridge, MA, USA. D. Stein, P. Dreuw, H. Ney, S. Morrissey, and A. Way. 2007. Hand in hand: Automatic sign language to speech translation. In 11th Conference on Theoretical and Methodological Issues in MachineTranslation (TMI-07), pages 214–220, Sk¨ovde, Sweden, September.</rawString>
</citation>
</citationList>
</algorithm>

