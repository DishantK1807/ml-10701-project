1:143	Living up to standards   Margaret King TIM/ISSCO ETI University of Geneva Margaret.King@issco.unige.ch    Abstract This paper attacks one part of the question "Are evaluation methods, metrics and resources reusable" by arguing that a set of ISO standards developed for the evaluation of software in general are as applicable to natural language processing software as to any other.
2:143	Main features of the ISO proposals are presented, and a number of applications where they have been applied are mentioned, although not discussed in any detail.
3:143	Acknowledgements The work recorded here is far from being all my own.
4:143	I would like first to record my thanks to Nigel Bevan, technical editor of the ISO standards discussed for much interesting and enlightening discussion.
5:143	Then many thanks must go to all my colleagues in the EAGLES and ISLE projects, especially Sandra Manzi and Andrei Popescu-Belis.
6:143	Finally, I must thank all those whose work on applying the standards reported here provoked reflection and helped to convince me of the value of the approach: Marc Blasband, Maria Canelli, Dominique Estival, Daniele Grasso, Vronique Sauron, Marianne Starlander and Nancy Underwood.
7:143	1 Introduction      This paper is constructed around a syllogism: 1.
8:143	ISO standards 9126 and 14598 are applicable to the evaluation of any type of software 2.
9:143	Natural language processing software is a type of software 3.
10:143	ISO standards 9126 and 14598 are applicable to the evaluation of natural language processing software.
11:143	In support of the major premise, I shall set out some of the major features of the ISO standards in question.
12:143	The minor premise needs no support: indeed, it is almost a tautology.
13:143	The truth of the conclusion will logically depend therefore on whether I have managed to convince the reader of the truth of the major premise.
14:143	There will be little explicit argument in this direction: simply setting out key features of the approach should suffice.
15:143	I will try, however, to reinforce the conclusion by briefly reviewing a number of natural language processing applications where the ISO standards have been followed with encouraging results.
16:143	My hope, of course, is to encourage readers to apply the standards themselves.
17:143	2 ISO standards work on software evaluation ISO has been publishing standards on software evaluation since 1991.
18:143	The bibliography gives a detailed picture of what standards have already been published and of what standards are in preparation.
19:143	ISO/IEC 9126 was the first standard to appear.
20:143	It has subsequently been modified, and in its new versions the original content of 1991 has been refined, modified and distributed over a series of separate but inter-related standards.
21:143	The keystone of ISO work is that the basis of an evaluation is an explicit and detailed statement of what is required of the object to be evaluated.
22:143	This statement is formulated very early in the process of defining an evaluation and is called a quality model.
23:143	The process of evaluation involves defining how measurements can be applied to the object to be evaluated in order to discover how closely it meets the requirements set out in the quality model.
24:143	The object to be evaluated is a clumsy phrase.
25:143	It has been used because, in the ISO picture, evaluation may take place at any point in the lifecycle of a software product, and may have as its object not only the final product but intermediate products, including specifications and code which has not yet been executed.
26:143	It follows from this that a quality model may apply to a set of specifications just as much as to a piece of finished software.
27:143	Indeed, one might envisage using quality models as a way of guiding the whole process of producing a software product, from initial research and prototyping through to delivering and field testing the final product.
28:143	That this is in line with best practice in software engineering constitutes, to my mind, an argument in favour of the ISO proposals.
29:143	As well as a set of standards relating to the definition of quality models (the 9126 series) ISO also offers a set of standards relating to the process of evaluation (the 14598 series).
30:143	One document sets out a standard for the evaluation process seen at its most generic level, further proposals relate definition of the process to the particular viewpoints of software developers, of acquirers of software and of evaluators typically working as third party evaluators.
31:143	Other documents in the 14598 series provide supporting material for those involved in evaluation, offering standards for planning and management of evaluations and for documentation of evaluation modules.
32:143	Of the 9126 series, only the first document which directly deals with quality models has as yet been published.
33:143	Documents in preparation deal with standards for the metrics which form a critical accompaniment to any quality model.
34:143	It would be unrealistic in the space of a single paper to discuss even the documents already published in any detail.
35:143	In what follows, we concentrate on outlining the foundations of the ISO proposals, the quality model and the process of evaluation.
36:143	3 Quality models (ISO 9126) A quality model consists of a set of quality characteristics, each of which is decomposed into a set of quality sub-characteristics.
37:143	Metrics measure how an object to be evaluated performs with respect to the quality characteristics and sub-characteristics.
38:143	The quality characteristics and sub-characteristics making up the quality model of ISO 9126-1/01 are shown in figure 1, on the next page.
39:143	All that figure 1 shows are names: ISO 9126-1/01 gives both definitions and discussion.
40:143	The quality characteristics are intended to be applicable to any piece of software product or intermediate product.
41:143	They are thus necessarily defined at a rather high level of generality, and need to be made more specific before they are applicable to any particular piece of software.
42:143	They are also defined through natural language definitions, and are thus not formal in the mathematical or logical sense.
43:143	This being so, they are open to interpretation.
44:143	Defining a specific evaluation implies deciding on an appropriate interpretation for that evaluation.
45:143	ISO 9126/01, whilst not barring the possibility that a quality model other than that contained in the standard might be used, requires that if another model is used, it should be clearly described.
46:143	Software quality shall be evaluated using a defined quality model.
47:143	A quality model shall be used when setting quality goals for software products and intermediate products.
48:143	This part of ISO/IEC 9126 provides a recommended quality model which can be used as a checklist of issues relating to quality (although other ways of categorising quality may be more appropriate in particular circumstances).
49:143	When a quality model other than that in this part of ISO/IEC 9126 is used it shall be clearly described. (ISO 9126/01, 1.5, Quality relationships).
50:143	Work within the EAGLES project on defining a general framework for evaluation design extended this model by allowing the quality sub-characteristics in their turn to be   decomposed; the process of decomposition being repeated if necessary.
51:143	suitability accuracy interoperability security  functionality                                  Figure 1   The structure thus obtained is hierarchical, and, theoretically of unlimited depth.
52:143	ISO 9126-1/01 does not rigidly specify the relationship between quality characteristics and metrics.
53:143	The EAGLES extension requires that each terminal node of the structure has at least one metric associated with it.
54:143	The structure then becomes a hierarchy of attribute value pairs, where each node is labelled with the name of an attribute.
55:143	The values of the attributes at the terminal nodes are directly obtained by the application of metrics.
56:143	The value of a higher level node is obtained by combining the values of attributes nodes immediately dominated by the higher level node: values percolate upwards.
57:143	Exactly how the combination of values is done is determined by a combining function which reflects the relative importance of the attributes in a particular evaluation.
58:143	This formalization provides an operational semantics for any particular instantiation of the quality model.
59:143	Once the evaluation designer has decided what attributes to include in his quality model software product quality reliability usability maturity fault tolerance recoverability understandability learnability operability attractiveness time behaviour resource utilisation analysability changeability stability testability portability efficiency maintainability adaptability installability co-existence replaceability and how to organise them, and once he has defined and assigned metrics to the terminal nodes, what functionality, for example, means within that quality model is defined by the decomposition of the functionality node and by the associated metrics.
60:143	Metrics will be discussed only briefly here.
61:143	The ISO standard distinguishes between internal metrics, external metrics and quality in use metrics.
62:143	The difference between them is determined by what kind of an evaluation object they are applied to.
63:143	Internal metrics apply to static properties of software, that is software considered independently of its execution.
64:143	Examples might be the number of lines of code or the programming language used.
65:143	As can be seen from the inclusion of the programming language in this list, metrics are not necessarily quantitative in their nature, although they should, of course, be as objective as possible.
66:143	(This is one of the points we shall not go into further here.)
67:143	External metrics apply to software when it is being executed, to the behaviour of the system as seen from outside.
68:143	Thus they may measure the accuracy of the results, the response time of the software, the learnability of the user interface and a host of other attributes that go to make up the quality of the software as a piece of software.
69:143	Quality in use metrics apply when the software is being used to accomplish a particular task in a particular environment.
70:143	They are more concerned with the effects of using the software than with the software itself.
71:143	Quality in use metrics are therefore very dependent on a particular environment and a particular task.
72:143	Quality in use is itself a superordinate aspect of quality, for these same reasons.
73:143	It is clearly influenced by the quality characteristics which make up the quality model, but is determined by the interaction of different quality characteristics in a particular task environment.
74:143	The ISO standards published so far say little about what makes a metric a good metric.
75:143	Some work elsewhere (Popescu-Belis, 1999, Hovy et al, 2003) has made some suggestions.
76:143	First, metrics should be coherent, in the sense that they should respect the following criteria:  A metric should reach its highest value for perfect quality (with respect to the attribute being measured), and, reciprocally, only reach its highest level when quality is perfect.
77:143	 A metric should reach its lowest level only for the worst possible quality (again, with respect to the attribute being tested)  A metric should be monotonic: that is, if the quality of software A is higher than that of software B, then the score of A should be higher than the score of B. We might compare two metrics (or more strictly two rating functions: see the section on process below) by saying that a metric m 1  is more severe than a metric m 2  if it yields lower scores than m 2  for every possible quality level.
78:143	Conversely, one metric may be more lenient than another.
79:143	To these rather formal considerations, we might add:  A metric must be clear and intuitive  It must correlate well with human judgements under all conditions  It must measure what it is supposed to measure  It must be reliable, exhibiting as little variance as possible across evaluators or for equivalent inputs  It must be cheap to prepare and to apply  It should be automated if possible 4 Evaluation process (ISO 14598) A first section of ISO 14598-1/99 is concerned with an overview of how all the different 9126 and 14596 documents concerned with software evaluation fit together.
80:143	This overview can be summarized quite briefly.
81:143	It is fundamental to the preparation of any evaluation that a quality model reflecting the users requirements of the object to be evaluated be constructed.
82:143	The 9126 series of documents is intended to support construction of the quality model.
83:143	The 14598 series is concerned with the process of evaluation, seen from different viewpoints.
84:143	Separate documents in the series tackle evaluation from the point of view of developers, acquirers and (third party) evaluators.
85:143	All of these make use of the 9126 series, and are further supported by the second half of 14598-1, which sets out a generic picture of the process of evaluation, and by two further documents, the first concerned with planning and management of a software evaluation process, the second with guidance for documenting evaluation modules.
86:143	Although these other documents in the series are clearly important, we limit ourselves here to summarizing the process of evaluation, as set out in ISO 14598-1.
87:143	The evaluation process is conceived as being generic: it applies to component evaluation as well as to system evaluation, and may be applied at any appropriate phase of the product life cycle.
88:143	The evaluation process is broken down into four main stages, each of which is considered separately below:  Stage I: Establish evaluation requirements.
89:143	This step is broken down into a further three steps:  a) Establish the purpose of the evaluation  The commentary on this point reveals just how wide the scope of the standard is intended to be.
90:143	The purpose of evaluating the quality of an intermediate product may be to:  Decide on the acceptance of an intermediate product from a subcontractor  Decide on the completion of a process and when to send products to the next process  Predict or estimate end product quality  Collect information on intermediate products in order to control and manage the process (The reader will remember that intermediate product means, for example, specifications or code before it is executed).
91:143	The purpose of evaluating an end product may be to:  Decide on the acceptance of the product  Decide when to release the product  Compare the product with competitive products  Select a product from among alternative products  Assess both positive and negative effects of a product when it is used  Decide when to enhance or replace the product.
92:143	It follows from this very broad range of possibilities that the standard is meant to apply not only to any kind of intermediate or final software product, but to any evaluation scenario, including comparative evaluation.
93:143	b) Identify types of products to be evaluated  Types of products here does not mean application software, but rather is concerned with the stage reached in the products life cycle, which determines whether and what intermediate product or final product is to be evaluated.
94:143	c) Specify quality model  The quality model is, of course, to be defined using ISO 9126-1/01 as a guide.
95:143	However, a note quoted again below adds:  The actual characteristics and sub-characteristics which are relevant in any particular situation will depend on the purpose of the evaluation and should be identified by a quality requirements study.
96:143	The ISO/IEC 9126-1 characteristics and subcharacteristics provide a useful checklist of issues related to quality, but other ways of categorising quality may be more appropriate in particular circumstances. (ISO 14598-1/99)  An important word here is checklist: the basic purpose of the ISO quality model is to serve as a guide and as a reminder for what should be included in evaluating software.
97:143	Arguing about the exact interpretation of the quality characteristics is pointless.
98:143	Their interpretation is given by the model in which they are incorporated.
99:143	Stage II:Specify the evaluation  This too breaks down into three steps: a) Select metrics b) Establish rating levels for metrics c)   Establish criteria for assessment Quality characteristics and sub-characteristics cannot be directly measured.
100:143	Metrics must therefore be defined which correlate to the quality characteristic.
101:143	Different metrics may be used in different environments and at different stages of a products development.
102:143	Metrics have already been discussed to some extent in the section on quality models above.
103:143	A metric typically involves producing a score on some scale, reflecting the particular systems performance with respect to the quality characteristic in question.
104:143	This score, uninterpreted, says nothing about whether the system performs satisfactorily.
105:143	To illustrate this idea, consider the Geneva education system, where marks in examinations range from 1 to 6.
106:143	How do you know, without being told, that 6 is the best mark and 1 the worst?
107:143	In fact, most people guess that it is so: they may then have a difficult time in Zurich where 1 is the highest mark.
108:143	Establishing rating levels for metrics involves determining the correspondence between the uninterpreted score and the degree of satisfaction of the requirements.
109:143	Since quality refers to given needs, there can be no general rules for when a score is satisfactory.
110:143	This must be determined for each specific evaluation.
111:143	Each measure contributes to the overall judgement of the product, but not necessarily in a uniform way.
112:143	It may be, for example, that one requirement is critical, whilst another is desirable, but not strictly necessary.
113:143	In this case, if a system performs badly with respect to the critical characteristic, it will be assessed negatively no matter what happens to all the other characteristics.
114:143	If it performs badly with respect to the desirable but not necessary characteristic, it is its performance with respect to all the other characteristics which will determine whether the system is acceptable or not.
115:143	This consideration feeds directly into the third step, establishing criteria for assessment, which involves defining a procedure for summarizing the results of the evaluation of the different characteristics, using for example decision tables or weighting functions of different kinds.
116:143	Stage III: Design the evaluation  Designing the evaluation involves producing an evaluation plan, which describes the evaluation methods and the schedule of the evaluator action.
117:143	The other documents in the 14598 series expand on this point, and the plan should be consistent with a measurement plan, as described and discussed in the document on planning and management.
118:143	(ISO 14598-2/00)  Stage IV: Execute the evaluation  This final stage again breaks down into three stages:  a) Measurement b) Rating        c)   Assessment These steps are intuitively straightforward in the light of the discussion above.
119:143	Measurement gives a score on a scale appropriate to the metric being used.
120:143	Rating determines the correlation between the raw score and the rating levels, in other words, tells us whether the score can be considered to be satisfactory.
121:143	Assessment is a summary of the set of rated levels and can be seen as a way of putting together the individual ratings to give an overall picture which also reflects the relative importance of different characteristics in the light of the particular quality requirements.
122:143	Final decisions are taken on the basis of the assessment.
123:143	5 ISO, EAGLES and natural language applications in practice.
124:143	It would be impossible of course to claim knowledge of all applications of the ISO standards, even within the limited area of work on natural language.
125:143	In this concluding section only those applications that came to the authors cognisance through her involvement with work in the EAGLES, ISLE and Parmenides projects are mentioned.
126:143	The ISO model of 9126/91 as extended and formalized by the first EAGLES project has been tested by application to a number of different language engineering applications.
127:143	Within the TEMAA project it was applied to the evaluation of spelling checkers, and initial work was done on quality models for grammar checkers and translation memory systems.
128:143	As part of the EAGLES project itself, a number of projects in the general field of information retrieval were asked to apply the framework, and produced, in those cases where the project included a substantial evaluation component, encouraging results.
129:143	The second EAGLES project was, for the evaluation group, essentially a consolidation and dissemination project, where an attempt was made to encourage use of earlier results.
130:143	During this time, the model was also applied in the context of the ARISE project, which developed a prototype system whereby information on railway timetables could be obtained through spoken dialogue.
131:143	Similarly, an Australian manufacturer of speech software used the framework to evaluate a spoken language dialogue system.
132:143	Case studies undertaken in the context of post-graduate work have applied the ISO/EAGLES methodology to the evaluation of dictation systems, grammar checkers and terminology extraction tools.
133:143	One part of the ISLE project, now coming to an end, has been applying the methodology to the construction of a large scale quality model of machine translation systems.
134:143	Many of the results of this work can be consulted by looking at the EAGLES and ISLE web sites.
135:143	Recently, work has begun on the Parmenides project.
136:143	This project is concerned with ontology based semantic mining of information from web based documents, with a special interest in keeping track of information which changes over time.
137:143	Evaluation plays an important role in the project.
138:143	Three separate user groups are supplying the basis for case studies.
139:143	At the time of writing, user requirements are being defined, which will be translated into quality requirements for the software to be developed within the project and which will serve as the basis for the quality models to be used in on-going and final evaluation.
140:143	6 Conclusion.
141:143	The workshop for which this paper has been written addresses the question of whether there is anything that can be shared between evaluations.
142:143	The answer which I hope to have made convincing is that one thing which can be shared is a way of thinking about how evaluations should be designed and carried out.
143:143	Adhering to an acknowledged standard in the construction of quality models and in developing the process of a specific evaluation can only make it easier to share more detailed aspects of evaluation and provides a common framework for discussion of such issues as metrics and their validity.

