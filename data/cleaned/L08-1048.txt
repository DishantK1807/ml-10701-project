<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>P Boersma</author>
<author>D Weenink</author>
</authors>
<title>Praat, a system for doing phonetics by computer</title>
<date>2001</date>
<journal>Glot International</journal>
<volume>5</volume>
<pages>345</pages>
<contexts>
<context>ons and Annotations Using the above-described setup, we created a corpus of 15 dialogs containing a total of 3 hours and 41 minutes of speech. The corpus was transcribed and word-aligned using Praat (Boersma and Weenink, 2001). SONIC (Pellom and Hacioglu, 2001) speech recognition software was used to automatically word align the utterances, which were corrected by two human annotators. The dialogs were further annotated u</context>
</contexts>
<marker>Boersma, Weenink, 2001</marker>
<rawString>P. Boersma and D. Weenink. 2001. Praat, a system for doing phonetics by computer. Glot International, 5(9/10):341 345.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S E Brennan</author>
<author>H H Clark</author>
</authors>
<date>1996</date>
<booktitle>Conceptual Pacts and Lexical Choice in Conversation. Learning, Memory</booktitle>
<volume>22</volume>
<pages>1493</pages>
<contexts>
<context> information, effects associated with triggers, etc.), and referring expression annotation, associating object identi ers with noun phrases in the transcripts. Unlike studies on negotiated reference (Brennan and Clark, 1996), the objects were not hard to describe in isolation, but 2available online at http://slate.cse.ohio-state.edu/quakecorpora/scare/ because they appeared in contexts with multiple identical distractor</context>
</contexts>
<marker>Brennan, Clark, 1996</marker>
<rawString>S.E. Brennan and H.H. Clark. 1996. Conceptual Pacts and Lexical Choice in Conversation. Learning, Memory, 22(6):1482 1493.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donna K Byron</author>
<author>Eric Fosler-Lussier</author>
</authors>
<title>The OSU Quake 2004 corpus of two-party situated problemsolving dialogs</title>
<date>2006</date>
<booktitle>In Proceedings of the 15th Language Resources and Evaluation Conference (LREC’06</booktitle>
<contexts>
<context>opriate free resource. The corpus required to answer research questions related to situated language should connect world information to the human language. One situated language corpus is available (Byron and Fosler-Lussier, 2006), but it does not include information to automatically link world attributes with the language. In the current work, we use the same stimuli and tasks, however the roles of the dialog partners have b</context>
<context> given full knowledge of the world to be able to plan how to complete the tasks. This produced a large number of referring expressions and instructional language. Compared to the corpus presented in (Byron and Fosler-Lussier, 2006) this corpus contains referent annotation, synchronized positional/gaze information and word aligned transcripts. This paper serves to announce this corpus as a public resource and describe its compo</context>
</contexts>
<marker>Byron, Fosler-Lussier, 2006</marker>
<rawString>Donna K. Byron and Eric Fosler-Lussier. 2006. The OSU Quake 2004 corpus of two-party situated problemsolving dialogs. In Proceedings of the 15th Language Resources and Evaluation Conference (LREC’06).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D K Byron</author>
<author>A Koller</author>
<author>J Oberlander</author>
<author>L Stoia</author>
<author>K Striegnitz</author>
</authors>
<title>Generating instructions in virtual environments (GIVE): A challenge and an evaluation testbed for NLG</title>
<date>2007</date>
<booktitle>In Workshop on Shared Tasks and Comparative Evaluation in NLG</booktitle>
<location>Arlington, VA, USA</location>
<contexts>
<context>luation has been received well by the community and generated a recent proposal for a challenge in instruction-giving in virtual environments as an evaluation testbed for natural language generation (Byron et al., 2007). This corpus represents the second in a line of related VRbased corpora from our lab; each version of the corpus enables different types of language technology development. However, we believe that </context>
</contexts>
<marker>Byron, Koller, Oberlander, Stoia, Striegnitz, 2007</marker>
<rawString>D. K. Byron, A. Koller, J. Oberlander, L. Stoia, and K. Striegnitz. 2007. Generating instructions in virtual environments (GIVE): A challenge and an evaluation testbed for NLG. In Workshop on Shared Tasks and Comparative Evaluation in NLG, Arlington, VA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donna K Byron</author>
</authors>
<title>The OSU Quake 2004 corpus of two-party situated problem-solving dialogs</title>
<date>2005</date>
<tech>Technical Report OSU-CISRC-805-TR57</tech>
<institution>The Ohio State University Computer Science and Engineering Department</institution>
<contexts>
<context>ld at a frequency of 10 times per second. These two data sources were synchronized using calibration markers. A technical report is available that describes the recording equipment and software used (Byron, 2005). It is important to note that the knowledge shared by the dialog partners in this domain comes from both the dialog they are engaged in, and also their shared view of the world. The DF’s actions cha</context>
</contexts>
<marker>Byron, 2005</marker>
<rawString>Donna K. Byron. 2005. The OSU Quake 2004 corpus of two-party situated problem-solving dialogs. Technical Report OSU-CISRC-805-TR57, The Ohio State University Computer Science and Engineering Department, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Dale</author>
<author>S Geldof</author>
<author>J Prost</author>
</authors>
<title>CORAL: Using natural language generation for navigational assistance</title>
<date>2003</date>
<booktitle>Proceedings of the 26th Australasian Computer Science Conference</booktitle>
<editor>In M. Oudshoorn, editor</editor>
<location>Adelaide, Australia</location>
<contexts>
<context>lleher et al., 2005), helping users navigate using hand-held tourist information portals (Johnston et al., 2002), giving pedestrian directions (Yang et al., 1999) or in-car driving direction systems (Dale et al., 2003), inter alia. All of these applications present an exciting and challenging new frontier for dialog agents, since attributes of the real-world setting must be combined with other contextual factors f</context>
</contexts>
<marker>Dale, Geldof, Prost, 2003</marker>
<rawString>R. Dale, S. Geldof, and J. Prost. 2003. CORAL: Using natural language generation for navigational assistance. In M. Oudshoorn, editor, Proceedings of the 26th Australasian Computer Science Conference, Adelaide, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Johnston</author>
<author>S Bangalore</author>
<author>G Vasireddy</author>
<author>A Stent</author>
<author>P Ehlen</author>
<author>M Walker</author>
<author>S Whittaker</author>
<author>P Maloor</author>
</authors>
<date>2002</date>
<contexts>
<context>terpretation of situated language (Lauria et al., 2001), using visual information in the referring process (Kelleher et al., 2005), helping users navigate using hand-held tourist information portals (Johnston et al., 2002), giving pedestrian directions (Yang et al., 1999) or in-car driving direction systems (Dale et al., 2003), inter alia. All of these applications present an exciting and challenging new frontier for </context>
</contexts>
<marker>Johnston, Bangalore, Vasireddy, Stent, Ehlen, Walker, Whittaker, Maloor, 2002</marker>
<rawString>M. Johnston, S. Bangalore, G. Vasireddy, A. Stent, P. Ehlen, M. Walker, S. Whittaker, and P. Maloor. 2002.</rawString>
</citation>
<citation valid="true">
<title>MATCH: An architecture for multimodal dialogue systems</title>
<date>2002</date>
<booktitle>In Association for Computational Linguistics</booktitle>
<pages>376--383</pages>
<marker>2002</marker>
<rawString>MATCH: An architecture for multimodal dialogue systems. In Association for Computational Linguistics, 2002, pages 376 383.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kelleher</author>
<author>F Costello</author>
<author>J Van Genabith</author>
</authors>
<title>Dynamically structuring, updating and interrelating representations of visual and linguistic discourse context</title>
<date>2005</date>
<journal>Arti cial Intelligence</journal>
<volume>167</volume>
<pages>102</pages>
<marker>Kelleher, Costello, Van Genabith, 2005</marker>
<rawString>J. Kelleher, F. Costello, and J. Van Genabith. 2005. Dynamically structuring, updating and interrelating representations of visual and linguistic discourse context. Arti cial Intelligence, 167(1):62 102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kipp</author>
</authors>
<title>Gesture Generation by Imitation From Human Behavior to Computer Character Animation</title>
<date>2004</date>
<publisher>Dissertation.com</publisher>
<contexts>
<context>oglu, 2001) speech recognition software was used to automatically word align the utterances, which were corrected by two human annotators. The dialogs were further annotated using the Anvil software (Kipp, 2004), a free Det Head Value Count Percent Value Count Percent the 364 39% common noun 558 60% that/this 264 29% one 166 18% none 253 27% it 116 13% a 46 5% that 57 6% none 30 3% Table 1: Distribution of </context>
</contexts>
<marker>Kipp, 2004</marker>
<rawString>M. Kipp. 2004. Gesture Generation by Imitation From Human Behavior to Computer Character Animation. Dissertation.com.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Lauria</author>
<author>G Bugmann</author>
<author>T Kyriacou</author>
<author>J Bos</author>
<author>E Klein</author>
</authors>
<title>Training personal robots using natural language instructions</title>
<date>2001</date>
<journal>IEEE Intelligent Systems</journal>
<volume>16</volume>
<pages>9</pages>
<contexts>
<context>r a variety of situated tasks (tasks performed from a location within an environment). Many research projects deal with situated language, from many perspectives: interpretation of situated language (Lauria et al., 2001), using visual information in the referring process (Kelleher et al., 2005), helping users navigate using hand-held tourist information portals (Johnston et al., 2002), giving pedestrian directions (</context>
</contexts>
<marker>Lauria, Bugmann, Kyriacou, Bos, Klein, 2001</marker>
<rawString>S. Lauria, G. Bugmann, T. Kyriacou, J. Bos, and E. Klein. 2001. Training personal robots using natural language instructions. IEEE Intelligent Systems, 16(5):2 9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pellom</author>
<author>K Hacioglu</author>
</authors>
<title>Sonic: The University of Colorado Continuous Speech Recognizer</title>
<date>2001</date>
<tech>Techical Report# TR-CSLR-2001, 1</tech>
<contexts>
<context>-described setup, we created a corpus of 15 dialogs containing a total of 3 hours and 41 minutes of speech. The corpus was transcribed and word-aligned using Praat (Boersma and Weenink, 2001). SONIC (Pellom and Hacioglu, 2001) speech recognition software was used to automatically word align the utterances, which were corrected by two human annotators. The dialogs were further annotated using the Anvil software (Kipp, 2004</context>
</contexts>
<marker>Pellom, Hacioglu, 2001</marker>
<rawString>B. Pellom and K. Hacioglu. 2001. Sonic: The University of Colorado Continuous Speech Recognizer. Techical Report# TR-CSLR-2001, 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Peruch</author>
<author>Loic Belingard</author>
<author>Catherine ThinusBlanc</author>
</authors>
<title>Spatial Cognition II, LNAI 1849, chapter Transfer of Spatial Knowledge from Virtual to Real Environments</title>
<date>2000</date>
<pages>253--264</pages>
<publisher>Springer-Verlag</publisher>
<location>Berlin Heidelberg</location>
<contexts>
<context>have been found to be very robust in treating virtual world spatial representations in the same way as real-world objects, even when the graphical depiction in the virtual world is very impoverished (Peruch et al., 2000). We take the view that spatial language and references to objects in a virtual world maintain most properties when transferred to the real world domain, and a corpus collected in a virtual environme</context>
</contexts>
<marker>Peruch, Belingard, ThinusBlanc, 2000</marker>
<rawString>Patrick Peruch, Loic Belingard, and Catherine ThinusBlanc, 2000. Spatial Cognition II, LNAI 1849, chapter Transfer of Spatial Knowledge from Virtual to Real Environments, pages 253 264. Springer-Verlag, Berlin Heidelberg.</rawString>
</citation>
</citationList>
</algorithm>

