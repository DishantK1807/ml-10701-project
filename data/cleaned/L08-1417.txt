<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>M Bisani</author>
<author>H Ney</author>
</authors>
<title>Bootstrap Estimates for Confidence Intervals in ASR Performance Evaluation. In</title>
<date>2004</date>
<booktitle>Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing</booktitle>
<volume>1</volume>
<pages>409--412</pages>
<location>Montreal, Canada</location>
<contexts>
<context> is neither a proportion nor a mean of independent observations, is not amenable to traditional statistical tests, so we use bootstrap resampling to test for significance (Efron and Tibshirani, 1993; Bisani and Ney, 2004; Keller et al, 2005), with a significance level of 0.05. In our implementation we used the “shift” procedure described in Noreen (1989) and Riezler and Maxwell (2005). 3. Results 3.1. Levels of Agree</context>
</contexts>
<marker>Bisani, Ney, 2004</marker>
<rawString>Bisani, M. and H. Ney. (2004). Bootstrap Estimates for Confidence Intervals in ASR Performance Evaluation. In Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing. Montreal, Canada, Volume 1, pp. 409-412.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Efron</author>
<author>R J Tibshirani</author>
</authors>
<title>An Introduction to the Bootstrap</title>
<date>1993</date>
<publisher>Chapman &amp; Hall</publisher>
<location>New York</location>
<contexts>
<context>cision and recall. F1, which is neither a proportion nor a mean of independent observations, is not amenable to traditional statistical tests, so we use bootstrap resampling to test for significance (Efron and Tibshirani, 1993; Bisani and Ney, 2004; Keller et al, 2005), with a significance level of 0.05. In our implementation we used the “shift” procedure described in Noreen (1989) and Riezler and Maxwell (2005). 3. Result</context>
</contexts>
<marker>Efron, Tibshirani, 1993</marker>
<rawString>Efron, B. and R.J. Tibshirani. (1993). An Introduction to the Bootstrap. New York: Chapman &amp; Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J L Fleiss</author>
</authors>
<title>Statistical Methods for Rates and Proportions. 2nd ed</title>
<date>1981</date>
<publisher>Wiley</publisher>
<location>New York</location>
<contexts>
<context> number of positive judgments in common divided by the total number of positive judgments. The statistics p+ and pare the proportions of specific agreement on positives and negatives, respectively (Fleiss, 1981). The formulas for overlap and specific agreement are shown in Figure 3, based on a standard contingency table where cell a represents the number of agreements on positives, d the number of agreement</context>
<context>= 2a / (2a + b + c) p= 2d / (2d + b + c) Figure 3: Agreement formulas. Figure 4 shows pairwise agreement between adjudicators, labeled A through D, and also includes the commonly used kappa metric (Fleiss, 1981). The lowest agreement is between adjudicators A and B, where kappa is 0.57. 0.00 0.10 0.20 0.30 0.40 0.50 0.60 0.70 0.80 0.90 1.00 AB BD AD BC AC CD kappa p+ poverlap Figure 4: Adjudicator agreement</context>
</contexts>
<marker>Fleiss, 1981</marker>
<rawString>Fleiss, J.L. (1981). Statistical Methods for Rates and Proportions. 2nd ed. New York: Wiley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Keller</author>
<author>S Bengio</author>
<author>S Y Wong</author>
</authors>
<title>Benchmarking Non-Parametric Statistical Tests</title>
<date>2005</date>
<booktitle>Advances in Neural Information Processing Systems 18</booktitle>
<location>Vancouver, BC, Canada</location>
<contexts>
<context>on nor a mean of independent observations, is not amenable to traditional statistical tests, so we use bootstrap resampling to test for significance (Efron and Tibshirani, 1993; Bisani and Ney, 2004; Keller et al, 2005), with a significance level of 0.05. In our implementation we used the “shift” procedure described in Noreen (1989) and Riezler and Maxwell (2005). 3. Results 3.1. Levels of Agreement Adjudicator agr</context>
</contexts>
<marker>Keller, Bengio, Wong, 2005</marker>
<rawString>Keller, M., S. Bengio, and S.Y. Wong. (2005). Benchmarking Non-Parametric Statistical Tests. Advances in Neural Information Processing Systems 18. Vancouver, BC, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E W Noreen</author>
</authors>
<title>Computer Intensive Methods for Testing Hypotheses: An Introduction</title>
<date>1989</date>
<publisher>Wiley</publisher>
<location>New York</location>
<marker>Noreen, 1989</marker>
<rawString>Noreen, E.W. (1989). Computer Intensive Methods for Testing Hypotheses: An Introduction. New York: Wiley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K A Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W J Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation</title>
<date>2001</date>
<journal>IBM Research Division, Thomas J. Watson Research Center</journal>
<tech>Technical Report RC22176 (W0109-022</tech>
<contexts>
<context>f human language technologies depends crucially on the construction of high-quality ground truth data. Even methodologies employing automated metrics (e.g. BLEU for evaluation of machine translation (Papineni et al, 2001)) require this often labor-intensive and expensive step. Thus, a goal of many evaluation methodologies is to minimize the initial cost of developing this ground truth, to maximize its reusability, or</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2001</marker>
<rawString>Papineni, K.A., S. Roukos, T. Ward, W.J. Zhu. (2001). BLEU: a method for automatic evaluation of machine translation. Technical Report RC22176 (W0109-022), IBM Research Division, Thomas J. Watson Research Center.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Riezler</author>
<author>J T Maxwell</author>
</authors>
<title>On Some Pitfalls in Automatic Evaluation and Significance Testing for MT</title>
<date>2005</date>
<booktitle>Proc. of the ACL-05 Workshop on Intrinsic and Extrinsic Evaluation Methods for MT and Summarization</booktitle>
<location>Ann Arbor, Michigan</location>
<marker>Riezler, Maxwell, 2005</marker>
<rawString>Riezler, S. and J.T. Maxwell. (2005). On Some Pitfalls in Automatic Evaluation and Significance Testing for MT. Proc. of the ACL-05 Workshop on Intrinsic and Extrinsic Evaluation Methods for MT and Summarization, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E M Voorhees</author>
</authors>
<title>Variations in Relevance Judgments and the Measurement of Retrieval Effectiveness</title>
<date>2000</date>
<journal>Information Processing and Management</journal>
<volume>36</volume>
<pages>697--716</pages>
<marker>Voorhees, 2000</marker>
<rawString>Voorhees, E.M. (2000). Variations in Relevance Judgments and the Measurement of Retrieval Effectiveness. Information Processing and Management 36(5), pp. 697-716.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E M Voorhees</author>
</authors>
<title>The Philosophy of Information Retrieval Evaluation</title>
<date>2001</date>
<journal>Lecture Notes in Computer Science</journal>
<volume>2406</volume>
<pages>355--370</pages>
<publisher>Springer-Verlag</publisher>
<location>London, UK</location>
<contexts>
<context> Adjudication Task We created adjudication pools by adapting the methodology of the National Institute for Standards and Technology (NIST) Text REtrieval Conference (TREC) (Voorhees and Harman, 2000; Voorhees, 2001). To create adjudication pools, results were aggregated from several open source and commercial tools using lower-than-normal matching thresholds. To be maximally useful, evaluation should be done wi</context>
</contexts>
<marker>Voorhees, 2001</marker>
<rawString>Voorhees, E.M. (2001). The Philosophy of Information Retrieval Evaluation. Lecture Notes in Computer Science 2406, pp. 355-370. London, UK: Springer-Verlag.</rawString>
</citation>
</citationList>
</algorithm>

