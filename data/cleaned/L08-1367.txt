<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>L Brayda</author>
<author>C Bertotti</author>
<author>L Cristoforetti</author>
<author>M Omologo</author>
<author>P Svaizer</author>
</authors>
<title>Modifications on NIST MarkIII array to improve coherence properties among input signals</title>
<date>2005</date>
<booktitle>In Proceedings of AES, 118th Audio Engineering Society Convention</booktitle>
<location>Barcelona, Spain</location>
<contexts>
<context>ements of each of the different acoustic pre-processing modules in terms of inter-microphone spacing. For comparison purposes, the sessions were also acquired by a modified NIST MarkIII linear array (Brayda et al., 2005), placed just above the harmonic array. The MarkIII, depicted in Figure 3 is composed of 64 uniformly-spaced electret microphones, specifically developed for far-field voice recognition, speaker loca</context>
</contexts>
<marker>Brayda, Bertotti, Cristoforetti, Omologo, Svaizer, 2005</marker>
<rawString>Brayda, L., Bertotti, C., Cristoforetti, L., Omologo, M., and Svaizer, P. (2005). Modifications on NIST MarkIII array to improve coherence properties among input signals. In Proceedings of AES, 118th Audio Engineering Society Convention. Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Cristoforetti</author>
<author>M Omologo</author>
<author>M Matassoni</author>
<author>P Svaizer</author>
<author>E Zovato</author>
</authors>
<title>Annotation of a multichannel noisy speech corpus</title>
<date>2000</date>
<booktitle>In Proceedings of LREC</booktitle>
<location>Athens, Greece</location>
<contexts>
<context>six FBK sessions (in Italian) have been manually transcribed and segmented at word level, introducing also specific labels for acoustic events. An annotation guideline, modified from a previous work (Cristoforetti et al., 2000), was used in order to ensure as much consistency as possible between the two annotators. The data were annotated using Transcriber5, a free graphic annotation tool which permits multichannel view. T</context>
</contexts>
<marker>Cristoforetti, Omologo, Matassoni, Svaizer, Zovato, 2000</marker>
<rawString>Cristoforetti, L., Omologo, M., Matassoni, M., Svaizer, P., and Zovato E. (2000). Annotation of a multichannel noisy speech corpus. In Proceedings of LREC 2000. Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Furui</author>
</authors>
<title>Recent Advances in Speaker Recognition. Pattern Recognition Letters</title>
<date>1997</date>
<booktitle>In Proceedings of Interspeech</booktitle>
<pages>859--872</pages>
<location>Lisbon, Portugal</location>
<contexts>
<context>ing, all the participants were sitting in front of the television and read out some phonetically rich sentences3 that may be exploited to train algorithms for speaker identification and verification (Furui, 1997). During the second phase, each person interacted with the system trying to accomplish a list of predefined tasks. These included the typical actions to control a traditional television: channel swit</context>
</contexts>
<marker>Furui, 1997</marker>
<rawString>Furui, S. (1997). Recent Advances in Speaker Recognition. Pattern Recognition Letters, pp. 859--872 Goronzy, S., and Beringer, N. (2005). Integrated Development and on-the-Fly Simulation of Multimodal Dialogs. In Proceedings of Interspeech 2005. Lisbon, Portugal, pp. 2477--2480.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Huang</author>
<author>J Benesty</author>
</authors>
<title>Audio Signal Processing for Next-Generation Multimedia Communication Systems</title>
<date>2004</date>
<publisher>Kluwer Academic</publisher>
<location>Boston</location>
<contexts>
<context> three languages. The two channels of the system audio output were decorrelated in order to allow an effective implementation of stereo acoustic echo cancellation without impairing listening quality (Huang and Benesty, 2004). The system was controlled by the wizard through a Windows PC station located in an adjacent room. “EB GUIDE Studio”, a tool suitably designed to manage the dialogue flow in the WOZ experiments, was</context>
</contexts>
<marker>Huang, Benesty, 2004</marker>
<rawString>Huang, Y., and Benesty, J. (2004). Audio Signal Processing for Next-Generation Multimedia Communication Systems. Boston: Kluwer Academic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Lanz</author>
</authors>
<title>Approximate bayesian multibody tracking</title>
<date>2006</date>
<booktitle>IEEE transaction on Pattern Analysis and Machine Intelligence</booktitle>
<pages>1436--1449</pages>
<contexts>
<context>ersonal comments and were not intended for the system. As to the video data, a set of 3D coordinates for the head of each participants was created with a video tracker based on a generative approach (Lanz, 2006). Given the 3D labels, for each session a reference was derived, which includes the ID of the active speaker, his/her coordinates and some information about the presence of noises. The reference file</context>
</contexts>
<marker>Lanz, 2006</marker>
<rawString>Lanz, O. (2006). Approximate bayesian multibody tracking. IEEE transaction on Pattern Analysis and Machine Intelligence, pp. 1436--1449.</rawString>
</citation>
</citationList>
</algorithm>

