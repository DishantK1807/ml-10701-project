LINGUISTIC MODEL BASED ON THE GENERATIVE TOPOLOGICAL INFORMATION SPACE Seiichi Uchinami and Yoshikazu Tezuka Faculty of Engineering, Osaka University Yamada-Kami, Suita, Osaka, 565 JAPAN Based on the st~uctuzL~m, we propose a generative semantic model which has a topological information space generative grammar as basic rules.
In this model a semantic map which is called a topological information space, is generated by the grammar,and the space can express implications and similarities among concepts.
In the syntax, a syntactic generative grammar is defined based on the space grammar, and a mapping from the map to the language is defined.
The mapping is composed of two mappings: one is a meaning affix mapping ~ which maps a conceptual area in the space to a token in the language,and the other is an operator mapping ~ which maps a generative rule in semantics to a rewriting rule in syntax.
By these mappings, a derivation tree in semantics is mapped to a derivation tree in syntax, and vice versa.
An algebraic system on the space is defined, and an algebraic system on the sentences is derived by the (~,~)-mappings.
English will be analyzed according to this model and the algebraic systems on them.
Finally an information processing model is described based on the model.
The information processing in a natural language is carried out in the following steps: recognizing the inputs, parsing, interpreting, deducing, updating them, and outputting.
These processes are discussed in details.
I. INTRODUCTION Linguistics has been investigated from three aspects: syntax, semantics, and pragmatics.
As for syntax, many studies have been done since Chomsky presented a generative grammar based on strueturalism, and splended accomplishments have been made.
As for semantics, some reports have been published.
In the standard theory and the Case grammar, syntactic rules are considered to be powerful enough to describe and manage meanings, but it is insufficient to describe meanings completely with the discrete and branching rules, because meanings have continuous properties.
In the stratificational grammar and the generative semantics,semantic components seem to be more important than in the standard theory, because semantic rules are used basically.
But they have the similar defects as the standard theory, because these rules are discrete and branching ones.
' Lakoff and McCawley's generative semantics model are not enough to describe meanings, because their semantic rules are treated with the same form of syntax.
In general, their notations adopt classifications based on the categories or binary classifications.
So it has the following weak points:lack of expressive power of similarity and distance, and ordering of property value of concepts.
We have proposed to adopt a high dimensional semantic map (i.e.
a topologieal information space complementing for these defects.
It is said that when one wants to express one's intention, not a sentence but a concept is formed in his brain at first, then it is translated into a sentential form, feeding back the difference between the concept and the sentence translated, and at last it is expressed as a speech or a writing.
Therefore we have proposed the model that the concept which we want to utter is formed at first as a specified area in the semantic information space, next it is transformed into a phrase-marker (P-marker) in the deep structure, and at last it is transformed in the sentential form in the surface structure being fedback in each stage.
2. OUTLINE OF THE LINGUISTIC ACTIVITY MODEL There are two ways in describing meanings: one is connotational semantics; in this case meanings of sentences in a language A are described by sentences in a language B, for example, English is translated into Japanese.
The other is the operational semantics; in programming language, input data are computed and the results are output.
So the meanings of a programming language is expressed as an operator that prescribe input-output relation.
In our model these two semantics are considered as follows.
As for the connotational semantics, we take the topological information space as the language that describes meanings.
In this model we express the meanings of a natural language in the following way: we locate the concepts in the semantic map, i.e. the topological information space as follows; if a concept A implies a concept B, we assign them as the area B contains the area A, and if a similarity (or distance) between a concept A and B is greater than a similarity (or distance) between a concept A and 93 C, we locate the area B nearer ( or farther ) the area A than C.
As for the operational semantics, there are two kinds of operators.
One is responces or reactions against the received message, the other is updatings or rearrangements of the memory.
The former is carried out by responding with a speech, writing, or actions.
The latter is carried out by updating the database.
The model has four description levels: (i) Expression level ( utterances, writings, and actions ) (2) Surface level ( sentences ) (3) Deep level ( phrase-markers ) (4) Semantic level ( information space ).
In the expression level, one's intention is expressed through one's organs.
The surface level is the level of the language which we use in the daily life, and the set of sentences compose elements in this level.
In the deep level, each element is a generator of a surface description, and is in the form of P-marker, i.e. so called a derivation tree.
In the semantic level, the concept is expressed as an area or a file of areas in the information space, where the information space is something like a semantic map, and is made up of the neighbourhood system or the metric space, and has topological properties, which can express distances, similarities and inclusions so on.
In the functional point of view, the information space is composed of a meaning subspace and an estimating subspace, where the meaning subspace expresses topological relations among concepts, the estimating subspace expresses various estimated yalues in the process of management.
The estimating subspace has an activity axis, an occurrence probability axis and so on.
There are three levels of processing on them as follows: (I) Expression processing (expression level ÷~surface level ~ ), (2) Syntactic processing ( surface level ÷~ deep level ~ ), (3) Semantic processing ( deep level ÷÷ semantic level ~ ).
The expression processing is to utter, write or act, and in the opposite direction to recognize the received signs.
The syntactic processing is mappings from the deep level to the surface level and vice versa, in other words, mappings from P-markers to the sentences and the mappings among P-markers.
A syntactic structure consists of two level elements and the algebraic structures on them.
The semantic processing is mappings from the semantic level to the deep level and vice versa, and mappings among the semantic level, in other words mappings from domains in the information space to P-markers and vice versa, and the mappings among domains in the information space.
A semantic structure consists of two level elements and the algebraic structures on them.
The correspondence between the semantic structure and the syntactic structure is as follows.
There are two mappings which connect two structures, one is a meaning affix mapping ~ that maps an area in the space to a word in the syntactic grammar, the other is an operator mapping ~ that maps an operator on the space to a production rule in the syntactic grammar.
The algebra on the syntactic and the semantic structure are defined.
3. TOPOLOGICAL INFORMATION SPACE In the syntax-generative grammar, it is of no use to introduce relations among sentences, because there are no semantic relations among sentences which are generated by the grammar.
But in the semantic-generative grammar, not only elements but also a topology over them should be generated.
Because interpreting meanings of sentences, distances, similarities and inclusions among concepts which are expressed by points or areas, are very important.
In an algebraic point of view, a topological space is defined by an ordered pair (X,T), where X is a support (set of points), and T is a topology on X.
The whole topological space is generated as a dictionary, or a thesaurus, or the universe of knowledge.
In conversation with someone or a description of one's concept, a particular area is pointed out to communicate one's intention with others.
Then we need two kinds of production rules: one is the universe generative rules which generate the whole topological space, i.e. elements set and a topology on them, and the other is the utterance generative rules which generate distinct conceptual areas.
In terms of sorts of topology, we investigated topology-types which are required to express properties of meanings of about one thousand Chinese characters for ordinary use.
Following types of topology are listed up; I) Linear number axis.
In this type, a property value is expressed in a numerical value such as an integer or a real number, e.g. a weight axis: 150 Ibs.
2) Cyclic number axis.
Property values are expressed in numerical values in a given closed interval, and both end points are identified, i.e. a number sequence is defined cyclically, e.g. a time axis; one o'clock, two o'clock,..
twelve o'clock, one o'clock, ..
. 3) Ordinal axis.
Property values can not be expressed in numerical expression, --94• but property values are lined up in order along its strength and weakness, e.g. a sensation of warmth axis; cold cool, comfortable, warm, hot, heated.
4) Cyclic ordinal axis.
Property values are lined up in order cyclically, for example, a season axis; spring, summer, autumn, winter, spring,..
. 5) More general topology.
Property values can not be expressed in type i)4), and are given weaker topology as near-and-far relations or similarity relations among elements, for example, chromaticity diagram on color; yellow, red, blue, green, etc.
6) Simple set.
There is no topology on elements, so only a medley of elements constitutes a set, e.g. a set of terms which expresses aspects or units.
We'll formalize the model that can cover all sorts of topology listed above.
A topological information space generative grammar (TISG) consists of three levels of production rules which are restricted in the rewriting order.
Def.l Space Constitution Grammar : Gi G1 = < VNi' VTi' Pl' S1 > (i) where Vi= VNiU VTi, VNi~ VTi = ~ (2) D = { •, #, I } (3) LA(v,D)={(a~)*~I a,SgV, ~ D } (4) V\] is a finite set ( vocabulary ), VN\] arid V~ 1 are called a nonterminal vocEDulary, ~ terminal vocabulary respectively.
S. is a subset of VNi (initial vocabulary), and Pi is a T1nite set of production rules ( rewriting rules ) of the form: P1 : A ÷ ~ (5) where A eVNi ' ~e LA(Vi,D).
D is a space constitutor set, and consists of direct product: •, connected sum: #, and direct sum: I • Def.2 Space Property Grammar : G2 ~2 = < VN2 ' VT2 ' P2 ' $2 > (6) where V 2 = VN2U VT2, VN2nVT2 = property production rule P2 is a finite set of production rules of the form: P2 : A ÷ ~, where Ae VN2, (7) g { a, ~, ca, aa -l, aba-lb -I, abe-1 }, a,b eV~ . (8) A grammar G2 generates properties of subspaces.
Sorts of properties are as foliOWS: (i) Line axis ( a ) (ii) Cyclic axis ( a ) (J i i) Sphere axis (Sphere) ( aa-1 ) (iv) Projective axis ( aa ) (Projective plane) (v) Torus axis (Torus) (aba-lb "1) (vi) Boundary axis ( abe -1 ) (Surface with boundary) where type (id)-(vi) are of polyhedral forms of manifold.
Def.3 Topology Prescription Grammar:G3 G3 = < VN3 ' VT3 ' P3 ' S3 > (9) where V 3 = VN3UVT3, VN3~VT3 = P3 consists of two parts, one is P^_ which generates the universe, the ~her is P~A which generates a specified area to p~int out a concept.
P3T : A ÷ ~ (i0) e topological spaces of each types } P3A : A * ~ (ii) 6 ( areas of topological spaces } G3 generates the topology of each subspace, then following types of topologies are adopted adaptively: To, Ti, T2, R, T3, CR, T, N, T4, T~, T, Compact, Metric, Uniform, SeparableVand so on.
Def.4 The Topological Information Space Generative Grammar : G I G I = < G1, G2, G3>, (12) where G1, G2 and G3 are sub-grammars defined above.
And the relations among three levels are as follows: S 1 = S, S 2 = VTi, S 3 = VT2 Def.5 The Topological Information Space : I I = I(Gi) (13) The topological information space generated by G T is written as eq.(13) Def.6 The Syntax Generative Grammar:'G G s = < V N, V T, R, S > (14) s where S is an initial vocabulary, and subset of V., R is a set of phrase structure r~writing rules.
The other side V is divided into two: V=V U V a, where V is significant vocabulary, aYidVG is g~ammatical vocabulary.
An intersectlon of V with V~ is not always null.
P A generation tree, i.e. derivation tree of a sentence is called a P.marker (phrase marker), and the set of all Pmarkers generated by G is written as P=P(G).
The terminal string extracted from the treetop of the P-marker is called a sentence, and the set of all sentences generated by G, is written as L(G), and is called the language generated from the grammar G.
The P-marker sets and the set of all sub-P-markers gotten by decomposing P are called ~niverse of P-markers, and written as P.
Def.7 The Semantic Algebraic System:~i The semantic algebraic systen~ ~I is defined as ~I = < I, I I, E I> (15) where I is the information space defined by GT, and IT, E T are the interior and extePior operators on I respectively.
Generally speaking interior operators are functlons I I (n~2), and exterior operators are functions I×2÷I, where is an exterior operator.
Def.8 The Syntactic Algebraic S~tem:~s The syntactic algebraic system is defined as ~s = < P' Is' Es > (16) where ~ is a set of P-markers generated by G, and I and E are the interior and exterior op~ratorsSon ~.
--95-Def.9 The meaning affix mapping : f, (17) ~' : D ÷ Vp where D is the set of all areas in the space I.
@' assigns an area ( a concept in semantic map ) to a token or string of tokens ( words ) in the syntactic level.
We interpretea sentence through used-rewriting rules, so in order to avoid ambiguity we extend V ¢ to P, i.e. : D ÷ P P (18) Def.lO The operator mapping : : O I ~ O s (19) where 01 = Pi U ~u IiU E I (20) O s = RUVGU IsU E s (21) assigns the semantic operator in the semantic space to the syntactic operator in the syntax.
4. THE SEMANTIC ALGEBRAIC SYSTEM IN ENGLISH We will show the semantic algebraic system in English briefly.
Fig.l shows the outline of G I.
\[\]\] The organization of the support in E.n.gl.ish .--% o.rganization of the .meaning subs.p.ac.e. --The mean'ing subspace is used to express the topology among concepts.
It consists of three subspaces: intellectual, feeling, and ordering subspaces.
The intellectual subspace is a field to represent, state and judge.
The feeling subspace is a field to express out actions, emotions and senses.
The ordering subspace is a field to express the ordering of events or the informations.
~ (I) The intellectual s.u.bspace In Engl'ish there are four typical intellectual subspaces: {i} nouns or noun phrases, {2} adjectives or adjec~ve phrases, {3} adverbs, {4} verbs.
These four subspaces are written as IN, IA, ID, and I v respectively.
They constitute the support of the system, but some of adverbs correspond to the operators, for example, "very".
These four subspaces are composed to the higher level by nesting each other.
(2) The feeling subspace The feeling subspace is divided into three subspaces: action driving, emotional and sense subspaces.
(i) The action driving subspace This subspace expresses forms of actions and action-driving potentials.
The forms of actions are imperative, prohibition, request, hope, desire, petition, question, doubt, obligation, permission, causative, voluntary and intention so on.
This subspace is divided into the reply and the action subspaces, in the functional point of view.
The reply subspace expresses " answer by language ", and the action subpace expresses the actions except utterance, e.g. eat.
The words are mapped from the areas in the space by the meaning affix mapping @ and the operator mapping ~ as follows: if one receives words which arouse actions, one finds form of actions in this subspace by ~-~ and finds driving potentials by ~-~.
The meaning affix mapping ~ is defined on the following types of words: verbs which arouse actions (for example, ask, order etc.), imperative and interrogative forms of verbs, and auxiliary verbs of prohibition and wish so on.
The meaning affix mapping designates only " forms of actions aroused ", and " the content of actions " is designated by the area in I . For example, imperative sentence " VRead " is managed as follows.
The form of action is designated " ordinary imperative ", and a action " to read " is designated as a corresponding area in I subspace.
• V The operator mapping ~ has following functions, As for verbs listed above, the aroused degree of the action is designated.
And if there is an adverb that modifies a verb, and its adverb expresses the degree, $ is designated by the degree expressed by the adverb, for example, a word " abs0\]ute\]y " designates " extreme " degree.
(ii) The emotional subspace The emotional subspace is used to express emotions of a speaker and a hearer, and to modify a criterion level of decision of taking action, and this subspace does not arouse immediate actions.
i<information space> ÷ <meaming ss>.<estimating ss> Pl <meaning subspace> ÷ <intellectual ss>.<feeling ss>.<ordering ss> <estimating subspace> ÷ <reliability ax>.<activity ax>.<occurrence probabilLty ax>.< . .>.
.. <i~teIiectu~ subspace> + <noun ss>|<adjective ss> l<adverb ss>I<verb ss> <feeling subspace> ÷ <action d~iving ss>.<emotio~l ss>.<sense ss> <action driving subspace> + <reply ss>.<action ss> <emotional subspace> ÷ <state of emotions ss>.<degree of emotions ss> <ordering subspace> ÷ <events ordering ss>.<cau~ality ordering ss> <events ordering subspace> ÷ <seasons> <months> l <times> I< ...71... p2:<reliability axis> + I . . <seasons> ÷ S, ..
'. i where ss means "subspace", and ax means "axis" ) I ÷ ×, ( O<x<l ) I ÷ \[0,\]\], ...
P3A: $ ÷ P3T: 5 + <spring> <samm~z > <autumn> <wimZ~> <s p~ing > l <~m~ > l <a~tamn> l <wi~ > Fig.\] A part of the rewriting ru\]es Jn the information space generative grammar 96This subspace is divided into two: the state of emotions and the degree of emotion's subspaces.
Usually the area is computed both on the subject and the indirect object.
Sorts of emotions are joy, anger, pity, fear, love, hatred and sadness etc.
is computed by adjectives, verbs and nouns that express emotions, and interjections.
And ~ is determined by the degree of words listed above, adverbs, and emphasizing styles.
(~i) The sense subspace Kinds of senses are the senes of sight, hearing, smell, taste, touch, and internal organs.
These senses are awoke by direct excitations and by particular words in conversation.
Incase of words, there are two types as follows: {I} The words which designate a certain sense area in the space, for example, dazzling, hungry.
These words are mapped by @-i into the sense subspace.
{2} The words which activate the potential of a certain area in the sense estimating subspace.
For example, a word " rain " arouses the sense of cold and chilly in Japan.
The sense potential is raised by these words, and the degree is computed by ~-i The stimuli from the five organs of sense are gained by actual experiences, but the stimuli by words request to image the same experience as a speaker.
(3) The o.rd.ering subspace This subspace expresses ordering series of domains in time or in logic.
Usually the ordering axis is a real time axis of (-~,~), and is divided into three areas: past, present, and future.
But present is the relative value, and has meaning of only a time base.
(i) Ordering the events This designates the occurrence time of the contents described in the intellectual and feeling subspaces.
There are two kinds of time assignment, one is simple: past, present, or future.
The other is composite: perfect, simultaneous, or delay.
The composite assignment designates ordering in time or in logic among clauses or events.
(ii) Ordering the causality As for logic, input clauses are classified into two groups: one is a group of assumption or causes, the other is a group of conclusion or effects.
And a suitable causality type is assigned to each clause.
\[2\] OPERATORS IN ENGLISH (i) The intelle'ctual subspace (i) The exterior operators The exterior operators modify or restrict the conceptual area in a specified axis, and there are two types as follows: the value-shift type and the quantifier type.
For example, let u ~Vpf, v ~VG¢, and d: an area in the space, w:exterior operator on the space, if ~-1(u)=d and ~-1(v)=~, then the area corresponding to a phrase " uv " is formed by " md " in the space.
There are four types in the exterior operators as follows: (a) Restricting to limit, e.g. very (b) Settlement of range, (i) Extension of range, e.g. all (2) Reduction of range, e.g. small (c) Inversion of range, e.g. unpresant (d) Shift or limit the value of reliability in the estimating subspace, e.g. infer.
Sorts of limiting are conclusion, presumption, hearsay, degree, possibility, question, negation & emphasis.
(ii) The interior operators There are four levels in the interior operators as follows: words, phrases, clauses and sentences.
Let a,c ~Vp%, beVG%, ¢-1(a)=a, ~-1(c)=y, ~-1(b)=B, a,T ~ D, B ~{binary operators over the space}.
Then 6=~-l(abc)=~'l(a).~-l(b).~-l(c)=~T.
{1} The interior operators common to each level (space) (operators) (syntaxi synthesis of areas + enumeration in, by+ Sum: parallel logical sum ex.
red and white tulips, Selection: selection exclusive or ex, either You or I, Product: series logical product ex.
beautiful and healthy.
{2} The interior operators in words Compound words in syntax are corresponding to these operators.
Usually the operator is designated by a rewriting rule in the syntax, and V G does not appear in the compound words.
This operator limits the area expressed by the main word in the compound word by the area expressed by the subordinated word.
For example, the conceptual area of " letter paper " is the restricted area of " paper " for a letter.
{3} The interior operators in phrases These operators resemble to the operators in the words.
But in this level, not only rewriting rules but, also V~ such as " the monkey in a cage designates an operator too.
In case of noun phrases there are two kernels:V and one VG, and these are mapped to oneParea.
In case of adjective phrases or adverb phrases such as " in a cage ", there are one kernel V and one V~, so the lack of V_ causes F t~at these phrases are mapped to unary operators in the space.
A phrase has a ease, and each phrase is attached a pair of the concept and its case.
{4} The interior operators in clauses The process of composing clauses from words and phrases is corresponding to the unification of some conceptual areas as follows.
There are three main --97concepts: subject, object and action.
And there are three types of unifications as follows; *Mutual dependency: composition of transitive verb with direct object, and composition of direct object with indirect object.
*Uni-directional dependency: composition of the subject and verb ( phrase ).
*Mutual independency: composition of two clauses by a coordinate conjunction.
{5} The interior operators in sentences There are two methods of composition by a coordinate junction or nesting.
(2) The feeling subspace This information does not always appear, but if it appears it designates the state of feeling between the sender and the receiver.
(3) The ordering subspace (i) The exterior operators A shift or limitation of the value in the ordering axis is designated by the inflection of verbs and tense.
(~) The interior operators Conjunctions designate interior operators.
The operators are classified into subjunctive, indicative and imperative groups in the modal point of view, Also operators are divided into copulative, alternative, adversative, disjunctive and illative conjunctive groups in the conjunctive point of view.
5. INFORMATION PROCESSING MODEL ON TIIE INFORMATION SPACE MODEL Our communication is carried out bidirectionary.
On sending we compose a concept which we want to communicate others, next point out a corresponding area in the topological information space, map an area or areas to tokens in the syntax by the meaning affix mapping ~ or operator mapping ~, form the P-marker in the deep level, get the sentences, and at last speak or write sentences.
Descriptions of entities and relationships are managed as follows: (i) when we quote one entity, or when we express one entity's properties, a particular area in the information space is pointed out.
(2) when we express two or more entities and relationships among them, a direct product of two or more areas of entitie~ and an area of the relationship is pointed out.
Both entity-subspace and a relationship-subspace are topological information spaces.
Then the composed space become a topological space too.
On receiving we listen or read the sentences, analyze them lexically, parse them, get the P-marker in the surface level, transform it to the deep P-marker, map it to the derivation tree of the topological information space generative grammar, find the corresponding areas, compose the areas and relationship among them, interprete the message, update the memory, and respond the required actions.
These two processes are inverse relation, so we here describe in detail these processes in the latter case.
We depict processing steps in Fig.2.
\[\]\] Lexical analysis and Parsing In this step syntactic processing is carried out.
There are four recognition levels of syntax as follows: (i) Rec.og.nizing phonemes & characters The received phonemes or' ch'aracters are checked whether they belong to permissible phonemes or characters.
(2) Lexical analysis Input strings are divided by the word delimiters, and recognized as words.
Words are checked whether they are contained in the tokendictionary or not.
(3) Parsing & Deriving P-markers Delimiters of sentences are searched and each sentence is parsed.
If ambiguity occurs in parsing, all feasible P-markers are listed up.
Input ~I Lexicai Analysis~ O~_erational semantics I I Parsing 1 ~ -~ ~ -~ •'~--~ : ~1 '\]' A-1 % ~< S ntax ....
> ( P-markers ) % ~yn~ax l~Ctlonary *, % ~, ! >I Range check I I Concept Prescriptionl -i; \[ ! Integration check ( Conceptual areas )--~ Feeling, Ordering --~(F e) ' ~ Interpretation --< Knowledge Dictionary J i Output Utterance ::: Description (P-mar%.ers) Sentence I Generation ~(File) I Updating Induction Deduction Evaluation Fig.2 The Information Processing Model --98-(4) Reduction of P-markers to generator P-markers The parsed P-marker in the surface level is transformed into a generative P-marker in the deep level.
If recognition is failed in each step, the degree of potential for question is increased.
And if the degree of potential for question exceeds the threshold, a question to resolve the ambiguity is formed, and is utterd.
\[2\] Range check The value of property of the input data is checked whether it is out of range of permissible interval or not, i.e. range check of property value is carried out.
Because in the information space, the domain of property value is defined by the topological information space generative grammar.
This process is divided into two sub-processes: (i) the validity judgement of the conceptual area that is mapped from the words or phrases in the input sentences, i.e. the check for grammatical sentence~ (~) meta-description of a virtual world, i.e. the definition of words or assumtion of property values etc.
"' A ' is defined to be ' B '" is interpreted that the range of @(B) is adjusted to @(A) by modifying the characteristic functions of A for the virtual view.
\[3\] Intellectual interpretation The object is definitely prescribed to be in such a situation, and is managed as follows.
(i) The intellectual prescription In this step the focussed conceptual area is pointed out to interprete the communicated intention, and the area is mapped from the words, phrases, clauses or sentences.
This means the specialization of universal predicates.
An element of direct product of IA, IN, Iv, ..
etc. are pointed out.
(2) Correlation The corr'elation between subject and object in the sentence is clarified, and the relationship among entities are investigated, and the cases of each word is made clear; there are following cases Agentive, Factitive, Objective, Dative, State, Action arousing, Emotional, Feeling, Time, Cause, Result, Degree, Locative and Goal cases so on.
As for cases we don't make verbs special treatment as the dependency model, so verbs are assigned cases, too.
The correlated tuples of conceptual areas are filed with cases.
\[4\] Integration check In bussiness database systems, the conceptual schema for the enterprise is analyzed at set-up-time, and the most suitable schema is selected, and is not time-variant.
And the correspondence between the external schema and the conceptual schema is preset, so the input data is integrated to the conceptual schema automatically.
On the contrary, in the academic use of the database or in our thinking, the universe of knowledge is not fixed, and is growing according to the input data from the circumstances.
So we introduce View (Aspect) for integrating the same object in different records.
A group of experimental data, a group of sentences in a book, etc., have the same view.
This view is different from the view in the relational model.
A group of fragmentary data with the same view is checked whether they can be integrated to one object if they express the same object.
A group of fragmentary data, which has the view that contains or is contained by the input data view, is checked whether they can be integrated to one object or not.
\[5\] Feeling and Ordering interpretation (I) The feeling interpretation In the action arousing subspace, whether action is required or not is examined, where the action means responses by hands, speech or writing so o~ There are emotional and feeling subspaces.
As for the emotional-state, the conditions of the sender and the receiver are judges by particular words concerning emotions.
As for the emotional state, the same judgement is executed.
(2) Ordering information interpretation For described events, before-andafter relations on time, and cause-andeffect relations are judged.
These informations are used in deduction and induction of theorems from axioms, and in management of subjunctive mode.
E6\] Evaluation of the received contents After the grammatical valuation of input sentences and semantic interpretation in the space, following managements are carried out: evaluation of communicated contents, and judgement of logical validity.
These managements are executed by inferences using deductions, inductions and arithmetic operations on areas in the space.
By these.processing, confirming the validity on the communicated contents, and drawing new conclusions from inputs and knowledge, are executed.
(I) Arithmetic operations Arithmetic operations are used in deduction, induction and other managem~nts.
There are following property-types: D: a power set of areas, H: a power set of hyperplanes, V: a power set of values P E: a power set of estimating value.
And following kinds of operations exist.
D × H ×V × *D × H × V × E (2) Evaluation of Declaration The input informations are checked whether they contradict with the data that are already input and confirmed, (3) Deduction and Induction --99-(i) Deduction The question is rewritted to the questions on the space.
Using the algebraic properties, the equation is transformed and solved.
In case that the algorithm is cataloged, a suitable procedure is searched and triggered.
Also suitable procedures are triggered if the estimating value exceeds the threshold in each process.
In case that the algorithm is not cataloged, or the input is not a question, deductions from the input is executed.
We communicate each other with some view, and the received information is interpreted in that view, i.e. if the received data contradicts with the same view data, the input data must be checked whether it is right or not.
And if a contradiction is not deduced, the valuable data deduced from the input are arranged and stored.
In these processes, the deduction is executed by syllogisms or resolution.
(2) Induction The induction is executed as follows: at first some special predicates in the same view are selected, common variables are searched, universal special predicates are reconstructured by choosing the domain appropreately from the existential special predicates.
These existential predicates are not always valid, but if the contradiction is not found by checking the domain in the information space feeding back the result, the Predicates ~re regarded to be correct probably, and are stored as a hypothesis, and output.
Where induction is executed on the data which have the same view, and the predicates are selected from the predicates which have the same properties in the same view data.
This operation is useful in creative thinking, for example, from the data gathered, common properties are extracted, and the induction is executed to the predicates which contain the common properties.
As a result, from the experimental data or the observational field data, some valuable hypotheses are generated.
(4) Updating the Memory or Database The received message are parsed and mapped to the semantic level, interpreted and deduced.
As a result new facts or new informations are clarified.
These data are stored in the database.
There are two ways of updatings: one is a permanent amendment: if the data is a principle one, modifications of the information space are needed, so the information space generative grammar is reconstructed, and the corresponding amendments of files are carried out.
The other is a temporary modification in an interim file.
C7\] Composition of Intention & Utterance If the question is ambiguous or the answer is not deducible from the database and inputs, the action-driving potential to fill up the information insufficiency is elevated, then the question to resolve the ambiguities is composed and utterd.
If the question is correct and the answer is deducible from the dictionary and inputs, the answer file in the semantic level is translated into the P-marker, and is utterd.
If the input is not an interrogation, then the database is updated, and no answer or agreeable responces are made, In every case, the intention is described in file form in the semantic level, i.e. tuples of conceptual areas with cases.
The file is recomposed to the derivation tree in the syntactic level by 0 and $, transformed to the surface description, and uttered.
6. CONCLUSION A generative semantics model based on the topological space generative grammar was proposed.
This model has more descriptive power than other models because both implications and similarities can be generated in the basic level.
The aim of this model is to describe and manage the semantics algebraically, and for that purpose English was arranged based on the model.
The question-answering process in a natural language was clarified.
In this model not only a concept but also estimation of the information is considered.
Then the motivation for next actions can be interpreted.
Based on the model, we are now implementing a research-DBMS.
Using it we can built up and test hypotheses by KJ-methods and so on.
REFERENCES i.
Chomsky, N".
Aspect of the Theory of Syntax ", MIT Press, 1965 2.Fillmore,J.C."The Case for Case", In Universals in Linguistic Theory.
Bach,E; Harms,T.R.
eds. Holt, Rinehart & Winston, 1968,ppi-90.
3. Jackendoff,R.S".
Semantic Interpretation in Generative Grammar ", MIT Press, 1972.
4.CODASYL Dev.
Committee, "An Information Algebr~ Phase I Rep.", C.A(~ 5-4,April 1962,pp190-207.
5.Uchinami,S.,Tezuka,Y.
and Kasahara,Y".
A Model of Linguistic Information Algebra ", Tech.Rep. of Osaka Univ.
1970, 20(962), pp711-723.
6.Tsurumi,,Y.,Uchinami,S.
and Tezuka Y".
Information Retrieval using the Meaning Space ", Trans.
of IECE of Japan,1972 May, 55D5,pp307314.
7.Uchinami,S.
and Tezuka,Y".
On the Formal Properties of the Topological Information Space Generative Grammar & its Space ", Trans.
of IECE of Japan, 1980 Jan., 63DI, pp79-86

