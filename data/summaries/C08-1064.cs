Richard Zens and Hermann Ney. 2007. Efficient
N07-1062
tic (Koehn et al., 2003). In all experiments that fol-
N03-1017
matching. For example, Chan et al. (2007) and
P07-1005
plementation of Lopez (2007). Pattern matching,
D07-1104
Callison-Burch et al. (2005) and Zhang and Vo-
P05-1032
tic (Koehn et al., 2003). We replace these with
N03-1017
nal prefix trees (Zens and Ney, 2007). See Lopez
N07-1062
Adam Lopez. 2007. Hierarchical phrase-based transla-
D07-1104
Franz Josef Och and Hermann Ney. 2002. Discrimina-
P02-1038
ducibility and for minimum error rate training (Och, 2003).
J03-1002 P03-1021
Simard et al. (2005) (filtered) 4
H05-1095
weighting (Koehn et al., 2003).
N03-1017
(Papineni et al., 2002).4
P02-1040
Franz Josef Och. 2003. Minimum error rate training in
J03-1002 P03-1021
Necip Fazil Ayan and Bonnie Dorr. 2006a. Going
N06-1013 P06-1002
initiated by Callison-Burch et al. (2005) and Zhang
P05-1032
2007; DeNeefe et al., 2007; Simard et al., 2005).
D07-1079 H05-1095
ing translation (Chiang, 2007; Simard et al., 2005;
H05-1095
(Koehn et al., 2003; Zens and Ney, 2007). How-
N03-1017 N07-1062 P07-2045
external prefix trees (Zens and Ney, 2007). To
N07-1062
phrase-based models (Koehn et al., 2003; Zens and
N03-1017
Quirk and Menezes, 2006), and it may be that this
N06-1002
Yaser Al-Onaizan and Kishore Papineni. 2006. Dis-
P06-1067
v is very frequent, this is too slow. Lopez (2007;
D07-1104
ing (Och, 2003) and tested on the NIST 2005
J03-1002 P03-1021
Necip Fazil Ayan and Bonnie J. Dorr. 2006b. A max-
N06-1013 P06-1002
phrase-based translation by Callison-Burch et al.(2005) and Zhang and Vogel (2005). The key point
P05-1032
uses Giza++ alignments (Och and Ney, 2003)
J03-1002 P03-1021
Ayan and Dorr (2006a) showed that a loose heuris-
N06-1013 P06-1002
Chris Quirk and Arul Menezes. 2006. Do we need
N06-1002
Franz Josef Och and Hermann Ney. 2003. A system-
J03-1002 P03-1021
DeNeefe et al. (2007) 57
D07-1079
Zens and Ney (2007) 225
N07-1062
mum error rate training (Och, 2003).
J03-1002 P03-1021
do so. Dyer et al. (2008) address this bottleneck
W08-0333
ing translation models. Zens and Ney (2007) re-
N07-1062
bitrarily large. Callison-Burch et al. (2005) and
P05-1032
aligned with GIZA++ (Och and Ney, 2003) and
J03-1002 P03-1021
