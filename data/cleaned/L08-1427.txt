<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>D Vaufreydaz</author>
</authors>
<title>Modélisation statistique du langage à partir d'Internet pour la reconnaissance automatique de la parole continue. Thèse de doctorat de l’Université J. Fourier Grenoble I</title>
<date>2002</date>
<location>France</location>
<contexts>
<context>as the web allows obtaining freely and quickly a large quantity of text. Recently, several research works proposed techniques to exploit the resources from the web for natural language processing. In [1], a web robot that retrieves text from the Internet to build a text corpus is proposed. From some given starting points on the web, the robot can reach and retrieve recursively text documents and html</context>
<context>hmer. In our case, retrieving the Khmer pages from some well selected news websites allows us to get big quantity of text more rapidly than using a robot to crawl many sites on the net as proposed in [1]. Once html pages are retrieved, further processing is needed in order to build a text corpus: Filtering in order to extract only text from html pages Converting legacy character encoding to stand</context>
</contexts>
<marker>[1]</marker>
<rawString>Vaufreydaz, D. (2002) Modélisation statistique du  langage à partir d'Internet pour la reconnaissance  automatique de la parole continue. Thèse de doctorat  de l’Université J. Fourier Grenoble I, France. </rawString>
</citation>
<citation valid="true">
<authors>
<author>X Zhu</author>
<author>R Rosenfeld</author>
</authors>
<title>Improving Trigram Language Modelling with the World Wide Web. In</title>
<date>2001</date>
<booktitle>Proc. ICASSP</booktitle>
<pages>533--536</pages>
<location>Salt Lake, USA</location>
<contexts>
<context>eb, the robot can reach and retrieve recursively text documents and html pages. However, we must control the robot in order to get only the text in the target domain and language. Another approach in [2] consists in estimating words n-gram probabilities using the World Wide Web. The probabilities are estimated from the number of pages found using a given search engine. Those kinds of methods applied </context>
</contexts>
<marker>[2]</marker>
<rawString>Zhu, X., Rosenfeld, R. (2001) Improving Trigram  Language Modelling with the World Wide Web. In  Proc. ICASSP, pages 533-536, Salt Lake, USA. </rawString>
</citation>
<citation valid="false">
<note>www-clips.imag.fr/geod/User/brigitte.bigi</note>
<contexts>
<context>encoding Segmenting text into sentences and word or sub-word units using automatic segmentation tools Converting special signs and numbers to text Normalizing the words By using the ClipsTextTK [3], this process could be done rapidly by adapting the language dependent part of the toolkit for Khmer language. We developed tools for the conversion of encoding (from legacy ad-hoc code to Unicode), </context>
</contexts>
<marker>[3]</marker>
<rawString>www-clips.imag.fr/geod/User/brigitte.bigi/ </rawString>
</citation>
<citation valid="true">
<authors>
<author>C Barras</author>
</authors>
<title>Transcriber: development and use of a tool for assisting speech corpora production</title>
<date>2000</date>
<journal>In Speech Communication</journal>
<volume>33</volume>
<pages>1--2</pages>
<contexts>
<context>ty volunteers (students at ITC) who were motivated to contribute to the development of the language resources for Khmer were recruited and trained to do the manual transcription. By using Transcriber [4], 6h30mn of speech signal were manually transcribed in Unicode Khmer script (only speech read in the studio was transcribed and without extra detailed information). This 6h30mn of transcription contai</context>
</contexts>
<marker>[4]</marker>
<rawString>Barras, C., et al. (2000) Transcriber: development  and use of a tool for assisting speech corpora  production. In Speech Communication Vol 33, No  1-2. </rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kurimo</author>
</authors>
<title>Unsupervised segmentation of words into morphemes Morpho Challenge 2005: Application to Automatic Speech Recognition</title>
<date>2006</date>
<booktitle>In Proc. Interspeech</booktitle>
<pages>1021--1024</pages>
<location>Pittsburgh, PA</location>
<contexts>
<context>aller than word vocabulary. Some previous works using sub-word units for language modeling have recently been published for Arabic, Turkish (morphological analysis). Data-driven or fully unsupervised [5] word decomposition algorithms were used like in [6, 7] as well as working on the character level for unsegmented languages like in [8]. For character-based language like Chinese, mixed vocabularies c</context>
</contexts>
<marker>[5]</marker>
<rawString>Kurimo, M., et al. (2006) Unsupervised segmentation  of words into morphemes Morpho Challenge 2005:  Application to Automatic Speech Recognition. In  Proc. Interspeech, pages 1021-1024, Pittsburgh, PA. </rawString>
</citation>
<citation valid="true">
<authors>
<author>N Abdillahi</author>
</authors>
<title>Automatic transcription of Somali language</title>
<date>2006</date>
<booktitle>In Proc. Interspeech</booktitle>
<pages>289--292</pages>
<location>Pittsburgh</location>
<contexts>
<context>g sub-word units for language modeling have recently been published for Arabic, Turkish (morphological analysis). Data-driven or fully unsupervised [5] word decomposition algorithms were used like in [6, 7] as well as working on the character level for unsegmented languages like in [8]. For character-based language like Chinese, mixed vocabularies containing both characters and a set of frequent words (</context>
</contexts>
<marker>[6]</marker>
<rawString>Abdillahi, N., et al. (2006) Automatic transcription of  Somali language. In Proc. Interspeech, pages  289-292, Pittsburgh. </rawString>
</citation>
<citation valid="true">
<authors>
<author>M Afify</author>
</authors>
<title>On the use of morphological analysis for dialectal Arabic Speech Recognition</title>
<date>2006</date>
<booktitle>In Proc. Interspeech</booktitle>
<pages>277--280</pages>
<location>Pittsburgh, PA</location>
<contexts>
<context>g sub-word units for language modeling have recently been published for Arabic, Turkish (morphological analysis). Data-driven or fully unsupervised [5] word decomposition algorithms were used like in [6, 7] as well as working on the character level for unsegmented languages like in [8]. For character-based language like Chinese, mixed vocabularies containing both characters and a set of frequent words (</context>
</contexts>
<marker>[7]</marker>
<rawString>Afify, M., et al. (2006) On the use of morphological  analysis for dialectal Arabic Speech Recognition. In  Proc. Interspeech pages 277-280, Pittsburgh, PA. </rawString>
</citation>
<citation valid="true">
<authors>
<author>E Denoual</author>
<author>Y Lepage</author>
</authors>
<title>The character as an appropriate unit of processing for non-segmenting languages. NLP Annual Meeting</title>
<date>2006</date>
<pages>731--734</pages>
<location>Tokyo, Japan</location>
<contexts>
<context>kish (morphological analysis). Data-driven or fully unsupervised [5] word decomposition algorithms were used like in [6, 7] as well as working on the character level for unsegmented languages like in [8]. For character-based language like Chinese, mixed vocabularies containing both characters and a set of frequent words (mostly 2 characters words) are used in language modeling [9]. Note that a text i</context>
</contexts>
<marker>[8]</marker>
<rawString>Denoual, E., Lepage, Y. (2006) The character as an  appropriate unit of processing for non-segmenting  languages. NLP Annual Meeting, pages 731-734,  Tokyo, Japan. </rawString>
</citation>
<citation valid="true">
<authors>
<author>L Chen</author>
</authors>
<title>Broadcast News Transcription in Mandarin</title>
<date>2000</date>
<booktitle>Proc. ICSLP'2000</booktitle>
<location>Beijing, China</location>
<contexts>
<context>d languages like in [8]. For character-based language like Chinese, mixed vocabularies containing both characters and a set of frequent words (mostly 2 characters words) are used in language modeling [9]. Note that a text in Khmer could be segmented into word, syllables or character-cluster. The character-cluster could be a good modeling unit as its segmentation is trivial because of its non-ambiguit</context>
</contexts>
<marker>[9]</marker>
<rawString>Chen, L., et al. (2000) &amp;quot;Broadcast News  Transcription in Mandarin,&amp;quot; Proc. ICSLP'2000,  Beijing, China. </rawString>
</citation>
<citation valid="true">
<authors>
<author>X Huang</author>
</authors>
<title>Spoken Language Processing – A Guide to Theory, Algorithm, and System Development</title>
<date>2001</date>
<publisher>Prentice Hall</publisher>
<contexts>
<context>knowledge on the acoustic and phonology systems of the language in question. There were several techniques found in the literature for generating a pronunciation dictionary. Among them we can mention [10] which proposed a modeling technique based on pronunciation rules. This method requires knowledge on the target language and also of its phonetic rules. Grapheme based modeling has been successfully a</context>
</contexts>
<marker>[10]</marker>
<rawString>Huang, X., et al. (2001) Spoken Language  Processing – A Guide to Theory, Algorithm, and  System Development, Prentice Hall. </rawString>
</citation>
<citation valid="true">
<authors>
<author>J Billa</author>
</authors>
<title>Audio indexing of Arabic broadcast news</title>
<date>2002</date>
<booktitle>In Proc. IEEE International Conference on Acoustique, Speech and Signal Processing</booktitle>
<pages>5--8</pages>
<location>Orlando</location>
<contexts>
<context>que based on pronunciation rules. This method requires knowledge on the target language and also of its phonetic rules. Grapheme based modeling has been successfully addressed for different languages [11, 12]. It has the advantage of being straightforward and fully automatic. For Khmer language, a grapheme based dictionary is generated by converting the Khmer character in its Unicode representation to its</context>
</contexts>
<marker>[11]</marker>
<rawString>Billa, J., et al. (2002) Audio indexing of Arabic  broadcast news. In Proc. IEEE International  Conference on Acoustique, Speech and Signal  Processing. Pages 5-8, Orlando. </rawString>
</citation>
<citation valid="true">
<authors>
<author>M Bisani</author>
<author>H Ney</author>
</authors>
<title>Multigram-based grapheme-to-phoneme conversion for LVCSR</title>
<date>2003</date>
<booktitle>In Proc. EUROSPEECH. Pages 933-936</booktitle>
<location>Geneva, Switzerland</location>
<contexts>
<context>que based on pronunciation rules. This method requires knowledge on the target language and also of its phonetic rules. Grapheme based modeling has been successfully addressed for different languages [11, 12]. It has the advantage of being straightforward and fully automatic. For Khmer language, a grapheme based dictionary is generated by converting the Khmer character in its Unicode representation to its</context>
</contexts>
<marker>[12]</marker>
<rawString>Bisani, M., Ney., H. (2003) Multigram-based  grapheme-to-phoneme conversion for LVCSR.  In  Proc. EUROSPEECH. Pages 933-936 Geneva,  Switzerland. </rawString>
</citation>
<citation valid="false">
<note>http://cmusphinx.sourceforge.net/html/cmusphinx.php</note>
<contexts>
<context>ictionary 4.2. Acoustic modeling The most basic acoustic modeling for Khmer language is grapheme based modeling. We used our grapheme based dictionary which has 77 modeling units. We used SphinxTrain [13] toolkit from Sphinx project for building Hidden Markov Models (HMMs) acoustic models. With our speech training database described previously, we train acoustic models based on grapheme. Context-indep</context>
</contexts>
<marker>[13]</marker>
<rawString>http://cmusphinx.sourceforge.net/html/cmusphinx.php </rawString>
</citation>
<citation valid="false">
<note>http://www-clips.imag.fr/geod/User/sopheap.seng/asr</note>
<marker>[14]</marker>
<rawString>http://www-clips.imag.fr/geod/User/sopheap.seng/asr/ </rawString>
</citation>
</citationList>
</algorithm>

