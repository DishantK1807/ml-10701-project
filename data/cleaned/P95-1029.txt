Using Higher-Order Logic Programming for Semantic Interpretation of Coordinate Constructs Seth Kulick University of Pennsylvania Computer and Information Science 200 South 33rd Street Philadelphia, PA 19104-6389 USA skulick@linc, cis.
upenn, edu Abstract Many theories of semantic interpretation use A-term manipulation to compositionally compute the meaning of a sentence.
These theories are usually implemented in a language such as Prolog that can simulate A-term operations with first-order unification.
However, for some interesting cases, such as a Combinatory Categorial Grammar account of coordination constructs, this can only be done by obscuring the underlying linguistic theory with the "tricks" needed for implementation.
This paper shows how the use of abstract syntax permitted by higher-order logic programming allows an elegant implementation of the semantics of Combinatory Categorial Grammar, including its handling of coordination constructs.
1 Introduction
Many theories of semantic interpretation use A-term manipulation to compositionally compute the meaning of a sentence.
These theories are usually implemented in a language such as Prolog that can simulate A-term operations with first-order unification.
However, there are cases in which this can only be done by obscuring the underlying linguistic theory with the "tricks" needed for implementation.
For example, Combinatory Categorial Grammar (CCG) (Steedman, 1990) is a theory of syntax and semantic interpretation that has the attractive characteristic of handling many coordination constructs that other theories cannot.
While many aspects of CCG semantics can be reasonably simulated in first-order unification, the simulation breaks down on some of the most interesting cases that CCG can theoretically handle.
The problem in general, and for CCG in particular, is that the implementation language does not have sufficient expressive power to allow a more direct encoding.
The solution given in this paper is to show how advances in logic programming allow the implementation of semantic theories in a very direct and natural way, using CCG as a case study.
We begin by briefly illustrating why first-order unification is inadequate for some coordination constructs, and then review two proposed solutions.
The sentence in (la) usually has the logical form (LF) in (lb).
(la) John and Bill run.
(15) (and (run John) (run Bill)) CCG is one of several theories in which (lb) gets derived by raising John to be the LF AP.(P john), where P is a predicate that takes a NP as an argument to return a sentence.
Likewise, Bill gets the LF AP.(P bill), and coordination results in the following LF for John and Bill: (2) AP.(and (P john) (P bill)) When (2) is applied to the predicate, (15) will result after 13-reduction.
However, under first-order unification, this needs to simulated by having the variable z in Az.run(z) unify both with Bill and John, and this is not possible.
See (Jowsey, 1990) and (Moore, 1989) for a thorough discussion.
(Moore, 1989) suggests that the way to overcome this problem is to use explicit A-terms and encode /~-reduction to perform the needed reduction.
For example, the logical form in (3) would be produced, where X\rtm(X) is the representation of Az.run (z).
(3) and (apply (I\run(X), j ohn).
apply (l\run(l), bill) ) This would then be reduced by the clauses for apply to result in (lb).
For this small example, writing such an apply predicate is not difficult.
However, as the semantic terms become more complex, it is no trivial matter to write ~-reduction that will correctly handle variable capture.
Also, if at some point it was desired to determine if the semantic forms of two different sentences were the same, a predicate would be needed to compare two lambda forms for a-equivalence, which again is not a simple task.
Essentially, the logic variable X is meant to be interpreted as a bound variable, which requires an additional layer of programming.
213 (Park, 1992) proposes a solution within first-order unification that can handle not only sentence (la), but also more complex examples with determiners.
The method used is to introduce spurious bindings that subsequently get removed.
For example, the semantics of (4a) would be (4b), which would then get simplified to (4c).
(4a) A farmer and every senator talk (4b) exists(X1,fanaer(I1) a( exists (x2, (x2=xl) ataZk (X2)) ) ) &f orallCl3, senat or (X3) => (exists (X2, (12=13) &talk (X2)) ) ) (4c) exists (Xl,fanaerCXl)ktalk(Xl)) &forall (13, senator (13) =>talk (13)) While this pushes first-order unification beyond what it had been previously shown capable of, there are two disadvantages to this technique: (1) For every possible category that can be conjoined, a separate lexical entry for and is required, and (2) As the conjoinable categories become more complex, the and entries become correspondingly more complex and greatly obscure the theoretical background of the grammar formalism.
The fundamental problem in both cases is that the concept of free and bound occurrences of variables is not supported by Prolog, but instead needs to be implemented by additional programming.
While theoretically possible, it becomes quite problematic to actually implement.
The solution given in this paper is to use a higher-order logic programming language, AProlog, that already implements these concepts, called "abstract syntax" in (Miller, 1991) and "higher-order abstract syntax" in (Pfenning and Elliot, 1988).
This allows a natural and elegant implementation of the grammatical theory, with only one lexical entry for and.
This paper is meant to be viewed as furthering the exploration of the utility of higher-order logic programming for computational linguistics see, for example, (Miller & Nadathur, 1986), (Pareschi, 1989), and (Pereira, 1990).
2 CCG
CCG is a grammatical formalism in which there is a one-to-one correspondence between the rules of composition 1 at the level of syntax and logical form.
Each word is (perhaps ambiguously) assigned a category and LF, and when the syntactical operations assign a new category to a constituent, the corresponding semantic operations produce a new LF for that constituent as well.
The CCG rules shown in Figure 1 are implemented in the system described 1In the genera\] sense, not specifically the CCG rule for function composition.
Function Application (>): I/Y:F Y:y =>g:Fy Function Application (<): Y:y I\Y:F=>I:Fy Function Composition (> X/Y:F Y/Z:G=>X/Z: Function Composition (< Y\Z:G X\Y:F=>X\Z: Type Raising (> T): np:x =>./(s\np) : ~F.Fx Type Raising (< T): np:x =>e\(s/np):AF.Vx B): )tx.F(Gx) B): ~x.F(Gx) Figure 1: CCG rules harry found ........
~ ..........
>T S:s/(S:s\NP:harry') (S:found ~ npl np2\NP:npl)/NP:np2 >B S:found' harry' np2/NP:np2 Figure 2: CCG derivation of harry found simulated by first-order unification in this paper.
2 3 Each of the three operations have both a forward and backward variant.
As an illustration of how the semantic rules can be simulated in first-order unification, consider the derivation of the constituent harry found, where harry has the category np with LF harry' and found is a transitive verb of category (s\np)/np with LF (5) Aobject.Asubject.(found' subject object) In the CCG formalism, the derivation is as follows: harry gets raised with the > T rule, and then forward composed by the > B rule with found, and the result is a category of type s/rip with LF Az.(found' harry' z).
In section 3 it will be seen how the use of abstract syntax allows this to be expressed directly.
In first-order unification, it is simulated as shown in Figure 2.
4 The
final CCG rule to be considered is the coordination rule that specifies that only like categories can coordinate: 2The type-raising rules shown are actually a simplification of what has been implemented.
In order to handle determiners, a system similar to NP-complement categories as discussed in (Dowty, 1988) is used.
Although a worthwhile further demonstration of the use of abstract syntax, it has been left out of this paper for space reasons.
3The \ for a backward-looking category should not be confused with the \ for A-abstraction.
*example adapted from (Steedman, 1990, p.
220). 214 (6) X ¢on3 X => x This is actually a schema for a family of rules, collectively called "generalized coordination", since the semantic rule is different for each case.
5 For
example, if X is a unary function, then the semantic rule is (Ta), and if the functions have two arguments, then the rule is (7b).
s (7a) @FGH = Az.F(Gz)(Hz) (7b) @~FGH = Az.Ay.F(Gzy)(Hzy) For example, when processing (la), rule (Ta) would be used with: • F = Az.Ay.(~md' z y) • G = AP.(P john'), H = AP.(P bill') with the result c~FGH = Az.(and' (z john') (z bill')) which is c=-equivalent to (2).
3 ~PROLOG and Abstract Syntax AProlog is a logic programming language based on higher-order hereditary Harrop formulae (Miller et al., 1991).
It differs from Prolog in that first-order terms and unification are replaced with simply-typed A-terms and higher-order unification 7, respectively.
It also permits universal quantification and implication in the goals of clauses.
The crucial aspect for this paper is that together these features permits the usage of abstract syntax to express the logical forms terms computed by CCG.
The built-in A-term manipulation is used as a "meta-language" in which the "object-language" of CCG logical forms is expressed, and variables in the object-language are mapped to variables in the meta-language.
The AProlog code fragment shown in Figure 3 declares how the CCG logical forms are represented.
Each CCG LF is represented as an untyped A-term, namely type t=.
abe represents object-level abstraction Az.M by the meta-level expression (abe I), sit is not established if this schema should actually produce an unbounded family of rules.
See (Weir, 1988) and (Weir and Joshi, 1988) for a discussion of the implications for automata-theoretic power of generalized coordination and composition, and (Gazda~, 1988) for linguistic axguments that languages like Dutch may require this power, and (Steedman, 1990) for some further discussion of the issue.
In this paper we use the generalized rule to illustrate the elegance of the representation, but it is an easy change to implement a bounded coordination rule.
eThe,I~ notation is used because of the combinatory logic background of CCG.
See (Steedman, 1990) for details.
7defined as the unification of simply typed A-terms, modulo ~,/conversion.
kind tat type.
type abe (tat -> tat) -> tat.
type app tat -> tat -> tat.
type forall (tat -> tat) -> tat.
type exists (tat -> tat) -> tat.
type >> tat -> tm -> tat.
type,t tat -> ta -> tat.
Figure 3: Declarations for AProlog representation of CCG logical forms where N is a meta-level function of type ta ---* tat.
A meta-level A-abstraction Ay.P is written y\p.S Thus, if waZked' has type tat --* tat, then y\(walked' y) is a AProlog (meta, level) function with type ta -* tat, and (abe y\(walked' y)) is the object-level representation, with type tat.
The LF for found shown in (5) would be represented as Cabs obj\(abs sub\(found' sub obj))), app encodes application, and so in the derivation of harry found, the type-raised harry has the AProlog value (abe p\(app p harry')).
9 The
second part of Figure 3 shows declares how quantifiers are represented, which are required since the sentences to be processed may have determiners.
forall and exists are encoded similarly to abstraction, in that they take a functional argument and so object-level binding of variables by quantifiers is handled by meta-hvel A-abstraction.
>> and tt are simple constructors for implication and conjunction, to be used with forall and exists respectively, in the typical manner (Pereira and Shieber, 1987).
For example, the sentence every man found a bone has as a possible LF (8a), with the AProlog representation (8b)10: SThis is the same syntax for ~-abstraction as in (3).
(Moore, 1989) in fact borrows the notation for Aabstraction from AProlog.
The difference, of course, is that here the abstraction is a meta-level, built-in construct, while in (3) the interpretation is dependent on an extra layer of programming.
Bound variables in AProlog can be either upper or lower case, since they axe not logic vaxlables, and will be written in lower case in this paper.
9It is possible to represent the logical forms at the object-level without using abs and app, so that harry could be simply p\(p harry').
The original implementation of this system was in fact done in this manner.
Space prohibits a full explanation, but essentially the fact that AProlog is a typed language leads to a good deal of formal clutter if this method is used.
1°The LF for the determiner has the form of a Montagovian generalized quantifier, giving rise to one fully scoped logical form for the sentence.
It should be stressed that this particular kind of LF is assumed here purely for the sake of illustration, to make the point that composition at the level of derivation and LF are oneto-one.
Section 4 contains an example for which such a 215 type apply tm -> tm -> tm -> o.
type compose tm -> tm -> tm -> o.
type raise tm -> tm -> o.
apply (abs R) S (R S).
compose (abs F) (abs G) (abs x\(F (G x))).
raise Tn (abe P\(app P Tm)).
Figure 4: ~Prolog implementation of CCG logical form operations (8a) 3=.((bone' =) A y) ( ound' =))) (8b) (exists x\ ((bone' x) it& (forall xl\ (CLan' xl) >> (found' xl x))))) Figure 4 illustrates how directly the CCG operations can be encoded 11.
o is the type of a meta-level proposition, and so the intended usage of apply is to take three arguments of type tm, where the first should be an object-level )~-abstraction, and set the third equal to the application of the first to the second.
Thus, for the query ?apply (abe sub\(walked' sub)) harry' N.
It unifies with the ta -~ ta function sub\(walked ~ sub), S with harry' and M with (It S), the recta-level application of R to S, which by the built-in fi-reduction is (walked' harry' ).
In other words, object-level function application is handled simply by the meta-level function application.
Function composition is similar.
Consider again the derivation of harry found by typeraising and forward composition, harry would get type-raised by the raise clause to produce (abe p\(app p haxry~)), and then composed with found, with the result shown in the following query: ?compose (abe p\(app p harry')) (abe obj\ (abe sub\ (found' sub obj))) M.
M = (abe x\ (app (abs sub\(found ~ sub x)) harry' )).
derivation fails to yield all available quantifier scopings.
We do not address here the further question of how the remaining scoped readings axe derived.
Alternatives that appear compatible with the present approach are quantitier movement (Hobbs & Shieber, 1987), type-ralsing at LF (Paxtee & Rooth, 1983), or the use of disambiguated quantifers in the derivation itself (Park, 1995).
11There are other clauses, not shown here, that determine the direction of the CCG rule.
For either direction, however, the semantics axe the same and both directiona.I rules call these clauses for the semantic computation.
kind cat type fs type bs type np type s type conj type noun type.
cat -> cat -> cat.
cat -> cat -> cat.
cat. cat.
cat. cat.
type atomic-~ype cat -> o.
atomic-type rip.
atomic-type s.
atomic-type conj.
atomic-type noun.
Figure 5: Implementation of the CCG category system At this point a further/~-reduction is needed.
Note however this is not at all the same problem of writing a /~-reducer in Prolog.
Instead it is a simple matter of using the meta-level ~-reduction to eliminate ~-redexes to produce the final result (abe x\(found I harry x)).
We won't show the complete declaration of the/~-reducer, but the key clause is simply: red (app (abe N) N) (N N).
Thus, using the abstract syntax capabilities of ~Prolog, we can have a direct implementation of the underlying linguistic formalism, in stark contrast to the first-order simulation shown in Figure 2.
4 Implementation
of Coordination A primary goal of abstract-syntax is to support recursion through abstractions with bound variables.
This leads to the interpretation of a bound variable as a "scoped constant" it acts like a constant that is not visible from the top of the term, but which becomes visible during the descent through the abstraction.
See (Miller, 1991) for a discussion of how this may be used for evaluation of functional programs by "pushing" the evaluation through abstractions to reduce redexes that are not at the top-level.
This technique is also used in the fl-reducer briefly mentioned at the end of the previous section, and a similar technique will be used here to implement coordination by recursively descending through the two arguments to be coordinated.
Before describing the implementation of coordination, it is first necessary to mention how CCG categories are represented in the ~Prolog code.
As shown in Figure 5, cat is declared to be a primitive type, and np, s, conj, noun are the categories used in this implementation, fs and bs are declared 216 type coord cat -> tm -> tm -> tm -> o.
coord (fs • B) (abs It) (abs S) (abs T) "pi x\ (coord B (~ x) (S x) (T x)).
cooed (be i B) (abe R) (abe S) (abe T) "pi x\ (coord B (R x) (S x) (T x)).
coord B R S (and' E S) :atomic-type B.
Figure 6: Implementation of coordination to be constructors for forward and backward slash.
For example, the CCG category for a transitive verb (s\np)/np would be represented as (fs np (bs np s)).
Also, the predicate atomic-type is declared to be true for the four atomic categories.
This will be used in the implementation of coordination as a test for termination of the recursion.
The implementation of coordination crucially uses the capability of AProlog for universal quantification in the goal of a clause, pi is the meta-level operator for V, and Vz.M is written as pi x\l|.
The operational semantics for AProlog state that pi x\G is provable if and only if \[c/z\]G is provable, where c is a new variable of the same type as z that does not otherwise occur in the current signature.
In other words, c is a scoped constant and the current signature gets expanded with c for the proof of \[c/z\]G.
Since e is meant to be treated as a generic placeholder for any arbitrary z of the proper type, c must not appear in any terms instantiated for logic variables during the proof of \[c/z\]G.
The significance of this restriction will be illustrated shortly.
The code for coordination is shown in Figure 6.
The four arguments to cooed are a category and three terms that are the object-level LF representations of constituents of that category.
The last argument will result from the coordination of the second and third arguments.
Consider again the earlier problematic example (la) of coordination.
Recall that after john is type-raised, its LF will be (abs p\(app p john')) and similarly for bill.
They will both have the category (fs (bs np s) s).
Thus, to obtain the LF for John and Bill, the following query would be made: ?coord (fs (bs np s) s) (abs p\(app p john')) Cabs pkCapp p bill')) M.
This will match with the first clause for coord, with • t instantiated to (be np s) • Btos • It to (p\(app p john')) • S to (p\(app p bill')) • and T a logic variable waiting instantiation.
Then, after the meta-level/~-reduction using the new scoped constant c, the following goal is called: ?coord s (app ¢ john') (app c bill') II.
where II = (T c).
Since s is an atomic type, the third coord clause matches with • B instantiated to s • R to (app c john') • S to (app c bill') • II to (and' (app c john') (app c bill')) Since I = (T c), higher-order unification is used by AProlog to instantiate T by extracting c from II with the result T = x\(and' (app x john') (app x bill')) and so H from the original query is (abe x\(and' (app • john') (app • bill'))) Note that since c is a scoped constant arising from the proof of an universal quantification, the instantiation T = x\(and' (app ¢ john') (app • bill')) is prohibited, along with the other extractions that do not remove c from the body of the abstraction.
This use of universal quantification to extract out c from a term containing c in this case gives the same result as a direct implementation of the rule for cooordination of unary functions (7a) would.
However, this same process of recursive descent via scoped constants will work for any member of the conj rule family.
For example, the following query ?coord (~s np (be np s)) Cabs obj\(abs sub\(like' sub obj))) (abs obj\(abs sub\(hate' sub obj))) M.
14 = (abe x\ (abe xl\ (and' (like' xl x) (hate' xl x)))).
corresponds to rule (7b).
Note also that the use of the same bound variable names obj and sub causes no difficulty since the use of scoped-constants, meta-level H-reduction, and higher-order unification is used to access and manipulate the inner terms.
Also, whereas (Park, 1992) requires careful consideration of handling of determiners with coordination, here such sentences are handled just like any others.
For example, the sentence Mary gave every dog a bone and some policeman a flower results in the LF 12.
12This is a case in which the paxticulax LF assumed here fails to yield another available scoping.
See footnote 10.
217 (and' (exists x\C(bone' x) Itlt (fore11 xl\((dog' xl) >> (gave' aaxy' x xl))))) (exists x\((flover J x) 11 (existu xl\((poiiceman' xl) IU~ (gave' =axy' x xl)))))) Thus, "generalized coordination", instead of being a family of separate rules, can be expressed as a single rule on recursive descent through logical forms.
(Steedman, 1990) also discusses "generalized composition", and it may well be that a similar implementation is possible for that family of rules as well.
5 Conclusion
We have shown how higher-order logic programming can be used to elegantly implement the semantic theory of CCG, including the previously difficult case of its handling of coordination constructs.
The techniques used here should allow similar advantages for a variety of such theories.
An argument can be made that the approach taken here relies on a formalism that entails implementation issues that are more difficult than for the other solutions and inherently not as efficient.
However, the implementation issues, although more complex, are also well-understood and it can be expected that future work will bring further improvements.
For example, it is a straightforward matter to transform the,XProlog code into a logic called L~ (Miller, 1990) which requires only a restricted form of unification that is decidable in linear time and space.
Also, the declarative nature of ~Prolog programs opens up the possibility for applications of program transformations such as partial evaluation.
6 Acknowledgments
This work is supported by ARC) grant DAAL03-890031, DARPA grant N00014-90-J-1863, and ARO grant DAAH04-94-G-0426.
I would like to thank Aravind Joshi, Dale Miller, Jong Park, and Mark Steedman for valuable discussions and comments on earlier drafts.
References David Dowty.
1988. Type raising, functional composition, and non-constituent conjunction.
In Richard T.
Oehrle, Emmon Bach, and Deirdre Wheeler, editors, Categorial Grammars and Natural Language Structures.
Reidel, Dordrecht, pages 153-198.
Gerald Gazdar.
1988. Applicability of indexed grammars to natural languages.
In U.
Reyle and C.
Rohrer, editors, Natural language parsing and linguistic theories.
Reidel, Dordrecht, pages 69-94.
Jerry R.
Hobbs and Stuart M.
Shieber. 1987.
An algorithm for generating quantifier scopings.
Computational Linguistics, 13:47-63.
Einar Jowsey.
1990. Constraining Montague Grammar for Computational Applications.
PhD thesis, University of Edinburgh.
Dale Miller.
1990. A logic programming language with lambda abstraction, function variables and simple unification.
In P.
Schroeder-Heister, editor, Eztensions of Logic Programming, Lecture Notes in Artifical Intelligence, Springer-Verlag, 1990.
Dale Miller.
1991. Abstract syntax and logic programming.
In Proceedings of the Second Russian Conference on Logic Programming, September 1991.
Dale Miller and Gopalan Nadathur.
1986. Some uses of higher-order logic in computational linguistics.
In 24th Annual Meeting of the Association for Computational Linguistics, pages 247-255.
Dale Miller, Gopalan Nadathur, Frank Pfenning, Andre Scedrov.
1991. Uniform proofs as a foundation for logic programming.
In Annals of Pure and Applied Logic, 51:125-157.
Robert C.
Moore. 1989.
Unification-based semantic interpretation.
In 27th Annual Meeting of the Association for Computational Linguistics, pages 33-41.
Remo Pareschi.
1989. Type-Driven Natural Language Aanalysis.
PhD thesis, University of Edinburgh.
Jong C.
Park. 1992.
A unification-based semantic interpretation for coordinate constructs.
In 80th Annual Meeting of the Association for Computational Linguistics, pages 209-215.
Jong C.
Park. 1995.
Quantifier scope and constituency.
In 33rd Annual Meeting of the Association for Computational Linguistics (this volume).
Barbara Partee and Mats Rooth.
1983. Generalized conjunction and type ambiguity.
In Rainer Banerle, Christoph Schwarze, and Arnim von Stechow, editors, Meaning, Use, and Interpretation of Language.
W. de Gruyter, Berlin, pages 361383.
Fernando C.N.
Pereira. 1990.
Semantic interpretation as higher-order deduction.
In Jan van Eijck, editor, Logics in AI: European Workshop JELIA '90, Lecture Notes in Artificial Intelligence number 478, pages 78-96.
Springer-Verlag, Berlin, Germany.
Fernando C.N.
Pereira and Stuart M.
Shieber. 1987.
Prolog and Natural-Language Analysis.
Number 10 in CSLI Lecture Notes.
Center for the Study of Language and Information, Stanford, California, 1985.
Distributed by the University of Chicago Press.
Frank Pfenning and Conal Elliot.
1988. Higherorder abstract syntax.
In Proceedings of the A CMSIGPLAN Conference on Programming Language Design and Implementation, 1988.
Mark J.
Steedman. 1990.
Gapping as constituent coordination.
In Linguistics and Philosophy 13, pages 207-263 David Weir.
1988. Characterizing Mildly Conteztsensitive Grammar Formalism.
CIS-88-74, PhD thesis, University of Pennsylvania.
David Weir and Aravind Joshi.
1988. Combinatory categorial grammars: generative power and relation to linear CF rewriting systems.
In ~6th Annual Meeting of the Association for Computational Linguistics, pages 278-285 .

