The maximum entropy model shown in (Borthwick et al., 1998) in particular seems a promising approach because of its ability to handle overlapping and large feature sets within n well founded nmthenmtical ti'amework.
W98-1118
shown that lnodels based on HMMs and decision trees such as (Nol)al;~t et al., 1999) ~,r(; much more generalisable and adaptable to slew classes of words than systems based on traditional hand-lmilt 1)attexns a.nd domain specific heuristic rules such as (Fukuda et al., 1998), overcoming the 1)rol)lems associated with data sparseness with the help of sophisticated smoothing algorithms 201 (Chen and Goodman, 1996).
P96-1041
Nymble (Bikel et al., 1997), a system which uses HMMs is one of the most successflfl such systems and trains on a corpus of marked-up text, using only character features in addition to word bigrams.
A97-1029
With the rapid growth in the mlmbcr of tmb\]ished l)al)ers in the field of moh;('ular-biolog 3, there has been growing interest in the at)plication of informa.tion extra(:tion, (Sekimizu et al., 1998) (Collier et al., 1999)(Thomas et al., 1999) (Craven and Kmnlien, 1999), to help solve souse (sf the t)robhmss that are associated with information overload.
E99-1043
