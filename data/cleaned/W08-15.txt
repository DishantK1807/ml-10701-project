1:139	Coling 2008 22nd International Conference on Computational Linguistics Proceedings of the workshop on Speech Processing for Safety Critical Translation and Pervasive Applications Workshop chairs: Pierrette Bouillon, Farzad Ehsani, Robert Frederking, Michael McTear and Manny Rayner 23 August 2008 c2008 The Coling 2008 Organizing Committee Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Nonported license http://creativecommons.org/licenses/by-nc-sa/3.0/ Some rights reserved Order copies of this and other Coling proceedings from: Association for Computational Linguistics (ACL) 209 N. Eighth Street Stroudsburg, PA 18360 USA Tel: +1-570-476-8006 Fax: +1-570-476-0860 acl@aclweb.org ISBN 978-1-905593-52-1 Design by Chimney Design, Brighton, UK Production and manufacture by One Digital, Brighton, UK ii Introduction Two ideas currently gaining popularity in spoken dialogue construction are safety critical translation and pervasive speech-enabled applications.
2:139	Safety critical, and in particular, medical, applications have emerged as one of the most popular domains for speech translation.
3:139	At the first workshop on medical speech translation, held at HLT 2006, a measure of consensus emerged on at least some points.
4:139	The key issue that differentiates the medical domain from most other application areas for speech translation is its safety-critical nature; systems can realistically be fielddeployed now or in the very near future; the basic communication model should be collaborative, and allow the client users to play an active role; and medical systems are often most useful when deployed on mobile devices.
5:139	This last point offers a natural link to pervasive computing applications, where spoken language technologies provide an effective and natural interface for mobile devices in situations where traditional modes of communication are less appropriate.
6:139	However, there is so far little agreement on many central questions, including choices of architectures, component technologies, and evaluation methodologies.
7:139	In this workshop we hope that people interested in these types of application will meet, exchange ideas and demo live systems.
8:139	iii  Organizers: Pierrette Bouillon, U Geneva (Switzerland) Farzad Ehsani, Fluential (US) Robert Frederking, CMU (US) Michael McTear, U Ulster (Northern Ireland) Manny Rayner, U Geneva (Switzerland) Programme Committee: Laurent Besacier, U Grenoble (France) Pierrette Bouillon, U Geneva (Switzerland) Mike Dillinger, SpokenTranslation (US) Farzad Ehsani, Fluential (US) Glenn Flores, U Texas (US) Robert Frederking, CMU (US) Hitoshi Isahara, NICT (Japan) Michael McTear, U Ulster (Northern Ireland) Shri Narayanan, USC (US) Aarne Ranta, U Gothenburg (Sweden) Manny Rayner, U Geneva (Switzerland) Tanja Schultz, U Karlsruhe (Germany) Harold Somers, U Manchester (UK) and Dublin City U (Ireland) Bowen Zhou, IBM (US) v  Table of Contents Mitigation of Data Sparsity in Classifier-Based Translation Emil Ettelaie, Panayiotis G. Georgiou and Shrikanth S. Narayanan1 Speech Translation with Grammatical Framework Bjorn Bringert5 An Integrated Dialog Simulation Technique for Evaluating Spoken Dialog Systems Sangkeun Jung, Cheongjae Lee, Kyungduk Kim and Gary Geunbae Lee9 Economical Global Access to a VoiceXML Gateway Using Open Source Technologies Kulwinder Singh and Dong-Won Park  17 Interoperability and Knowledge Representation in Distributed Health and Fitness Companion Dialogue System Jaakko Hakulinen and Markku Turunen24 The 2008 MedSLT System Manny Rayner, Pierrette Bouillon, Jane Brotanek, Glenn Flores, Sonia Halimi, Beth Ann Hockey, Hitoshi Isahara, Kyoko Kanzaki, Elisabeth Kron, Yukie Nakao, Marianne Santaholma, Marianne Starlander and Nikos Tsourakis32 Language Understanding in Maryland Virtual Patient Sergei Nirenburg, Stephen Beale, Marjorie McShane, Bruce Jarrell and George Fantry36 Rapid Portability among Domains in an Interactive Spoken Language Translation System Mark Seligman and Mike Dillinger40 Speech Translation for Triage of Emergency Phonecalls in Minority Languages Udhyakumar Nallasamy, Alan Black, Tanja Schultz, Robert Frederking and Jerry Weltman48 Speech to Speech Translation for Nurse Patient Interaction Farzad Ehsani, Jim Kimzey, Elaine Zuber, Demitrios Master and Karen Sudre  54 A Small-Vocabulary Shared Task for Medical Speech Translation Manny Rayner, Pierrette Bouillon, Glenn Flores, Farzad Ehsani, Marianne Starlander, Beth Ann Hockey, Jane Brotanek and Lukas Biewald60 vii  Conference Programme Saturday, August 23, 2008 9:309:40 Opening Remarks Session 1: Architectures for Speech Translation 09:4010:05 Mitigation of Data Sparsity in Classifier-Based Translation Emil Ettelaie, Panayiotis G. Georgiou and Shrikanth S. Narayanan 10:0510:30 Speech Translation with Grammatical Framework Bjorn Bringert 10:3011:00 Break Session 2: Pervasive Speech Applications 11:0011:25 An Integrated Dialog Simulation Technique for Evaluating Spoken Dialog Systems Sangkeun Jung, Cheongjae Lee, Kyungduk Kim and Gary Geunbae Lee 11:2511:50 Economical Global Access to a VoiceXML Gateway Using Open Source Technologies Kulwinder Singh and Dong-Won Park 11:5012:15 Interoperability and Knowledge Representation in Distributed Health and Fitness Companion Dialogue System Jaakko Hakulinen and Markku Turunen 12:3014:00 Lunch ix Saturday, August 23, 2008 (continued) Session 3: Speech Translation Demos 14:0015:30 The 2008 MedSLT System Manny Rayner, Pierrette Bouillon, Jane Brotanek, Glenn Flores, Sonia Halimi, Beth Ann Hockey, Hitoshi Isahara, Kyoko Kanzaki, Elisabeth Kron, Yukie Nakao, Marianne Santaholma, Marianne Starlander and Nikos Tsourakis 14:0015:30 Language Understanding in Maryland Virtual Patient Sergei Nirenburg, Stephen Beale, Marjorie McShane, Bruce Jarrell and George Fantry 14:0015:30 Rapid Portability among Domains in an Interactive Spoken Language Translation System Mark Seligman and Mike Dillinger 15:3016:00 Break Session 4: Speech Translation Systems 16:0016:25 Speech Translation for Triage of Emergency Phonecalls in Minority Languages Udhyakumar Nallasamy, Alan Black, Tanja Schultz, Robert Frederking and Jerry Weltman 16:2516:50 Speech to Speech Translation for Nurse Patient Interaction Farzad Ehsani, Jim Kimzey, Elaine Zuber, Demitrios Master and Karen Sudre Session 5: A Shared Task for Medical Speech Translation?
9:139	16:5017:05 A Small-Vocabulary Shared Task for Medical Speech Translation Manny Rayner, Pierrette Bouillon, Glenn Flores, Farzad Ehsani, Marianne Starlander, Beth Ann Hockey, Jane Brotanek and Lukas Biewald 17:05close Panel Discussion x Coling 2008: Proceedings of the workshop on Speech Processing for Safety Critical Translation and Pervasive Applications, pages 14 Manchester, August 2008 Mitigation of data sparsity in classifier-based translation Emil Ettelaie, Panayiotis G. Georgiou, Shrikanth S. Narayanan Signal Analysis and Interpretation Laboratory Ming Hsieh Department of Electrical Engineering Viterbi School of Engineering University of Southern California ettelaie@usc.edu Abstract The concept classifier has been used as a translation unit in speech-to-speech translation systems.
10:139	However, the sparsity of the training data is the bottle neck of its effectiveness.
11:139	Here, a new method based on using a statistical machine translation system has been introduced to mitigate the effects of data sparsity for training classifiers.
12:139	Also, the effects of the background model which is necessary to compensate the above problem, is investigated.
13:139	Experimental evaluation in the context of crosslingual doctor-patient interaction application show the superiority of the proposed method.
14:139	1 Introduction Statistical machine translation (SMT) methods are well established in speech-to-speech translation systems as the main translation technique (Narayanan et al., 2003; Hsiao et al., 2006).
15:139	Due to their flexibility these methods provide a good coverage of the dialog domain.
16:139	The fluency of the translation, however, is not guaranteed.
17:139	Disfluencies of spoken utterances plus the speech recognizer errors degrade the translation quality even more.
18:139	All these ultimately affect the quality of the synthesized speech output in the target language, and the effectiveness of the concept transfer.
19:139	It is quite common, though, to use other means of translation in parallel to the SMT methods (Gao et al., 2006; Stallard et al., 2006).
20:139	Concept classification, as an alternative translation method, has been successfully integrated in speech-to-speech translators (Narayanan et al., 2003; Ehsani et al., 2006).
21:139	A well defined dialog domain, e.g. doctor-patient dialog, can be partly covered by a number of concept classes.
22:139	Upon a successful classification of the input utterance, the translation task reduces to c2008.
23:139	Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
24:139	Some rights reserved.
25:139	synthesizing a previously created translation of the concept, as a mere look up.
26:139	Since the main goal in such applications is an accurate exchange of concepts, this method would serve the purpose as long as the input utterance falls within the coverage of the classifier.
27:139	This process can be viewed as a quantization of a continuous semantic sub-space.
28:139	The classifier is adequate when the quantization error is small (i.e. the derived concept and input utterance are good matches), and when the utterance falls in the same sub-space (domain) as the quantizer attempts to cover.
29:139	Since it is not feasible to accurately cover the whole dialog domain (since a large number of quantization levels needed) the classifier should be accompanied by a translation system with a much wider range such as an SMT engine.
30:139	A rejection mechanism can help identify the cases that the input utterance falls outside the classifier coverage (Ettelaie et al., 2006).
31:139	In spite of this short coming, the classifierbased translator is an attractive option for speechto-speech applications because of its tolerance to noisy input and the fluency of its output, when it operates close to its design parameters.
32:139	In practice this is attainable for structured dialog interactions with high levels of predictability.
33:139	In addition, it can provide the users with both an accurate feedback and different translation options to choose from.
34:139	The latter feature, specially, is useful for applications like doctor-patient dialog.
35:139	Building a concept classifier starts with identifying the desired concepts and representing them with canonical utterances that express these concepts.
36:139	A good set of concepts should consist of the ones that are more frequent in a typical interaction in the domain.
37:139	For instance in a doctor-patient dialog, the utterance Where does it hurt? is quite common and therefore its concept is a good choice.
38:139	Phrase books, websites, and experts judgment are some of the resources that can be used for concept selection.
39:139	Other frequently used concepts include those that correspond to basic communicative and social aspects of the interaction such as greeting, acknowledgment and confirmation.
40:139	After forming the concept space, for each class, 1 utterances that convey its concept must be gathered.
41:139	Hence, this training corpus would consist of a group of paraphrases for each class.
42:139	This form of data are often very difficult to collect as the number of classes grow.
43:139	Therefore, the available training data are usually sparse and cannot produce a classification accuracy to the degree possible.
44:139	Since the classifier range is limited, high accuracy within that range is quite crucial for its effectiveness.
45:139	One of the main issues is dealing with data sparsity.
46:139	Other techniques have also been proposed to improve the classification rates.
47:139	For example in (Ettelaie et al., 2006) the accuracy has been improved by introducing a dialog model.
48:139	Also, a background model has been used to improve the discrimination ability of a given concept class model.
49:139	In this work a novel method for handling the sparsity is introduced.
50:139	This method utilizes an SMT engine to map a single utterance to a group of them.
51:139	Furthermore, the effect of the background model on classification accuracy is investigated.
52:139	Section 2 reviews the concept classification process and the background model.
53:139	In Section 3 the sparsity handling method using an SMT is introduced.
54:139	Data and experiments are described in Section 4.
55:139	The results are discussed in Section 5.
56:139	2 Concept classifier and background model The concept classifier based on the maximum likelihood criterion can be implemented as a language model (LM) scoring process.
57:139	For each class a language model is built using data expressing the class concept.
58:139	The classifier scores the input utterance using the class LMs and selects the class with highest score.
59:139	In another word if C is the set of concept classes and e is the input utterance, the classification process is, c = argmaxcC {Pc (e|c)} (1) where Pc(e |c) is the score of e from the LM of class c. The translation job is concluded by playing out a previously constructed prompt that expresses the concept c in the target language.
60:139	It is clear that a class with limited training data items will have an undertrained associated LM with poor coverage.
61:139	In practice such a model fails to produce a usable LM score and leads to a poor classification accuracy.
62:139	Interpolating the LM with a background language model results in a smoother model (Stolcke, 2002) and increases the overall accuracy of the classifier.
63:139	The background model should be built from a larger corpus that fairly covers the domain vocabulary.
64:139	The interpolation level can be optimized for the best performance based on heldout set.
65:139	3 Handling sparsity by statistical machine translation The goal is to employ techniques that limit the effects of data sparsity.
66:139	What is proposed here is to generate multiple utterances  possibly with lower quality  from a single original one.
67:139	One approach is to use an SMT to generate n-best lists of translation candidates for the original utterances.
68:139	Such lists are ranked based on a combination of scores from different models (Ney et al., 2000).
69:139	The hypothesis here is that for an SMT trained on a large corpus, the quality of the candidates would not degrade rapidly as one moves down the n-best list.
70:139	Therefore a list with an appropriate length would consist of translations with acceptable quality without containing a lot of poor candidates.
71:139	This process would result in more data, available for training, at the cost of using noisier data.
72:139	Although the source language of the SMT must be the same as the classifiers, its target language can be selected deliberately.
73:139	It is clear that a language with large available resources (in the form of parallel corpora with the source language) must be selected.
74:139	For simplicity this language is called the intermediate language here.
75:139	A classifier in the intermediate language can be built by first generating an n-best list for every source utterance in the classifiers training corpus.
76:139	Then the n-best lists associated with each class are combined to form a new training set.
77:139	The class LMs are now built from these training sets rather than the original sets of the source utterances.
78:139	To classify a source utterance e, first the SMT is deployed to generate an n-best list (in the intermediate language) from it.
79:139	The list will consist of candidates f1, f2,, fn.
80:139	The classification process can be reformulated as, c = argmaxcC braceleftBigg nproductdisplay i=1 Pc (fi|c) bracerightBigg (2) Here, Pc(fi |c) is the score of the ith candidate fi from the LM of class c. The scores are considered in the probability domain.
81:139	The new class LMs can also be smoothed by interpolation with a background model in the intermediate language.
82:139	4 Data and Experiments 4.1 Data The data used in this work were originally collected for, and used in, the Transonics project (Narayanan et al., 2003) to develop an English/Farsi speech-tospeech translator in the doctor-patient interaction domain.
83:139	For the doctor side, 1,269 concept classes were carefully chosen using experts judgment and medical phrase books.
84:139	Then, for each concept, English data were collected from a website, a webbased game, and multiple paraphrasing sessions at the Information Sciences Institute of the University 2 Conventional n-best length (baseline) 100 500 1,000 2,000 Accuracy [%] 74.9 77.4 77.5 76.8 76.4 Relative error reduction [%] 0.0 10.0 10.4 7.6 6.0 Accuracy in 4-best [%] 88.6 90.7 91.0 91.3 90.5 Relative error reduction [%] 0.0 18.4 21.1 23.7 16.7 Table 1: Classification accuracy for the conventional method and the proposed method with different lengths of n-best list of Southern California.
85:139	The total size of the data set consists of 9,893 English phrases.
86:139	As the test corpus for this work, 1,000 phrases were randomly drawn from the above set and the rest were used for training.
87:139	To make sure that the training set covered every class, one phrase per class was excluded from the test set selection process.
88:139	To generate the n-best lists, a phrase based SMT (Koehn et al., 2003) was used.
89:139	The intermediate language was Farsi and the SMT was trained on a parallel English/Farsi corpus with 148K lines (1.2M words) on the English side.
90:139	This corpus was also used to build the classification background models in both languages.
91:139	The SMT was optimized using a parallel development set with 915 lines (7.3K words) on the English side.
92:139	4.2 Classification Accuracy Measures Classifier accuracy is often used as the the quality indicator of the classification task.
93:139	However, it is common in the speech-to-speech translation systems to provide the user with a short list of potential translations to choose from.
94:139	For example the user of system in (Narayanan et al., 2003) is provided with the top four classifier outputs.
95:139	In such cases, it is practically useful to measure the accuracy of the classifier within its n-best outputs (e.g., n = 4 for the above system).
96:139	In this work the classification accuracy was measured on both the single output and the 4-best outputs.
97:139	4.3 Experiments To compare the proposed method with the conventional classification, a classifier based on each method was put to test.
98:139	In the proposed method, it is expected that the accuracy is affected by the length of the n-best lists.
99:139	To observe that, n-best lists of lengths 100, 500, 1000, and 2000 were used in the experiments.
100:139	The results are shown in Table 1.
101:139	In all of the above experiments the background interpolation factor was set to 0.9 which is close to the optimum value obtained in (Ettelaie et al., 2006).
102:139	To examine the effect of the background model, the conventional and proposed methods were tried with different values of the interpolation factor  (the background model is weighted by 1).
103:139	For the conventional method the length of the n-best list was set to 500.
104:139	Figure 1 shows the accuracy 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.045% 50% 55% 60% 65% 70% 75% 80% 85% 90% 95% Conv.
105:139	4-bestConv.
106:139	New 4-bestNew Background Interpolation Factor Accu racy 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.00% 5% Background Interpolation Factor () Accu racy Figure 1: The effect of background model on classification accuracy changes with respect to the interpolation factor for these two methods.
107:139	5 Discussion Table 1 shows the advantage of the proposed method over the conventional classification with a relative error rate reduction up to 10.4% (achieved when the length of the SMT n-best list was 500).
108:139	However, as expected, this number decreases with longer SMT n-best lists due to the increased noise present in lower ranked outputs of the SMT.
109:139	Table 1 also shows the accuracy within 4-best classifier outputs for each method.
110:139	In that case the proposed method showed an error rate which was relatively 23.7% lower than the error rate of the conventional method.
111:139	That was achieved at the peak of the accuracy within 4-best, when the length of the SMT n-best list was 1,000.
112:139	In this case too, further increase in the length of the n-best list led to an accuracy degradation as the classifier models became noisier.
113:139	The effect of the background model on classifier accuracy is shown in Figure 1.
114:139	The figure shows the one-best accuracy and the accuracy within 4best outputs, versus the background interpolation factor () for both conventional and proposed methods.
115:139	As the curves indicate, withequal to zero the classifier has no discriminating feature since all the class scores are driven solely from the background model.
116:139	However, a slight increase in , leads to a large jump in the accuracy.
117:139	The reason is that the background model was built from a large general domain corpus and hence, had no bias toward any of the classes.
118:139	With a small , the score from the background model dominates the overall class scores.
119:139	In spite of that, the score differences caused by the class LMs are notable in improving the classifier performance.
120:139	As  increases the role of the class LMs becomes more prominent.
121:139	This makes the classifier models more discriminative and increases its accuracy as shown in Figure 1.
122:139	When the factor is in the close vicinity of one, the smoothing effect of the background model diminishes and leaves the 3 classes with spiky models with very low vocabulary coverage (lots of zeros).
123:139	This leads to a rapid drop in accuracy as  reaches one.
124:139	Both the conventional and proposed methods follow the above trend as Figure 1 shows, although, the proposed method maintains its superiority throughout the range of  that was examined.
125:139	The maximum measured accuracies for conventional and proposed methods were 75.2% and 78.7% respectively and was measured at = 0.999 for both methods.
126:139	Therefore, the error rate of the proposed method was relatively 14.1% lower than its counterpart from the conventional method.
127:139	Figure 1 also indicates that when the accuracy is measured within the 4-best outputs, again the proposed method outperforms the conventional one.
128:139	The maximum 4-best accuracy for the conventional method was measured at the sample point  = 0.9 and was equal to 88.6%.
129:139	For the proposed method, that number was measured as 91.5% achieved at the sample point  = 0.999.
130:139	In another words, considering the 4-best classifier outputs, the error rate of the proposed method was relatively 25.4% lower.
131:139	6 Conclusion The proposed language model based method can be used to improve the accuracy of the concept classifiers specially in the case of sparse training data.
132:139	It outperformed the conventional classifier, trained on the original source language paraphrases, in the experiments.
133:139	With this method, when the input utterance is within the classification domain, the classifier can be viewed as a filter that produces fluent translations (removes the noise) from the SMT output.
134:139	The experiments also emphasized the importance of the background model, although indicated that the classification accuracy was not very sensitive to the value of the background interpolation factor.
135:139	This relieves the developers from the fine tuning of that factor and eliminates the need for a development data set when a suboptimal solution is acceptable.
136:139	We believe that significant improvements to the technique can be made through the use of weighted n-best lists based on the SMT scores.
137:139	In addition we believe that using a much richer SMT engine could provide significant gains through increased diversity in the output vocabulary.
138:139	We intend to extend on this work through the use of enriched, multilingual SMT engines, and the creation of multiple classifiers (in several intermediate languages).
139:139	7 Acknowledgment This work was supported in part by funds from DARPA.

