Other research has shown that query statistics from a web search engine can be used as a substitute for counts collected from large corpora (Volk, 2001; Keller et al., 2002).
W02-1030
Curran and Miles Osborne Institute for Communicating and Collaborative Systems University of Edinburgh 2 Buccleuch Place, Edinburgh EH8 9LW United Kingdom a0 jamesc,osborne a1 @cogsci.ed.ac.uk Abstract Banko and Brill (2001) suggested that the development of very large training corpora may be more effective for progress in empirical Natural Language Processing than improving methods that use existing smaller training corpora.
P01-1005
Recent work has replicated the Banko and Brill (2001) results on the much more complex task of automatic thesaurus extraction, showing that contextual statistics, collected over a very large corpus, signi cantly improve system performance (Curran and Moens, 2002).
P01-1005 P02-1030
Banko and Brill (2001) report on confusion set disambiguation experiments where they apply relatively simple learning methods to a one billion word training corpus.
P01-1005
Smoothing typically adds considerable computational complexity to the system since multiple models need to be estimated and applied together, and it is often considered a black art (Chen and Goodman, 1996).
P96-1041
We are also interested in applying the exponential models of lexical attraction and repulsion described by Beeferman et al.(1997) to the very large corpus.
P97-1048
