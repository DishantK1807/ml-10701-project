Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 192–201,
Paris, October 2009. c 2009 Association for Computational Linguistics
Clustering Words by Syntactic Similarity Improves Dependency  
Parsing of Predicate-Argument Structures 
 
Kenji Sagae and Andrew S. Gordon 
Institute for Creative Technologies 
University of Southern California 
13274 Fiji Way 
Marina del Rey, CA 90292 
{sagae,gordon}@ict.usc.edu 
 
  
 
Abstract 
We present an aproach for deriving syntactic 
word clusters from parsed text, grouping 
words acording to their unlexicalized syntac-
tic contexts. We then explore the use of these 
syntactic clusters in leveraging a large corpus 
of tres generated by a high-acuracy parser to 
improve the acuracy of another parser based 
on a diferent formalism for representing a dif-
ferent level of sentence structure.  In our ex-
periments, we use phrase-structure tres to 
produce syntactic word clusters that are used 
by a predicate-argument dependency parser, 
significantly improving its acuracy. 
1 Introduction

Syntactic parsing of natural language has ad-
vanced greatly in recent years, in large part due 
to data-driven techniques (Colins, 199; 
Charniak, 200; Miyao and Tsuji, 205; 
McDonald et al., 205; Nivre et al., 207) cou-
pled with the availability of large trebanks. Sev-
eral recent eforts have started to lok for ways 
to go beyond what individual anotated data sets 
and individual parser models can ofer, loking 
to combine diverse parsing models, develop 
cros-framework interoperability and evaluation, 
and leverage the availability of large amounts of 
text available. Two research directions that have 
produced promising improvements on the acu-
racy of data-driven parsing are: (1) combining 
diferent parsers using ensemble techniques, such 
as voting (Henderson and Bril, 199; Sagae and 
Lavie, 206; Hal et al., 207) and stacking 
(Nivre and McDonald, 208; Martins et al., 
208), and (2) semi-supervised learning, where 
unlabeled data (plain text) is used in adition to a 
trebank (McClosky et al., 206; Ko et al., 
208). 
In this paper we explore a new way to obtain 
improved parsing acuracy by using a large 
amount of unlabeled text and two parsers that use 
diferent ways of representing syntactic structure. 
In contrast to previous work where automaticaly 
generated constituent tres were used directly to 
train a constituent parsing model (McClosky et 
al., 206), or where word clusters were derived 
from a large corpus of plain text to improve a 
dependency parser (Ko et al., 208), we use a 
large corpus of constituent tres (previously gen-
erated by an acurate constituent parser), which 
we use to produce syntacticaly derived clusters 
that are then used to improve a transition-based 
parser that outputs dependency graphs that re-
flect predicate-argument structure where words 
may be dependents of more than one parent. 
This type of representation is more general than 
dependency tres (Sagae and Tsuji, 208; 
Henderson et al., 208), and is suitable for repre-
senting both surface relations and long-distance 
dependencies (such as control, it-cleft and tough 
movement). 
The first contribution of this work is a novel 
aproach for deriving syntactic word clusters 
from parsed text, grouping words by the general 
syntactic contexts where they apear, and not by 
n-gram word context (Brown et al., 192) or by 
imediate dependency context (Lin, 198). Un-
like in clustering aproaches that rely on lexical 
context (either linear or gramatical) to group 
words, resulting in a notion of word similarity 
that blurs syntactic and semantic characteristics 
of lexical items, we use unlexicalized syntactic 
context, so that words are clustered based only 
on their syntactic behavior.  This way, we at-
tempt to generate clusters that are more concep-
tualy similar to part-of-spech tags or supertags 
192
(Bangalore and Joshi, 199), but organized hier-
archicaly to provide tagsets with varying levels 
of granularity. 
Our second contribution is a methodology for 
leveraging a high-acuracy parser to improve the 
acuracy of a parser that uses a diferent formal-
ism (that represents diferent structural informa-
tion), without the ned to proces the input with 
both parsers at run-time. In our experiments, we 
show that we can improve the acuracy of a fast 
dependency parser for predicate-argument struc-
tures by using a corpus which was previously 
automaticaly anotated using a highly acurate 
but considerably slower phrase-structure tre 
parser. This is acomplished by using the slower 
parser only to parse the data used to create the 
syntactic word clusters.  During run-time, the 
dependency parser uses these clusters, which 
encapsulate syntactic knowledge from the 
phrase-structure parser.  Although our experi-
ments focus on the use of phrase-structure and 
dependency parsers, the same framework can be 
easily aplied to data-driven parsing using other 
syntactic formalisms, such as CG or HPSG. 
2 Clustering
by Syntactic Similarity 
We developed a new aproach to clustering 
words acording to their syntactic similarity. Our 
method involves the use of hierarchical aglom-
erate clustering techniques using the calculated 
syntactic distance betwen words. Syntactic dis-
tance betwen words is computed as the cosine 
distance betwen vector representations of the 
frequency of unique parse tre paths emanating 
from the word in a corpus of parse tres. In this 
research, we employ a novel encoding of syntac-
tic parse tre paths that includes direction infor-
mation and non-terminal node labels, but does 
not include lexical information or part-of-spech 
tags. Consequently, the resulting hierarchy 
groups words that apear in similar places in 
similar parse tres, regardles of its asigned 
part-of-spech tag.  In this section we describe 
our aproach in detail. 
2.1 Parse
tre path representation 
Gordon and Swanson (207) first described a 
corpus-based method for calculating a measure 
of syntactic similarity betwen words, and dem-
onstrated its utility in improving the performance 
of a syntax-based Semantic Role Labeling sys-
tem. The central idea behind their aproach was 
that parse tre paths could be used as features 
for describing a word’s gramatical behavior. 
Parse tre paths are descriptions of tre transi-
tions from a terminal (e.g. a verb) to a diferent 
node in a constituent parse tre of a sentence. 
Parse tre paths gained popularity in early Se-
mantic Role Labeling research (Gildea and Juraf-
sky, 202), where they were used as features de-
scribing the relationship betwen a verb and a 
particular semantic role label. For example, Fig-
ure 1 ilustrates a parse tre path betwen a verb 
and a semanticaly related noun phrase. 
Gordon and Swanson viewed parse tre paths 
as features that could be used to describe the syn-
tactic contexts of words in a corpus. In their ap-
proach, al of the posible parse tre paths that 
begin at a given word were identified in a large 
set of automaticaly generated constituent parse 
tres. The normalized frequency counts of 
unique parse tre paths were combined into a 
feature vector that describes the location that the 
given word apears in the set of parse tres. This 
syntactic profile was then compared with other 
profiles using a cosine distance function, produc-
ing a quantitative value of word similarity. In 
this maner, the syntactic similarity betwen the 
verb “pluck” and the verb “whisk” was calcu-
lated as 0.849. 
One drawback of the aproach of Gordon and 
Swanson was the inclusion of part-of-spech tags 
in the encoding of the parse tre paths. As a con-
sequence, the cosine distance betwen words of 
diferent clases was always zero, regardles of 
their similarities in the remainder of the paths. 
To corect this problem in our curent research, 
we removed part-of-spech tags from the encod-
ing of parse tre paths, deleting the tag that be-
gins each path and replacing tags when they ap-
pear at the end of a path with a generic terminal 
label. 
A second drawback of the aproach of Gordon 
and Swanson is that the path directionality is un-
derspecified. Consider the parse tre paths that 
 
Figure 1: An example parse tre path from 
the verb ate to the argument NP He, repre-
sented as ↑VBD↑VP↑S↓NP. 
 
193
emanate from each of the words “some” and 
“pancakes” in Figure 1. In the original encoding, 
the paths for each of these words would be iden-
tical (if the part of spech tags were removed), 
despite their unique locations in this parse tre. 
To corect this problem in our curent research, 
we elaborated the original set of two path identi-
fiers (↑ and ↓) to a set of six tags that included 
information about the direction of the transition. 
Up-Right () and Down-Left () transition are 
used to and from nodes that are the first constitu-
ent of a non-terminal. Up-Left () and Down-
Right () transitions are used to and from nodes 
that are the last constituent of a non-terminal. 
Transitions to and from al other constituent 
nodes are labeled Up-Midle (↑) or Down-
Midle (↓), acordingly. For example, we repre-
sent the parse tre path depicted in Figure 1 as: 
VPSNP. 
2.2 Profiles
for BLIP WSJ Corpus words 
As in the previous work of Gordon and Swanson 
(207), we characterize the syntactic properties 
of words as the normalized frequency of unique 
parse tre paths emanating from the word in a 
large corpus of syntactic parse tres. 
In our research, we used the Brown Labora-
tory for Linguistic Information Procesing 
(BLIP) 1987-89 WSJ Corpus Release 1 
(Charniak et al., 200), which contains aproxi-
mately 30 milion words of Wal Stret Journal 
news articles, parsed with Charniak (200) 
parser.  Although the tres in the BLIP corpus 
are enriched with function tags and empty nodes, 
we remove this information, leaving only the 
tres produced by the Charniak parser. We iden-
tified the top five thousand most frequent words 
(or, more generaly, types, since these also in-
clude other sequences of characters, such as 
numbers and punctuation) in this corpus, treating 
words that difered in capitalization or in as-
signed part-of-spech tag as separate types. 
These five thousand types corespond to ap-
proximately 85% of the tokens in the BLIP 
corpus. For each token instance of each of these 
five thousand types, we identified every ocur-
ring parse tre path emanating from the token in 
each of the sentences in which it apeared. The 
most frequent type was the coma, which ap-
peared 2.2 milion times and produced 18 mil-
lion parse tre paths. The least frequent token in 
this set was the singular noun “polution,” with 
731 instances producing 35,185 parse tre paths. 
To generate syntactic profiles for a given type, 
the frequency of unique parse tre paths was ta-
tabulated, and then normalized by dividing this 
frequency by the number of tokens of that type in 
the corpus. To reduce the dimensionality of these 
normalized frequency vectors, parse tre paths 
that apeared in les than 0.2% of the instances 
were ignored. This threshold value produced 
vectors with dimensionality that was comparable 
acros al five thousand types, and smal enough 
to proces given our available computational re-
sources. The mean vector size was 2,28 dimen-
sions, with a standard deviation of 734. 
2.3 Distance
calculation and clustering 
Pairwise distances betwen each of the five thou-
sand types were computed as the cosine distance 
betwen their profile vectors. We then grouped 
similar types using hierarchical aglomerate 
clustering techniques, where distance betwen 
clusters is calculated as mean distance betwen 
elements of each cluster (average link cluster-
ing). 
The thre most similar types (the first 2 clus-
tering steps) consisted of the capitalized subordi-
nating conjunctions “Although,” “While,” and 
“Though.” The two most disimilar types (the 
last to be included in any existing cluster) were 
the symbol “@” and the question mark. 
2.4 Cluster
label selection 
Hierarchical aglomerate clustering produces a 
binary-branching tre structure, where each 
branch point is ordered acording to a similarity 
value betwen 0 and 1. In our clustering of the 
top five thousand most frequent types in the 
BLIP corpus, there are five thousand leaf nodes 
representing individual tokens, and 499 branch 
points that cluster these types into a single tre. 
We label each of these 499 branch points, and 
treat these cluster labels as features of the types 
that they dominate. For example, the singular 
noun “house” participates in 14 clusters of in-
creasing size. The syntactic features of this type 
can therefore be characterized by 14 cluster la-
bels, which overlap with varying degres with 
other tokens in the set. 
We view these cluster labels as conceptualy 
similar to traditional part-of-spech tags in that 
they are indicative of the syntactic contexts in 
which words are likely to apear.  Because 
words are clustered based on their unlexicalized 
syntactic contexts, the resulting clusters are more 
likely to reflect purely syntactic information than 
are clusters derived from lexical context, such as 
adjacent words (Brown et al., 192) or imedi-
ate head-word (Lin, 198). However, the extent 
194
to which these syntactic contexts are specified 
can vary from a more general to a more fine-
grained level than that of parts-of-spech.  As 
clusters become more fine-grained, they become 
more similar to supertags (Bangalore and Joshi, 
199). Clusters that represent more specific syn-
tactic contexts can encode information about, for 
example, subcategorization.  As these labels are 
derived empiricaly from a large corpus of syn-
tactic parse tres, they acurately represent syn-
tactic distinctions in real discourse at diferent 
granularities, in contrast to the single arbitrary 
granularity of theoreticaly derived part-of-
spech tags used in existing trebanks (Marcus et 
al., 193). 
While it is sometimes useful to view types as 
having multiple part-of-spech tags at diferent 
levels of granularity (e.g. the 14 tags for the 
token “house”), it is often useful to select a sin-
gle level of granularity to use acros al tokens. 
For example, it is useful to know which one of 
the 14 cluster labels for “house” to use if ex-
actly 10 part-of-spech distinctions are to be 
made among tokens in the set. These cluster la-
bels can be identified by slicing the tre at the 
level for which there are exactly 10 branches, 
then using the label of the first branch point in 
each branch as the label for al of its leaf-node 
types, or the leaf-node itself in the case where no 
further branching exists. Given our hierarchical 
clustering, there are five thousand diferent ways 
to slice the tre in this maner, yielding sets of 
cluster labels (and un-clustered types) that vary 
in size from 1 to 500. We identified these sets 
for use in the experiments described in the next 
sections. 
Figure 2 shows a dendrogram representation 
of the cluster tre when it is sliced to produce 
exactly 60 clusters, 19 of which are individual 
types. For the other 41 clusters, we show only 
the most frequent word in the cluster and the 
number of aditional words in the cluster.  The 
scale line in the lower left of Figure 2 indicates 
the horizontal length of a calculated similarity 
betwen clusters of 0.1. 
3 Transition-based dependency parsing 
with word clusters 
The clusters obtained with the aproach de-
scribed in section 2 provide sets of syntactic tags 
with varying levels of granularity.  Previous 
work by Ko et al. (208) and Miler et al. 
(204) sugests that diferent levels of cluster 
granularity may be useful in natural language 
 
 
 
Figure 2: A hierarchical clustering of the top 
five thousand tokens in the BLIP corpus, cut 
at 60 clusters. 
195
procesing tasks with discriminative training. 
We ad the syntactic clusters as features in a 
transition-based parser that uses a clasifier to 
decide among shift/reduce parser actions based 
on the local context of the decision. This transi-
tion-based parsing aproach has ben found to be 
eficient and acurate in dependency parsing of 
surface syntactic dependencies (Yamada and 
Matsumoto, 203; Nivre et al., 204; Hal et al., 
207) and predicate-argument parsing (Hender-
son et al., 208; Sagae and Tsuji, 208). 
Our experiments are based on an implementa-
tion of Sagae and Tsuji (208)’s algorithm for 
basic shift-reduce parsing with multiple heads, 
which we use to identify predicate-argument de-
pendencies extracted from the HPSG Trebank 
developed by Miyao et al. (204).  Using this 
data set alows for a comparison of our results 
with those obtained in previous work on data-
driven HPSG predicate-argument analysis, while 
demonstrating the use of our clustering aproach 
for cros-framework parser improvement, since 
the clusters were derived from syntactic tres in 
Pen Trebank format (as produced by the Char-
niak parser, without empty nodes, co-indexation 
or function tags), and used in the identification of 
HPSG Trebank predicate-argument 
dependencies.  Figure 3 shows a predicate-
argument dependency structure folowing the 
anotation standard of the HPSG Trebank, 
where arows point from head to modifier.  We 
note that unlike in the widely known PropBank 
(Palmer et al., 205) predicate-argument struc-
tures, argument labels start from ARG1 (not 
ARG0), and predicate-argument relationships are 
anotated for al words. One diference betwen 
in our implementation is that, instead of maxi-
mum entropy clasification used by Sagae and 
Tsuji, we perform parser action clasification 
using the averaged perceptron (Freund and 
Schapire, 199; Colins, 202), which alows for 
the inclusion of al of Sagae and Tsuji’s fea-
tures, in adition to a set of cluster-based fea-
tures, while retaining fast training times. 
We now describe the parsing aproach, start-
ing with the dependency DAG parser that we use 
as a baseline, folowed by how the syntactic clus-
ter features were aded to the baseline parser. 
3.1 Arc-standard parsing for dependency 
DAGs 
Sagae and Tsuji (208) describe two algorithms 
for dependency parsing with words that have 
multiple heads.  Each coresponds to extensions 
of Nivre (204)’s arc-standard and arc-eager al-
gorithms for dependency (tre) parsing.  In our 
experiments, we used an implementation of the 
arc-standard extension.  
Nivre’s arc-standard dependency parsing algo-
rithm uses a stack to proces the input string one 
word at a time, from left to right, using two gen-
eral types of parser action: shift (push the next 
input token onto the stack), and reduce (create a 
dependency arc betwen the top two items on the 
stack, and pop the item marked as the depend-
ent). Reduce actions are subdivided into reduce-
right and reduce-left, indicating which of the two 
items on the top of the stack is the head, and 
which is the dependent in the newly formed de-
pendency arc.  These two reduce actions can be 
further subdivided to reflect what type of de-
pendency arc is created, in the case of labeled 
dependency parsing. The extension for alowing 
multiple heads per word consists of the adition 
a new type of parser action: atach, which creates 
a dependency arc without removing anything 
from the stack. As with reduce actions, there are 
two types of atach: atach-left which creates a 
dependency arc betwen the top two items on the 
stack such that the item on top is the head, and 
 
 
 
 
 
 
 
 
 
 
 
Figure 3: Predicate-argument dependency structure folowing the HPSG Trebank standard. 
196
right-atach, which creates a dependency arc be-
twen the top two items on the stack such that 
the top item is the dependent, then pops it from 
the stack and unshifts it back into the input. Fi-
naly, this algorithm for unlabeled graphs can be 
extended to produce labeled dependencies in the 
same way as Nivre’s algorithm, by replacing the 
reduce and atach actions with sets of actions that 
perform the reduce or atach operation and also 
name the label of the arc created.  Sagae and 
Tsuji (208) provide a more detailed description 
of the algorithm, including an example that ilus-
trates the new atach actions. 
This basic algorithm is only capable of pro-
ducing labeled directed acyclic graphs where, if 
the nodes (which corespond to words) are 
placed on a left to right sequence on a horizontal 
line in the order in which the words apear in the 
input sentence, al arcs can be drawn above the 
nodes without crosing. This coresponds to the 
notion of projectivity that similarly limits the 
types of tres produced by Nivre’s algorithm. 
Just as in dependency parsing with tre struc-
tures, a way to efectively remove this limitation 
is the use of pseudo-projective transformations 
(Nivre and Nilson, 205), where arcs that cros 
have their heads moved towards the rot and 
have their labels edited to reflect this change, 
often making it reversible.  Once crosing arcs 
have ben “lifted” so that no crosing arcs re-
main, the “projectivized” structures are used to 
train a parsing model. Projective structures pro-
duced by this model can be “deprojectivized” 
through the use of the edits in the arc labels, in 
an atempt to produce structures that conform to 
the scheme in the original data. Sagae and Tsuji 
also propose a simple arc reversal transform, 
which simply reverses the direction of a depend-
ency arc (editing the arc label to note this 
change).  This transformation, which can be re-
versed trivialy, makes it posible to remove cy-
cles in dependency graphs. 
3.2 Baseline
features 
To create output graph structures for an input 
sentence, the algorithm described in section 3.1 
relies on an oracle that tels it what action to take 
at each parser state, where the state is the con-
tents of the stack, remaining words in the input, 
and the dependency arcs formed so far.  In 
gramar-based shift-reduce parsing, this oracle 
may take the form of a lok-up table derived 
from gramar rules.  In our data-driven seting, 
where the parser learns to chose actions based 
on examples of corectly parsed data, the (likely 
imperfect) substitute for the oracle is a clasifier 
that takes features that represent the parser state 
as input, and produces a matching parser action 
as output.  These features should represent as-
pects of the parser state that may be informative 
as to what the coresponding apropriate action 
is. Our baseline model uses the averaged percep-
tron with a core set of features derived from the 
folowing templates, where S(n) denotes the n-th 
item from the top of the stack (for example, S(1) 
is the item on top of the stack), and I(n) denotes 
the next n-th input token: 
1. For the items S(1) and S(2): 
a. the total number of dependents; 
b. the number of dependents to the 
right of the item; 
c. the number of dependents to the left 
of the item; 
d. the part-of-spech tag of the right-
most dependent of the item; 
e. the part-of-spech tag of the leftmost 
dependent of the item; 
f. the arc label of the rightmost de-
pendent of the item; 
g. the arc label of the leftmost depend-
ent of the item; 
2. the words in items S(1), S(2), S(3), I(1) and 
I(2); 
3. the part-of-spech tags in items S(1), S(2), 
S(3), I(1), I(2) and I(3); 
4. the part-of-spech tag of the word i medi-
aely to the right of S(2); 
5. the part-of-spech tag of the word imedi-
ately to the left of S(1); 
6. whether an arc exists betwen S(1) and S(2); 
7. whether an arc exists betwen S(1) and I(1); 
8. the direction of the arc betwen S(1) and 
S(2), if any; 
9. the label of the arc betwen S(1) and S(2), if 
any; 
10. the label of the arc betwen S(1) and I(1), if 
any; 
11. the distance, in linear sequence of words, 
betwen S(1) and S(2); 
12. the distance, in linear sequence of words, 
betwen S(1) and I(1); 
197
13. the previous parser action. 
In adition to the core set of features, we also 
use features obtained by concatenating the part-
of-spech tags in S(1), S(2) and I(1) with the fea-
tures derived from templates 1-6, and aditional 
features derived from selected concatenation of 
two or thre core features. 
3.3 Cluster-based features 
To take advantage of the clusters that reflect syn-
tactic similarity betwen words, we asign arbi-
trary unique labels to each of the hierarchical 
clusters obtained using the procedure described 
in section 2.  These cluster labels are used to 
generate aditional features that help the parser 
make its decisions base on the syntactic profile 
of words. As explained in section 2.4, each there 
may be several cluster labels (coresponding to 
clusters of diferent granularities) asociated with 
each word. To select the set of cluster labels to 
be used to generate features, we first select a de-
sired granularity for the clusters, and use the set 
of labels resulting from slicing the cluster tre at 
the apropriate level, as discused in section 2.4. 
We experimented with several levels of cluster 
granularity using development data, and folow-
ing Ko et al. (208), we also experimented with 
using two sets of cluster labels with diferent 
levels of granularity at the same time.  Given a 
specific level of granularity, the cluster-based 
features we used are: 
14. the cluster labels for the words in items S(1), 
S(2), S(3), I(1), I(2), I(3); 
15. the cluster labels for the words in the right-
most and leftmost dependents of S(1) and 
S(2); 
16. the concatenation of the cluster labels for the 
words in S(1), S(2) and I(1), and the features 
derived from feature templates 1-15. 
In experiments where we used two sets of 
cluster labels coresponding to diferent levels of 
granularity, we aded al the cluster-based fea-
tures in 14 and 15 for both sets of labels, and the 
features in 16 only for the set coresponding to 
the coarser-grained clusters. 
4 Experiments

Folowing previous experiments with Pen Tree-
bank WSJ data, or anotations derived from it, 
we used sections 02-21 of the HPSG Trebank as 
training material, section 2 for development, 
and section 23 for testing. Only the predicate-
argument dependencies were used, not the phrase 
structures or other information from the HPSG 
analyses. For al experiments described here, 
part-of-spech taging was done separately using 
a CRF tager with acuracy of 97.3% on sections 
22-24. Our evaluation is based on labeled preci-
sion and recal of predicate-argument dependen-
cies.  Although acuracy is comonly used for 
evaluation of dependency parsers, in our task the 
parser is not restricted to output a fixed number 
of dependencies. Labeled precision and recal of 
predicate-argument pairs are also the standard 
evaluation metrics for data-driven HPSG and 
CG parsers (although the predicate-argument 
pairs extracted from the HPSG Trebank and the 
CGBank are specific to their formalisms and 
not quantitatively comparable). 
We started by eliminating cycles from the de-
pendency graphs extracted from the HPSG Tree-
bank by using the arc reversal transform in the 
folowing way: for each cycle detected in the 
data, the shortest arc in the cycle was reversed 
until no cycles remained. We then aplied 
pseudo-projective transformation to create data 
that can be used to train our parser, described in 
section 3.  By detransforming the projective 
graphs generated from gold-standard dependen-
cies, we obtain labeled precision of 98.1% and 
labeled recal of 97.7%, which is below the acu-
racy expected for detransformation of syntactic 
dependency tres.  This is expected, since arc 
crosing ocurs more frequently in predicate-
argument graphs in the HPSG Trebank than in 
surface syntactic dependencies. 
We first trained a parsing model without clus-
ter-based features, using only the baseline set of 
features, which was the product of experimenta-
tion using the development set.  On the test set, 
this baseline model has labeled precision and 
recal of 8.7 and 8.2, respectively, slightly be-
low the precision and recal obtained by Sagae 
and Tsuji on the same data (89.0 precision and 
8.5 recal). 
We then used the development set to explore 
the efects of cluster sets with diferent levels of 
granularity.  The baseline model has precision 
and recal of 8.6 and 8.0 on the development 
set.  We found that by slicing the cluster tre 
relatively close to the rot, resulting in a set of 
50 to 10 distinct cluster labels (coresponding to 
relatively coarse clusters), we obtain smal (0.3 
to 0.4), but statisticaly significant (p < 0.05) 
improvements on precision and recal over the 
baseline model on the development set.  By in-
creasing the number of cluster labels (making the 
198
distinctions among members of diferent clusters 
more fine-grained) in steps of 10, we observed 
improvements in precision and recal until the 
point where there were 60 distinct cluster la-
bels. This set of 60 cluster labels produced the 
highest values of precision and recal (89.5 and 
89.0) that we obtained for the development set 
using only one set of cluster labels.  Figure 4 
shows how precision, recal and F-score on the 
development set varied with the number of clus-
ter labels used. 
Folowing Ko et al. (208), we also experi-
mented with using two sets of cluster labels with 
diferent levels of granularity.  We found that 
using the set of 60 labels and an aditional set 
with fewer than 60 labels did not improve or 
hurt precision and recal.  Finer grained clusters 
with more than 1,00 labels (combined with the 
set of 60 labels) improved results further.  The 
highest precision and recal figures of 90.1 and 
89.6 were obtained with the sets of 60 and 
1,40 labels. 
We parsed the test set using the best configu-
ration of cluster-based features as determined 
using the development set (the sets with 60 and 
1,40 cluster labels) and obtained 90.2 precision, 
89.8 recal and 90.0 f-score, a 13.8% reduction in 
eror over a strong baseline. Table 1 sumarizes 
our results on the test set.  For comparison, we 
also shows results published by Sagae and Tsuji 
(208), to our knowledge the highest f-score re-
ported for this test set, and Miyao and Tsuji 
(205), who first reported results on this data set. 
4.1 Surface
dependency parsing with clus-
ter-based features 
The parser used in our experiments with HPSG 
Trebank predicate-argument structures can as-
sign more than one head for a single word, but 
when the parser is trained using only dependency 
tres, it behaves in exactly the same way as a 
parser based on Nivre’s arc-standard algorithm, 
since it never ses examples of atach actions 
during training. To se whether our clusters can 
improve surface dependency parsing, and to al-
low for comparison of our results to a larger 
body of research on surface dependency parsing, 
we used dependency tres extracted from the 
Pen Trebank using the Yamada and Matsu-
moto (203) version of the Pen Trebank head-
percolation rules to train parsing models that 
produce dependency tres.  However, no tuning 
of the features or metaparameters was per-
formed; the parser was trained as-is on depend-
ency tres. 
We used the standard train, development and 
test sets splits to train two models, as in our ex-
periments with predicate-argument dependen-
cies: a baseline that uses no cluster information, 
and a model that uses two sets of clusters that 
were found to improve results in the develop-
ment set. The unlabeled acuracy of our baseline 
model on the test set is 89.96%, which is consid-
erably lower than the best curent results. Ko et 
al. (208) report 90.84% for a first-order edge-
factored model, and 92.02% for a second-order 
model (and as high as 93.16% with a second-
order model enriched with cluster features de-
rived from plain text).  Using two sets of clus-
ters, one with 60 and one with 1,20 labels, ac-
curacy improves by 1.32%, to reach 91.28% (a 
13.15% reduction in eror compared to our base-
line). While stil below the level of the strongest 
results for this dataset, it is interesting to se that 
 Precision Recal F-score 
Baseline 8.7 8.2 8.4 
Clusters 90.2 89.8 90.0 
S & T 89.9 8.5 8.7 
Miyao et al. 85.0 84.3 84.6 
 
Table 1: Results obtained on the test set us-
ing our baseline model and our best cluster-
based features. The results in the botom two 
rows are from Sagae and Tsuji (208) and 
Miyao and Tsuji (205).  
Figure 4: Efect of cluster granularity on 
labeled the precision and recal of predicate-
argument pairs in the development set. The 
improvement in precision and recal betwen 
the baseline (zero cluster labels, where no 
cluster information is aded) and 60 cluster 
labels is statisticaly significant (p < 0.005). 
 
199
the improvement in acuracy over the baseline 
observed for surface dependency tres is similar 
to the improvement observed for predicate-
argument dependency graphs. 
5 Related
work 
Many aspects of this research were inspired by 
the recent work of Ko et al. (208), who re-
ported impresive results on improving depend-
ency parsing acuracy using a second order 
edge-factored model and word clusters derived 
from plain text using the Brown et al. (192) al-
gorithm. Our clustering aproach is significantly 
diferent, focusing on the use of parsed data to 
produce strictly syntactic clusters.  It is posible 
that using both types of clusters may be benefi-
cial. 
McClosky et al. (206) used a large corpus of 
parsed text to obtain improved parsing results 
through self-training.  A key diference in our 
general framework is that it alows for a parser 
with one type of syntactic representation to im-
prove the acuracy of a diferent parser with a 
diferent type of formalism.  In this regard, our 
work is related to that of Sagae et al. (207), who 
used a stacking-like framework to alow a sur-
face dependency parser to improve an HPSG 
parser.  In that work, however, as in other work 
that combines diferent parsers through stacking 
(Martins et al., 208; Nivre and McDonald, 
208) or voting (Henderson and Bril, 199), 
multiple parsers ned to proces new text at run-
time.  In our aproach for leveraging diverse 
parsers, one of the parsers is used only to create a 
parsed corpus from which we extract clusters of 
words that have similar syntactic behaviors, and 
only one parser is neded at run-time. 
6 Conclusion

We have presented a novel aproach for deriving 
word clusters based on syntactic similarity, and 
shown how these word clusters can be aplied in 
a transition-based dependency parser. 
Our experiments focused on predicate-
argument structures extracted from the HPSG 
Trebank, which demonstrates that the syntactic 
clusters are efective in leveraging cros-
framework parser representations to improve 
parsing acuracy. However, we expect that simi-
lar acuracy improvements can be obtained in 
parsing using other frameworks and formalisms, 
and posibly in other natural language procesing 
tasks. 
Acknowledgments 
The project or efort described here has ben 
sponsored by the U.S. Army Research, Devel-
opment, and Enginering Comand (RDE-
COM). Statements and opinions expresed do 
not necesarily reflect the position or the policy 
of the United States Government, and no oficial 
endorsement should be infered. 
References  
Srinivas Bangalore and Aravind K. Joshi. 199. Su-
pertaging: an aproach to almost parsing. Compu-
tational Linguistics 25, 2 (Jun. 199), 237-265. 
Peter F. Brown, Vincent J. Dela Pietra, Peter V. 
deSouza, Jenifer C. Lai, and Robert L. Mercer. 
192. Clas-Based n-gram Models of Natural Lan-
guage. Computational Linguistics, 18(4):467–479. 
Eugene Charniak. 200. A maximum-entropy-
inspired parser. In Procedings of the First Met-
ing of the North American Chapter of the Asocia-
tion for Computational Linguistics (NACL), pages 
132–139. 
Charniak, E., Blaheta, D., Ge, N., Hal, K., Hale, J., 
and Johnson, M. (200) BLIP 1987-89 WSJ Cor-
pus Release 1. Philadelphia, PA: Linguistic Data 
Consortium. 
Michael Colins. 199. Head-Driven Statistical Mod-
els for Natural Language Parsing. Ph.D. thesis, 
University of Pensylvania. 
Michael Colins. 202. Discriminative Training Me-
thods for Hiden Markov Models: Theory and 
Experiments with Perceptron Algorithms. In Pro-
ceedings of EMNLP, pages 1–8. 
Yoav Freund and Robert E. Schapire. 199. Large 
Margin Clasification Using the Perceptron Algo-
rithm. Machine Learning, 37(3):27–296. 
Daniel Gildea and Daniel Jurafsky. 202. Automatic 
Labeling of Semantic Roles. Computational Lin-
guistics 28(3): 245-288. 
Andrew Gordon and Reid Swanson. 207. Generaliz-
ing semantic role anotations acros syntacticaly 
similar verbs. Procedings of the 207 meting of 
the Asociation for Computational Linguistics 
(ACL-07), Prague, Czech Republic, June 23-30, 
2007. 
Johan Hal, Jens Nilson, Joakim Nivre, Gulsen Ery-
igit, Beata Megyesi, Matias Nilson, and Markus 
Saers. 207. Single malt or blended? A study in 
multilingual parser optimization. In Procedings of 
EMNLP-CoNL. 
James Henderson, Paola Merlo, G. Musilo, and Ivan 
Titov. 208. A latent variable model of synchro-
nous parsing for syntactic and semantic dependen-
200
cies. In Procedings of the Shared Task of the Con-
ference on Computational Natural Language 
Learning (CoNL), pages 178-182. Manchester, 
UK. 
John Henderson and Eric Bril. 199. Exploiting di-
versity in natural language procesing: combining 
parsers. In Procedings of the Fourth Conference 
on Empirical Methods in Natural Language Proc-
esing (EMNLP). 
Tery Ko, Xavier Careras and Michael Colins. 
208. Simple semi-supervised dependency parsing. 
In Procedings of the 46th Anual Meting of the 
Asociation for Computational Linguistics: Human 
Language Technologies (ACL-08:HLT), pages 
595-603. 
Dekang Lin. 198. Automatic retrieval and clustering 
of similar words. In Procedings of the 17th inter-
national Conference on Computational Linguistics 
Volume 2. Montreal, Quebec, Canada. 
Mitchel P. Marcus, Mary A. Marcinkiewicz, Beatrice 
Santorini. 193. Building a large anotated corpus 
of English: The Pen Trebank, Computational 
Linguistics, 19(2), June 193. 
André F. T. Martins, Dipanjan Das, Noah A. Smith, 
and Eric P. Xing. 208. Stacking Dependency 
Parsers. In Procedings of the Conference on Em-
pirical Methods in Natural Language Procesing, 
Waikiki, HI. 
David McClosky, Eugene Charniak, and Mark John-
son. 206. Efective Self-Training for Parsing. In 
Procedings of HLT-NACL, pages 152–159. 
Ryan McDonald, Koby Cramer, and Fernando 
Pereira. 2005. Online large-margin training of de-
pendency parsers. In Procedings of ACL, pages 
91–98. 
Scot Miler, Jethran Guines and Alex Zamanian. 
204. Name Taging withWord Clusters and Dis-
criminative Training. In Procedings of HLT-
NACL, pages 37–342. 
Miyao, Yusuke, Takashi Ninomiya, and Jun’ichi Tsu-
ji. 204. Corpus-oriented gramar development 
for acquiring a Head-driven Phrase Structure 
Gramar from the Pen Trebank. In Procedings 
of the International Joint Conference on Natural 
Language Procesing (IJCNLP).  
Miyao Yusuke and Jun'ichi Tsuji. 205. Probabilistic 
disambiguation models for wide-coverage HPSG 
parsing. In Procedings of the 43rd Anual Met-
ing on Asociation for Computational Linguistics. 
Joakim Nivre.204. Incrementality in Deterministic 
Dependency Parsing. In Incremental Parsing: 
Bringing Enginering and Cognition Together 
(Workshop at ACL-2004). 
Joakim Nivre, Johan Hal, and Jens Nilson. 204. 
Memory-based dependency parsing. In Proced-
ings of CoNL, pages 49–56. 
Joakim Nivre. and Jens Nilson. 205. Pseudo-
Projective Dependency Parsing. In Procedings of 
the 43rd Anual Meting of the Asociation for 
Computational Linguistics (ACL), p. 9-106. 
Joakim Nivre, Johan Hal, Sandra Kubler, Ryan 
McDonald, Jens Nilson, Sebastian Riedel, and 
Deniz Yuret. 207. The CoNL 207 shared task 
on dependency parsing. In Procedings of 
EMNLP-CoNL, pages 915-932. 
Nivre, J. and McDonald, R. (208) Integrating Graph-
Based and Transition-Based Dependency Parsers. 
In Procedings of the 46th Anual Meting of the 
Asociation for Computational Linguistics: Human 
Language Technologies (ACL-08: HLT), 950-958. 
Martha Palmer, Dan Gildea and Paul Kingsbury. 
2005. The Proposition Bank: A Corpus Anotated 
with Semantic Roles. Computational Linguistics, 
31:1. 
Kenji Sagae and Alon Lavie. 206. Parser combina-
tion by reparsing. In Procedings of NACL: Short 
Papers, pages 129–132. 
Kenji Sagae, Yusuke Miyao Jun’ichi and Tsuji. 207. 
HPSG Parsing with shalow dependency con-
straints. In Procedings of the 4th Meting of the 
Asociation for Computational Linguistics. 
Kenji Sagae and Jun’ichi Tsuji. 208. Shift-reduce 
dependency DAG parsing. In Procedings of the 
International Conference on Computational Lin-
guistics (COLING 208). 
Hiroyasu Yamada and Y. Matsumoto. 203. Statisti-
cal Dependency Analysis With Suport Vector 
Machines. In Procedings of the Eighth Interna-
tional Workshop on Parsing Technologies (IWPT), 
pages 195–206. 
 
201

