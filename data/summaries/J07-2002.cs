Widdows, Dominic. 2003. Unsupervised
N03-1036
tion (Jones and Martin 1997), automatic thesaurus extraction (Grefenstette 1994; Lin
A97-1025
Lin, Dekang and Patrick Pantel. 2001.
H01-1046
similarity is concerned, our dependency model employs Lin’s (1998a) measure and
P98-2127
nation (Lin 1998a; Schütze 1998), automatic thesaurus construction (Grefenstette 1994;
P98-2127
Syntax-based semantic space models (Grefenstette 1994; Lin 1998a) go beyond mere
P98-2127
repeated all experiments for the word-based model with Lin’s (1998a) distance measure, obtaining
P98-2127
McCarthy et al. (2004) use their ranking model to automatically infer the first senses
P04-1036
or objects. A similar result is reported in Henderson et al. (2002), who find that using
C02-1091
Like McCarthy et al. (2004), we also assessed the word sense disambiguation potential
P04-1036
and Lin (1998a).
P98-2127
A different mapping is used in Grefenstette (1994) and Lin (1998a), who consider only
P98-2127
sis (Grefenstette 1994; Lee 1999; Curran and Moens 2002) and full-blown parsing (Lin
P02-1030 P99-1004
model class (Grefenstette 1994; Lin 1998a; Lin and Pantel 2001; Curran and Moens 2002).
H01-1046 P02-1030 P98-2127
lines of Kanejiya, Kumar, and Prasad’s (2003) cognitive modeling work. They use SVD
W03-0208
McCarthy et al.’s (2004) approach crucially relies on the quality of the set of neigh-
P04-1036
Curran and Moens 2002) or full parsing (Lin 1998a; Curran and Moens 2002; Curran
P02-1030 P98-2127
the two studies. Recall that we obtain dependency relations using MINIPAR (Lin 1998b), whereas
P98-2127
stette 1994; Lin 1998a) to paraphrase identification (Lin and Pantel 2001) and collocation
H01-1046 P98-2127
version 0.5 (Lin 1998b, 2001), a wide-coverage dependency parser. MINIPAR employs a
H01-1046 P98-2127
(Grefenstette 1994; Curran and Moens 2002) or features (Lin 1998a).
P02-1030 P98-2127
Dunning, Ted. 1993. Accurate methods for
J93-1003
Leibler divergence, skew divergence, and Lin’s (1998a) measure.
P98-2127
Lin, Dekang. 1999. Automatic identification
P99-1041
discovery (Lin 1999; Bannard, Baldwin, and Lascarides 2003; McCarthy, Keller, and
P99-1041 W03-1809
Lin (1998a) constructs a semantic space similar to Grefenstette (1994) except that the
P98-2127
The dependency-based models proposed by Grefenstette (1994) and Lin (1998a) con-
P98-2127
senses from raw text. We obtained results similar to McCarthy et al. (2004) on the sense
P04-1036
use it exclusively in all subsequent work (McCarthy et al. 2004; Koeling, McCarthy, and
P04-1036
dimensions (e.g., 500 and 1,000) generally obtained worse performance. Lin’s (1998a)
P98-2127
elements, and Lin’s (1998a) similarity measure. This model will be used for our subse-
P98-2127
We replicated McCarthy et al.’s (2004) procedure for evaluating the acquired pre-
P04-1036
due to differences in the basis mapping function. Because McCarthy et al. (2004) use all
P04-1036
and can be obtained via shallow syntactic processing (Grefenstette 1994; Lee 1999;
P99-1004
thesauri (Grefenstette 1994; Lin 1998a; Curran and Moens 2002) or used in applications
P02-1030 P98-2127
We replicated McCarthy et al.’s (2004) study using our optimal dependency-based
P04-1036
answering (Lin and Pantel 2001).
H01-1046
segmentation (Choi, Wiemer-Hastings, and Moore 2001), contextual spelling correc-
W01-0514
1998), and density (Agirre and Rigau 1996). A number of hybrid approaches have also
C96-1005
identifying labeled dependencies (Lin 1998b).
P98-2127
new languages, domains, and sense inventories. McCarthy et al. (2004) show that the
P04-1036
Lee, Lillian. 1999. Measures of distributional
P99-1004
as word sense discrimination (Schütze 1998) and ranking (McCarthy et al. 2004), text
P04-1036
ging (Kanejiya, Kumar, and Prasad 2003; Widdows 2003) to shallow syntactic analy-
N03-1036 W03-0208
2003) or words with a syntactic relation such as subject or object (Lin 1998a). Usually,
P98-2127
Lin, Dekang. 1998a. Automatic retrieval
P98-2127
1998a) or a fixed subset (Lee 1999), but there is no qualitative distinction between
P99-1004
different set of nouns from McCarthy et al. (2004); this is due to the use of a different
P04-1036
line, the baseline word-based model, and McCarthy et al.’s (2004) state of the art model.
P04-1036
can be used to compute the similarity S between two target words (see Lee [1999] for an
P99-1004
spaces into the modeling paradigm proposed by McCarthy et al. (2004). In all cases, we
P04-1036
Lin, Dekang. 1998b. Dependency-based
P98-2127
Curran and Moens 2002), automatic clustering, lexicon acquisition, and in general
P02-1030
as the relation–word pairs used by McCarthy et al. (2004). We would also like to observe
P04-1036
} the set of senses for w. McCarthy et al.’s (2004) model assigns
P04-1036
Agirre, Eneko and German Rigau. 1996.
C96-1005
and Brew 2004), intelligent tutoring (Kanejiya, Kumar, and Prasad 2003), and coherence
W03-0208
prevalence score. McCarthy et al. (2004) undertook a thorough comparison and ob-
P04-1036
different relations. Even in cases where many relations are used (Lin 1998a; Lin and
P98-2127
Lin, Dekang. 2001. LaTaT: Language and text
H01-1046
Grefenstette’s study with a more sophisticated parser (Curran and Moens 2002) re-
P02-1030
(Dunning 1993).
J93-1003
Brew 2004) and NLP (McCarthy et al. 2004; Weeds 2003; Widdows 2003).
N03-1036 P04-1036 W03-1810
Curran, James R. and Marc Moens. 2002.
P02-1030
both the dependency-based model and McCarthy et al. (2004) significantly outperform
P04-1036
