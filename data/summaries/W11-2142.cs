F. Casacuberta and E. Vidal. 2004. Machine translation
J04-2004
provided in the Moses toolkit (P. Koehn et al., 2007),
P07-2045
P. Koehn and K. Knight. 2003. Empirical Methods
E03-1076
described by Matusov et al. (2006; 2008). This ap-
E06-1005
C. Tillmann. 2004. A unigram orientation model for sta-
N04-4026
J. Senellart L. Dugast and P. Koehn. 2007. Statistical
P07-2045 W07-0732
splitting (Koehn and Knight, 2003). In comparison
E03-1076
F.J. Och. 2003. Minimum Error Rate Training for Statis-
J03-1002 P03-1021
F.J. Och and H. Ney. 2003. A Systematic Comparison of
J03-1002 P03-1021
R. Zens and H. Ney. 2006. N-gram Posterior Proba-
W06-3110
pairs (Casacuberta and Vidal, 2004). Training this
J04-2004
applied: n-gram posteriors (Zens and Ney, 2006),
W06-3110
D. Vilar, S. Stein, M. Huck, and H. Ney. 2010. Jane:
W10-1738
with standard MERT (Och, 2003) on 100-best lists.
J03-1002 P03-1021
J. Niehues and M. Kolss. 2009. A POS-Based Model for
W09-0435
J. Wuebker, A. Mauser, and H. Ney. 2010. Training
P10-1049
T. Ward K. Papineni, S. Roukos and W. Zhu. 2002. Bleu:
P02-1040
ing models (Tillmann, 2004) aiming at predicting
N04-4026
E. Matusov, N. Ueffing, and H. Ney. 2006. Computing
E06-1005
Chiang, 2007). The model weights are optimized
J07-2003
per, the open source Jane toolkit (Vilar et al., 2010)
W10-1738
duced by Chiang (2007) with some state-of-the-art
J07-2003
better BLEU scores (K. Papineni and Zhu, 2002),
P02-1040
D. Chiang. 2007. Hierarchical Phrase-Based Transla-
J07-2003
L. Huang and D. Chiang. 2007. Forest Rescoring: Faster
J07-2003 P07-1019
model as described in Wuebker et al. (2010). A
P10-1049
