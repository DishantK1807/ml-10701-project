kmerican Journal of Computational Linguir tics Microfiche 3 Jaime R.
Carbonell andLAl'lan M.
Collins Bolt Besanek and Newman Inc.
Cambridge, Massachusetts 01974 by the Association for Computations 1 Linguistics ABSTRACT This papar discu~see human semantic knowledge and proceesing in terms of the SCHOLAR system.
In one major section we discuss the imprecision, the incompleteness, the open-endedness, and the uncertainty of psopl,eqs knowledge.
In the other major section we diecuss strategies people use to make different types of deductive, negative, and functional inferences, and the way uncertainties combine in these inferences.
Irapreeision can occur either in memory or in camunication.
SCHOLAR can have precf ae values or fuzzy values stored, and its procedures can, to eome extent, deal with fuzzy questions when precise valtues are stored, and with precise queltions, when fuzzy values are stored.
Embedding allows info tion to be specified in the data base to any level of detail or preci sfon.
But SCHOLAR only camunicatea the nwst important info tion on any topic (as rneasured by importmce tags), unless more info tion is requested.
1.t should also be possible by using importance tags to adjust what +jon SCHOLAR communicates, in accord with the sophistication and, interests of the listener.
Inference atrategiee that are appropriate when the complete set of object attributes, or values, is known (i.em, in a closed world) do not apply when knowledge is incomplete e, in an open wrld) . There are a variety of uncert~in inf ercnces that people use to circumvent the hales in their knowledge, which are being progr ed in SCHOLAR.
There is a set of transitive relations -superordinate, superpart, s larity, praimity, subordinate, and subpart relations -that people frequently use to make deductive inferences, Currently SCHO only handles superordinate inferences (em g ., the Llanos has a rainy season because it is a savanna) and superpart inferences (e .g,, the language in Rio is Portuguese because Rio is part of Brazil).
~eductive inferences can be more or leas certain (similarity inferences are like suptordinate inferences.
but leas certain) and can have restrictions on their use (only certain attributes transfer an superpart).
~bn knowledge is incomplete, it is not safe to assume that something is not true just because it is not stored.
Thus an inference is necessary to decide when to say 'Now and when to say 'I donBt know,@ There is a eamp1Pcated set sf strategies in SCHOLAR to find vatious kinds of contradictions that people case to say *NO, " If a contradiction cannot be found, another nega8ive inference, called the Wlack-aF-knawledgea inference, f s tried* When enough is known abut an abjech it is possible to conclude that someaing is not true ut mat object ow the ground8 that if it were true, it muld be stared, another class of wcertain inferences depends an ill-def ined knovledge of functional datenainants, e ..g., that climate depends OR latitude and altitude.
D%f ferent ways that pople use fmctional knowledge irnm1ve fmctianal ealeulatisms (a.g,, if a place has a particular latitude, it probably has a particular elihate), functional analogies (e,g,, if a place is like another place in latitude and altitude, it probably has the sme chimte), and ts answer Why questions (egg,, a place hg a particular elfmte because of its latitude and altitude), Different inf erenees can esIwBine in different ways, Somtims one strategy may call another strategy to hind an anewer, men different inferences independently reach the sme or differmt con-elusions, aey coItnbiwe to increase or dsreass certainty, The pming sf uncertain Bnfermces is wecessqw to make cawutars as clever and aa fuzzy-thinking as pmple.
TABLE OF CONTENTS 2.
The Scholar System as an Environment to Study Natural ~~ma~~i~~.~~.~.~..~~~~~~~~~~~~~~~.~~~~~~~~~.~..~.~~.~.~~~ 6 3.1 Imprecision or Fuzziness..oa.
..ooOOoaI)DoOo~OoOoOOOoO~~ 3.2 Incompleteness, Embedding, and R~levancy............ 12 3-3 The Reference Problem and Context .................... 13 3,4 Closed versus Open Worlds oOo~o~o~o~~O~DoDeOoo~d~OODo 15 3.5 The True-False ~ichotorny and ~uantification ..,...... 17 4, Natural Infeuen@es.,..o...,P0DoomoeOOo0OO~BOoOOOoo.~.o.o.0 18 4.1 Deductive ~~f~~e~~e~..oOQ.oO.O~OoOO~~OO~oO~OOOOOO.Oo~~ 4.2 Negative Infer~~~es..o..o.ooOoOoDooOOoOoOooOooaoO~o.~~ 4-4 Inductive Inferenceso0.0.00D~000DoD.0..o~a~OOOoOOD~028 4.5 Combining Inferences and Accumulating Uncertainty ...
29 %, Introduction In this paper we will discuss how to eepresent and process infomatioil in a computer in ways that are natural to people.
This does not mean doing away completely with representations and procedures which computers have traditionally used, but adding new representations and procedures which they have not used.
People often store and communicate imprecise, incomplete, and unquantified info tion; they aften assert truth or falsity in relative terms; and they seldom seem to use rigorous logic in their inferential processes.
Because of these conditions, people s,eem to have an almost infinite info tion processing capacity, with inference making and problem solving abilities more refined and far more flexible than any existing computer program.
Now man we study aese hman eapabiLities in order to make our machines show similar perfbnnance?
A combination of approaches is perhaps best.
Observation of people ' s behavior, introspection, some experimentation, protocol analysf s, and synthesis of computer programs can all be vhluable technil~ues.
A 6 recent paper (CalZins, mrnock and Passafime ) discusses a technique for combining protocol analysis with program synthesis as applied to tutorial dialogues.
The synthesis directs what to analyze, and the strategies observed in the analysis are evaluated by synthesis, in a kind of feedback Poop We have been using the SCHOLAR system in this way as a vehicle for experimentation with natural semnties.
Before we discuss some of the major problems in natural semantics, we will briefly describe the SCHOLAR system, since it ie the enviroment for our research.
A word of caution though: we are only trying to develop some insights, without attempting to be exhaustive.
More questions wil.1 be raised than qnewers provided.
There are many observable things people do that we do not how how to simulate, Semantics .1x1 this section we will discuss, very briefly, same pertinent aspects of SCBO a mixed-initiative instructional system.
More debiled dilseussions are pmvided in CarboneIlP 3p and Wamock 14 and Collins, . Several data bases currently exist: me is &out the geography of South America, anoeher about the ARPA network, and a third about a text-editing system called NLS.
SCHOLAR s knowledge about any subject matter is in the form of a static semantic network of facts, concepts, and procedures.
This 12 ia a modified and extended nemork a la Quillin and has a rich internal structure with a well-deQEined syntax.
~ialogue with SCHOLAR take8 place $XI a aeubaet of ~nglish that is limited mainly by SCHOLAR% currently primitive syntactic capabi lities.
In tutorial fashion, the system uses its semantic network to generate the material it presents, the questions it asks, and the corrections it makes.
At any time SCHOLAR accepts questions and r ests from the student, and generates responses based on its semantic network, making calculations and f nferences of different types that it has been progaamed to handle.
The dialogue is unanticipated, and is dependent on the student's rsspanses, questions, and requests.
Figure 1 presents a sample protocol of an interaction with SCHOLAR: the person types after the asterisk and returns control to the system with a second asterisk, Figure 2 shows some excerpts of SCHOLAR'S semantic network.
Properties, none of which are obligatory, can have as values (single words usually English words defined elsewhere in the network), n ers, different types of lirts, and other properties.
Attributes are usually English words, but there is a set of special attributes for i rtant relations, like SUPERC (for superconcept or superardinate, ee.g., Lima is a city and a capf tal), SUPERP (for superpart, e.g., Lima ia a part of Peru and South ~merica), SUPERA (for superattribute, e,g,, fertile refers to soil and soil refers to topagraphy), APPLIEDFO (color applies to things, *PROBABLY SPANISH* "TELL ME SOFIETHING ABOUT PERU* PERU IS A COUNTRY, IT IS IN WESTERN SOUTH RSCCA w IT IS ON THE COAST OF THE PACIFIC, THE ITRL IS L a THE MOUNTAINS ARE W OUS . THE REGIONS ARE THE ZON mNGLE, THE ATaC DESERT, AND THE ANDES, NOW YOU CAN EITHER ANSmR MY QUESTION OR ASK A NEW ONE, *THE A OF ARGENTINA IS PIP(90,000 SQUARE MILES*.
APPROX TELY TRUE, BUT A MOW EXACT VALUE I$ ~,200,000, THE EASTERN BORDERING COUNTRY OF PEhU IS ---NO.
THE SOUTHERN BORDEMNG COUNTRY OF PERU SfS CHILE, THE EASTERN BORDERING COUNTRY OF PERU IS BRAZIL, 6 T 1s THE MOST mPOR'PCWT DIFFE CE BE EM PERU AND P THE PRf Y DIFFEmNCE 4115': PERU IS IN WESTERN SOUTH RICA.
BUT PAmGWAY IS IN CENTRAL SOUTH RICA, Figure 11, A Sample Dialogue mtwean S&-IOUR and a Student.
(Student lnputs are enclosed by asterisks).
PTAL SUPERC (r 0) CITY PLACE (X 01 OP (I: 0) GOVElRNmNT ZED/m (T 4) COUNTRY STATE PLES (I 2) ($EOR BUEN MONTEVIDEO l3RAS ILIA GEORGECS(FOW BW(P"rA QUITO SAPaTfAGO ASUNCTON U/PAZ WASHINGTON) FERTILE CONTRA (I 0) BA SUPERA (I 0) SOfE PEW SUPERC (I 0) CO SUPEX (I 1 B) LOCATION (I 0) IN (I 0) ~OUTN/MERICA (I.
O) STE EN ON (I 0) COAST (I 0) OF (I 0) PACIFIC IATITWDE (I 4) CE (I 0) -18 0 LONG1 E (1 5) GE (1 0) -82 -68 ~RDERING/CO~TRIES (I: 1 ) NORT~~ (I 1) (SL COLOMBIA ECU EASTERN (I 11 IBWiZfL SOVTHEASTEHaM (1 1) BOLIVIA SOUTHERN (1 2) CHILE e-nTaE (I 1) EX~ CITIES (1 2) PR1PaCI:PAE (I 0) (,$L LIMA ClhEEWO AREQUIPA TRUJILLO CHICIAYO CUZCO) LIMA SUPEW (I 0) CfW CAPITAL SUPERC (I 1 B) PERU SOUTH/ LOCATION (I 0) IN (I 0) PERU Figure 2, Four Partial Entries from SCHOLAR'S Georgraphy Da'ta Base, and capit.1 to countrian and states), CONTRA (for contradihflon, e .go barren contradicts fertile and democracy contradicts dictatorship), 8 case-structure attributes like agent and instrument (see Fillmbre ), and various oaerts, The entry for location under Peru in Figure.
2 illustrates an important aspect of SCWOIARBs semantic netm9k called Under the attribute location there is the value South plus several s&attributes ng which is hrdeefng countries.
But mder bordering countries there are s-attributes like Sorthern and eastern, some af which have several values, E&eddfng describes the ability $a go dom as deep as nseessaq to describe a property in more or less detail.
In the data base there are ale0 tags, such as the (X 0) after Pocation and the (1 1) after brdering csmtries, meae tags are eal led or tags (1-tags), and they vary from 0 to 6, The lower the tag, the mre bprtat the piece sf in fa tion is, The tags add up as you ga dam through Pmer e&edded Bevels.
One of the ways SCHO uses 1-ags is to decide what +s relevant to say at any given ti-, In the rest of this paper, we will di~cuss how we are using SCHOLkR to cope: wi* gome of the problems in natural semantics.
However, Lhero are still many nathral-aewantics problems we have not touched, 3, In this section we discuss some aspects of natural semantic infomation and its relation to artf Ficial intelligence.
3,f Imprecise language is an essential characteristic of human PO comnrun&cation.
As Lyons says, *Far from being a defect as some philosophers have suggested, referential 'impreciseness' ...
makes language a more efficient means of communication.
" Talking ut a tall person or a blue-green object does not require precise specification of height or spectral characteristics.
The imprecision may occur either in communication or storage.
If we say that a colleague receives a large salary, we may or may not how the figure.
SCHOLAR currently stores areas and populations in n form, but it can respond to the fuzzy question "Is Montevideo large"? with a pertinent answer like: 'It is not one of the largest cities in South America, but it is the largest city in Uruguay, " Here SCWOLaR has found tm supeqarts, South meriea and Uruguay* and then campred Mntevidw to other cities in each with qespect to population.
However, it is mrce co n for people to @tore values that are irarprecise or flfuzzy', what 2adeb19 calls 'linguistic' variables.
This is the case with values like large', 'red', 'ho-t', 'richg, etc.
It seems to us that one must be able to store either precise values or fuzzy values interchangeably.
(In fact, SCHO has fuzzy values as well as preoiae values atoted, e.g., that the Brazilian Highlands has a large population).
Furthermore, the procedures that act upon therre values must be flexible enough to deal with either.
32 Imprecise statements $re of ten motivated by incomplete specification.
Since all specifications can be refined, they are essentially incomplete.
We store what is necessary, and if we store more, we only comunieate what is pertinent.
SCHOLAR does this through its I-tags.
If it is asked 'Tell me about Perm," it only gims a few salient facts.
Further specification can be added by refining existing values.
lor axmple, instead of 'blue we can have 'Navy bluev, OB.
'quite dark MaPry blue",tee.
Furbher specification can also be added by giving plow properties with attributes somenhat ortkogonal to previous ones.
An example of this is 'tall man' veraua 'tall, heav mn wearing glasses0.
Properties can be specified to any level of detail by embedding, an inherent quality of SCHO -type semantic networks.
Somawhat related to incompleteness and relevancy is the eference problem (see Olsonl') Referring to a colleague, we nay 'define8 him as the father of Jack and Jill, or the author of that paper on self-referential otatments, or tihe tall thin fellufth glasses.
We decide on some specification de.pending on the :ontext, including our assumptions about the person we are talking to.
People usually specify only to the degree that is needed.
In this sense, every partial specification is a 'definition'.
The problem of context pemades matualb senam8;%es.
Definitions and specifications, anaphoric references, what and how to answer, all depend on context.
Furthe re, there usually eo-exist a range of contexts from overall context to short-tern running contexts.
For example.
at a given time, SCHOLAR may have the contexts South America, Argentina and Buenos Airesr each with some dwamically adjustable If fe.
What is releva*.
at any given the depends on this contextual hierarchy.
A start toward making references specific to the listener is possible in a SCHOLAR-type system by using I-tags (see Collins, Warnock, and ~assaf iumeb) . The likelihood that another pereon will know about any concept ie raugkily pmwrtional to the importance of the concept, as measured by the 1-tags, with respect to the overall context.
Therefore, it is possible to sstfmate .the sophistication of a permn based on the level of tags of the concepts he mentions in his conversation.
This estimate then can influence the description one uses in referring to Some concept.
For example, to an unsophisticated listener one might refer to the "capital of Argentina" rather than 'Buenos Aires, a because the I-tags for the concepts *capitalw and "Argentinaw are lamr than *ose for 'Buenos AiresFw as masured from a context such a8 geographyc In the fugure we want to have adjustable contexts in SCROLM, eo mat it can talk about ~e ARPA network, say, "from a communications point of viewm to one person and *from a progr fng point a% viewm to another person.
What this entails is a temporary alteration of the relative values of I-tags throughout the saantic nebork, Thwe concepts that are referred to under $Pae concept wcommicationU (such as message capacity bit-rate, ee . ) should be temporarily increased in importance wherever they occur dab base, for the person interested in communication.
A corresponding chmge must be made for the person interested in ing OP any aaer concept or set of concepts.
This kind of sensitivity to tihe interests and background of the person, and the kind of sensitivity (described above) to the saphistication sf Ule person may be the two major alments in the way people adapt what they say to the listener, 3.4 In some realm of discourse such as an airline resrsmatians 17 15 .ystam (Hoods ), a blocks world (Winograd F, or a lunar rocks catalogue (Woods, Kaplan, and ~ash-~e~erl~), there is a closed aet of objects, attributes, and rmluel~ to deal with.
However, .ip most real world domains such as those faced by SIR (~a~hael"), 2 TLC (quillian'2) at SCHOLAR (Carbonell ), there are open set8 of objects, attributes, and values.
It turns out that the procedures and even the rulae of inferdnce that can be applied are different in closed and open worlds, The distinction between closed and open assts is one of exhaustiveness and not one of size, For ex le,, the set of states (e.g., Iowa) . which is a cYbeed set for most people, is probably larger than the set of cattle breeds (eager Aolatein), nfrich is an o set.
However, &pa sets tmd to be lkrger in% general than closed sets.
The distinction is important in a variety of ways.
For example, if there are no basaleic rocks stored 191 a ehasad ata base, then it makes sense to aay *Nom to the quelrtian %ere any basaltic rocks brought back?* Bag if no oolcanoea are stared for the U.
S,, it does not follm that the aur to the question "Are there any mlcandee in the U.
S.7. A more appropriate answer is *I dont.t know'.
Putthe re, it makes 8en.e to ask *at the smallest block in a scene is or the rock wia least alminm c~ncmtRatfsn, But it makes no sense to ask what is the malleat city in Brazil or the leaat f in the U.
S, It uould be an appmpriate strategy for deciding how many flights from Boston to Chitago are nonstop, to consider each flight and count how mny make O stops.
But it would not be an appropriate strategy to consider each person smred in a 1hPted hta base (such as h s bve), in orden to answer the question *How many people in the U.
S. are over 30 years old"?
Within open worlds there are cbsed sets, so that a question like 'How many states are on the Pacific'? makes sense whereae 'How many cities are on the Pacific"? does not.
SCAOLAR dais with thie by distinguishing exhaustive sets from n~n-exhaustive sets.
We will discuss in Section 4 how SdlHOmR Begins to deal with open mrld semantics.
We essmtial point here is that the welldefined pmcadums that are appropriate for a closed world shply do not carry over to an open world.
Unfortunately, mat of h knowledge is open-ended, and w people have complex strategies for dealing with uncertainty and facing problears such as how to apply new attributes ar values Lo objects where they haven't applied in the paete 33 me two-valued logic that undatliee the propasitional calculus and related approachee to inference ca~ot encompass natural ssltwa cs.
The tfouble arises because truth varies in degree, in the, in range, in certainty, and in point of view of the observer, when it is applied to real-world objects.
We will briefly examine some of the implications of the multivalued nature or tgu%Pa for natural smaatica, olVc logic uses quantif icetion to distinguish between the universal and the particular, e.g., between "All men are mrtdW and amme men bve mrts, "" But *ere is no allowance mde for the degrees of truth as between say "Some nren have wartsR and .Some men have ears,* even though only a fraction have warts and a &t all haw ears, Pwple will infer that Mewbn had ears (given no info tion to the contrary as with Van Gogh), but will not infer *at Nets&an had warts, The inference in *e fomer case treats the particular like the universal, because almost all men have ears.
The more generally trw a statement is, the more certainty people assign to such an inference.
There just are not many universal truths to be found out in the cold, cruel world, and so pa~ple make the Best of it, Degree of truth mries not only with respect ta fuzzy variables (see Section 3.1) and quantification.
but alao in sther respects.
The aky is blue, but not all the the.
The yellow of a lemn Pa less variable an the yellow sf corn, which sometimes brders OM white, IBsaton is cold in the winter, but it is not m%a cold from the paint of view of an Eskimo.
Nixan told us that he didn't know about the cover-up of Watergate, but one is only =re or lees catain that he didn't know.
What these examples are designed to show is eat people are uncertain about the truth of any propaition for a variety of reasons.
Sometimes people seem to merge all the many sources of uncertainty together, but somethes they can distinguish different aspects sf aeir uncertainty with respect to a single proposition.
SCMOLM does not wow have my means far representing uncertainty, but the natural way to add such info tian is in tags stored along with the I-tags.
Just ae with I-tagsp U-tags can apply at all edded levels of ae data base.
Beause we have ~tarted on prsgr ng uncertain in'ferences (discussed below), it has be~orrme desfraB%e ka represent the underlying uncertainty in cIatxa base as well., %n order ta evalute how certain any inference my be, 4, Natural Pfiferenees We classify hum senoantic inferences into Pour major types: deductive, negative, fuetionaE, and indueti= inferences, The varioue tnes are discussed in gomewhat greater deUP1 in mBlias 5 and Quillian7 and Collins, Carbonell, and Warnock We do not argue mat these describe all the inferential strategies that people use, but only some of the major varieties.
The different strategies described are being implmented as subroutines in SCWO mile we think that people have a large eet of such strategies, the n er is probably less than one hundred.
Therefore, despite the inelegance of such an approach, we do not regard it as an endless task to encompass the bag of inferential tricks a person uses, In Figure 3 we have included excerpts from tape-recorded dialogues between h n tutares and studmts to illustrate some of the more complicated strategies people use, and the ways they ca&ine togethere We will discuss examples individually be low, 4.1 Deductive Inferences There are several transitive relations that people use frequently to infer that a property of one thing may be a property of the other.
These include superordinate, superpart, similarity, proximity, s rdinate, and eubpart relations.
Of the above types SCHO now hanaes only suprardinate and superpart infersnces, mich are the mast co n.
For example, if asked *Does the Llanos have a rainy seas~n?~, SCHOLAR will There is some jungle in here (points to Venezuela) but this breaks into a savanna around the Orinoco, Oh right, that is where they grow the coffee up there?
I don't think that the savanna is used for growing coffee.
The trouble is the savanna has a rainy season and *u can't count on rain in general.
But I don't know.
This area around Sao Paula is caf fee regionr and it is sort of getting into the savanna region there.
Are there any other areas where oil is found other than Venezuela?
Not particularly.
There is same ail offshore there but in general oil comes from Venezuela.
Venezuela ie the only one that b making any money in oil.
Is the Chac~ the cattle cauntq?
I know the cattle country is down there, I think it's mre sheep country.
It@,e like western Texas 80 in same sense 1 guess itus cattle country.
&nd the no~thern part oT Argentina has a large sort of semi-arid plain that extends into Paraguay.
And that's a plains area hat is relatively unpopulated.
Because it" pretty drya Figure 3.
Tutor-Student Dialogue Excerpts first look under Llanos and failing to find the info there, will look under Llanosv SUPEX (for superordinate), which is savanna, and its SUPEW (far superpart), which is Venezuela and Colombia.
A rainy season is a property of savannas and so the superordinate inference provies the answer.
The superpart inference is less general because it is restricted to certain attltlbutes such as climate, language, and topography.
One would not want to conclude that the capital of Massachusetts is Washington, D.
C., just because Massachusetts is part of the United Shates, Because moat properties of a sdperordinate or superpart are only generally true, and hot universally true, exceptions must be stored to preclude an incorrect inference (~a~heel'~).
similarity and proximity inferences parallel the eupemrdihate and superpart inferences, but they carry less certainty.
An example of a person using a pmximity inference is sham in the latter part of the tutor's response in E The tutor first said that a savanna could not be used for growing caf fee, but then he backed off this conelusion because of the proximity of the large Brazilian savanna to the coffee-growing region there.
To illustrate a similarity inference: if one knows a wallaby is like a kangaroo, Only amaller, then one will infer that a wallaby probably has a pouch.
We plan to add similarity information to SCHOLAR in the near future, because it will also be useful in making functioaal analogies which are discussed below.
The tecently added map facility (Harnock and ~ollins'') which ties together visual and semantic representations, makes proximity inferences possible, but they are still a way off.
Subordinate and subpart inf erencee follow a somewhat different pattern from the athers discussed.
If asked whether South rfca produces any oil, a person will answer "YesM because Venezuela, which is part of South America, produces oil.
But one does not want to conclude that South merica is hot because the mazon jungle is.
We haven't warked out the details of the restrictions on these inferences as yet.
There are other transitive relations that are used to mke deductive inferences but they are not as prevalent as the ones outlined here, Negative information, such as the fact that men do not have wheels, is not usually stared but rather inferred.
In a closed world thia presents no prablemt it is reaeondle to assume that if something it? not stored, then it is not true.
In factr early versions of SCHOLAR say *Now if asked "fs oil a product of Brazil"? just because oil isn't storad for Brazil.
But in the real warld, the fact Ulat somthing is not stored does not necessarily mean t it is not true.
People seem to have complex strategies for deciding when to say @Now and when to say @I don't know.
~4 We have recently been implementing these in SCHOLAR.
One kind of negative inference now in SCHOLAR is a simple contradiction procedure.
It relies on contradictory values stored with various concepts: for example, barren contradicts fertile, and democracy contradicts dictatorship.
Suppose SCHOLAR ia asked 1s the Pampas barren?* It would find the soil of the Pampas 1s fertile, anti since fertile contradicts barren, it wuld say *No.
The soil of the Pampas is fertile".
There is an hpoNant class of contradictions that are not subsumed under the procedure ve.
For example, conrtider the questio~ *Is Buenos Aires a city in Brazil?.
The fact that Buenos Aires is not among the cities of Brazil is no reason to say "Norw because there are eitiea in Brazil, such as Cor which are not stored.
But there are three facts that ether make a contradiction possible$ (1) Buenos Aires is located in Argentina, (2) cities only have one location, and 3) Argentina and Brazil are mutually exclusive.
We can illustrate tne necessity for conditions (2) and (3) : (2) even though Portuguese is the language of Portugal, it is alsd the language of Brazil e, language can have mbre than one location]; (3) even though Sao Paulo is in South America, it is also in Brazil . South America and Brazil are not mutually exclusive).
Making an incorrect negative inference about cities with more than one location (e.g.
Kansas City) or different cities with the same name (Rome, New York, and Rome, Italy) is precluded by storing bath locations specifically, just as with deductive inferences . The strategy we have worked out and implemented to find different contradictions of this kind is fairly complex.
Failure to find a contradiction leads to anather kind of negative inference people use which we call the lack-of -knowledge 5 inference (Collins, Carbonell and Warnock . Ex le 2 of Figure 3 shows the tutor using this strategy.
The baeiB of the tubrws inference is this: since he knows as muck abut other Sou* merican countries as he knows about Venezuela, it is a plausible but uncertain inference that.
if other countries produced ail, he would how about Lt.
(his conclusion was at least somavhat wrong, because there are in fact several other aountries in South Ame~ica that produce oil.
though far those countries oil is not nearly so important a% it is for Venezuela).
Sach a strategy is currently being implemented in SCHO in the following way: If asked a question like *Is oil a product of Uruguay"? where no ail is stored, SCHOLAR can look for oil under aidlar object8 keg., Venezuela or Brazil) or objects with the sme SUPEX and SWEW, ff SCHOWR finds sik stored wia Venezuela (say with an 1 -tag of 3) and if it has enough tion stored abut Uruguay (up to an I-mg of 8, say) to know about oil if it were at all important, then it can infer that Uruguay probably has no I.
The degree of certainty expressed in the answer ~hould depend on the difference in I-tags en the depth of what it knms ut Uruguay and the level at which oil is stored with sMlar ob jecta.
If SCHOLAR can find no similar objects that have property in question, as with "Is sand a product of Uruguay"? the appropriate answer is something like *I donot know whether sand is a product of any country in South America".
The 'heaakk-of-knowledge inference is based on the assumption that one's knowledge is fairly coneistent for similar objects.
4.3 Functional
Inferences Fmc tional inferences are ca n in the dialogues we collected 6 (Ccllins, Wainock, and Passafiume ).
Examples 1, 3, and 4 in Figure 3 illustrate the three different ways m have seen people use functional knowledge: in quasi calculations, in analogies, and in anmer to 'whyw questions.
Functional knowledge, which includes knowledge about functional determinants and their intgractions, ie learned, just as is factual knowledge, and therefore is stored in SCHOLAR'S data base under concept8 such as climate or agricultural products.
We wuPd argue t the representation of functional knowledge should be in a fom that different procedures can use.
One problem is to find a why to represent such knowledge in SCHOLAR so that it can be more or less precise, and still be accessible to different sarsm~nes that.
infer anmers to questions or that describe the functional relation to students.
FmctPanaB calculations can be used Pa both.
a positive and negative my.
One simple positive function now in SCHOLAR calculates the climate of a place if the information is not stwed, Based ow the major functional dete nawts of climate, which are latitude md altitude, SCMOUR will infer *ether the climate is tropical, sub-*apical, temperate, or cold/palar.
A negative use 0% calculation based on the agricultural products em~ti~n is show in me first pa9$ of the tutoro s aaamr in Example 1.
The functional determinants of agricultural products Pwelude the cl$ma&e, soil, and rainfall, The tutor pieked the lack of rain as a basis for a tentative wNo.w Nqative cabculatians do not require as precise knawledge as positive calculations.
They often only require that one or two of the functional deteminants have an inappropriate value.
Like funcf ional calculatione, functional analogies can be meitive or negative.
Example 3 shows the tutor making a positive functional analogy, again with the agricultural products function.
Phere he thought of a region, western Texas, that matched the 2haeo En terns of climate ad rainfall, the functiokaf Beteminsnts of cattle raising, Since he knew that western Wxas was cattle country he inferred that the Chaco might be as well.
A negative f nnc tional analogy might have occurred if the student had asked whether the Chiieo produced rubber.
Since the zon jungle and Xndonesfa produce rubber, the tutor could have said WN~W on the basis of the mismtch between the Chaea and those regions, with respect to climate and raidfall.
A positive and negative analogy subroutine has been implemented in SCHOLAR.
It is a fallback strategy to be used icf them is not enough info tfsn stared calculate ae functional relationship.
For a functional analogy it is only necessary to know the functionally relevant altrfiutes and Uaeir relative importance.
Then SCHOLAR looks to see if it knows any similar objects where the property in question is in fact stored.
It tries to find a match or a mismatch by comparing the gioen object and the similar object with respect to their values on the Eunctiollally relevant attributes.
People frequently uae such analogical reasoning, probably because of the ill-defined nature of their knawledge about functional relations.
The laet example in Figure 3 sh&s the use of a functional relation to anewer a @Whyw question.
The population density of a place depends on an indefinite set of functional determinants: climate, soil, and rainfall are major ones but distance from the sea, the par'icular continent, presence of valuable minerals, all contribute in different ways.
The tutor picked one determinant t had a value inapprgpriate for a large population density and gave that as a reason.
By contrast a geographer could probably mite a mole treatise on why the Chaco has a low pspulation dmsity, What we aspire POP SCHOLAR to do 1s wht the tumr didp that is, to pick one or two of the rnarmr deteminanta wit21 appropriate values and give those as a reason.
Q,4 Xndubtive Inferences We menuon inductive inferences here only because they are a major class of human inference.
We have not yet tried to progrm *em in IAR since they occur mstly in staring rather than retrieving infomation, The generalization and dfscridnation processes underlyfwg indueti on have been dasenssed 7' in detail elsewhere (~eeker'; WIRS~OP~~~; Collins and Quillian ) a 4.5 The inferential procdaserr described can combine in a ~riety of ways.
For inehance, contradictions can combine with deductive inferences.
SCBOWLR will anmer a question like "Is the Atlantic orange"? with wNo, it is blue, because it finds blue fe atorad with the SUPER., ocean.
Also one fanctfanal inference may call another.
If the agricultural products function needs a value for bhe climate of some region, it could call the climate function to compute it.
A more important way that inferences combine shows up when different strategies reach independent canclusiona about the same question.
A good example is Example I.
in Figure 3.
Them a negative functional inference, wkth an implicit lack-of-knowledge ihferance, fiest led to a tentative *Nou mawer, but *en a proximity inference produced a possible 'Yeem answer, and so the tutor backed off his earlier ""No".
men several inferences co-ine to yield the sme conclusion, aey increase the certainty of answer, and when they produce oppasite eoneluslons, aey deresse the certainty, There are a n er of sources of mcerainty in inferential procedures.
Uncertainty can derive from the size sf Ule diffemrence between I-tags &n Ule lack-of-knowledge inference, it can derive from the degree of match or mismatch in a functional analogy.
it can derive from the degree of predictivcanees of the functional dateminants, andl as m discussed earlier, it can derive fmm Uae degree of certainty about the info tfon storad.
Theae souces of uncertainty may be c ined ta produce an overdl uncertainty 9 (see for example tling This overall uncertainty ia important so that long, tenuous chains of reasoning are not pursued to their pointless end, and so that the degree of uncertainty in the answer can be Sadicated to the student, 5, Copcluaions what we have tried Ca show in this paper is the fuzzy, illdef Fned, mcer-in nature of much of h n howledge and thinking.
We want =HOUR ta be just aa fuzxy-thinking as we are.
6, This paper was started by Jaim R.
Carbonell who died quddsnly F&aary 2, 1973, I have completed it as best I could following his outline, I want to thank Eleanor H, Wamock wha helped me with the editing and Daniel 6, Bobraw and Mss Quillian who have contributed many ideas to our work.
The programing of various subroutines described in the paper was done by Nelleke Aiello, Jaime G.
Carbonell, Susan k.
Greesser, Mark Lo Miller.
Joseph Jo PassaPbume, and Eleanor H, Warnock, AllIan M, Colbfns.
This research was supparted in part by the Office of Naval -search, XmPo tion Systsma, uader Contract No, NO00f4-70-C-0264, and also in part by Ule Office sf Naval Research, Permnnel and Training, under Contract No, M00014-7%-C-0228, and by the Air Fame Systams Command, Electronic Systms Division, under Contract No.
F19628-72-C-0163, References J.
D. Becker, "A Model for the Encoding of Experiatial Info tion,* in R.
Schank & K.
Colby (Bds.), Computer Models of Thought and Language, Freeman., Sa Franci~co J.
R. Carbonell, *~ixed-Iniatiatiw Man-Computer Instructional Dialogues.
* Ph.L Thesis, M.I,T,, Dept.
of Electrical Engineering (June 1970).
J. R.
Carbonell. *A.
I. in C.A.I.: An Artificial-Intelligence Approach to Computer-Ass is-d Instmct ion" IEEE Trans.
on Man-Machine Systems.
I Vol, MMS-11, No.
4 (Dece&er 1970).
J, R.
Carbonell, *Artificial Intelligence and Large Interactive Man-Computer Systems " Proceedings of 1971 IEEE Systems, Man, and Cybernetics Conference, Anaheim, California A, M, Collins, J, R.
Carknell, and E, H.
Warnoek, "Semmtic Inferential Processing by Computer" in J.
Rose (Ed).
Advances in Cybernetics and Systems.
Wrdaw 6 Breach, Mndon (1994).
A. M.
Collins, E.
H, Warnock, and J.
JQ Passafiume, "Analysis and Synthesis of Tutorial Dialoguesn in G.
Bower (Ed.
) . The Psychology of Learning and Motivation.
Val. 9, Academic Press A.
M. Collins and M.
Re QuiL'lian, "How to Make a Language Usera in E.
Tulving and We Donaldeon (Eds.
) Organization of Memory Academic Press, New York (1972).
8. C.
Pillmre, "The Case for Casew in Bach and Hams ((~da)., Universals in Linguistics Theory.
Molt, Mnehart, and Winston, N.
Ye (1968).
9. Re Kling, "FUZZY P NER: Computing Inexactness in a Procedural Problem Salving Language.
" Uniwrsity of Wisconsin Technical Report NO.
168 (February 1973).
J. Lyons.
Introduction to Theoretical Linguistics, Cambridge University Press, Cambridqe, England (1968) . D.
R. Olson, wLanguage and Thought: Aspects of a Cognitive Theory of SemanticsY I Vole 77, No.
4 (July 1970).
12. M.
R. Quillian, 'The Teachable Language Comprehender: A Simulation Program and Theory of Languagew CACM, Vol.
12, No.
8 (August 1969).
13. B.
Raphael, *SIR: A Computer Program for Semantic Information Retrievaln in M.
L. Minsky (Ed.
) Semantic Information Proceers6ng7 M.1.T.
Press, Cambridge, Mass.
(1968). 14.
E. H.
Warnock and A.
M. Collins, "Semantic ~etworks" ~olt Beranek and Ne n Inc.
Report No.
2833 (May 1974).
15. T.
Winograd, Understanding Natural Language Academic Press, New York.
(1972). 16.
P. H.
Winston, *Learning Structural Descriptions from Examples,* Project MAC TR-76, M.I.T.
(September 1970).
17, We A.
Woods, vSemantics for a Question-Answering System, @ Aiken Computation Laboratory, Report No.
NSF-19, Harvatd Univefsity (August 1967) . B.
8, W, A.
Woods, R.
M. Kaplan, and Be Nash-Webber, ''The Lunar Sciences Natural Language Infomation Systq,* Bo1.t Beranek and Ne n Inc., Report No.
2378 (June '1972).
19. L.
A. Zddeh, wOutlining of a New Approach to the Analysis of Complex Systems and Decision Processes" IEEE Trans.
on Systems, Man, and Cybernetics, Vol.
SMC-3, No.
1 (January 1973) .

