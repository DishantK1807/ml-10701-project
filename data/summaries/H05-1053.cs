This is lower than reported for other sets of annotated data (for example it was 75% for the nouns in the SENSEVAL-2 English all-words task), but quite close to the reported 62.8% agreement between the first two taggings for single noun tagging for the SENSEVAL-3 English lexical sample task (Mihalcea et al., 2004).
W04-0807
In response to this problem, McCarthy et al.(2004) proposed a method for automatically inducing the 1This figure is the mean of two different estimates (Snyder and Palmer, 2004), the difference being due to multiword handling.
P04-1036 W04-0811
et al.(2004) we use a3a5a4a7a6a9a8 and obtain our thesaurus using the distributional similarity metric described by Lin (1998).
P98-2127
Most researchers working on word sense disambiguation (WSD) use manually sense tagged data such as SemCor (Miller et al., 1993) to train statistical classifiers, but also use the information in SemCor on the overall sense distribution for each word as a backoff model.
H93-1061
Over a decade ago, Gale et al.(1992) observed the tendency for one sense of a word to prevail in a given discourse.
H92-1045
Indeed, only 5 out of the 26 systems in the recent SENSEVAL-3 English all words task (Snyder and Palmer, 2004) outperformed the heuristic of choosing the most frequent sense as derived from SemCor (which would give 61.5% precision and recall1).
W04-0811
Predominant Senses We use the method described in McCarthy et al.(2004) for finding predominant senses from raw text.
P04-1036
Although sense distribution data derived from SemCor can be more accurate than such information derived automatically (McCarthy et al., 2004), in a given domain there will be words for which the SemCor frequency distributions are inappropriate or unavailable.
P04-1036
One could also use the rankings to estimate probability distributions and compare the distributions with measures such as alpha-skew divergence (Lee, 1999).
P99-1004
