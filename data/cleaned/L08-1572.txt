<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>Shlomo Argamon</author>
<author>Moshe Koppel</author>
<author>Jonathan Fine</author>
<author>Anat Rachel Shimoni</author>
</authors>
<title>Gender, genre, and writing style in formal written texts</title>
<date>2003</date>
<journal>Text</journal>
<volume>23</volume>
<contexts>
<context>58 features, many of which have been used in authorship identification (McColly and Weier, 1983; Smith, 1998; McEnery and Oakes, 2000), genre research (Biber, 1988; Biber, 1992; Kessler et al., 1997; Argamon et al., 2003) or research to detect stylistic inconsistency (Glover and Hirst, 1996). The rest of this section describes these features grouped by the type of processing necessary to compute them. 3.1. Simple Sur</context>
</contexts>
<marker>Argamon, Koppel, Fine, Shimoni, 2003</marker>
<rawString>Shlomo Argamon, Moshe Koppel, Jonathan Fine, and Anat Rachel Shimoni. 2003. Gender, genre, and writing style in formal written texts. Text, 23(3):321—346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas Biber</author>
</authors>
<title>Variation Across Speech and Writing</title>
<date>1988</date>
<publisher>Cambridge University Press</publisher>
<location>Cambridge</location>
<contexts>
<context>various stylistic and lexical features. We use 158 features, many of which have been used in authorship identification (McColly and Weier, 1983; Smith, 1998; McEnery and Oakes, 2000), genre research (Biber, 1988; Biber, 1992; Kessler et al., 1997; Argamon et al., 2003) or research to detect stylistic inconsistency (Glover and Hirst, 1996). The rest of this section describes these features grouped by the type</context>
</contexts>
<marker>Biber, 1988</marker>
<rawString>Douglas Biber. 1988. Variation Across Speech and Writing. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas Biber</author>
</authors>
<title>The multi-dimensional approach to linguistic analyses of genre variation: An overview of methodology and findings. Computers and the Humanities</title>
<date>1992</date>
<contexts>
<context>stic and lexical features. We use 158 features, many of which have been used in authorship identification (McColly and Weier, 1983; Smith, 1998; McEnery and Oakes, 2000), genre research (Biber, 1988; Biber, 1992; Kessler et al., 1997; Argamon et al., 2003) or research to detect stylistic inconsistency (Glover and Hirst, 1996). The rest of this section describes these features grouped by the type of processin</context>
</contexts>
<marker>Biber, 1992</marker>
<rawString>Douglas Biber. 1992. The multi-dimensional approach to linguistic analyses of genre variation: An overview of methodology and findings. Computers and the Humanities, 26(5):331–345.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
<author>Rebecca Watson</author>
</authors>
<title>The second release of the rasp system</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, (ACL/COLING–06</booktitle>
<location>Sydney, Australia</location>
<contexts>
<context>y piece of text, we compute the percentage of its words that occur in each of these 7 sets of words. 3.3. Part of Speech Distributions We use the RASP (Robust and Accurate Statistical Parser) system (Briscoe et al., 2006) to tag every word in a text with its corresponding part of speech, and then use of the distribution of the various parts of speech, as features. Percentage of words that are adjectives Percentage of</context>
</contexts>
<marker>Briscoe, Carroll, Watson, 2006</marker>
<rawString>Ted Briscoe, John Carroll, and Rebecca Watson. 2006. The second release of the rasp system. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, (ACL/COLING–06), Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Chen</author>
<author>Susan T Dumais</author>
</authors>
<title>Bringing order to the Web: automatically categorizing search results</title>
<date>2000</date>
<booktitle>In Proceedings of CHI-00, ACM International Conference on Human Factors in Computing Systems</booktitle>
<pages>145--152</pages>
<publisher>ACM Press</publisher>
<location>Den Haag, NL</location>
<contexts>
<context>elied on humans, but this can be a very expensive process and it becoming increasing common, in research, to use more automatic methods for corpus generation. Many automatic techniques (Hassel, 2001; Chen and Dumais, 2000; Sato and Sato, 1999) make use of the vast amount of text accessible on the World Wide Web to construct corpora that specifically meet the needs of an application. For instance, it is now possible to</context>
</contexts>
<marker>Chen, Dumais, 2000</marker>
<rawString>Hao Chen and Susan T. Dumais. 2000. Bringing order to the Web: automatically categorizing search results. In Proceedings of CHI-00, ACM International Conference on Human Factors in Computing Systems, pages 145– 152, Den Haag, NL. ACM Press, New York, US.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David L Donoho</author>
<author>Miriam Gasko</author>
</authors>
<title>Breakdown properties of location estimates based on halfspace depth and projected outlyingness</title>
<date>1992</date>
<journal>The Annals of Statistics</journal>
<volume>20</volume>
<contexts>
<context>ontext of location estimation in statistical data and has been shown to have many desirable properties including resistance to outliers and affine equivariance (Maronna and Yohai, 1995; Donoho, 1982; Donoho and Gasko, 1992). Let a be a direction (unit length column vector) in Rp then the outlyingness, SD, of an observation xi (row vector) can be estimated as: SD(xi) = maxa xia median(Xa)mad(Xa) Where xia is the project</context>
</contexts>
<marker>Donoho, Gasko, 1992</marker>
<rawString>David L. Donoho and Miriam Gasko. 1992. Breakdown properties of location estimates based on halfspace depth and projected outlyingness. The Annals of Statistics, 20(4):1803–1827, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David L Donoho</author>
</authors>
<title>Breakdown properties of multivariate location estimators. Ph.D. qualifying paper</title>
<date>1982</date>
<institution>Harvard University</institution>
<contexts>
<context>gated in the context of location estimation in statistical data and has been shown to have many desirable properties including resistance to outliers and affine equivariance (Maronna and Yohai, 1995; Donoho, 1982; Donoho and Gasko, 1992). Let a be a direction (unit length column vector) in Rp then the outlyingness, SD, of an observation xi (row vector) can be estimated as: SD(xi) = maxa xia median(Xa)mad(Xa) </context>
</contexts>
<marker>Donoho, 1982</marker>
<rawString>David L. Donoho. 1982. Breakdown properties of multivariate location estimators. Ph.D. qualifying paper, Harvard University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rudolf Flesch</author>
</authors>
<title>The Art of Readable Writing. Harper and Row</title>
<date>1974</date>
<location>New York</location>
<contexts>
<context>age of words that are pronouns In addition to these features, we implemented many of the most popular readability metrics, which are calculated using the surface features above. Readability measures (Flesch, 1974) attempt to provide a rough indication of the reading level required for a text. These measures are obviously lacking where true readability is concerned because they do not directly capture the rich</context>
</contexts>
<marker>Flesch, 1974</marker>
<rawString>Rudolf Flesch. 1974. The Art of Readable Writing. Harper and Row, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angela Glover</author>
<author>Graeme Hirst</author>
</authors>
<title>Detecting stylistic inconsistencies in collaborative writing</title>
<date>1996</date>
<editor>In Sharples, Mike and van der Geest, Thea (eds</editor>
<publisher>Springer-Verlag</publisher>
<location>London</location>
<contexts>
<context>n (McColly and Weier, 1983; Smith, 1998; McEnery and Oakes, 2000), genre research (Biber, 1988; Biber, 1992; Kessler et al., 1997; Argamon et al., 2003) or research to detect stylistic inconsistency (Glover and Hirst, 1996). The rest of this section describes these features grouped by the type of processing necessary to compute them. 3.1. Simple Surface Features The simplest type of the features used are ones that coun</context>
</contexts>
<marker>Glover, Hirst, 1996</marker>
<rawString>Angela Glover and Graeme Hirst. 1996. Detecting stylistic inconsistencies in collaborative writing. In Sharples, Mike and van der Geest, Thea (eds.), The new writing environment: Writers at work in a world of technology, Springer-Verlag, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Graff</author>
</authors>
<title>English gigaword. Linguistic Data Consortium, catalog number LDC2003T05</title>
<date>2003</date>
<contexts>
<context>reated some features that attempt to capture this. We measure this on a segment of text by calculating how frequently words from that segment appear in 10 years of newswire using the Gigaword Corpus (Graff, 2003). First we ranked all words by frequency in the Gigaword corpus, and then we make sets of words based on these frequencies. We then measure the distribution of words in these sets for pieces of text.</context>
<context>f and Rousseeuw (2000). (More information on this exact procedure can be found in Guthrie (2008).) 5. Experiments In each of the experiments we use exactly 50 random pieces of text from the Gigaword (Graff, 2003) corpus of newswire to represent our “normal” corpus and we select one piece of text from a different source to act as an outlier either from a newspaper editorial, translation of a news story, or fr</context>
</contexts>
<marker>Graff, 2003</marker>
<rawString>David Graff. 2003. English gigaword. Linguistic Data Consortium, catalog number LDC2003T05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Guthrie</author>
</authors>
<title>Unsupervised Detection of Anomalous Text (working title</title>
<date>2008</date>
<tech>Ph.D. thesis</tech>
<institution>University of Sheffield</institution>
<contexts>
<context> for determining which observations are farthest away from the rest of the data. While choosing a cutoff to automatically separate outliers from non-outliers is difficult, other experimental results (Guthrie, 2008) performed on these corpora indicate that using this detection method often results in the outlying piece of text having the greatest distance from the rest of the corpus. Further research is ongoing</context>
</contexts>
<marker>Guthrie, 2008</marker>
<rawString>David Guthrie. 2008. Unsupervised Detection of Anomalous Text (working title). Ph.D. thesis, University of Sheffield.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Hassel</author>
</authors>
<title>Internet as corpus automatic construction of a swedish news corpus</title>
<date>2001</date>
<booktitle>In Proceedings of the 13th Nordic Conference on Computational Linguistics (NODALIDA01</booktitle>
<location>Uppsala, Sweden</location>
<contexts>
<context>as generally relied on humans, but this can be a very expensive process and it becoming increasing common, in research, to use more automatic methods for corpus generation. Many automatic techniques (Hassel, 2001; Chen and Dumais, 2000; Sato and Sato, 1999) make use of the vast amount of text accessible on the World Wide Web to construct corpora that specifically meet the needs of an application. For instance</context>
</contexts>
<marker>Hassel, 2001</marker>
<rawString>Martin Hassel. 2001. Internet as corpus automatic construction of a swedish news corpus. In Proceedings of the 13th Nordic Conference on Computational Linguistics (NODALIDA01), Uppsala, Sweden, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mia Hubert</author>
<author>Peter J Rousseeuw</author>
<author>Karlien Vanden Branden</author>
</authors>
<title>Robpca: a new approach to robust principal component analysis. Technometrics, 47:64–79. Brett Kessler, Geoffrey Nunberg, and Hinrich Sch¨utze</title>
<date>2005</date>
<contexts>
<context>position of the centered feature matrix X = U V and taking U to be our new feature matrix. This new feature matrix will be at most dimension n n and results in no loss of information for this purpose(Hubert et al., 2005). This procedure was used as and initial step on the feature matrix to reduce the number of dimensions before computing the Stahel-Donoho Estimator for all experiments presented in this paper. The ap</context>
</contexts>
<marker>Hubert, Rousseeuw, Branden, 2005</marker>
<rawString>Mia Hubert, Peter J. Rousseeuw, and Karlien Vanden Branden. 2005. Robpca: a new approach to robust principal component analysis. Technometrics, 47:64–79. Brett Kessler, Geoffrey Nunberg, and Hinrich Sch¨utze.</rawString>
</citation>
<citation valid="true">
<title>Automatic detection of text genre</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics (ACL–97</booktitle>
<pages>32--38</pages>
<marker>1997</marker>
<rawString>1997. Automatic detection of text genre. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics (ACL–97), pages 32–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Kilgarriff</author>
<author>Tony Rose</author>
</authors>
<title>Measures for corpus similarity and homogeneity</title>
<date>1998</date>
<booktitle>In Proceedings of the 3rd conference on Empirical Methods in Natural Language Processing</booktitle>
<pages>46--52</pages>
<location>Granada, Spain</location>
<marker>Kilgarriff, Rose, 1998</marker>
<rawString>Adam Kilgarriff and Tony Rose. 1998. Measures for corpus similarity and homogeneity. In Proceedings of the 3rd conference on Empirical Methods in Natural Language Processing, pages 46–52, Granada, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Kilgarriff</author>
</authors>
<title>Using word frequency lists to measure corpus homogeneity and similarity between corpora</title>
<date>1997</date>
<booktitle>In Proceedings ACL SIGDAT workshop on very large corpora</booktitle>
<pages>231--245</pages>
<location>Beijing</location>
<marker>Kilgarriff, 1997</marker>
<rawString>Adam Kilgarriff. 1997. Using word frequency lists to measure corpus homogeneity and similarity between corpora. In Proceedings ACL SIGDAT workshop on very large corpora, pages 231–245, Beijing and Hong Kong, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Kilgarriff</author>
</authors>
<title>Comparing corpora</title>
<date>2001</date>
<journal>International Journal of Corpus Linguistics</journal>
<volume>6</volume>
<marker>Kilgarriff, 2001</marker>
<rawString>Adam Kilgarriff. 2001. Comparing corpora. International Journal of Corpus Linguistics, 6(1):1–37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ricardo A Maronna</author>
<author>Victor J Yohai</author>
</authors>
<title>The behavior of the stahel-donoho robust multivariate estimator</title>
<date>1995</date>
<journal>Journal of the American Statistical Association</journal>
<volume>90</volume>
<contexts>
<context>s been thoroughly investigated in the context of location estimation in statistical data and has been shown to have many desirable properties including resistance to outliers and affine equivariance (Maronna and Yohai, 1995; Donoho, 1982; Donoho and Gasko, 1992). Let a be a direction (unit length column vector) in Rp then the outlyingness, SD, of an observation xi (row vector) can be estimated as: SD(xi) = maxa xia medi</context>
</contexts>
<marker>Maronna, Yohai, 1995</marker>
<rawString>Ricardo A. Maronna and Victor J. Yohai. 1995. The behavior of the stahel-donoho robust multivariate estimator. Journal of the American Statistical Association, 90(429):330–341, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William McColly</author>
<author>Dennis Weier</author>
</authors>
<title>Literary attribution and likelihood-ratio tests: The case of the Middle English Pearl poems</title>
<date>1983</date>
<journal>Computers and the Humanities</journal>
<volume>17</volume>
<contexts>
<context>al piece of text in the corpora as a vector, where the components correspond to various stylistic and lexical features. We use 158 features, many of which have been used in authorship identification (McColly and Weier, 1983; Smith, 1998; McEnery and Oakes, 2000), genre research (Biber, 1988; Biber, 1992; Kessler et al., 1997; Argamon et al., 2003) or research to detect stylistic inconsistency (Glover and Hirst, 1996). T</context>
</contexts>
<marker>McColly, Weier, 1983</marker>
<rawString>William McColly and Dennis Weier. 1983. Literary attribution and likelihood-ratio tests: The case of the Middle English Pearl poems. Computers and the Humanities, 17(2):45–97, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tony McEnery</author>
<author>Michael Oakes</author>
</authors>
<date>2000</date>
<booktitle>Hanbook of Natural Language Processing, chapter Authorship Identification and Computational Stylometry</booktitle>
<pages>545--562</pages>
<publisher>Marcel Dekker</publisher>
<location>New York</location>
<contexts>
<context>ector, where the components correspond to various stylistic and lexical features. We use 158 features, many of which have been used in authorship identification (McColly and Weier, 1983; Smith, 1998; McEnery and Oakes, 2000), genre research (Biber, 1988; Biber, 1992; Kessler et al., 1997; Argamon et al., 2003) or research to detect stylistic inconsistency (Glover and Hirst, 1996). The rest of this section describes thes</context>
</contexts>
<marker>McEnery, Oakes, 2000</marker>
<rawString>Tony McEnery and Michael Oakes, 2000. Hanbook of Natural Language Processing, chapter Authorship Identification and Computational Stylometry, pages 545–562. Marcel Dekker, New York. Robert Dale and Hermann Moisl and Harlod Somers (eds.).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Magnus Sahlgren</author>
<author>Jussi Karlgren</author>
</authors>
<title>Counting lumps in word space: Density as a measure of corpus homogeneity</title>
<date>2005</date>
<journal>Buenos Aires, Argentine</journal>
<booktitle>In Proceedings of the 12th International Conference on String Processing and Information Retrieval (SPIRE05</booktitle>
<pages>151--154</pages>
<marker>Sahlgren, Karlgren, 2005</marker>
<rawString>Magnus Sahlgren and Jussi Karlgren. 2005. Counting lumps in word space: Density as a measure of corpus homogeneity. In Proceedings of the 12th International Conference on String Processing and Information Retrieval (SPIRE05), pages 151–154, Buenos Aires, Argentine.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoshi Sato</author>
<author>Madoka Sato</author>
</authors>
<title>Toward automatic generation of web directories</title>
<date>1999</date>
<booktitle>In ProceedingsofInternational Symposium on Digital Libraries (ISDL99</booktitle>
<pages>127--134</pages>
<location>Tsukuba, Japan</location>
<contexts>
<context>is can be a very expensive process and it becoming increasing common, in research, to use more automatic methods for corpus generation. Many automatic techniques (Hassel, 2001; Chen and Dumais, 2000; Sato and Sato, 1999) make use of the vast amount of text accessible on the World Wide Web to construct corpora that specifically meet the needs of an application. For instance, it is now possible to construct a corpus o</context>
</contexts>
<marker>Sato, Sato, 1999</marker>
<rawString>Satoshi Sato and Madoka Sato. 1999. Toward automatic generation of web directories. In ProceedingsofInternational Symposium on Digital Libraries (ISDL99), pages 127–134, Tsukuba, Japan, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>MWA Smith</author>
</authors>
<title>The authorship of acts i and ii of pericles: A new approach using first words of speeches. Computers and the Humanities</title>
<date>1998</date>
<pages>22--23</pages>
<contexts>
<context>orpora as a vector, where the components correspond to various stylistic and lexical features. We use 158 features, many of which have been used in authorship identification (McColly and Weier, 1983; Smith, 1998; McEnery and Oakes, 2000), genre research (Biber, 1988; Biber, 1992; Kessler et al., 1997; Argamon et al., 2003) or research to detect stylistic inconsistency (Glover and Hirst, 1996). The rest of th</context>
</contexts>
<marker>Smith, 1998</marker>
<rawString>MWA Smith. 1998. The authorship of acts i and ii of pericles: A new approach using first words of speeches. Computers and the Humanities, 22:23–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Werner A Stahel</author>
</authors>
<title>Breakdown of covariance estimators</title>
<date>1981</date>
<booktitle>Resarch Report 31, Fachgruppe f¨ur Statistik, Swiss Federal Institute of Technology (ETH</booktitle>
<location>Z¨urich</location>
<marker>Stahel, 1981</marker>
<rawString>Werner A. Stahel. 1981. Breakdown of covariance estimators. Resarch Report 31, Fachgruppe f¨ur Statistik, Swiss Federal Institute of Technology (ETH), Z¨urich.</rawString>
</citation>
</citationList>
</algorithm>

