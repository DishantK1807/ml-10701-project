<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>Gemma Boleda</author>
<author>Toni Badia</author>
<author>Eloi Batlle</author>
</authors>
<title>Acquisition of semantic classes for adjectives from distributional evidence</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th COLING</booktitle>
<pages>1119--1125</pages>
<contexts>
<context>djectives were constructed as a by-product of larger projects in (Hatzivassiloglou and McKeown, 1993; Freitag et al., 2005). Extraction of distributional features was also discussed in (Lapata, 2001; Boleda et al., 2004; Boleda et al., 2005), but applied in the semantic classification of adjectives. We have identified three types of constraints as the potential semantic descriptors of adjectives: 2A subtle agreement</context>
</contexts>
<marker>Boleda, Badia, Batlle, 2004</marker>
<rawString>Gemma Boleda, Toni Badia, and Eloi Batlle. 2004. Acquisition of semantic classes for adjectives from distributional evidence. In Proceedings of the 20th COLING, pages 1119˝U–1125. ACL. Gemma Boleda, Toni Badia, and Sabine Schulte im Walde.</rawString>
</citation>
<citation valid="true">
<title>Morphology vs. syntax in adjective class acquisition</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL-SIGLEX Workshop on Deep Lexical Acquisition</booktitle>
<pages>77--86</pages>
<location>Ann Arbor, Michigan</location>
<marker>2005</marker>
<rawString>2005. Morphology vs. syntax in adjective class acquisition. In Proceedings of the ACL-SIGLEX Workshop on Deep Lexical Acquisition, pages 77–86, Ann Arbor, Michigan, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Magdalena Derwojedowa</author>
<author>Maciej Piasecki</author>
<author>Stanisław Szpakowicz</author>
<author>Magdalena Zawisławska</author>
</authors>
<title>Polish WordNet on a shoestring</title>
<date>2007</date>
<booktitle>In Proceedings of Biannual Conference of the Society for Computational Linguistics and Language Technology</booktitle>
<volume>11</volume>
<pages>169--178</pages>
<institution>Universität Tübingen. Magdalena Derwojedowa, Maciej Piasecki, Stanisław Szpakowicz, Magdalena</institution>
<location>Tübingen</location>
<contexts>
<context>e generated the list of the k = 20 LUs most related to the given one. One of the co-authors manually assessed all elements on all lists, distinguishing any elements that are in some wordnet relation (Derwojedowa et al., 2007) to the head LU. The evaluated LU lists were classified into: • very useful – a half, or almost a half, of the LUs on the list are in some semantic relation to the given one, • useful – a sizable par</context>
</contexts>
<marker>Derwojedowa, Piasecki, Szpakowicz, Zawisławska, 2007</marker>
<rawString>Magdalena Derwojedowa, Maciej Piasecki, Stanisław Szpakowicz, and Magdalena Zawisławska. 2007. Polish WordNet on a shoestring. In Proceedings of Biannual Conference of the Society for Computational Linguistics and Language Technology, Tübingen, April 11 ˝U13 2007, pages 169–178. Universität Tübingen. Magdalena Derwojedowa, Maciej Piasecki, Stanisław Szpakowicz, Magdalena Zawisławska, and Bartosz Broda.</rawString>
</citation>
<citation valid="true">
<title>Words, concepts and relations in the construction of Polish WordNet</title>
<date>2008</date>
<booktitle>Proceedings of the Global WordNet Conference, Seged</booktitle>
<pages>162--177</pages>
<editor>In A. Tanâcs, D. Csendes, V. Vincze, Ch. Fellbaum, and P. Vossen, editors</editor>
<institution>University of Szeged</institution>
<location>Hungary</location>
<marker>2008</marker>
<rawString>2008. Words, concepts and relations in the construction of Polish WordNet. In A. Tanâcs, D. Csendes, V. Vincze, Ch. Fellbaum, and P. Vossen, editors, Proceedings of the Global WordNet Conference, Seged, Hungary January 22–25 2008, pages 162–177. University of Szeged.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas G Dietterich</author>
</authors>
<title>Approximate statistical tests for comparing supervised classification learning algorithms</title>
<date>1997</date>
<journal>Neural Computation</journal>
<volume>10</volume>
<contexts>
<context> – all and frequent (&gt; 1000) – and verbs, see Table 1. There only is no statistically significant difference between CRMI and RWF in the case of all verbs, respectively: 71.99% and 73.45%. Following (Dietterich, 1997), we applied McNemar’s test in order to check statistical significance of the difference between CRMI and RWF in the case of all verbs. McNemar’s test is based on the contingency table of the num5We </context>
</contexts>
<marker>Dietterich, 1997</marker>
<rawString>Thomas G. Dietterich. 1997. Approximate statistical tests for comparing supervised classification learning algorithms. Neural Computation, 10(7):1895–1924.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph L Fleiss</author>
</authors>
<title>Measuring nominal scale agreement among many raters</title>
<date>1971</date>
<journal>Psychological Bulletin</journal>
<volume>76</volume>
<contexts>
<context>the results. The average scoresachievedbytestparticipantsarepresentedinTable2. The inter-judge agreement was measured by Fleiss’s kappa, which allows the measure of agreement among many participants (Fleiss, 1971). The high value of kappa, supported by the manual evaluation of the test results, shows that the agreement was high, and the raters made similar errors. Examples of more difficult verb test QA pairs</context>
</contexts>
<marker>Fleiss, 1971</marker>
<rawString>Joseph L. Fleiss. 1971. Measuring nominal scale agreement among many raters. Psychological Bulletin, 76(5):378–382.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dayne Freitag</author>
<author>Matthias Blume</author>
<author>John Byrnes</author>
<author>Edmond Chow</author>
<author>Sadik Kapadia</author>
<author>Richard Rohwer</author>
<author>Zhiqiang Wang</author>
</authors>
<title>New experiments in distributional representations of synonymy</title>
<date>2005</date>
<booktitle>In Proceedings of the Ninth Conference on Computational Natural Language Learning (CoNLL-2005</booktitle>
<pages>25--32</pages>
<location>Ann Arbor, Michigan</location>
<contexts>
<context>ror depends on the tagger error rate. Mostknownmethodsoftransformationandsimilaritycomputation are based directly on the frequencies of LUs, with context co-occurrences collected from a corpus, e.g. (Freitag et al., 2005; Weeds and Weir, 2005). We have observed that noise and bias in an unbalanced corpus, as is the case withIPIC,cansignificantlyinfluencetheextractedMSR.In order to compensate for that, we follow a typ</context>
<context>ceptable, and the errors seem to be compensated by the large amount of data processed.3 MSRs for adjectives were constructed as a by-product of larger projects in (Hatzivassiloglou and McKeown, 1993; Freitag et al., 2005). Extraction of distributional features was also discussed in (Lapata, 2001; Boleda et al., 2004; Boleda et al., 2005), but applied in the semantic classification of adjectives. We have identified th</context>
<context>r results than the joint matrix ANmod+AAdv+AA. 4. Results and evaluation For the needs of a general automated test of MRS accuracy, we have adapted the idea of a WordNet-Based Similarity Test (WBST) (Freitag et al., 2005) to an evaluation similar to what we had done with nouns (Piasecki et al., 2007b). WBST consists of pairs 〈q,A〉: question-word (q) – four answer-words (A) among which only one is a nearsynonym of q. </context>
<context>baseline random selection is 25%. We divided the analysed adjectives and verbs into two groups by their frequency in IPIC: those occurring &gt; 1000 and the others. We can thus compare our results with (Freitag et al., 2005) who presented their results only for LUs with &gt; 1000 occurrencies. Working with the same generated co-occurrence matrices for verbs and adjectives, we compared the application of RWF with four other</context>
<context>icance of the difference between CRMI and RWF in the case of all verbs. McNemar’s test is based on the contingency table of the num5We reimplemented Lin’s measure, CRMI and RFF; we cite results from (Freitag et al., 2005). ber of examples misclassified (here an incorrect answer) by both, one of or any classifier. For all verbs we recorded: n00 = 557 (wrong answers from CRMI and RWF), n01 = 262 (CRMI −, RWF +), n10 = </context>
</contexts>
<marker>Freitag, Blume, Byrnes, Chow, Kapadia, Rohwer, Wang, 2005</marker>
<rawString>Dayne Freitag, Matthias Blume, John Byrnes, Edmond Chow, Sadik Kapadia, Richard Rohwer, and Zhiqiang Wang. 2005. New experiments in distributional representations of synonymy. In Proceedings of the Ninth Conference on Computational Natural Language Learning (CoNLL-2005), pages 25–32, Ann Arbor, Michigan, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maayan Geffet</author>
<author>Ido Dagan</author>
</authors>
<title>Vector quality and distributional similarity</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th international conference on Computational Linguistics, COLING2004</booktitle>
<pages>247--254</pages>
<marker>Geffet, Dagan, 2004</marker>
<rawString>Maayan Geffet and Ido Dagan. 2004. Vector quality and distributional similarity. In Proceedings of the 20th international conference on Computational Linguistics, COLING2004, pages 247–254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Hatzivassiloglou</author>
<author>K R McKeown</author>
</authors>
<title>Towards the automatic identification of adjectival scales: Clustering adjectives according to meaning</title>
<date>1993</date>
<booktitle>In Proceedings of the 31st ACL</booktitle>
<pages>172--182</pages>
<publisher>ACL</publisher>
<contexts>
<context>rict: a small number of errors is acceptable, and the errors seem to be compensated by the large amount of data processed.3 MSRs for adjectives were constructed as a by-product of larger projects in (Hatzivassiloglou and McKeown, 1993; Freitag et al., 2005). Extraction of distributional features was also discussed in (Lapata, 2001; Boleda et al., 2004; Boleda et al., 2005), but applied in the semantic classification of adjectives.</context>
<context>the given adjective (AAdv), • the co-occurrence with an adjective that agrees on case, number and gender as a potential co-constituent of the same noun phrase (AA). The last feature was advocated in (Hatzivassiloglou and McKeown, 1993) as expressing negative semantic information: only unrelated adjectives can sit in the same noun phrase. Our corpus data, however, suggest that it is too strong a bias. In addition, our AA constraint</context>
<context>le verb matrix. In the case of adjectives, the differences of accuracy achieved for different types of constraint are much smaller. The joined matrix is also better than any single one. The claim of (Hatzivassiloglou and McKeown, 1993) that cooccurence of two adjectives in one noun phrase (clearly indicated in Polish by their morphological agreement) is a negative feature is contradicted by the result of AA alone and AA combined w</context>
<context>ctives. A very small number of morphosyntactic constraints resulted in a relatively high accuracy in the WBST. The results of the WBST are well above the random baseline, and better than reported in (Hatzivassiloglou and McKeown, 1993; Freitag et al., 2005), though we worked with many fewer LUs. We also achieved results closer to human performance than those for nouns (Piasecki et al., 2007b). The method we propose here should be </context>
</contexts>
<marker>Hatzivassiloglou, McKeown, 1993</marker>
<rawString>V. Hatzivassiloglou and K. R. McKeown. 1993. Towards the automatic identification of adjectival scales: Clustering adjectives according to meaning. In Proceedings of the 31st ACL,, pages 172–182. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Israel</author>
</authors>
<title>Determining sample size</title>
<date>1992</date>
<tech>Tech. rep</tech>
<institution>University of Florida</institution>
<contexts>
<context>aphers. We randomly selected two subsets of LUs, verbs and adjectives. The sizes of the samples were determined in such a way that, with the 95% confidence level according to the method discussed in (Israel, 1992), the results of the manual evalutation perfomed on the samples can be ascribed to the whole sets. For every LU in each subset, we generated the list of the k = 20 LUs most related to the given one. </context>
</contexts>
<marker>Israel, 1992</marker>
<rawString>G. Israel. 1992. Determining sample size. Tech. rep., University of Florida.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Lapata</author>
</authors>
<title>A corpus-based account of regular polysemy: The case of context-sensitive adjectives</title>
<date>2001</date>
<booktitle>In Proceedings of the NAACL</booktitle>
<pages>63--70</pages>
<publisher>ACL</publisher>
<contexts>
<context>d.3 MSRs for adjectives were constructed as a by-product of larger projects in (Hatzivassiloglou and McKeown, 1993; Freitag et al., 2005). Extraction of distributional features was also discussed in (Lapata, 2001; Boleda et al., 2004; Boleda et al., 2005), but applied in the semantic classification of adjectives. We have identified three types of constraints as the potential semantic descriptors of adjectives</context>
</contexts>
<marker>Lapata, 2001</marker>
<rawString>Maria Lapata. 2001. A corpus-based account of regular polysemy: The case of context-sensitive adjectives. In Proceedings of the NAACL, pages 63–70. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Using syntactic dependency as local context to resolve word sense ambiguity</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics and 8th Conference of the European Chapter of the Association for Computational Linguistics (ACL-97</booktitle>
<pages>64--71</pages>
<publisher>ACL</publisher>
<location>Madrid, Spain</location>
<contexts>
<context>nk(cj) where rank(cj) calculates the position of cj (starting from zero) in the ranking based on fw. The construction of RWF has been inspired by the neighbour set comparison technique introduced in (Lin, 1997) and modified in (Weeds and Weir, 2005). It was applied to the comparison of the results of two MSRs. In our approach we use rank vectors in calculating MSR and ranks are the values of the features. </context>
</contexts>
<marker>Lin, 1997</marker>
<rawString>Dekang Lin. 1997. Using syntactic dependency as local context to resolve word sense ambiguity. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics and 8th Conference of the European Chapter of the Association for Computational Linguistics (ACL-97), pages 64–71, Madrid, Spain. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words</title>
<date>1998</date>
<booktitle>In COLING</booktitle>
<pages>768--774</pages>
<publisher>ACL</publisher>
<contexts>
<context>the computed similarity of row vectors is used as an estimate of the similarity of the corresponding LUs. A rich description of a context would usually be based on parsing results, e.g., (Ruge, 1992; Lin, 1998; Weeds and Weir, 2005). A context is represented as an instance of a lexico-syntactic relation, e.g.,an object of eat. Relation instances could be identified effectively given the output of a suffici</context>
<context>s only for LUs with &gt; 1000 occurrencies. Working with the same generated co-occurrence matrices for verbs and adjectives, we compared the application of RWF with four other measures:5: Lin’s measure (Lin, 1998), CRMI (Weeds and Weir, 2005), RFF (Geffet and Dagan, 2004) and Freitag et al.’s measure (Freitag et al., 2005) (the authors call it “optimal”). From a large number of proposed solutions, we selected</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Automatic retrieval and clustering of similar words. In COLING 1998, pages 768–774. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Hinrich Schütze</author>
</authors>
<title>Foundations of Statistical Natural Language Processing</title>
<date>2001</date>
<publisher>The MIT Press</publisher>
<contexts>
<context> are measures based on probability distribution or on Information Theory. In (Piasecki et al., 2007b) several functions have been tested; the best result was achieved with the t_score measure, e.g., (Manning and Schütze, 2001), applied as the weight function fw: fw(w,c) = t_score(w,c) = M[w,c]− TFwTFc WradicalBig TFwTFc W (1) TFw = summationtextM[w,•], TFc = summationtextM[•,c] are the total frequencies of LUs and feature</context>
</contexts>
<marker>Manning, Schütze, 2001</marker>
<rawString>Christopher D. Manning and Hinrich Schütze. 2001. Foundations of Statistical Natural Language Processing. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maciej Piasecki</author>
<author>Stanisław Szpakowicz</author>
<author>Bartosz Broda</author>
</authors>
<title>Automatic selection of heterogeneous syntactic features in semantic similarity of Polish nouns</title>
<date>2007</date>
<contexts>
<context>ctic level, effective enough given rich Polish inflection, because no efficient, accurate parser for Polish is available in the public domain yet. We have earlier constructed an MSR for Polish nouns (Piasecki et al., 2007a) and discussed its evaluation (Piasecki et al., 2007b). Here, we present a natural continuation of that work: MSRs for verbs and adjectives, the remaining open categories in plWordNet. Work financed</context>
<context>e compared rows of LUs; 3. local selection of features for the comparison of two units; 4. similarity calculation for a pair of row vectors. At the local selection level, however, we have introduced (Piasecki et al., 2007a) a Rank Weight Function (RWF) as a means of abstracting from the corpus frequencies in weights assigned to features of the given LU; a feature is a particular instance of a lexico-morphosyntactic re</context>
<context>a function that somehow measures the relevance of the feature cj to the LU wi. Natural candidates for the weight functions are measures based on probability distribution or on Information Theory. In (Piasecki et al., 2007b) several functions have been tested; the best result was achieved with the t_score measure, e.g., (Manning and Schütze, 2001), applied as the weight function fw: fw(w,c) = t_score(w,c) = M[w,c]− TFw</context>
<context>e needs of a general automated test of MRS accuracy, we have adapted the idea of a WordNet-Based Similarity Test (WBST) (Freitag et al., 2005) to an evaluation similar to what we had done with nouns (Piasecki et al., 2007b). WBST consists of pairs 〈q,A〉: question-word (q) – four answer-words (A) among which only one is a nearsynonym of q. In our case, a WBST is generated on the basis of plWordNet. An instance of the t</context>
<context>omly selected and added toA; next, three other LUs not inq’s synsets (detractors) are randomly drawn from plWordNet to complete 4Here we use almost the same constraint as that presented for nouns in (Piasecki et al., 2007b) but in the reverse direction. or( and( in(pos[0],fin,ger,praet,impt,imps,inf,ppas,ppact,pcon,pant), rlook(1,end,$SR,or( in(pos[$SR],fin,ger,praet,impt,imps,inf,ppas,ppact, pcon,pant,conj,interp) an</context>
</contexts>
<marker>Piasecki, Szpakowicz, Broda, 2007</marker>
<rawString>Maciej Piasecki, Stanisław Szpakowicz, and Bartosz Broda. 2007a. Automatic selection of heterogeneous syntactic features in semantic similarity of Polish nouns.</rawString>
</citation>
<citation valid="false">
<booktitle>In Proceedings of the Text, Speech and Dialog 2007 Conference</booktitle>
<volume>4629</volume>
<publisher>LNAI. Springer</publisher>
<marker></marker>
<rawString>In Proceedings of the Text, Speech and Dialog 2007 Conference, volume 4629 of LNAI. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maciej Piasecki</author>
<author>Stanisław Szpakowicz</author>
<author>Bartosz Broda</author>
</authors>
<title>Extended similarity test for the evaluation of semantic similarity functions</title>
<date>2007</date>
<booktitle>In Vetulani (Vetulani</booktitle>
<pages>104--108</pages>
<contexts>
<context>ctic level, effective enough given rich Polish inflection, because no efficient, accurate parser for Polish is available in the public domain yet. We have earlier constructed an MSR for Polish nouns (Piasecki et al., 2007a) and discussed its evaluation (Piasecki et al., 2007b). Here, we present a natural continuation of that work: MSRs for verbs and adjectives, the remaining open categories in plWordNet. Work financed</context>
<context>e compared rows of LUs; 3. local selection of features for the comparison of two units; 4. similarity calculation for a pair of row vectors. At the local selection level, however, we have introduced (Piasecki et al., 2007a) a Rank Weight Function (RWF) as a means of abstracting from the corpus frequencies in weights assigned to features of the given LU; a feature is a particular instance of a lexico-morphosyntactic re</context>
<context>a function that somehow measures the relevance of the feature cj to the LU wi. Natural candidates for the weight functions are measures based on probability distribution or on Information Theory. In (Piasecki et al., 2007b) several functions have been tested; the best result was achieved with the t_score measure, e.g., (Manning and Schütze, 2001), applied as the weight function fw: fw(w,c) = t_score(w,c) = M[w,c]− TFw</context>
<context>e needs of a general automated test of MRS accuracy, we have adapted the idea of a WordNet-Based Similarity Test (WBST) (Freitag et al., 2005) to an evaluation similar to what we had done with nouns (Piasecki et al., 2007b). WBST consists of pairs 〈q,A〉: question-word (q) – four answer-words (A) among which only one is a nearsynonym of q. In our case, a WBST is generated on the basis of plWordNet. An instance of the t</context>
<context>omly selected and added toA; next, three other LUs not inq’s synsets (detractors) are randomly drawn from plWordNet to complete 4Here we use almost the same constraint as that presented for nouns in (Piasecki et al., 2007b) but in the reverse direction. or( and( in(pos[0],fin,ger,praet,impt,imps,inf,ppas,ppact,pcon,pant), rlook(1,end,$SR,or( in(pos[$SR],fin,ger,praet,impt,imps,inf,ppas,ppact, pcon,pant,conj,interp) an</context>
</contexts>
<marker>Piasecki, Szpakowicz, Broda, 2007</marker>
<rawString>Maciej Piasecki, Stanisław Szpakowicz, and Bartosz Broda. 2007b. Extended similarity test for the evaluation of semantic similarity functions. In Vetulani (Vetulani, 2007), pages 104–108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maciej Piasecki</author>
</authors>
<title>Handmade and automatic rules for Polish tagger</title>
<date>2006</date>
<journal>In Sojka</journal>
<marker>Piasecki, 2006</marker>
<rawString>Maciej Piasecki. 2006. Handmade and automatic rules for Polish tagger. In Sojka et al. (Sojka et al., 2006).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Przepiórkowski</author>
</authors>
<title>The IPI PAN Corpus: Preliminary version</title>
<date>2004</date>
<institution>Institute of Computer Science PAS</institution>
<contexts>
<context> particularly useful if it places LUs most closely related to υ near the top of the suggestion list. The process relies on a morphosyntactically annotated corpus of Polish: the IPI PAN corpus (IPIC) (Przepiórkowski, 2004) of about 254 million tokens. We work at the morphosyntactic level, effective enough given rich Polish inflection, because no efficient, accurate parser for Polish is available in the public domain y</context>
<context>n in JOSKIPI (Piasecki, 2006), in the first and expression we check whether there is a form that is the head of an utterance, e.g., a finite form, at position 0 – mnemonics come from the IPIC tagset (Przepiórkowski, 2004). Next we look to the right (rlook) for a noun form in the accusative case or a next verb. $SR is a variable that stores the position of iteration. Finally, we check whether the right iteration stopp</context>
</contexts>
<marker>Przepiórkowski, 2004</marker>
<rawString>Adam Przepiórkowski. 2004. The IPI PAN Corpus: Preliminary version. Institute of Computer Science PAS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Ruge</author>
</authors>
<title>Experiments on linguistically-based term associations</title>
<date>1992</date>
<booktitle>Information Processing and Management</booktitle>
<pages>28--3</pages>
<contexts>
<context> • finally, the computed similarity of row vectors is used as an estimate of the similarity of the corresponding LUs. A rich description of a context would usually be based on parsing results, e.g., (Ruge, 1992; Lin, 1998; Weeds and Weir, 2005). A context is represented as an instance of a lexico-syntactic relation, e.g.,an object of eat. Relation instances could be identified effectively given the output o</context>
</contexts>
<marker>Ruge, 1992</marker>
<rawString>G. Ruge. 1992. Experiments on linguistically-based term associations. Information Processing and Management, 28(3):317–332.</rawString>
</citation>
<citation valid="true">
<date>2006</date>
<booktitle>ProceedingsoftheText, Speech and Dialog 2006Conference, Lecture Notes in Artificial Intelligence</booktitle>
<editor>Petr Sojka, Ivan Kopecek, and Karel Pala, editors</editor>
<publisher>Springer</publisher>
<marker>2006</marker>
<rawString>Petr Sojka, Ivan Kopecek, and Karel Pala, editors. 2006. ProceedingsoftheText, Speech and Dialog 2006Conference, Lecture Notes in Artificial Intelligence. Springer.</rawString>
</citation>
<citation valid="true">
<title>Wydawnictwo Pozna´nskie Sp. z o.o</title>
<date>2007</date>
<booktitle>Proceedings of the 3rd Language and Technology Conference, October 5–7, 2007</booktitle>
<editor>Zygmunt Vetulani, editor</editor>
<location>Pozna´n, Poland</location>
<marker>2007</marker>
<rawString>Zygmunt Vetulani, editor. 2007. Proceedings of the 3rd Language and Technology Conference, October 5–7, 2007, Pozna´n, Poland. Wydawnictwo Pozna´nskie Sp. z o.o., Pozna´n.</rawString>
</citation>
</citationList>
</algorithm>

