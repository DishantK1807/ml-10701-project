Proceedings of NAACL HLT 2009: Short Papers, pages 49–52,
Boulder, Colorado, June 2009. c 2009 Association for Computational Linguistics
Modeling Dialogue Structure with 
Adjacency Pair Analysis and Hiden Markov Models 
 
Kristy 
Elizabeth 
Boyer
*1
 
Robert 
Phillips
1,2
 
Eun 
Young 
Ha
1 
Michael D.  
Wallis
1,2 
Mladen A.  
Vouk
1 
James C. 
Lester
1 
 
1
Department of Computer Science 
North Carolina State University 
Raleigh, NC, USA 
 
2
Aplied Research Asociates 
Raleigh, NC, USA 
 
*
keboyer@ncsu.edu 
 
Abstract 
Automaticaly detecting dialogue structure 
within corpora of human-human dialogue is 
the subject of increasing atention. In the do-
main of tutorial dialogue, automatic discovery 
of dialogue structure is of particular interest 
because these structures inherently represent 
tutorial strategies or modes, the study of 
which is key to the design of inteligent tutor-
ing systems that comunicate with learners 
through natural language.  We propose a 
methodology in which a corpus of human-
human tutorial dialogue is first manualy an-
notated with dialogue acts.  Dependent adja-
cency pairs of these acts are then identified 
through χ
2
 analysis, and hiden Markov mod-
eling is aplied to the observed sequences to 
induce a descriptive model of the dialogue 
structure.    
1 Introduction

Automaticaly learning dialogue structure from 
corpora is an active area of research driven by a 
recognition of the value ofered by data-driven ap-
proaches (e.g., Bangalore et al., 206).  Dialogue 
structure information is of particular importance 
when the interaction is centered around a learning 
task, such as in natural language tutoring, because 
techniques that suport empirical identification of 
dialogue strategies can inform not only the design 
of inteligent tutoring systems (Forbes-Riley et al., 
207), but also contribute to our understanding of 
the cognitive and afective proceses involved in 
learning through tutoring (VanLehn et al., 207).  
   Although traditional top-down aproaches (e.g., 
Cade et al., 208) and some empirical work on 
analyzing the structure of tutorial dialogue 
(Forbes-Riley et al., 207) have yielded significant 
results, the field is limited by the lack of an auto-
matic, data-driven aproach to identifying dialogue 
structure.  An empirical aproach to identifying 
tutorial dialogue strategies, or modes, could ad-
dres this limitation by providing a mechanism for 
describing in sucinct probabilistic terms the tuto-
rial strategies that actualy ocur in a corpus. 
   Just as early work on dialogue act interpretation 
utilized hiden Markov models (HMs) to capture 
linguistic structure (Stolcke et al., 200), we pro-
pose a system that uses HMs to capture the 
structure of tutorial dialogue implicit within se-
quences of already-taged dialogue acts. This ap-
proach operates on the premise that at any given 
point in the tutorial dialogue, the colaborative in-
teraction is in a dialogue mode that characterizes 
the nature of the exchanges betwen tutor and stu-
dent. In our model, a dialogue mode is defined by 
a probability distribution over the observed sym-
bols (e.g., dialogue acts and adjacency pairs). 
   Our previous work has noted some limitations 
of first-order HMs as aplied to sequences of 
individual dialogue acts (Boyer et al., in pres). 
Chief among these is that HMs alow arbitrarily 
frequent transitions betwen hiden states, which 
does not conform wel to human intuition about 
how tutoring strategies are aplied.  Training an 
HM on a sequence of adjacency pairs rather than 
individual dialogue acts is one way to generate a 
49
more descriptive model without increasing model 
complexity more than is required to acomodate 
the expanded set of observation symbols.  To this 
end, we aply the aproach of Midgley et al. 
(206) for empiricaly identifying significant adja-
cency pairs within dialogue, and proced by treat-
ing adjacency pairs as atomic units for the 
purposes of training the HM.  
2 Corpus
Analysis 
This analysis uses a corpus of human-human tuto-
rial dialogue colected in the domain of introduc-
tory computer science.  Forty-thre learners 
interacted remotely with a tutor through a key-
board-to-keyboard remote learning environment 
yielding 4,864 dialogue moves. 
   The tutoring corpus was manualy taged with 
dialogue acts designed to capture the salient char-
acteristics of the tutoring proces (Table 1). 
 
Tag Act Example 
Q Question Where should I 
declare i? 
EQ Evaluation Question How does that lok? 
S Statement You ned a 
closing brace. 
G Grounding Ok. 
EX Extra-Domain You may use 
your bok. 
PF Positive Fedback Yes, that’s right. 
LF Lukewarm Fedback Sort of. 
NF Negative Fedback No, that’s not right. 
Table 1. Dialogue Act Tags 
 
The corespondence betwen uterances and dia-
logue act tags is one-to-one. Compound uterances 
(i.e., a single uterance comprising more than one 
dialogue act) were split by the primary anotator 
prior to the inter-rater reliability study.
1
   
  The importance of adjacency pairs is wel-
established in natural language dialogue (e.g., 
Schlegof & Sacks, 1973), and adjacency pair 
analysis has iluminated important phenomena in 
tutoring as wel (Forbes-Riley et al., 207).  For 
the curent corpus, bigram analysis of dialogue acts 
yielded a set of comonly-ocuring pairs. How-
ever, as noted in (Midgley et al., 206), in order to 
                                                             
1
 Details of the study procedure used to colect the corpus, as 
wel as Kapa statistics for inter-rater reliability, are reported 
in (Boyer et al., 208). 
establish that two dialogue acts are truly related as 
an adjacency pair, it is important to determine 
whether the presence of the first member of the 
pair is asociated with a significantly higher prob-
ability of the second member ocuring.  For this 
analysis we utilize a χ
2
 test for independence of the 
categorical variables act
i
 and act
i+1
 for al two-way 
combinations of dialogue act tags.  Only pairs in 
which speaker(act
i
)≠speaker(act
i+1
) were consid-
ered.  Other dialogue acts were treated as atomic 
elements in subsequent analysis, as discused in 
Section 3. Table 2 displays a list of the dependent 
pairs sorted by descending (unadjusted) statistical 
significance; the subscript indicates tutor (t) or stu-
dent (s). 
 
act
i
 act
i+1
 
P(act
i+1
|   
    act
i
) 
P(act
i+1
| 
   ¬act
i
) 
χ
2 
val p-val 
EQ
s
 PF
t
 0.48 0.07 654 <0.001 
G
s
 G
t
 0.27 0.03 380 <0.001 
EX
s
 EX
t
 0.34 0.03 378 <0.001 
EQ
t
 PF
s
 0.18 0.01 322 <0.001 
EQ
t
 S
s
 0.24 0.03 289 <0.001 
EQ
s
 LF
t
 0.13 0.01 265 <0.001 
Q
t
 S
s
 0.65 0.04 235 <0.001 
EQ
t
 LF
s
 0.07 0.0 219 <0.001 
Q
s
 S
t
 0.82 0.38 210 <0.001 
EQ
s
 NF
t
 0.08 0.01 207 <0.001 
EX
t
 EX
s
 0.19 0.02 177 <0.001 
NF
s
 G
t
 0.29 0.03 172 <0.001 
EQ
t
 NF
s
 0.1 0.01 133 <0.001 
S
s
 G
t
 0.16 0.03 95 <0.001 
S
s
 PF
t
 0.30 0.10 90 <0.001 
S
t
 G
s
 0.07 0.04 36 <0.001 
PF
s
 G
t
 0.14 0.04 34 <0.001 
LF
s
 G
t
 0.2 0.04 30 <0.001 
S
t
 EQ
s
 0.1 0.07 29 <0.001 
G
t
 EX
s
 0.07 0.03 14 0.002 
S
t
 Q
s
 0.07 0.05 14 0.002 
G
t
 G
s
 0.10 0.05 9 0.027 
EQ
t
 EQ
s
 0.13 0.08 8 0.042 
Table 2. Dependent Adjacency Pairs 
3 HMM
on Adjacency Pair Sequences 
The keyboard-to-keyboard tutorial interaction re-
sulted in a sequence of uterances that were ano-
tated with dialogue acts.  We have hypothesized 
that a higher-level dialogue structure, namely the 
tutorial dialogue mode, overlays the observed dia-
logue acts. To build an HM model of this struc-
50
ture we treat dialogue mode as a hiden variable 
and train a hiden Markov model to induce the 
dialogue modes and their asociated dialogue act 
emision probability distributions. 
  An adjacency pair joining algorithm (Figure 1) 
was aplied to each sequence of dialogue acts. 
This algorithm joins pairs of dialogue acts into 
atomic units acording to a priority determined by 
the strength of the adjacency pair dependency. 
 
Sort adjacency pair list L by descending statistical 
significance 
For each adjacency pair (act
1, act
2
) in L 
    For each dialogue act sequence (a
1, a
2, …, a
n
)  
    in the corpus 
        Replace al pairs (a
i
=act
1, a
i+1
=act
2
) with a 
        new single act (act
1
act
2
) 
Figure 1. Adjacency Pair Joining Algorithm 
 
   Figure 2 ilustrates the aplication of the adja-
cency pair joining algorithm on a sequence of dia-
logue acts.  Any dialogue acts that were not 
grouped into adjacency pairs at the completion of 
the algorithm are treated as atomic units in the 
HMianalysis. 
 
Original Dialogue Act Sequence: 
Q
s 
S
t
 LF
t
 S
t
 S
t
 G
s
 EQ
s
 LF
t
 S
t
 S
t
 Q
s
 S
t 
After Adjacency Pair Joining Algorithm: 
Q
s
S
t
 LF
t
 S
t
 S
t
G
s
 EQ
s
LF
t
 S
t
 S
t
 Q
s
S
t
 
Figure 2. DA Sequence Before/After Joining 
 
   The final set of observed symbols consists of 39 
tags: 23 adjacency pairs (Table 2) plus al individ-
ual dialogue acts augmented with a tag for the 
speaker (Table 1).  
  It was desirable to learn n, the best number of 
hiden states, during modeling rather than specify-
ing this value a priori. To this end, we trained and 
ten-fold cros-validated seven models (each featur-
ing randomly-initialized parameters) for each 
number of hiden states n from 2 to 15, inclusive.
2
  
The average log-likelihod was computed acros 
al seven models for each n, and this average log-
                                                             
2
 n=15 was chosen as an initial maximum number of states 
because it comfortably exceded our hypothesized range of 3 
to 7 (informed by the tutoring literature).  The Akaike Infor-
mation Criterion measure steadily worsened above n = 5, con-
firming no ned to train models with n > 15. 
likelihod l
n
 was used to compute the Akaike In-
formation Criterion, a maximum-penalized likeli-
hod estimator that penalizes more complex 
models (Scot, 202).  The best fit was obtained 
with n=4 (Figure 3).  The transition probability 
distribution among hiden states is depicted in 
Figure 4, with the size of the nodes indicating rela-
tive frequency of each hiden state; specificaly, 
State 0 acounts for 63% of the corpus, States 1 
and 3 acount for aproximately 15% each, and 
State 2 acounts for 7%. 
 
 
 
Figure 3. Dialogue Act Emision Probability 
Distribution by Dialogue Mode
3
 
4 Discussion
and Future Work 
This exploratory aplication of hiden Markov 
models involves training an HM on a mixed in-
put sequence consisting of both individual dialogue 
acts and adjacency pairs.  The best-fit HM con-
sists of four hiden states whose emision symbol 
probability distributions lend themselves to inter-
pretation as tutorial dialogue modes. For example, 
State 0 consists primarily of tutor statements and 
positive fedback, two of the most comon dia-
logue acts in our corpus. The transition probabili
51
 
Figure 4. Transition Probability Distribution
4 
 
ties also reveal that State 0 is highly stable; a self-
transition is most likely with probability 0.835. 
State 3 is an interactive state featuring student re-
flection in the form of questions, statements, and 
requests for fedback. The transition probabilities 
show that nearly 60% of the time the dialogue 
transitions from State 3 to State 0; this may indi-
cate that after establishing what the student does or 
does not know in State 3, the tutoring switches to a 
les colaborative “teaching” mode represented by 
State 0.  
     Future evaluation of the HM presented here 
wil include comparison with other types of 
graphical models.  Another important step is to 
corelate the dialogue profile of each tutoring ses-
sion, as revealed by the HM, to learning and af-
fective outcomes of the tutoring sesion. This type 
of inquiry can lead directly to design recomenda-
tions for tutorial dialogue systems that aim to 
maximize particular learner outcomes. In adition, 
leveraging knowledge of the task state as wel as 
surface-level uterance content below the dialogue 
act level are promising directions for refining the 
descriptive and predictive power of these models.     
 
Acknowledgements 
 
This research was suported by the National Science 
Foundation under Grants REC-0632450, IS-
081291, CNS-0540523, and GRFP.  Any opinions, 
findings, and conclusions or recomendations ex-
presed in this material are those of the 
authors and do not necesarily reflect the views of the 
National Science Foundation. 
References 
Boyer, K.E., Philips, R., Walis, M., Vouk, M., & 
Lester, J. (208).  Balancing cognitive and moti-
vational scafolding in tutorial dialogue.  Pro-
ceedings of the 9th International Conference on 
Inteligent Tutoring Systems, Montreal, Canada, 
239-249. 
Boyer, K.E., Ha, E.Y., Walis, M., Philips, R., Vouk, 
M. & Lester, J. (in pres).  Discovering tutorial 
dialogue strategies with hiden Markov models. 
To apear in Procedings of the 14
th
 International 
Conference on Artificial Inteligence in Educa-
tion, Brighton, U.K. 
Bangalore, S., DiFabrizio, G., Stent, A. (206). 
Learning the structure of task-driven human-
human dialogs.  Procedings of ACL, Sydney, 
Australia, 201-208. 
Cade, W., Copeland, J., Person, N., & D'Melo, S. 
(208). Dialog modes in expert tutoring. Proced-
ings of the 9th International Conference on Intel-
ligent Tutoring Systems, Montreal, Canada, 470-
479. 
Forbes-Riley, K., Rotaru, M., Litman, D. J., & 
Tetreault, J. (207). Exploring afect-context de-
pendencies for adaptive system development. 
Procedings of NACL HLT, Companion Volume, 
41-4. 
Midgley, T. D., Harison, S., & MacNish, C. (207). 
Empirical verification of adjacency pairs using 
dialogue segmentation. Procedings of the 7
th
 
SIGdial Workshop on Discourse and Dialogue, 
104-108. 
Schlegof, E.A., Sacks, H. (1973). Opening up clos-
ings.  Semiotica, 8(4), 289-327. 
Scot, S. L. (202). Bayesian methods for hiden 
Markov models: Recursive computing in the 21st 
century. Journal of the American Statistical Aso-
ciation, 97(457), 37-351. 
Stolcke, A., Cocaro, N., Bates, R., Taylor, P., Van 
Ess-Dykema, C., Ries, K., Shirberg, E., Jurafsky, 
D., Martin, R., Meter, M. (200).  Dialog act 
modeling for automatic taging and recognition of 
conversational spech. Computational Linguistics 
26(3), 39-373. 
VanLehn, K., Graeser, A., Jackson, G.T., Jordan, P., 
Olney, A., Rose, C.P. (207). When are tutorial 
dialogues more efective than reading? Cognitive 
Science, 31(1), 3-62. 
52

