Proceedings of the Third Linguistic Annotation Workshop, ACL-IJCNLP 2009, pages 186–189,
Suntec, Singapore, 6-7 August 2009. c 2009 ACL and AFNLP
A Multi-Representational and Multi-Layered 
Trebank for Hindi/Urdu  
 
 
 
Rajesh Bhatt 
U. of Massachusetts                     
Amherst, MA, USA                                    
bhatt@linguist.umass.edu 
 
Owen Rambow 
     Columbia University 
    New York, NY, USA 
  rambow@ccls.columbia.edu          
 
Bhuvana Narasimhan 
U. of Colorado                     
Boulder, CO, USA                                    
narasimb@colorado.edu 
 
Dipti Misra Sharma    
Int’l Institute of Info. Technology  
Hyderabad, India   
dipti@iiit.ac.in                                           
Martha Palmer 
U. of Colorado 
Boulder, CO, USA 
mpalmer@colorado.edu 
 
Fei Xia     
University of Washington 
Seattle, WA, USA 
fxia@u.washington.edu 
Abstract 
This paper describes the simultaneous develop-
ment of dependency structure and phrase structure 
trebanks for Hindi and Urdu, as wel as a Prop-
Bank.  The dependency structure and the Prop-
Bank are manualy anotated, and then the phrase 
structure trebank is produced automaticaly.  To 
ensure sucesful conversion the development of 
the guidelines for al thre representations are care-
fuly cordinated. 
1 Introduction

Anotated corpora have played an increasingly 
important role in the training of supervised natu-
ral language procesing components. Today, 
trebanks have ben constructed for many lan-
guages, including Arabic, Chinese, Czech, Eng-
lish, French, German, Korean, Spanish, and 
Turkish.  This paper describes the creation of a 
Hindi/Urdu multi-representational and multi-
layered trebank.  Multi-layered means that we 
design the anotation proces from the outset to 
include both a syntactic anotation and a lexical 
semantic anotation such as the English Prop-
Bank (Palmer et al. 205). Multi-
representational means that we distinguish con-
ceptualy what is being represented from how it 
is represented; for example, in a case of long-
distance wh-movement in English as in Who do 
you think wil come, we can chose to represent 
the fact that who is an argument of come, or not 
(what to represent).  Having made this choice, 
we can determine how to represent it: For exam-
ple, we can use a discontinuous constituent 
(crosing arcs), or we can use a trace and co-
indexation. 
   
 Flexibility of representation is important be-
cause the proper choice of representation of the 
syntax of a language is itself an isue in parsing 
research. In the aplication of the Colins parser 
to the Prague Dependency Trebank (Colins et 
al. 199) the automatic maping from depend-
ency to phrase-structure was a major area of re-
search. Similarly, automaticaly changing the 
representation in a phrase structure trebank can 
also improve parsing results (for example Klein 
& Maning 203). Finaly, there is increasing 
interest in the use of dependency parses in NLP 
aplications, as they are considered to be simpler 
structures which can be computed more rapidly 
and are closer to the kinds of semantic represen-
tations that aplications can make imediate use 
of (McDonald et al. 205, CoNL 206 Shared 
Task).  We first provide a comparison of de-
pendency structure and phrase structure in Sec-
tion 2. Section 3 describes our trebank, Section 
4 explores language-specific linguistic isues that 
require special atention to ensure consistent 
conversion, and Section 5 sumarizes our con-
version aproach. 
2 Two
Kinds of Syntactic Structure  
Two diferent aproaches to describing syntactic 
structure, dependency structure (DS) (Mel’čuk 
1979) and phrase structure (PS) (Chomsky, 
1981), have in a sense divided the field in two, 
with paralel eforts on both sides. Formaly, in a 
PS tre, al and only the leaf nodes are labeled 
186
with words from the sentence (or empty catego-
ries), while the interior nodes are labeled with 
nonterminal labels. In a dependency tre, al 
nodes are labeled with words from the sentence 
(or empty categories). Linguisticaly, a PS 
groups consecutive words hierarchicaly into 
phrases (or constituents), and each phrase is as-
signed a syntactic label. In a DS, syntactic de-
pendency (i.e., the relation betwen a syntactic 
head and its arguments and adjuncts) is the pri-
mary syntactic relation represented. The notion 
of constituent is only derived. 
 
In a dependency representation, a node stands for 
itself, for the lexical category (or “preterminal”) 
spaning only the word itself (e.g., N), and for its 
maximal projection spaning the node and al 
words in the subtre it anchors (e.g., NP). Thus, 
intermediate projections which cover only some 
of the dependents of a word (such as N’ or VP) 
do not directly corespond to anything in a de-
pendency representation. Atachments at the dif-
ferent levels of projection are therefore not dis-
tinguished in a dependency tre. This has certain 
ramifications for anotation.  Conisder for ex-
ample scope in conjunctions.  The two readings 
of young men and women can be distinguished 
(are the women young as wel or not?). If a de-
pendency representation represents conjunction 
by treating the conjunction as a dependent to the 
first conjunct, then the two readings do not re-
ceive diferent syntactic representations, unles a 
scope feature is introduced for the adjective.  
Supose y depends on x in a DS, we ned to ad-
dres the folowing questions in order to devise a 
DS-to-PS conversion algorithm that builds the 
coresponding phrase structure: 1) What kinds of 
projections do x and y have? 2) How far should y 
project before it ataches to x's projection? 3) What 
position on x's projection chain should y's projec-
tion atach to?  These questions are answered by 
the anotation manual of the target PS represen-
tation – there are many posible answers. If the 
source dependency representation contains the 
right kind of information (for example, the scope 
of adjectives in conjunctions), and if the target 
phrase structure representation is wel docu-
mented, then we can devise a conversion algo-
rithm. 
 
Another important isue is that of “non-
projectivity” which is used to represent discon-
tinuous constituents. Non-projectivity is comon 
in dependency-based syntactic theories, but rare 
in phrase structure-based theories. The next sec-
tion highlights our most salient representation 
choices in Trebank design. 
3 Treebank
Design 
Our goal is the delivery of a trebank that is 
multi-representational: it wil have a syntactic 
dependency version and a phrase structure ver-
sion. Another recent trend in trebanking is the 
adition of deper, semantic levels of anotation 
on top of the syntactic anotations of the PTB, 
for example PropBank (Palmer et al. 205).  A 
multi-layered aproach is also found in the Pra-
gue Dependency Trebank (Hajič et al. 201), or 
in trebanks based on LFG (King et al. 203) or 
HPSG (Oepen et al. 202). A leson learned here 
is that the adition of deper, more semantic lev-
els may be complicated if the syntactic anota-
tion was not designed with the posibility of mul-
tiple layers of anotation in mind. We therefore 
also propose a trebank that is from the start 
multi-layered: we wil include a PropBank-style 
predicate-argument anotation in the release. 
Crucialy, the lexical subcategorization frames 
that are made explicit during the proces of prop-
banking should always inform the syntactic 
structure of the trebanking efort. In adition, 
some of the distinctions made by PS that are not 
naturaly present in DS, such as unacusativity 
and nul arguments, are more naturaly made dur-
ing PropBank anotation. Our curent aproach 
anticipates that the adition of the PropBank an-
notation to the DS wil provide a rich enough 
structure for acurate PS conversion. 
 
In order to ensure sucesful conversion from DS 
to PS, we are simultaneously developing thre 
sets of guidelines for Hindi: dependency struc-
ture, phrase structure, and PropBank. While al-
lowing DS and PS guidelines to be based on dif-
ferent, independently motivated principles (se 
Section 4), we have ben going through a com-
prehensive list of constructions in Hindi, care-
fuly exploring any potentialy problematic is-
sues.  Specificaly, we make sure that both DS 
and PS represent the same syntactic facts (what 
is represented): we know that if PS makes a dis-
tinction that neither DS nor PropBank make, then 
we canot posibly convert automaticaly. Fur-
thermore, we cordinate the guidelines for DS 
and PS with respect to the examples chosen to 
suport the conversion proces. These examples 
form a conversion test suite. 
187
4 Syntactic
Annotation Choices 
4.1 Dependency
Structure Guidelines 
 
Our dependency analysis is based on the Pan-
inian gramatical model (Bharati et al 199, 
Sharma et al. 207). The model ofers a syntac-
tico-semantic level of linguistic knowledge with 
an especialy transparent relationship betwen 
the syntax and the semantics.  The sentence is 
treated as a series of modifier-modified relations 
which has a primary modified (generaly the 
main verb). The apropriate syntactic cues (rela-
tion markers) help in identifying various rela-
tions.  The relations are of two types – karaka 
and others. 'Karakas' are the roles of various par-
ticipants in an action (arguments). For a noun to 
hold a karaka relation with a verb, it is important 
that they (noun and verb) have a direct syntactic 
relation. Relations other than 'karaka' such as 
purpose, reason, and posesion are also captured 
using the relational concepts of the model (ad-
juncts). These argument labels are very similar in 
spirit to the verb specific semantic role labels 
used by PropBank, which have already ben suc-
cesfuly maped to richer semantic role labels 
from VerbNet and FrameNet. This sugests that 
much of the task of PropBanking can be done as 
part of the dependency anotation. 
4.2 Phrase
Structure Guidelines 
Our PS guidelines are inspired by the Principles-
and-Parameters methodology, as instantiated by 
the theoretical developments starting with Gov-
ernment and Binding Theory (Chomsky 1981). 
We asume binary branching. There are thre 
theoretical comitments/design considerations 
that underlie the guidelines. First, any minimal 
clause distinguishes at most two positions struc-
turaly (the core arguments). These positions can 
be identified as the specifier of VP and the com-
plement of V. With a transitive predicate, these 
positions are ocupied by distinct NPs while with 
an unacusative or pasive, the same NP ocu-
pies both positions. Al other NPs are represented 
as adjuncts. Second, we represent any displace-
ment of core arguments from their canonical po-
sitions, irespective of whether a clause boundary 
is crosed, via traces. The displacement of other 
arguments is only represented if a clause bound-
ary is crosed. Third, syntactic relationships such 
as agrement and case always require c-
comand but do not necesarily require a [speci-
fier, head] configuration. Within these con-
straints, we always chose the simplest structure 
compatible with the word order. We work with a 
very limited set of category labels (NP, AP, 
AdvP, VP, CP) asuming that finer distinctions 
betwen diferent kinds of verbal functional 
heads can be made via features. 
4.3 Two
Constructions in Hindi 
We give examples for two constructions in Hindi 
and show the DS and PS for each. 
Simple Transitive Clauses: 
(1) ram-ne  khir       khayi 
 ram-erg  rice-puding   ate 
 ‘Ram ate rice-puding.’ 
The two main arguments of the Hindi verb in 
Figure 1(b) have dependency types k1 and k2. 
They corespond roughly to subject and object, 
and they are the only arguments that can agre 
with the verb.  In the PS, Figure 1(a), the two 
arguments that corespond to k1 and k2 have 
fixed positions in the phrase structure as ex-
plained in Section 4.2. 
 
Figure 1: PS and DS for transitive clause in (1). 
 
Unacusative verbs: 
(2) darwaza khul  raha      hai 
   dor.M    open Prog.MSg   be.Prs.Sg 
  ‘The dor is opening.’ 
Here, the isue is that the DS guidelines treats 
unacusatives like other intransitives, with the 
surface argument simply anotated as k1.  In 
contrast, PS shows a derivation in which the sub-
ject originates in object position. 
 
 
Figure 2: PS and DS for the unacusative in (2). 
5 Conversion
Process  
The DS-to-PS conversion proces has thre 
steps. First, for each (DS, PS) pair apearing in 
the conversion test suite, we run a consistency 
188
checking algorithm to determine whether the DS 
and the PS are consistent. The inconsistent cases 
are studied manualy and if the inconsistency 
canot be resolved by changing the analyses 
used in the guidelines, a new DS that is consis-
tent with the PS is proposed. We cal this new 
dependency structure “DS
cons
” (“cons” for “con-
sistency”; DS
cons
 is the same as DS for the con-
sistent cases). Because the DS and PS guidelines 
are carefuly cordinated, we expect the incon-
sistent cases to be rare and wel-motivated. Sec-
ond, conversion rules are extracted automaticaly 
from these (DS
cons, PS) pairs. Last, given a new 
DS, a PS is created by aplying conversion rules. 
Note that non-projective DSs wil be converted 
to projective DS
cons
. (For an alternate acount of 
handling non-projective DSs, se Kuhlman and 
Möhl (207).) A preliminary study on the Eng-
lish Pen Trebank showed promising results 
and eror analyses indicated that most conversion 
erors were caused by ambiguous DS paterns in 
the conversion rules. This implies that including 
suficient information in the input DS could re-
duce ambiguity, significantly improving the per-
formance of the conversion algorithm. The de-
tails of the conversion algorithm and the experi-
mental results are described in (Xia et al., 209). 
6 Conclusion

We presented our aproach to the joint develop-
ment of DS and PS trebanks and a PropBank for 
Hindi/Urdu. Since from the inception of the pro-
ject we have planed manual anotation of DS 
and automatic conversion to PS, we are develop-
ing the anotation guidelines for al structures in 
paralel. A series of linguistic constructions with 
specific examples are being carefuly examined 
for any DS anotation decisions that might result 
in inconsistency betwen DS and PS and/or mul-
tiple conversion rules with identical DS paterns. 
Our preliminary studies yield promising results, 
indicating that cordinating the design of DS/PS 
and PropBank guidelines and runing the con-
version algorithm in the early stages is esential 
to the suces of building a multi-
representational and multi-layered trebank. 
 
Acknowledgments 
This work is suported by NSF grants CNS-
0751089, CNS-075171, CNS-0751202, and 
CNS-0751213. 
 
 
References  
A. Bharati, V. Chaitanya and R. Sangal. 199. Natu-
ral Language Procesesing: A Paninian Per-
spective, Prentice Hal of India, New Delhi. 
N. Chomsky. 1981. Lectures on Government and 
Binding: The Pisa Lectures. Holand: Foris Pub-
lications. 
M. Colins, Jan Hajič, L. Ramshaw and C. Tilman. 
199. A Statistical Parser for Czech. In the Proc 
of ACL-1999, pages 505-512. 
J. Hajič, E. Hajicova, M. Holub, P. Pajas, P. Sgal, B. 
Vidova-Hladka, and V. Reznickova. 201. The 
Curent Status of the Prague Dependency Tree-
bank. Lecture Notes in Artificial Inteligence 
(LNAI) 216, p 1—20, NY. 
T. H. King, R. Crouch, S. Riezler, M. Dalrymple and 
R. Kaplan. 203. The PARC70 Dependency 
Bank. In Proc. of the 4th Int’ Workshop on 
Linguisticaly Interpreted Corpora (LINC-
203), Budapest, Hungary. 
D. Klein and C. D. Maning. 203. Acurate Unlexi-
calized Parsing. In the Proc of ACL-2003,.Japan 
M. Kuhlman and M. Möhl. 207. Mildly context-
sensitive dependency language. In the Proc of 
ACL 207. Prague, Czech Republic. 
R. McDonald, F. Pereira, K. Ribarov and J. Hajič. 
205.  Non-Projective Dependency Parsing using 
Spaning Tre Algorithms. In Proc. of HLT-
EMNLP 205. 
I. Melčuk. 1979. Studies in Dependency Syntax. 
Karoma Publishers, Inc. 
S. Oepen, K. Toutanova, S. M. Shieber, C. D. Man-
ning, D. Flickinger, and T. Brants, 202. The 
LinGO Redwods Trebank: Motivation and Pre-
liminary Aplications. In Proc. of COLING, 
2002. Taipei, Taiwan. 
M. Palmer, D. Gildea, P. Kingsbury. 205. The 
Proposition Bank: An Anotated Corpus of Seman-
tic Roles.Computational Linguistics, 31(1):71-
106. 
D. M. Sharma, R. Sangal, L. Bai, R. Begam, and K.V. 
Ramakrishnamacharyulu. 207. AnCora : 
TreBanks for Indian Languages, Anotation 
Guidelines (manuscript), IIT, Hyderabad, India. 
 
F. Xia, O. Rambow, R. Bhat, M. Palmer and D. 
Sharma, 209. Towards a Multi-Representational 
Trebank. In Proc. of the 7th Int’lWorkshop on 
Trebanks and Linguistic Theories (TLT-7). 
 
189

