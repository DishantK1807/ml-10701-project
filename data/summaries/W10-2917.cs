al., 2005; Moore, 2005; Cherry and Lin, 2006;
H05-1011 P06-2014
BerkeleyAligner (Liang et al., 2006) (Berke-
N06-1014
tions; Liu et al. (2005) and Taskar et al. (2005)
H05-1010 P05-1057
Haghighi et al., 2009).
P09-1104
HuaWu, HaifengWang, andZhanyiLiu. 2006. Boost-
P06-2117
Yang Liu, Qun Liu, and Shouxun Lin. 2005. Log-
P05-1057
Moses (Koehn et al., 2003) is used for decoding.
N03-1017
Necip Fazil Ayan and Bonnie J. Dorr. 2006. A max-
N06-1013
While Ayan and Dorr (Ayan and Dorr, 2006)
N06-1013
Alexander Fraser and Daniel Marcu. 2006. Semi-
P06-1097
used (Taskar et al., 2005; Cherry and Lin, 2006;
H05-1010 P06-2014
sify unseen test data (Liu et al., 2005; Taskar et
P05-1057
Ayan and Dorr (2006) propose another way of
N06-1013
EM style algorithm (Brown et al., 1993; Vogel
J93-2003
Percy Liang, Benjamin Taskar, and Dan Klein. 2006.
N06-1014
Haghighi et al., 2009). For alignment ensemble,
P09-1104
Taskar et al. (2005) also employ similar bi-lexical
H05-1010
ingframeworkofAyanandDorr(2006). Although
N06-1013
help the task. For example, Moore (2005) uses
H05-1011
In this paper, we follow Ayan and Dorr (2006)â€™s
N06-1013
Robert C. Moore. 2005. A discriminative framework
H05-1011
Aria Haghighi, John Blitzer, and Dan Klein. 2009.
P09-1104
learning of word alignment. Liu et al. (2005)
P05-1057
Colin Cherry and Dekang Lin. 2006. Soft syntactic
P06-2014
Moore (2005). We estimate these counts on
H05-1011
Franz Josef Och and Hermann Ney. 2003. A sys-
J03-1002
et al., 1996; Och and Ney, 2003). Recently, su-
J03-1002
Moore (2005) proposes a similar framework, but
H05-1011
ditional link probability (Moore, 2005) of ei
H05-1011
beled data, respectively. Wu et al. (2006) propose
P06-2117
alignment, Callison-Burch et al. (2004) compare
P04-1023
