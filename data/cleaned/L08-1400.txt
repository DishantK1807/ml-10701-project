<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<title>Applying machine learning for high performance named-entity extraction. In Pacific Association for Computational Linguistics</title>
<date>1999</date>
<marker>1999</marker>
<rawString>1999. Applying machine learning for high performance named-entity extraction. In Pacific Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D M Bikel</author>
<author>S Miller</author>
<author>R Schwartz</author>
<author>R Weischedel</author>
</authors>
<title>Nymble: a high-performance learning namefinder</title>
<date>1997</date>
<booktitle>In Proc. 5th Conference on Applied Natural Language Processing (ANLP-97</booktitle>
<contexts>
<context>o not naturally address the sequential nature of the problem, they have largely given way to approaches that model labeling as a series of related decisions, in particular hidden Markov models (HMM) (Bikel et al., 1997), structured perceptrons (Collins, 2002), and conditional random fields (CRF) (McCallum and Li, 2003). The last two approaches are particularly appealing, because in contrast to generative approaches</context>
</contexts>
<marker>Bikel, Miller, Schwartz, Weischedel, 1997</marker>
<rawString>D.M. Bikel, S. Miller, R. Schwartz, and R. Weischedel. 1997. Nymble: a high-performance learning namefinder. In Proc. 5th Conference on Applied Natural Language Processing (ANLP-97), April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Borthwick</author>
</authors>
<title>A Maximum Entropy Approach to Named Entity Recognition</title>
<date>1999</date>
<tech>Ph.D. thesis</tech>
<institution>New York University</institution>
<contexts>
<context>eously. All of the approaches that have been tried for problems like part-of-speech have also been applied to NER, including decision trees (Baluja et al., 1999), log-linear models (maximum entropy) (Borthwick, 1999), and support vector machines (Isozaki and Kazawa, 2002). However, inasmuch as these paradigms do not naturally address the sequential nature of the problem, they have largely given way to approaches</context>
</contexts>
<marker>Borthwick, 1999</marker>
<rawString>A. Borthwick. 1999. A Maximum Entropy Approach to Named Entity Recognition. Ph.D. thesis, New York University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Buckwalter</author>
</authors>
<title>Buckwalter Arabic Morphological Analyzer Version 2.0. Linguistic Data Consortium</title>
<date>2004</date>
<booktitle>LDC Cat alog No.: LDC2004L02, ISBN</booktitle>
<pages>1--58563</pages>
<institution>University of Pennsylvania</institution>
<contexts>
<context>r/them’. To model Arabic morphology, we use the BAMA morphological analyzer and the MADA system for morphological disambiguation. 3.2. BAMA We use the Buckwalter Arabic Morphological Analyzer (BAMA) (Buckwalter, 2004), to obtain all possible word analyses. BAMA models Arabic morphology for over 35K lexemes. The number of possible fully diacritized forms per lexeme varies from 3K forms for nouns to 17K forms for v</context>
</contexts>
<marker>Buckwalter, 2004</marker>
<rawString>Tim Buckwalter. 2004. Buckwalter Arabic Morphological Analyzer Version 2.0. Linguistic Data Consortium, University of Pennsylvania, 2002. LDC Cat alog No.: LDC2004L02, ISBN 1-58563-324-0.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for hidden Markov models: theory and experiments with perceptron algorithms</title>
<date>2002</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context> of the problem, they have largely given way to approaches that model labeling as a series of related decisions, in particular hidden Markov models (HMM) (Bikel et al., 1997), structured perceptrons (Collins, 2002), and conditional random fields (CRF) (McCallum and Li, 2003). The last two approaches are particularly appealing, because in contrast to generative approaches like HMMs, they make no unwarranted ind</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative training methods for hidden Markov models: theory and experiments with perceptron algorithms. In Proceedings of EMNLP 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dayne Freitag</author>
</authors>
<title>Trained named entity recognition using distributional clusters</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context>er words observed to have occurred in their close context, then clustered in a way that heuristically minimizes information loss. Several studies have documented the utility of such features for NER (Freitag, 2004; Miller et al., 2004), and our informal experiments confirm their considerable benefit in the processing of Arabic. As with word identity, there are different cluster-membership features for every po</context>
</contexts>
<marker>Freitag, 2004</marker>
<rawString>Dayne Freitag. 2004. Trained named entity recognition using distributional clusters. In Proceedings of EMNLP 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
</authors>
<title>Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05</booktitle>
<pages>573--580</pages>
<location>Ann Arbor, Michigan</location>
<contexts>
<context> Figure 1: Three BAMA analyses for the word A9G9AU AA C3 BA byn. 3.3. MADA MADA, The Morphological Analysis and Disambiguation for Arabic tool, is an off-the-shelf resource for Arabic disambiguation (Habash and Rambow, 2005; Habash, 2007). MADA selects among BAMA analyses using a combination of classifiers that tag words on all 14 orthogonal dimensions of Arabic morphology. The version of MADA used in this paper was tra</context>
</contexts>
<marker>Habash, Rambow, 2005</marker>
<rawString>Nizar Habash and Owen Rambow. 2005. Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 573–580, Ann Arbor, Michigan, June. Association for Computational Linguistics. Nizar Habash, Abdelhadi Soudi, and Tim Buckwalter.</rawString>
</citation>
<citation valid="true">
<title>On Arabic Transliteration</title>
<date>2007</date>
<booktitle>Arabic Computational Morphology: Knowledge-based and Empirical Methods</booktitle>
<editor>In A. van den Bosch and A. Soudi, editors</editor>
<publisher>Springer</publisher>
<marker>2007</marker>
<rawString>2007. On Arabic Transliteration. In A. van den Bosch and A. Soudi, editors, Arabic Computational Morphology: Knowledge-based and Empirical Methods. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
</authors>
<title>Arabic Morphological Representations for Machine Translation</title>
<date>2007</date>
<booktitle>Arabic Computational Morphology: Knowledge-based and Empirical Methods</booktitle>
<editor>In A. van den Bosch and A. Soudi, editors</editor>
<publisher>Springer</publisher>
<contexts>
<context>lyses for the word A9G9AU AA C3 BA byn. 3.3. MADA MADA, The Morphological Analysis and Disambiguation for Arabic tool, is an off-the-shelf resource for Arabic disambiguation (Habash and Rambow, 2005; Habash, 2007). MADA selects among BAMA analyses using a combination of classifiers that tag words on all 14 orthogonal dimensions of Arabic morphology. The version of MADA used in this paper was trained on the Pe</context>
</contexts>
<marker>Habash, 2007</marker>
<rawString>Nizar Habash. 2007. Arabic Morphological Representations for Machine Translation. In A. van den Bosch and A. Soudi, editors, Arabic Computational Morphology: Knowledge-based and Empirical Methods. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Isozaki</author>
<author>H Kazawa</author>
</authors>
<title>Efficient support vector classifiers for named entity recognition</title>
<date>2002</date>
<booktitle>In Proceedings of COLING 2002. Mohamed Maamouri</booktitle>
<location>Ann</location>
<contexts>
<context>ied for problems like part-of-speech have also been applied to NER, including decision trees (Baluja et al., 1999), log-linear models (maximum entropy) (Borthwick, 1999), and support vector machines (Isozaki and Kazawa, 2002). However, inasmuch as these paradigms do not naturally address the sequential nature of the problem, they have largely given way to approaches that model labeling as a series of related decisions, i</context>
</contexts>
<marker>Isozaki, Kazawa, 2002</marker>
<rawString>H. Isozaki and H. Kazawa. 2002. Efficient support vector classifiers for named entity recognition. In Proceedings of COLING 2002. Mohamed Maamouri, Ann Bies, and Tim Buckwalter.</rawString>
</citation>
<citation valid="true">
<title>The Penn Arabic Treebank: Building a large-scale annotated Arabic corpus</title>
<date>2004</date>
<booktitle>In NEMLAR Conference on Arabic Language Resources and Tools</booktitle>
<location>Cairo, Egypt</location>
<marker>2004</marker>
<rawString>2004. The Penn Arabic Treebank: Building a large-scale annotated Arabic corpus. In NEMLAR Conference on Arabic Language Resources and Tools, Cairo, Egypt.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A McCallum</author>
<author>W Li</author>
</authors>
<title>Early results for named entity recognition with conditional random fields</title>
<date>2003</date>
<booktitle>In Proceedings of the Seventh Conference on Natural Language Learning (CoNLL</booktitle>
<contexts>
<context>aches that model labeling as a series of related decisions, in particular hidden Markov models (HMM) (Bikel et al., 1997), structured perceptrons (Collins, 2002), and conditional random fields (CRF) (McCallum and Li, 2003). The last two approaches are particularly appealing, because in contrast to generative approaches like HMMs, they make no unwarranted independence assumptions, and can therefore fruitfully incorpora</context>
</contexts>
<marker>McCallum, Li, 2003</marker>
<rawString>A. McCallum and W. Li. 2003. Early results for named entity recognition with conditional random fields. In Proceedings of the Seventh Conference on Natural Language Learning (CoNLL 2003).</rawString>
</citation>
</citationList>
</algorithm>

