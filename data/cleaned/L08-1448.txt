<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>ELDA</author>
</authors>
<title>Evaluations and Language resources Distribution Agency, Home Page http://www.elda.org</title>
<contexts>
<context>t appropriate models and features are being used in the processing of the speech data. For data-handling institutions such as ELDA (the European Evaluations and Language-resources Distribution Agency [1]) and LDC (the US Linguistic Data Consortium [2]) whose main role is the collection and distribution of large volumes of speech data, there is little need for any single staff member to become familia</context>
</contexts>
<marker>[1]</marker>
<rawString>ELDA Evaluations and Language resources Distribution Agency, Home Page http://www.elda.org</rawString>
</citation>
<citation valid="true">
<title>The Linguistic Data Consortium, Home Page http://www.ldc.upenn.edu</title>
<contexts>
<context> in the processing of the speech data. For data-handling institutions such as ELDA (the European Evaluations and Language-resources Distribution Agency [1]) and LDC (the US Linguistic Data Consortium [2]) whose main role is the collection and distribution of large volumes of speech data, there is little need for any single staff member to become familiar with the stylistic contents of any individual </context>
</contexts>
<marker>[2]</marker>
<rawString>The Linguistic Data Consortium, Home Page http://www.ldc.upenn.edu/</rawString>
</citation>
<citation valid="true">
<title>The NIST Rich Transcription Evaluation Project, Meeting Recognition Evaluation, Documentation</title>
<note>http://www.nist.gov/speech/tests/rt/rt2002</note>
<contexts>
<context>r the display and retrieval of multi-modal data. 2. Browser Technologies With the growing recent interest in processing multimodal interaction, beginning with projects such as NIST Rich Transcription [3], AMI [4], and CHIL [5], there has been considerable research into collecting and annotating very large corpora of audio and visual information related to human spoken interactions [6], and subsequent</context>
</contexts>
<marker>[3]</marker>
<rawString>The NIST Rich Transcription Evaluation Project, Meeting Recognition Evaluation, Documentation. http://www.nist.gov/speech/tests/rt/rt2002/</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carlette</author>
<author>et al</author>
</authors>
<date>2005</date>
<booktitle>The AMI Meeetings Corpus , in proc Symposium on Annotating and Measuring Meeting Behaviour</booktitle>
<contexts>
<context>play and retrieval of multi-modal data. 2. Browser Technologies With the growing recent interest in processing multimodal interaction, beginning with projects such as NIST Rich Transcription [3], AMI [4], and CHIL [5], there has been considerable research into collecting and annotating very large corpora of audio and visual information related to human spoken interactions [6], and subsequently huge e</context>
</contexts>
<marker>[4]</marker>
<rawString>Carlette, J., et.al.,  The AMI Meeetings Corpus , in proc Symposium on Annotating and Measuring Meeting Behaviour, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Waibel</author>
<author>H Steusloff</author>
<author>R Stiefelhagen</author>
</authors>
<title>CHIL Computers in the human interaction loop , 5th international workshop on image analysis for multimedia interactive services</title>
<date>2004</date>
<location>Lisbon</location>
<contexts>
<context>eval of multi-modal data. 2. Browser Technologies With the growing recent interest in processing multimodal interaction, beginning with projects such as NIST Rich Transcription [3], AMI [4], and CHIL [5], there has been considerable research into collecting and annotating very large corpora of audio and visual information related to human spoken interactions [6], and subsequently huge efforts into mi</context>
</contexts>
<marker>[5]</marker>
<rawString>Waibel, A., Steusloff, H., and Stiefelhagen, R.,  CHIL Computers in the human interaction loop , 5th international workshop on image analysis for multimedia interactive services, Lisbon, April 2004.</rawString>
</citation>
</citationList>
</algorithm>

