Finite-State Registered Automata
for Non-Concatenative Morphology
Yael Cohen-Sygal
∗
University of Haifa
Shuly Wintner
†
University of Haifa
We introduce finite-state registered automata (FSRAs), a new computational device within the
framework of finite-state technology, specifically tailored for implementing non-concatenative
morphological processes. This model extends and augments existing finite-state techniques,
which are presently not optimized for describing this kind of phenomena. We first define the
model and discuss its mathematical and computational properties. Then, we provide an extended
regular language whose expressions denote FSRAs. Finally, we exemplify the utility of the model
by providing several examples of complex morphological and phonological phenomena, which are
elegantly implemented with FSRAs.
1. Introduction
Finite-state (FS) technology has been considered adequate for describing the morpho-
logical processes of the world’s languages since the pioneering works of Koskenniemi
(1983) and Kaplan and Kay (1994). Several toolboxes provide extended regular expres-
sion description languages and compilers of the expressions to finite-state automata
(FSAs) and transducers (FSTs) (Karttunen et al. 1996; Mohri 1996; van Noord and
Gerdemann 2001a). While FS approaches to most natural languages have generally been
very successful, it is widely recognized that they are less suitable for non-concatenative
phenomena; in particular, FS techniques are assumed not to be able to efficiently account
for the non-concatenative word formation processes that Semitic languages exhibit
(Lavie et al. 1988).
While much of the inflectional morphology of Semitic languages can be rather
straightforwardly described using concatenation as the primary operation, the main
word formation process in such languages is inherently non-concatenative. The stan-
dard account describes words in Semitic languages as combinations of two morphemes:
a root and a pattern.
1
The root consists of consonants only, by default three (although
longer roots are known). The pattern is a combination of vowels and, possibly, con-
sonants too, with “slots” into which the root consonants can be inserted. Words are
created by interdigitating roots into patterns: The first consonant of the root is inserted
into the first consonantal slot of the pattern, the second root consonant fills the second
slot, and the third fills the last slot. After the root combines with the pattern, some
∗ Department of Computer Science, University of Haifa, 31905 Haifa, Israel. E-mail: yaelc@cs.haifa.ac.il.
† Department of Computer Science, University of Haifa, 31905 Haifa, Israel. E-mail: shuly@cs.haifa.ac.il.
1 An
additional morpheme, vocalization, is used to abstract the pattern further; for the present purposes,
this distinction is irrelevant.
Submission received: 17 August 2004; revised submission received: 15 June 2005; accepted for publication: 26
September 2005.
© 2006 Association for Computational Linguistics
Computational Linguistics Volume 32, Number 1
Figure 1
Na¨ıve FSA with duplicated paths.
morpho-phonological alternations take place, which may be non-trivial but are mostly
concatenative.
The major problem that we tackle in this work is medium-distance dependencies,
whereby some elements that are related to each other in some deep-level representation
(e.g., the consonants of the root) are separated on the surface. While these phenomena
do not lie outside the descriptive power of FS systems, na¨ıvely implementing them in
existing finite-state calculi is either impossible or, at best, results in large networks that
are inefficient to process, as the following examples demonstrate.
Example 1
We begin with a simplified problem, namely accounting for circumfixes. Consider three
Hebrew patterns: hasquaresquareasquarea, hitsquareasquareasquareut,andmisquaresquareasquare, where the empty boxes indi-
cate the slots in the patterns into which the consonants of the roots are inserted. Hebrew
orthography
2
dictates that these patterns be written hsquaresquaresquarea, htsquaresquaresquareut,andmsquaresquaresquare,re-
spectively, i.e., the consonants are inserted into the ‘square’ slots as one unit (i.e., the patterns
can be viewed as circumfixes). An automaton that accepts all the possible combinations
of three-consonant stems and these three circumfixes is illustrated in Figure 1.
3
Given r
stems and p circumfixes, the number of its states is (2r + 2)p + 2, i.e., increases linearly
with the number of stems and circumfixes. The number of arcs in this automaton is
3rp + 2p,i.e,alsoO(rp). Evidently, the three basic different paths that result from the
three circumfixes have the same body, which encodes the stems. An attempt to avoid
the duplication of paths is represented by the automaton of Figure 2, which accepts the
language denoted by the regular expression (ht + h + m)(root)(ut + a +epsilon1). The number
of states here is 2r + 4, i.e., is independent of the number of circumfixes. The number
of arcs is (3r + 2p), that is, O(r + p), and thus, the complexity of the number of arcs is
also reduced. Obviously, however, such an automaton over-generates by accepting also
invalid words such as msquaresquaresquareut. In other words, it ignores the dependencies which hold
between prefixes and suffixes of the same circumfix. Since finite-state devices have no
2 Many
of the vowels are not explicitly depicted in the Hebrew script.
3 This
is an over-simplified example; in practice, the process of combining roots with patterns is highly
idiosyncratic, like other derivational morphological processes.
50
Cohen-Sygal and Wintner Non-Concatenative Morphology
Figure 2
Over-generating FSA.
memory, save for the states, there is no simple and space-efficient way to account for
such dependencies.
Example 2
Consider now a representation of Hebrew where all vowels are explicit, e.g., the pattern
hitsquareasquareesquare. Consider also the roots r.g.z, b.$.l,andg.b.r. The consonants of a given root
are inserted into the ‘square’ slots to obtain bases such as hitragez, hitba$el,andhitgaber.The
finite state automaton of Figure 3 is the minimized automaton accepting the language;
it has fifteen states. If the number of three letter roots is r, then a general automaton
accepting the combinations of the roots with this pattern will have 4r + 3 states and 5r +
1 arcs. Notice the duplicated arcs which stem from copying the pattern in the different
paths.
Example 3
Another non-concatenative process is reduplication: The process in which a morpheme
or part of it is duplicated. Full reduplication is used as a pluralization process in Malay
and Indonesian; partial reduplication is found in Chamorro to indicate intensivity. It
can also be found in Hebrew as a diminutive formation of nouns and adjectives:
keleb klablab $apan $panpan zaqan zqanqan $axor $xarxar
dog puppy rabbit bunny beard goatee black dark
qatan qtantan
little tiny
Let Σ be a finite alphabet. The language L = {ww | w ∈ Σ
∗
} is known to be
trans-regular, therefore no finite-state automaton accepts it. However, the language
L
n
= {ww | w ∈ Σ
∗, |w| = n} for some constant n is regular. Recognizing L
n
is a finite
approximation of the general problem of recognizing L. The length of the words in
natural languages can in most cases be bounded by some n ∈ N, hence the amount
of reduplication in natural languages is practically limited. Therefore, the descriptive
power of L
n
is sufficient for the amount of reduplication in natural languages (by
Figure 3
FSA for the pattern hitsquareasquareesquare.
51
Computational Linguistics Volume 32, Number 1
constructing L
n
for a small number of different ns). An automaton that accepts L
n
can
be constructed by listing a path for each accepted string (since Σ and n are finite, the
number of words in L
n
is finite). The main drawback of such an automaton is the
growth in its size as |Σ| and n increase: The number of strings in L
n
is |Σ|
n
. Thus, finite-
state techniques can account for limited reduplication, but the resulting networks are
space-inefficient.
As a final, non-linguistic, motivating example, consider the problem of n-bit incre-
mentation, introduced by Kornai (1996).
Example 4
The goal of this example is to construct a transducer over Σ={0, 1} whose input is a
32 bit binary number and whose output is the result of adding 1 to the input. A
transducer that performs addition by 1 on binary numbers has only 5 states and 12 arcs,
4
but this transducer is neither sequential nor sequentiable. The problem is that since the
input is scanned left to right but the carry moves right to left, the output of the first bit
has to be delayed, possibly even until the last input bit is scanned. Thus, for an n-bit
binary incrementor, 2
n
disjunctions have to be considered, and therefore a minimized
transducer has to assign a separate state to each combination of bits, resulting in 2
n
states and a similar number of transitions.
In this work we propose a novel FS model which facilitates the expression of
medium-distance dependencies such as interdigitation and reduplication in an efficient
way. Our main motivation is theoretical, i.e., reducing the complexity of the number
of states and arcs in the networks; we show that these theoretical contributions result
in practical improvements. In Section 3 we define the model formally, show that it is
equivalent to FSAs and define many closure properties directly.
5
We then (Section 4)
define a regular expression language for denoting FSRAs. In Section 5 we provide dedi-
cated regular expression operators for some non-concatenative phenomena and exem-
plify the usefulness of the model by efficiently accounting for the motivating examples.
In Section 6 we extend FSRAs to transducers. The model is evaluated through an actual
implementation in Section 7. We conclude with suggestions for future research.
2. Related Work
In spite of the common view that FS technology is in general inadequate for describing
non-concatenative processes, several works address the above-mentioned problems in
various ways. We summarize existing approaches in this section.
Several works examine the applicability of traditional two-level systems for imple-
menting non-concatenative morphology. Two-Level Morphology was used by Kataja
and Koskenniemi (1988) to create a rule system for phonological and morphophonolog-
ical alternations in Akkadian, accounting for word inflection and regular verbal deriva-
tion. As this solution effectively defines lexical representations of word-forms, its main
disadvantage is that the final network is the na¨ıve one, suffering from the space com-
plexity problems discussed above. Lavie et al. (1988) examine the applicability of Two-
4 A
complete explanation of the construction can be found in http://www.xrce.xerox.com/competencies/
content-analysis/fsCompiler/fsexamples.html#Add1.
5 Many
of the formal proofs and constructions, especially the ones that are similar to the case of standard
FSAs, are suppressed; see Cohen-Sygal (2004) for the complete proofs and constructions.
52
Cohen-Sygal and Wintner Non-Concatenative Morphology
Level Morphology to the description of Hebrew Morphology, and in particular to verb
inflection. Their lexicon consists of three parts: verb primary bases (the past tense, third
person, singular, masculine), verb prefixes, and verb suffixes. They attempt to describe
Hebrew verb inflection as a concatenation of prefix+base+suffix, implementable by the
Two-Level model. However, they conclude that “The Two-Level rules are not the natural
waytodescribe...verb inflection process. The only alternative choice ...is to keep all
bases ...it seems wasteful to save all the secondary bases of verbs of the same pattern.”
Other works deal with non-concatenative morphology by extending ordinary FSAs
without extending their expressivity. The traditional two-level model of Koskenniemi
(1983) is expanded into n-tape automata by Kiraz (2000), following the insight of Kay
(1987) and Kataja and Koskenniemi (1988). The idea is to use more than two levels of
expression: The surface level employs one representation, but the lexical form employs
multiple representations (e.g., root, pattern) and therefore can be divided into different
levels, one for each representation. Elements that are separated on the surface (such as
the root’s consonants) are adjacent on a particular lexical level. For example, to describe
circumfixation using this model, a 4-tape automaton of the form 〈surface, PR pattern,
circumfix, stem〉 is constructed, so that each word is represented by 4 levels. The surface
level represents the final form of the word. The PR pattern is the pattern in which
the stem and the circumfix are combined (P represents the circumfix’s position and
R the root letter’s position), e.g., PRRRP. The circumfix and stem levels represent the
circumfix and the stem respectively.
For example, combining the Hebrew stem pqd with the circumfix ht-ut will have
the 4-level representation shown in Figure 4. Notice that the symbols representing the
circumfix in the PR pattern level (i.e., the occurrences of the symbol ‘P’), the circumfix
symbols in the circumfix level, and the circumfix symbols in the surface level are located
in correlating places in the different levels. The same holds for the stem symbols. In
this way, it is clear which symbols of the surface word belong to the circumfix, which
belong to the stem, and how they combine together to create the final form of the word.
The 4-tape automaton of Figure 5 accepts all the combinations created by circumfixing
roots with the three circumfixes of Example 1. Each arc is attributed with a quadruplet,
consisting of four correlating symbols in the four levels. Notice that as in FSAs, the paths
encoding the roots are duplicated for each circumfix, so that this automaton is as space-
inefficient as ordinary FSAs. Kiraz (2000) does not discuss the space complexity of this
model, but the number of states still seems to increase with the number of roots and
patterns. Moreover, the n-tape model requires specification of dependencies between
symbols in different levels, which may be non-trivial.
Walther (2000a) suggests a solution for describing natural language reduplication
using finite-state methods. The idea is to enrich finite-state automata with three new
operations: repeat, skip,andself loops. Repeat arcs allow moving backwards within a
string and thus repeat a part of it (to model reduplication). Skip arcs allow moving
forwards in a string while suppressing the spell out of some of its letters; self loop arcs
model infixation. In Walther (2000b), the above technique is used to describe Temiar
Figure 4
4-tape representation for the Hebrew word htpqdut.
53
Computational Linguistics Volume 32, Number 1
Figure 5
4-tape automaton for circumfixation example.
reduplication, but no complexity analysis of the model is given. Moreover, this tech-
nique does not seem to be able to describe interdigitation.
Beesley and Karttunen (2000) describe a technique, called compile-replace,for
constructing FSTs, which involves reapplying the regular-expression compiler to its
own output. The compile-replace algorithm facilitates a compact definition of non-
concatenative morphological processes, but since such expressions compile to the na¨ıve
networks, no space is saved. Furthermore, this is a compile-time mechanism rather than
a theoretical and mathematically founded solution.
Other works extend the FS model by enabling some sort of context-sensitivity. Blank
(1985, 1989) presents a model, called Register Vector Grammar, introducing context-
sensitivity by representing the states and transitions of finite-state automata as ternary-
valued vectors, which need not be fully specified. No formal properties of this model are
discussed. In a similar vein, Kornai (1996) introduces vectorized finite-state automata,
where both the states and the transitions are represented by vectors of elements of
a partially ordered set. The vectors are manipulated by operations of unification and
overwriting. The vectors need not be fully determined, as some of the elements can
be unknown (free). In this way information can be moved through the transitions by
the overwriting operation and traversing these transitions can be sanctioned through
the unification operation. As one of the examples of the advantages of this model,
Kornai (1996) shows it can efficiently solve the problem of 32-bit binary incrementor
(Example 4). Using vectorized finite-state automata, a 32-bit incrementor is constructed
where first, using overwriting, the input is scanned and stored in the vectors, and
then, using unification, the result is calculated where the carry can be computed from
right to left. We return to this example in example 6, where we show how our own
model can solve it efficiently. The formalism presented by Kornai (1996) allows a
significant reduction in the network size, but its main disadvantage lies in the fact
that it significantly deviates from the standard methodology of developing finite-state
devices, and integration of vectorized automata with standard ones remains a challenge.
Moreover, it is unclear how, for a given problem, the corresponding network should be
constructed: Programming with vectorized automata seems to be unnatural, and no
regular expression language is provided for them.
A more general approach to the design of finite-state machines is introduced by
Mohri, Pereira, and Riley (2000). They introduce an object-oriented library for manipu-
54
Cohen-Sygal and Wintner Non-Concatenative Morphology
lating finite-state devices that is based on the algebraic concepts of rational power series
and semirings. This approach facilitates a high degree of generality as the algorithms
are defined for the general algebraic notions, which can then be specialized according
to the needs of the user. They exemplify the usefulness of this library by showing how to
specialize it for the manipulation of weighted automata and transducers. Our work can
be seen as another specialization of this general approach, tailored for ideally dealing
with our motivating examples.
Several works introduce the notion of registers, whether for solving similar prob-
lems or motivated by different considerations. Krauwer and des Tombe (1981) refer
to transducers with a finite number of registers when comparing transducers and
context free grammars with respect to their capabilities to describe languages. They
sketch a proof showing that such transducers are equivalent to ordinary finite-state
transducers. However, they never formally define the model and do not discuss its
ability to efficiently implement non-concatenative natural languages phenomena. More-
over, they do not show how the closure properties can be implemented directly on
these registered transducers, and do not provide any regular language denoting such
transducers.
Motivated by different considerations, Kaminski and Francez (1994) present a com-
putational model which extends finite state automata to the case of infinite alphabets.
This model is limited to recognizing only regular languages over infinite alphabets
while maintaining closure under Kleene star and boolean operations, with the excep-
tion of closure under complementation. The familiar automaton is augmented with
registers, used to store alphabet symbols, whose number is fixed for each automa-
ton and can vary from one automaton to another. The model is designed to deal
with infinite alphabets, and therefore it cannot distinguish between different symbols;
it can identify different patterns but cannot distinguish between different symbols
in the pattern as is often needed in natural languages. Our solution is reminiscent
of Kaminski and Francez (1994) in the sense that it augments finite-state automata
with finite memory (registers) in a restricted way, but we avoid the above-mentioned
problem. In addition, our model supports a register alphabet that differs from the
language alphabet, allowing the information stored in the registers to be more mean-
ingful. Moreover, our transition relation is a more simplified extension of the stan-
dard one in FSAs, rendering our model a conservative extension of standard FSAs
and allowing simple integration of existing networks with networks based on our
model.
Finally, Beesley (1998) directly addresses medium-distance dependencies between
separated morphemes in words. He proposes a method, called flag diacritics, which adds
features to symbols in regular expressions to enforce dependencies between separated
parts of a string. The dependencies are forced by different kinds of unification actions.
In this way, a small amount of finite memory is added, keeping the total size of the
network relatively small. Unfortunately, this method is not formally defined, nor are
its mathematical and computational properties proved. Furthermore, flag diacritics are
manipulated at the level of the extended regular expressions, although it is clear that
they are compiled into additional memory and operators in the networks themselves.
The presentations of Beesley (1998) and Beesley and Karttunen (2003) do not explicate
the implementation of such operators and do not provide an analysis of their com-
plexity. Our approach is similar in spirit, but we provide a complete mathematical and
computational analysis of such extended networks, including a proof that the model
is indeed regular and constructions of the main closure properties. We also provide
dedicated regular expression operations for non-concatenative processes and show
55
Computational Linguistics Volume 32, Number 1
how they are compiled into extended networks, thereby accounting for the motivating
examples.
3. Finite-state Registered Automata
We define a new model, finite-state registered automata (FSRA), aimed at facilitating
the expression of various non-concatenative morphological phenomena in an efficient
way. The model augments finite-state automata with finite memory (registers) in a
restricted way that saves space but does not add expressivity. The number of registers
is finite, usually small, and eliminates the need to duplicate paths as it enables the
automaton to “remember” a finite number of symbols. In addition to being associated
with an alphabet symbol, each arc is also associated with an action on the registers.
There are two kinds of actions, read and write. The read action, denoted R, allows
traversing an arc only if a designated register contains a specific symbol. The write
action, denoted W, allows traversing an arc while writing a specific symbol into a
designated register. In this section we define FSRAs and show that they are equivalent
to standard FSAs (Section 3.1). We then directly define several closure operations over
FSRAs (Section 3.2) and provide some optimizations in Section 3.3. We conclude this
section with a discussion of minimization (Section 3.4).
3.1 Definitions
and Examples
Definition
A finite-state registered automaton (FSRA) is a tuple A = 〈Q, q
0,Σ,Γ, n,δ, F〉, where:
a114
Q is a finite set of states.
a114
q
0
∈ Q is the initial state.
a114
Σ is a finite alphabet (the language alphabet).
a114
n ∈ N (indicating the number of registers).
a114
Γ is a finite alphabet including the symbol ‘#’ (the registers alphabet).
We use meta-variables u
i, v
i
to range over Γ and u, v to range over Γ
n
.
a114
The initial content of the registers is #
n, meaning that the initial value
of all the registers is ‘empty’.
a114
δ ⊆ Q ×Σ∪{epsilon1}×{R, W}×{0, 1, 2,..., n − 1}×Γ× Q is the transition
relation. The intuitive meaning of δ is as follows:
– (s,σ, R, i,γ, t) ∈ δ where i > 0 implies that if A is in state s, the input
symbol is σ, and the content of the i-th register is γ, then A may
enter state t.
– (s,σ, W, i,γ, t) ∈ δ where i > 0 implies that if A is in state s and the
input symbol is σ, then the content of the i-th register is changed
into γ (overwriting whatever was there before) and A may enter
state t.
– (s,σ, R,0,#,t) implies that if A is in state s and the input symbol is σ,
then A may enter state t. Notice that the content of register number 0
is always #. We use the shorthand notation (s,σ, t) for such transitions.
a114
F ⊆ Q is the set of final states.
56
Cohen-Sygal and Wintner Non-Concatenative Morphology
Definition
A configuration of A is a pair (q, u), where q ∈ Q and u ∈ Γ
n
(q is the current state
and u represents the registers content). The set of all configurations of A is denoted by
Q
c
. The pair q
c
0
= (q
0,#
n
) is called the initial configuration, and configurations with the
first component in F are called final configurations. The set of final configurations is
denoted by F
c
.
Definition
Let u = u
0
u
1
...u
n−1
and v = v
0
v
1
...v
n−1
. Given a symbol α ∈ Σ∪{epsilon1} and an FSRA
A, we say that a configuration (s, u) produces a configuration (t, v), denoted (s, u) turnstileleft
α,A
(t, v), iff either one of the following holds:
a114
There exists i,0≤ i ≤ n − 1, and there exists γ ∈ Γ, such that (s,α, R, i,γ, t) ∈
δ and u = v and u
i
= v
i
= γ;or
a114
There exists i,0≤ i ≤ n − 1, and there exists γ ∈ Γ, such that (s,α, W, i,γ, t) ∈
δ and for all k, k ∈{0, 1,..., n − 1}, such that k negationslash= i, u
k
= v
k
and v
i
= γ.
Informally, a configuration c
1
produces a configuration c
2
iff the automaton can
move from c
1
to c
2
when scanning the input α (or without any input, when α = epsilon1)inone
step. If the register operation is R, then the contents of the registers in the two configura-
tions must be equal, and in particular the contents of the designated register in the two
configurations should be the expected symbol (γ). If the register operation is W, then the
contents of the registers in the two configurations is equal except for the designated reg-
ister, whose contents in the produced configuration should be the expected symbol (γ).
Definition
A run of A on w is a sequence of configurations c
0,..., c
r
such that c
0
= q
c
0, c
r
∈ F
c,and
for every k,1≤ k ≤ r, c
k−1
turnstileleft
α
k,A
c
k
and w = α
1
...α
r
.AnFSRAA accepts awordw if
there exists a run of A on w.Noticethat|w| may be less than r since some of the α
i
may
be epsilon1.Thelanguage recognized by an FSRA A, denoted by L(A), is the set of words over
Σ
∗
accepted by A.
Example 5
Consider again example 1. We construct an efficient FSRA accepting all and only the
possible combinations of stems and circumfixes. If the number of stems is r, we define
an FSRA A = 〈Q, q
0,Σ,Γ,2,δ,{q
f
}〉 where:
a114
Q = {q
0, q
1,..., q
2r+2, q
f
}
a114
Σ={a, b, c,..., z, ht, ut}
a114
Γ={htsquaresquaresquareut, hsquaresquaresquarea, msquaresquaresquare,#}
a114
δ = {(q
0, ht, W,1,htsquaresquaresquareut, q
1
), (q
0, h, W,1,hsquaresquaresquarea, q
1
)}
∪
{(q
0, m, W,1,msquaresquaresquare, q
1
), (q
2r+2, ut, R,1,htsquaresquaresquareut, q
f
)}
∪
{(q
2r+2, a, R,1,hsquaresquaresquarea, q
f
), (q
2r+2,epsilon1, R,1,msquaresquaresquare, q
f
)}
∪
{(q
1,α
1, q
i
), (q
i,α
2, q
i+1
), (q
i+1,α
3, q
2r+2
) | 2 ≤ i ≤ 2r and
α
1
α
2
α
3
is the i-th stem}.
57
Computational Linguistics Volume 32, Number 1
This automaton is shown in Figure 6. The number of its states is 2r + 4 (like the FSA
of Figure 2), that is, O(r), and in particular independent of the number of circumfixes.
The number of arcs is also reduced from O(r × p), where p indicates the number of
circumfixes, to O(r + p).
Example 6
Consider again example 2. The FSRA of Figure 7 also accepts the same language. This
automaton has seven states and will have seven states for any number of roots. The
number of arcs is also reduced to 3r + 3.
Next, we show that finite-state registered automata and standard finite state au-
tomata recognize the same class of languages. Trivially, every finite-state automaton
has an equivalent FSRA: Every FSA is also an FSRA since every transition (s,σ, t)inan
FSRA is a shorthand notation for (s,σ, R,0,#,t). The other direction is also simple.
Theorem 1
Every FSRA has an equivalent finite-state automaton.
We prove this by constructing an equivalent FSA toagivenFSRA. The construction is
based on the fact that in FSRAs the number of registers is finite, as are the sets Γ and
Q, the register alphabet and states, respectively. Hence the number of configurations is
finite. The FSA’s states are the configurations of the FSRA, and the transition function
simulates the ‘produces’ relation. Notice that this relation holds between configurations
depending on Σ only, similarly to the transition function in an FSA. The constructed
FSA is non-deterministic, with possible epsilon1-moves. The formal proof is suppressed.
The number of configurations in A is |Q|×|Γ|
n, hence the growth in the number of
states when constructing A
prime
from A might be in the worst case exponential in the num-
ber of registers. In other words, the move from FSAs to FSRAs can yield an exponential
reduction in the size of the network. As we show below, the reduction in the number of
states can be even more dramatic.
The FSRA model defined above allows only one register operation on each tran-
sition. We extend it to allow up to k register operations on each transition, where k
is determined for each automaton separately. The register operations are defined as a
sequence (rather than a set), in order to allow more than one operation on the same
Figure 6
FSRA for circumfixation.
58
Cohen-Sygal and Wintner Non-Concatenative Morphology
Figure 7
FSRA for the pattern hitsquareasquareesquare.
register over one transition. This extension allows further reduction of the network size
for some automata as well as other advantages that will be discussed presently.
Definition
An order-k finite-state registered automaton (FSRA-k) is a tuple A = 〈Q, q
0,Σ,Γ, n,
k,δ, F〉, where:
a114
Q, q
0,Σ,Γ, n, F and the initial content of the registers are as before.
a114
k ∈ N (indicating the maximum number of register operations allowed
on each arc).
a114
Let Actions
Γ
n
= {R, W}×{0, 1, 2,..., n − 1}×Γ. Then
δ ⊆ Q ×Σ∪{epsilon1}×


k
uniondisplay
j=1
braceleftbig
〈a
1,..., a
j
〉|for all i,1≤ i ≤ j, a
i
∈ Actions
Γ
n
bracerightbig


× Q
is the transition relation. δ is extended to allow each transition to be
associated with a series of up to k operations on the registers. Each
operation has the same meaning as before.
The register operations are executed in the order in which they are specified. Thus,
(s,σ,〈a
1,..., a
i
〉, t) ∈ δ where i ≤ k implies that if A is in state s, the input symbol is σ and
all the register operations a
1,..., a
i
are executed successfully, then A may enter state t.
Definition
Given a ∈ Actions
Γ
n
we define a relation over Γ
n, denoted u forces
a
v for u, v ∈ Γ
n
. We define
u forces
a
v where u = u
0
...u
n−1
and v = v
0
...v
n−1
iff the following holds:
a114
if a = (R, i,γ) for some i,0≤ i ≤ n − 1 and for some γ ∈ Γ, then u = v
and u
i
= v
i
= γ.
a114
if a = (W, i,γ) for some i,0≤ i ≤ n − 1 and for some γ ∈ Γ, then for all
k ∈{0, 1,..., n − 1} such that k negationslash= i, u
k
= v
k
and v
i
= γ.
This relation is extended to series over Actions
Γ
n
. Given a series 〈a
1,..., a
p
〉∈(Actions
Γ
n
)
p
where p ∈ N, we define a relation over Γ
n
denoted u forces
〈a
1,...,a
p
〉
v for u, v ∈ Γ
n
.We
define u forces
〈a
1,...,a
p
〉
v iff the following holds:
a114
if p = 1, then u forces
a
1
v.
a114
if p > 1, then there exists w ∈ Γ
n
such that u forces
a
1
w and w forces
〈a
2,...,a
p
〉
v.
59
Computational Linguistics Volume 32, Number 1
Definition
Let u, v ∈ Γ
n
. Given a symbol α ∈ Σ∪{epsilon1} and an FSRA-k A, we say that a configuration
(s, u) produces a configuration (t, v), denoted (s, u) turnstileleft
α,A
(t, v), iff there exist 〈a
1,..., a
p
〉∈
(Actions
Γ
n
)
p
for some p ∈ N such that (s,α,〈a
1,..., a
p
〉, t) ∈ δ and u forces
〈a
1,...,a
p
〉
v.
Definition
A run of A on w is a sequence of configurations c
0,..., c
r
such that c
0
= q
c
0, c
r
∈ F
c,andfor
every l,1≤ l ≤ r, c
l−1
turnstileleft
α
l,A
c
l
and w = α
1
...α
r
.AnFSRA-kA accepts awordw if there
exists a run of A on w.Thelanguage recognized by an FSRA-k A, denoted by L(A), is
the set of words over Σ
∗
accepted by A.
Example 7
Consider the Arabic nouns qamar (moon), kitaab (book), $ams (sun), and daftar (note-
book). The definite article in Arabic is the prefix al, which is realized as al when pre-
ceding most consonants; however, the ‘l’ of the prefix assimilates to the first consonant
of the noun when the latter is ‘d’, ‘$’, etc. Furthermore, Arabic distinguishes between
definite and indefinite case markers. For example, nominative case is realized as the
suffix u on definite nouns, un on indefinite nouns. Examples of the different forms of
Arabic nouns are:
word nominative definite nominative indefinite
qamar ’alqamaru qamarun
kitaab ’alkitaabu kitaabun
$ams ’a$$amsu $amsun
daftar ’addaftaru daftarun
The FSRA-2 of Figure 8 accepts all the nominative definite and indefinite forms of
the above nouns. In order to account for the assimilation, register 2 stores information
about the actual form of the definite article. Furthermore, to ensure that definite nouns
occur with the correct case ending, register 1 stores information of whether or not a
definite article was seen.
Figure 8
FSRA-2 for Arabic nominative definite and indefinite nouns.
60
Cohen-Sygal and Wintner Non-Concatenative Morphology
FSRA-k and FSRAs recognize the same class of languages. Trivially, every FSRA has
an equivalent FSRA-k: Every FSRA is an FSRA-k for k = 1. The other direction is also
simple.
Theorem 2
Every FSRA-k has an equivalent FSRA.
We show how to construct an equivalent FSRA (or FSRA-1) A
prime
given an FSRA-k A. Each
transition in A is replaced by a series of transitions in A’, each of which performs one
operation on the registers. The first transition in the series deals with the new input
symbol and the rest are epsilon1-transitions. This construction requires additional states to
enable the addition of transitions. Each transition in A that is replaced requires the
addition of as many states as the number of register operations performed on this
transition minus one. The formal construction is suppressed.
In what follows, the term FSRA will be used to denote FSRA-k. Simple FRSA will
be referred to as FSRA-1. For the sake of emphasis, however, the term FSRA-k will still
be used in some cases.
FSRA is a very space-efficient finite-state device. The next theorem shows how
ordinary finite-state automata can be encoded efficiently by the FSRA-2 model. Given
a finite-state automaton A, an equivalent FSRA-2 A
prime
is constructed. A
prime
has three states
and two registers (in fact, only one register is used since register number 0 is never
addressed). One state functions as a representative for the final states in A, another
one functions as a representative for the non-final states in A, and the third as an
initial state. The register alphabet consists of the states of A and the symbol ‘#’. Each
arc in A has an equivalent arc in A
prime
with two register operations. The first reads
the current state of A from the register and the second writes the new state into the
register. If the source state of a transition in A is a final state, then the source state of
the corresponding transition in A
prime
will be the final states representative; if the source
state of a transition in A is a non-final state, then the source state of the corresponding
transition in A
prime
will be the non-final states representative. The same holds also for the
target states. The purpose of the initial state is to write the start state of A into the
register. In this way A
prime
simulates the behavior of A. Notice that the number of arcs in A
prime
equals the number of arcs in A plus one, i.e., while FSRAs can dramatically reduce the
number of states, compared to standard FSAs, a reduction in the number of arcs is not
guaranteed.
Theorem 3
Every finite-state automaton has an equivalent FSRA-2 with three states and two
registers.
Proof 1
Let A = 〈Q, q
0,Σ,δ, F〉 be an FSA and let f : Q →
braceleftBig
q
f, q
nf
bracerightBig
be a total function defined
by
f (q) =
braceleftBigg
q
f
q ∈ F
q
nf
q /∈ F
61
Computational Linguistics Volume 32, Number 1
Construct an FSRA-2 A
prime
= 〈Q
prime, q
prime
0,Σ
prime,Γ
prime,2,2,δ
prime, F
prime
〉, where:
a114
Q
prime
= {q
prime
0, q
nf, q
f
}. q
prime
0
is the initial state, q
f
is the final states representative,
and q
nf
is the non-final states representative
a114
Σ
prime
=Σ
a114
Γ=Q ∪{#}
a114
F
prime
= {q
f
}
a114
δ
prime
= {(f (s),σ,〈(R,1,s), (W,1,t)〉, f (t)) | (s,σ, t) ∈ δ}
∪
{(q
prime
0,epsilon1,〈(W,1,q
0
)〉, f (q
0
))}
The formal proof that L(A) = L(A
prime
) is suppressed. squaresolid
3.2 Closure
Properties
The equivalence shown in the previous section between the classes of languages recog-
nized by finite-state automata and finite-state registered automata immediately implies
that finite-state registered automata maintain the closure properties of regular lan-
guages. Applying the regular operations to finite-state registered automata can be easily
done by converting them first into finite-state automata. However, as shown above,
such a conversion may result in an exponential increase in the size of the automaton,
invalidating the advantages of this model. Therefore, we show how some of these
operations can be defined directly for FSRAs. The constructions are mostly based on
the standard constructions for FSAs with some essential modifications. In what follows,
let A
1
= 〈Q
1, q
1
0,Σ
1,Γ
1, n
1, k
1,δ
1, F
1
〉 and A
2
= 〈Q
2, q
2
0,Σ
2,Γ
2, n
2, k
2,δ
2, F
2
〉 be finite-state
registered automata.
3.2.1 Union. Two FSRAs, A
1, A
2, are unioned into an FSRA A inthesamewayasinFSAs:
by adding a new initial state and connecting it with epsilon1-arcs to each of the (former) initial
states of A
1, A
2
. The number of registers and the maximal number of register operations
per arc in A is the maximum of the corresponding values in A
1, A
2
.Noticethatin
any specific run of A, the computation goes through just one of the original automata;
therefore the same set of registers can be used for strings of L(A
1
)orL(A
2
) as needed.
3.2.2 Concatenation. We show two different constructions of an FSRA A = 〈Q, q
0,Σ,
Γ, n, k,δ, F〉 to recognize L(A
1
) · L(A
2
). Concatenation in finite-state automata is achieved
by leaving only the accepting states of the second automaton as accepting states and
adding an epsilon1-arc from every accepting state of the first automaton to the initial state of
the second automaton. Doing just this in FSRA is insufficient because using the same
registers might cause undesired effects: The result might be affected by the content left
in the registers after dealing with a substring from L(A
1
). Thus, this basic construction
is used with care. The first alternative is to employ more registers in the FSRA. In this
way when dealing with a substring from L(A
1
)thefirstn
1
registers are used, and when
moving to deal with a substring from L(A
2
) the next n
2
registers are used. The second
alternative is to use additional register operations that clear the content of the registers
before handling the next substring from L(A
2
). This solution may be less intuitive but
will be instrumental for Kleene closure below.
62
Cohen-Sygal and Wintner Non-Concatenative Morphology
3.2.3 Kleene
Closure. The construction is based on the concatenation construction.
Notice that it cannot be based on the first alternative (adding registers) due to the fact
that the number of iterations in Kleene star is not limited, and therefore the number of
registers needed cannot be bounded. Thus, the second alternative is used: Register op-
erations are added to delete the content of registers. The construction is done by turning
the initial state into a final one (if it is not already final) and connecting each of the final
states to the initial state with an epsilon1-arc that is associated with a register operation that
deletes the contents of the registers, leaving them ready to handle the next substring.
3.2.4 Intersection. For the intersection construction, assume that A
1
and A
2
are epsilon1-free
(we show an algorithm for removing epsilon1-arcs in Section 3.3.1). The following construction
simulates the runs of A
1
and A
2
simultaneously. It is based on the basic construction for
intersection of finite-state automata, augmented by a simulation of the registers and
their behavior. Each transition is associated with two sequences of operations on the
registers, one for each automaton. The number of the registers is the sum of the number
of registers in the two automata. In the intersection automaton the first n
1
registers
are designated to simulate the behavior of the registers of A
1
and the next n
2
registers
simulate the behavior of A
2
. In this way a word can be accepted by the intersection au-
tomaton iff it can be accepted by each one of the automata separately. Notice that register
operations from δ
1
and δ
2
cannot be associated with the same register. This guarantees
that no information is lost during the simulation of the two intersected automata.
3.2.5 Complementation. Ordinary FSAs are trivially closed under complementation.
However, given an FSA A whose language is L(A), the minimal FSA recognizing the
complement of L(A) can be exponentially large. More precisely, for any integer n > 2,
there exists a non-deterministic finite-state automaton (NFA) with n states A, such that
any NFA that accepts the complement of L(A) needs at least 2
n−2
states (Holzer and
Kutrib 2002). We have no reason to believe that FSRAs will demonstrate a different
behavior; therefore, we maintain that in the worst case, the best approach for com-
plementing an FSRA would be to convert it into FSA and complement the latter. We
therefore do not provide a dedicated construction for this operator.
3.3 Optimizations
3.3.1 epsilon1-removal. An epsilon1-arc in an FSRA is an arc of the form (s,epsilon1,〈vectora〉, t) where vectora is used
as a meta-variable over
parenleftbig
Actions
Γ
n
parenrightbig
+
(i.e., vectora represents a vector of register operations).
Notice that this kind of arc might occur in an FSRA by its definition. Given an FSRA
that might contain epsilon1-arcs, an equivalent FSRA without epsilon1-arcs can be constructed. The
construction is based on the algorithm for epsilon1-removal in finite-state automata, but the
register operations that are associated with the epsilon1-arc have to be dealt with, and this
requires some care. The resulting FSRA has one more state than the original, and some
additional arcs may be added, too.
The main problem is epsilon1-loops; while these can be easily removed in standard FSAs,
here such loops can be associated with register operations which must be accounted for.
The number of possible sequences of register operations along an epsilon1-loop is unbounded,
but it is easy to prove that there are only finitely many equivalence classes of such
sequences: Two sequences are in the same equivalence class if and only if they have
the same effect on the state of the machine; since each machine has a finite number of
configurations (see theorem 1), there are only finitely many such equivalence classes.
Therefore, the basic idea behind the construction is as follows: If there exists an
epsilon1-path from q
1
to q
2
with the register operationsvectora over its arcs, and an arc (q
2,σ,〈
vector
b〉, q
3
)
63
Computational Linguistics Volume 32, Number 1
Figure 9
epsilon1 removal paradigm.
where σ negationslash= epsilon1,andanepsilon1-path from q
3
to q
4
with the register operations vectorc over its arcs,
then the equivalent epsilon1-free network will include the arcs (q
2,σ,〈
vector
b〉, q
3
), (q
1,σ,〈vectora,
vector
b〉, q
3
),
(q
2,σ,〈
vector
b,vectorc〉, q
4
), and (q
1,σ,〈vectora,
vector
b,vectorc〉, q
3
), with all the epsilon1-arcs removed. This is illustrated
in Figure 9. Notice that if q
1
and q
2
are the same state, then states q
2
and q
3
will be
connected by two parallel arcs differing in their associated register operations; the same
holds for states q
2
and q
4
. Similarly, when q
3
and q
4
are the same state.
In addition to the above changes, special care is needed for the case in which the
empty word is accepted by the original automaton. The formal construction is similar
in spirit to the epsilon1-removal paradigm in weighted automata (Mohri 2000), where weights
along an epsilon1-path need to be gathered. Therefore, we suppress the formal construction
and the proof of its correctness.
3.3.2 Optimizing
Register Operations. In FSRAs, traversing an arc depends not
only on the input symbol but also on satisfying the series of register operations.
Sometimes, a given series of register operations can never be satisfied, and thus
the arc to which it is attached cannot be traversed. For example, the series of reg-
ister operations 〈(W,1,a), (R,1,b)〉 can never be satisfied, hence an arc of the form
(q
1,σ,〈(W,1,a), (R,1,b)〉, q
2
) is redundant. In addition, the constructions of Sections 3.2
and 3.3.1 might result in redundant states and arcs that can never be reached or can
never lead to a final state. Moreover, in many cases a series of register operations can
be minimized into a shorter series with the same effect. For example, the series of
register operations 〈(W,1,a), (R,1,a), (W,1,b)〉 is equal in its effect to the series 〈(W,1,b)〉.
Therefore, we show an algorithm for optimizing a given FSRA by minimizing the series
of register operations over its arcs and removing redundant arcs and states.
For a given FSRA A = 〈Q, q
0,Σ,Γ, n,δ, F〉, we construct an equivalent FSRA A
prime
=
〈Q, q
0,Σ,Γ, n, δ
prime, F〉 = Opt(A), such that δ
prime
is created from δ by removing redundant
arcs and by optimizing all the series of register operations. We begin by defining
parenleftbig
Actions
Γ
n
parenrightbig
+
|i
as the subset of
parenleftbig
Actions
Γ
n
parenrightbig
+
that consists only of operations over the
i-th register. Define a total function sat
i
:
parenleftbig
Actions
Γ
n
parenrightbig
+
|i
−→ {true, false} by:
sat
i
(vectora) =
braceleftbigg
true if there exist u, v ∈ Γ
n
such that u forces
vectora
v
false otherwise
64
Cohen-Sygal and Wintner Non-Concatenative Morphology
sat
i
(vectora) = true iff the series of register operations vectora is satisfiable, i.e., there exists a
configuration of register contents for which all the operations in the series can be
executed successfully. Determining whether sat
i
(vectora) = true by exhaustively checking
all the vectors in Γ
n
may be inefficient. Therefore, we show a necessary and sufficient
condition for determining whether sat
i
(vectora) = true for somevectora ∈
parenleftbig
Actions
Γ
n
parenrightbig
+
|i, which can
be checked efficiently. In addition, this condition will be useful in optimizing the series
of register operations as will be shown later. A series of register operations over the i-th
register is not satisfiable if either one of the following holds:
a114
A write operation is followed by a read operation expecting a different
value.
a114
A read operation is immediately followed by a read operation expecting a
different value.
Theorem 4
For all vectora = 〈(op
1, i,γ
1
), (op
2, i,γ
2
),...,(op
s, i,γ
s
)〉∈
parenleftbig
Actions
Γ
n
parenrightbig
+
|i, sat
i
(vectora) = false if and
only if either one of the following holds:
1. There exists k,1≤ k < s, such that op
k
= W and there exists m, k < m ≤ s,
such that op
m
= R, γ
k
negationslash= γ
m
and for all j, k < j < m, op
j
= R.
2. There exists k,1≤ k < s, such that op
k
= op
k+1
= R and γ
k
negationslash= γ
k+1
.
Notice that if i = 0, then by the definition of FSRAs, all the register operations in
the series are the same operation, which is (R, 0, #); and this operation can never fail.
In addition, if all the operations in the series are write operations, then again, by the
definition of FSRAs, these operations can never fail. If none of the two conditions of the
theorem holds, then the series of register operations is satisfiable.
We now show how to optimize a series of operations over a given register. An
optimized series is defined only over satisfiable series of register operations in the
following way:
a114
If all the operations are write operations, then leave only the last one (since
it will overwrite all its predecessors).
a114
If all the operations are read operations, then by theorem 4, they are all the
same operation, and in this case just leave one of them.
a114
If there are both read and write operations, then distinguish between two
cases:
– If the first operation is a write operation, leave only the last write
operation in the series.
– If the first operation is a read operation, leave the first operation
(which is read) and the last write operation in the series. If the last
write operation writes into the register the same symbol that the
read operation required, then the write is redundant; leave only the
read operation.
65
Computational Linguistics Volume 32, Number 1
Definition
Define a function min
i
:
parenleftbig
Actions
Γ
n
parenrightbig
+
|i
−→
parenleftbig
Actions
Γ
n
parenrightbig
+
|i
.Letvectora = 〈(op
1, i,γ
1
), ...,(op
s, i,
γ
s
)〉.Ifsat
i
(vectora) = true then:
a114
If for all k,1≤ k ≤ s, op
k
= W, define min
i
(vectora) = 〈(W, i,γ
s
)〉.
a114
If for all k,1≤ k ≤ s, op
k
= R then define min
i
(vectora) = 〈(R, i,γ
s
)〉.
a114
If there exists m,1≤ m ≤ s such that op
m
= W and if there exists t,
1 ≤ t ≤ s, such that op
t
= R then:
min
i
(vectora) =



















〈(W, i,γ
j
)〉 if op
1
= W and
for all k, j < k ≤ s, op
k
= R
〈(R, i,γ
1
), (W, i,γ
j
)〉 if op
1
= R and
for all k, j < k ≤ s, op
k
= R and γ
1
negationslash= γ
j
〈(R, i,γ
1
)〉 if op
1
= R and if there exists j,1≤ j ≤ s,
such that for all k, j < k ≤ s,
op
k
= R and γ
1
= γ
j
The formal proof that min
i
(vectora) is the minimal equivalent series of register operations
ofvectora is suppressed.
We now show how to optimize a series of register operations. Define a function
min :
parenleftbig
Actions
Γ
n
parenrightbig
+
−→
parenleftbig
Actions
Γ
n
parenrightbig
+
∪{null}. For all vectora ∈
parenleftbig
Actions
Γ
n
parenrightbig
+
define min(vectora) =
vector
b
where
vector
b is obtained fromvectora by:
a114
Each subseriesvectora
i
ofvectora, consisting of all the register operations on the i-th
register, is checked for satisfaction. If sat
i
(vectora
i
) = false then the arc cannot be
traversed and min(vectora) =
vector
b = null.Ifsat
i
(vectora
i
) = true thenvectora
i
is replaced invectora by
min(vectora
i
). Notice that the order of the minimized subseries in the complete
series is unimportant as they operate on different registers.
a114
If there exists i negationslash= 0, such that vectora
i
is not empty, then the subseriesvectora
0
consisting only of operations of the form (R, 0, #) is deleted fromvectora.
Finally, given an FSRA A = 〈Q, q
0,Σ,Γ, n,δ, F〉, construct an equivalent FSRA A
prime
=
〈Q, q
0,Σ,Γ, n,δ
prime, F〉 = Opt(A) where
δ
prime
=
braceleftbigparenleftbig
q
1,σ,〈min(vectora)〉, q
2
parenrightbig
|
parenleftbig
q
1,σ,〈vectora〉, q
2
parenrightbig
∈ δ and min(vectora) negationslash= null
bracerightbig
Opt(A) is optimized with respect to register operations.
Like FSAs, FSRAs may have states that can never be reached or can never lead to a
final state. These states (and their connected arcs) can be removed in the same way they
are removed in FSAs. In sum, FSRA optimization is done in two stages:
1. Minimizing the series of register operations over the FSRA transitions.
2. Removing redundant states and arcs.
Notice that stage 1 must be performed before stage 2 as it can result in further re-
duction in the size of the network when performing the second stage. For a given FSRA
A, define OPT(A) as the FSRA obtained from Opt(A) by removing all the redundant
66
Cohen-Sygal and Wintner Non-Concatenative Morphology
states and transitions. An FSRA A is optimized if OPT(A) = A (notice that OPT(A)is
unique, i.e., if B = OPT(A)andC = OPT(A), then B = C).
3.4 FSRA
Minimization
FSRAs can be minimized along three different axes: states, arcs, and registers. Reduc-
tion in the number of registers can always be achieved by converting an FSRA to an
FSA (Section 3.1), eliminating registers altogether. Since FSRAs are inherently non-
deterministic (see the discussion of linearization below), their minimization is related
to the problem of non-deterministic finite-state automata (NFA) minimization, which
is known to be NP-hard.
6
However, while FSRA arc minimization is NP-hard, FSRA
state minimization is different. Recall that in theorem 3 we have shown that any FSA
has an equivalent FSRA-2 with 3 states and 2 registers. It thus follows that any FSRA
has an equivalent FSRA-2 with 3 states (simply convert the FSRA to an FSA and then
convert it to an FSRA-2 with 3 states). Notice that minimizing an FSRA in terms of states
or registers can significantly increase the number of arcs. As many implementations of
finite-state devices use space that is a function of the number of arcs, the benefit that lies
in such minimization is limited. Therefore, a different minimization function, involving
all the three axes, is called for. We do not address this problem in this work. As for
arc minimization, we cite the following theorem. As its proof is most similar to the
corresponding proof on NFA, we suppress it.
Theorem 5
FSRA arc minimization is NP-hard.
The main advantage of finite-state devices is their linear recognition time. In finite-
state automata, this is achieved by determinizing the network, ensuring that the
transition relation is a function. In FSRAs, in contrast, a functional transition re-
lation does not guarantee linear recognition time, since multiple possible transi-
tions can exist for a given state and a given input symbol. For example, given an
FSRA A = 〈Q, q
0,Σ,Γ, n, k,δ, F〉, and some q, q
1, q
2
∈ Q and σ ∈ Σ, two arcs such as
(q,σ,〈(W,1,a)〉, q
1
), (q,σ,〈(W,1,b)〉, q
2
) ∈ δ do not hamper the functionality of the FSRA
transition relation. However, they do imply that for the state q and for the same input
symbol (σ), more than one possible arc can be traversed. We use deterministic to denote
FSRAs in which the transition relation is a function, and a new term, linearized, is used
to denote FSRAs for which linear recognition time is guaranteed.
Generally, a FSRA is linearized if it is optimized, epsilon1-free, and given a current state
and a new input symbol, and at most one transition can be traversed. Thus, if the
transition relation includes two arcs of the form (q,σ,〈vectora〉, q
1
), (q,σ,〈
vector
b〉, q
2
), then vectora and
vector
b must be a contradicting series of register operations. Two series of register operations
are contradicting if at most one of them is satisfiable. Since the FSRA is optimized, each
series of register operations is a concatenation of subseries, each operating on a differ-
ent register; and the subseries operating on the i-th register must be either empty or
〈(W, i,γ)〉 or 〈(R, i,γ)〉 or 〈(R, i,γ
1
), (W, i,γ
2
)〉. 〈(W, i,γ)〉 contradicts neither 〈(R, i,γ)〉 nor
〈(R, i,γ
1
), (W, i,γ
2
)〉. 〈(R, i,γ)〉 and 〈(R, i,γ
1
), (W, i,γ
2
)〉 are contradicting only if γ negationslash= γ
1
.
6 While
this theorem is a part of folklore, we were unable to find a formal proof. We explicitly prove this
theorem in Cohen-Sygal (2004).
67
Computational Linguistics Volume 32, Number 1
Definition
An FSRA A = 〈Q, q
0,Σ,Γ, n, k,δ, F〉, is linearized if it is optimized, epsilon1-free, and for
all (q,σ,〈vectora〉, q
1
), (q,σ,〈
vector
b〉, q
2
) ∈ δ such that 〈vectora〉 negationslash= 〈
vector
b〉, where 〈vectora〉 = 〈(op
1
1, i
1
1,γ
1
1
),...,(op
1
k,
i
1
k,γ
1
k
)〉 and 〈
vector
b〉 = 〈(op
2
1, i
2
1,γ
2
1
),...,(op
2
m, i
2
m,γ
2
m
)〉 , there exists j
1,1≤ j
1
≤ k and there
exists j
2,1≤ j
2
≤ m, such that op
1
j
1
= op
2
j
2
= R, i
1
j
1
= i
2
j
2
and γ
1
j
1
negationslash= γ
2
j
2
.
Ana¨ıve algorithm for converting a given FSRA into an equivalent linearized one
is to convert it to an FSA and then determinize it. In the worst case, this results in
an exponential increase in the network size. As the following theorem shows, FSRA
linearization is NP-complete.
Theorem 6
FSRA linearization is NP-complete.
Proof 2
Evidently, given an FSRA A, it can be verified in polynomial time that A is linearized.
Therefore, FSRA linearization is in NP.
Let φ be a CNF formula with m clauses and n variables. Construct an FSRA A such
that L(A) = {epsilon1} if φ is satisfiable, otherwise L(A) = ∅.
Let x
1,..., x
n
be the variables of φ. Define A = 〈Q, q
0,Σ,Γ, n,1,δ, F〉, such that:
a114
Q = {q
0, q
1,..., q
n+m
}
a114
F = {q
n+m
}
a114
Σ is irrelevant (choose any Σ).
a114
Γ={T, F}.
• δ = {(q
i−1,epsilon1,(W, i, T), q
i
) | 1 ≤ i ≤ n}∪{(q
i−1,epsilon1,(W, i, F), q
i
) | 1 ≤ i ≤ n}
∪
{(q
n+i−1,epsilon1,(R, j, T), q
n+i
) | 1 ≤ i ≤ m and x
j
occurs in the i-th clause}
∪
{(q
n+i−1,epsilon1,(R, j, F), q
n+i
) | 1 ≤ i ≤ m and x
j
occurs in the i-th clause}
Notice that each path in A is of length m + n.Thefirstn arcs in the path
write an assignment into the registers, then it is possible to traverse the
remaining m arcs in the path only if the assignment stored into the
registers satisfies φ.
For example, for the CNF formula (x
1
∨ x
2
∨ x
5
) ∧ (x
1
∨ x
2
) ∧ (x
3
∨ x
4
∨ x
5
), the FSRA of
Figure 10 is constructed. Observe that the number of states and arcs in this FSRA is
O(mn). Now, linearize A into an FSRA A
prime
and assume this can be done in polynomial
time. By the definition of linearized FSRA, A
prime
does not contain epsilon1-arcs. Therefore, epsilon1 ∈
L(A
prime
) iff the initial state of A
prime
is also a final one. Hence, φ is satisfiable iff the initial state
of A
prime
is also a final one. squaresolid
4. A Regular Expression Language for FSRAs
Regular expressions are a formal way for defining regular languages. Regular language
operations construct regular expressions in a convenient way. Several toolboxes (soft-
ware packages) provide extended regular expression description languages and compil-
68
Cohen-Sygal and Wintner Non-Concatenative Morphology
Figure 10
FSRA for a given CNF formula.
ers of the expressions to finite-state devices, automata, and transducers (see Section 1).
We provide a regular expression language for constructing FSRAs, the denotations
of whose expressions are FSRAs. In the following discussion we assume the regular
expression syntax of XFST (Beesley and Karttunen 2003) for basic expressions.
7
Definition
Let Actions
Γ
n
= {R, W}×{0, 1, 2,..., n − 1}×Γ, where n is the number of registers and
Γ is the register alphabet. If R is a regular expression and vectora ∈
parenleftbig
Actions
Γ
n
parenrightbig
+
is a series of
register operations, then the following are also regular expressions: vectora triangleright R, vectora trianglerighttrianglerightR, vectora triangleleft R,
andvectora trianglelefttriangleleftR.
We now define the denotation of each of the above expressions. Let R be a regular
expression whose denotation is the FSRA A,andletvectora ∈
parenleftbig
Actions
Γ
n
parenrightbig
+
. The denotation
of vectora triangleleft R is an FSRA A
prime
obtained from A by adding a new node, q, which becomes the
initial node of A
prime, and an arc from q to the initial node of A; this arc is labeled by epsilon1
and associated with vectora. Notice that in the regular expression vectora triangleleft R, R and vectora can contain
operations on joint registers. In some cases, one would like to distinguish between the
registers used in vectora and in R. Usually, it is up to the user to correctly manipulate the
usage of registers, but in some cases automatic distinction seems desirable. For example,
if R includes a circumfix operator (see below), its corresponding FSRA will contain
register operations created automatically by the operator. Instead of remembering that
circumfixation always uses register 1, one can simply distinguish between the registers
of vectora and R via the vectora trianglelefttriangleleft R operator. This operator has the same general effect as the
previous one, but the transition relation in its FSRA uses fresh registers that are added
to the machine.
In a similar way, the operators vectora triangleright R and vectora trianglerighttrianglerightR are translated into networks. The
difference between these operators and the previous ones is that here, the register
operations in vectora are executed after traversing all the arcs in the FSRA denoted by R.
Using these additional operators, it is easy to show that every FSRA has a corresponding
regular expression denoting it, by a trivial modification of the construction presented by
Kleene (1956).
Example 8
Consider the case of vowel harmony in Warlpiri (Sproat 1992), where the vowel of
suffixes agrees in certain aspects with the vowel of the stem to which it is attached.
7 In
particular, concatenation is denoted by juxtaposition and epsilon1 is denoted by 0.
69
Computational Linguistics Volume 32, Number 1
A simplified account of the phenomenon is that suffixes come in two varieties, one with
‘i’ vowels and one with ‘u’ vowels. Stems whose last vowel is ‘i’ take suffixes of the
first variety, whereas stems whose last vowel is ‘u’ or ‘a’ take the other variety. The
following examples are from Sproat (1992) (citing Nash (1980)):
1. maliki+kil
.
i+l
.
i+lki+ji+li
(dog+PROP+ERG+then+me+they)
2. kud
.
u+kul
.
u+l
.
u+lku+ju+lu
(child+PROP+ERG+then+me+they)
3. minija+kul
.
u+l
.
u+lku+ju+lu
(cat+PROP+ERG+then+me+they)
An FSRA that accepts the above three words is denoted by the following complex
regular expression:
define LexI [m a l i k i]; % words ending in ‘i’
define LexU [k u d u]; % words ending in ‘u’
define LexA [m i n i j a]; % words ending in ‘a’
! Join all the lexicons and write to register 1 ‘u’ or ‘i’
! according to the stem‘s last vowel.
define Stem [<(W,1,i)> triangleleft LexI] | [<(W,1,u)> triangleleft [LexU | LexA]];
! Traverse the arc only if the scanned symbol is the content of
! register 1.
define V [<(R,1,i)> triangleright i] | [<(R,1,u)> triangleright u];
define PROP [+ k V l V]; % PROP suffix
define ERG [+ l V]; % ERG suffix
define Then [+ l k V]; % suffix indicating ‘then’
define Me [+ j V]; % suffix indicating ‘me’
define They [+ l V]; % suffix indicating ‘they’
! define the whole network
define WarlpiriExample Stem PROP ERG Then Me They;
Register 1 stores the last vowel of the stem, eliminating the need to duplicate paths
for each of the different cases. The lexicon is divided into three separate lexicons
(LexI, LexU, LexA), one for each word ending (‘i’, ‘u’, or ‘a’ respectively). The separate
lexicons are joined into one (the variable Stem) and when reading the last letter of
the base word, its type is written into register 1. Then, when suffixing the lexicon
base words, the variable V uses the the content of register 1 to determine which of
the symbols ‘i’, ‘u’ should be scanned and allows traversing the arc only if the correct
symbol is scanned. Note that this solution is applicable independently of the size of the
lexicon, and can handle other suffixes in the same way.
Example 9
Consider again Example 7. The FSRA constructed for Arabic nominative definite and
indefinite nouns can be denoted by the following regular expression:
! Read the definite article (if present).
! Store in register 1 whether the noun is definite or indefinite.
! Store in register 2 the actual form of the definite article.
70
Cohen-Sygal and Wintner Non-Concatenative Morphology
define Prefix [<(W,1,indef)> triangleleft 0] | [<(W,1,def),(W,2,l)> triangleleft ’al] |
[<(W,1,def),(W,2,$)> triangleleft ’a$] | [<(W,1,def),(W,2,d)> triangleleft ’ad];
! Normal base definite and indefinite
define Base [ [<(R,2,l)> triangleleft 0] | [<(R,1,indef)> triangleleft 0] ]
[[kitaab]|[qamar]];
! Bases beginning with $ definite and indefinite
define $Base [ [<(R,2,$)> triangleleft 0] | [<(R,1,indef)> triangleleft 0]][$ams];
! Bases beginning with d definite and indefinite
define dBase [ [<(R,2,d)> triangleleft 0] | [<(R,1,indef)> triangleleft 0]][daftar];
! Read definite and indefinite suffixes.
define Suffix [<(R,1,def)> triangleright u] | [<(R,1,indef)> triangleright un];
! The complete network.
define ArabicExample Prefix [Base | $Base | dBase] Suffix;
The variable Prefix denotes the arcs connecting the first two states of the FSRA,
in which the definite article (if present) is scanned and information indicating whether
the word is definite or not is saved into register 1. In addition, if the word is definite
then register 2 stores the actual form of the definite article. The lexicon is divided
into several parts: The Base variable denotes nouns that do not trigger assimilation.
Other variables ($Base, dBase) denote nouns that trigger assimilation, where for each
assimilation case, a different lexicon is constructed. Each part of the lexicon deals with
both its definite and indefinite nouns by allowing traversing the arcs only if the register
content is appropriate. The variable Suffix denotes the correct suffix, depending on
whether the noun is definite or indefinite. This is possible using the information that
was stored in register 1 by the variable Prefix.
5. Linguistic Applications
We demonstrated in examples 5 and 6 that FSRAs can model some non-concatenative
phenomena more efficiently than standard finite-state devices. We now introduce new
regular expression operators, accounting for our motivating linguistic phenomena, and
show how expressions using these operators are compiled into the appropriate FSRA.
5.1 Circumfixes
We introduce a dedicated regular expression operator for circumfixation and show how
expressions using this operator are compiled into the appropriate FSRA. The operator
accepts a regular expression, denoting a set of bases, and a set of circumfixes, each
of which is a pair of regular expressions (prefix, suffix). It yields as a result an FSRA
obtained by applying each circumfix to each of the bases. The main purpose of this
operator is to deal with cases in which the circumfixes are pairs of strings, but it is
defined such that the circumfixes can be arbitrary regular expressions.
Definition
Let Σ be a finite set such that square,{,},〈,〉,⊗ /∈ Σ. We define the ⊗ operation to be of
the form
R ⊗{〈β
1
squareγ
1
〉〈β
2
squareγ
2
〉...〈β
m
squareγ
m
〉}
71
Computational Linguistics Volume 32, Number 1
where: m ∈ N is the number of circumfixes; R is a regular expression over Σ denoting
the set of bases; and β
i, γ
i
for 1 ≤ i ≤ m are regular expressions over Σ denoting the
prefix and suffix of the i-th circumfix, respectively.
Notice that R,β
i,γ
i
may denote infinite sets. To define the denotation of this op-
erator, let A
β
i, A
γ
i
be the FSRAs denoted by β
i,γ
i, respectively. The operator yields an
FSRA constructed by concatenating three FSRAs. The first is the FSRA constructed from
the union of the FSRAs A
prime
β
1,..., A
prime
β
m, where each A
prime
β
i
is an FSRA obtained from A
β
i
by adding a new node, q, which becomes the initial node of A
prime
β
i, and an arc from q
to the initial node of A
β
i
; this arc is labeled by epsilon1 and associated with 〈(W,1,β
i
squareγ
i
)〉
(register 1 is used to store the circumfix). In addition, the register operations of the
FSRA A
β
i
are shifted by one register in order not to cause undesired effects by the
use of register 1. The second FSRA is the FSRA denoted by the regular expression R
(again, with one register shift) and the third is constructed in the same way as the
first one, the only difference being that the FSRAs are those denoted by γ
1,...,γ
m
and the associated register operation is 〈(R,1,β
i
squareγ
i
)〉. Notice that the concatenation
operation, defined in Section 3.2.2, adjusts the register operations in the FSRAs to be
concatenated, to avoid undesired effects caused by using joint registers. We use this
operation to concatenate the three FSRAs, leaving register 1 unaffected (to handle the
circumfix).
Example 10
Consider the participle-forming combinations in German, e.g., the circumfix ge-t.A
simplified account of the phenomenon is that German verbs in their present form take
an n suffix but in participle form they take the circumfix ge-t. The following examples
are from Sproat (1992):
s¨auseln ‘rustle’ ges¨auselt ‘rustled’
br¨usten ‘brag’ gebr¨ustet ‘bragged’
The FSRA of Figure 11, which accepts the four forms, is denoted by the regular
expression
[s ¨a usel | br ¨u ste] ⊗{〈epsilon1squaren〉〈gesquaret〉}
This regular expression can be easily extended to accept more German verbs in other
forms. More circumfixation phenomena in other languages such as Indonesian and
Arabic can be modeled in the same way using this operator.
Figure 11
Participle-forming combinations in German.
72
Cohen-Sygal and Wintner Non-Concatenative Morphology
Example 11
Consider again Example 5. The FSRA accepting all the possible combinations of stems
and the Hebrew circumfixes h-a, ht-ut, m-epsilon1 can be denoted by the regular expression
R ⊗{〈hsquarea〉〈htsquareut〉〈msquareepsilon1〉} where R denotes an FSA accepting the roots.
5.2 Interdigitation
Next, we define a dedicated operator for interdigitation. It accepts a set of regular
expressions, representing a set of roots, and a list of patterns, each of which containing
exactly n slots. It yields as a result an FSRA denoting the set containing all the strings
created by splicing the roots into the slots in the patterns. For example, consider the He-
brew roots r.$.m, p.&.l, p.q.d and the Hebrew patterns hitsquareasquareesquare,misquaresquareasquare,hasquaresquareasquarea.
The roots are all trilateral, and the patterns have three slots each. Given these two
inputs, the new operator yields an FSRA denoting the set {hitra$em, hitpa&el, hitpaqed,
mir$am, mip&al, mipqad, har$ama, hap&ala, hapqada}.
Definition
Let Σ be a finite set such that square,{,},〈,〉,⊕ /∈ Σ. We define the splice operation to be of
the form
{〈α
11,α
12,...,α
1n
〉,〈α
21,α
22,...,α
2n
〉,...,〈α
m1,α
m2,...,α
mn
〉}
⊕
{〈β
11
squareβ
12
square...β
1n
squareβ
1 n+1
〉,〈β
21
squareβ
22
square...β
2n
squareβ
2 n+1
〉,...,〈β
k1
squareβ
k2
square...β
kn
squareβ
kn+1
〉}
where:
a114
n ∈ N is the number of slots (represented by ‘square’) in the patterns into which
the roots letters should be inserted.
a114
m ∈ N is the number of roots to be inserted.
a114
k ∈ N is the number of patterns.
a114
α
ij,β
ij
are regular expressions (including regular expressions denoting
FSRAs).
The left set is a set of roots to be inserted into the slots in the right set of patterns.
For the sake of brevity, β
i
and α
i
are used as shorthand notations for β
i1
squareβ
i2
square...squareβ
i(n+1)
and α
i1
α
i2
...α
in, respectively.
Consider first the case where α
ij
∈ Σ∪{epsilon1} for 1 ≤ i ≤ m and 1 ≤ j ≤ n and β
ij
∈
Σ∪{epsilon1} for 1 ≤ i ≤ k and 1 ≤ j ≤ n + 1. In this case the splice operation yields as a result
an FSRA-1 A = 〈Q, q
0,Σ,Γ,3,δ, F〉, such that L(A) = {β
j1
α
i1
β
j2
α
i2
...β
jn
α
in
β
j(n+1)
| 1 ≤
i ≤ m ,1≤ j ≤ k}, where:
a114
Q = {q
0, q
1,..., q
2n+1
}
a114
F = {q
2n+1
}
a114
Σ=
parenleftbig
{α
ij
| 1 ≤ i ≤ m ,1≤ j ≤ n}∪{β
ij
| 1 ≤ i ≤ k ,1≤ j ≤ n + 1}
parenrightbig
\{epsilon1}
73
Computational Linguistics Volume 32, Number 1
Figure 12
Interdigitation FSRA – general.
a114
Γ={β
i
| 1 ≤ i ≤ k}∪{α
i
| 1 ≤ i ≤ m}∪{#}.
a114
δ = {(q
0,β
i1, W,1,β
i, q
1
)| 1 ≤ i ≤ k}
∪
{(q
1,α
i1, W,2,α
i, q
2
)| 1 ≤ i ≤ m}
∪
{(q
2j−2,β
ij, R,1,β
i, q
2j−1
)| 1 ≤ i ≤ k ,2≤ j ≤ n + 1}
∪
{(q
2j−1,α
ij, R,2,α
i, q
2j
)| 1 ≤ i ≤ m ,2≤ j ≤ n}
This FSRA is shown in Figure 12. It has 3 registers, where register 1 remembers the
pattern and register 2 remembers the root. Notice that the FSRA will have 3 registers
and 2n + 2 states for any number of roots and patterns. The number of arcs is k × (n +
1)+ m × n. In the (default) case of trilateral roots, for m roots and k patterns the resulting
machine has a constant number of states and O(k + m)arcs.
In the general case, where α
ij
and β
ij
can be arbitrary regular expressions, the
construction of the FSRA denoted by this operation is done in the same way as in the
case of circumfixes with two main adjustments. The first is that in this case the final
FSRA is constructed by concatenating 2n + 1 intermediate FSRAs (n FSRAs for the n
parts of the roots and n + 1 FSRAs for the n + 1 parts of the patterns). The second is that
here, 2 registers are used to remember both the root and the pattern. We suppress the
detailed description of the construction.
Example 12
Consider again the Hebrew roots r.$.m, p.&.l, p.q.d and the Hebrew patterns hitsquareasquareesquare,
misquaresquareasquare,andhasquaresquareasquarea. The splice operation
{〈r,$,m〉〈p,&,l〉〈p, q, d〉}⊕{〈hitsquareasquareesquare〉〈misquaresquareasquare〉〈hasquaresquareasquarea〉}
74
Cohen-Sygal and Wintner Non-Concatenative Morphology
yields the FSRA of Figure 13. The epsilon1-arc was added only for the convenience of the
drawing.
It should be noted that like other processes of derivational morphology, Hebrew
word formation is highly idiosyncratic: Not all roots combine with all patterns, and
there is no systematic way to determine when such combinations will be realized
in the language. Yet, this does not render our proposed operators useless: One can
naturally characterize classes of roots and classes of patterns for which all the com-
binations exist. Furthermore, even when such a characterization is difficult to come by,
the splice operator can be used, in combination with other extended regular expres-
sion operators, to define complex expressions for generating the required language.
This is compatible with the general approach for using finite-state techniques, imple-
menting each phenomenon independently and combining them together using closure
properties.
5.3 Reduplication
We now return to the reduplication problem as was presented in example 3. We extend
the finite-state registered model to efficiently accept L
n
= {ww | w ∈ Σ
∗, |w| = n},a
finite instance of the general problem, which is arguably sufficient for describing
reduplication in natural languages. Using FSRAs as defined above does not improve
space efficiency, because a separate path for each reduplication is still needed. Notice
that the different symbols in L
n
have no significance except the pattern they create.
Therefore, FSRAs are extended in order to be able to identify a pattern without actually
distinguishing between different symbols in it. The extended model, FSRA*, is obtained
from the FSRA-1 model by adding a new symbol, ‘*’, assumed not to belong to Σ,and
by forcing Γ to be equal to Σ. The ‘*’ indicates equality between the input symbol and
the designated register content, eliminating the need to duplicate paths for different
symbols.
Figure 13
Interdigitation example.
75
Computational Linguistics Volume 32, Number 1
Definition
Let ∗ /∈ Σ.AnFSRA* is an FSRA-1 where Σ=Γ(and thus includes ’#’) and the tran-
sition function is extended to be δ ⊆ Q ×Σ∪{epsilon1,∗}×{R, W}×{0, 1, 2,..., n − 1}×
Σ∪{∗}× Q. The extended meaning of δ is as follows:
a114
(s,σ, R, i,γ, t) ∈ δ,(s,σ, W, i,γ, t) ∈ δ where σ,γ negationslash= ∗ imply the same as
before.
a114
(s,σ, R, i,∗, t) ∈ δ and (s,∗, R, i,σ, t) ∈ δ for σ negationslash= epsilon1 imply that if the
automaton is in state s, the input symbol is σ and the content of the i-th
register is the same σ, then the automaton may enter state t.
a114
(s,σ, W, i,∗, t) ∈ δ and (s,∗, W, i,σ, t) ∈ δ for σ negationslash= epsilon1 imply that if the
automaton is in state s and the input symbol is σ, then the content of the
i-th register is changed to σ, and the automaton may enter state t.
a114
(s,∗, R, i,∗, t) ∈ δ implies that if the automaton is in state s, the input
symbol is some σ ∈ Σ and the content of the i-th register is the same σ,
then the automaton may enter state t.
a114
(s,∗, W, i,∗, t) ∈ δ implies that if the automaton is in state s and the input
symbol is some σ ∈ Σ, then the content of the i-th register is changed to the
same σ, and the automaton may enter state t.
With this extended model we can construct an efficient registered automaton for
L
n
: The number of registers is n+1. Registers 1,..., n remember the first n symbols to be
duplicated. Figure 14 depicts an extended registered automaton that accepts L
n
for n =
4. Notice that the number of states depends only on n and not on the size of Σ. Figure 15
schematically depicts an extended registered automaton that accepts L
n
for some n ∈ N.
The language {ww ||w|≤n} for some n ∈ N can be generated by a union of FSRA*,
each one generating L
n
for some i ≤ n. Since n is usually small in natural language
reduplication, the resulting automaton is manageable, and in any case, considerably
smaller than the na¨ıve automaton.
5.4 Assimilation
In example 7, FSRAs are used to model assimilation in Arabic nominative definite
nouns. Using the FSRA* model defined above, further reduction in the network size
can be achieved. The FSRA* of Figure 16 accepts all the nominative definite forms of the
Arabic nouns kitaab, qamar,anddaftar (more nouns can be added in a similar way).
Register 1 stores information about the actual form of the definite article, to ensure that
assimilation occurs when needed and only then. Notice that in this FSRA, in contrast to
Figure 14
Reduplication for n =4.
76
Cohen-Sygal and Wintner Non-Concatenative Morphology
Figure 15
Reduplication – general case.
the FSRA of Figure 8, the definite Arabic article al is not scanned as one symbol but as
two separate symbols.
6. Finite-state Registered Transducers
We extend the FSRA model to finite-state registered transducers (FSRT), denoting
relations over two finite alphabets. The extension is done by adding to each transition an
output symbol. This facilitates an elegant solution to the problem of binary incrementors
which was introduced in Example 4.
Example 13
Consider again the 32-bit incrementor example introduced in Example 4. Recall that
a sequential transducer for an n-bit binary incrementor would require 2
n
states and a
similar number of transitions. Using the FSRT model, a more efficient n-bit transducer
can be constructed. A 4-bit FSRT incrementor is shown in Figure 17. The first four
transitions copy the input string into the registers, then the input is scanned (using
the registers) from right to left (as the carry moves), calculating the result, and the
last four transitions output the result (in case the input is 1
n, an extra 1 is added in
the beginning). Notice that this transducer guarantees linear recognition time, since
from each state only one arc can be traversed in each step, even when there are
epsilon1-arcs. In the same way, an n-bit transducer can be constructed for all n ∈ N. Such
a transducer will have n registers, 3n + 1 states and 6n arcs. The FSRT model solves
the incrementor problem in much the same way it is solved by vectorized finite-state
Figure 16
FSRA* for Arabic nominative definite nouns.
77
Computational Linguistics Volume 32, Number 1
Figure 17
4-bit incrementor using FSRT.
automata, but the FSRT solution is more intuitive and is based on existing finite-state
techniques.
It is easy to show that FSRTs, just like FSRAs, are equivalent to their non-registered
counterparts. It immediately implies that FSRTs maintain the closure properties of
regular relations. As in FSRAs, implementing the closure properties directly on FSRTs
is essential for benefiting from their space efficiency. The common operators such as
union, concatenation, etc., are implemented in the same ways as in FSRAs. A direct
implementation of FSRT composition is a na¨ıve extension of ordinary transducer com-
position, based on the intersection construction of FSRAs. We explicitly define these
operations in Cohen-Sygal (2004).
7. Implementation and Evaluation
In order to practically compare the space and time performance of FSRAs and FSAs, we
have implemented the special operators introduced in Sections 4 and 5 for circumfix-
ation and interdigitation, as well as direct construction of FSRAs. We have compared
FSRAs with ordinary FSAs by building corresponding networks for circumfixation,
interdigitation, and n-bit incrementation. For circumfixation, we constructed networks
for the circumfixation of 1,043 Hebrew roots and 4 circumfixes. For interdigitation we
constructed a network accepting the splicing of 1,043 roots into 20 patterns. For n-bit
incrementation we constructed networks for 10-bit, 50-bit, and 100-bit incrementors.
Table 1 displays the size of each of the networks in terms of states, arcs, and actual file
size.
78
Cohen-Sygal and Wintner Non-Concatenative Morphology
Table 1
Space comparison between FSAs and FSRAs.
Operation Network type States Arcs Registers File size
Circumfixation FSA 811 3,824 – 47kB
(4 circumfixes, 1,043 roots) FSRA 356 360 1 16kB
Interdigitation FSA 12,527 31,077 – 451kB
(20 patterns, 1,043 roots) FSRA 58 3,259 2 67kB
10-bit incrementor Sequential FST 268 322 – 7kB
FSRT 31 60 10 2kB
50-bit incrementor Sequential FST 23,328 24,602 – 600kB
FSRT 151 300 50 8kB
100-bit incrementor Sequential FST 176,653 181,702 – 4.73Mb
FSRT 301 600 100 17kB
Table 2
Time comparison between FSAs and FSRAs.
200 words 1,000 words 5,000 words
Circumfixation FSA 0.01s 0.02s 0.08s
(4 circumfixes, 1,043 roots) FSRA 0.01s 0.02s 0.09s
Interdigitation FSA 0.01s 0.02s 1s
(20 patterns, 1,043 roots) FSRA 0.35s 1.42s 10.11s
10-bit incrementor Sequential FST 0.01s 0.05s 0.17s
FSRT 0.01s 0.06s 0.23s
50-bit incrementor Sequential FST 0.13s 0.2s 0.59s
FSRT 0.08s 0.4s 1.6s
Clearly, FSRAs provide a significant reduction in the network size. In particular, we
could not construct an n-bit incrementor FSA for any n greater than 100 as a result of
memory problems, whereas using FSRAs we had no problem constructing networks
even for n = 50, 000.
In addition, we compared the recognition times of the two models. For that purpose,
we used the circumfixation, interdigitation, 10-bit incrementation, and 50-bit incremen-
tation networks to analyze 200, 1,000, and 5,000 words. As can be seen in Table 2, time
performance is comparable for the two models, except for interdigitation, where FSAs
outperform FSRAs by a constant factor. The reason is that in this network the usage of
registers is massive and thereby, there is a higher cost to the reduction of the network
size, in terms of analysis time. This is an instance of the common tradeoff of time versus
space: FSRAs improve the network size at the cost of slower analysis time in some cases.
When using finite-state devices for natural language processing, often the generated
networks become too large to be practical. In such cases, using FSRAs can make network
size manageable. Using the closure constructions one can build desired networks of
reasonable size, and at the end decide whether to convert them to ordinary FSAs, if
time performance is an issue.
8. Conclusions
In this work we introduce finite-state registered networks (automata and transducers),
an extension of finite-state networks which adds a limited amount of memory, in the
79
Computational Linguistics Volume 32, Number 1
form of registers, to each transition. We show how FSRAs can be used to efficiently
model several non-concatenative morphological phenomena, including circumfixation,
root and pattern word formation in Semitic languages, vowel harmony, and limited
reduplication.
The main advantage of finite-state registered networks is their space efficiency. We
show that every FSA can be simulated by an equivalent FSRA with three states and
two registers. For the motivating linguistic examples, we show a significant decrease
in the number of states and the number of transitions. For example, to account for all
the possible combinations of r roots and p patterns, an ordinary FSA requires O(r × p)
arcs whereas an FSRA requires only O(r + p). As a non-linguistic example, we show
a transducer that computes n-bit increments of binary numbers. While an ordinary
(sequential) FST requires O(2
n
) states and arcs, an FSRT which guarantees linear recog-
nition time requires only O(n) states and arcs.
In spite of their efficiency, finite-state registered networks are equivalent, in terms
of their expressive power, to ordinary finite state networks. We provide an algorithm for
converting FSRAs to FSAs and prove the equivalence of the models. Furthermore, we
provide direct constructions of the main closure properties of FSAs for FSRAs, including
concatenation, union, intersection, and composition.
In order for finite-state networks to be useful for linguistic processing, we provide
a regular expression language denoting FSRAs. In particular, we provide a set of
extended regular expression operators that denote FSRAs and FSRTs. We demonstrate
the utility of the operators by accounting for a variety of complex morphological and
phonological phenomena, including circumfixation (Hebrew and German), root-and-
pattern (Hebrew), vowel harmony (Warlpiri), assimilation (Arabic), and limited redu-
plication. These dedicated operators can be used in conjunction with standard finite
state calculi, thereby providing a complete set of tools for the computational treatment
of non-concatenative morphology.
This work opens a variety of directions for future research. An immediate question
is the conversion of FSAs to FSRAs. While it is always possible to convert a given FSA
to an FSRA (simply add one register which is never used), we believe that it is possible
to automatically convert space inefficient FSAs to more compact FSRAs. A pre-requisite
is a clear understanding of the parameters for minimization: These include the number
of states, arcs, and registers, and the size of the register alphabet. For a given FSRA, the
number of states can always be reduced to a constant (theorem 3) and registers can be
done away with entirely (by converting the FSRA to an FSA, Section 3.1). In contrast,
minimizing the number of arcs in an FSRA is NP-hard (Section 3.4). A useful conversion
of FSAs to FSRAs must minimize some combination of these parameters, and while it
may be intractable in general, it can be practical in many special cases. In particular,
the case of finite languages (acyclic FSAs) is both of practical importance and — we
conjecture — can result in good compaction.
More work is also needed in order to establish more properties of FSRTs. In particu-
lar, we did not address issues such as sequentiality or sequentiability for this model.
Similarly, FSRA
∗
can benefit from further research. All the closure constructions for
FSRA
∗
s can be done in a similar way to FSRAs, with the exception of intersection. For in-
tersection, we believe that the use of predicates (van Noord and Gerdemann 2001b) can
be beneficial. Furthermore, the use of predicates can be beneficial for describing natural
language reduplication where the reduplication is not as bounded as the example we
deal with in this work. In addition, the FSRA
∗
model can be extended into transducers.
Finally, in Section 7 we discuss an implementation of FSRAs. Although we have
used this system to construct networks for several phenomena, we are interested in
80
Cohen-Sygal and Wintner Non-Concatenative Morphology
constructing a network for describing the complete morphology of a natural language
containing many non-concatenative phenomena, e.g., Hebrew. A morphological ana-
lyzer for Hebrew, based on finite-state calculi, already exists (Yona and Wintner 2005),
but is very space-inefficient and, therefore, hard to maintain. It would be beneficial to
compact such a network using FSRTs, and to inspect the time versus space tradeoff on
such a comprehensive network.
Acknowledgments
We are grateful to Dale Gerdemann for his
help and inspiration. We thank Victor Harnik
and Nissim Francez for their comments on
an earlier version of this paper. We are also
thankful to the anonymous reviewers, whose
comments helped substantially to improve
this article. This research was supported by
The Israel Science Foundation (grant
no. 136/01).

References

Beesley, Kenneth R. 1998. Constraining
separated morphotactic dependencies in
finite-state grammars. In Proceedings of
FSMNLP-98, pages 118–127, Bilkent,
Turkey.

Beesley, Kenneth R. and Lauri Karttunen.
2000. Finite-state non-concatenative
morphotactics. In Proceedings of the
Fifth Workshop of the ACL Special Interest
Group in Computational Phonology,
SIGPHON-2000, pages 1–12,
Luxembourg.

Beesley, Kenneth R. and Lauri Karttunen.
2003. Finite-State Morphology. CSLI
Publications.

Blank, Glenn D. 1985. A new kind of
finite-state automaton: Register vector
grammar. In Proceedings of the International
Joint Conference on Artificial Intelligence,
pages 749–755, UCLA.

Blank, Glenn D. 1989. A finite and real-time
processor for natural language.
Communications of the ACM,
32(10):1174–1189.

Cohen-Sygal, Yael. 2004. Computational
implementation of non-concatenative
morphology. Master’s thesis, Department
of Computer Science, University of Haifa,
Israel.

Holzer, Markus and Martin Kutrib. 2002.
State complexity of basic operations on
nondeterministic finite automata. In
Jean-Marc Champarnaud and Denis
Maurel, editors, Implementation and
Application of Automata, 7th International
Conference, CIAA 2002, volume 2608 of
Lecture Notes in Computer Science,
Springer, pages 148–157.

Kaminski, Michael and Nissim Francez.
1994. Finite memory automata. Theoretical
Computer Science, 134(2):329–364.
Kaplan, Ronald M. and Martin Kay. 1994.
Regular models of phonological rule
systems. Computational Linguistics,
20(3):331–378.

Karttunen, Lauri, Jean-Pierre Chanod,
Gregory Grefenstette, and Anne Schiller.
1996. Regular expressions for language
engineering. Natural Language Engineering,
2(4):305–328.

Kataja, Laura and Kimmo Koskenniemi.
1988. Finite-state description of Semitic
morphology: A case study of ancient
Akkadian. In Proceedings of COLING 88,
International Conference on Computational
Linguistics, pages 313–315, Budapest.

Kay, Martin. 1987. Nonconcatenative
finite-state morphology. In Proceedings of
the Third Conference of the European Chapter
of the Association for Computational
Linguistics, pages 2–10, Copenhagen,
Denmark.

Kiraz, George Anton. 2000. Multitiered
nonlinear morphology using multitape
finite automata: A case study on Syriac
and Arabic. Computational Linguistics,
26(1):77–105.

Kleene, S. C. 1956. Representation of events
in nerve nets and finite automata. In C. E.
Shannon and J. McCarthy, editors,
Automata Studies. Princeton University
Press, pages 3–42.

Kornai, Andr´as. 1996. Vectorized finite-state
automata. In Proceedings of the Workshop on
Extended Finite-State Models of Languages in
the 12th European Conference on Artificial
Intelligence, pages 36–41, Budapest.

Koskenniemi, Kimmo. 1983. Two-Level
Morphology: A General Computational Model
for Word-Form Recognition and Production.
The Department of General Linguistics,
University of Helsinki.

Krauwer, Steven and Louis des Tombe. 1981.
Transducers and grammars as theories of
language. Theoretical Linguistics, 8:173–202.
Lavie, Alon, Alon Itai, Uzzi Ornan, and Mori

Rimon. 1988. On the applicability of
two-level morphology to the inflection of
Hebrew verbs. Technical Report 513,
Computational Linguistics Volume 32, Number 1
Department of Computer Science,
Technion, 32000 Haifa, Israel.

Mohri, Mehryar. 1996. On some applications
of finite-state automata theory to natural
language processing. Natural Language
Engineering, 2(1):61–80.

Mohri, Mehryar. 2000. Generic
epsilon-removal algorithm for weighted
automata. In Sheng Yu and Andrei Paun,
editors, 5th International Conference, CIAA
2000, volume 2088, Springer-Verlag,
pages 230–242.

Mohri, Mehryar, Fernando Pereira, and
Michael Riley. 2000. The design principles
of a weighted finite-state transducer
library. Theoretical Computer Science,
231(1):17–32.

Nash, David. 1980. Topics in Warlpiri
Grammar. Ph.D. thesis, Massachusetts
Institute of Technology.

Sproat, Richard W. 1992. Morphology and
Computation. MIT Press, Cambridge, MA.
van Noord, Gertjan and Dale Gerdemann.
2001a. An extendible regular expression
compiler for finite-state approaches in
natural language processing. In O. Boldt
and H. J ¨urgensen, editors, Automata
Implementation, 4th International Workshop
on Implementing Automata, WIA’99,
Potsdam, Germany, Revised Papers,
number 2214 in Lecture Notes in Computer
Science. Springer.

van Noord, Gertjan and Dale Gerdemann.
2001b. Finite state transducers with
predicates and identity. Grammars,
4(3):263–286.

Walther, Markus. 2000a. Finite-state
reduplication in one-level prosodic
morphology. In Proceedings of
the First Conference of the North
American Chapter of the Association
for Computational Linguistics,
pages 296–302, Seattle.

Walther, Markus. 2000b. Temiar
reduplication in one-level prosodic
morphology. In Proceedings of
SIGPHON, Workshop on Finite-State
Phonology, pages 13–21, Luxembourg.

Yona, Shlomo and Shuly Wintner.
2005. A finite-state morphological
grammar of Hebrew. In Proceedings of
the ACL-2005 Workshop on Computational
Approaches to Semitic Languages,
Ann Arbor.

