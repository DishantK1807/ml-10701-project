Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 450–459,
Portland, Oregon, June 19-24, 2011. c©2011 Association for Computational Linguistics
Optimal Head-Driven Parsing Complexity
for Linear Context-Free Rewriting Systems
Pierluigi Crescenzi
Dip. di Sistemi e Informatica
Universit`a di Firenze
Daniel Gildea
Computer Science Dept.
University of Rochester
Andrea Marino
Dip. di Sistemi e Informatica
Universit`a di Firenze
Gianluca Rossi
Dip. di Matematica
Universit`a di Roma Tor Vergata
Giorgio Satta
Dip. di Ingegneria dell’Informazione
Universit`a di Padova
Abstract
We study the problem of finding the best head-
driven parsing strategy for Linear Context-
Free Rewriting System productions. A head-
driven strategy must begin with a specified
righthand-side nonterminal (the head) and add
the remaining nonterminals one at a time in
any order. We show that it is NP-hard to find
the best head-driven strategy in terms of either
the time or space complexity of parsing.
1 Introduction
Linear Context-Free Rewriting Systems (LCFRSs)
(Vijay-Shankar et al., 1987) constitute a very general
grammatical formalism which subsumes context-
free grammars (CFGs) and tree adjoining grammars
(TAGs), as well as the synchronous context-free
grammars (SCFGs) and synchronous tree adjoin-
ing grammars (STAGs) used as models in machine
translation.1 LCFRSs retain the fundamental prop-
erty of CFGs that grammar nonterminals rewrite
independently, but allow nonterminals to generate
discontinuous phrases, that is, to generate more
than one span in the string being produced. This
important feature has been recently exploited by
Maier and Søgaard (2008) and Kallmeyer and Maier
(2010) for modeling phrase structure treebanks with
discontinuous constituents, and by Kuhlmann and
Satta (2009) for modeling non-projective depen-
dency treebanks.
The rules of a LCFRS can be analyzed in terms
of the properties of rank and fan-out. Rank is the
1To be more precise, SCFGs and STAGs generate languages
composed by pair of strings, while LCFRSs generate string lan-
guages. We can abstract away from this difference by assuming
concatenation of components in a string pair.
number of nonterminals on the right-hand side (rhs)
of a rule, while fan-out is the number of spans of
the string generated by the nonterminal in the left-
hand side (lhs) of the rule. CFGs are equivalent to
LCFRSs with fan-out one, while TAGs are one type
of LCFRSs with fan-out two. Rambow and Satta
(1999) show that rank and fan-out induce an infi-
nite, two-dimensional hierarchy in terms of gener-
ative power; while CFGs can always be reduced to
rank two (Chomsky Normal Form), this is not the
case for LCFRSs with any fan-out greater than one.
General algorithms for parsing LCFRSs build a
dynamic programming chart of recognized nonter-
minals bottom-up, in a manner analogous to the
CKY algorithm for CFGs (Hopcroft and Ullman,
1979), but with time and space complexity that are
dependent on the rank and fan-out of the gram-
mar rules. Whenever it is possible, binarization of
LCFRS rules, or reduction of rank to two, is there-
fore important for parsing, as it reduces the time
complexity needed for dynamic programming. This
has lead to a number of binarization algorithms for
LCFRSs, as well as factorization algorithms that
factor rules into new rules with smaller rank, with-
out necessarily reducing rank all the way to two.
Kuhlmann and Satta (2009) present an algorithm
for binarizing certain LCFRS rules without increas-
ing their fan-out, and Sagot and Satta (2010) show
how to reduce rank to the lowest value possible for
LCFRS rules of fan-out two, again without increas-
ing fan-out. G´omez-Rodr´ıguez et al. (2010) show
how to factorize well-nested LCFRS rules of arbi-
trary fan-out for efficient parsing.
In general there may be a trade-off required
between rank and fan-out, and a few recent pa-
pers have investigated this trade-off taking gen-
450
eral LCFRS rules as input. G´omez-Rodr´ıguez et
al. (2009) present an algorithm for binarization of
LCFRSs while keeping fan-out as small as possi-
ble. The algorithm is exponential in the resulting
fan-out, and G´omez-Rodr´ıguez et al. (2009) mention
as an important open question whether polynomial-
time algorithms to minimize fan-out are possible.
Gildea (2010) presents a related method for bina-
rizing rules while keeping the time complexity of
parsing as small as possible. Binarization turns out
to be possible with no penalty in time complexity,
but, again, the factorization algorithm is exponen-
tial in the resulting time complexity. Gildea (2011)
shows that a polynomial time algorithm for factor-
izing LCFRSs in order to minimize time complexity
would imply an improved approximation algorithm
for the well-studied graph-theoretic property known
as treewidth. However, whether the problem of fac-
torizing LCFRSs in order to minimize time com-
plexity is NP-hard is still an open question in the
above works.
Similar questions have arisen in the context of
machine translation, as the SCFGs used to model
translation are also instances of LCFRSs, as already
mentioned. For SCFG, Satta and Peserico (2005)
showed that the exponent in the time complexity
of parsing algorithms must grow at least as fast as
the square root of the rule rank, and Gildea and
ˇStefankoviˇc (2007) tightened this bound to be lin-
ear in the rank. However, neither paper provides an
algorithm for finding the best parsing strategy, and
Huang et al. (2009) mention that whether finding the
optimal parsing strategy for an SCFG rule is NP-
hard is an important problem for future work.
In this paper, we investigate the problem of rule
binarization for LCFRSs in the context of head-
driven parsing strategies. Head-driven strategies be-
gin with one rhs symbol, and add one nontermi-
nal at a time. This rules out any factorization in
which two subsets of nonterminals of size greater
than one are combined in a single step. Head-driven
strategies allow for the techniques of lexicalization
and Markovization that are widely used in (projec-
tive) statistical parsing (Collins, 1997). The statis-
tical LCFRS parser of Kallmeyer and Maier (2010)
binarizes rules head-outward, and therefore adopts
what we refer to as a head-driven strategy. How-
ever, the binarization used by Kallmeyer and Maier
(2010) simply proceeds left to right through the rule,
without considering the impact of the parsing strat-
egy on either time or space complexity. We examine
the question of whether we can efficiently find the
strategy that minimizes either the time complexity
or the space complexity of parsing. While a naive
algorithm can evaluate all null! head-driven strategies
in time null(null null null!), where null is the rule’s rank and null
is the total length of the rule’s description, we wish
to determine whether a polynomial-time algorithm
is possible.
Since parsing problems can be cast in terms of
logic programming (Shieber et al., 1995), we note
that our problem can be thought of as a type of
query optimization for logic programming. Query
optimization for logic programming is NP-complete
since query optimization for even simple conjunc-
tive database queries is NP-complete (Chandra and
Merlin, 1977). However, the fact that variables in
queries arising from LCFRS rules correspond to the
endpoints of spans in the string to be parsed means
that these queries have certain structural properties
(Gildea, 2011). We wish to determine whether the
structure of LCFRS rules makes efficient factoriza-
tion algorithms possible.
In the following, we show both the the timeand
space-complexity problems to be NP-hard for head-
driven strategies. We provide what is to our knowl-
edge the first NP-hardness result for a grammar fac-
torization problem, which we hope will aid in under-
standing parsing algorithms in general.
2 LCFRSs
and parsing complexity
In this section we briefly introduce LCFRSs and de-
fine the problem of optimizing head-driven parsing
complexity for these formalisms. For a positive in-
teger null, we write [null] to denote the set null1nullnullnullnullnullnullnull.
As already mentioned in the introduction,
LCFRSs generate tuples of strings over some finite
alphabet. This is done by associating each produc-
tion null of a grammar with a function null that takes as
input the tuples generated by the nonterminals in null’s
rhs, and rearranges their string components into a
new tuple, possibly adding some alphabet symbols.
Let null be some finite alphabet. We write null null for
the set of all (finite) strings over null . For natural num-
bers null null 0 and nullnullnull1nullnullnullnullnullnullr null 1, consider a func-
451
tion null : (null null)f1 nullnullnullnullnull(null null)fr null (null null)f defined by
an equation of the form
null(nullnull1,1nullnullnullnullnullnull1,f1nullnullnullnullnullnullnullnullr,1nullnullnullnullnullnullr,frnull) = null null
Here the nulli,j’s denote variables over strings in null null,
and null = nullnull1nullnullnullnullnullnullfnull is an null-tuple of strings over
null’s argument variables and symbols in null . We say
that null is linear, non-erasing if null contains exactly
one occurrence of each argument variable. We call null
and null the rank and the fan-out of null, respectively,
and write null(null) and null(null) to denote these quantities.
Example 1 null1(nullnull1,1nullnull1,2null) = nullnull1,1null1,2null takes as
input a tuple with two strings and returns a tuple
with a single string, obtained by concatenating the
components in the input tuple. null2(nullnull1,1nullnull1,2null) =
nullnullnull1,1nullnullnullnull1,2nullnull takes as input a tuple with two
strings and wraps around these strings with sym-
bols nullnullnullnullnullnullnull null null . Both functions are linear, non-
erasing, and we have null(null1) = null(null2) = 1, null(null1) = 1
and null(null2) = 2. a50
A linear context-free rewriting system is a tuple
null = (nullNnullnullTnullnullnullnull), where nullN and nullT are finite,
disjoint alphabets of nonterminal and terminal sym-
bols, respectively. Each null null nullN is associated with
a value null(null), called its fan-out. The nonterminal null
is the start symbol, with null(null) = 1. Finally, null is a
set of productions of the form
null : null null null(null1nullnull2nullnullnullnullnullnullr(g)) null (1)
where nullnullnull1nullnullnullnullnullnullr(g) null nullN, and null : (null nullT )f(A1)
nullnullnullnullnull (null nullT )f(Ar(g)) null (null nullT )f(A) is a linear, non-
erasing function.
Production (1) can be used to transform the
null(null) string tuples generated by the nonterminals
null1nullnullnullnullnullnullr(g) into a tuple of null(null) strings gener-
ated by null. The values null(null) and null(null) are called the
rank and fan-out of null, respectively, written null(null) and
null(null). Given that null(null) = 1, null generates a set of
strings, defining the language null(null).
Example 2 Let null1 and null2 be as in Example 1, and
let null3() = nullnullnullnullnull. Consider the LCFRS null defined by
the productions null1 : null null null1(null), null2 : null null null2(null)
and null3 : null null null3(). We have null(null) = 1, null(null) =
null(null) = 2, null(null3) = 0 and null(null1) = null(null2) = null(null) =
1. We have null(null) = nullnullnnullnnullnnulln nullnull null 1null. For in-
stance, the string null3null3null3null3 is generated by means
fan-out strategy
4 ((null1 nullnull4) nullnull3)null nullnull2
3 (null1 nullnull4)null null (null2 nullnull3)
3 ((null1 nullnull2)null nullnull4) nullnull3
2 ((nullnull2 nullnull3) nullnull4) nullnull1
Figure 1: Some parsing strategies for production null in Ex-
ample 3, and the associated maximum value for fan-out.
Symbol null denotes the merging operation, and superscript
null marks the first step in the strategy in which the highest
fan-out is realized.
of the following bottom-up process. First, the tuple
nullnullnullnullnull is generated by null through null3. We then iterate
three times the application of null2 to nullnullnullnullnull, resulting
in the tuple nullnull3null3nullnull3null3null. Finally, the tuple (string)
nullnull3null3null3null3null is generated by null through application of
null1. a50
Existing parsing algorithms for LCFRSs exploit
dynamic programming. These algorithms compute
partial parses of the input string null, represented by
means of specialized data structures called items.
Each item indexes the boundaries of the segments
of null that are spanned by the partial parse. In the
special case of parsing based on CFGs, an item con-
sists of two indices, while for TAGs four indices are
required.
In the general case of LCFRSs, parsing of a pro-
duction null as in (1) can be carried out in null(null) null 1
steps, collecting already available parses for nonter-
minals null1nullnullnullnullnullnullr(g) one at a time, and ‘merging’
these into intermediate partial parses. We refer to the
order in which nonterminals are merged as a pars-
ing strategy, or, equivalently, a factorization of the
original grammar rule. Any parsing strategy results
in a complete parse of null, spanning null(null) = null(null)
segments of null and represented by some item with
2null(null) indices. However, intermediate items ob-
tained in the process might span more than null(null)
segments. We illustrate this through an example.
Example 3 Consider a linear non-erasing function
null(nullnull1,1nullnull1,2nullnull nullnull2,1nullnull2,2nullnull nullnull3,1nullnull3,2nullnull nullnull4,1nullnull4,2null)
= nullnull1,1null2,1null3,1null4,1null null3,2null2,2null4,2null1,2null, and a pro-
duction null : null null null(null1nullnull2nullnull3nullnull4), where all the
nonterminals involved have fan-out 2. We could
parse null starting from null1, and then merging with null4,
452
v1
v2
v3 v4e1
e3
e2
e4
Figure 2: Example input graph for our construction of an
LCFRS production.
null3, and null2. In this case, after we have collected the
first three nonterminals, we have obtained a partial
parse having fan-out 4, that is, an item spanning 4
segments of the input string. Alternatively, we could
first merge null1 and null4, then merge null2 and null3, and
finally merge the two obtained partial parses. This
strategy is slightly better, resulting in a maximum
fan-out of 3. Other possible strategies can be ex-
plored, displayed in Figure 1. It turns out that the
best parsing strategy leads to fan-out 2. a50
The maximum fan-out null realized by a parsing
strategy determines the space complexity of the
parsing algorithm. For an input string null, items will
require (in the worst-case) 2null indices, each taking
null(nullnullnull) possible values. This results in space com-
plexity of null(nullnullnull2f). In the special cases of parsing
based on CFGs and TAGs, this provides the well-
known space complexity of null(nullnullnull2) and null(nullnullnull4),
respectively.
It can also be shown that, if a partial parse hav-
ing fan-out null is obtained by means of the combi-
nation of two partial parses with fan-out null1 and null2,
respectively, the resulting time complexity will be
null(nullnullnullf+f1+f2) (Seki et al., 1991; Gildea, 2010). As
an example, in the case of parsing based on CFGs,
nonterminals as well as partial parses all have fan-
out one, resulting in the standard time complexity of
null(nullnullnull3) of dynamic programming methods. When
parsing with TAGs, we have to manipulate objects
with fan-out two (in the worst case), resulting in time
complexity of null(nullnullnull6).
We investigate here the case of general LCFRS
productions, whose internal structure is consider-
ably more complex than the context-free or the tree
adjoining case. Optimizing the parsing complexity
for a production means finding a parsing strategy
that results in minimum space or time complexity.
We now turn the above optimization problems
into decision problems. In the MIN SPACE STRAT-
EGY problem one takes as input an LCFRS produc-
tion null and an integer null, and must decide whether
there exists a parsing strategy for null with maximum
fan-out not larger than null. In the MIN TIME STRAT-
EGY problem one is given null and null as above and must
decide whether there exists a parsing strategy for
null such that, in any of its steps merging two partial
parses with fan-out null1 and null2 and resulting in a par-
tial parse with fan-out null, the relation null+null1+null2 null null
holds.
In this paper we investigate the above problems in
the context of a specific family of linguistically mo-
tivated parsing strategies for LCFRSs, called head-
driven. In a head-driven strategy, one always starts
parsing a production null from a fixed nonterminal in
its rhs, called the head of null, and merges the remain-
ing nonterminals one at a time with the partial parse
containing the head. Thus, under these strategies,
the construction of partial parses that do not include
the head is forbidden, and each parsing step involves
at most one partial parse. In Figure 1, all of the dis-
played strategies but the one in the second line are
head-driven (for different choices of the head).
3 NP-completeness results
For an LCFRS production null, let null be its head non-
terminal, and let null1nullnullnullnullnullnulln be all the non-head
nonterminals in null’s rhs, with null+ 1 = null(null). A head-
driven parsing strategy can be represented as a per-
mutation null over the set [null], prescribing that the non-
head nonterminals in null’s rhs should be merged with
null in the order nullpi(1)nullnullpi(2)nullnullnullnullnullnullpi(n). Note that
there are null! possible head-driven parsing strategies.
To show that MIN SPACE STRATEGY is NP-
hard under head-driven parsing strategies, we reduce
from the MIN CUT LINEAR ARRANGEMENT prob-
lem, which is a decision problem over (undirected)
graphs. Given a graph null = (nullnullnull) with set of ver-
tices null and set of edges null, a linear arrangement
of null is a bijective function null from null to [null], where
nullnullnull = null. The cutwidth of null at gap null null [nullnull1] and
with respect to a linear arrangement null is the number
of edges crossing the gap between the null-th vertex and
its successor:
nullnull(nullnullnullnullnull) = nullnull(nullnullnull) null nullnullnull(null) null null null null(null)nullnull null
453
null : null null null(nullnullnull1nullnull2nullnull3nullnull4)
null(nullnullH,e1nullnullH,e2nullnullH,e3nullnullH,e4nullnullnullnullA1,e1,lnullnullA1,e1,rnullnullA1,e3,lnullnullA1,e3,rnullnullnullnullA2,e1,lnullnullA2,e1,rnullnullA2,e2,lnullnullA2,e2,rnullnull
nullnullA3,e2,lnullnullA3,e2,rnullnullA3,e3,lnullnullA3,e3,rnullnullA3,e4,lnullnullA3,e4,rnullnullnullnullA4,e4,lnullnullA4,e4,rnull) =
null nullA1,e1,lnullA2,e1,lnullH,e1nullA1,e1,rnullA2,e1,rnull nullA2,e2,lnullA3,e2,lnullH,e2nullA2,e2,rnullA3,e2,rnull
nullA1,e3,lnullA3,e3,lnullH,e3nullA1,e3,rnullA3,e3,rnull nullA3,e4,lnullA4,e4,lnullH,e4nullA3,e4,rnullA4,e4,r null
Figure 3: The construction used to prove Theorem 1 builds the LCFRS production null shown, when given as input the
graph of Figure 2.
The cutwidth of null is then defined as
nullnull(null) = min
h
max
inull[nnull1]
nullnull(nullnullnullnullnull) null
In the MIN CUT LINEAR ARRANGEMENT problem,
one is given as input a graph null and an integer null, and
must decide whether nullnull(null) null null. This problem has
been shown to be NP-complete (Gavril, 1977).
Theorem 1 The MIN SPACE STRATEGY problem
restricted to head-driven parsing strategies is NP-
complete.
PROOF We start with the NP-hardness part. Let
null = (nullnullnull) and null be an input instance for
MIN CUT LINEAR ARRANGEMENT, and let null =
nullnull1nullnullnullnullnullnullnnull and null = nullnull1nullnullnullnullnullnullqnull. We assume
there are no self loops in null, since these loops do not
affect the value of the cutwidth and can therefore be
removed. We construct an LCFRS production null and
an integer nullnull as follows.
Production null has a head nonterminal null and a non-
head nonterminal nulli for each vertex nulli null null . We let
null generate tuples with a string component for each
edge nulli null null. Thus, we have null(null) = null. Accord-
ingly, we use variables nullH,ei, for each nulli null null, to
denote the string components in tuples generated by
null.
For each nulli null null , let null(nulli) null null be the set of
edges impinging on nulli; thus nullnull(nulli)null is the degree
of nulli. We let nulli generate a tuple with two string
components for each nullj null null(nulli). Thus, we have
null(nulli) = 2 nullnullnull(nulli)null. Accordingly, we use variables
nullAi,ej,l and nullAi,ej,r , for each nullj null null(nulli), to de-
note the string components in tuples generated by
nulli (here subscripts l and r indicate left and right
positions, respectively; see below).
We set null(null) = null + 1 and null(null) = null, and
define null by null null null(nullnullnull1nullnull2nullnullnullnullnullnulln), with
null(nullHnullnullA1nullnullnullnullnullnullAn) = nullnull1nullnullnullnullnullnullqnull. Here nullH is the
tuple of variables for null and each nullAi, null null [null], is the
tuple of variables for nulli. Each string nulli, null null [null], is
specified as follows. Let nulls and nullt be the endpoints
of nulli, with nullsnullnullt null null and null null null. We define
nulli = nullAs,ei,lnullAt,ei,lnullH,einullAs,ei,rnullAt,ei,r null
Observe that whenever edge nulli impinges on vertex
nullj, then the left and right strings generated by nullj
and associated with nulli wrap around the string gen-
erated by null and associated with the same edge. Fi-
nally, we set nullnull = null + null.
Example 4 Given the input graph of Figure 2, our
reduction constructs the LCFRS production shown
in Figure 3. Figure 4 gives a visualization of how the
spans in this production fit together. For each edge
in the graph of Figure 2, we have a group of five
spans in the production: one for the head nontermi-
nal, and two spans for each of the two nonterminals
corresponding to the edge’s endpoints. a50
Assume now some head-driven parsing strategy
null for null. For each null null [null], we define nullpii to be the
partial parse obtained after step null in null, consisting
of the merge of nonterminals nullnullnullpi(1)nullnullnullnullnullnullpi(i).
Consider some edge nullj = (nullsnullnullt). We observe that
for any nullpii that includes or excludes both nontermi-
nals nulls and nullt, the nullj component in the definition
of null is associated with a single string, and therefore
contributes with a single unit to the fan-out of the
partial parse. On the other hand, if nullpii includes only
one nonterminal between nulls and nullt, the nullj compo-
nent is associated with two strings and contributes
with two units to the fan-out of the partial parse.
We can associate with null a linear arrangement nullpi
of null by letting nullpi(nullpi(i)) = null, for each nulli null null .
From the above observation on the fan-out of nullpii ,
454
xA1,e1,lxA2,e1,l xH,e1 xA1,e1,rxA2,e1,r xA2,e2,lxA3,e2,l xH,e2 xA2,e2,rxA3,e2,r xA1,e3,lxA3,e3,l xH,e3 xA1,e3,rxA3,e3,r xA3,e4,lxA4,e4,l xH,e4 xA3,e4,rxA4,e4,r
H
A1
A2
A3
A4
Figure 4: A visualization of how the spans for each nonterminal fit together in the left-to-right order defined by the
production of Figure 3.
we have the following relation, for every null null [nullnull1]:
null(nullpii ) = null + nullnull(nullnullnullpinullnull) null
We can then conclude that nullnullnull is a positive instance
of MIN CUT LINEAR ARRANGEMENT if and only
if nullnullnullnull is a positive instance of MIN SPACE STRAT-
EGY. This proves that MIN SPACE STRATEGY is
NP-hard.
To show that MIN SPACE STRATEGY is in NP,
consider a nondeterministic algorithm that, given an
LCFRS production null and an integer null, guesses a
parsing strategy null for null, and tests whether null(nullpii ) null
null for each null null [null]. The algorithm accepts or rejects
accordingly. Such an algorithm can clearly be im-
plemented to run in polynomial time. squaresolid
We now turn to the MIN TIME STRATEGY prob-
lem, restricted to head-driven parsing strategies. Re-
call that we are now concerned with the quantity
null1 + null2 + null, where null1 is the fan-out of some partial
parse null, null2 is the fan-out of a nonterminal null, and null
is the fan out of the partial parse resulting from the
merge of the two previous analyses.
We need to introduce the MODIFIED CUTWIDTH
problem, which is a variant of the MIN CUT LIN-
EAR ARRANGEMENT problem. Let null = (nullnullnull) be
some graph with nullnullnull = null, and let null be a linear ar-
rangement for null. The modified cutwidth of null at
position null null [null] and with respect to null is the number
of edges crossing over the null-th vertex:
nullnullnull(nullnullnullnullnull) = nullnull(nullnullnull) null nullnullnull(null) null null null null(null)nullnull null
The modified cutwidth of null is defined as
nullnullnull(null) = min
h
max
inull[n]
nullnullnull(nullnullnullnullnull) null
In the MODIFIED CUTWIDTH problem one is given
as input a graph null and an integer null, and must
decide whether nullnullnull(null) null null. The MODIFIED
CUTWIDTH problem has been shown to be NP-
complete by Lengauer (1981). We strengthen this
result below; recall that a cubic graph is a graph
without self loops where each vertex has degree
three.
Lemma 1 The MODIFIED CUTWIDTH problem re-
stricted to cubic graphs is NP-complete.
PROOF The MODIFIED CUTWIDTH problem has
been shown to be NP-complete when restricted to
graphs of maximum degree three by Makedon et al.(1985), reducing from a graph problem known as
bisection width (see also Monien and Sudborough
(1988)). Specifically, the authors construct a graph
nullnull of maximum degree three and an integer nullnull from
an input graph null = (nullnullnull) with an even number null
of vertices and an integer null, such that nullnullnull(nullnull) null nullnull
if and only if the bisection width nullnull(null) of null is not
greater than null, where
nullnull(null) = min
A,BnullV
nullnull(nullnullnull) null nullnullnull null nullnullnull null nullnullnull
with nullnullnull = null, nullnullnull = null , and nullnullnull = nullnullnull.
The graph nullnull has vertices of degree two and three
only, and it is based on a grid-like gadget null(nullnullnull); see
Figure 5. For each vertex of null, nullnull includes a com-
ponent null(2null4null8null4+8). Moreover, nullnull has a compo-
nent called an null-shaped graph, containing left and
right columns null(3null4null12null4 + 12) connected by a
middle bar null(2null4null12null4 + 9); see Figure 6. From
each of the null vertex components there is a sheaf of
2null2 edges connecting distinct degree 2 vertices in
the component to 2null2 distinct degree 2 vertices in
455
null x x1
x2
x3
x4
x5 x x1 x2 x
5
x3 x
4
Figure 5: The null(5null10) component (left), the modification of its degree 2 vertex null (middle), and the corresponding
arrangement (right).
the middle bar of the null-shaped graph. Finally, for
each edge (nullinullnullj) of null there is an edge in nullnull con-
necting a degree 2 vertex in the component corre-
sponding to the vertex nulli with a degree 2 vertex in
the component corresponding to the vertex nullj. The
integer nullnull is set to 3null4 + null3 + null null 1.
Makedon et al. (1985) show that the modified
cutwidth of null(nullnullnull) is null null 1 whenever null null 3 and
null null 4null + 8. They also show that an optimal lin-
ear arrangement for nullnull has the form depicted in Fig-
ure 6, where half of the vertex components are to
the left of the null-shaped graph and all the other ver-
tex components are to the right. In this arrangement,
the modified cutwidth is attested by the number of
edges crossing over the vertices in the left and right
columns of the H-shaped graph, which is equal to
3null4 null 1 + null22null2 + null = 3null4 + null3 + null null 1 (2)
where null denotes the number of edges connecting
vertices to the left with vertices to the right of the
null-shaped graph. Thus, nullnull(null) null null if and only if
nullnullnull(nullnull) null nullnull.
All we need to show now is how to modify the
components of nullnull in order to make it cubic.
Modifying the vertex components All vertices
null of degree 2 of the components corresponding to
a vertex in null can be transformed into a vertex of
degree 3 by adding five vertices null1nullnullnullnullnullnull5 con-
nected as shown in the middle bar of Figure 5. Ob-
serve that these five vertices can be positioned in
the arrangement immediately after null in the order
null1nullnull2nullnull5nullnull3nullnull4 (see the right part of the figure).
The resulting maximum modified cutwidth can in-
crease by 2 in correspondence of vertex null5. Since
the vertices of these components, in the optimal
arrangement, have modified cutwidth smaller than
2null4 +null3 +null2, an increase by 2 is still smaller than
the maximum modified cutwidth of the entire graph,
which is 3null4 + null(null3).
Modifying the middle bar of the H-shaped graph
The vertices of degree 2 of this part of the graph can
be modified as in the previous paragraph. Indeed, in
the optimal arrangement, these vertices have mod-
ified cutwidth smaller than 2null4 + 2null3 + null2, and
an increase by 2 is still smaller than the maximum
cutwidth of the entire graph.
Modifying the left/right columns of the H-shaped
graph We replace the two copies of component
null(3null4null12null4 + 12) with two copies of the new
component null(3null4null24null4 + 16) shown in Figure 7,
which is a cubic graph. In order to prove that rela-
tion (2) still holds, it suffices to show that the modi-
fied cutwidth of the component null(nullnullnull) is still null null1
whenever null null 3 and null = 8null + 16.
We first observe that the linear arrangement ob-
tained by visiting the vertices of null(nullnullnull) from top to
bottom and from left to right has modified cutwidth
nullnull1. Let us now prove that, for any partition of the
vertices into two subsets null1 and null2 with nullnull1nullnullnullnull2null null
4null2, there exist at least null disjoint paths between ver-
tices of null1 and vertices of null2. To this aim, we dis-
tinguish the following three cases.
null Any row has (at least) one vertex in null1 and one
vertex in null2: in this case, it is easy to see there
exist at least null disjoint paths between vertices
of null1 and vertices of null2.
null There exist at least 3null ‘mixed’ columns, that is,
columns with (at least) one vertex in null1 and one
vertex in null2. Again, it is easy to see that there
exist at least null disjoint paths between vertices
456
Figure 6: The optimal arrangement of nullnull.
of null1 and vertices of null2 (at least one path every
three columns).
null The previous two cases do not apply. Hence,
there exists a row entirely formed by vertices
of null1 (or, equivalently, of null2). The worst case
is when this row is the smallest one, that is, the
one with (cnull3null1)2 + 1 = 4null + 7 vertices. Since
at most 3null null 1 columns are mixed, we have
that at most (3null null 1)(null null 2) = 3null2 null 7null +
2 vertices of null2 are on these mixed columns.
Since nullnull2null null 4null2, this implies that at least null
columns are fully contained in null2. On the other
hand, at least 4null+7null(3nullnull1) = null+8 columns
are fully contained in null1. If the null1-columns
interleave with the null2-columns, then there exist
at least 2(nullnull1) disjoint paths between vertices
of null1 and vertices of null2. Otherwise, all the null1-
columns precede or follow all the null2-columns
(this corresponds to the optimal arrangement):
in this case, there are null disjoint paths between
vertices of null1 and vertices of null2.
Observe now that any linear arrangement partitions
the set of vertices in null(nullnullnull) into the sets null1, consist-
ing of the first 4null2 vertices in the arrangement, and
null2, consisting of all the remaining vertices. Since
there are null disjoint paths connecting null1 and null2, there
must be at least nullnull1 edges passing over every vertex
in the arrangement which is assigned to a position
between the (4null2 + 1)-th and the position 4null2 + 1
from the right end of the arrangement: thus, the
modified cutwidth of any linear arrangement of the
vertices of null(nullnullnull) is at least null null 1.
We can then conclude that the original proof
of Makedon et al. (1985) still applies, according to
relation (2). squaresolid
Figure 7: The null(5null10) component.
We can now reduce from the MODIFIED
CUTWIDTH problem for cubic graphs to the MIN
TIME STRATEGY problem restricted to head-driven
parsing strategies.
Theorem 2 The MIN TIME STRATEGY problem re-
stricted to head-driven parsing strategies is NP-
complete.
PROOF We consider hardness first. Let null and null
be an input instance of the MODIFIED CUTWIDTH
problem restricted to cubic graphs, where null =
(nullnullnull) and null = nullnull1nullnullnullnullnullnullnnull. We construct an
LCFRS production null exactly as in the proof of The-
orem 1, with rhs nonterminals nullnullnull1nullnullnullnullnullnulln. We
also set nullnull = 2 nullnull + 2 nullnullnullnull + 9.
Assume now some head-driven parsing strategy null
for null. After parsing step null null [null], we have a partial
parse nullpii consisting of the merge of nonterminals
nullnullnullpi(1)nullnullnullnullnullnullpi(i). We write nullnull(nullnullnullnullnull) to denote
the exponent of the time complexity due to step null.
As already mentioned, this quantity is defined as the
sum of the fan-out of the two antecedents involved
in the parsing step and the fan-out of its result:
nullnull(nullnullnullnullnull) = null(nullpiinull1) + null(nullpi(i)) + null(nullpii ) null
Again, we associate with null a linear arrangement
nullpi of null by letting nullpi(nullpi(i)) = null, for each nulli null null .
As in the proof of Theorem 1, the fan-out of nullpii
is then related to the cutwidth of the linear arrange-
457
ment nullpi of null at position null by
null(nullpii ) = nullnullnull + nullnull(nullnullnullpinullnull) null
From the proof of Theorem 1, the fan-out of nonter-
minal nullpi(i) is twice the degree of vertex nullpi(i), de-
noted by nullnull(nullpi(i))null. We can then rewrite the above
equation in terms of our graph null:
nullnull(nullnullnullnullnull) = 2 nullnullnullnull + nullnull(nullnullnullpinullnullnull 1) +
+ 2 nullnullnull(nullpi(i))null + nullnull(nullnullnullpinullnull) null
The following general relation between cutwidth
and modified cutwidth is rather intuitive:
nullnullnull(nullnullnullpinullnull) = 12 null [nullnull(nullnullnullpinullnullnull 1) +
nullnullnull(nullpi(i))null + nullnull(nullnullnullpinullnull)] null
Combining the two equations above we obtain:
nullnull(nullnullnullnullnull) = 2 nullnullnullnull + 3 nullnullnull(nullpi(i))null +
+ 2 nullnullnullnull(nullnullnullpinullnull) null
Because we are restricting null to the class of cubic
graphs, we can write:
nullnull(nullnullnullnullnull) = 2 nullnullnullnull + 9 + 2 nullnullnullnull(nullnullnullpinullnull) null
We can thus conclude that there exists a head-driven
parsing strategy for null with time complexity not
greater than 2 null nullnullnull + 9 + 2 null null = nullnull if and only
if nullnullnull(null) null null.
The membership of MODIFIED CUTWIDTH in NP
follows from an argument similar to the one in the
proof of Theorem 1. squaresolid
We have established the NP-completeness of both
the MIN SPACE STRATEGY and the MIN TIME
STRATEGY decision problems. It is now easy to see
that the problem of finding a spaceor time-optimal
parsing strategy for a LCFRS production is NP-hard
as well, and thus cannot be solved in polynomial (de-
terministic) time unless P = NP.
4 Concluding
remarks
Head-driven strategies are important in parsing
based on LCFRSs, both in order to allow statistical
modeling of head-modifier dependencies and in or-
der to generalize the Markovization of CFG parsers
to parsers with discontinuous spans. However, there
are null! possible head-driven strategies for an LCFRS
production with a head and null modifiers. Choosing
among these possible strategies affects both the time
and the space complexity of parsing. In this paper
we have shown that optimizing the choice according
to either metric is NP-hard. To our knowledge, our
results are the first NP-hardness results for a gram-
mar factorization problem.
SCFGs and STAGs are specific instances of
LCFRSs. Grammar factorization for synchronous
models is an important component of current ma-
chine translation systems (Zhang et al., 2006), and
algorithms for factorization have been studied by
Gildea et al. (2006) for SCFGs and by Nesson et al.(2008) for STAGs. These algorithms do not result
in what we refer as head-driven strategies, although,
as machine translation systems improve, lexicalized
rules may become important in this setting as well.
However, the results we have presented in this pa-
per do not carry over to the above mentioned syn-
chronous models, since the fan-out of these models
is bounded by two, while in our reductions in Sec-
tion 3 we freely use unbounded values for this pa-
rameter. Thus the computational complexity of opti-
mizing the choice of the parsing strategy for SCFGs
is still an open problem.
Finally, our results for LCFRSs only apply when
we restrict ourselves to head-driven strategies. This
is in contrast to the findings of Gildea (2011), which
show that, for unrestricted parsing strategies, a poly-
nomial time algorithm for minimizing parsing com-
plexity would imply an improved approximation al-
gorithm for finding the treewidth of general graphs.
Our result is stronger, in that it shows strict NP-
hardness, but also weaker, in that it applies only to
head-driven strategies. Whether NP-hardness can be
shown for unrestricted parsing strategies is an im-
portant question for future work.
Acknowledgments
The first and third authors are partially supported
from the Italian PRIN project DISCO. The sec-
ond author is partially supported by NSF grants IIS-
0546554 and IIS-0910611.
458
References
Ashok K. Chandra and Philip M. Merlin. 1977. Op-
timal implementation of conjunctive queries in rela-
tional data bases. In Proc. ninth annual ACM sympo-
sium on Theory of computing, STOC ’77, pages 77–90.
Michael Collins. 1997. Three generative, lexicalised
models for statistical parsing. In Proc. 35th Annual
Conference of the Association for Computational Lin-
guistics (ACL-97), pages 16–23.
F. Gavril. 1977. Some NP-complete problems on graphs.
In Proc. 11th Conf. on Information Sciences and Sys-
tems, pages 91–95.
Daniel Gildea and Daniel ˇStefankoviˇc. 2007. Worst-case
synchronous grammar rules. In Proc. 2007 Meeting
of the North American chapter of the Association for
Computational Linguistics (NAACL-07), pages 147–
154, Rochester, NY.
Daniel Gildea, Giorgio Satta, and Hao Zhang. 2006.
Factoring synchronous grammars by sorting. In
Proc. International Conference on Computational
Linguistics/Association for Computational Linguistics
(COLING/ACL-06) Poster Session, pages 279–286.
Daniel Gildea. 2010. Optimal parsing strategies for Lin-
ear Context-Free Rewriting Systems. In Proc. 2010
Meeting of the North American chapter of the Associa-
tion for Computational Linguistics (NAACL-10), pages
769–776.
Daniel Gildea. 2011. Grammar factorization by tree de-
composition. Computational Linguistics, 37(1):231–
248.
Carlos G´omez-Rodr´ıguez, Marco Kuhlmann, Giorgio
Satta, and David Weir. 2009. Optimal reduction of
rule length in Linear Context-Free Rewriting Systems.
In Proc. 2009 Meeting of the North American chap-
ter of the Association for Computational Linguistics
(NAACL-09), pages 539–547.
Carlos G´omez-Rodr´ıguez, Marco Kuhlmann, and Gior-
gio Satta. 2010. Efficient parsing of well-nested linear
context-free rewriting systems. In Proc. 2010 Meeting
of the North American chapter of the Association for
Computational Linguistics (NAACL-10), pages 276–
284, Los Angeles, California.
John E. Hopcroft and Jeffrey D. Ullman. 1979. Intro-
duction to Automata Theory, Languages, and Compu-
tation. Addison-Wesley, Reading, MA.
Liang Huang, Hao Zhang, Daniel Gildea, and Kevin
Knight. 2009. Binarization of synchronous
context-free grammars. Computational Linguistics,
35(4):559–595.
Laura Kallmeyer and Wolfgang Maier. 2010. Data-
driven parsing with probabilistic linear context-free
rewriting systems. In Proc. 23rd International Con-
ference on Computational Linguistics (Coling 2010),
pages 537–545.
Marco Kuhlmann and Giorgio Satta. 2009. Treebank
grammar techniques for non-projective dependency
parsing. In Proc. 12th Conference of the European
Chapter of the ACL (EACL-09), pages 478–486.
Thomas Lengauer. 1981. Black-white pebbles and graph
separation. Acta Informatica, 16:465–475.
Wolfgang Maier and Anders Søgaard. 2008. Treebanks
and mild context-sensitivity. In Philippe de Groote,
editor, Proc. 13th Conference on Formal Grammar
(FG-2008), pages 61–76, Hamburg, Germany. CSLI
Publications.
F. S. Makedon, C. H. Papadimitriou, and I. H. Sudbor-
ough. 1985. Topological bandwidth. SIAM J. Alg.
Disc. Meth., 6(3):418–444.
B. Monien and I.H. Sudborough. 1988. Min cut is NP-
complete for edge weighted trees. Theor. Comput.
Sci., 58:209–229.
Rebecca Nesson, Giorgio Satta, and Stuart M. Shieber.
2008. Optimal null-arization of synchronous tree adjoin-
ing grammar. In Proc. 46th Annual Meeting of the
Association for Computational Linguistics (ACL-08),
pages 604–612.
Owen Rambow and Giorgio Satta. 1999. Independent
parallelism in finite copying parallel rewriting sys-
tems. Theor. Comput. Sci., 223(1-2):87–120.
Benoˆıt Sagot and Giorgio Satta. 2010. Optimal rank re-
duction for linear context-free rewriting systems with
fan-out two. In Proc. 48th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 525–533,
Uppsala, Sweden.
Giorgio Satta and Enoch Peserico. 2005. Some com-
putational complexity results for synchronous context-
free grammars. In Proceedings of Human Lan-
guage Technology Conference and Conference on
Empirical Methods in Natural Language Processing
(HLT/EMNLP), pages 803–810, Vancouver, Canada.
H. Seki, T. Matsumura, M. Fujii, and T. Kasami. 1991.
On multiple context-free grammars. Theoretical Com-
puter Science, 88:191–229.
Stuart M. Shieber, Yves Schabes, and Fernando C. N.
Pereira. 1995. Principles and implementation of de-
ductive parsing. The Journal of Logic Programming,
24(1-2):3–36.
K. Vijay-Shankar, D. L. Weir, and A. K. Joshi. 1987.
Characterizing structural descriptions produced by
various grammatical formalisms. In Proc. 25th An-
nual Conference of the Association for Computational
Linguistics (ACL-87), pages 104–111.
Hao Zhang, Liang Huang, Daniel Gildea, and Kevin
Knight. 2006. Synchronous binarization for machine
translation. In Proc. 2006 Meeting of the North Ameri-
can chapter of the Association for Computational Lin-
guistics (NAACL-06), pages 256–263.
459

