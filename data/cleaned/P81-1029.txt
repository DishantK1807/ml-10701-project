0.0 INTRODUCTION
A CASE FOR RULE-DRIVEN SEMANTIC PROCESSING Marcha Palmer Department of Computer and Information Science University of Pennsylanla The primary cask of semantic processing is to provide an appropriate mapping between the synCactlc consClCuanCs of a parsed sentence and the arguments of the semanclc predlcaces implied by the verb.
This is known as the Alignment Problem.\[Levln\] Sectloo One of thls paper gives an overview of a generally accepted approach to semantic processing that goes through several levels of representation to achieve this mapping.
Although somewhat inflexible and cumbersome, the different levels succeed in preservln S the context sensitive information provided by verb semantics.
Section Two presents the author's rule-driven approach which is more uniform and flexible yet still accommodates context senslClve constraints.
This approach is based on general underlying principles for syntactic methods of Incroduclns semantic arguments and has interesting implications for linguistic theories about case.
These implications are dicuesed in Section Three.
A system that implements this approach has been designed for and tested on pulley problem statements gathered from several physics text books.\[Palmer\] 1.0 MULTI-STAGE SEMANTIC ANALYSIS A popular approach \[Woods\], \[Simmons\], \[Novak\] for assisnlng semantic roles Co syntactic coosClcueoCs can be described with three levels of representation a schema level, a canonical level, and a predicate level.
These levels are used to bridge the gap between the surface syncactlc representation and the "deep" conceptual represeoCatlon necessary for communicating wlth the Incernal database.
While the following description of these levels may not correspond to any one Implementaclon in particular, It will give the flavor of the overall approach.
I.i Schema Level The first level corresponds to the possible surface order configurations a verb can appear in.
In a domain of equilibrium problems the sentence "A rope supports one end of a scaffold".
could match a schema like "<physobJ> SUPPORTS <locpart> of <physobJ>".
The word ordering here implies chec the first <physobJ> is the SUBJ and the <locpart> is the OBJ.
Other likely schemes for sentences involving the SUPPORT verbs are "<physobJ> SUPPORTS <physobJ> AT <locpart>," "<physobJ> SUPPORTS <force>," "<physobJ> IS SUPPORTED," sod "<locpart> IS SUPPORTED."\[Novak\] Once a particular sentence has marched a schema, it is useful to rephrase the information in a more "canonical" form, so Chac a single of inference rules can apply Co a group of schemas.
1.2 Canonical
Level This intermediate level of representation usually consists of the verb itself, (or perhaps a more primitive semantic predicate chosen to represent the verb) and a list of possible roles, e.g. arguments to the predicate.
These roles correspond loosely to a union of the various semantic types indicated in the schemas.
The schemas above could all easily map into: SUPPORTS(<physobJ>l,<physobJ>2, <Iocpart>,<force>).
The "canonical" verb representation found at this level bears certain similarities to a standard verb case frame, \[Simmons, Bruce\] in the roles played by the arguments to that predicate.
There has been some controversy over whether or not any benefits are gained by labeling these arguments "cases" and aCtempting to apply linguistic generalities about case.
\[Fillmore\] The possible benefits do not seem to have been realized, wlth a resulting shift away from explicit ties to case in recent work.
\[Charnlak\], \[Wilks\] 1.3 Predicate Level However, the implied relationships between the arguments still have to be spelled out, and thls is the function of our third and final level of representation.
This level necessarily makes use of predicates chat can be found in the data base, and for the purposes of the program is effectively s "deep" semanclc representaClon.
A verb such as SUPPORT would require several predicates in an equilibrium domain.
For example, the "scaffold" sentence above could result in the followln S llst corresponding Co the general predlcaCes listed immediately below.
"Scaffold" Example SUPPORT(rope,scaffold) UP(Fl,rope) UOWN(F2,scaffold) CONTACT(rope,scaffold) LOCPT(rtendl,rope) LOCPT(rtend2,scaffold) SAMEPLACE(rceodl,rtend2) General Predicates SUPPORT(<physobJ>l,<physobJ>2) UP(<force>l,<physobJ>1) OOWN(<force>2,<physobj>2) CONTACT(<physobJ>l,<physobJ>2) LOCPT(<locparc>l,<physobJ>l) LOCPT(<locpart>2,<physobJ>2) SAMEPLACE(<locpart>t,<locpert>2) 125 Producing the above list requires common sense deductions \[Bundyl about the existence of objects fllllng arguments chat do not correspond directly Co the canonical arguments, i.e. the two <locpt>s, and any arguments that were missing from the explicit seuteoce.
For instance, in our scaffold example, no <force> was mentioned, and must be inferred.
The usefulness of the canonical form is illustrated here, as It prevents tedious duplication of inference rules for slightly varying schemas.
The relevant information from the sentence has now been expressed in a form compatible wlth some internal database.
The goal of thls semantic analysis has been to provide a mapping between the original syntactic constituents and the predicate arguments in the final representation.
For our scaffold example the following mapping has been achieved.
The filling in of gaps in the final representation, although motivated by the needs of the database, also serves to rest and expand the mapping of the syntactic constituents.
SUBJ <rope <physobJ>l OBJ <end <pbysobJ>2 OFPP<scaffold <locpart>2 An obvious question at this point is whether or not the mappings from syntactic constituents to predicate arguments can be achieved directly, since the above multi-stage approach has at least three major disadvantages: 1) It is tedious for the programmer co produce the original schemas, and the resulting amount of special purpose code is cumbersome.
It is difficult. for the programmer to guarantee that all schemas have been accounted for.
2) This type of system is not very robust.
A schema that has been left out simply cannot be matched no matter how much it has in common with stored schemas.
3) Because of the inflexibility of the system It is frequently desirable co add new Informaclon.
Adding Just one schema, much less an entire verb, can be clme consuming.
How much of a hindrance thls will be is dependent on the extent Co which the semantic information has been embedded in the code.
The LUNAR project's use of a meanlns representation language greatly increased the efficiency of adding new information.
The following section presents a system thaC uses syntactic cues at the semantic predicate level to find mappings directly.
This method has Inceresclng implications for theories about cases.
2.0 RULE-DRIVEN SEMANTIC ANALYSIS This section presents a system for semantic processin S that maps syntactic constituents directly onto the arguments of the semantic predicates suggested by the verb.
In order Co make these assignments, the possible syntactic mappings must be associated with each argument place in the original semantic predicates.
For instance, the only possible syntactic constituent that can be assigned to the <physobJ>1 place of a SUPPORT predicate is the SUBJ, and a <physobJ>2 can only be filled by an OBJ.
But a <locpart> might be an OBJ or the object of an AT preposition, as in "The scaffold iS supported at one end".
(The scaffold in this example is the syntactic subject of a passive sentence, so iC is also considered the logical object.
For our purposes we will look on it as an OBJ).
It might seem at first glance chat we would want to allow our <physobJ>2 to be the object of ao OF preposition, as in "The rope supports one end of the scaffold".
But that is only true if the OFPP follows something llke a <locpart> which can be an OgJ in a sentence about SUPPORT.
(Of course, Just any OPPP will not supply a <physobJ>2.
In "The rope supports the end of greatest weight.", the object of the OPPP Is not a <physobJ> so could not satisfy <physobJ>2.
The <physobJ>2 in thls case must be provided by the previous context).
It is this very dependency on the existence of other spmcific types of syntactic constituents chat was captured by the schemas mentioned above.
It is necessary for an alternative system to also handle context sensitive constraints.
2.1 Decision
Trees The three levels of representation mentioned in Section One can be viewed as the bottom, middle and top of a tree.
SUPPOET(p I,p2) CONTACT(pl,p2) LOCPT (lpC 1,pl ) LOCPT(lpc2,p2) I J I SUPPORT(p I, p2, lpt, force) / I \ / J \ I SUBJ OBJ OPPP <physobJ> SUPPORTS <locpart> OF <physobJ> "The rope supports one and of the scaffold".
126 The inference rules that link the three levels deal mainly with any necessary renaming of the role an argument plays.
The SUBJ of the schema level is renamed <physobJ>1 or pl at the canonical level, and is still pl at the predicate level.
One way of viewing the schemas is as leaf nodes produced by a decision tree that starts at the predicate level.
The levels of the tree correspond to the different syntactic constituents that can map onto the arguments of the original set of predicates.
Since more than one argument can be renamed as a particular syntactic constituent, there can be more than one branch at each level.
If a semantic argument might not be mentioned explicitly in the syntactic configuration, this also has to be expressed as a rule, ex.
pl -> NULL.
(Ex. "The scaffold is supported").
When all of the branches have been taken, each terminal node represents the set of decisions corresponding to a particular schema.
(See Appendix A).
Note that the canonical level never has co be expressed explicitly.
By working top down instead of bottom up unnecessary duplication of inference rules iS automatically avoided.
The information in the original three levels can be stored equivalently as the top node of the decision tree along with the renaming rules for the semantic arguments (rewrite rules).
This would reverse the order of analysis from the bottom-up mode suggested in section one to a cop-down mode.
This uses a more compact representation, but would be computationally less efficient.
Growing the entire decision tree every time a sentence needed to be matched would be quite cumbersome.
However, if only the path to the correct terminal node needed to be generated, this approach would be computatlonally competitive.
By ordering the decisions according to syntactic precedence, and by using the data from the sentence in question to prune the tree WHILE it is being generated, the correct decisions can usuallly be made, with the only path explored being the path to the correct schema.
2.2 Context
Sensitive Constraints Context sensltivity can be preserved by only allowing the p2->OPPP rule to apply after a mappin S for Iptl has been found, evidence that an Iptl->OBJ rule could have already applied.
To test whether such a mapping has been made given a LOCPT predicate, it is only necessary tO see if the iptl argument has been renamed by a syntactic constituent.
The renaming process can be thought of as an instantlatlon of typed variables, the semantic arguments by syntactic constituents.
\[Palmer, Galller, and Welner\] Then the following preconditions must be satisfied before applying the p2->OFPP rule: ( /\ stands for AND) p2->OFPP/ LOCPT(Iptl,p2) /\ not(varlable(iptl)) These preconditions will still need to be satisfied when a LOCPT predicate is part of another verb representation.
Anytime a <locpart> is mentioned It can be followed by an OFPP introducing the <physobJ> of which It is a location part.
This relationship between a <locparc> and a <physobJ> is Just as valid when the verb is "hang" or "connect".
Ex. "The pulley is connected to the right end of the string".
" The particle is hung from the right end of the string".
These particular constraints are general to the domain rather than being restricted to "support'.
This illustetes the efflclency of associating constraints with semantic predicates rather than verbs, allowing for more advantage to be taken of generalities.
There is an obvious resemblance here to the notation used for Local Constraints grammars \[Joshi and Levy\]: p2->OFPP/ DOM(LOCPT) /\ LMS(Iptl) /\ not(var(iptl)) DOM DOMinate, LMS Left Most Sister It can be demonstrated that the context sensitive constraints presented here are a simple special case of their Local Constraints, since the dominating node is limited to being the immediate predicate head.
Whether or not such a restricted local context will prove sufficient for more complex domains remains to be proven.
2.3 Overview
As illustrated above, our mappings from syntactic constituents to semantic arguments can be found directly, thus gaining flexibility and uniformity without losing context sensitivity.
Once the verb has been recognized, the semantic predicates representing the verb can drive the selection of renaming rules directly, avoiding the necessity of an intermediate level of representation.
The contextual dependencies originally captured by the schemes are preserved in preconditions that are associated with the application of the renaming rules.
Since the renaming rules and the preconditions refer only to semantic predicates and arguments to the predicates, there is a sense in which they are independent of individual verbs.
By applying only those rules that are relevant to the sentence in question, the correct mappings can be found quickly and efficiently.
The resulting system is highly flexible, since the same predicates are used in the representation of all the verbs, and many of the preconditions are general to the domain.
This facillitates the addition of similar verbs since most of the necessary semantic predicates with the appropriate renaming rules will already be present.
127 3.0 THE ROLE OF CASE INFORMATION Although the canonical level has often been viewed as the case frame level, doing away with the canonical level does not necessarily imply chat cases are no longer relevant to semantic processing.
On the contrary, the importance here of syntacclc cues for introducing semantic arguments places even more emphasis on the traditional noclon of case.
The suggestion is chat the appropriate level for case information is in fact the predicate level, and that most cradlClonal cases should be seen as arguments to clearly defined semantic predicates.
These predicates are no~ merely the simple set of flat predicates indicated in the previous sections.
There is an implicit structurihg to chat set of predicates indicated by the implications holding between them.
A SUPPORT relationship implies the existence of UP and DOWN forces and a CONTACT relationship.
A CONTACT relationship implies the existence of LOCPT's and a SAMEPLACE relationship between them.
The set of predicates describing "support" can be produced by expanding the implications of the SUPPORT(pl,p2) predicate into UP(fl,pl) and DOWN(f2,p2) and CONTACT(pl,p2).
CONTACT(pl,p2) is in turn expanded into LOCPT(Iptl,pl) and LOCPT(ipt2,p2) and SAMEPLACE(IpI,Ipt2).
These deflniclons, or expansions, are represented as the following rewrite rules: supporc<->SUPPORT(pl,p2) SUPPORT(pl,p2)<-> UP(fI,pI)/\DOWN(f2,p2) /\CONTACT(pl,p2) CONTACT(pl,p2)<-> LOCPT(IpCI,pI)/\LOCPT(Ipt2,p2) /\SAMEPLACE(pl,p2) When "support" has been recognized as the verb, these rules can be applied, to build up the set of semantic predicates needed to represent support.
If there were expansions for UP and DOWN they could be applied as well.
As the rules are being applied the mappings of syntactic constituents to predicate arguments can be made at the same time, as each argument is introduced.
The case information is not merely the set of semantic predicates or Just the SUPPORT(pI,p2) predicate alone.
Rather, the case information is represented by the set of predicates, the dependencies indicated by the expansions for the predicates, and the renaming rules that arm needed to fled the appropriate mappings.
The renaming rules correspond to the traditional syntactic cues for introducing particular cases.
They are further restricted by being associated wlth the predicate context of an argument rather than the argument in IsolaClon.
When this structured case information is used to drive semantic processing, It is not a passive frame that waits for its slots to be filled, but rather an active structure that goes in search of fillers for itsarguments.
If these Instantiatlons are sot indicated explicitly by syntax, they must be inferred from a world model.
The following example illustrates how the acClve case structure can also supply cases not mentioned explicitly in the sentence.
3.1 Example
Given a pair of sentences like "Two men are lifting a dresser.
A rope supports the end of greatest weight".
we will assume that the first sentence has already been processed.
Having recognized that the verb of the second sentence is "support', the appropriate expansion can be applied co produce: SUPPORT(rope,p2) This would in turn be expanded to: UP(fl,rope) DOWN(f2,p2) CONTACT(rope,p2) In expanding the CONTACT relationship, an 1ptl for "rope" and a p2 for "end" need co be found.
(See Section Two) Since the sentence does not supply an ATPP that might introduce an lpcl for the "rope" and since there are no more expansions that can be applied, a plausible inference must be made.
The lptl is likely co be an endpoinc Chat is not already in contact with something else.This implicit object corresponding to the free end of the rope cam be name "ropend2".
The p2 is more difficult.
The OFPP dome ant introduce a cphyaobJ>, although It does specify the "and" more precisely.
The "end" must first be recognized as belonging Co the dresser, and then as being its heaviest end, "dresserend2".
This is really an anaphora problem chat cannot be decided by the verb, and could in fact have already been handled.
Given "dreseerend2", it only remains for the "dresser" Co be inferred as the p2 of the LOCPT relationship, using the same principles that allow an OFPP to introduce a p2.
The final set of predicates would be SUPPORT(rope,dresser) /1\ /1\ / I \ UP(fl,rope) \] DOWN(f2,dreeser) I CONTACT(rope,dresser) /1\ /l\ / I \ LOCPT(ropend2,rope)LOCPT(dreeserend2,dresser) I \[ SAMZPLACE(ropmud2,dresserend2) Both the ropeod2 and "dresser" were supplied by plausible reasoning using the context and a world model.
There are always many inferences that can be drawn when processing a single sentence.
The detailed nature of the case structure presented above gives one method of regulating ~hls inferencing.
128 3.2 Associations wlt____~h llnsulstlcs A recent trend in linguistics co consider cases as &rguments to thematic relations offers a surprising amount of support for this position.
Without denying the extremely useful tles between syntactic constltuencs sod semantic cases, Jackendoff questions the abillcy of case to capture complex semantic relationships.
\[Jackendoff\] His main objection is that standard case theory does not allow a noun phrase to be assigned more than one case.
In examples llke "Esau traded hls birthright (to Jacob) for a mess of pottage," Jackendoff sees two related actions: "The first is the change of hands of the birthright from Esau to Jacob.
The direct object is Theme, the sub~ect is Source, and the to-object is Goal.
Also there is what I will call the secondary action, the changlnS of hands of the mess of pottage in the ocher direction.
In this action, the for-phrase is Secondary Theme, the subject is Secondary Goal, and the to-phrase is Secondary Source".
\[p.35\] This, of course, could not be captured by a Fillmore-llke case frame.
Jackendoff concludes that, "A theory of case grammar in which each noun phrase has exactly one semantic function in deep structure cannot provide deep structures which satisfy the stron S Katz-Postal Hypothesis, that is, which provide all semantic information about the sentence".
Jackendoff is sot completely dlscardln E case information, but rather suggesting a new level of semantic representation that tries to incorporate some of the advantages of case.
Making constructive use of Gruber's system of thematic relationships \[Gruher\], Jackendoff postulates "The thematic relations can now be defined in terms of \[these\] semantic subfunctlons.
Agent is the argument of CAUSE chat is an individual; Theme Is the argument of CHANGE that is an individual; Source and Goal are the initial and final state arguments of CHANGE.
Location will be defined in terms of a further semanclc function BE thac takes an individual (the Theme) and a state (the Locatlon).
\[p.39\] Indeed, Jackendoff is one example of a trend noted by Janet Fodor She points out chat "it may be more revealing to regard the noun phrases which are associated in a variety of case relations with the LEXICAL verb as the arguments of the primitive SEMANTIC predicates into which It is analyzed.
These semantic predicates typically have very few arguments, perhaps three at the most, but there are a lot of them and hence there will be a lot of distinguishable "case caCesorles.'(Those which Fillmore has identified appear to be those associated wlth semantic components that are particularly frequent or prominent, such as CAUSE, USE, BECOME, AT)".
\[p.93\] Fodor summarizes with, "As a contribution CO semantics, therefore, it seems best to regard Fillmore's analyses as merely scepplng stones on the way Co a more complete specification of the meanings of verbs".
The one loose end in thls neat summation of case is its relation to syntax.
Fodor conclnues, "Whether there are any SYNTACTIC properties of case categories that Fillmore's theory predicts but which are missed by the semantic approach is another question"....
It Is the thesis of thls paper that these synCactlc properties of case categories are the very cues that are used to drive the filling of semantic arguments by syntactic constituents.
Thls system also allows the same syntactic constituent to flll more than one argument, e.g. case category.
The following section presents further evidence chat thls system could have direct implications for linguistic theories about case.
Although it may at first seem that the analysis of the INSTRUMENT case contradicts certain assumptions that have been made, it actually serves to preserve a useful disctinction between marked end unmarked INSTRUMENTS.
3.3 The
INSTRUMENT Case The cases necessary for "support" were all accomodated as arguments to semantic primitives.
Thls does not imply, however, that cases can never play a more important role In the semantic representation.
It is possible for a case to have Its own expansion which contains information about how semantic predicates should be structured.
There is quite convincing evidence in the pulley domain for the influential effect of one particular case, In thls domaln INSTRUMENTS are essentially "intermediaries" in "hang" and "connect" relationships.
An <inter>medlary is a flexible llne segment that effects a LOCATION or CONTACT relationship respectively between two physical objects.
Example sentences are "A particle is hung by a string from a pulley," and "A particle is connected to another particle by a string".
The following rewrite rules ere the expansions for the "hang" and "connect ° verbs, where the EFFECT predicate wlll have Its own expansion corresponding to the definition of an intermediary.
han S <-> EFFECT(lnter,LOCATION(pI,Ioc)) connect <-> EFFECT(Inter,CONTACT(pI,F2)) Application of these rules repectlvely results in the following representation for the example sentences: EFFECT(string,LOCATION(perticlel,pulleyl)) EFFECT(strlng,CONTACT(parrlclel,psrtlcle2)) 129 The expansion of EFFECT itself is: EFFECT(inter, REL(argl,arg2)) <-> REL(argl,inter), REL(inter,arg2)) where REL stands for any semantic predicate.
The application of this expansion to the above representations results in: LOCATION(particlel,string) LOCATION(strlng,pullayl) and CONTACT(particlel,strins) CONTACT(sCrlng,partlcla2) These predicates can then be expanded, with LOCATION bringing in SUPPORT and CONTACT, and CONTACT bringing in LOCPT.
3.4 Possible
Implications There seams to be a direct connection between the previous expansion of intermediary and the analysis of the INSTRUMENT case done by Beth Levln at MIT.\[Levln\] She pointed out a distinct difference in the use of the same INSTRUMENT in the following two sentences: "John cut his foot with a rock".
"John cut his foot on a rock".
In the first sentence there is an implication that John was in some way "controlling" the cutting of his foot, and using the rock to do so.
In the second sentence there is no such implication, and John probably cut his foot accidentally.
The use of the "with" preposition marks the rock as an INSTRUMENT.
that is being manipulated by John, whereas "on" introduces an unmarked INSTRUMENT with no implied ralationshion to John.
It would seem that something llke the expansion for EFFECT could help to capture part of what is being implied by the "control" relationship.
Bringing in the transitivity relationship makes explicit a connection between John and the rock as well as between the foot and the rock.
~n the second sentence only the connection between the foot and the rock is implied.
The connection implied here is certainly more complicated than a simple CONTACT relationship, and would neccsssitate a more detailed understanding of "cut".
But the suggestion of "control" is at least indicated by the embedding of the CUT predicate within EFFECT and CAUSE.
CAUSE(John,EFFECT(rock,(CUT(foot-of-John))) The tie between the AGENT and the INSTRUMENT is another implication of "control" that should be explored.
That the distinction between marked and unmarked INSTRUMENTS can be captured by the EFFECT relationship is illustrated by the processing of the following two sentences: "The particle is hung from a pulley by a string".
"The particle is hung on a string".
In the first sentence an "inter" (a marked INSTRUMENT) is supplied by the BYPP, and the following representation is produced: EFFECT(string,LOCATION(partlcle,pulley)) In the second sentence no "inter" is found, and in the absence of an "inter" the EFFECT relationship cannot be expanded.
The LOCATION(particle,strlng) predicate is left to stand alone and is in turn expanded.
(The ONPP can indicate a "lot.
°) The intriguing possibility of verb independent definitions for cases requires much more exploration.
\[Charniak\] The suggestion here is that a deeper level of representation, the predicate level, is appropriate for investigating case implications, and that important cases llke AGENTS and INSTRUMENTS have implications for mats-level structuring of those predicates.
3.5 Summary
In summary, there is a surprising amount of information at the semantic predicate level that allows syntactic constituents to be mapped directly onto semantic arguments.
This results in a semantic processer that has the advantage of being easy to build and more flexible than existing processers.
It also brings to light substantial evidence that cases should not be discarded but should be reexamined with respect to the roles they play as arguments to semantic predicates.
The INTERMEDIAKY case is seen to play a particularly important role having to do not with any particular semantic predicate, but with the choice of semantic predicates in general.
References \[I\] Bruce, B., Case system for natural language, "Artificial Intelligence," Vol.
6, No.
4, Winter, pp.
327-360. \[2\] Bundy, et-al, Solving Mechanics Problems Using Mats-Level Inference, Expert Systems i_.~n the Micro-Electronic ARe, Michia, D.(ed), Edinburgh University Press, Edinburgh, U.K., 1979.
\[3\] Charnlak, E., A brief on case, Working Paper No.22, (Castagnola: ~nstitute for Semantics and Cognitive Studies), L975.
{4\] Fillmore, C., The case for case, Universals In Linguistic Theory, Bach and Harms (eds).
New York; Holt, Rinehart and Winston, pp.
1-88. \[5\] Fodor, Janet D., Semantics: Theories of Meanin~ in Generative Grammar, Language and Thought Series.
Thomas Y.
Crowell Co., Inc., 1977, p.
93 130 \[6\] Gruber, Syntax and Co., 1976.
J.S., Lexlcal Structures in Semantics, North-Holland Pub.
\[7\] Jackendoff, R.S., Semantic Interpreter i_nn Generative Grammar, HIT Press, Cambridge, MA, 1972, p.
39. \[8\] Levln, B.
"Instrumental With and the Control Relation in English," HIT Master*s Thesis, 1979.
\[9\] Novak, G.S., Computer Understanding of Physics Problems Stated in Natural Language,Amerlcan Journal of CompuCatlonal Linguistics, Microfiche 53, 1976.
\[I0\] Palmer, M., Where to Connect?
Solving Problems in Semantics, DAI Working Paper No.
22, University of Edinburgh, July 1977.
\[11\] Palmer, M., "Driving Semantics for a Limited Domain," Ph.D.
Thesis, forthcoming, University of Edinburgh.
\[12\] Palmer, H., Galller, J., and Weiner, J., Implementations as Program Specifications: A Semantic Processer in Prolog, (submitted IJCAI, Vancouver, August 1981).
\[13\] Simmons, R.F., Semantic Networks: Their Computation and Use for Understanding English Sentences, Computer Models of Thought and Language, Schank and Colby (eds).
San Francisco: W.H.
Freeman and Co., 1973.
\[14\] Wilks, Y., Processing Case, "American Journal of Computational Linguistics," 1976.
\[15\] Woods, W.A., Semantics and Quantification in Natural Language Question Answering, BEN Report 3687, Cambridge, Mass, November 1977.
APPENDIX A / p2 -> OgJ/ / SUPPORT(SUBJ,OBJ) /\ CONTACT(SUBJ,OBJ) /\ LOCPT(IptI,SUBJ) /\ LOCPT(!pt2,OBJ) l ipc2 -> ATPP i SUPPORT(SUBJ,OBJ) /\ CONTACT(SUBJ,OBJ) /\ LOCPT(IptI,SUBJ) /\ LOCPT(ATPP,OBJ) I I SUBJ I SUPPORT(pl,p2) /\ CONTACT(pI,p2) /\ LOCPT(lpCl,pI) /\ LOCPT(lpc2,p2) / pl -> SUBJ / / SUPPORT(SUBJ,p2) /\ CONTACT(SUBJ,p2) /\ LOCPT(IptI,SUBJ) /\ LOCPT(Ipt2,p2) \ \ lpt2 -> OBJ \ SUPPORT(SUBJ,p2) /\ CONTACT(SUBJ,p2) /\ LOCPT(lptl,SUBJ) /\ LOCPT(OBJ,p2) \ \ p2 -> OFPP \ SUPPORT(SUBJ,OFPP) /\ CONTACT(SUBJ,OPPP) /\ LOCPT(1ptl,SUBJ) /\ LOCPT(OBJ,OPPP) \ \ OBJ ATPP \ <physobj> SUPPORTS <physobJ> AT <locpart> \ \ SUBJ \ OBJ OFPP <physobJ> SUPPORTS <locparC> OF <physobJ> \ \ pl -> NULL \ SUPPORT(pl,p2) /\ CONTACT(pI,p2) /\ LOCPT(lptl,pl) /\ LOCPT(lpC2,p2) / \ / \ etc.
etc. 131

