However, until now, Lexical Chaining algorithms have only been proposed for English as they rely on linguistic resources such as Thesauri (Morris and Hirst, 1991) or Ontologies (Barzilay and Elhadad, 1997; Hirst and St-Onge, 1997; Silber and McCoy, 2002; Galley and McKeown, 2003).
J02-4004 J91-1002 W97-0703
In particular, they have successfully been used in the field of Automatic Text Summarization(BarzilayandElhadad, 1997).
W97-0703
The TnT tagger (Brants, 2000) is first applied to our context corpus to morpho-syntactically mark all the words in it.
A00-1031
Morris and Hirst (1991) were the first to propose the concept of Lexical Chains to explore the discourse structure of a text.
J91-1002
Our chaining algorithm is based on both approaches of (Barzilay and Elhadad, 1997) and (Hirst and StOnge, 1997).
W97-0703
Their evaluation shows that their algorithm is more accurate than (Barzilay and Elhadad, 1997) and (Silber and McCoy, 2002) ones.
J02-4004 W97-0703
But, asBarzilayandElhadad(1997) point at, the use of a part-of-speech tagger could eliminate wrong inclusions of words such as read, which has both noun and verb entries in WordNet.
W97-0703
As a consequence, Silber and McCoy (2002) propose a linear time version of (Barzilay and Elhadad, 1997) lexical chaining algorithm.
J02-4004 W97-0703
In particular, (Silber and McCoy, 2002)’s implementation creates a structure, called meta-chains, that implicitly stores 36 all chain interpretations without actually creating them, thus keeping both the space and time usage of the program linear.
J02-4004
In this section, we propose a new greedy algorithm which can be seen as an extension of (Hirst and StOnge, 1997) and (Barzilay and Elhadad, 1997) algorithms as it allows polysemous words to belong to different chains thus breaking the “one-word/oneconcept per document” paradigm (Gale et al., 1992).
H92-1045 W97-0703
So, Barzilay and Elhadad (1997) propose the first dynamic method to compute Lexical Chains.
W97-0703
So, in this section, we will only present some results generated by our architecture (like (Barzilay and Elhadad, 1997; Teich and Fankhauser, 2004) do), althoughweacknowledgethatothercomparativeevaluations (with WordNet, with Human Lexical Chains or within independent applications like Text Summarization) must be done in order to draw definitive conclusions.
W97-0703
Evaluation Inthissection, asitisdonein(BarzilayandElhadad, 1997; Teich and Fankhauser, 2004), we present the c=5 c=6 c=7 c=8 Doc 1 19 13 7 7 Doc 2 13 6 3 3 Doc 3 3 4 4 4 Doc 4 6 4 3 3 Table 3: # Clusters per Lexical Chain fivehighest-scoringchainsforthebestthresholdthat we experimentally evaluated to be c = 7 for each domain (See Tables 4, 5, 6, 7).
W97-0703
In particular, in future work, we want to compare our methodology using WordNet as the basic knowledge base, implement different similarity measures (Resnik, 1995; Jiang and Conrath, 1997; Leacock and Chodorow, 1998), experiment different Lexical Chains algorithms (Hirst and St-Onge, 1997; BarzilayandElhadad, 1997; GalleyandMcKeown, 2003), scale our greedy algorithm for realworld applications following (Silber and McCoy, 2002) ideas and finally evaluate our system in independent Natural Language Processing applications such as Text Summarization (Doran et al., 2004).
J02-4004 W97-0703
Their biggest contribution to the study of Lexical Chains is the mapping of WordNet (Miller, 1995) relations and paths (transitive relationships) to (Morris and Hirst, 1991) word relationship types.
J91-1002
Indeed, comparatively to the experiments made by (Gale et al., 1992) that deal with “well written discourse”, web documents show unusual discourse structures.
H92-1045
Like in (Barzilay and Elhadad, 1997), we define a chain score which is defined in Equation 16 where |chain| is the number of words in the chain.
W97-0703
For that purpose, we propose a new greedy algorithm which can be seen as an extension of (Hirst and St-Onge, 1997) and (Barzilay and Elhadad, 1997) algorithms which allows polysemous words to belong to different chains thus breaking the “one-word/one-concept per document” paradigm (Gale et al., 1992)1.
H92-1045 W97-0703
