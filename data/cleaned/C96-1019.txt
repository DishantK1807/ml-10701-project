Connectivity in Bag Generation Arturo Trujillo and Simon Berry* School of Computer and Mathem~tical Sciences The Robert Gordon University, St Andrew Street Aberdeen Al/l 1fig Scotland {iat,cs5s by } (c~_ sct us.
vgu.ac, ul< Abstract 'Fhis l)aper presents a pruning technique which can bc used to reduce the number of paths searched in rule-based b~g generators of the type proposed by (Poznafiski el; aal., 1!)95) and (l'opowMl, 1995).
Pruning the search space in these generators is important given the.
computational cost of bag generation.
'rhe technique relies on a connectivity constraint between the semantic indices associated with each lexical sign in a ba R.
Testing the algorithm on a range of sentences shows reductions in the~ generation time and the nmnber of edges constru cl.cd. 1 Introduction Bag generation is a form of natural language gel> er;ttion in which the input is ;~ bag (Mso known as a inultiset: a set in which rcpe~ted elements are significant) of lexicM elements and the output is a grammatical sentence or a statistically most probable permutation with respect to some.
bmguage model.
Bag generation has been considered within the st~tistieal and rule-based paradigms of computational linguistics, and catch has handled this problem differently (Chen and Lee, 1994; Whitelock, 1994; Popowich, 1995; Tn0illo, 1995).
This paper only considers ruh' based approaches to this problem.
Bag generation has received particulm: attention in lexicalist approaches to MT, as exemplitied by Shake-and-Bake generation (Beaven, 1992; Whitelock, 1994).
One can also envisage applications of bag generation to generation fi'om mini*Now at S\[1ARP L~tboral, ories of I"mrope, Oxh)rd Science \[)ark, Oxford OX4 4CA.
E-ma~il: simon~sh~Lrp.co, nk tmdly recursiw', semantic ropresentactions (Cope.stake ct aal., 1995) and other semantic fi'ameworks which separate scoping fi'om content information (leyle, 1995).
ht these frameworks, the unordered natllFe ()f predicate or relation sets makes the aI> plict~tion o\[' bag generation techniques attra.ctiw:.
A notational convention used in the I)al)er is that items such as 'dogt' stand for simplitied lexical signs of the.
form (Shieber, 198(0: SI'M -\[ ttl/I,N = dog \]....
\[ attc:~l = 1 J In such signs, the semantic argument will be referred to as an qndex' and will be shown as n subscril)t to a lexeme; in the above exmnple, the index has been giwm the unique type 1.
The term index is borrowed rl'Olll IIPSG (Pollard and Sag, 1994) where indices ~u'e used as arguments to relations; however these indices tnay also be equated with dis(-onrse referents in l)lt:I' (Kamp and Ieyle, 1993).
As with most lexicalist generators, semantic variables ttttlSl; \[)c distinguished in order to disallow tr;mslationally incorrect permutations of the target bag.
We distinguish variables by uniquely typing them.
Two assumptions are made regarding \[cxiealsemantic indexing.
Assmnption 1 All lea'teal signs must be indexed, including fltnetional and nonprcdicative elements (Calder cl aal., 1989).
Assumption 2 All le.~ical signs must be connecled to each other.
7'wo lea:ical signs arc connected if they are directly connected; furthermore, the connectivity rclation is h'an.silivc.
Definition 1 7'wo signs, A, 11, are directly connccled if there cxisl at least two paths, PathA, Palht3, such that A:PathA is token identical with B:PathB.
The indices involved in determining connectivity arc; specified as pa.rameters for a pro._ ticul;tr formalism, l'k)r exanq)le, in tlPSG, !01 play a major role in preventing the generation of incorrect translations.
\[CAT=S 1 ~ \[oKr=NP l \[O~T=VP 1) \[SEM=E~\]J LS~M:A~G1 :=~\] LL~:M=IEL.,,~o'~=IIljj \[CAT=NP\] \[CAT=Det 1 rcA~'=Na \] 2) L~.=I ~ j ~ Ls,,~:.,,,~ ~ =l~l L~E~=@\[,,~<----V1\]\] \[CAT=N1\] 3) \[~,_~ j \[oa,,=m\] \[OAT=Eli \[cKr=PP\] \[CAT=vPl Figure CAT= A \[CAT---N1 SEM:ARG1 :~\] \] CAT= N1 \[OAT = PP SI,'M: ARG1 ~\[~\]\] \] \[ CAT = N 1 \[ OA'I'= P \[SEM__@~^lm3~\]\[ --=~J\] \[CAT=NP \] CAT= Vtra rCAT=N p \] 1: Simple unification grammar.
It will be shown that it is possible to exploit the connectivity Assumption 2 above in order to achieve a reduction in the number of redundant wfss constructed by both types of generator described in section 2.
3.1 Using
Connectivity for Pruning Take the following bag: Ex.
2 {dogl,thcl,brown:,big:} (corresponding to 'the big brown dog').
Assume that the next wfss to be constructed by the generator is the NP 'the dog'.
Given the grammar in Figure 1, it is possible to deduce that 'brown' can never be part of a complete NP constructed from such a substring.
This can be determined as follows.
If this adjective were part of such a sentence, 'brown' would have to appear as a leaf in some constituent that combines with 'the dog' or with a constituent containing 'the dog'.
From the grammar, the only constituents that can combine with 'dog' are VP, Vtra and P.
However, none of these constituents can have 'brownl' as a leaf: ill the case of P and Vtra this is trivial, since they are both categories of a ditferent lexical type.
In the case of the VP, 'brownl' cannot appear as a leaf either because expansions of the VP are restricted to NP complements with 2 as their semantic index, which in turn would also require adjectives within them to }lave this index.
l,'urthermore, 'brown1' cannot OCCUr as a loaf in a deel)er constituent in the VP t)ecause such an occurrence would be associated with a different index.
In such cases 'brown' would modify a different noun with a different index: Ex.
a { the\], dog\], withl,2, the~, lnvwn2, collar2} A naive implementation of this deduction would attempt to expand the VP depth-ill'st, left to right, ill order to accommodate 'brown' in a complete derivation.
Since this would not be possible, the NP 'the dog' would be discarded.
This approach is grossly inefficient however.
What is required is a more tractable algorithm which, given a wfss and its associated sign, will be able to determine whether all remaining lexical elements can ever form part of a complete sentence which includes that wfss.
Note that deciding whether a lexical sign can appear outside a phrase is determined purely by the grammar, and not by whether the lexical elements share the same index or not.
Thus, a more complex grammar would allow 'the man' from the bag Ex.
4 {thel,manl,shaves<l,\],himselfl} even though 'himself' has the same index as 'the IIlan'.
3.2 Outer
Domains The approach introduced here compiles the relevant information of\[line fi'om the grammar and uses it to check for connectivity during bag generation.
The compilation process results in a set of (Sign,Lex,Bindings) triples called outer domains.
'l'his set is based on a unification-based phrase structure grammar defined as follows: Definition 2 d grammar is a tuple (N, 7;P,S), where P is a sct of productions ce ~ /3, a is a sign, /3 is a list of signs, N is the set of all ee, T is the set of all signs appearing as elements of \[3 which unify with lexical entries, and S is the start sign.
Outer domains are defined as follow: Definition 3 {(Sign, Lcx, Binds) I Sign C N tO T, Lcx ~ T and there exists a derivation Oe ~ /31Signt /32 LeJ /33 or a ~ f11Lez\] /32,S'iqnl /33, and Sign' a unifier for Sign, Lez j a unifier for Lcx, and Binds the set of all path pairs <SignPath, LexPalh> such thai Sign':SignPath is Ioken identical with LezS :LexPath} Intuitively, the outer domains indicate that preterminal category Lex ('an appear in a complete sentence with subconstituent Sign, such that l,cx is not a leaf of Sign.
Using ideas from data flow analysis (Kennedy, 1981), predictive parser constructions (Aho et aal., 1986) and feature grammar compilation (Trujillo, 1994) it is possible to construct such a set of triples.
Outer domains thus represent elements whi(:h may lie outside a subtree of category Sign in a complete sentential 103 they would be indicated through paths such as SYNSEM :LOCAL:CONTI,INT:INI) EX.
'\[b ensure that only connected lexical signs are generated and analysed, the following assumt)tion must also be made: Assumption 3 A grammar will only generate or analyse connected lexical signs.
2 Bag
Generation Algorithms Two main tyl)es of rule-based bag generators have been proposed.
The first type consists of a parser suitably relaxed to take into account the unordered character of tile input (Whitelock, 1994; Popowich, 1995; Trujillo, 1995).
For example, in generators based on a chart 1)arser, the hm(tanmntal rule is applie(1 only when the edges to be ('ombined share no \]exical leaves, in contrast to requiring that the two edges have source and target nodes in common.
The other type of generator applies a greedy algorithm to an initial solution in order Co find a grammatical sentence (1)oznafiski et aal., 1.995). 2.1 Redundancy in Bag Generation One disadvantage with the above generators is that they construct a nnnd)er of strnctures which need Dot have been computed at all.
In buihl-ing these structures, the generator is e\[fcctively searching branches of the search space which never lead to a COml)lete sentence.
Consider the the tbllowing input bag: { dog, barked, the, brown, big} Previous rest,archers (Ih:ew, 1992; l)hillil)s, 1993) have noted that from such a lx~g, tile following strings ;u:e generated but none can fi)rtn part of a (;omplete sentence (note that indices are omitted when there is no possibility of conrnsion; # indicates that the subs|ring will never be part of ~ complete sentence): Ex.
1 # the dog the dog barked # the brown dog For simph'~ cases in chart based generators such unnecessary strings do not create many problems, but for k)nger sentences, each additional su bstring implies a further branclt in the search tree to be considered.
Since tile (;Oml)Utational ('Oml)lexity of the greedy bag generator (Poznafiski (% aal., 1995) is polynolni&l (i.e.
O(?,.d)), the cf\]'ect of,'(~(hlnda,lt sul)structnres is not as detrimentM as for parser based generators.
Neverthelc'ss, a (:ert~in am(rant of mmccesm~ry work is t)erformed.
'lk) show this, consider the test-rewrite sequence for l!'~xaml)h'.
I: Test: (log barked the brown big R.ewrite: __ barked the dog brown big Test: barked (the dog) brown big Rewrite: __ (the dog) barked brown big Test: ((the (log) barked) brown big Rewrite: the brown dog barked __ big Test: ((the (brown (log)) harked)big Rewrite: tile big (brown dog) barked _.
Test: ((the (big (brown clog))) barked) ('terminate) In this scqnence donble und(,rscorc (__).
indicates the starting position of a moved constituent; the moved constituent itself is given in bold t~ce; the bracketing indicates analysed constituents (for expository purposes the algorithm has been oversimplified, but the general idea remains the salne).
Now consider the step where 'brown' is inserte(l 1)etwe(;n '|tie' and 'dog'.
This action causes the complete structure for 'the dog barked' to be discarded and replaced with that for %he brown (tog barked', which in turn is discarded and replaced by 'the big brown dog barked'.
2.2 Previous
Work A number of prnning techniqtms have I)een suggested to re(hwe the mnom,t of redundancy in bag generators.
Brew (19921 proposed a constraint propagation technique which eliminates branches during I)ag generation by considering the necessary lh,~ctor-argument relationships that exist between the component basic signs of categorial signs.
These relationships form a graph indic:Lting the necessary conditions for a lexical item to form part of a comt/h'.te sentence.
Such graphs can 1)e use(l to elinlinate 1;he substrings in l'3xaml)le 1.
Unh)rtunately the technique exploits specilic asl)ects of categorial grammars an(l it is not <:lear how the.y may he used with other formalisms.
Trujillo (1995) adapts some of Brew's ideas 1,o phrase structure grammars by ('emil|ling l!'of low functions and constructing adjacency graphs.
While this al)l)roach reduces the size of the search sl)ace, it; does not prune it; sulllciently for cert,|in classes of rood|tiers.
Phillips (199'.{) proposes handling ine\[ticiency ~1; the expense of completeness.
Ills idea is to mainl.a.il~ a queue, of rood|liable constituents (e.g.
N Is) in order to delay their combination with other constituents until rood|tiers (e.g.
Pl's) have been ana.lysed.
While practical, this approach can lead to alternative wdid sentences not being gen(;r;(.t(~(I.
3 Connectivity
Restrictions In scm('hing ILr a~ nmchanisIn that el i.li~,al.es un tteCCssitry WISS, it will I)e l)ossible to use indices in lexical signs.
As lnenl;ione(\[ earlier, these indices derivation.
The following definition specifies how outer domains are used: Definition4 A lexical sign Lea/ is in the outer domain of Sign' if\[ there is a triple (Sign,Lex, Binds) in outer domains such that Sign and Lex unify with Sign I and Lez j respectively, and there is at least one pair <PathS, PathL> E Binds such that Sign':PathS unifies with LezQPathL.
In compiling outer domains, inner domains are used to facilitate computation.
Inner domains are defined as follows: Definition 5 {(Sign, Lex, Binds) I Sign C N U T, Lex 6 7' and there exists a derivation (~ :~ /31LezS f12, with Sign I a unifier for Sign, Le~ s a unifier for Lex, and Binds the set of all path pairs <SignPath, LexPath> such that Sign':SignPath is token identical with LezS :LexPath} The inner domains thus express all the possible terminal categories which may be derived from each nonterminal in the grammar.
To be able to exploit connectivity during generation, inner and outer domains contain only triples in which Binds has at least one element.
In this way, only those lexical categories which are directly connected to the sign are taken into account; the implication of this will become clearer later.
As an example, the outer domain of NP as derived from the above grammar is: (N P\[sem:arg l:X\],Vtra\[sem:arg2:Y\], { <<sem:argl.,sem:arg2 > } ) (NP\[~em:arg~:X\],Vt~a\[sem :arga:Y\], { <sem:argl,sem:arga > } ) (NP\[~o,n:~rgl:X\],P\[~em:~rga:Y\], { <sem:argl,sem:arg3> }) This set indicates that for any NIP, the only terminal categories not contained in the subtree with root NP, and with which the NP shares a semantic index, are Vtra and P.
For instance, the first triple arises from the following tree: S NP/sem:argl:X\] VP\[sem:arg2:X\] Vtra\[sem:arg2:X\] NP a.a Pruning through Outer Domains and Connectivity The pruning technique developed here operates on grammars whose analyses result in connected leaves.
Consider SOllle wfss W constructed from a bag B and with category C; this category, in the form of a sign, will include syntactic and lexical-semantic information.
Such a wfss will have been constructed during the bag generation process.
Now, either W includes all the input elements as leaves, in which case W constitutes a complete sentence, or there are elements in the input bag which are not part of W.
In the latter case, for bags obeying Assmnption 2, the following condition holds for any W that can form part of a complete sentence: Condition 1 Let L be the set of leaves appearing in W, let a be the.graph (V, Fd, where V : {C3 U BL, and E-{ {x,y} \] x,y 6 Vand y is in the outer domain of x}.
Then G is connected.
'lb show that; this condition indeed holds, consider a grammatical ordering of some input bag B, represented as the string W: ce..
T&.w By Assumption 2, the lexical elements in the bag, and therefore in any grammaticM ordering of it, are connected.
Now consider reducing this string using the production rule: D~75 to give the string W': O~,.
D..o2 In this case, the signs in W' will also be connected.
This can be shown by contradiction: Proof 1 Assume that there is some sign ~ in W' to which D is not connected.
Then grammar G would allow disconnected strings to be generated, contrary to Assumption 3.
7'his is because D would not be able to rewrite 7161 in such a way that both daughters were connected to ~, leading to a disconnected string.
The situation in string W' is analogous to that in Condition 1.
By identifying signs which are directly connected in E, it is possible to determine whether g is connected and consequently whether C can form part of a complete derivation, instead of simply comparing the value of index paths, it is more restrictive to use outer domains since they give us precisely those elements which are directly connected to a sign and are in its outer domain.
3.4 Example
Consider P~xample 2.
'Ib eliminate the wfss 'the dog' from further consideration, a connected graph of lexical signs is constructed before generation is started (Figure 2).
This graph is built by nsing the outer domain of each lexical element to decide which of the remaining elements could possibly share an index with it in a complete sentence.
1@4 dog1 big1 1LhcI brown i Figure 2: Initial commcted graph.
When a new wfss is constructed during genera|ion, say by application of the modified fimdame.ntal rule or during the rewrite phase in a greedy algorithm, this initial graph is updated and tested for connectivity.
If the updated graph is not conneeted then the proposed wfss cannot form part of a complete sentence.
Updating the graph involves three steps, l"irstly every node in the graph which is a leaf' of tit(' new wfss is deleted, toge.t.lmr with its associated ares.
Secondly, a new node corresponding to tit(: new wNs is added to the graph.
Finally, a new arc is added to the graph between the uew node and every other node lying in its outer domain.
The updated (disconnected) graph that ensnes after constructing 'the clog' is shown in Figure 3; this NP is therefore rejected.
%|it dog'l big1 4 ~ brown1 Figure 3: Updated disconnected graph after the wfss 'the dog' is constructed.
4 Compiling
Connectivity Domains For reasons of space, the computation of outer domains cannot be described fully here.
The broad outline, however, is as follows.
First, the inner domains of the grammar are calculated.
This involves the calculation of the fixed point of set equations, analogous to those used in the construction of First sets for predictive parsers (Aho et aal., 1986; Trujillo, 1994).
Given the inner domains of each category in the grammar, the construction of the outer domains involves the computation of the lixed point of set equations relating the outer domain of a category to the inner domain of its sisters and to the outer domain of its mother, in a manner analogous to the eoinputation of Follow sets.
I)uring computation, the set of Binds is monotonically increased as difDreut ways of directly connecting sign and lexeme arc found.
5 Results
The abow~' pruning tcchnique has been tested on bags of different sizes including different combinatkms of modifiers.
Sentences were generated using two versions of a modified chart parser.
In one, ew'.ry inactive edge constructed was added to the chart.
In the.
other, every inactive edge was tested to see if it led to a disconnected graph; if it did, then the edge was discarded.
The results of the experiment are shown in Table 1.
The implementation was in Prolog on a Sun SpareS|at|on 10; the generation timings do not include garbage collection time.
The grammar used for the experiment consisted of simplified, feature-based versions of the 11) rules in GPSG; there were 18 rules and 50 lexical entries.
Compilation of the outer domains for these rules took apt)roximately 37 minutes, and the resulting set occupies 40K of men> ory.
In the general case, however, tile size of the outer domains is O(n2), where n is the number of distinct signs; this number can be controlled by employing equivalence classes of different levels of specificity for pre-terminal and non-terminal signs.
Chart Gen.
+ Pruning Hag size Time Edgcs Time Edges 2 0.1 15 8.1 15 4 0.3 37 (1.4 36 7 1.5 103 2.0 99 7 0.9 72 11.0 67 I\] 5.1 213 3.9 138 12 2.6 133 3.4 123 15 9.0 294 7.2 186 15 117.6 448 11.1 253 17 2.3 126 2.6 1105 'l'al~le 1: Effect of pruning (times in secs).
Only one reading was generated for each bag, corresponding to one attachment site for PPs.
'l'he tMJe shows that the technique ctm yieht reductions in the number of edges (both active aud inactive) and time taken, especially for longer sentences, while retaining the overheads at an acceptable level.
6 Conclusion
A technique fl)r pruning the search space of a bag generator has been implemented and its usefulness shown in Lhe geueration of different types of constructions.
The technique relies on a connectivity constraint imposed on the semantic relationships 105 expressed in the input bag.
In order to apply the algorithm, outer domains needed to be compiled from the grammar; these are used to discard wfss by ensuring l'exical signs outside a wfss can indeed appear outside that string.
Exploratory work employing adjacency constraints during generation has yielded further improvements in execution time when applied in conjunction with the pruner.
If extended appropriately, these constraints could prune the search space even further.
This work will be reported at a later date.
Acknowledgments Two anonymous reviewers provided very useful comments; we regret not being able to do justice to all their suggestions.
References A.
V. Aho, R.
Sethi, and J.
D. Ullman.
1986. Compilers Principles, Techniques, and Tools.
Addison Wesley, Reading, MA.
J. L.
Beaven. 1992.
Lexicalist Unification Based Machine Translation.
Ph.D. thesis, Department of Artificial Intelligence, University of Edinburgh, Edinburgh, UK.
C. Brew.
1992. Letting the cat out of the bag: Generation for Shake-and-Bake MT.
In Proceedings of the 14th COLING, pages 610-16, Nantes, France, August.
J. Calder, M.
Reape, and H.
Zeevat. 1989.
An algorithm for generation in unification categorial grammar.
In Proceedings of the Fourth European Conference of the ACL, pages 233-40, Manchester, England, April.
It.H. Chen and Y.S.
Lee. 1994.
A corrective training algorithm for adaptive learning in bag generation.
In New Methods in Language Processing, Manchester, UK.
A. Copestake, D.
Flickinger, R.
Malouf, S.
Riehemann, and I.
Sag. 1995.
Translation using minimal recursion semantics.
In Proceedings of the 6th International Conference on Theoretical and Methodological Issues in Machine Translation, Leuven, Belgium, July.
II. Kamp and U.
Reyle. 1993.
From Discourse to Logic Introduction to Modeltheoretic Semantics of Natural Language, Formal Logic and Discourse Representation Theory, volume 42 of Studies in Linguistics and Philosophy.
Kluwer Academic, Dordrecht, The Netherlands.
Ken Kennedy.
1981. A survey of data flow analysis techniques.
In Muchnick and Jones (1981), chapter 1, pages 5-54.
Steven S.
Muchnick and Neil D.
Jones, editors.
1981. Program Flow Analysis: Theory and Applications.
Software. Prentice-Hall, Englewood Cliffs, NJ.
J. D.
Phillips. 1993.
Generation of text from logical formulae.
Machine Translation, 8(4):20935.
C. Pollard and I.
Sag. 1994.
Head Driven Phrase Structure Grammar.
Chicago University Press, IL.
Fred Popowich.
1995. Improving the efficiency of a generation algorithm for Shake and Bake machine translation using Head-Driven Phrase Structure Grammar.
In Proceedings of Natural Language Understanding and Logic Programming V, Lisbon, Portugal, May.
V. Poznafiski, J.
L. Beaven, and P.
Whitelock. 1995.
An efficient generation algorithm for lexiealist MT.
In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics, Boston, MA, June.
Uwe Reyle.
1995. On reasoning with ambiguities.
In Proceedings of the Seventh Conference of the European Chapter of the Association for Computational Linguistics, pages 1-15, Dublin, Ireland, March.
C. J.
Rupp, M.
A. Rosner, and R.
L. Johnson, editors.
1994. Constraints, Language and Computation.
Academic Press, London.
S. M.
Shieber. 1986.
An Introduction to Unification-based Approaches to Grammar, volume 4 of CSLI Lecture Notes.
CSLI, Stanford, CA.
A. Trujillo.
1994. Computing FIRST and FOLLOW functions for Feature-Theoretic grammars.
In Proceedings of the 15th COLING, pages 875-80, Kyoto, Japan, August.
A. Trujillo.
1995. Lexicalist Machine Translation of Spatial Prepositions.
Ph.D. thesis, Computer Laboratory, University of Cambridge, April.
Pete Whitelock.
1994. Shake-and-bake translation.
In Rupp et al.(1994), pages 339-59. 106

