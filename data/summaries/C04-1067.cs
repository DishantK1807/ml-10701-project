‚1;‚2;‚3;‚4 are calculated by deleted interpolation as described in (Brants, 2000).
A00-1031
It is observed that the Markov model-based method has high overall accuracy, however, the accuracy drops for unknown words, and the character tagging method has high accuracy for unknown words but lower accuracy for known words (Yoshida et al., 2003; Xue, 2003; Sproat and Emerson, 2003).
W03-1719
We use the following systems for comparison: Bakeoff-1, 2, 3 The top three systems participated in the SIGHAN Bakeoff (Sproat and Emerson, 2003).
W03-1719
We use the following systems for comparison: ChaSen The word segmentation and POS-tagging system based on extended Markov models (Asahara and Matsumoto, 2000; Matsumoto et al., 2001).
C00-1004
Asahara et al.(2003) studied Chinese word segmentation based on a character tagging method with support vector machines.
W03-1720
Markov Model-Based Method Word-based Markov models are used in English part-of-speech (POS) tagging (Charniak et al., 1993; Brants, 2000).
A00-1031
Uchimoto et al.(2001) studied Japanese word segmentation using ME models.
W01-0512
This approach is also used in base-NP chunking (Ramshaw and Marcus, 1995) and named entity recognition (Sekine et al., 1998) as well as word segmentation.
W95-0107 W98-1120
In the above equation, P(ti) and P(wi;t) are estimated by the maximum-likelihood method, and the probability of a POC tag ti, given a character wi (P(tijwi;ti 2 TPOC)) is estimated using ME models (Berger et al., 1996).
J96-1002
They did not use some of the features we used like character types, and our method achieved higher accuracies compared to theirs on the AS, HK and PK corpora (Asahara et al., 2003).
W03-1720
Several POC-tag sets have been studied (Sang and Veenstra, 1999; Sekine et al., 1998), and we use the ‘B, I, E, S’ tag set shown in Table 1 1.
W98-1120
1The ‘B, I, E, S’ tags are also called ‘OP-CN, CN-CN, CNCL, OP-CL’ tags (Sekine et al., 1998) or ‘LL, MM, RR, LR’ tags (Xue, 2003).
W98-1120
The candidates of unknown words can be generated by heuristic rules(Matsumoto et al., 2001) or statistical word models which predict the probabilities for any strings to be unknown words (Sproat et al., 1996; Nagata, 1999).
J96-3004 P99-1036
The following values are used to evaluate the performance of word segmentation: R : Recall (The number of correctly segmented words in system’s output divided by the number of words in test data) P : Precision (The number of correctly segmented words in system’s output divided by the number of words in system’s output) F : F-measure (F = 2£R£P=(R+P)) Rknown : Recall for known words Runknown : Recall for unknown words Corpus # of Training Words # of Testing Words # of Words Rate of (known/unknown) in Dictionary Unknown Words AS 5,806,611 11,985 (11,727/ 258) 146,212 0.0215 HK 239,852 34,955 (32,463/2,492) 23,747 0.0713 PK 1,121,017 17,194 (16,005/1,189) 55,226 0.0692 RWCP 840,879 93,155 (93,085/ 70) 315,602 0.0008 Table 3: Statistical Information of Corpora 4.1 Experiments of Chinese Word Segmentation We use three Chinese word-segmented corpora, the Academia Sinica corpus (AS), the Hong Kong City University corpus (HK) and the Beijing University corpus (PK), all of which were used in the First International Chinese Word Segmentation Bakeoff (Sproat and Emerson, 2003) at ACL-SIGHAN 2003.
W03-1719
The tagging task can be solved by using general machine learning techniques such as maximum entropy (ME) models (Xue, 2003) and support vector machines (Yoshida et al., 2003; Asahara et al., 2003).
W03-1720
