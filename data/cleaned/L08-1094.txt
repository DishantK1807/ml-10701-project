<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>E Bailly-Bailliere</author>
<author>S Bengio</author>
</authors>
<title>The BANCA database and evaluation protocol. In</title>
<date>2003</date>
<booktitle>Proc. of IAPR AVBPA, Springer LNCS-2688</booktitle>
<pages>625--638</pages>
<marker>Bailly-Bailliere, Bengio, 2003</marker>
<rawString>Bailly-Bailliere, E., Bengio, S., et al. (2003). The BANCA database and evaluation protocol. In: Proc. of IAPR AVBPA, Springer LNCS-2688, 625-638.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Bimbot</author>
<author>H P Hutter</author>
</authors>
<title>Speaker verification in the telephone network: research activities in the CAVE project”, in</title>
<date>1997</date>
<booktitle>Proc. Eurospeech</booktitle>
<pages>971--974</pages>
<marker>Bimbot, Hutter, 1997</marker>
<rawString>Bimbot F., Hutter H. P., et al. (1997). “Speaker verification in the telephone network: research activities in the CAVE project”, in Proc. Eurospeech 1997, pp. 971-974.</rawString>
</citation>
<citation valid="true">
<authors>
<author>BioSecure</author>
</authors>
<title>Biometrics for Secure Authentication</title>
<date>2007</date>
<booktitle>FP6 Network of Excellence (NoE</booktitle>
<pages>2002--507634</pages>
<contexts>
<context>l biometric traits, namely: speech, iris, face, handwriting, fingerprints, hand and keystroking. The database comprises 400 subjects and was acquired in a realistic office-like scenario. • BioSecure (BioSecure, 2007). This database considers three acquisition scenarios, namely: unsupervised Internet acquisition, including voice, and face; supervised office-like scenario, including voice, finger prints, face, iri</context>
</contexts>
<marker>BioSecure, 2007</marker>
<rawString>BioSecure (2007). Biometrics for Secure Authentication, FP6 Network of Excellence (NoE), IST-2002-507634. (http://www.biosecure.info/).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Campbell</author>
<author>A Higgins</author>
</authors>
<title>YOHO speaker verification corpus LDC94s16). Available at the LDC website: http://www.ldc.upenn.edu</title>
<date>1994</date>
<contexts>
<context>r text-dependent speaker recognition research grouped into two broad categories: unimodal and multimodal databases. 2.1 Other unimodal databases for text-dependent speaker recognition For years YOHO (Campbell &amp; Higgins, 1994; Campbell, 1995) has been the best known database for evaluation of text-dependent speaker recognition. It consists of 96 utterances for enrolment collected in 4 different sessions and 40 utterances </context>
</contexts>
<marker>Campbell, Higgins, 1994</marker>
<rawString>Campbell J. and Higgins A. (1994). YOHO speaker verification  corpus LDC94s16). Available at the LDC website: http://www.ldc.upenn.edu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J P Campbell</author>
</authors>
<title>Testing with the YOHO CD-ROM voice verification corpus</title>
<date>1995</date>
<booktitle>in Proc. ICASSP</booktitle>
<volume>1</volume>
<pages>341--344</pages>
<contexts>
<context>ecognition research grouped into two broad categories: unimodal and multimodal databases. 2.1 Other unimodal databases for text-dependent speaker recognition For years YOHO (Campbell &amp; Higgins, 1994; Campbell, 1995) has been the best known database for evaluation of text-dependent speaker recognition. It consists of 96 utterances for enrolment collected in 4 different sessions and 40 utterances for test (10 ses</context>
</contexts>
<marker>Campbell, 1995</marker>
<rawString>Campbell J. P. (1995). “Testing with the YOHO CD-ROM voice verification corpus”, in Proc. ICASSP 1995, vol. 1, pp. 341-344.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C-W Che</author>
<author>Q Lin</author>
<author>D-S Yuk</author>
</authors>
<title>An HMM approach to text-prompted speaker verification”, in</title>
<date>1996</date>
<booktitle>Proc. ICASSP</booktitle>
<volume>2</volume>
<pages>673--676</pages>
<marker>Che, Lin, Yuk, 1996</marker>
<rawString>Che C.-W., Lin Q. and Yuk D.-S. (1996). “An HMM approach to text-prompted speaker verification”, in Proc. ICASSP 1996, vol. 2, pp. 673-676.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Dessimoz</author>
<author>J Richiardi</author>
</authors>
<title>Multimodal biometrics for identity documents (MBioID</title>
<date>2007</date>
<journal>Forensic Science International</journal>
<volume>167</volume>
<pages>154--159</pages>
<marker>Dessimoz, Richiardi, 2007</marker>
<rawString>Dessimoz, D., Richiardi, J., et al. (2007). Multimodal biometrics for identity documents (MBioID). Forensic Science International 167, 154-159.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Dumas</author>
<author>J Hennebert</author>
</authors>
<title>MyIdea Sensors speci¯ cations and acquisition protocol</title>
<date>2005</date>
<booktitle>Computer Science Department Research Report DIUF-RR 2005.01, University de Fribourg in</booktitle>
<marker>Dumas, Hennebert, 2005</marker>
<rawString>Dumas, B., Hennebert, J., et al. (2005). MyIdea Sensors speci¯ cations and acquisition protocol. Computer Science Department Research Report DIUF-RR 2005.01, University de Fribourg in Switzerland. Faundez-Zanuy M., Fierrez-Aguilar J., Ortega-Garcia J.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Gonzalez-Rodriguez</author>
</authors>
<title>Multimodal biometric databases: An overview</title>
<date>2006</date>
<journal>IEEE Aerospace and Electronic Systems Magazine</journal>
<volume>21</volume>
<pages>pp.</pages>
<marker>Gonzalez-Rodriguez, 2006</marker>
<rawString>and Gonzalez-Rodriguez J. (2006). &amp;quot;Multimodal biometric databases: An overview&amp;quot;, IEEE Aerospace and Electronic Systems Magazine, Vol. 21, n. 8, pp.</rawString>
</citation>
<citation valid="false">
<date>2006</date>
<pages>29--37</pages>
<marker>2006</marker>
<rawString>29-37, August 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Fierrez-Aguilar</author>
<author>J Ortega-Garcia</author>
</authors>
<date>2005</date>
<booktitle>Extended Multimodal Database and Testing Protocol”, Deliverable D5.7, BioSec, FP6 IP</booktitle>
<pages>2002--001766</pages>
<marker>Fierrez-Aguilar, Ortega-Garcia, 2005</marker>
<rawString>Fierrez-Aguilar J. and Ortega-Garcia J. (2005). “Extended Multimodal Database and Testing Protocol”, Deliverable D5.7, BioSec, FP6 IP IST-2002-001766, December 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Fierrez</author>
<author>J Ortega-Garcia</author>
</authors>
<title>Biosec baseline corpus: a multimodal biometric database</title>
<date>2007</date>
<marker>Fierrez, Ortega-Garcia, 2007</marker>
<rawString>Fierrez, J., Ortega-Garcia, J., et al. (2007). Biosec baseline corpus: a multimodal biometric database.</rawString>
</citation>
<citation valid="false">
<journal>Pattern Recognition</journal>
<volume>40</volume>
<pages>1389--1392</pages>
<marker></marker>
<rawString>Pattern Recognition 40, 1389-1392.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P J Flynn</author>
</authors>
<date>2007</date>
<note>Biometric databases”, chapter in A. K</note>
<contexts>
<context>D (Dessimoz et al., 2007), and M3 (Meng et al., 2006). Other current initiatives in multimodal database collection closely related to the BioSec database are the following (Faundez-Zanuy et al. 2006; Flynn, 2007): • BiosecurID. This database includes 7 unimodal biometric traits, namely: speech, iris, face, handwriting, fingerprints, hand and keystroking. The database comprises 400 subjects and was acquired i</context>
</contexts>
<marker>Flynn, 2007</marker>
<rawString>Flynn P. J. (2007). “Biometric databases”, chapter in A. K.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Flynn Jain</author>
<author>A A</author>
</authors>
<title>Ross (Eds.), Handbook of Biometrics</title>
<date>2007</date>
<publisher>Springer</publisher>
<marker>Jain, A, 2007</marker>
<rawString>Jain, P. Flynn, A. A. Ross (Eds.), Handbook of Biometrics, Springer, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Garcia-Salicetti</author>
<author>C Beumier</author>
</authors>
<title>BIOMET: A multimodal person authentication database including face, voice, fingerprint, hand and signature modalities</title>
<date>2003</date>
<marker>Garcia-Salicetti, Beumier, 2003</marker>
<rawString>Garcia-Salicetti, S., Beumier, C., et al. (2003). BIOMET: A multimodal person authentication database including face, voice, fingerprint, hand and signature modalities.</rawString>
</citation>
<citation valid="false">
<authors>
<author>In</author>
</authors>
<booktitle>Proc. of IAPR AVBPA, Springer LNCS-2688</booktitle>
<pages>845--853</pages>
<marker>In, </marker>
<rawString>In: Proc. of IAPR AVBPA, Springer LNCS-2688 845-853.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hébert</author>
</authors>
<title>Text-Dependent Speaker Recognition”, chapter 37 in Benesty, Sondhi and Huang (Eds.) “Handbook of Speech Processing</title>
<date>2008</date>
<publisher>Springer</publisher>
<contexts>
<context> Das &amp; Kumar, 2006). HMMs on the other hand are more complex, provide more flexibility and at least comparable results, and are the most commonly used technique in text-dependent speaker recognition (Hébert, 2008; Matsui &amp; Furui, 1993; Che, Lin &amp; Yuk, 1996; Bimbot et al., 1997). Most of the works previously reported for text-dependent speaker recognition using HMMs tend to use a speaker independent set of HMM</context>
</contexts>
<marker>Hébert, 2008</marker>
<rawString>Hébert, M. (2008), “Text-Dependent Speaker Recognition”, chapter 37 in Benesty, Sondhi and Huang (Eds.) “Handbook of Speech Processing”, Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J Leggetter</author>
<author>P C Woodland</author>
</authors>
<title>Flexible speaker adaptation using maximum likelihood linear regression</title>
<date>1995</date>
<booktitle>in Proc. Eurospeech</booktitle>
<pages>1155--1158</pages>
<contexts>
<context> in the literature (Subramanya et al., 2007; Toledano et al., 2008) have started to modify this method by substituting Baum-Welch retraining by Maximum Likelihood Linear Regression (MLLR) adaptation (Leggetter &amp; Woodland, 1995) of the speaker independent HMMs. This allows to use more complex (and, if properly trained, more reliable) HMMs while keeping the speaker models small (since only the MLLR transformation matrices ne</context>
</contexts>
<marker>Leggetter, Woodland, 1995</marker>
<rawString>Leggetter C. J. and Woodland P. C. (1995). “Flexible speaker adaptation using maximum likelihood linear regression”, in Proc. Eurospeech 1995, pp. 1155-1158.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Matsui</author>
<author>S Furui</author>
</authors>
<title>Concatenated phoneme models for text-variable speaker recognition”, in</title>
<date>1993</date>
<booktitle>Proc. ICASSP</booktitle>
<volume>2</volume>
<pages>391--394</pages>
<contexts>
<context>2006). HMMs on the other hand are more complex, provide more flexibility and at least comparable results, and are the most commonly used technique in text-dependent speaker recognition (Hébert, 2008; Matsui &amp; Furui, 1993; Che, Lin &amp; Yuk, 1996; Bimbot et al., 1997). Most of the works previously reported for text-dependent speaker recognition using HMMs tend to use a speaker independent set of HMMs and retrain the para</context>
</contexts>
<marker>Matsui, Furui, 1993</marker>
<rawString>Matsui T. and Furui S. (1993). “Concatenated phoneme models for text-variable speaker recognition”, in Proc. ICASSP 1993, vol. 2, pp. 391-394.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Meng</author>
<author>P C Ching</author>
</authors>
<title>The multi-biometric, multi-device and multilingual (M3) corpus. In</title>
<date>2006</date>
<booktitle>Proc. MMUA Workshop</booktitle>
<marker>Meng, Ching, 2006</marker>
<rawString>Meng, H., Ching, P.C., et al. (2006). The multi-biometric, multi-device and multilingual (M3) corpus. In: Proc. MMUA Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Messer</author>
<author>J Matas</author>
</authors>
<title>XM2VTSDB: The extended M2VTS database. In</title>
<date>1999</date>
<booktitle>Proc. of IAPR AVBPA</booktitle>
<marker>Messer, Matas, 1999</marker>
<rawString>Messer, K., Matas, J., et al. (1999). XM2VTSDB: The extended M2VTS database. In: Proc. of IAPR AVBPA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>NIST</author>
</authors>
<title>National Institute of Standards and Technology. Speaker Recognition Evaluation Home Page, http://www.nist.gov/speech/tests/spk/index.htm, (accessed</title>
<date>2008</date>
<contexts>
<context>tional Institute of Standards and Technology (NIST) has promoted research in the context of text-independent speaker recognition with the organization of yearly international competitive evaluations (NIST, 2008; Przybocki, Martin &amp; Le, 2006) which have fostered the definition of challenging tasks through a strong effort in the development of publicly available speech databases. Despite its potential applica</context>
</contexts>
<marker>NIST, 2008</marker>
<rawString>NIST (2008). National Institute of Standards and Technology. Speaker Recognition Evaluation Home Page, http://www.nist.gov/speech/tests/spk/index.htm, (accessed Feb. 2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Ortega-Garcia</author>
<author>J Fierrez-Aguilar</author>
</authors>
<title>MCYT baseline corpus: a bimodal biometric database</title>
<date>2003</date>
<booktitle>IEE Proc. VISP 150</booktitle>
<pages>391--401</pages>
<marker>Ortega-Garcia, Fierrez-Aguilar, 2003</marker>
<rawString>Ortega-Garcia, J., Fierrez-Aguilar, J., et al. (2003): MCYT baseline corpus: a bimodal biometric database. IEE Proc. VISP 150, 391-401.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Przybocki</author>
<author>A F Martin</author>
<author>N Le A</author>
</authors>
<title>NIST speaker recognition evaluation chronicles part 2”, in</title>
<date>2006</date>
<booktitle>Proc. IEEE Odyssey</booktitle>
<marker>Przybocki, Martin, Le A, 2006</marker>
<rawString>Przybocki M. A., Martin A. F., and Le A. N. (2006). “NIST speaker recognition evaluation chronicles part 2”, in Proc. IEEE Odyssey 2006: The speaker and language recognition workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Ramasubramanian</author>
<author>A Das</author>
<author>V P Kumar</author>
</authors>
<title>Text-dependent speaker recognition using one-pass dynamic programming algorithm”, in</title>
<date>2006</date>
<booktitle>Proc. ICASSP 2006</booktitle>
<volume>1</volume>
<pages>901--904</pages>
<marker>Ramasubramanian, Das, Kumar, 2006</marker>
<rawString>Ramasubramanian V., Das A. and Kumar V. P. (2006). “Text-dependent speaker recognition using one-pass dynamic programming algorithm”, in Proc. ICASSP 2006, vol. 1, pp. 901-904.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Subramanya</author>
<author>Zhengyou Zhang</author>
<author>A C Surendran</author>
<author>P Nguyen</author>
<author>M Narasimhan</author>
<author>A Acero</author>
</authors>
<date>2007</date>
<contexts>
<context> utterance is verified by performing speech recognition with the speaker independent and the speaker-dependent HMMs and comparing the acoustic scores obtained. Recently other works in the literature (Subramanya et al., 2007; Toledano et al., 2008) have started to modify this method by substituting Baum-Welch retraining by Maximum Likelihood Linear Regression (MLLR) adaptation (Leggetter &amp; Woodland, 1995) of the speaker </context>
<context>dependent recognition results in this paper. We have avoided using here recent improvements in text-dependent speaker recognition, such as the use of discriminative methods after the MLLR adaptation (Subramanya et al., 2007) or phoneme or state-based T-Normalization (Toledano et al., 2008) because our main interest in this paper is the comparison of different databases for speaker recognition research. Therefore, we pre</context>
</contexts>
<marker>Subramanya, Zhang, Surendran, Nguyen, Narasimhan, Acero, 2007</marker>
<rawString>Subramanya, A.; Zhengyou Zhang; Surendran, A.C.; Nguyen, P.; Narasimhan, M.; Acero, A. (2007).</rawString>
</citation>
<citation valid="true">
<authors>
<author>“A Generative-Discriminative</author>
</authors>
<title>Framework using Ensemble Methods for Text-Dependent Speaker Verification</title>
<date>2007</date>
<booktitle>in IEEE International Conference on Acoustics, Speech and Signal Processing</booktitle>
<marker>Generative-Discriminative, 2007</marker>
<rawString>“A Generative-Discriminative Framework using Ensemble Methods for Text-Dependent Speaker Verification” in IEEE International Conference on Acoustics, Speech and Signal Processing, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ICASSP</author>
</authors>
<date>2007</date>
<booktitle>Page(s): IV-225 IV-228. Toledano</booktitle>
<volume>4</volume>
<pages>15--20</pages>
<marker>ICASSP, 2007</marker>
<rawString>ICASSP 2007.  Volume 4, 15-20 April 2007 Page(s): IV-225 IV-228. Toledano D. T., Esteve-Elizande C., Gonzalez-Rodriguez J., Fernandez-Pozo  R. and Hernandez-Gomez L.</rawString>
</citation>
<citation valid="true">
<title>Phoneme and Sub-Phoneme T-Normalization for Text-Dependent Speaker Recognition</title>
<date>2008</date>
<booktitle>in Proc</booktitle>
<marker>2008</marker>
<rawString>(2008). “Phoneme and Sub-Phoneme T-Normalization for Text-Dependent Speaker Recognition”, in Proc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>IEEE Speaker</author>
</authors>
<title>and Language Recognition Workshop (Odyssey</title>
<date>2008</date>
<marker>Speaker, 2008</marker>
<rawString>IEEE Speaker and Language Recognition Workshop (Odyssey) 2008.</rawString>
</citation>
</citationList>
</algorithm>

