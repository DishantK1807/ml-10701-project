Bridging the Gap: Academic and Industrial Research in Dialog Technologies Workshop Proceedings, pages 9–16, NAACL-HLT, Rochester, NY, April 2007.
c©2007 Association for Computational Linguistics References B Bonet.
2002. An e-Optimal Grid-based Algorithm for Partially Observable Markov Decision Processes.
In Proceedings of the Nineteenth International Conference on Machine Learning(ICML 2002), Sydney, Australia.
RI Brafman.
1997. A Heuristic Variable Grid Solution Method for POMDPs.
In AAAI, Cambridge, MA.
K. Georgila, J.
Henderson, and O.
Lemon. 2005.
Learning user simulations for information state update dialogue systems.
Proc. of Eurospeech.
Lisbon, Portugal.
LP Kaelbling, ML Littman, and AR Cassandra.
1998. Planning and Acting in Partially Observable Stochastic Domains.
Artificial Intelligence.
101:99-134. O.
Lemon, K.
Georgila, and J.
Henderson. 2006.
Evaluating Effectiveness and Portablility of Reinforcement Learned Dialogue Strategies with real users: the TALK TownInfo Evaluation.
In Proc.
of IEEE/ACL SLT, Palm Beach, Aruba.
E. Levin, R.
Pieraccini, and W.
Eckert. 2000.
A Stochastic Model of Human-Machine Interaction for Learning Dialog Strategies.
IEEE Trans Speech and Audio Processing, 8(1):11-23.
O. Pietquin and T.
Dutoit. 2005.
A probabilistic framework for dialog simulation and optimal strategy learning, IEEE Transactions on Speech and Audio Processing, Special Issue on Data Mining of Speech, Audio and Dialog.
Joelle Pineau, Geoffrey Gordon, and Sebastian Thrun.
2003. Point-based value iteration: An anytime algorithm for pomdps.
In International Joint Conference on Artificial Intelligence (IJCAI), pages 1025-1032.
August. V.
Rieser and O.
Lemon. 2006.
Cluster-based User Simulations for Learning Dialogue Strategies.
In Proc.
of ICSLP, Pittsburgh, PA.
Nicholas Roy, Geoffrey Gordon, and Sebastian Thrun.
2005. Finding approximate pomdp solutions through belief compression.
Journal of Artificial Intelligence Research, 23: 1-40.
J. Schatzmann, K.
Weilhammer, M.N.
Stuttle, and S.
Young. 2006.
A Survey of Statistical User Simulation Techniques for Reinforcement-Learning of Dialogue Management Strategies.
Knowledge Engineering Review, Cambridge University Press.
21(2):97-126. K.
Scheffler and S.
J. Young.
2002. Automatic learning of dialogue strategy using dialogue simulation and reinforcement learning.
In Proc.
of NAACL/HLT.
San Diego, CA.
RS Sutton and AG Barto.
1998. Reinforcement Learning: An Introduction.
Adaptive Computation and Machine Learning.
MIT Press, Cambridge, Mass.
X Wei and AI Rdunicky.
1999. An Agenda-based dialog management architecture for spoken language systems.
In Proc.
of IEEE ASRU.
Seattle, WA.
JD Williams and SJ Young.
2005. Scaling up POMDPs for Dialogue Management: the Summary POMDP Method.
In IEEE workshop on Automatic Speech Recognition and Understanding (ASRU2005), Puerto Rico.
J. Williams and S.
Young. 2006.
Scaling pomdps for dialog management with composite summary point-based value iteration (cspbvi).
In AAAI Workshop on Statistical and Empirical Approaches for Spoken Dialogue Systems, Boston.
Jason D.
Williams. 2006.
Partially Observable Markov Decision Processes for Spoken Dialogue Management Ph.D. thesis, University of Cambridge, April.
SJ Young, JD Williams, J.
Schatzmann, MN Stuttle, and K.
Weilhammer. 2005.
The hidden information state approach to dialogue management.
Technical report, Cambridge Univ.
Engin. Dept.
S. Young, J.
Schatzmann, K.
Weilhammer, and H.
Ye. 2007.
The Hidden Information State Approach to Dialog Management.
In Proc.
of ICASSP.
Honalulu, Hawaii.
S. Young.
2006. Using POMDPs for Dialog Management.
In Proc.
of IEEE/ACLSLT.
Palm Beach, Aruba.

