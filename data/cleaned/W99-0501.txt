m m m m mm m m n \[\] WordNet 2 A Morphologically and Semantically Enhanced Resource Sanda M.
Harabagiu George A.
Miller Dan I.
Moldovan Department of Computer Cogmt~ve Scmnce Laboratory Department of Computer Scmnce and Engineering Princeton Umvermty Scmnce and Eng~eneermg Southern Methodist Umvermty 221 Nassau Street Southern Methodist Umvers~ty Dallas, TX 75275-0122 Princeton, NJ 08542 Dallas, TX 75275-0122 sanda@seas smu edu geo@clarzty prznceton edu moldovan@seas smu edu Abstract Th~s paper presents an on-going project mtended to enhance WordNet molpholog~cally and semanttcally The mottvatmn for th~s work steams from the current hm~tat~ons of WordNet when used as a hngmst~c knowledge base We enwmon a software tool that automatically parses the conceptual defining glosses, attributing part-ofspeech tags and phrasal brackets The nouns, verbs, adjectives and adverbs from every defimtmn are then d~samb~guated and hnked to the corresponding synsets Th~s increases the connectlv~ty between synsets allowing the ~etneval of topically ~elated concepts Furthermore, the tool t~ansforms the glosses, first into logical forms and then into semantm fo~ms Usmg der~vatmnal morphology new hnks are added between the synsets 1 Motivation WordNet has already been ~ecogmzed as a valuable ~esource m the human language technolog> and know, ledge processing commumtms Its apphcabfl~ty has been c~ted m mo~e than 200 papers and s~stems have been m~plemented usmg WordNet A Wo~dNet bkbhog~aph~ ~s mamtamed at the Umve~mt) of Penns:~l~ama ( http //www c~s upenn edu/~oseph~ /wnbtblw html) In Europe, WordNet ~s being u~ed to develop a multflmgual database w~th basic semantic relatmns between words for several European languages (the EuroWordNet project) Capabihties WordNet was conceived as a machine-readable dmtlonary, followmg psychohngmstm principles Unhke standard alphabetmal dmt~onaHes ~hmh o~gamze vocabula~ms using mo~phologmal mmllm ltms, WordNet structures lex~cal reformation m terms of word meanings WordNet maps word forms m ~ord senses usmg the s)ntact~c category as a parametel Although it covers onl~ fouI paits of speech nouns verbs, adjectives and adverbs, it encompasses a large majont) of Enghsh words ( http //www cogscz pmnceton edu/~..wn) Wolds of the same syntactm catego~) that can be used to express the same meamng are grouped into a smgle synonym set, called synset Words wlth multiple meanings (polysemous) belong to multiple synsets An ~mportant part of the 99 643 synsets encoded m WordNet 1 6 contain word collocatmns, thus representing complex nominals (e g the synset {manufacturer, maker, manufacturing business}, (omplex velbals (eg the synset {leave office, quit, step down}, complex adjectlvals (e g the ~ynset {true, dead on target} or complex adverbmls (e g the synset {out of hand, beyond control} The iep~esentatmn of collocatmns as synset entries p~ov~des for their semantm mterp~etatmn Wolds and concepts are furthei connected through a small set of lexmo-semantm relatmns The dominant semantm relatmn is the hypernymy, xvh~ch structures the noun concepts m 11 hmraichms and the verb concepts into 512 )he, atchins Thlee melonym Ielatlons are encoded between noun concepts the ha~_member, the ha~_~tu\]f and the has_part ~elatlons Loglcal opelatlon~ betx~een events or entltms ale modeled through entazlment and cause_to ~elatmns between verb concepts or antonymy relatmns among nouns, veibs ad)ect~ves or adverb words The~e are only a few mo~phologmally motivated connectmns between x~ords known as perta~mym relatmns Llmltatmns The mare ~eaknesses of \Vo~dNet c~ted m the hte~ature ale 1 The lack oi connections between noun and verb hmrarctnes 2 Limited number of connectmns between topically related words 3 The lack of morpholog!cat relations 4 The absence of thema61c relatmns/ selectmnal restnctmns 5 Some concepts (word senses) and relatmns are mmsmg " 6 Since glosses were written manually, sometimes the2e m a lack of umform~ty and consmtency 2n the defimtmns The key idea m our project is to put to wo, k the rich sourse of mformauon contained m glosses that now can be used only by humans to Iead the deflmtmn of synsets For example, Wo, dNet 1 6 hsts the concept {cat, true cat) with the gloss (fellne mammal usually havlng thlck soft fur and belng unable to roar, domestxc cats, wxldcats) Currently, from a concept like thin, only a few other concepts could be reached In Extended Wo2dNet, the concept {cat, true cat} will be,elated to 215othel concepts (I0 from its own gloss, 38 flom the glosses of its hypern>ms, 25 concepts that use ~t m the*r glosses as a defining concept plus other 142 concepts with which the concept mteracts in these 25 glosses) Thin level of mformatmn,s rich enough to presume that the Extended WordNet will work well as a knowledge base for common-sense reasoning 2 Related work Machine Readable DmUonanes (MRDs) have long been,ecogmzed as ~aluable resources m computauonal hngmstlcs In their paper, Ide and Vetoms (Ide and Veloms, 1993) plojected a rather pes~lmmuc outlook for the uuhty of MRDs as knowledge sources, a view that has impeded the enthus2asm of some researchers (Wfiks et al 1996) make a strong argument m favor of using MRDs and shine thel, posluve experience w~th using some dlcuonarms The MmdNet project at Mmrosoft alms at fully automatmg the development of a vel} large lexlcal knowledge base using t~o MRDs the Longman DicUonary of ContemporaD Enghsh (LDOCE) and the American Heritage Third EdlUon (AHD3) Man:y techmcal aspects of thin project are rooted m the works of Vanderwende (Vanderwende 1996) and Richardson (R2chardson 1997) 3 Word sense disambiguation of gloss concepts There are se~e, al dlffe~ences bet~een gloss dlsamblguauon and text dlsamb~guatmn A n-la\]oi difference is that m our project we know the meaning of each gloss, namely the synset to whmh a gloss apphes Second, the glosses contain a defimUon, comments, and one or more examples We address the word sense dmamblguaUon problem by using three complementary methods (a) heunstms, (b) conceptual dens,ty, and (c) staustins on large corpora The first two methods rely enurely on the mfolmaUon contained m WordNet, while the th,rd one uses other corpora Specffically, the sources of knowledge available to us me (1) lexlcal mformauon that includes part of speech, posluon of ~ords (1 e head word), and lexmal lelauons (2) collocauons and s)ntacuc patterns, (3) s}nset to which a gloss belongs, (4) hypernyms of s)nset and their glosses (5) synsets of pobsemouns x~o2ds and their glosses, (6) hypernyms of synsets of polysemous words, and their glosses, and so on Method 1 Classes of heur,st,cs for word sense dmarnblguatmn A statable techmque for dmamblguatmg dmuonarms is to rely on heu!mucs able to cope with d~ffe2ent sources of mformauon Work m tins alea w~ doue by Ravin (Rax m 1990) in a similar project at IBM, (Klavans et al 1990), and others We present no~ some of the heunsUcs used by us 1.
ClassHypernyms A way of explaining a concept m to speclahze a more general concept (, e a hypernym) It m hkely that an explanatmn begins with a phrase whose head is one of ~ts hypernyms, and the features are expressed either as attributes m the same phrase o2 as phrases attached to the first phrase Example The gloss of synset {xntrusxon} is (entrance by force or without permxsslon or welcome) • entrance#3, the head of the fiist phrase, is a hype~n)m of zntruszon, thus we pick sense 3 of noun entrance (The senses in Wo2dNet a2e,anked acco, dmg to then frequency ot occmrence m the Brown corpus, entrance#3 means sense 3 of wo, d entrance ) 2 Class Lmgmstlc Parallehsm It 2s hkel? that the s} ntacuc pal allehsm of t~ o xx ord~ uanslates into semantic parallelmm and the ~xo2ds may have a common hypernym, or one m a hypernym of the other Fo~ adjectives, the hypein) m) is replaced by the similarity relation Other heuristics in this class check ~hether or not two pol)semous words belong to the same synset, or one is a hypern} m of the other, or if they belong to the same the2 arch:y Example The gloss of {interaction} is (a mutual or.
reczprocal actlon) • Adjective reciprocal has only one sense,n WordNet 1 6, whereas mutual has two senses But we find that between sense 2 of mutual and reciprocal there is a szmdar link m WordNet 1 6, thus pick mutual#2 3.
Class. Gloss Comments.
In glosses, comments and examples are meant to provide supplemental information It ts possible to find the specmhzatlon o, typical relation hnkmg the comment to the preceding head phrase m one of the synsets (or gloss) of the head phrase E~ample The gloss of the synset {scuff, scuffing} IS (the act of scufflng (scraplng or dragging the feet)) • In %¥ordNet 1 6 there is a synset {scuff#l, drag}, thus verb scuff Is dlsamblguated 4 Class.
Gloss Examples Examples in WordNet prov,de collocatmnal reformation of the words m synsets The intrinsic semanuc tag of the word from the synset which is used in the example can occur in the same lexical relation in some other gloss, carrymg the semantic tag w,th ~t Example Synset {penetration} has the gloss (the act of forcing a way Into something) • \[wlrw2\] ---\[force way\] The gloss of {way#9} contains the example (2 'I had xt my way' '), provldmg the lexlcal relation \[w3rw2\] = \[have way\] • Noun way is dxsamblguated (sense 9), and verbs have#7 and force#9 have a common hypernym, therefore verb force ~s also dlsambiguated 5 Class Collocations Nouns representing actions ate nommahzatmns of some verbs If a verbal collocation contains a noun, and is also a s~ nonym of some mo, phologmally related verb, then,t is likely to be the nommahzatlon source The verb from the gloss of a synonym describing an actmn, ff not the source of the nomlnahzaUon is hkely to belong to the same hmtarchy as the true nommahzatlon source, since they must share some properties Ezample Let s = {escape, flight}, with the gloss (the act of escaping physically) • The ~erb escape Is morphologically identical to the noun escape from synset s • Sense 1 of verb escape has a hypernym collocation usmg noun flxght from s, thus is selected 6 Class Lex~cal Relat,ons %.
lexlcal relatmn using a ~ ord w both in the gloss of a s} nsct s and m some other gloss s~gnals a prope~D, of w associated u~th s In other cases x~hen ~wo ielatmns \[w,r w~\] and \[w,~ w~.\] are ~ound m txvo glosses of %%bldNet, and the~e are senses of w~ and w~ that have a common hypernym, it is hkely that the correlatmn between w, and the common hypeInym is projected m both collocatlons Example The gloss of the synset {Underground Rallroad} Is (abolltlonlsts secret ald to escaping slaves) • We have \[wlrw2\] \[ald to slave\] • The gloss of {ald#4} is (ald to someone) • The pronoun someone can tefel to {slave#l} thus sense 4 of noun ald IS picked Method 2 Conceptual dens,ty method We have,mplemented a WSD system for free text that disamb,guates multiple wolds mmultaneousl3 (Mlhalcea and Moldovan, 1999) The method is based on measuring the number of common nouns shared by the verb and noun hmrarchms, and thus gets around the lack of connections problem As an example, consider a verb noun pair of uotds Denote w~th < vl,v2,,Vh > and < nl,n2,,nt > the senses of the verb and the noun m WoidNet Fo~ each possible pelt v, n j, the conceptual density m computed as follows 1 Extract all the glosses from the sub-hmrmch~ of v, and determine the nouns from these glosses This constitutes the noun-context of verb v, Each such noun is stored together with a weight w that indicates the level m the sub-hmrarchy of the velb concept m whose gloss the noun was found 2 Determine the glosses of the noun sub-hmtatchy of nj and determine the nouns m them 3 Compute the conceptual denszty C u of the common concepts between the nouns obtained at (1) and the nouns obtained at (2) using the metllc Icd,j I & C~3 = lo9(descendentsj) (1) where • \[~d,~l is the number of common concepts between the tnelarch,es of v~ attd nj • w~ are the levels of the nouus m the lueiaich~ of verb v, • descendentsj *s the total number of uotd~ w,thm the hmra, chy of noun nj 4 C u tanks each pa,r v, nj, fol all ~ and j Vanants of th,s method work for other parts of speech pairs such as noun-noun, noun-verb, verb-verb, verb-noun, adje.cUve-noun and verb-adverb Th,s,s a powerful method that v, orks surprisingly x~ell even for free text We ha~e tested the method on SemCor, the pint of the Brown coipus tagged x~ltlt WotdNet seltses \V,th tlns technique it is possible to,ank the senses and \[o keep not only the h~st lanked sense, but the second ol th,td ~anked senses 3 especmlly when the tankmg is sufficiently close and there ~s another wa~ to check the vahd,ty of the d~samb~guaUon Method 3 Statistics on large corpora As a last resort, we can use a staustmal approach to d,samblguate those words that can not be done with any of the methods described so fal Consider a collocating word-word pmr wl w2 m whmh we conslde, that Wl has been dtsambtguated already The dlsambtguatmn of w2 proceeds as follows (1) Foi each sense w~, form a slmdanty hst with w) and all other words that may be m that synset {w.~, w', (1) ",(2)~ ' _, w 2 ) } (2) Form pans of wz and all the %xords m each ~Izmlarzty hst foI all z (3) Search a lalge empus for the occurrences o\[ any of the pans m the hst above,,., KI).
. K2)~,, { wtw~" OR ~1~ OR wzw 2 ) } We have searched the Internet using the AltaV~sta search engine The number of hits for each similarity hst measmes the,elatedness of w~ wtth each sense w~ and thus provtdes a ranking of the senses Overall Procedure and Results The followmg procedure was used to dlsamb~guate 12,762 words from 1000 randomly selected glosses Step 1 Identify and separate the monosemous words that have only one sense m WordNet (m out experiment 6468 words were found) Step 2 Apply Method 1 HeurlsUcs to the reroaming 6294 polysemous words Method 1 provides correct d~samblguatmn for 5475 words, thus an accmac~ of 87% Out of the remammg 13% of the words, 3% were dlsamb~guated erroneously and 10% could not be done with the heuristics used The correct sense for each word was determined manually by a team of three students We ha~e found a fe~ s) n~ets such as {commemorate, remember} that have no hnks to an~ other synsets, m no h3 pern3 ms and no hypom}ms Step 3 Apply Method 2 Conceptual Denszty to the 6294 polysemous words, staitmg hesh Step 4 Apply Method 3 StaUstlcs to the 6294 words using Alta¥~sta on the Internet Step 5 The results obtained wtth Method 1 and Method 2 are combined, that is, take all the wo, ds that were d~sambzguated, and m the case of conflict g~ve prmnty to Method 1 Step 6 The results from Step 5 are combmed wtth the results g~ven by Method 3 and m the case of conflmt gtve priority to results obtained m Step 5 Table 1 indicates the accuracy obtamed at each step An overall accmacy of 94% x~as achmved Out goal,s to improve the techmque to be able to dlsamb~guate all words automatmally These results must be seen agamst the background average rate of 59 39% correct sense asstgnment achmved when the first WordNet sense is assigned to each polysemous word This is considered the basehne performance level for word-sense dlsamblguat,on programs (Gale et al 1992) and is consistent ~uth out own measurements 4 Logical form transformation Our extenszon of WordNet Intends to serve as a lexlco-semantic Iesource for a variety of NLP apphcations, many of them requiring pragmauc and common-sense knowledge (Harabagm and Moldovan 1998) It is beneficial to transform the conceptual glosses m logical foimulae Approach to implement Logical Form Transformat,ons (LFTs) (1) Traditional lexmographm principles deteIImne the d,scnmmatlon of any conceptual defimtlons into a genus and the dzfferentza Our LFTs Implement the same dlstlncUon by always plaong the genus predicate on the first position of the LFT, and the rest of the LFT viewed as the definition differentia (2) A predmate is generated for every noun, verb, adjective or adverb encountered In any gloss The name of the predicate is a concatenatmn of the morpheme's base form, the pat t-of-speech and the WordNet semanuc sense, thus capturing the full lemcal and semantm disamblguaUon For example, the LFT of the gloss of {student, pupzl, educatee} contains the predmates learner n#l, enroll v#l and educabonaIJnstJtutlon n#l (3) In the sprat of the Davidsoman tzeatment oi the acUon predicates, all verb predmates (as ~ell as the nommahzaUons zeptesentmg acuons, e~ents or states) haxe thlee arguments actlon/state/eventpredlcate(e,,~\[,x~), where • e, zeptesents the eventuahty of the acUon state ot exent ~ stated b> the xetb to take place, • 3.~ ~epresents the syntactLc sub3ect of the acUon event ot state, and • ~ lepresents the syntactic object o~ the acuon event or state In the case when the subject or the object are present m the gloss, they share the correspondmg arguments wtth the actmn/state/event predmate For example, the LFT of (a person who backs a polltlclan) the gloss of {supporter, protagonlst, champion, admlrer, booster, friend} zs LFT = \[person n#l(:ci) ~z back v#l(el,xl,x2) & pohtloan n#2(x~) \] \[ I Method 1 Method 2 Method 3 (M1) U M2 \[ ((M1) U M2) U M3 I (Step 2).
(Step 3) (Step 4) (Step 5) \[ (Step 6) \[ Accuracy \[ 87 80 68 92 I 94 Table 1 Summary of results m % for the d~samb~guatmn of 1000 glosses (4) The role of complements wmthm a phrase ~s rephcated m the LFTs Predicates generated from modffiers share the same arguments w~th the predicates corresponding to the phrase heads Adjective p~ed~cates share the same argument as the predicate corresponding to the noun they modify An exemphficatlon ~s the LFT of the gloss of {art~fact, artefact}, whmh maps (a man-made object) into \[ object n~l(x~) ~ man-made a#l(x~)\] S~mllarly, the argument of adverbml predmate ~s the argument marking the eventuahty of the event/state/actmn they modify For example, the gloss of the verb synset {hare} is (run quickly), producing the LFT = \[run(e~,:~,x~) & qu~ckly(e~)\] (5) Conflunctmns a~e transformed m predicates, whmh enable the aggregatmn of several predicates under the same syntactic role (e g subject, object or preposmonal object) By conventmn, conjunctionpredmates have a variable number of arguments, since they cover a varmble number of predicates The first argument represents the "result" of the logmal operation induced by the conjunctmn (e g a logical and m the case of the and conjunctmn, or a loggcal or m the case of the or con\]unctmn) The rest of the a~guments mdmate the predicates covered by the conjunctmn, as they are a~guments of those predmates as well (6) We also generate p~edmates for every preposition encountered,n the gloss The prepos~tmn predicates always have two arguments the first argument corresponding to the predicate of the head of the phrase to which prepos~tmnal phlase ~s attached, whereas the second argument corresponds to the prepos~tmnal object Sources of mformatmn.
The ~mplementatlon of LFTs rehes on mformatmn provided b3 (a) Lexmal and semantm d~samb~guatmn p~oduced m the p~eprocessmg and semantm d~samb~guatmn phases Th,s mformatmn contributes to the creatmn of predicate names (b) Phrasal parsing, enabl,ng the recogmtmn of basic and complex phrases Th~s determines all complements to share the same predmate argument w~th the phrase head (c) Syntactm t~ansformatmn rules, d~scnmmatmg the syntactm subject and object of every verb (m nommahzatmn) based on the local syntactic context (d) Preposlt,onal attachment resolutmn, indicating the arguments of the prepos~tmn p~ed~cates Table 2 lllustiates the tlansfolmatlons fo~ the gloss of {tennis, lawn tennis} 5 Semantic form transformation Many NLP problems lely on the recogmuon of the tyDcal lexmo-semantm I elatlonshlps between hngulstm concepts The LFT codfficatlon meiely acknowledges the foUowmg syntax-based relatlonsh~ps (1) syntactic subjects, (2) s)ntactm objects (3) prepositional attachments (4) complex nominals and (5) adjecuval/adverblal adjuncts Semanuc mterpretat,ons of utterances, as ~ell as d~scou~e p~ocessmg require knowledge about the semantic or themat~c relatmnsh~ps between concepts The ~emant~c form trans.formatwns prov,de with constraint-based mappings of the syntax-based relatmns covered m the LFTs into binary thematic relatmns or semantLc relations (We dlstmgmsh between thematic ~elatmns such as agent, expenencer, etc, and semantic relatmns such as a-kind-of, part-of, etc ) Approach to ~mplement Semant,c Form Transformatmns (SFTs) 1 The syntactic sublect relations lecogmzed m the LFTs by the predmatlve formula subjeCt(xl )&:verb(e, ~ l, ~.~) can be mapped into a x aIlet:y of thematic relations The defimtlon of the thematm relations is enurely based on mfo~matmn internal to the WordNet database, explessed as constraints Fol example, all the subjects of verbs that are hyponyms of the verb cause or have thts concept as the genus of then glosses are defined to represent the Iole of agents (2) The syntactzc obTect ~elatmns a~e tecogmzed m the LFTs b) the predmauve founula verb(em,xi,x2) & aoua(~2) The defimtmn of tim thematic relatmns m whmh syntactm objects can be mapped is expressed m terms of verb synsets The constraining verb synsets ~epresent the upper-most hypernyms of all verbs that (z) have syntactic objects m the WordNet glosses and (~z) belong to the same hmrarchy or a~e defined by gloss gem from the same h~el arch:y (3) The preposztzonal predzcates ale tlansfolmed into thematm ol semantm relations When a IVo~dGloss (a game played w~th rackets by two or four players who hxt a ball back and forth over a net ~hat LFT SFT d~v~des a tennis court) game n#2(x2) & play v~2(e~,z~,x2) & w~th(et,z3) & racket n~4(z3) & by(el,z~) & or(xl,Z3,z4) gz two n#l(z3) &: four n#1(x4) & player n~l(z~) &: hit v#l(e~,x~,z~) ~z ball n#l(zs) &: back_and_forth r@l(e~) & over(e2,~) & net n~5(z~) gz d~wde v#5(e3,x~,z,z),~ tenms_court n~l(xT) gloss(tenms n~l,game n#2) object(game n#2,play v~2) agen~(pla~er n#l,play v#2) attribute(or(two n~l,four n#l),player n#l) agent(player n#l,h~t v~l) object(ball n#l,h~t v#l) locatmn(net n#5,h,t v#l) agent(net n#5,d,wde v#5) object(tenms_court n#l,d~v,de v#5) Table 2 T~ans~rmatlons associated with the gloss of synset {tennxs, lawn tennxs} (a game played wxth rackets by two or four players who h~t a ball back and forth over a net that d~v~des a tennis court) Net semantm relauon holds between the arguments of a pteposmonal p~edmate, that specffic ~elatmn becomes the semantic transformauon of the predicate Fol example, the PP attachment \[sacrament of penance\] derived from the gloss of {confession} indicates a semantic kind-o\[ relauon due to the fact that m WordNet penance is a hyponym of sacrament (4) The transformation of complex nominal predzcates into thematic or semanUc constraints m done by first seeking a WordNet relatmn (or a combmaUon of such relatmns) between the components of the predicate If such a (chain of) relation(s) m found, predicate nn is transformed into the dominant WordNet semantic relation Otherwise, the no predicate is transformed into a thematic relation (5) The Uansformatlon of ad3ectwal and adverbzal adjuncts, lepresented m the LFTs as p~edmates sharing the same argument with the concepts they modify shall be connected to their modifiers through attribute lelauons 6 Include more derivational morphology Smce the oIgamzaUon of WordNet dlwdes the Enghsh vocabulary into four sepmate domains-nouns, velbs, ad\]ecuves, and adverbsclosely related concepts are often entered in more than one of these domains Many (probably most) of these relatmns can be ~dentffied m terms of denvatlonal morphology, e ~, the noun executzon is derived from the verb execute and so is an example of a deverbal noun WordNet already contmns some of th~s kind of denvatmnal morphology dead\]ecUval nouns are hnked to their root adjecuves (length m derived \[tom long), deadjectival adverbs are hnked to then loot adjecu~es (rapidly Is derived from rapid), and some denommal ad\]ecUves are hnked to then ~oot nouns (cellular m derived from cell) In o~del to mcrease the connecUwty of WordNet it would be desirable to include more such deIlvaUonal morphology Fol example, denvauonal lelatmns betxxeen nouns and verbs should be palUcularly useful (Hull and Gomez 1996) both de= veIbal nouns (avowal from avow) and denommal verbs (sammarlze from summary) Such connecuons would facilitate the recogmtmn that the same idea can be expressed m different ways, e g, that "He summarized the book" and "He gave a summary of the book" are effecUvel~ eqmvalent m meanmg Sometimes these morphological relations can be picked up from glosses, as when {disagreement} is defined as (the speech act of dlsagreexng or arguing or disputing), but these are generally regarded as unmformaUve definitions, and the leveIse relation may not happen to occur Since many of the words ale polysemous, moxphologmal relatmns should not link words, but synsets that have related meanings Fot example, {execute} meaning (to put to death) should be hnked to {execution} meaning (the act of puttxng a condemned person to death), and {execute} meanmg (to carry out a task) should be hnked to {execution} meaning (the act of doing sometMng successfully), etc And m cases where the concepts of the noun and verb a~e dlffeIent-e g, {womanize} floin {woman}-no semanUc link ~ould need to be cleated References H Alsha~xl Analysm the dlcUonaly deflmuons In B Boguraev and T Bnscoe, editors, Compatatzonal Lexzcography for Natural Language Processrag, pages 153-170 Longman, London, 1989 R Bruce and L Guthne Genus dlsamblguatmn a study m weighted preference In Proceedings of COLING92, COLING92, pp 1187-1191 W Gale, K W Chinch and D Yarowsky Estimating uppel and lowel bounds on the peflolmance of ~old-sense dmamblguaUon programs In Proceed,ngs of the 30th Annual Meetzng of the A~socmtzon for Computatzonal Lmguzst~cs, New, ark, Delaware, 1992 S M Harabagm and D I Moldovan A Parallel Inierence System In IEEE Transactzon on Parallel and Dzstmbuted System, Aug 1998, pp 729-747 R D Hull and F Gomez Semantm mterpretatlon of nommahzatlons In Proceedings of the 13th Natzonal Conference on Artzficzal Intelhgence AAAI96, Portland, OR, 1996 N Ide and J Veroms Extracting knowledge bases from machine-readable dictionaries have we wasted our t~me ~ In KB ~4 KS, Tokyo, Japan, Dec 1993 J Klavans, M Chodorow amd N Wacholder From dmtlonaly to knowledge base via taxonomy In Electronzc Text Research, Umverslty of Waterloo, Cente~ for the New OED and Text Research, Waterloo, Canada, pages-110-132, 1990 R Mlhalcea and D I Moldovan A Method for Word Sense Dlsamb~guatlon of Unrestrmted Text In Proceedings o/ the 37th Annual Meeting of the ACL, June 1999 S Montemagm and L Vanderwende Structural Patterns vs stnng patterns for extracting semantic reformation from dictionaries In Proceedings of COLING92, COLING '92, pp 546-552 Y Ravin Dlsamblguatmg and interpreting verb defmltmns In Proceedings o/ the 28th Annual Meetmg o/the Assoczatzon /or Computatwnal L~nguz~tzcs, Pittsburgh, PA, pages 260-267, 1990 S Rmhardson Determining slmfiar~ty and mferimg ~elatmns m a lexmal knowledge base In PhD dzssertatwn, City Umverslty of New Yolk, 1997 L Vander~ende The Analysis of Noun Sequences using Semantm Informatmn Extracted from OnLine Dlctmnarms In Ph D dzssertatzon, George \Vastungton Umverslty, Washington D C, 1996 Y A Wllks, B M Slator, and L M Guthrm Electric words d~ctlona~ms, computers and meamng In MIT Press, 1996

