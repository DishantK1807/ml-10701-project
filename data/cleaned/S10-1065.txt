Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 296–299,
Uppsala, Sweden, 15-16 July 2010. c 2010 Association for Computational Linguistics
VENSES+: Adapting a dep semantic procesing system to the 
identification of nul instantiations 
Sara Tonelli 
Fondazione Bruno Kessler 
Trento, Italy. 
satonelli@fbk.eu 
Rodolfo Delmonte 
Università Ca’ Foscari 
Venezia, Italy. 
delmont@unive.it 
 
 
 
Abstract 
The system to spot INIs, DNIs and their anteced-
ents is an adaptation of VENSES, a system for 
semantic evaluation that has ben used for RTE 
chalenges in the last 6 years. In the folowing we 
wil briefly describe the system and then the ad-
ditions we made to cope with the new task. In 
particular, we wil discus how we maped the 
VENSES analysis to the representation of frame 
information in order to identify nul instantia-
tions in the text. 
1 Introduction

The SemEval-2010 task for linking events and 
their participants in discourse (Rupenhofer et 
al., 209) introduced a new isue w.r.t. the Se-
mEval-207 task “Frame Semantic Structure Ex-
traction” (Baker et al., 207), in that it focused 
on linking local semantic argument structures 
acros sentence boundaries. Specificaly, the task 
included first the identification of frames and 
frame elements in a text folowing the FrameNet 
paradigm (Baker et al., 198), then the identifica-
tion of localy uninstantiated roles (NIs). If these 
roles are indefinite (INI), they have to be marked 
as such and no antecedent has to be found. On 
the contrary, if they are definite (DNI), their 
coreferents have to be found in the wider dis-
course context. The chalenge comprised two 
tasks, namely the ful task (semantic role recog-
nition and labeling + NI linking) and the NIs 
only task, i.e. the identification of nul instantia-
tions and their referents given a test set with gold 
standard local semantic argument structure. 
We tok part to the NIs only task by modify-
ing the VENSES system for dep semantic pro-
cesing and entailment recognition (Delmonte et 
al., 205). In our aproach, we asume that the 
identification of nul instantiations is a complex 
task requiring diferent levels of semantic know-
ledge and several procesing steps. For this rea-
son, we believe that the rich analysis performed 
by the pipeline architecture of VENSES is par-
ticularly suitable for the task, also due to the 
smal amount of training data available and the 
heterogeneity of NI phenomena. 
2 The
VENSES system 
VENSES is a reduced version of GETARUNS 
(Delmonte, 208), a complete system for text 
understanding, whose backbone is LFG theory in 
its original version (Bresnan, 1982 and 200). 
The system produces diferent levels of analysis, 
from syntax to discourse. However, thre of 
them contribute most to the NI identification 
task: the lexico-semantic, the anaphora resolution 
and the dep semantic module. 
2.1 The
syntactic and lexico-semantic  
module 
The system produces a c(onstituent)-structure 
representation by means of a cascade of aug-
mented FSA, then it uses this output to map lexi-
cal information from a number of diferent lexica 
which however contain similar information re-
lated to verb/adjective and noun subcategoriza-
tion. The maping is done by spliting sentences 
into main and subordinate clauses. Other clauses 
are computed in their embeded position and can 
be either complement or relative clauses. 
The system output is an Augmented Head 
Dependent Structure (AHDS), which is a fuly 
indexed logical form, with Gramatical Rela-
tions and Semantic Roles. The inventory of se-
mantic roles we use is however very smal – 35, 
even though it is partly overlaping the one pro-
posed in the first FrameNet project. We prefer to 
use generic roles rather than specific Frame Ele-
ments (FEs) because sense disambiguation at this 
stage of computation may not be efective. 
296
2.2 The
anaphora resolution module 
The AHDS structure is pased to and used by a 
ful-fledged module for pronominal and ana-
phora resolution, which is in turn split into two 
submodules. The resolution procedure takes care 
only of third person pronouns of al kinds – re-
ciprocals, reflexives, posesive and personal. Its 
mechanisms are quite complex, as described in 
(Delmonte et al., 206). The first submodule 
basicaly treats al pronouns at sentence level – 
that is, taking into acount their position – and if 
they are left fre, they receive the anotation 
“external”. If they are bound, they are asociated 
to an antecedent’s index; else they might also be 
interpreted as expletives, i.e. they receive a label 
that prevents the folowing submodule to con-
sider them for further computation. 
The second submodule receives as input the ex-
ternal pronouns, and tries to find an antecedent in 
the previous stretch of text or discourse. To do 
that, the systems computes a topic hierarchy that 
is built folowing sugestions by (Sidner and 
Grosz, 1986) and is used in a centering-like 
maner. 
2.3 The
semantic module 
The output of the anaphora resolution module is 
used by the semantic module to substitute the 
pronoun’s head with the antecedent’s head. After 
this operation, the module produces Predicate-
Argument Structures or PAS on the basis of a 
previously produced Logical Form. PAS are pro-
duced for each clause and they separate obliga-
tory from non-obligatory arguments, and these 
from adjuncts and modifiers. Some adjuncts, like 
spatiotemporal locations, are only bound at 
propositional level. 
3 From
VENSES output to NIs identifi-
cation and binding 
After computing PAS information for each sen-
tence, we first map the test set gold standard an-
notation of frame information to VENSES out-
put. Starting from the PAS with frames and FE 
labels atached to the predicates and the argu-
ments, we run a module for DNI/INI spoting 
and DNI binding. It is composed by two diferent 
submodules, one for verbal predicates and one 
for nominal ones. 
3.1 NIs
identification and binding with ver-
bal predicates 
As pointed out in (Rupenhofer et al., 209), the 
identification of DNI/INIs includes thre main 
steps: i) recognizing that a core role is mising i) 
ascertaining if it has a definite interpretation and 
ii) if yes, finding a role filer for it. 
For verbal predicates, the two first steps are ac-
complished starting from the PAS structure pro-
duced by VENSES and trying to map them with 
the valence paterns in FrameNet. To this pur-
pose, we take into acount the list of al valence 
paterns extracted for every LU and every frame 
from FrameNet 1.4 and from the training data, in 
which al posible sequences of FEs (both 
overtly expresed and nul instantiated) are listed 
with their gramatical functions, corenes status 
and frequencies. For example, the predicate 
“barbecue.v” in the APLY_HEAT frame is char-
acterized by two paterns, both ocuring once. 
In the first, Fod is the subject (ext) and Cok is 
constructionaly not instantiated (cni). In the sec-
ond, the peripheral FE Time is also present: 
 
sr(barbecue-v,aply_heat,[[fod
c,np,ext],[cok-c,cni,nul],1],[[time-
p,p,dep],[fod-c,np,ext],[cok-
c,cni,nul],1]). 
 
The first step in our computation is selecting for 
the curent predicate those paterns or templates 
that contain the same number of core arguments 
of the clause under analysis plus one. This is due 
to the fact that NIs are always core FEs. For ex-
ample, if a test sentence contains the “barbe-
cue.v” lexical unit labeled with the AP-
PLY_HEAT frame and only the Fod FE is overtly 
anotated, we lok in the template list for al pat-
terns in which “barbecue.v” apears with the 
Fod FE and another implicit core FE (either INI 
or DNI). If “barbecue.v” is not present in the 
template list, we consider the templates of the 
other verbal lexical units in the same frame. 
The second step is asesing the licensor of the 
omision, whether lexical or constructional. Here 
we only distinguish complement governing 
predicates and pasive constructions. For exam-
ple, if “barbecue.v” is atested in the template list 
both with an indefinite and with a definite instan-
tiation of the Cok FE, we check if it ocurs in 
the pasive form in the test sentence. If yes, we 
infer that Cok has to be labeled as an indefinite 
nul instantiation (INI). Another licensor of the 
omision could be the imperative form of the 
verb, which however has not ben considered yet 
by our system. 
If we ases that the nul instantiation is not 
indefinite, we lok for an antecedent of the NI 
and, if we find it, we label it as a DNI. Other-
wise, we don’t encode any information about 
297
omited roles. The strategy devised for searching 
for posible referential expresions is as folows: 
1. Given the curent PAS (with frame labels), 
lok in the previous sentence(s) for compa-
rable PAS. Comparable means that the predi-
cate is the same or semanticaly related based 
on WordNet synsets. 
2. If a comparable PAS is found, check if they 
share at least one argument slot – typicaly 
they should share the subject role. 
3. If yes, lok for the best head available in that 
PAS by semantic matching with the FE label 
as a referent for the DNI label in the curent 
sentence. In case that does not produce any 
matching, we lok into the list of al heads in 
FrameNet asociated to the FE label and se-
lect the one present in the PAS that matches. 
3.2 NIs
identification and binding with 
nominal predicates 
In order to identify DNI/INIs of nominal predi-
cates, we take into acount the History List pro-
duced by VENSES in the AHDS analysis, where 
al nominal heads describing Events, Spatial and 
Temporal Locations and Body Parts in the 
document are colected together with their cur-
rent sentence ID. Such list is derived from 
WordNet general nouns. 
Based on a computational lexicon of Com-
mon Sense Reasoning relations made available 
with ConceptNet 2.0 by MIT AI Lab (Liu and 
Singh, 204), we first proces the history list in 
order to identify the relations betwen nominal 
heads in diferent sentences. Such relations in-
clude inheritance and inferences. For instance, if 
the curent sentence contains the nominal heads 
“dor” or “window”, they are conected to the 
“house” head, if it is present in the History List 
as a spatial location ocuring in a previous sen-
tence. For instance, sentence 42 of the test 
document n. 13 contains the noun “wal” as lexi-
cal unit of the ARCHITECTURAL_PART frame. In 
the History List, it is clasified as a place. Also 
the noun “house” in sentence n. 7 (token 7) is 
clasified as a place in the History List. Since 
ConceptNet alows us to infer a meronymy rela-
tion betwen “wal” and “house”, we can derive 
the folowing information, saying that “place” in 
sent. 45, token 25, is related to “house”, in sent. 
7, token 7: 
loc(42-25, place, wal, house-[7-7]). 
Starting from this information, we then check 
which core FEs are overtly expresed in the test 
sentence for the “wal” lexical unit. As encoded 
in the FrameNet database, the ARCHITEC-
TURAL_PART frame has two core FEs, namely 
Part and Whole. Since Part is already present in 
sentence n. 45, we asume that Whole could be a 
candidate DNI. After loking up the relations 
betwen nominal heads identified in the previous 
step, we make the hypothesis that “house” be the 
antecedent of the Whole DNI. We then check if 
“house” apears as a head of the hole FE either 
in the FrameNet database or in the training data 
of the SemEval task in order to perform some 
semantic verification. If this hypothesis is con-
firmed, we finaly take the syntactic node headed 
by the antecedent as the best DNI referent. In our 
example, “house” is the head of the node 501, so 
we generate the folowing output, in which the 
Whole FE is identified with the node 501 
(headed by “house”) in sentence 7:   
 
 <fe id="s42_f5_e2" name="Whole"> 
 <fenode idref="s7_501"/> 
 <flag name="Definite_Interpretation"> 
 
Note that, in case the antecedent does not apear 
as the head of the candidate FE, it is discarded 
and no information about NIs is generated. This 
is clearly a limit of our aproach, because nomi-
nal predicates are never asigned an INI label. 
4 System
output and evaluation 
The SemEval test data comprise two anotated 
documents extracted from Conan Doyle’s novels. 
We report some statistics about the test data with 
gold standard anotation and a comparison with 
our system output in Table 1. 
 
 Text 1 Text 2 
N. of sentences 249 276 
Gold standard data 
N. of DNIs 158 191 
N. of INIs 15 245 
System output 
N. of DNIs 35 30 
N. of INIs 16 20 
F-score 0.0121 
Table 1: Comparison betwen gold standard and  
system output 
 
The amount of NIs detected by our system is 
much lower than the gold standard one, particu-
larly for INIs. This depends partly on the fact 
that no specific strategy for INI detection with 
nominal predicates has ben devised so far, as 
described in Section 3.2. Another problem is that 
a lot of DNIs in the gold standard don’t get re-
solved, while our system always loks for a re-
298
ferent in case of DNIs and if it is not found, the 
procedure fails. 
The isue of detecting which DNIs are liable 
not to have an explicit antecedent remains an 
open problem. In general, Rupenhofer et al. 
(209) sugest to treat the DNI identification and 
binding as a coreference resolution task. How-
ever, the only information available is in fact the 
label of the mising FE. The authors propose to 
obtain information about the likely filers of a 
mising FE from anotated data sets, but the task 
showed that this procedure could be sucesful 
only in case al FE labels are semanticaly wel 
identifiable: in fact many FE labels are devoid of 
any specific asociated meaning. Furthermore, 
lexical filers of a given semantic role in the Fra-
meNet data sets can be as diverse as posible. 
For example, a complete search in the FrameNet 
database for the FE Charges wil reveal heads 
like “posesion, inocent, actions”, where the 
significant portion of text adresed by the FE 
would be in the specification i.e. "posesion of 
a gun" etc. Only in case of highly specialized 
FEs there wil be some help in the semantic 
characterization of a posible antecedent. An-
other open isue is the notion of context where 
the antecedent should be searched for, which is 
lacking an apropriate definition. 
If we take into acount our system results on 
Text 1, we notice that only 3 DNIs have ben 
identified and linked to the corect antecedent, 
while the overal amount of exact matches in-
cluding INIs is 7. However, in 21 other cases the 
system corectly identifies a nul instantiated role 
and asigns the right FE label, but it either de-
tects an INI instead of a DNI (and vice-versa), or 
it finds the wrong antecedent for the DNI. A 
similar performance is achieved on Text 2: no 
DNI has ben linked to the corect antecedent, 
and in only 8 cases there is an exact match be-
twen the INIs identified by the system and those 
in the gold standard. However, in 18 cases a nul 
instantiation is detected and asigned the corect 
FE label, even if either the referent or the defi-
nitenes label is wrong. Some evaluation metrics 
taking into acount the diferent information lay-
ers conveyed by the system would help high-
lighting such diferences and pointing out the NI 
identification steps that ned to be consolidated. 
5 Conclusions

In this paper, we have introduced VENSES+, a 
modified version of the VENSES system for dep 
semantic procesing and entailment detection. 
We described two strategies for the identification 
of nul instantiations in a text, depending on the 
predicate clas (either nominal or verbal). 
  The system tok part to the SemEval task for 
NIs identification and binding. Even if the pre-
liminary results are far from satisfactory, we 
were able to devise a general strategy for dealing 
with the task. Only 2 teams tok part to the 
competition, and the first ranked system achieved 
F1 = 0.0140. This confirms that NI identification 
is a very chalenging isue which can be hardly 
modeled. Anyway, it deserves further eforts, as 
various NLP aplications could benefit from the 
efective identification of nul instantiated roles, 
from SRL to coreference resolution and informa-
tion extraction. 
References  
Baker, C., Elsworth, M. and Erk, K. 207. Frame 
Semantic Structure Extraction. In Procedings of 
the 4
th
 International Workshop on Semantic 
Evaluations. Prague, Czech Republic. 
Baker, C. F., Filmore, C. J., & Lowe, J. B. 198. The 
Berkeley FrameNet project. In Procedings of 
COLING-ACL-98, Montreal, Canada. 
Bresnan, J. 200. Lexical-functional syntax. Oxford: 
Blackwel. 
Bresnan, J. (ed.). 1982. The mental representation of 
gramatical relations, The MIT Pres, Cambridge. 
Delmonte R., 208. Computational Linguistic Text 
Procesing – Lexicon, Gramar, Parsing and 
Anaphora Resolution, Nova Science, New York. 
Delmonte, R., Toneli, S., Picolino Boniforti, M. A., 
Bristot, A., and Pianta, E. 205. VENSES – A Lin-
guisticaly-based System for Semantic Evaluation. 
In Proc. of the 1
st
 PASCAL RTE Workshop. 
Delmonte, R., Bristot, A., Picolino Boniforti, M.A., 
and Toneli, S. 206. Another Evaluation of 
Anaphora Resolution Algorithms and a Compari-
son with GETARUNS' Knowledge Rich Aproach, 
In Proc. of ROMAND 206, Trento, p. 3-10. 
Grosz, B., and Sidner, C. 1986. Atention, intentions 
and the structure of discourse. Computational Lin-
guistics, 12, 175–204. 
Liu, H., and Singh, P. 204. ConceptNet: a practical 
comonsense reasoning tolkit. At 
htp:/web.media.mit.edu/~push/ConceptNet.pdf. 
Rupenhofer, J., Sporleder, C., Morante, R., Baker, C. 
and Palmer, M. 209. SemEval-2010 Task 10: 
Linking Events and Their Participants in Dis-
course. In Proc. of the HLT-NACL Workshop on 
Semantic Evaluations: Recent Achievements and 
Future Directions. Boulder, Colorado. 
299

