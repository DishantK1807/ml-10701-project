1:111	Book Reviews Computational Linguistics in Medicine Werner Schneider and A-L Sagvall Hein, Editors North-Holland Publishing Co. , New York, 1977, 181 pp.
2:111	, $28.25, ISBN 0-444-85040-6.
3:111	The convening of an international conference on Computational Linguistics in Medicine and the substantive results reported in many of the papers in this volume of Conference Proceedings testify to the special relevance of research in computational linguistics to the problem of processing medical information.
4:111	While no discipline, even the most mathematically oriented, escapes a dependence on language to record and transmit its findings, medicine relies for its daily operations on the ability of its practitioners to draw upon information in natural language form, both patient data and the medical knowledge relevant to treatment.
5:111	Given the diversity and complexity of the problems that are handled, and the vast store of medical knowledge that must be remembered or consulted as part of the treatment process, it is no wonder that medicine is one of the first fields to seek computer aids for accessing and processing natural language information.
6:111	The purpose of this conference was to explore whether developments in computational linguistics and artificial intelligence have something to contribute to this problem.
7:111	Two major directions of research are seen in the papers at this conference and in the field it represents.
8:111	Broadly speaking, one stream of research draws upon the methods of artificial intelligence and is concerned with general mechanisms of knowledge representation and reasoning, in this case as they apply mainly to clinical decision making.
9:111	Language processing as such is not much in evidence in these papers, but the need to draw upon knowledge in language form is the background and assumption of much of the work.
10:111	On the other hand, there is a growing body of research devoted to developing techniques for analyzing and processing the natural language form of medical information.
11:111	In this work, there is a trend toward representing the data in structures that take account of the semantic relations among terms in medical statements.
12:111	Though at this time the two areas of research are still quite distinct, a common ground may develop in the future when the AI projects look deeper into their data sources, and the data processors seek more powerful systems for representing information.
13:111	The 18 papers in the volume are organized into three sections: Methodological Background (7 papers), Medical Projects and Applications (7 papers), and Aspects of Hardware and Software (4 papers).
14:111	Cross-cutting these major divisions, the papers can be grouped by topic to indicate the range of present work in this area as represented by the Conference.
15:111	Five papers deal with trends and general methods.
16:111	These are: Werner Schneider (Uppsala University Data Center), The impact of CL and AI techniques on modelling in medicine; Erik Sandewall (Informatics Laboratory, Link6ping University, Link6ping, Sweden), Current trends in artificial intelligence; Carl W. Welin (Dept. of Linguistics, University of Stockholm), Semantic networks and natural language understanding; Uwe Wein (University of DUsseldorf and Uppsala University Data Center), On the representation of nonprocedural knowledge; R. Pfeifer et al.17:111	(University of Zurich and Uppsala University Data Center), PSYPAC: A formal system for the modelling of cognitive processes.
18:111	Three papers deal with the modelling of the process of clinical decision-making and the development of computer aids to the process.
19:111	These are: M. N. Epstein and E. 'B.
20:111	Kaplan (Section on Medical Information Science, University of California, San Francisco), Criteria for clinical decision making; E. H. Shortliffe (Dept. of Medicine, Massachusetts General Hospital, Boston), A rule-bosed approach to the generation of advice and explanations in clinical medicine; Stephen G. Pauker, M.D. and Peter Szolovits (Dept. of Medicine, Tufts University School of Medicine, and Laboratory for Computer Science, M.I.T.), Analyzing and simulating taking the history of the present illness: context formation.
21:111	Six papers deal with the representation and coding of the information in medical records.
22:111	These are: A. W. Pratt (Director, Division of Computer Research and Technology, N.I.H.), The use of categorized nomenclatures for representing medical statements; Ruby S. Okubo and Baldwin G. Lamson (Dept. of Data Processing, UCLA Hospital), The human interface in natural language retrieval; Anna-Lena Sagvall Hein (Uppsala University Data Center), An approach to the construction of a text-comprehension system for X-ray reports; J. van Egmond et al.23:111	(Dept. of Medical Information, University Hospital of Ghent), Systematization in the registration of medical diagnostic statements; M. de Heaulme and Ch.
24:111	Mery (INSERM U 88, and Service de Rhumatologie, H6pital Cochin, Paris), REMEDE: An artificial language for clinical documentation; K. Sauter et al.25:111	(4 affiliations, 2 from W. Germany and 2 from Swe44 American Journal of Computational Linguistics, Volume 6, Number 1, January-March 1980 Book Reviews Computational Linguistics in Medicine den), A data structure model for a medical information system.
26:111	Two papers deal with medical terminology on the word level: M. Wolff-Terroine (Dept. of Scientific Information, Institut Gustave-Roussy, Villejuif, France), Terminology and nomenclatures; F. Wingert (Institut fur Medizinische Informatik und Biomathematik, Univ. MUnster, West Germany), Morphosyn tactic analysis of medical compound word forms.
27:111	One paper deals with the design of a large retrieval system: N. Banerjee (Data and Information Systems Group, Applications Software, Siemens AG, Munich), CONDOR: Communication in natural language with dialogue oriented retrieval systems.
28:111	And one paper deals with a possible architecture of a LISP machine: Jack Urmi (Information Laboratory, Link6ping Univ.), Designing LISP oriented hardware.
29:111	Space permits a more detailed treatment of only the main groups of papers.
30:111	In the general methods set, Werner Schneider in the opening paper traces the background to the Conference in the work of a study group of the International Hospital Federation on the application of computer techniques in health care.
31:111	The 1975 report of the study group, which is summarized in the paper, led to the organization of this Conference in recognition of the importance of research directed toward the development of techniques for the formalization of medical knowledge.
32:111	Schneider describes and criticizes the early, and still dominant, attitude toward the use of computers in medicine: "The basic idea was that more data -especially so-called 'hard'-data, i.e. measured by natural science methodology -would produce more and better information and that more information would lead to better decisions.
33:111	As a consequence a large number of sometimes huge databanks have been established, mostly based on a rather random choice of which data should be collected and treated by more or less advanced statistical procedures".
34:111	In contrast, Schneider stresses the importance of developing models and formalizing techniques for the representation of medical knowledge.
35:111	In Erik Sandewall's characterization of Artificial Intelligence the dominant methodology of AI is "to implement limited-purpose systems in order to develop general methods and principles, and also in order to develop software tools".
36:111	Sandewall lists a number of general methods that he sees emerging in AI research (practical, low-key parsing of natural language; assimilation of natural language into a data base; representation of natural-language-based knowledge in a data base; deductive search; search in a problem space; scene analysis) and charts the major applicational areas in terms of their use of these methods.
37:111	Carl Welin's paper in this group is a straightforward summary of the major constructs of semantic networks.
38:111	Uwe Hein's paper proposes criteria for the design of a medium for the representation of knowledge and presents a 3-level system for this purpose, implemented in LISP.
39:111	The PSYPAC system (Pfeifer et al).
40:111	is intended as an instrument for building models of cognitive processes in human behavior.
41:111	What is proposed is a very general formalism for such descriptions.
42:111	To analyze the clinical decision process procedurally, to determine which parts of the process can (and perhaps can best) be performed by computer, to design such a system and engineer it for fail-safe operation and for physician acceptance, these are some of the questions faced in computational research on clinical decision making.
43:111	Epstein and Kaplan provide a modular model of the clinical decision process in which the major modules are Input, Question-Answering, Data Base, and Clinical Decision Making.
44:111	The latter module, which is based on papers in the medical literature, consists of successive iterations through the functional blocks of data acquisition, data analysis and plan formation with associated feedback between functional blocks.
45:111	A set of questions that have to be answered for each patient problem is stated, and technical issues, such as the need to limit the search space, are also raised.
46:111	In addition to the process model, a generalized knowledge representation model (based on prior work of Kulikowski and Weiss) is sketched.
47:111	The last half of the paper is devoted to the formulation and discussion of criteria for the process and knowledge-representation models, and the issues both medical and technical associated with each criterion.
48:111	Some of the authors' criteria include medical factors not commonly considered in AI models, e.g., utility-driven search strategy and modification of diagnosis therapy or therapy based on outcome information.
49:111	There is a brief informative discussion of statistical approaches, production rules, and network representation methods as they apply to the clinical decision problem.
50:111	The paper is a model of clear exposition and provides a comprehensive framework for thinking about the clinical decision process in precise procedural terms.
51:111	E.H. Shortliffe's MYCIN system for computerbased medical consultation is well know in the AI field and beyond.
52:111	The paper in this volume can serve as a brief introduction to the design criteria of MYCIN and also the design itself for those who have not read other papers or the book on the system.
53:111	The knowledge base in MYCIN is provided by physician-experts and is represented as production rules.
54:111	A major design criterion was to provide the system with the ability to explain decisions to the physician user.
55:111	American Journal of Computational Linguistics, Volume 6, Number 1, January-March 1980 45 Book Reviews Computational Linguistics in Medicine The approach to the clinical decision making problem taken by Pauker and Szolovits begins with an analysis of clinical hypothesis formation as it appears in the actual behavior of expert clinicians, with particular emphasis on the formation of the initial hypothesis in response to the history of the present illness.
56:111	"Before making any decisions about diagnostic tests or treatments, or indeed before asking more than the most cursory, automatic, descriptive questions, the physician must limit his domain of consideration to an appropriately narrow context".
57:111	The paper analyzes this process of context formation and describes a program, the Present Illness Program, written in CONNIVER and MACLISP, which simulates this process.
58:111	The domain of the program is a patient who presents with the chief complaint of edema.
59:111	A supervisory component acquires patient-specific data from the physician, checks it and stores it in a short term memory.
60:111	The short-term memory also contains "demon" programs, compiled from a knowledge base in long-term memory, whose task is to match stored patterns against the patient-specific findings.
61:111	The paper describes and evaluates the operation of the program.
62:111	In addition, the authors offer some general remarks of interest on computational linguistics in medicine.
63:111	At some point (and usually at many points) in the health care process and in clinical research, patient data must be consulted.
64:111	Where large numbers of patients are involved, the problems of organizing, coding and retrieving the data are crucial.
65:111	Since much of the data is initially in natural language form, the approaches and systems which have evolved for actual use are extremely interesting from a computational linguistics point of view.
66:111	These systems were not developed by computational linguistics, but in a number of respects they represent the most advanced applicational research in CL because of their commitment to provide large scale, real world natural language data processing.
67:111	One of the earliest systems to adopt a natural language approach to report-storage and retrieval (though it does not perform linguistic analysis of the input string) is the Natural Language Retrieval System of UCLA Hospital, which has been in operation since the mid 1960's (Okubo and Lamson).
68:111	Four data bases of impressive size are maintained (Surgical Pathology, Autopsy, Nuclear Medicine, Neuroradiology), a total in 1977 of 234,794 documents containing 4,252,385 words.
69:111	Retrieval requests are formulated in conventional Boolean query logic by a search specialist employing a large thesaurus.
70:111	The paper discusses factors which would influence the design of an interactive interface to replace the present human interaction of requester and search specialist in formulating the data base query.
71:111	Suggestions based on extensive experience with the system include providing the user the ability to browse through selected parts of the thesaurus with  updated frequency counts for terms and an easy way of referencing synonymous multiple word descriptors and cross-linkages that combine two or more synonym classes to represent another search entity.
72:111	Several papers in this group describe patient-data systems that provide a structuring of the natural language input strings in order to facilitate and sharpen retrieval.
73:111	These systems are particularly interesting for CL because they employ (or imply) a syntactic/semantic model of the input information.
74:111	Again, because of space limitations, only some of the systems can be discussed here, although all the papers in this group were substantive and worthwhile.
75:111	The system for automatic encoding of natural language pathology reports, developed at NIH from the mid 1960's and onward (Pratt), is based on look-up in a semantically structured phrase dictionary, the Systematized Nomenclature of Pathology (SNOP).
76:111	SNOP terms are divided into four highly structured lists: Topography (names of body sites -T-terms), Morphology (names of structural changes that occur in tissues as a result of disease -Mterms), Etiology (causative agents of disease -Eterms), Function (names of the physiological manifestations associated with disease -F-terms).
77:111	The automatic encoder identifies syntactic units, transforms certain morphologically related forms into the word form used in the SNOP vocabulary, looks up the units in the encoding dictionary (SNOP), and combines the resulting codes for the T, M, E, F terms into "TMEF statements" which compose the document surrogate.
78:111	Translated back into English the complete TMEF statement might be read as a prototype pathology report sentence: This body site T has undergone morphological change M due to the causative agent E resulting in physiological manifestations F. The TMEF statement thus constitutes a fixed formatted record which is efficient for high precision retrieval and at the same time constitutes a syntactic-semantic model of the pathology data in the original natural language pathology report.
79:111	It is interesting to compare the TMEF (SNOP) formalization of pathology diagnostic statements with the artificial language REMEDE (de Heaulme and Mery), which is in use for the (manual) encoding of clinical reports in Rheumatology, Endocrinology, Urology, and Vascular Surgery in Hopital Cochin, Pads.
80:111	As in SNOP, the point of view in REMEDE is that the nomenclature should reflect the semantic structure.
81:111	The systematized nomenclature can be employed in a formally defined syntax; REMEDE has, for example, such symbols as < ("of"), > ("due to"), * ("treated by") and = ("equal" -46 American Journal of Computational Linguistics, Volume 6, Number 1, January-March 1980 Book Reviews Linguistic Structures Processing used to introduce the results of a treatment or examination).
82:111	For vocabulary fields S for Symptoms, T for Topographies, E for Etiology, TR for Treatments and R for Results, the basic clinical sentence in this language is S<T>E*TR=R. Logical operators can be used, and further operators (e.g. , for "between" and "qualified by") have been defined, so that relatively complex clinical statements can be expressed.
83:111	Also a means for including time data is included.
84:111	This artificial language is sufficiently close to the syntactic form of simple, straightforward natural language sentences expressing the same information that it would seem feasible to automate the coding process directly from natural language input, although this possibility is not discussed in the paper.
85:111	Taken as a whole, this volume shows the existence of an area of interest between the processing of medical information and the analysis and processing of language.
86:111	Naomi Sager, New York University Linguistic Structures Processing Studies in Linguistics, Computational Linguistics, and Artificial Intelligence Antonio Zampolli, Editor North-Holland Publishing Co. , New York, 1977, 586 pp.
87:111	, $48.00, ISBN 0-444o85017-1.
88:111	This book is a collection of good articles.
89:111	It is not, however, a good collection of articles.
90:111	The only connection between them is that their authors all lectured at the International Summer School on Computational and Mathematical Linguistics at Pisa in 1974.
91:111	Each lecturer was asked to contribute a chapter to the book; some of the contributions were specifically written for it, while others are papers that the authors had published elsewhere.
92:111	Although each article is good by itself, the book as a whole lacks a common theme, a logical progression from one article to another, and a common level of background knowledge expected of the reader.
93:111	Three of the articles taken together make a good survey of computational linguistics: On natural language based computer systems by Stanley Petrick, Natural language understanding systems within the A1 paradigm by Yorick Wilks, and Five lectures on artificial intelligence by Terry Winograd.
94:111	Although the articles are three to five years old, the issues they discuss are still among the most active research topics today.
95:111	One strength is the variety of viewpoints on many of the same systems and issues.
96:111	One weakness is the skimpy treatment of semantic networks and related graphs: Winograd, for example, devotes two pages to them out of 123, while using eleven pages to reproduce the same SHRDLU dialog that he has been quoting for the past eight years.
97:111	One absurdity is the placement of these introductory articles near the end of the book because the chapters are listed alphabetically by their authors' last names.
98:111	Three tutorials on techniques are Synthesis of speech from unrestricted text by Jonathan Allen, Morphological and syntactic analysis by Martin Kay, and Lunar rocks in natural English by William Woods.
99:111	Allen's article is a short survey of the state of the art and current issues in speech synthesis.
100:111	Woods describes the various phases of the LUNAR system; he doesn't give enough detail to enable a beginner to build his own system, but he gives enough motivation and references to show someone where to go for further information.
101:111	Kay, however, buries the reader in detail, including 21 pages of traces from his parser.
102:111	Such detail is acceptable in a technical report, but an article of this sort should put more emphasis on the reasons for these techniques.
103:111	Some comparisons with the parsing methods of Petrick, Wilks, Winograd, and Woods would be especially useful since they are discussed elsewhere in the same book.
104:111	Two articles that relate computational questions to more general issues in linguistics and psychology are Scenes-and-frames semantics by Charles Fillmore and Cognition: The linguistic approach by David Hays.
105:111	Fillmore's article meanders for seventeen untitled sections: he presents a wealth of observations that a semantic theory must account for, but he never attempts to systematize his observations or present a tentative theory of his own.
106:111	Hays, on the other hand, has a short, tightly organized discussion of the psychological implications of cognitive networks.
107:111	But his article is so vague and devoid of examples that it is hardly more than an extended abstract.
108:111	Four other papers, 'The position of embedding transformations in a grammar" revisited by Emmon Bach, Focus and negation by Eva Haji~owi, Some observations concerning the differences between sentence and text by Ferenc Kiefer, and John is easy to please by Barbara Partee, treat theoretical points in linguistics that are also important computationally.
109:111	Yet none of the authors cite any computational or AI work in their bibliographies or make any attempt to relate their issues to computational methods.
110:111	These four articles illustrate a frequent failing of interdisciplinary conferences: the speakers talk past one another without ever reconciling their vocabularies or coming to grips with common issues.
111:111	(In their more recent work, Bach and Partee and their graduate students have been combining Montague

