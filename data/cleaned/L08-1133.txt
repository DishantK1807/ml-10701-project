<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>James Allen</author>
<author>Mark Core</author>
</authors>
<title>Draft of DAMSL: Dialog act markup in several layers</title>
<date>1997</date>
<note>Unpublished manuscript</note>
<contexts>
<context>designed to combine in one comprehensive annotation scheme the communicative functions of dialogue acts distinguished in Dynamic Interpretation Theory (DIT, (Bunt, 2000)), and many of those in DAMSL (Allen and Core, 1997) and in other annotation schemes. Important differences between the DIT++ and DAMSL schemes are the more clearly defined notion of dimension (Bunt, 2006) and the more elaborate and finegrained set of</context>
</contexts>
<marker>Allen, Core, 1997</marker>
<rawString>James Allen and Mark Core. 1997. Draft of DAMSL: Dialog act markup in several layers. Unpublished manuscript.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jens Allwood</author>
<author>Joakim Nivre</author>
<author>Elisabeth Ahls´en</author>
</authors>
<title>Manual for coding interaction management</title>
<date>1993</date>
<tech>Technical report</tech>
<institution>G¨oteborg University</institution>
<note>Project report: Semantik och talspr˚ak</note>
<marker>Allwood, Nivre, Ahls´en, 1993</marker>
<rawString>Jens Allwood, Joakim Nivre, and Elisabeth Ahls´en. 1993. Manual for coding interaction management. Technical report, G¨oteborg University. Project report: Semantik och talspr˚ak.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ron Artstein</author>
<author>Massimo Poesio</author>
</authors>
<title>Inter-Coder Agreement for Computational Linguistics. Computational Linguistics, To appear. See: http://cswww.essex.ac. uk/Research/nle/arrau/icagr.pdf 11To provide such an in-depth analysis is beyond the scope (and aim) of this paper; see also (Geertzen</title>
<date>2006</date>
<marker>Artstein, Poesio, 2006</marker>
<rawString>Ron Artstein and Massimo Poesio. Inter-Coder Agreement for Computational Linguistics. Computational Linguistics, To appear. See: http://cswww.essex.ac. uk/Research/nle/arrau/icagr.pdf 11To provide such an in-depth analysis is beyond the scope (and aim) of this paper; see also (Geertzen, 2006).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harry Bunt</author>
</authors>
<title>Dialogue pragmatics and context specification</title>
<date>2000</date>
<booktitle>Abduction, Belief and Context in Dialogue; Studies in Computational Pragmatics</booktitle>
<pages>81--150</pages>
<editor>In Harry Bunt and William Black, editors</editor>
<publisher>John Benjamins</publisher>
<location>Amsterdam, The Netherlands</location>
<contexts>
<context> Dialogue act tagset The DIT++ tagset was designed to combine in one comprehensive annotation scheme the communicative functions of dialogue acts distinguished in Dynamic Interpretation Theory (DIT, (Bunt, 2000)), and many of those in DAMSL (Allen and Core, 1997) and in other annotation schemes. Important differences between the DIT++ and DAMSL schemes are the more clearly defined notion of dimension (Bunt,</context>
</contexts>
<marker>Bunt, 2000</marker>
<rawString>Harry Bunt. 2000. Dialogue pragmatics and context specification. In Harry Bunt and William Black, editors, Abduction, Belief and Context in Dialogue; Studies in Computational Pragmatics, pages 81–150. John Benjamins, Amsterdam, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harry Bunt</author>
</authors>
<title>Dimensions in dialogue annotation</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>1444--1449</pages>
<contexts>
<context>complexities in the interaction, both human-machine and human-human dialogues are considered. The dialogues analysed are drawn from different corpora: OVIS (Strik et al., 1997), DIAMOND (Geertzen and Bunt, 2006), and a collection of Map Task dialogues (Caspers, 2000). The number of utterances that are drawn from each corpus are specified in Table 1. On average, naive annotators needed 23.2 seconds to annota</context>
<context> 2000)), and many of those in DAMSL (Allen and Core, 1997) and in other annotation schemes. Important differences between the DIT++ and DAMSL schemes are the more clearly defined notion of dimension (Bunt, 2006) and the more elaborate and finegrained set of functions for feedback and other aspects of dialogue control that is available in DIT, partly inspired by the work of Allwood (see: Allwood et al. (1993</context>
</contexts>
<marker>Bunt, 2006</marker>
<rawString>Harry Bunt. 2006. Dimensions in dialogue annotation. In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC 2006), pages 1444–1449.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean Carletta</author>
</authors>
<title>Assessing agreement on classification tasks: The kappa statistic</title>
<date>1996</date>
<journal>Computational Linguistics</journal>
<volume>22</volume>
<contexts>
<context>ured as a percentage of the cases on which the annotators agree (percentage agreement), but more often expected agreement is taken into account by using for instance the kappa statistic (Cohen, 1960; Carletta, 1996). Inter-annotator agreement expresses the degree to which annotations that have been made by multiple annotators can be relied upon. An issue in determining inter-annotator agreement is what kind of </context>
</contexts>
<marker>Carletta, 1996</marker>
<rawString>Jean Carletta. 1996. Assessing agreement on classification tasks: The kappa statistic. Computational Linguistics, 22(2):249–254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johanneke Caspers</author>
</authors>
<title>Pitch accents, boundary tones and turn-taking in Dutch map task dialogues</title>
<date>2000</date>
<booktitle>In Proceedings of the 6th International Conference on Spoken Language Processing (ICSLP</booktitle>
<volume>1</volume>
<pages>565--568</pages>
<contexts>
<context>nd human-human dialogues are considered. The dialogues analysed are drawn from different corpora: OVIS (Strik et al., 1997), DIAMOND (Geertzen and Bunt, 2006), and a collection of Map Task dialogues (Caspers, 2000). The number of utterances that are drawn from each corpus are specified in Table 1. On average, naive annotators needed 23.2 seconds to annotate each utterance where expert annotators needed 11.8 se</context>
</contexts>
<marker>Caspers, 2000</marker>
<rawString>Johanneke Caspers. 2000. Pitch accents, boundary tones and turn-taking in Dutch map task dialogues. In Proceedings of the 6th International Conference on Spoken Language Processing (ICSLP 2000), volume 1, pages 565–568.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Cohen</author>
</authors>
<title>A coefficient of agreement for nominal scales</title>
<date>1960</date>
<booktitle>Education and Psychological Measurement</booktitle>
<pages>20--37</pages>
<contexts>
<context>ometimes measured as a percentage of the cases on which the annotators agree (percentage agreement), but more often expected agreement is taken into account by using for instance the kappa statistic (Cohen, 1960; Carletta, 1996). Inter-annotator agreement expresses the degree to which annotations that have been made by multiple annotators can be relied upon. An issue in determining inter-annotator agreement </context>
</contexts>
<marker>Cohen, 1960</marker>
<rawString>Jacob Cohen. 1960. A coefficient of agreement for nominal scales. Education and Psychological Measurement, 20:37–46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeroen Geertzen</author>
<author>Harry Bunt</author>
</authors>
<title>Measuring annotator agreement in a complex hierarchical dialogue act annotation scheme</title>
<date>2006</date>
<booktitle>In Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue</booktitle>
<pages>126--133</pages>
<contexts>
<context>or different complexities in the interaction, both human-machine and human-human dialogues are considered. The dialogues analysed are drawn from different corpora: OVIS (Strik et al., 1997), DIAMOND (Geertzen and Bunt, 2006), and a collection of Map Task dialogues (Caspers, 2000). The number of utterances that are drawn from each corpus are specified in Table 1. On average, naive annotators needed 23.2 seconds to annota</context>
</contexts>
<marker>Geertzen, Bunt, 2006</marker>
<rawString>Jeroen Geertzen and Harry Bunt. 2006. Measuring annotator agreement in a complex hierarchical dialogue act annotation scheme. In Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue, pages 126–133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeroen Geertzen</author>
</authors>
<title>Inter-annotator agreement within DIT++ dimensions</title>
<date>2006</date>
<tech>Technical report</tech>
<institution>Tilburg University</institution>
<location>Tilburg, The Netherlands</location>
<marker>Geertzen, 2006</marker>
<rawString>Jeroen Geertzen. 2006. Inter-annotator agreement within DIT++ dimensions. Technical report, Tilburg University, Tilburg, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeroen Geertzen</author>
</authors>
<title>DitAT: a flexible tool to support web-based dialogue annotation</title>
<date>2007</date>
<booktitle>In Jeroen Geertzen, Elias Thijsse, Harry Bunt, and Amanda Schiffrin, editors, Proceedings of the Seventh International Workshop on Computational Semantics (IWCS</booktitle>
<pages>320--323</pages>
<contexts>
<context> the communicative functions in the scheme, and to a very brief, 1-page set of annotation guidelines4. The task was facilitated by the use of an annotation tool that had been built for this occasion (Geertzen, 2007). This tool allowed the subjects to assign each utterance one tag for each dimension without any further constraints. Both the naive and expert annotators could provide comments with each utterance f</context>
</contexts>
<marker>Geertzen, 2007</marker>
<rawString>Jeroen Geertzen. 2007. DitAT: a flexible tool to support web-based dialogue annotation. In Jeroen Geertzen, Elias Thijsse, Harry Bunt, and Amanda Schiffrin, editors, Proceedings of the Seventh International Workshop on Computational Semantics (IWCS), pages 320–323.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Klaus Krippendorff</author>
</authors>
<title>Content Analysis: An Introduction to its Methodology. Sage Publications</title>
<date>1980</date>
<location>Beverly Hills, CA, USA</location>
<contexts>
<context>session explaining the dialogue data, the dialogue act tagset, 1In the case of Cohen’s kappa, this is often taken to be between 0.8 and 1.0. For a general discussion, see e.g. (Landis and Koch, 1977; Krippendorff, 1980). and the use of an annotation tool. Expert annotators can be characterised as linguistically trained subjects that have experience in annotating dialogue and are thoroughly familiar with the tagset.</context>
</contexts>
<marker>Krippendorff, 1980</marker>
<rawString>Klaus Krippendorff. 1980. Content Analysis: An Introduction to its Methodology. Sage Publications, Beverly Hills, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Richard Landis</author>
<author>Gary G Koch</author>
</authors>
<title>A one-way components of variance model for categorical data</title>
<date>1977</date>
<journal>Biometrics</journal>
<pages>33--671</pages>
<contexts>
<context>ted in an introductory session explaining the dialogue data, the dialogue act tagset, 1In the case of Cohen’s kappa, this is often taken to be between 0.8 and 1.0. For a general discussion, see e.g. (Landis and Koch, 1977; Krippendorff, 1980). and the use of an annotation tool. Expert annotators can be characterised as linguistically trained subjects that have experience in annotating dialogue and are thoroughly famil</context>
</contexts>
<marker>Landis, Koch, 1977</marker>
<rawString>J. Richard Landis and Gary G. Koch. 1977. A one-way components of variance model for categorical data. Biometrics, 33:671–679.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amanda Schiffrin</author>
<author>Harry Bunt</author>
</authors>
<title>Defining a preliminary set of interoperable semantic descriptors</title>
<date>2007</date>
<booktitle>LIRICS Project Deliverable D4.2</booktitle>
<institution>Tilburg University</institution>
<marker>Schiffrin, Bunt, 2007</marker>
<rawString>Amanda Schiffrin and Harry Bunt. 2007. Defining a preliminary set of interoperable semantic descriptors. LIRICS Project Deliverable D4.2, Tilburg University.</rawString>
</citation>
</citationList>
</algorithm>

