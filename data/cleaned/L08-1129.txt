<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<date>2007</date>
<booktitle>Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007). Association for Computational Linguistics</booktitle>
<editor>Eneko Agirre, Llu´ıs M`arquez, and Richard Wicentowski, editors</editor>
<location>Prague, Czech Republic</location>
<marker>2007</marker>
<rawString>Eneko Agirre, Llu´ıs M`arquez, and Richard Wicentowski, editors. 2007. Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007). Association for Computational Linguistics, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Aline Villavicencio</author>
</authors>
<title>Extracting the unextractable: A case study on verbparticles</title>
<date>2002</date>
<booktitle>In Proceedings of the Sixth Conference on Computational Natural Language Learning (CoNLL</booktitle>
<pages>98--104</pages>
<location>Taipei, Taiwan</location>
<contexts>
<context>k has relied on i) manual scrutiny of the lists output from systems (Lin, 1999; Krenn and Evert, 2001; Blaheta and Johnson, 2001; Piao et al., 2003), ii) comparison with predefined lexical resources (Baldwin and Villavicencio, 2002; Fazly and Stevenson, 2006) and also iii) human judgments of compositionality (Bannard et al., 2003; McCarthy et al., 2003; Venkatapathy and Joshi, 2005). Most of these approaches for evaluation prod</context>
</contexts>
<marker>Baldwin, Villavicencio, 2002</marker>
<rawString>Timothy Baldwin and Aline Villavicencio. 2002. Extracting the unextractable: A case study on verbparticles. In Proceedings of the Sixth Conference on Computational Natural Language Learning (CoNLL 2002), pages 98–104, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Bannard</author>
<author>Timothy Baldwin</author>
<author>Alex Lascarides</author>
</authors>
<title>A statistical approach to the semantics of verb-particles</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL Workshop on</booktitle>
<pages>65--72</pages>
<contexts>
<context>and Johnson, 2001; Piao et al., 2003), ii) comparison with predefined lexical resources (Baldwin and Villavicencio, 2002; Fazly and Stevenson, 2006) and also iii) human judgments of compositionality (Bannard et al., 2003; McCarthy et al., 2003; Venkatapathy and Joshi, 2005). Most of these approaches for evaluation produce useful results by specifically targeting a particular sub-type of multiword expressions, such as</context>
<context>nt because the notion of multiword is not clear cut. Furthermore, non-compositionality is only one aspect of multiwords since there are nonproductive yet compositional phrases for example frying pan (Bannard et al., 2003). This article explores the use of substitution as a methodology for creating multiword data. To do this we examine the dataset created for the English Lexical Substitution task in SemEval (McCarthy </context>
</contexts>
<marker>Bannard, Baldwin, Lascarides, 2003</marker>
<rawString>Colin Bannard, Timothy Baldwin, and Alex Lascarides. 2003. A statistical approach to the semantics of verb-particles. In Proceedings of the ACL Workshop on multiword expressions: analysis, acquisition and treatment, pages 65–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Don Blaheta</author>
<author>Mark Johnson</author>
</authors>
<title>Unsupervised learning of multi-word verbs</title>
<date>2001</date>
<booktitle>In Proceedings of the ACL Workshop on Collocations</booktitle>
<pages>54--60</pages>
<location>Toulouse, France</location>
<contexts>
<context>wo, however an outstanding issue is evaluation methodology (Gr´egoire et al., 2008). Previous work has relied on i) manual scrutiny of the lists output from systems (Lin, 1999; Krenn and Evert, 2001; Blaheta and Johnson, 2001; Piao et al., 2003), ii) comparison with predefined lexical resources (Baldwin and Villavicencio, 2002; Fazly and Stevenson, 2006) and also iii) human judgments of compositionality (Bannard et al., 2</context>
</contexts>
<marker>Blaheta, Johnson, 2001</marker>
<rawString>Don Blaheta and Mark Johnson. 2001. Unsupervised learning of multi-word verbs. In Proceedings of the ACL Workshop on Collocations, pages 54–60, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Cotton</author>
<author>Phil Edmonds</author>
<author>Adam Kilgarriff</author>
<author>Martha Palmer</author>
</authors>
<date>2001</date>
<note>SENSEVAL-2. http://www.sle.sharp.co.uk/senseval2</note>
<contexts>
<context>ng (and therefore choice of synonym) in the right context. Multiwords have pretty much been ignored in the tasks from SemEval and its predecessors: SENSEVAL (Kilgarriff and others, 1998), SENSEVAL-2 (Cotton et al., 2001) and SENSEVAL-3 (Mihalcea and Edmonds, 2004). In the WSD tasks, multiwords have usually been manually marked up 1 and , in the event of more than one entry of the same multiword in the same dictionar</context>
</contexts>
<marker>Cotton, Edmonds, Kilgarriff, Palmer, 2001</marker>
<rawString>Scott Cotton, Phil Edmonds, Adam Kilgarriff, and Martha Palmer. 2001. SENSEVAL-2. http://www.sle.sharp.co.uk/senseval2/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Afsaneh Fazly</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Automatically constructing a lexicon of verb phrase idiomatic combinations</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL-2006</booktitle>
<pages>337--344</pages>
<location>Trento, Italy</location>
<contexts>
<context>y of the lists output from systems (Lin, 1999; Krenn and Evert, 2001; Blaheta and Johnson, 2001; Piao et al., 2003), ii) comparison with predefined lexical resources (Baldwin and Villavicencio, 2002; Fazly and Stevenson, 2006) and also iii) human judgments of compositionality (Bannard et al., 2003; McCarthy et al., 2003; Venkatapathy and Joshi, 2005). Most of these approaches for evaluation produce useful results by speci</context>
</contexts>
<marker>Fazly, Stevenson, 2006</marker>
<rawString>Afsaneh Fazly and Suzanne Stevenson. 2006. Automatically constructing a lexicon of verb phrase idiomatic combinations. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL-2006), pages 337–344, Trento, Italy, April.</rawString>
</citation>
<citation valid="true">
<date>2008</date>
<booktitle>Proceedings of the LREC 2008 Workshop: Towards a Shared Task for Multiword Expressions (MWE 08</booktitle>
<editor>Nicole Gr´egoire, Brigitte Krenn, and Stefan Evert, editors</editor>
<location>Marrakech, Morroco</location>
<marker>2008</marker>
<rawString>Nicole Gr´egoire, Brigitte Krenn, and Stefan Evert, editors. 2008. Proceedings of the LREC 2008 Workshop: Towards a Shared Task for Multiword Expressions (MWE 08), Marrakech, Morroco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graham Katz</author>
<author>Eugenie Giesbrecht</author>
</authors>
<title>Automatic identification of non-compositional multiword expressions using latent semantic analysis</title>
<date>2006</date>
<booktitle>In Proceedings of the ACL Workshop on multiword expressions: identifying and exploiting Underlying Properties</booktitle>
<pages>12--19</pages>
<contexts>
<context>ctions. The distinction between collocation and semantic is based on semantic transparency and might perhaps be done automatically by comparing semantics of constituent words with that of the phrase (Katz and Giesbrecht, 2006). The distinction between whether the substitute replaces the entire phrase, i.e. that between colloc1 and colloc2 would best be done in future by asking the annotators to stipulate this in a box. In</context>
</contexts>
<marker>Katz, Giesbrecht, 2006</marker>
<rawString>Graham Katz and Eugenie Giesbrecht. 2006. Automatic identification of non-compositional multiword expressions using latent semantic analysis. In Proceedings of the ACL Workshop on multiword expressions: identifying and exploiting Underlying Properties, pages 12–19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Kilgarriff</author>
</authors>
<title>SENSEVAL evaluating word sense disambiguation systems</title>
<date>1998</date>
<note>http: //www.itri.brighton.ac.uk/events/senseval/proceedings</note>
<marker>Kilgarriff, 1998</marker>
<rawString>Adam Kilgarriff et al. 1998. SENSEVAL evaluating word sense disambiguation systems. http: //www.itri.brighton.ac.uk/events/senseval/proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brigitte Krenn</author>
<author>Stefan Evert</author>
</authors>
<title>Can we do better than frequency? A case study on extracting PP-verb collocations</title>
<date>2001</date>
<booktitle>In Proceedings of the ACL Workshop on Collocations</booktitle>
<pages>39--46</pages>
<location>Toulouse, France</location>
<contexts>
<context>s or a mixture of the two, however an outstanding issue is evaluation methodology (Gr´egoire et al., 2008). Previous work has relied on i) manual scrutiny of the lists output from systems (Lin, 1999; Krenn and Evert, 2001; Blaheta and Johnson, 2001; Piao et al., 2003), ii) comparison with predefined lexical resources (Baldwin and Villavicencio, 2002; Fazly and Stevenson, 2006) and also iii) human judgments of composit</context>
</contexts>
<marker>Krenn, Evert, 2001</marker>
<rawString>Brigitte Krenn and Stefan Evert. 2001. Can we do better than frequency? A case study on extracting PP-verb collocations. In Proceedings of the ACL Workshop on Collocations, pages 39–46, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic identification of noncompositional phrases</title>
<date>1999</date>
<booktitle>In Proceedings of ACL-99</booktitle>
<pages>317--324</pages>
<institution>Univeristy of Maryland</institution>
<location>College Park, Maryland</location>
<contexts>
<context> linguistics or a mixture of the two, however an outstanding issue is evaluation methodology (Gr´egoire et al., 2008). Previous work has relied on i) manual scrutiny of the lists output from systems (Lin, 1999; Krenn and Evert, 2001; Blaheta and Johnson, 2001; Piao et al., 2003), ii) comparison with predefined lexical resources (Baldwin and Villavicencio, 2002; Fazly and Stevenson, 2006) and also iii) huma</context>
</contexts>
<marker>Lin, 1999</marker>
<rawString>Dekang Lin. 1999. Automatic identification of noncompositional phrases. In Proceedings of ACL-99, pages 317–324, Univeristy of Maryland, College Park, Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Roberto Navigli</author>
</authors>
<date>2007</date>
<contexts>
<context>al., 2003). This article explores the use of substitution as a methodology for creating multiword data. To do this we examine the dataset created for the English Lexical Substitution task in SemEval (McCarthy and Navigli, 2007) (hereafter referred to as LEXSUB). In this paper, we examine the subset of the LEXSUB dataset where annotators identified that the target was an integral part of a phrase. We wish to see how well su</context>
<context>nglish (Sharoff, 2006) for a set of 201 target words (nouns, verbs, adjectives and adverbs). Both manual and automatic methods were used for selecting both the words and selecting the sentences (see (McCarthy and Navigli, 2007) for further details). The 5 Annotators were all native English speakers living in the UK; 3 had a linguistics background whilst 2 did not. Each “item” is a target occurrence of a word in a sentence.</context>
<context>the MAJORITY&gt;=2 criterion resulted in 130 sentences with such a consensus which were entered in LEXSUBMW. Inter-annotator agreement figures and evaluation of WordNet as a baseline system is given in (McCarthy and Navigli, 2007). In the following section we provide a classification of all 282 TWPP responses and analyse the annotators’ TWPP responses in terms of this classification. 3. Analysis of the TWPP Responses Our clas</context>
</contexts>
<marker>McCarthy, Navigli, 2007</marker>
<rawString>Diana McCarthy and Roberto Navigli. 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bill Keller McCarthy</author>
<author>John Carroll</author>
</authors>
<title>SemEval-2007 task 10: English lexical substitution task</title>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007</booktitle>
<pages>48--53</pages>
<location>Prague, Czech Republic. Diana</location>
<marker>McCarthy, Carroll, </marker>
<rawString>SemEval-2007 task 10: English lexical substitution task. In Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 48–53, Prague, Czech Republic. Diana McCarthy, Bill Keller, and John Carroll.</rawString>
</citation>
<citation valid="true">
<title>Detecting a continuum of compositionality in phrasal verbs</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL</booktitle>
<volume>03</volume>
<pages>73--80</pages>
<marker>2003</marker>
<rawString>2003. Detecting a continuum of compositionality in phrasal verbs. In Proceedings of the ACL 03 Workshop: Multiword expressions: analysis, acquisition and treatment, pages 73–80.</rawString>
</citation>
<citation valid="true">
<date>2004</date>
<booktitle>Proceedings SENSEVAL-3 Second International Workshop on Evaluating Word Sense Disambiguation Systems</booktitle>
<editor>Rada Mihalcea and Phil Edmonds, editors</editor>
<location>Barcelona, Spain</location>
<marker>2004</marker>
<rawString>Rada Mihalcea and Phil Edmonds, editors. 2004. Proceedings SENSEVAL-3 Second International Workshop on Evaluating Word Sense Disambiguation Systems, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Piao</author>
<author>Paul Rayson</author>
<author>Dawn Archer</author>
<author>Andrew Wilson</author>
<author>Tony McEnery</author>
</authors>
<title>Extracting multiword expressions with a semantic tagger</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL Workshop on</booktitle>
<pages>49--56</pages>
<contexts>
<context>issue is evaluation methodology (Gr´egoire et al., 2008). Previous work has relied on i) manual scrutiny of the lists output from systems (Lin, 1999; Krenn and Evert, 2001; Blaheta and Johnson, 2001; Piao et al., 2003), ii) comparison with predefined lexical resources (Baldwin and Villavicencio, 2002; Fazly and Stevenson, 2006) and also iii) human judgments of compositionality (Bannard et al., 2003; McCarthy et al</context>
</contexts>
<marker>Piao, Rayson, Archer, Wilson, McEnery, 2003</marker>
<rawString>Scott Piao, Paul Rayson, Dawn Archer, Andrew Wilson, and Tony McEnery. 2003. Extracting multiword expressions with a semantic tagger. In Proceedings of the ACL Workshop on multiword expressions: analysis, acquisition and treatment, pages 49–56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Sag</author>
<author>Timothy Baldwin</author>
<author>Francis Bond</author>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
</authors>
<title>Multiword expressions: A pain in the neck for NLP</title>
<date>2002</date>
<booktitle>In Proceedings of the Third International Conference on Intelligent Text Processing and Computational Linguistics (CICLing 2002</booktitle>
<pages>1--15</pages>
<location>Mexico City, Mexico</location>
<marker>Sag, Baldwin, Bond, Copestake, Flickinger, 2002</marker>
<rawString>Ivan Sag, Timothy Baldwin, Francis Bond, Ann Copestake, and Dan Flickinger. 2002. Multiword expressions: A pain in the neck for NLP. In Proceedings of the Third International Conference on Intelligent Text Processing and Computational Linguistics (CICLing 2002), pages 1–15, Mexico City, Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Serge Sharoff</author>
</authors>
<title>Open-source corpora: Using the net to fish for linguistic data</title>
<date>2006</date>
<journal>International Journal of Corpus Linguistics</journal>
<volume>11</volume>
<contexts>
<context>tion Task The LEXSUB task was run as one of 19 semantic evaluation tasks at SemEval 2007 (Agirre et al., 2007). For the LEXSUB task, 2010 sentences were extracted from the Internet Corpus of English (Sharoff, 2006) for a set of 201 target words (nouns, verbs, adjectives and adverbs). Both manual and automatic methods were used for selecting both the words and selecting the sentences (see (McCarthy and Navigli,</context>
</contexts>
<marker>Sharoff, 2006</marker>
<rawString>Serge Sharoff. 2006. Open-source corpora: Using the net to fish for linguistic data. International Journal of Corpus Linguistics, 11(4):435–462.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sriram Venkatapathy</author>
<author>Aravind K Joshi</author>
</authors>
<title>Measuring the relative compositionality of verbnoun (v-n) collocations by integrating features</title>
<date>2005</date>
<booktitle>In Proceedings of the joint conference on Human Language Technology and Empirical methods in Natural Language Processing</booktitle>
<pages>899--906</pages>
<location>Vancouver, B.C., Canada</location>
<contexts>
<context>mparison with predefined lexical resources (Baldwin and Villavicencio, 2002; Fazly and Stevenson, 2006) and also iii) human judgments of compositionality (Bannard et al., 2003; McCarthy et al., 2003; Venkatapathy and Joshi, 2005). Most of these approaches for evaluation produce useful results by specifically targeting a particular sub-type of multiword expressions, such as verb-particles or verb-objects, where it is easier f</context>
</contexts>
<marker>Venkatapathy, Joshi, 2005</marker>
<rawString>Sriram Venkatapathy and Aravind K. Joshi. 2005. Measuring the relative compositionality of verbnoun (v-n) collocations by integrating features. In Proceedings of the joint conference on Human Language Technology and Empirical methods in Natural Language Processing, pages 899–906, Vancouver, B.C., Canada.</rawString>
</citation>
</citationList>
</algorithm>

