BusTUC A natural language bus route oracle Tore A m b l e Dept.
of computer and information science University of Trondheim Norway, N-7491 amble@idi, nt nu.
no Abstract The paper describes a natural language based expert system route advisor for the public bus transport in Trondheim, Norway.
The system is available on the Internet,and has been intstalled at the bus company's web server since the beginning of 1999.
The system is bilingual, relying on an internal language independent logic representation.
In between the question and the answer is a process of lexical analysis, syntax analysis, semantic analysis, pragmatic reasoning and database query processing.
One could argue that the information content could be solved by an interrogation, whereby the customer is asked to produce 4 items: s t a t i o n of departure, station of arrival, earliest departure timeand/or latest arrival time.
It Introduction A natural language interface to a computer database provides users with the capability of obtaining information stored in the database by querying the system in a natural language (NL).
With a natural language as a means of communication with a computer system, the users can make a question or a statement in the way they normally think about the information being discussed, freeing them from having to know how the computer stores or processes the information.
The present implementation represents a a major effort in bringing natural language into practical use.
A system is developed that can answer queries about bus routes, stated as natural language texts, and made public through the Internet World Wide Web is a myth that natural language is a better way of communication because it is "natural language".
The challenge is to prove by demonstration that an NL system can be made that will be preferred to the interrogative mode.
To do that, the system has to be correct, user friendly and almost complete within the actual domain.
P r e v i o u s Efforts, C H A T 8 0, P R A T 8 9 and HSQL Trondheim is a small city with a university and 140000 inhabitants.
Its central bus systems has 42 bus lines, serving 590 stations, with 1900 departures per day (in average).
T h a t gives approximately 60000 scheduled bus station passings per day, which is somehow represented in the route data base.
The starting point is to automate the function of a route information agent.
The following example of a system response is using an actual request over telephone to the local route information company: Hi, I live in Nidarvoll and tonight i must reach a train to Oslo at 6 oclock.
The system, called BusTUC is built upon the classical system CHAT-80 (Warren and Pereira, 1982).
CHAT-80 was a state of the art natural language system that was impressive on its own merits, but also established Prolog as a viable and competitive language for Artificial Intelligence in general.
The system was a brilliant masterpiece of software, efficient and sophisticated.
The natural language system was connected to a small query system for international geography.
The following query could be analysed and answered in a split second: Which country bordering the Mediterranean borders a country that is bordered by a country whose population exceeds the population of India?
(The answer 'Turkey' has become incorrect as time has passed.
The irony is that Geography was chosen as a domain without time.) and a typical answer would follow quickly: Bus number 54 passes by Nidarvoll skole at 1710 and arrives at Trondheim Railway Station at 1725.
The abi!ity to answer ridiculously long queries is of course not the main goal.
The main lesson is that complex sentences are analysed with a proper understanding without sacrificing efficiency.
Any superfificial pattern matching technique would prove futile sooner or later.
Making a N o r w e g i a n CHAT-80, PRAT-89 At the University of Trondheim (NTNU), two students made a Norwegian version of CHAT-80,called PRAT-89 (Teigen and Vetland, 1988),(Teigen and Vetland, 1989).
(Also, a similar Swedish project SNACK-85 was reported).
The dictionary was changed from English to Norwegian together with new rules for morphological analysis.
The change of grammar from English to Norwegian proved to be amazingly easy.
It showed that the langauges were more similar than one would believe, given that the languages are incomprehensible to each other's communities.
After changing the dictionary and graramar, the following Norwegian query about the same domain could be answered correctly in a few seconds.
Hvilke afrikanske land som hat en befolkning stoerre enn 3 millioner og mindre enn 50 millioner og er nord for Botswana og oest for Libya hat en hovedstad som hat en befolkning stoerre enn 100 tusen.
Coupling the s y s t e m to an SQL database.
After the remodelling, the system could answer queries in "Scandinavian" to an internal hospital database as well as CHAT-80 could answer Geography questions.
HSQL produced a Prolog-like code FOL (First Order Logic) for execution.
A mapping from FOL to the data base Schema was defined, and a translator from FOL to SQL was implemented.
The example Hvilke menn ligger i en kvinnes seng?
(Which men lie in a woman's bed?
) would be translated dryly into the SQL query: SELECT DISTINCT T3.name,Tl.sex,T2.reg_no,T3.sex, T4.reg_no,T4.bed_no,T5.hosp_no,T5.ward_no FROM PATIENT TI,OCCUPANCY T2,PATIENT T3, OCCUPANCY T4,WARD T5 WHERE (Tl.sex='f') AND (T2.reg_no=Tl.reg_no) AND (T3.sex='m') AND (T4.reg_no=T3.reg_no) AND (T4.bed_no=T2.bed_no) AND (T5.hosp_no=T4.hosp_no) AND (T5.ward_no=T4.ward_no) 2.3 T h e T h e U n d e r s t a n d i n g C o m p u t e r The HSQL was a valuable experience in the effort to make transportable natural language interfaces.
However, the underlying system CHAT-80 restricted the further development.
After the HSQL Project was finished, an internal reseach project TUC (the Understanding Computer) was initiated at NTNU to carry on the results from HSQL.
The project goals differed from those of HSQL in a number of ways, and would not be concerned with multimedia interfaces. On the other hand, portability and versatility were made central issues concerning the generality of the language and its applications.
The research goals could be summarised as to Give computers an operational understanding of natural language.
 Build intelligent systems with natural language capabilities.
 Study common sense reasoning in natural language.
A test criterion for the understanding capacity is that after a set of definitions in a Naturally Readable Logic, NRL, the system's answer to queries in NRL should conform to the answers of an idealised rational agent.
( A translation is beside the point o.f being a long query in Norwegian.) 2.2 HSQL H e l p S y s t e m for SQL A Nordic project HSQL (Help System for SQL) was accomplished in 1988-89 to make a joint Nordic effort interfaces to databases.
The HSQL project was led by the Swedish State Bureau (Statskontoret), with participants from Sweden, Denmark, Finland and Norway (Amble et al., 1990).
The aim of HSQL was to build a natural language interface to SQL databases for the Scandinavian languages Swedish, Danish and Norwegian.
These languages are very similar, and the Norwegian version of CHAT-80 was easily extended to the other Scandinavian languages.
Instead of Geography, a more typical application area was chosen to be a query system for hospital administration.
We decided to target an SQL database of a hospital administration which had been developed already.
The next step was then to change the domain of discourse from Geography to hospital administration, using the same knowledge representation techniques used in CHAT-80.
A semantic model of this domain was made, and then implemented in the CHAT-80 framework.
The modelling technique that proved adequate was to use an extended Entity Relationship (ER) model with a class (type) hierarchy, attributes belonging to each class, single inheritance of attributes and relationships.
Every man that lives loves Mary.
John is a man.
John lives.
Who loves Mary?
==> John 3 Anatomy of the bus route oracle The main components of the bus route information systems are:  A parser system, consisting of a dictionary, a lexical processor, a grammar and a parser.
 A knowledge base (KB), divided into a semantic KB and an application KB  A query processor, contalng a routing logic system, and a route data base.
The system is bilingual and contains a double set of dictionary, morphology and grammar.
Actually, it detects which language is most probable by counting the number of unknown words related to each language, and acts accordingly.
The grammars are surprisingly similar, but no effort is made to coalesce them.
The Norwegian grammar is slightly bigger than the English grammar, mostly because it is more elaborated but also because Norwegian allows a freer word order.
3.1 Features
of BusTUC For the Norwegian systems, the figures give an indication of the size of the domain: 420 nouns, 150 verbs, 165 adjectives, 60 prepositions, etc.
There are 1300 grammar rules ( 810 for English) although half of the rules are very low level.
The semantic net described below contains about 4000 entries.
A big name table of 3050 names in addition to the official station names, is required to capture the variety of naming.
A simple spell correction is a part of the system ( essentially 1 character errors).
The pragmatic reasoning is needed to translate the output from the parser to a route database query language . This is done by a production system called Pragma, which acts like an advanced rewriting system with 580 rules.
In addition, there is another rule base for actually generating the natural language answers (120 rules).
The system is mainly written in Prolog (Sicstus Prolog 3.7), with some Perl programs for the communication and CGI-scripts.
At the moment, there are about 35000 lines of programmed Prolog code (in addition to route tables which are also in Prolog).
Average response time is usually less than 2 seconds, but there are queries that demand up to 10 seconds.
The error rate for single, correct, complete and relevant questions is about 2 percent.
NRL is defined in a closed context.
Thus interfaces to other systems are in principle defined through simulating the environment as a dialogue partner.
TUC is a prototypical natural language processor for English written in Prolog.
It is designed to be a general purpose easily adaptable natural language processor.
It consists of a general grammar for a subset of English, a semantic knowledge base, and modules for interfaces to other interfaces like UNIX, SQL-databases and general textual information sources.
2.4 The
TABOR Project It so happened that a Universtity Project was starteded in 1996, called T A B O R ( " Speech based user interfaces and reasoning systems "), with the aim of building an automatic public transport route oracle, available over the public telephone.
At the onset of the project, the World Wide Web was fresh, and not as widespread as today, and the telephone was still regarded as the main source of information for the public.
Since then, the Internet became the dominant medium, and it is as likeley to find a computer with Internet connection, as to find a local busroute table.
( The consequtive wide spreading of cellular phones changed the picture in favour of the telephone, but that is another story).
It was decided that a text based information system should be built, regardless of the status of the speech rocgnition and speech synthesis effort, which proved to lag behind after a while.
The BusTUC system The resulting system BusTUC grew out as a natural application of TUC, and an English prototype could be built within a few months (Bratseth, 1997).
Since the summer 1996, the prototype was put onto the Internet, and been developed and tested more or less continually until today.
The most important extension was that the system was made bilingual (Norwegian and English) during the fall 1996.
In spring 1999, the BusTUC was finally adopted by the local bus company in Trondheim ( A/S Trondheim Trafikkselskap), which set up a server ( a 300 MHz PC with Linux).
Until today, over 150.000 questions have been answered, and BusTUC seems to stabilize and grow increasingly popular.
3.2 The
Parser S y s t e m The G r a m m a r S y s t e m The grammar is based on a simple grammar for statements, while questions and commands are derived by the use of movements.
The grammar 3 fiformalism which is called Consensical Grammar, (CONtext SENSitive CompositionAL Grammar) is an easy to use variant of Extraposition Grammar (Pereira and Warren, 1980), which is a generalisation of Definite Clause Grammars.
Compositional grammar means that the semantics of a a phrase is composed of the semantics of the subphrases; the basic constituents being a form of verb complements.
As for Extraposition grammars, a grammar is translated to Definite Clause Grammars, and executed as such.
A characteristic syntactic expression in Consensical G r a m m a r m a y define an incomplete construct in terms of a "difference " between complete constructs.
W h e n possible, the parser will use the subtracted part in stead of reading from the input, after a gap if necessary.
The effect is the same as for Exwhich is analysed as for which X is it true that the (X) person has a dog that barked? where the last line is analysed as a s t a t e m e n t . Movement is easily handled in Consensical Grammar without making special phrase rules for each kind of movement.
The following example shows how TUC manages a variety of analyses using movements: Max said Bill thought Joe believed Fido Barked.
Who said Bill thought Joe believed Fido barked?
Who did Max say thought Joe believed Fido barked? traposition grammars, but the this format is more intuitive.
Examples of grammar rules.
Who did Max say Bill thought believed Fido barked?
T h e parser The experiences with Consensical grammars are a bit mixed however.
The main problem is the parsing method itself, which is top down with backtracking.
Many principles that would prove elegant for small domains turned out to be too costly for larger domains, due to the wide variety of modes of expressions, incredible ambiguities and the sheer size of the covered language.
The disambiguation is a major problem for small grammars and large languages, and was solved by the following guidelines:  a semantic type checking was integrated into the parser, and would help to discard sematica/ly wrong parses from the start.
 a heuristics was followed that proved almost irreproachable: The longest possible phrase of a category that is semantically correct is in most cases the preferred interpretation.
 due to the perplexity of the language, some committed choices (cuts) had to be inserted into the grammar at strategic places.
As one could fear however, this implied that wrong choices being made at some point in the parsing could not be recovered by backtracking.
These problems also made it imperative to introduce a timeout on the parsing process of embarassing 10 seconds.
Although most sentences, would be parsed within a second, some legal sentences of moderate size actually need this time.
4 Example: Whose dog barked? is analysed as if the sentence had been Who has a dog t h a t barked? which is analysed as Which p e r s o n has a dog t h a t barked? fi3.3 The semantic knowledge base Adaptability means that the system does not need to be reprogrammed for each new application.
The design principle of TUC is that most of the changes are made in a tabular semantic knowledge base, while there is one general grammar and dictionary.
In general, the logic is generated automatically from the semantic knowledge base.
The nouns play a key role in the understanding part as they constitute the class or type hierarchy.
Nouns are defined in an a k i n d o f hierarchy.
The hierarchy is tree-structured with single inheritance.
The top level also constitute the top level ontology of TUC's world.
In fact, a type check of the compliances of verbs, nouns adjectives and prepositions is not only necessary for the semantic processing but is essential for the syntax analysis for the disambiguation as well.
In TUC, the legal combinations are carefully assembled in the semantic network, which then serves a dual purpose.
These semantic definitions are necessary to allow for instance the following sentences The dog saw a man with a telescope.
The man saw a dog with a telescope.
gives exactly the same code.
% Type of question % tuc is a program % A is a real bus % B isa saturday % Nidar is a place % D is an event Y.
C was known at D Y.
E is an event in C action(go,E), Y.
the action of E is Go actor(A,E), Y.
the actor of E is A srel(to,place,nidar,E),Y.
E is to nidar srel(on,time,B,E), y, E is on the saturday B to be treated differently because with telescope m a y modify the noun man but not the noun dog, while with telescope modifies the verb see, restricted to person.
The event parameter plays an important role in the semantics.
It is used for various purposes.
The most salient role is to identify a subset of time and space in which an action or event occured.
Both the actual time and space coordinates are connected to the actions through the event parameter.
Pragmatic reasoning The TQL is translated to a route database query language (BusLOG) which is actually a Prolog program.
This is done by a production system called Pragma, which acts like an advanced rewriting system with 580 rules.
In addition, there is another rule base for actually generating the natural language answers (120 rules).
4 Conclusions
The TUC approach has as its goal to automate the creation of new natural language interfaces for a well defined subset of the language and with a minimum of explicit programming.
The implemented system has proved its worth, and is interesting if for no other reason.
There is also an increasing interest from other bus companies and route information companies alike to get a similar system for their customers.
Further work remains to make the parser really efficient, and much work remains to make the language coverage complete within reasonable limits.
It is an open question whether the system of this kind will be a preferred way of offering information to the public.
If it is, it is a fair amount of work to make it a portable system that can be implemented elsewhere, also connecting various travelling agencies.
If not, it will remain a curiosity.
But anyway, a system like this will be a contribution to the development of intelligent systems.
3.4 The
Query Processor Event Calculus The semantics of the phrases are built up by a kind of verb complements, where the event play a central role.
The text is translated from Natural language into a form called TQL (Temporal Query Language/ TUC Query Language) which is a first order event calculus expression, a self contained expression containing the literal meaning of an utterance.
A formalism TQL that was defined, inspired by the Event Calculus by Kowalski and Sergot (Kowalski and Sergot, 1986).
The TQL expressions consist of predicates, functions, constants and variables.
The textual words of nouns and verbs are translated to generic predicates using the selected interpretation.
The following question Do you know whether the bus goes to Nidar on Saturday ? would give the TQL expression below.
BusTUC A natural language bus route oracle Tore A m b l e Dept.
of computer and information science University of Trondheim Norway, N-7491 amble@idi, nt nu.
no Abstract The paper describes a natural language based expert system route advisor for the public bus transport in Trondheim, Norway.
The system is available on the Internet,and has been intstalled at the bus company's web server since the beginning of 1999.
The system is bilingual, relying on an internal language independent logic representation.
In between the question and the answer is a process of lexical analysis, syntax analysis, semantic analysis, pragmatic reasoning and database query processing.
One could argue that the information content could be solved by an interrogation, whereby the customer is asked to produce 4 items: s t a t i o n of departure, station of arrival, earliest departure timeand/or latest arrival time.
It Introduction A natural language interface to a computer database provides users with the capability of obtaining information stored in the database by querying the system in a natural language (NL).
With a natural language as a means of communication with a computer system, the users can make a question or a statement in the way they normally think about the information being discussed, freeing them from having to know how the computer stores or processes the information.
The present implementation represents a a major effort in bringing natural language into practical use.
A system is developed that can answer queries about bus routes, stated as natural language texts, and made public through the Internet World Wide Web is a myth that natural language is a better way of communication because it is "natural language".
The challenge is to prove by demonstration that an NL system can be made that will be preferred to the interrogative mode.
To do that, the system has to be correct, user friendly and almost complete within the actual domain.
P r e v i o u s Efforts, C H A T 8 0, P R A T 8 9 and HSQL Trondheim is a small city with a university and 140000 inhabitants.
Its central bus systems has 42 bus lines, serving 590 stations, with 1900 departures per day (in average).
T h a t gives approximately 60000 scheduled bus station passings per day, which is somehow represented in the route data base.
The starting point is to automate the function of a route information agent.
The following example of a system response is using an actual request over telephone to the local route information company: Hi, I live in Nidarvoll and tonight i must reach a train to Oslo at 6 oclock.
The system, called BusTUC is built upon the classical system CHAT-80 (Warren and Pereira, 1982).
CHAT-80 was a state of the art natural language system that was impressive on its own merits, but also established Prolog as a viable and competitive language for Artificial Intelligence in general.
The system was a brilliant masterpiece of software, efficient and sophisticated.
The natural language system was connected to a small query system for international geography.
The following query could be analysed and answered in a split second: Which country bordering the Mediterranean borders a country that is bordered by a country whose population exceeds the population of India?
(The answer 'Turkey' has become incorrect as time has passed.
The irony is that Geography was chosen as a domain without time.) and a typical answer would follow quickly: Bus number 54 passes by Nidarvoll skole at 1710 and arrives at Trondheim Railway Station at 1725.
The abi!ity to answer ridiculously long queries is of course not the main goal.
The main lesson is that complex sentences are analysed with a proper understanding without sacrificing efficiency.
Any superfificial pattern matching technique would prove futile sooner or later.
Making a N o r w e g i a n CHAT-80, PRAT-89 At the University of Trondheim (NTNU), two students made a Norwegian version of CHAT-80,called PRAT-89 (Teigen and Vetland, 1988),(Teigen and Vetland, 1989).
(Also, a similar Swedish project SNACK-85 was reported).
The dictionary was changed from English to Norwegian together with new rules for morphological analysis.
The change of grammar from English to Norwegian proved to be amazingly easy.
It showed that the langauges were more similar than one would believe, given that the languages are incomprehensible to each other's communities.
After changing the dictionary and graramar, the following Norwegian query about the same domain could be answered correctly in a few seconds.
Hvilke afrikanske land som hat en befolkning stoerre enn 3 millioner og mindre enn 50 millioner og er nord for Botswana og oest for Libya hat en hovedstad som hat en befolkning stoerre enn 100 tusen.
Coupling the s y s t e m to an SQL database.
After the remodelling, the system could answer queries in "Scandinavian" to an internal hospital database as well as CHAT-80 could answer Geography questions.
HSQL produced a Prolog-like code FOL (First Order Logic) for execution.
A mapping from FOL to the data base Schema was defined, and a translator from FOL to SQL was implemented.
The example Hvilke menn ligger i en kvinnes seng?
(Which men lie in a woman's bed?
) would be translated dryly into the SQL query: SELECT DISTINCT T3.name,Tl.sex,T2.reg_no,T3.sex, T4.reg_no,T4.bed_no,T5.hosp_no,T5.ward_no FROM PATIENT TI,OCCUPANCY T2,PATIENT T3, OCCUPANCY T4,WARD T5 WHERE (Tl.sex='f') AND (T2.reg_no=Tl.reg_no) AND (T3.sex='m') AND (T4.reg_no=T3.reg_no) AND (T4.bed_no=T2.bed_no) AND (T5.hosp_no=T4.hosp_no) AND (T5.ward_no=T4.ward_no) 2.3 T h e T h e U n d e r s t a n d i n g C o m p u t e r The HSQL was a valuable experience in the effort to make transportable natural language interfaces.
However, the underlying system CHAT-80 restricted the further development.
After the HSQL Project was finished, an internal reseach project TUC (the Understanding Computer) was initiated at NTNU to carry on the results from HSQL.
The project goals differed from those of HSQL in a number of ways, and would not be concerned with multimedia interfaces. On the other hand, portability and versatility were made central issues concerning the generality of the language and its applications.
The research goals could be summarised as to Give computers an operational understanding of natural language.
 Build intelligent systems with natural language capabilities.
 Study common sense reasoning in natural language.
A test criterion for the understanding capacity is that after a set of definitions in a Naturally Readable Logic, NRL, the system's answer to queries in NRL should conform to the answers of an idealised rational agent.
( A translation is beside the point o.f being a long query in Norwegian.) 2.2 HSQL H e l p S y s t e m for SQL A Nordic project HSQL (Help System for SQL) was accomplished in 1988-89 to make a joint Nordic effort interfaces to databases.
The HSQL project was led by the Swedish State Bureau (Statskontoret), with participants from Sweden, Denmark, Finland and Norway (Amble et al., 1990).
The aim of HSQL was to build a natural language interface to SQL databases for the Scandinavian languages Swedish, Danish and Norwegian.
These languages are very similar, and the Norwegian version of CHAT-80 was easily extended to the other Scandinavian languages.
Instead of Geography, a more typical application area was chosen to be a query system for hospital administration.
We decided to target an SQL database of a hospital administration which had been developed already.
The next step was then to change the domain of discourse from Geography to hospital administration, using the same knowledge representation techniques used in CHAT-80.
A semantic model of this domain was made, and then implemented in the CHAT-80 framework.
The modelling technique that proved adequate was to use an extended Entity Relationship (ER) model with a class (type) hierarchy, attributes belonging to each class, single inheritance of attributes and relationships.
Every man that lives loves Mary.
John is a man.
John lives.
Who loves Mary?
==> John 3 Anatomy of the bus route oracle The main components of the bus route information systems are:  A parser system, consisting of a dictionary, a lexical processor, a grammar and a parser.
 A knowledge base (KB), divided into a semantic KB and an application KB  A query processor, contalng a routing logic system, and a route data base.
The system is bilingual and contains a double set of dictionary, morphology and grammar.
Actually, it detects which language is most probable by counting the number of unknown words related to each language, and acts accordingly.
The grammars are surprisingly similar, but no effort is made to coalesce them.
The Norwegian grammar is slightly bigger than the English grammar, mostly because it is more elaborated but also because Norwegian allows a freer word order.
3.1 Features
of BusTUC For the Norwegian systems, the figures give an indication of the size of the domain: 420 nouns, 150 verbs, 165 adjectives, 60 prepositions, etc.
There are 1300 grammar rules ( 810 for English) although half of the rules are very low level.
The semantic net described below contains about 4000 entries.
A big name table of 3050 names in addition to the official station names, is required to capture the variety of naming.
A simple spell correction is a part of the system ( essentially 1 character errors).
The pragmatic reasoning is needed to translate the output from the parser to a route database query language . This is done by a production system called Pragma, which acts like an advanced rewriting system with 580 rules.
In addition, there is another rule base for actually generating the natural language answers (120 rules).
The system is mainly written in Prolog (Sicstus Prolog 3.7), with some Perl programs for the communication and CGI-scripts.
At the moment, there are about 35000 lines of programmed Prolog code (in addition to route tables which are also in Prolog).
Average response time is usually less than 2 seconds, but there are queries that demand up to 10 seconds.
The error rate for single, correct, complete and relevant questions is about 2 percent.
NRL is defined in a closed context.
Thus interfaces to other systems are in principle defined through simulating the environment as a dialogue partner.
TUC is a prototypical natural language processor for English written in Prolog.
It is designed to be a general purpose easily adaptable natural language processor.
It consists of a general grammar for a subset of English, a semantic knowledge base, and modules for interfaces to other interfaces like UNIX, SQL-databases and general textual information sources.
2.4 The
TABOR Project It so happened that a Universtity Project was starteded in 1996, called T A B O R ( " Speech based user interfaces and reasoning systems "), with the aim of building an automatic public transport route oracle, available over the public telephone.
At the onset of the project, the World Wide Web was fresh, and not as widespread as today, and the telephone was still regarded as the main source of information for the public.
Since then, the Internet became the dominant medium, and it is as likeley to find a computer with Internet connection, as to find a local busroute table.
( The consequtive wide spreading of cellular phones changed the picture in favour of the telephone, but that is another story).
It was decided that a text based information system should be built, regardless of the status of the speech rocgnition and speech synthesis effort, which proved to lag behind after a while.
The BusTUC system The resulting system BusTUC grew out as a natural application of TUC, and an English prototype could be built within a few months (Bratseth, 1997).
Since the summer 1996, the prototype was put onto the Internet, and been developed and tested more or less continually until today.
The most important extension was that the system was made bilingual (Norwegian and English) during the fall 1996.
In spring 1999, the BusTUC was finally adopted by the local bus company in Trondheim ( A/S Trondheim Trafikkselskap), which set up a server ( a 300 MHz PC with Linux).
Until today, over 150.000 questions have been answered, and BusTUC seems to stabilize and grow increasingly popular.
3.2 The
Parser S y s t e m The G r a m m a r S y s t e m The grammar is based on a simple grammar for statements, while questions and commands are derived by the use of movements.
The grammar 3 fiformalism which is called Consensical Grammar, (CONtext SENSitive CompositionAL Grammar) is an easy to use variant of Extraposition Grammar (Pereira and Warren, 1980), which is a generalisation of Definite Clause Grammars.
Compositional grammar means that the semantics of a a phrase is composed of the semantics of the subphrases; the basic constituents being a form of verb complements.
As for Extraposition grammars, a grammar is translated to Definite Clause Grammars, and executed as such.
A characteristic syntactic expression in Consensical G r a m m a r m a y define an incomplete construct in terms of a "difference " between complete constructs.
W h e n possible, the parser will use the subtracted part in stead of reading from the input, after a gap if necessary.
The effect is the same as for Exwhich is analysed as for which X is it true that the (X) person has a dog that barked? where the last line is analysed as a s t a t e m e n t . Movement is easily handled in Consensical Grammar without making special phrase rules for each kind of movement.
The following example shows how TUC manages a variety of analyses using movements: Max said Bill thought Joe believed Fido Barked.
Who said Bill thought Joe believed Fido barked?
Who did Max say thought Joe believed Fido barked? traposition grammars, but the this format is more intuitive.
Examples of grammar rules.
Who did Max say Bill thought believed Fido barked?
T h e parser The experiences with Consensical grammars are a bit mixed however.
The main problem is the parsing method itself, which is top down with backtracking.
Many principles that would prove elegant for small domains turned out to be too costly for larger domains, due to the wide variety of modes of expressions, incredible ambiguities and the sheer size of the covered language.
The disambiguation is a major problem for small grammars and large languages, and was solved by the following guidelines:  a semantic type checking was integrated into the parser, and would help to discard sematica/ly wrong parses from the start.
 a heuristics was followed that proved almost irreproachable: The longest possible phrase of a category that is semantically correct is in most cases the preferred interpretation.
 due to the perplexity of the language, some committed choices (cuts) had to be inserted into the grammar at strategic places.
As one could fear however, this implied that wrong choices being made at some point in the parsing could not be recovered by backtracking.
These problems also made it imperative to introduce a timeout on the parsing process of embarassing 10 seconds.
Although most sentences, would be parsed within a second, some legal sentences of moderate size actually need this time.
4 Example: Whose dog barked? is analysed as if the sentence had been Who has a dog t h a t barked? which is analysed as Which p e r s o n has a dog t h a t barked? fi3.3 The semantic knowledge base Adaptability means that the system does not need to be reprogrammed for each new application.
The design principle of TUC is that most of the changes are made in a tabular semantic knowledge base, while there is one general grammar and dictionary.
In general, the logic is generated automatically from the semantic knowledge base.
The nouns play a key role in the understanding part as they constitute the class or type hierarchy.
Nouns are defined in an a k i n d o f hierarchy.
The hierarchy is tree-structured with single inheritance.
The top level also constitute the top level ontology of TUC's world.
In fact, a type check of the compliances of verbs, nouns adjectives and prepositions is not only necessary for the semantic processing but is essential for the syntax analysis for the disambiguation as well.
In TUC, the legal combinations are carefully assembled in the semantic network, which then serves a dual purpose.
These semantic definitions are necessary to allow for instance the following sentences The dog saw a man with a telescope.
The man saw a dog with a telescope.
gives exactly the same code.
% Type of question % tuc is a program % A is a real bus % B isa saturday % Nidar is a place % D is an event Y.
C was known at D Y.
E is an event in C action(go,E), Y.
the action of E is Go actor(A,E), Y.
the actor of E is A srel(to,place,nidar,E),Y.
E is to nidar srel(on,time,B,E), y, E is on the saturday B to be treated differently because with telescope m a y modify the noun man but not the noun dog, while with telescope modifies the verb see, restricted to person.
The event parameter plays an important role in the semantics.
It is used for various purposes.
The most salient role is to identify a subset of time and space in which an action or event occured.
Both the actual time and space coordinates are connected to the actions through the event parameter.
Pragmatic reasoning The TQL is translated to a route database query language (BusLOG) which is actually a Prolog program.
This is done by a production system called Pragma, which acts like an advanced rewriting system with 580 rules.
In addition, there is another rule base for actually generating the natural language answers (120 rules).
4 Conclusions
The TUC approach has as its goal to automate the creation of new natural language interfaces for a well defined subset of the language and with a minimum of explicit programming.
The implemented system has proved its worth, and is interesting if for no other reason.
There is also an increasing interest from other bus companies and route information companies alike to get a similar system for their customers.
Further work remains to make the parser really efficient, and much work remains to make the language coverage complete within reasonable limits.
It is an open question whether the system of this kind will be a preferred way of offering information to the public.
If it is, it is a fair amount of work to make it a portable system that can be implemented elsewhere, also connecting various travelling agencies.
If not, it will remain a curiosity.
But anyway, a system like this will be a contribution to the development of intelligent systems.
3.4 The
Query Processor Event Calculus The semantics of the phrases are built up by a kind of verb complements, where the event play a central role.
The text is translated from Natural language into a form called TQL (Temporal Query Language/ TUC Query Language) which is a first order event calculus expression, a self contained expression containing the literal meaning of an utterance.
A formalism TQL that was defined, inspired by the Event Calculus by Kowalski and Sergot (Kowalski and Sergot, 1986).
The TQL expressions consist of predicates, functions, constants and variables.
The textual words of nouns and verbs are translated to generic predicates using the selected interpretation.
The following question Do you know whether the bus goes to Nidar on Saturday ? would give the TQL expression below.
Machine Translation of Very Close Languages Jan HAJI(~ Computer Science Dept.
Johns Hopkins University 3400 N.
Charles St., Baltimore, MD 21218, USA hajic@cs.jhu.edu Jan HRIC KTI MFF UK Malostransk6 nfim.25 Praha 1, Czech Republic, 11800 hric@barbora.m ff.cuni.cz Vladislav KUBON OFAL MFF UK Malostransk6 mim.25 Praha 1, Czech Republic, 11800 vk@ufal.mff.cuni.cz Abstract Using examples of the transfer-based MT system between Czech and Russian RUSLAN and the word-for-word MT system with morphological disambiguation between Czech and Slovak (~ESILKO we argue that for really close languages it is possible to obtain better translation quality by means of simpler methods.
The problem of translation to a group of typologically similar languages using a pivot language is also discussed here.
demonstrate that this assumption holds only for really very closely related languages.
1. Czech-to-Russian MT system RUSLAN 1.1 History Introduction Although the field of machine translation has a very long history, the number of really successful systems is not very impressive.
Most of the funds invested into the development of various MT systems have been wasted and have not stimulated a development of techniques which would allow to translate at least technical texts from a certain limited domain.
There were, of course, exceptions, which demonstrated that under certain conditions it is possible to develop a system which will save money and efforts invested into human translation.
The main reason why the field of MT has not met the expectations of sci-fi literature, but also the expectations of scientific community, is the complexity of the task itself.
A successful automatic translation system requires an application of techniques from several areas of computational linguistics (morphology, syntax, semantics, discourse analysis etc).
as a necessary, but not a sufficient condition.
The general opinion is that it is easier to create an MT system for a pair of related languages.
In our contribution we would like to The first attempt to verify the hypothesis that related languages are easier to translate started in mid 80s at Charles University in Prague.
The project was called RUSLAN and aimed at the translation of documentation in the domain of operating systems for mainframe computers.
It was developed in cooperation with the Research Institute of Mathematical Machines in Prague.
At that time in former COMECON countries it was obligatory to translate any kind of documentation to such systems into Russian.
The work on the Czech-to-Russian MT system RUSLAN (cf.
Oliva (1989)) started in 1985.
It was terminated in 1990 (with COMECON gone) for the lack of funding.
System description The system was rule-based, implemented in Colmerauer's Q-systems.
It contained a fullfledged morphological and syntactic analysis of Czech, a transfer and a syntactic and morphological generation of Russian.
There was almost no transfer at the beginning of the project due to the assumption that both languages are similar to the extent that does not require any transfer phase at all.
This assumption turned to be wrong and several phenomena were covered by the transfer in the later stage of the project (for example the translation of the Czech verb "b~" [to be] into one of the three possible Russian equivalents: empty form, the form "byt6" in future fitense and the verb "javljat6sja"; or the translation of verbal negation).
At the time when the work was terminated in 1990, the system had a main translation dictionary of about 8000 words, accompanied by so called transducing dictionary covering another 2000 words.
The transducing dictionary was based on the original idea described in Kirschner (1987).
It aimed at the exploitation o f the fact that technical terms are based (in a majority o f European languages) on Greek or Latin stems, adopted according to the particular derivational rules o f the given languages.
This fact allows for the "translation" o f technical terms by means of a direct transcription of productive endings and a slight (regular) adjustment o f the spelling of the stem.
For example, the English words localization and discrimination can be transcribed into Czech as "lokalizace" and "diskriminace" with a productive ending -ation being transcribed to -ace.
It was generally assumed that for the pair Czech/Russian the transducing dictionary would be able to profit from a substantially greater number o f productive rules.
This hypothesis proved to be wrong, too (see B6mov~, Kubofi (1990)).
The set o f productive endings for both pairs (English/Czech, as developed for an earlier MT system from English to Czech, and Czech/Russian) was very similar.
The evaluation o f results o f RUSLAN showed that roughly 40% o f input sentences were translated correctly, about 40% with minor errors correctable by a human post-editor and about 20% of the input required substantial editing or re-translation.
There were two main factors that caused a deterioration of the translation.
The first factor was the incompleteness o f the main dictionary of the system.
Even though the system contained a set of so-called fail-soft rules, whose task was to handle such situations, an unknown word typically caused a failure o f the module o f syntactic analysis, because the dictionary entries contained besides the translation equivalents and morphological information very important syntactic information.
The second factor was the module of syntactic analysis o f Czech.
There were several reasons of parsing failures.
Apart from the common inability of most rule-based formal grammars to cover a particular natural language to the finest detail o f its syntax there were other problems.
One o f them was the existence of non-projective constructions, which are quite common in Czech even in relatively short sentences.
Even though they account only for 1.7/'o of syntactic dependencies, every third Czech sentence contains at least one, and in a news corpus, we discovered as much as 15 non-projective dependencies; see also Haji6 et al.(1998). An example o f a non-projective construction is "Soubor se nepodafilo otev~it".
[lit.: File Refl.
was_not._possible to_open.
It was not possible to open the file].
The formalism used for the implementation (Q-systems) was not meant to handle non-projective constructions.
Another source of trouble was the use o f so-called semantic features.
These features were based on lexical semantics o f individual words.
Their main task was to support a semantically plausible analysis and to block the implausible ones.
It turned out that the question o f implausible combinations o f semantic features is also more complex than it was supposed to be.
The practical outcome o f the use o f semantic features was a higher ratio of parsing failures semantic features often blocked a plausible analysis.
For example, human lexicographers assigned the verb 'to run' a semantic feature stating that only a noun with semantic features o f a human or other living being may be assigned the role o f subject of this verb.
The input text was however full o f sentences with 'programs' or 'systems' running etc.
It was o f course very easy to correct the semantic feature in the dictionary, but the problem was that there were far too many corrections required.
On the other hand, the fact that both languages allow a high degree o f word-order freedom accounted for a certain simplification o f the translation process.
The grammar relied on the fact that there are only minor word-order differences between Czech and Russian.
1.3 Lessons
learned from RUSLAN We have learned several lessons regarding the MT o f closely related languages:  The transfer-based approach provides a similar quality o f translation both for closely related and typologically different languages  Two main bottlenecks o f full-fledged transfer-based systems are: ficomplexity o f the syntactic dictionary relative unreliability o f the syntactic analysis of the source language Even a relatively simple component (transducing dictionary) was equally complex for English-to-Czech and Czech-to-Russian translation Limited text domains do not exist in real life, it is necessary to work with a high coverage dictionary at least for the source language.
2. Translation and localization 2.1 A pivot language Localization o f products and their documentation is a great problem for any company, which wants to strengthen its position on foreign language market, especially for companies producing various kinds o f software.
The amounts o f texts being localized are huge and the localization costs are huge as well.
It is quite clear that the localization from one source language to several target languages, which are typologically similar, but different from the source language, is a waste of money and effort.
It is o f course much easier to translate texts from Czech to Polish or from Russian to Bulgarian than from English or German to any o f these languages.
There are several reasons, why localization and translation is not being performed through some pivot language, representing a certain group o f closely related languages.
Apart from political reasons the translation through a pivot language has several drawbacks.
The most important one is the problem o f the loss o f translation quality.
Each translation may to a certain extent shift the meaning o f the translated text and thus each subsequent translation provides results more and more different from the original.
The second most important reason is the lack of translators from the pivot to the target language, while this is usually no problem for the translation from the source directly to the target language.
MAHT (Machine-aided human translation) systems.
We have chosen the TRADOS Translator's Workbench as a representative system o f a class o f these products, which can be characterized as an example-based translation tools.
IBM's Translation Manager and other products also belong to this class.
Such systems uses so-called translation memory, which contains pairs o f previously translated sentences from a source to a target language.
When a human translator starts translating a new sentence, the system tries to match the source with sentences already stored in the translation memory.
If it is successful, it suggests the translation and the human translator decides whether to use it, to modify it or to reject it.
The segmentation o f a translation memory is a key feature for our system.
The translation memory may be exported into a text file and thus allows easy manipulation with its content.
Let us suppose that we have at our disposal two translation memories one human made for the source/pivot language pair and the other created by an MT system for the pivot/target language pair.
The substitution o f segments o f a pivot language by the segments of a target language is then only a routine procedure.
The human translator translating from the source language to the target language then gets a translation memory for the required pair (source/target).
The system o f penalties applied in TRADOS Translator's Workbench (or a similar system) guarantees that if there is already a human-made translation present, then it gets higher priority than the translation obtained as a result o f the automatic MT.
This system solves both problems mentioned above the human translators from the pivot to the target language are not needed at all and the machinemade translation memory serves only as a resource supporting the direct human translation from the source to the target language.
3. M a c h i n e translation o f (very) closely related Slavic languages In the group o f Slavic languages, there are more closely related languages than Czech and Russian.
Apart from the pair o f Serbian and Croatian languages, which are almost identical and were Translation memory is the key The main goal of this paper is to suggest how to overcome these obstacles by means o f a combination of an MT system with commercial ficonsidered one language just a few years ago, the most closely related languages in this group are Czech and Slovak.
This fact has led us to an experiment with automatic translation between Czech and Slovak.
It was clear that application of a similar method to that one used in the system RUSLAN would lead to similar results.
Due to the closeness of both languages we have decided to apply a simpler method.
Our new system, (~ESILKO, aims at a maximal exploitation of the similarity of both languages.
The system uses the method of direct word-for-word translation, justified by the similarity of syntactic constructions of both languages.
Although the system is currently being tested on texts from the domain of documentation to corporate information systems, it is not limited to any specific domain.
Its primary task is, however, to provide support for translation and localization of various technical texts.
3.1 System
( ~ E S i L K O and its governing noun.
An alternative way to the solution of this problem was the application of a stochastically based morphological disambiguator (morphological tagger) for Czech whose success rate is close to 92/'0.
Our system therefore consists of the following modules: 1.
Import of the input from so-called 'empty' translation memory 2.
Morphological analysis of Czech 3.
Morphological disambiguation 4.
Domain-related bilingual glossaries (incl.
singleand multiword terminology) 5.
General bilingual dictionary 6.
Morphological synthesis of Slovak 7.
Export of the output to the original translation memory Letus now look in a more detail at the individual modules of the system: ad 1.
The input text is extracted out of a translation memory previously exported into an ASCII file.
The exported translation memory (of TRADOS) has a SGML-Iike notation with a relatively simple structure (cf.
the following example): Example 1.
A sample of the exported translation memory <RTF Preamble>...</RTF Preamble> <TrU> <CrD>23051999 <CrU>VK <Seg L=CS_01>Pomoci v~kazu ad-hoc m65ete rychle a jednoduge vytv~i~et regerge.
<Seg L=SK_01 >n/a </TrU> Our system uses only the segments marked by <Seg L=CS_01>, which contain one source language sentence each, and <Seg L=SK_01>, which is empty and which will later contain the same sentence translated into the target language The greatest problem of the word-for-word translation approach (for languages with very similar syntax and word order, but different morphological system) is the problem of morphological ambiguity of individual word forms.
The type of ambiguity is slightly different in languages with a rich inflection (majority of Slavic languages) and in languages which do not have such a wide variety of forms derived from a single lemma.
For example, in Czech there are only rare cases of part-of-speech ambiguities (st~t [to stay/the state], zena [woman/chasing] or tri [three/rub(imperative)]), much more frequent is the ambiguity of gender, number and case (for example, the form of the adjective jam[ [spring] is 27-times ambiguous).
The main problem is that even though several Slavic languages have the same property as Czech, the ambiguity is not preserved.
It is distributed in a different manner and the "form-for-form" translation is not applicable.
Without the analysis of at least nominal groups it is often very difficult to solve this problem, because for example the actual morphemic categories of adjectives are in Czech distinguishable only on the basis of gender, number and case agreement between an adjective by CESiLKO.
ad 2.
The morphological analysis of Czech is based on the morphological dictionary developed by Jan Haji6 and Hana Skoumalov~i in 1988-99 (for latest description, see Haji~ (1998)).
The dictionary contains over 700 000 dictionary entries and its typical coverage varies between fi99% (novels) to 95% (technical texts).
The morphological analysis uses the system of positional tags with 15 positions (each morphological.category, such as Part-of-speech, Number, Gender, Case, etc.
has a fixed, singlesymbol place in the tag).
Example 2 tags assigned to the word-form "pomoci" (help/by means of) pomoci: NFP2 ......
A ....
]NFS7 ......
A ....
I R--2 ........... where : N noun; R preposition F feminine gender S singular, P plural 7, 2 case (7 instrumental, 2 genitive) A affirmative (non negative) ad 3.
The module of morphological disambiguation is a key to the success o f the translation.
It gets an average number of 3.58 tags per token (word form in text) as an input.
The tagging system is purely statistical, and it uses a log-linear model of probability distribution see Haji~, Hladkfi (1998).
The learning is based on a manually tagged corpus of Czech texts (mostly from the general newspaper domain).
The system learns contextual rules (features) automatically and also automatically determines feature weights.
The average accuracy o f tagging is between 91 and 93% and remains the same even for technical texts (if we disregard the unknown names and foreign-language terms that are not ambiguous anyway).
The lemmatization immediately follows tagging; it chooses the first lemma with a possible tag corresponding to the tag selected.
Despite this simple lemmatization method, and also thanks to the fact that Czech words are rarely ambiguous in their Part-of-speech, it works with an accuracy exceeding 98%.
The multiple-word terms are sequences of lemmas (not word forms).
This structure has several advantages, among others it allows to minimize the size of the dictionary and also, due to the simplicity of the structure, it allows modifications of the glossaries by the linguistically naive user.
The necessary morphological information is introduced into the domain-related glossary in an off-line preprocessing stage, which does not require user intervention.
This makes a big difference when compared to the RUSLAN Czech-to-Russian MT system, when each multiword dictionary entry cost about 30 minutes of linguistic expert's time on average.
ad 5.
The main bilingual dictionary contains data necessary for the translation o f both lemmas and tags.
The translation of tags (from the Czech into the Slovak morphological system) is necessary, because due to the morphological differences both systems use close, but slightly different tagsets.
Currently the system handles the 1:1 translation of tags (and 2:2, 3:3, etc.).
Different ratio of translation is very rare between Czech and Siovak, but nevertheless an advanced system of dictionary items is under construction (for the translation 1:2, 2:1 etc.).
It is quite interesting that the lexically homonymous words often preserve their homonymy even after the translation, so no special treatment of homonyms is deemed necessary.
ad 6.
The morphological synthesis of Slovak is based on a monolingual dictionary of SIovak, developed by J.Hric (1991-99), covering more than ]00,000 dictionary entries.
The coverage of the dictionary is not as high as o f the Czech one, but it is still growing.
It aims at a similar coverage of Slovak as we enjoy for Czech.
ad 7.
The export o f the output of the system (~ESILKO into the translation memory (of TRADOS Translator's Workbench) amounts mainly to cleaning of all irrelevant SGML markers.
The whole resulting Slovak sentence is inserted into the appropriate location in the original translation memory file.
The following example also shows that the marker <CrU> contains an information that the target language sentence was created by an M T system.
ad 4.
The domain-related bilingual glossaries contain pairs of individual words and pairs of multiple-word terms.
The glossaries are organized into a hierarchy specified by the user; typically, the glossaries for the most specific domain are applied first.
There is one general matching rule for all levels of glossaries the longest match wins.
languages, namely for Czech-to-Polish translation.
Although these languages are not so similar as Czech and Slovak, we hope that an addition of a simple partial noun phrase parsing might provide results with the quality comparable to the fullfledged syntactic analysis based system RUSLAN (this is of course true also for the Czechoto-Slovak translation).
The first results of Czech-to Polish translation are quite encouraging in this respect, even though we could not perform as rigorous testing as we did for Slovak.
Acknowledgements 3.2 Evaluation of results The problem how to evaluate results of automatic translation is very difficult.
For the evaluation of our system we have exploited the close connection between our system and the TRADOS Translator's Workbench.
The method is simple the human translator receives the translation memory created by our system and translates the text using this memory.
The translator is free to make any changes to the text proposed by the translation memory.
The target text created by a human translator is then compared with the text created by the mechanical application of translation memory to the source text.
TRADOS then evaluates the percentage of matching in the same manner as it normally evaluates the percentage of matching of source text with sentences in translation memory.
Our system achieved about 90% match (as defined by the TRADOS match module) with the results of human translation, based on a relatively large (more than 10,000 words) test sample.
This project was supported by the grant GAt~R 405/96/K214 and partially by the grant GA(~R 201/99/0236 and project of the Ministry of Education No.
VS96151. The accuracy of the translation achieved by our system justifies the hypothesis that word-forword translation might be a solution for MT of really closely related languages.
The remaining problems to be solved are problems with the oneto many or many-to-many translation, where the lack of information in glossaries and dictionaries sometimes causes an unnecessary translation error.
A u t o m a t i c construction of parallel English-Chinese corpus for cross-language information retrieval Jiang Chen and Jian-Yun Nie D ~ p a r t e m e n t d ' I n f o r m a t i q u e et R e c h e r c h e O p ~ r a t i o n n e l l e Universit~ de M o n t r e a l C.P. 6128, succursale C E N T R E V I L L E M o n t r e a l (Quebec), C a n a d a H 3 C 3 J 7 {chen, nie} @iro.
umontreal, ca Abstract A major obstacle to the construction of a probabilistic translation model is the lack of large parallel corpora.
In this paper we first describe a parallel text mining system that finds parallel texts automatically on the Web.
The generated Chinese-English parallel corpus is used to train a probabilistic translation model which translates queries for Chinese-English cross-language information retrieval (CLIR).
We will discuss some problems in translation model training and show the preliminary C U R results.
1 Introduction
2 Parallel Text Mining Algorithm The PTMiner system is an intelligent Web agent that is designed to search for large amounts of parallel text on the Web.
The mining algorithm is largely language independent.
It can thus be adapted to other language pairs with only minor modifications.
Taking advantage of Web search engines as much as possible, PTMiner implements the following steps (illustrated in Fig.
1): 1 Search for candidate sites Using existing Web search engines, search for the candidate sites that may contain parallel pages; 2 File name fetching For each candidate site, fetch the URLs of Web pages that are indexed by the search engines; 3 Host crawling Starting from the URLs collected in the previous step, search through each candidate site separately for more URLs; 4 Pair scan From the obtained URLs of each site, scan for possible parallel pairs; 5 Download and verifying Download the parallel pages, determine file size, language, and character set of each page, and filter out non-parallel pairs.
2.1 Search
for candidate Sites We take advantage of the huge number of Web sites indexed by existing search engines in determining candidate sites.
This is done by submitting some particular requests to the search engines.
The requests are determined according to the following observations.
In the sites where parallel text exists, there are normally some pages in one language containing links to the parallel version in the other language.
These are usually indicated by those links' anchor texts 1.
For example, on some English page there may be a link to its Chinese version with the anchor text "Chinese Version" or "in Chinese".
1An a n c h o r t e x t is a piece of text on a W e b page which, w h e n clicked on, will take you to a n o t h e r linked page.
To be helpful, it u s u a l l y c o n t a i n s t h e key i n f o r m a t i o n about the linked page.
Parallel texts have been used in a number of studies in computational linguistics.
Brown et al.(1993) defined a series of probabilistic translation models for MT purposes.
While people may question the effectiveness of using these models for a full-blown MT system, the models are certainly valuable for developing translation assistance tools.
For example, we can use such a translation model to help complete target text being drafted by a human translator (Langlais et al., 2000).
Another utilization is in cross-language information retrieval (CLIR) where queries have to be translated from one language to another language in which the documents are written.
In CLIR, the quality requirement for translation is relatively low.
For example, the syntactic aspect is irrelevant.
Even if the translated word is not a true translation but is strongly related to the original query, it is still helpful.
Therefore, CLIR is a suitable application for such a translation model.
However, a major obstacle to this approach is the lack of parallel corpora for model training.
Only a few such corpora exist, including the Hansard English-French corpus and the HKUST EnglishChinese corpus (Wu, 1994).
In this paper, we will describe a method which automatically searches for parallel texts on the Web.
We will discuss the text mining algorithm we adopted, some issues in translation model training using the generated parallel corpus, and finally the translation model's performance in CLIR.
21 Figure 1: The workflow of the mining process.
T h e same phenomenon can be observed on Chinese pages.
Chances are t h a t a site with parallel texts will contain such links in some of its documents.
This fact is used as the criterion in searching for candidate sites.
Therefore, to determine possible sites for EnglishChinese parallel texts, we can request an English document containing the following anchor: Host Crawling anchor : "english version H ["in english",...].
Similar requests are sent for Chinese documents.
From the two sets of pages obtained by the above queries we extract two sets of Web sites.
T h e union of these two sets constitutes then the candidate sites.
T h a t is to say, a site is a candidate site when it is found to have either an English page linking to its Chinese version or a Chinese page linking to its English version.
A host crawler is slightly different from a Web crawler.
Web crawlers go through innumerable pages and hosts on the Web.
A host crawler is a Web crawler t h a t crawls through documents on a given host only.
A breadth-first crawling algorithm is applied in P T M i n e r as host crawler.
The principle is t h a t when a link to an unexplored document on the same site is found in a document, it is added to a list t h a t will be explored later.
In this way, most file names from the candidate sites are obtained.
Pair Scan File N a m e Fetching We now assume t h a t a pair of parallel texts exists on the same site.
To search for parallel pairs on a site, P T M i n e r first has to obtain all (or at least p a r t of) the H T M L file names on the site.
From these names pairs are scanned.
It is possible to use a Web crawler to explore the candidate sites completely.
However, we can take advantage of the search engines again to accelerate the process.
As the first step, we submit the following query to the search engines: to fetch the Web pages t h a t they indexed from this site.
If we only require a small a m o u n t of parallel texts, this result m a y be sufficient.
For our purpose, however, we need to explore the sites more thoroughly using a host crawler.
Therefore, we continue our search for files with a host crawler which uses the documents found by the search engines as the starting point.
After collecting file names for each candidate site, the next task is to determine the parallel pairs.
Again, we t r y to use some heuristic rules to guess which files m a y be parallel texts before downloading them.
The rules are based on external features of the documents.
By external feature, we mean those features which m a y be known without analyzing the contents of the file, such as its URL, size, and date.
This is in contrast with the internal features, such as language, character set, and H T M L structure, which cannot be known until we have downloaded the page and analyzed its contents.
The heuristic criterion comes from the following observation: We observe t h a t parallel text pairs usually have similar n a m e patterns.
The difference between the names of two parailel pages usually lies in a segment which indicates the language.
For example, "file-ch.html" (in Chinese) vs.
"file-en.html" (in English).
T h e difference m a y also appear in the path, such as ".../chinese/.../file.html" vs.
".../english/.../file.html'. T h e n a m e patterns described above are commonly used by webmasters to help organize their sites.
Hence, we can suppose t h a t a pair of pages with this kind of p a t t e r n are probably parallel texts.
First, we establish four lists for English prefixes, English suffixes, Chinese prefixes and Chinese suffixes.
For example: E n g l i s h P r e f i x = {e, en, e_, en_, e -, e n -, ...}.
For each file in one language, if a segment in its name corresponds to one of the language affixes, several new names are generated by changing the segment to the possible corresponding affixes of the other language.
If a generated name corresponds to an existing file, then the file is considered as a candidate parallel document of the original file.
Filtering Next, we further examine the contents of the paired files to determine if they are really parallel according to various external and internal features.
This may further improve the pairing precision.
The following methods have been implemented in our system.
usually have similar H T M L structures.
However, we also noticed that parallel texts may have quite different HTML structures.
One of the reasons is that the two files may be created using two HTML editors.
For example, one may be used for English and another for Chinese, depending on the language handling capability of the editors.
Therefore, caution is required when measuring structure difference numerically.
Parallel text alignment is still an experimental area.
Measuring the confidence values of an alignment is even more complicated.
For example, the alignment algorithm we used in the training of the statistical translation model produces acceptable alignment results but it does not provide a confidence value that we can "confidently" use as an evaluation criterion.
So, for the moment this criterion is not used in candidate pair evaluation.
Generated Corpus and Translation Model Training In this section, we describe the results of our parallel text mining and translation model training.
3 Text
Length Parallel files often have similar file lengths.
One simple way to filter out incorrect pairs is to compare the lengths of the two files.
The only problem is to set a reasonable threshold that will not discard too many good pairs, i.e. balance recall and precision.
The usual difference ratio depends on the language pairs we are dealing with.
For example, ChineseEnglish parallel texts usually have a larger difference ratio than English-French parallel texts.
The filtering threshold had to be determined empirically, from the actual observations.
For Chinese-English, a difference up to 50% is tolerated.
2.5.2 L
a n g u a g e a n d Character Set It is also obvious that the two files of a pair have to be in the two languages of interest.
By automatically identifying language and character set, we can filter out the pairs that do not satisfy this basic criterion.
Some Web pages explicitly indicate the language and the character set.
More often such information is omitted by authors.
We need some language identification tool for this task.
SILC is a language and encoding identification system developed by the RALI laboratory at the University of Montreal.
It employs a probabilistic model estimated on tri-grams.
Using these models, the system is able to determine the most probable language and encoding of a text (Isabelle et al., 1997).
2.5.3 H
T M L Structure and Alignment In the STRAND system (Resnik, 1998), the candidate pairs are evaluated by aligning them according to their H T M L structures and computing confidence values.
Pairs are assumed to be wrong if they have too many mismatching markups or low confidence values.
Comparing H T M L structures seems to be a sound way to evaluate candidate pairs since parallel pairs 23 The Corpus Using the above approach for Chinese-English, 185 candidate sites were searched from the domain hk.
We limited the mining domain to hk because Hong Kong is a bilingual English-Chinese city where high quality parallel Web sites exist.
Because of the small number of candidate sites, the host crawler was used to thoroughly explore each site.
The resulting corpus contains 14820 pairs of texts including 117.2Mb Chinese texts and 136.5Mb English texts.
The entire mining process lasted about a week.
Using length comparison and language identification, we refined the precision of the corpus to about 90%.
The precision is estimated by examining 367 randomly picked pairs.
Statistical Translation Model Many approaches in computational linguistics try to extract translation knowledge from previous translation examples.
Most work of this kind establishes probabilistic models from parallel corpora.
Based on one of the statistical models proposed by Brown et al.(1993), the basic principle of our translation model is the following: given a corpus of aligned sentences, if two words often co-occur in the source and target sentences, there is a good likelihood that they are translations of each other.
In the simplest case (model 1), the model learns the probability, p(tls), of having a word t in the translation of a sentence containing a word s.
For an input sentence, the model then calculates a sequence of words that are most probable to appear in its translation.
Using a similar statistical model, Wu (1995) extracted a largescale English-Chinese lexicon from the H K U S T corFigure 2: An alignment example using pure length-based method.
pus which is built manually.
In our case, the probabilistic translation model will be used for CLIR.
The requirement on our translation model may be less demanding: it is not absolutely necessary that a word t with high p(tls ) always be a true translation of s.
It is still useful if t is strongly related to s.
For example, although "railway" is not a true translation of "train" (in French), it is highly useful to include "railway" in the translation of a query on "train".
This is one of the reasons why we think a less controlled parallel corpus can be used to train a translation model for CLIR.
very noisy.
Aligning English-Chinese parallel texts is already very difficult because of the great differences in the syntactic structures and writing systems of the two languages.
A number of alignment techniques have been proposed, varying from statistical methods (Brown et al., 1991; Gale and Church, 1991) to lexical methods (Kay and RSscheisen, 1993; Chen, 1993).
The method we adopted is t h a t of Simard et al.(1992). Because it considers both length similarity and cognateness as alignment criteria, the method is more robust and better able to deal with noise than pure length-based methods.
Cognates are identical sequences of characters in corresponding words in two languages.
T h e y are commonly found in English and French.
In the case of English-Chinese alignment, where there are no cognates shared by the two languages, only the H T M L markup in both texts are taken as cognates.
Because the H T M L structures of parallel pages are normally similar, the markup was found to be helpful for alignment.
To illustrate how markup can help with the alignment, we align the same pair with both the pure length-based method of Gale & Church (Fig.
2), and the method of Simard et al.(Fig. 3).
First of all, we observe from the figures that the two texts are Parallel Text Alignment Before the mined documents can be aligned into parallel sentences, the raw texts have to undergo a series of some preprocessing, which, to some extent, is language dependent.
For example, the major operations on the Chinese-English corpus include encoding scheme transformation (for Chinese), sentence level segmentation, parallel text alignment, Chinese word segmentation (Nie et al., 1999) and English expression extraction.
The parallel Web pages we collected from various sites are not all of the same quality.
Some are highly parallel and easy to align while others can be Figure 3: An alignment example considering cognates.
divided into sentences.
The sentences are marked by <s i d = " x x x x " > and < / s > . Note that we determine sentences not only by periods, but also by means of H T M L markup.
We further notice that it is difficult to align sentences 0002.
The sentence in the Chinese page is much longer than its counterpart in the English page because some additional information (font) is added.
The length-based method thus tends to take sentence 0002, 0003, and 0004 in the English page as the translation of sentence 0002 in the Chinese page (Fig.
2), which is wrong.
This in turn provocated the three following incorrect alignments.
As we can see in Fig.
3, the cognate method did not make the same mistake because of the noise in sentence 0002.
Despite their large length difference, the two 0002 sentences are still aligned as a 1-1 pair, because the sentences in the following 4 alignments (0003 0003; 0004 0004, 0005; 0005 0006; 0006 0007) have rather similar H T M L markups and are taken by the program to be the most likely alignments.
Beside HTML markups, other criteria may also be incorporated.
For example, it would be helpful to consider strong correspondence between certain English and Chinese words, as in (Wu, 1994).
We hope to implement such correspondences in our future research.
3.4 Lexicon
Evaluation To evaluate the precision of the English-Chinese translation model trained on the Web corpus, we examined two sample lexicons of 200 words, one in each direction.
The 200 words for each lexicon were randomly selected from the training source.
We examined the most probable translation for each word.
The Chinese-English lexicon was found to have a precision of 77%.
The English-Chinese lexicon has a higher precision of 81.5%.
Part of the lexicons are shown in Fig.
4, where t / f indicates whether a translation is true or false.
These precisions seem to be reasonably high.
They are quite comparable to that obtained by Wu (1994) using a manual Chinese-English parallel corpus.
Effect of Stopwords We also found that stop-lists have significant effect on the translation model.
Stop-list is a set of the most frequent words that we remove from the train3.5 English word t/f access adaptation add adopt agent agree airline amendment, appliance apply attendance auditor -,average base_on t t t t t t t t t t t/f t t t t t t t t t t Translation office protection report prepare local follow standard adult inadequate part financial visit bill vehicle saving Figure 4: Part of the evaluation lexicons.
Figure 5: Effect of stop lists in C-E translation.
ing source.
Because these words exist in most alignments, the statistical model cannot derive correct translations for them.
More importantly, their existence greatly affects the accuracy of other translations.
They can be taken as translations for many words.
A priori, it would seem that both the English and Chinese stop-lists should be applied to eliminate the noise caused by them.
Interestingly, from our observation and analysis we concluded that for better precision, only the stop-list of the target language should be applied in the model training.
We first explain why the stop-list of the target language has to be applied.
On the left side of Fig.
5, if the Chinese word C exists in the same alignments with the English word E more than any other Chinese words, C will be the most probable translation for E.
Because of their frequent appearance, some Chinese stopwords may have more chances to be in the same alignments with E.
The probability of the translation E --+ C is then reduced (maybe even less than those of the incorrect ones).
This is the reason why many English words are translated to " ~ ' (of) by the translation model trained without using the Chinese stop-list.
We also found that it is not necessary to remove the stopwords of the source language.
In fact, as illustrated on the right side of Fig.
5, the existence of the English stopwords has two effects on the probability of the translation E -~ C: 1 They may often be found together with the Chinese word C.
Owing to the Expectation Maximization algorithm, the probability of E -~ C may therefore be reduced.
2 On
the other hand, there is a greater likelihood that English stopwords will be found together with the most frequent Chinese words.
Here, we use the term "Chinese frequent words" instead of "Chinese stopwords" because even if a stop-list is applied, there may still remain some common words that have the same effect as the stopwords.
The coexistence of English and Chinese frequent words reduces the probability that the Chinese frequent words are the translations of E, and thus raise the probability of E -+ C.
The second effect was found to be more significant than the first, since the model trained without the English stopwords has better precision than the model trained with the English stopwords.
For the correct translations given by both models, the model Mono-Lingual IR Translation Model Dictionary trained without considering the English stopwords gives higher probabilities.
4 English-Chinese CLIR Results Our final goal was to test the performance of the translation models trained on the Web parallel corpora in CLIR.
We conducted CLIR experiments using the Smart IR system.
4.1 Results
The English test corpus (for C-E CLIR) was the AP corpus used in TREC6 and TREC7.
The short English queries were translated manually into Chinese and then translated back to English by the translation model.
The Chinese test corpus was the one used in the TREC5 and TREC6 Chinese track.
It contains both Chinese queries and their English translations.
Our experiments on these two corpora produced the results shown in Tab.
1. The precision of monolingual IR is given as benchmark.
In both E-C and C-E CLIR, the translation model achieved around 40% of monolingual precision.
To compare with the dictionary-based approach, we employed a ChineseEnglish dictionary, CEDICT (Denisowski, 1999), and an English-Chinese online dictionary (Anonymous, 1999a) to translate queries.
For each word of the source query, all the possible translations given by the dictionary are included in the translated query.
The Chinese-English dictionary has about the same performace as the translation model, while the English-Chinese dictionary has lower precision than that of the translation model.
We also tried to combine the translations given by the translation model and the dictionary.
In both C-E and E-C CLIR, significant improvements were achieved (as shown in Tab.
1). The improvements show that the translations given by the translation model and the dictionary complement each other well for IR purposes.
The translation model may give either exact translations or incorrect but related words.
Even though these words are not correct in the sense of translation, they are very possibly related to the subject of the query and thus helpful for IR purposes.
The dictionary-based approach expands a query along another dimension.
It gives all the possible translations for each word including those that are missed by the translation model.
4.2 C
o m p a r i s o n W i t h M T S y s t e m s One advantage of a parallel text-based translation model is that it is easier to build than an MT system.
Now that we have examined the CLIR performance of the translation model, we will compare it with two existing MT systems.
Both systems were tested in E-C CLIR.
4.2.1 S
u n s h i n e W e b T r a n Server Using the Sunshine WebTran server (Anonymous, 1999b), an online Engiish-Chinese MT system, to translate the 54 English queries, we obtained an average precision of 0.2001, which is 50.3% of the mono-lingual precision.
The precision is higher than that obtained using the translation model (0.1804) or the dictionary (0.1427) alone, but lower than the precison obtained using them together (0.2232).
4.2.2 Transperfect
Kwok (1999) investigated the CLIR performance of an English-Chinese MT software called Transperfect, using the same TREC Chinese collection as we used in this study.
Using the MT software alone, Kwok achieved 56% of monolingual precision.
The precision is improved to 62% by refining the translation with a dictionary.
Kwok also adopted pretranslation query expansion, which further improved the precison to 70% of the monolingual results.
In our case, the best E-C CLIR precison using the translation model (and dictionary) is 56.1%.
It is lower than what Kwok achieved using Transperfect, however, the difference is not large.
4.3 F
u r t h e r P r o b l e m s The Chinese-English translation model has a fax lower CLIR performance than that of the EnglishFrench model established using the same method (Nie et al., 1999).
The principal reason for this is the fact that English and Chinese are much more different than English and French.
This problem surfaced in many phases of this work, from text alignment to query translation.
Below, we list some further factors affecting CLIR precision.
 The Web-collected corpus is noisy and it is difficult to align English-Chinese texts.
The alignment method we employed has performed more poorly than on English-French alignment.
This in turn leads to poorer performance of the translation model.
In general, we observe a higher fivariability in Chinese-English translations than in English-French translations.
 For E-C CLIR, although queries in both languages were provided, the English queries were not strictly translated from the original Chinese ones.
For example, A J g, ~ (human right situation) was translated into human right issue.
We cannot expect the translation model to translate issue back to ~ (situation).
 The training source and the CLIR collections were from different domains.
The Web corpus are retrieved from the parallel sites in Hong Kong while the Chinese collection is from People's Daily and Xinhua News Agency, which are published in mainland China.
As the result, some important terms such as ~ $ $ (mostfavored-nation) and --I!!
~ ~ (one-nation-twosystems) in the collection are not known by the model.
5 Summary
The goal of this work was to investigate the feasibility of using a statistical translation model trained on a Web-collected corpus to do English-Chinese CLIR.
In this paper, we have described the algorithm and implementation we used for parallel text mining, translation model training, and some results we obtained in CLIR experiments.
Although further work remains to be done, we can conclude that it is possible to automatically construct a Chinese-English parallel corpus from the Web.
The current system can be easily adapted to other language pairs.
Despite the noisy nature of the corpus and the great difference in the languages, the evaluation lexicons generated by the translation model produced acceptable precision.
While the current CLIR results are not as encouraging as those of English-French CLIR, they could be improved in various ways, such as improving the alignment method by adapting cognate definitions to HTML markup, incorporating a lexicon and/or removing some common function words in translated queries.
We hope to be able to demonstrate in the near future that a fine-tuned English-Chinese translation model can provide query translations for CLIR with the same quality produced by MT systems.
D i s t i l l i n g dialogues A m e t h o d using natural dialogue c o r p o r a for dialogue s y s t e m s d e v e l o p m e n t Arne Department JSnsson and Nils Dahlb~ick of Computer and Information Science LinkSping University S-581 83, L I N K O P I N G SWEDEN nilda@ida.liu.se, arnjo@ida.liu.se Abstract We report on a method for utilising corpora collected in natural settings.
It is based on distilling (re-writing) natural dialogues to elicit the type of dialogue that would occur if one the dialogue participants was a computer instead of a human.
The method is a complement to other means such as Wizard of Oz-studies and un-distilled natural dialogues.
We present the distilling method and guidelines for distillation.
We also illustrate how the method affects a corpus of dialogues and discuss the pros and cons of three approaches in different phases of dialogue systems development.
1 Introduction
on measures for inter-rater reliability (Carletta, 1996), on frameworks for evaluating spoken dialogue agents (Walker et al., 1998) and on the use of different corpora in the development of a particular system (The Carnegie-Mellon Communicator, Eskenazi et al.(1999)). The question we are addressing in this paper is how to collect and analyse relevant corpora.
We begin by describing what we consider to be the main advantages and disadvantages of the two currently used methods; studies of human dialogues and Wizard of Oz-dialogues, especially focusing on the ecological validity of the methods.
We then describe a m e t h o d called 'distilling dialogues', which can serve as a supplement to the other two.
It has been known for quite some time now, that the language used when interacting with a computer is different from the one used in dialogues between people, (c.f.
JSnsson and Dahlb~ick (1988)).
Given that we know that the language will be different, but not how it will be different, we need to base our development of natural language dialogue systems on a relevant set of dialogue corpora.
It is our belief that we need to clarify a number of different issues regarding the collection and use of corpora in the development of speech-only and multimodal dialogue systems.
Exchanging experiences and developing guidelines in this area are as important as, and in some sense a necessary pre-requisite to, the development of computational models of speech, language, and dialogue/discourse.
It is interesting to note the difference in the state of art in the field of natural language dialogue systems with that of corpus linguistics, where issues of the usefulness of different samples, the necessary sampling size, representativeness in corpus design and other have been discussed for quite some time (e.g.
(Garside et al., 1997; Atkins et al., 1992; Crowdy, 1993; Biber, 1993)).
Also the neighboring area of evaluation of NLP systems (for an overview, see Sparck Jones and Galliers (1996)) seems to have advanced further.
Some work have been done in the area of natural language dialogue systems, e.g. on the design of Wizard of Oz-studies (Dahlb~ck et al., 1998), 2 Natural and Wizard of Oz-Dialogues The advantage of using real dialogues between people is that they will illustrate which tasks and needs that people actually bring to a particular service provider.
Thus, on the level of the users' general goals, such dialogues have a high validity.
But there are two drawbacks here.
First; it is not self-evident that users will have the same task expectations from a computer system as they have with a person.
Second, the language used will differ from the language used when interacting with a computer.
These two disadvantages have been the major force behind the development of Wizard of Ozmethods.
The advantage here is that the setting will be human-computer interaction.
But there are important disadvantages, too.
First, on the practical side, the task of setting up a high quality simulation environment and training the operators ('wizards') to use this is a resource consuming task (Dahlb~ck et al., 1998).
Second, and probably even more important, is that we cannot then observe real users using a system for real life tasks, where they bring their own needs, motivations, resources, and constraints to bear.
To some extent this problem can be overcome using well-designed so called 'scenarios'.
As pointed out in Dahlb~ck (1991), on many levels of analysis the artificiality of the situation will not affifect the language used.
An example of this is the pattern of pronoun-antecedent relations.
But since the tasks given to the users are often pre-described by the researchers, this means t h a t this is not a good way of finding out which tasks the users actually want to perform.
Nor does it provide a clear enough picture on how the users will act to find something t h a t satisfies their requirements.
If e.g. the task is one of finding a charter holiday trip or buying a TVset within a specified set of constraints (economical and other), it is conceivable t h a t people will stay with the first item t h a t matches the specification, whereas in real life they would probably look for alternatives.
In our experience, this is primarily a concern if the focus is on the users' goals and plans, but is less a problem when the interest is on lowerlevel aspects, such as, syntax or patterns of pronounantecedent relationship (c.f.
Dahlb~ick (1991)).
To summarize; real life dialogues will provide a reasonably correct picture of the way users' approach their tasks, and what tasks they bring to the service provider, but the language used will not give a good approximation of what the system under construction will need to handle.
Wizard of Ozdialogues, on the other hand, will give a reasonable approximation of some aspects of the language used, but in an artificial context.
The usual approach has been to work in three steps.
First analyse real h u m a n dialogues, and based on these, in the second phase, design one or more Wizard of Oz-studies.
The final step is to fine-tune the system's performance on real users.
A good example of this method is presented in Eskenazi et al.(1999). But there are also possible problems with this approach (though we are not claiming that this was the case in their particular project).
Eskenazi et al.(1999) asked a h u m a n operator to act 'computerlike' in their Wizard of Oz-phase.
The advantage is of course that the h u m a n operator will be able to perform all the tasks t h a t is usually provided by this service.
The disadvantage is t h a t it puts a heavy burden on the h u m a n operator to act as a computer.
Since we know that lay-persons' ideas of what computers can and cannot do are in m a n y respects far removed from what is actually the case, we risk introducing some systematic distortion here.
And since it is difficult to perform consistently in similar situations, we also risk introducing non-systematic distortion here, even in those cases when the 'wizard' is an NLP-professional.
Our suggestion is therefore to supplement the above mentioned methods, and bridge the gap between them, by post-processing h u m a n dialogues to give them a computer-like quality.
The advantage, compared to having people do the simulation on the fly, is both that it can be done with more consistency, and also that it can be done by researchers t h a t actually know what h u m a n c o m p u t e r natural language dialogues can look like.
A possible disadvantage with using both Wizard of Oz-and real computer dialogues, is that users will quickly a d a p t to what the system can provide t h e m with, and will therefore not try to use it for tasks they know it cannot perform.
Consequently, we will not get a full picture of the different services they would like the system to provide.
A disadvantage with this method is, of course, t h a t post-processing takes some time compared to using the natural dialogues as they are.
There is also a concern on the ecological validity of the results, as discussed later.
Distilling dialogues Distilling dialogues, i.e. re-writing h u m a n interactions in order to have them reflect what a humancomputer interaction could look like involves a number of considerations.
The main issue is t h a t in corp o r a of natural dialogues one of the interlocutors is not a dialogue system.
The system's task is instead performed by a h u m a n and the problem is how to anticipate the behaviour of a system that does not exist based on the performance of an agent with different performance characteristics.
One important aspect is how to deal with h u m a n features that are not part of what the system is supposed to be a b l e to handle, for instance if the user talks about things outside of the domain, such as discussing an episode of a recent T V show.
It also involves issues on how to handle situations where one of the interlocuters discusses with someone else on a different topic, e.g. discussing the up-coming Friday party with a friend in the middle of an information providing dialogue with a customer.
It is i m p o r t a n t for the distilling process to have at least an outline of the dialogue system t h a t is under development: Will it for instance have the capacity to recognise users' goals, even if not explicitly stated?
Will it be able to reason about the discourse domain?
W h a t services will it provide, and what will be outside its capacity to handle?
In our case, we assume that the planned dialogue system has the ability to reason on various aspects of dialogue and properties of the application.
In our current work, and in the examples used for illustration in this paper, we assume a dialogue model that can handle any relevant dialogue phenomenon and also an interpreter and speech recogniser being able to understand any user input that is relevant to the task.
There is is also a powerful domain reasoning module allowing for more or less any knowledge reasoning on issues that can be accomplished within the domain (Flycht-Eriksson, 1999).
Our current system does, however, not have an explicit user task model, as opposed to a system task model (Dahlb~ick fiand JSnsson, 1999), which is included, and thus, we can not assume that the 'system' remembers utterances where the user explains its task.
Furthermore, as our aim is system development we will not consider interaction outside the systems capabilities as relevant to include in the distilled dialogues.
The context of our work is the development a multi-modal dialogue system.
However, in our current work with distilling dialogues, the abilities of a multi-modal system were not fully accounted for.
The reason for this is that the dialogues would be significantly affected, e.g. a telephone conversation where the user always likes to have the n e x t connection, please will result in a table if multi-modal output is possible and hence a fair amount of the dialogne is removed.
We have therefore in this paper analysed the corpus assuming a speech-only system, since this is closer to the original telephone conversations, and hence needs fewer assumptions on system performance when distilling the dialogues.
distilling. The system might in such cases provide less information.
The principle of providing all relevant information is based on the assumption that a computer system often has access to all relevant information when querying the background system and can also present it more conveniently, especially in a multimodal system (Ahrenberg et al., 1996).
A typical example is the dialogue fragment in figure 1.
In this fragment the system provides information on what train to take and how to change to a bus.
The result of distilling this fragment provides the revised fragment of figure 2.
As seen in the fragment of figure 2 we also remove a number of utterances typical for human interaction, as discussed below.
* S y s t e m utterances are m a d e m o r e computer-like and do n o t include irrelevant i n f o r m a t i o n. The Distillation guidelines Distilling dialogues requires guidelines for how to handle various types of utterances.
In this section we will present our guidelines for distilling a corpus of telephone conversations between a human information provider on local buses 1 to be used for developing a multimodal dialogue system (Qvarfordt and JSnsson, 1998; Flycht-Eriksson and JSnsson, 1998; Dahlb~ick et al., 1999; Qvarfordt, 1998).
Similar guidelines are used within another project on developing Swedish Dialogue Systems where the domain is travel bureau information.
We can distinguish three types of contributors: 'System' (i.e.
a future systems) utterances, User utterances, and other types, such as moves by other speakers, and noise.
latter is seen in $9 in the dialogue in figure 3 where the provided information is not relevant.
It could also be possible to remove $5 and respond with $7 at once.
This, however, depends on if the information grounded in $5-U6 is needed for the 'system' in order to know the arrival time or if that could be concluded from U4.
This in turn depends on the system's capabilities.
If we assume that the dialogue system has a model of user tasks, the information in $5-U6 could have been concluded from that.
We will, in this case, retain $5-U6 as we do not assume a user task model (Dahlb/ick and JSnsson, 1999) and in order to stay as close to the original dialogue as possible.
The next problem concerns the case when 'system' utterances are changed or removed.
 Dialogue contributions provided by s o m e t h i n g or s o m e o n e other than the u s e r or the ' s y s t e m ' are removed.
These are regarded as not being part Modifying system utterances The problem of modifying 'system' utterances can be divided into two parts: how to change and when to change.
They are in some respects intertwined, but as the how-part affects the when-part more we will take this as a starting point.
 The ' s y s t e m ' provides as m u c h relevant inform a t i o n as possible at once.
This depends on the capabilities of the systems output modalities.
If we have a screen or similar output device we present as much as possible which normally is all relevant information.
If we, on the other hand, only have spoken output the amount of information that the hearer can interpret in one utterance must be considered when 1The bus time table dialogues are collected at LinkSping University and are available (in Swedish) on http://www.ida.liu.se/~arnjo/kfb/dialoger.html of the interaction.
This means that if someone interrupts the current interaction, say that the telephone rings during a face-to-face interaction, the interrupting interaction is normally removed from the corpus.
Furthermore, 'system' interruptions are removed.
A human can very well interrupt another human interlocuter, but a computer system will not do that.
However, this guideline could lead to problems, for instance, when users follow up such interruptions.
If no information is provided or the interrupted sequence does not affect the dialogue, we have no problems removing the interruption.
The problem is what to do when information from the 'system' is used in the continuing dialogue.
For such cases we have no fixed strategy, yes I wonder if you have any m m buses or ().
like express buses leaving from LinkSping to Vadstena ().
on sunday ja ville undra om ni hade ndgra 5h bussar eUer ().
typ expressbussar sore dkte frdn LinkSping till Vadstena ().
pd sSnda $5: no the bus does not run on sundays nej bussen g~r inte pd sSndagar U6: how can you ().
can you take the train and then change some way ().
because ().
to MjSlby 'n' so hur kan man ().
kan man ta tdg d sen byta p~ ndtt sStt ().
fSr de ().
till mjSlby ~ sd $7: that you can do too yes de kan du gSra ocksd ja U8: how ().
do you have any such suggestions hut ().
har du n~ra n~gra s~na fSrslag $9: yes let's see (4s) a m o m e n t (15s) now let us see here ().
was it on the sunday you should travel ja ska se h~ir (4s) eft 5gonblick (15s) nu ska vise hSr ().
va de p~ sSndagen du skulle dka pd U10: yes right afternoon preferably ja just de eftermidda ggirna $11: afternoon preferable ().
you have train from LinkSping fourteen twenty nine eftermidda gSrna ().
du hat t~g frdn LinkSping fjorton d tjugonie U12: m m mm S13: and then you will change from MjSlby station six hundred sixty sd byter du frdn MjSlby station sexhundrasexti sexhundrasexti $15: fifteen and ten Figure 1: Dialogue fragment from a real interaction on bus time-table information U4: S5: U6: $7: I wonder if you have any buses or ().
like express buses going from LinkSping to Vadstena ().
on sunday no the bus does not run on sundays how can you ().
can you take the train and then change some way ().
because ().
to MjSlby and so you can take the train from LinkSping fourteen and twenty nine and then you will change at MjSlby station to bus six hundred sixty at fifteen and ten Figure 2: A distilled version of the dialogue in figure 1 the dialogue needs to be rearranged depending on how the information is to be used (c.f.
the discussion in the final section of this paper).
in figure 4).
A common case of this is when the ' s y s t e m ' is talking while looking for information, $5 in the dialogue fragment of figure 4 is an example of this.
Related to this is when the system provides its own comments.
If we can assume that it has such capabilities they are included, otherwise we remove them.
 'System' utterances which are no longer valid are removed.
Typical examples of this are the utterances $7, $9, $11 and $13 in the dialogue fragment of figure 1.
* Remove sequences of utterances where the 'system' behaves in a way a computer would not do.
For instance jokes, irony, humor, commenting on the other dialogue participant, or dropping the telephone (or whatever is going on in $7 The system does not repeat information that has already been provided unless explicitly asked to do so.
In human interaction it is not uncommon to repeat what has been uttered for purposes other than to provide grounding information or feedback.
This is for instance common during 'n' I must be at Resecentrum before fourteen and thirty five ().
'cause we will going to the interstate buses $5: U6: $7: aha ().
'n' then you must be there around twenty past two something then yes around t h a t ja ungefgir let's see here ( l l s ) two hundred and fourteen R y d end station leaves forty six ().
thirteen 'n' forty six then you will be down fourteen oh seven (.) jaha 'n' ().
the next one takes you there ().
fourteen thirty seven ().
but t h a t is too late Figure 3: Dialogue fragment from a real interaction on bus time-table information U2: $3: U4: $5: U6: $7: Well, hi ().
I a m going to Ugglegatan eighth ja hej ().
ja ska till Ugglegatan dtta Yes ja and ().
I wonder ().
it is somewhere in Tannefors och ().
jag undrar ().
det ligger ndnstans i Tannefors Yes ().
I will see here one one I will look exactly where it is one m o m e n t please ja ().
jag ska se hhr eft eft jag ska titta exakt vat det ligger eft 6gonblick barn Oh Yeah (operator disconnects) (25s) m m ().
okey (hs) what the hell (2s) (operator connects again) hello yes ((Telefonisten kopplar ur sig)) (25s) iihh ().
okey (hs) de va sore ]aan (2s) ((Telefonisten kopplar in sig igen)) halld ja ja hej It is bus two hundred ten which runs on old tannefors road t h a t you have to take and get off at the bus stop at t h a t bus stop named vetegatan Figure 4: Dialogue fragment from a natural bus timetable interaction search procedures as discussed above.
want to develop systems where the user needs to restrict his/her behaviour to the capabilities of the dialogue system.
However, there are certain changes m a d e to user utterances, in most cases as a consequence of changes of system utterances.
 The system does not ask for information it has already achieved.
For instance asking again if it is on Sunday as in $9 in figure 1.
This is not uncommon in h u m a n interaction and such utterances from the user are not removed.
However, we can assume t h a t the dialogue system does not forget what has been talked about before.
4.2 M
o d i f y i n g u s e r u t t e r a n c e s The general rule is to change user utterances as little as possible.
The reason for this is that we do not Utterances that are no longer valid are removed.
The most common cases are utterances whose request has already been answered, as seen in the distilled dialogue in figure 2 of the dialogue in figure 1.
sixteen fifty five sexton ]emti/em U12: sixteen fifty five ().
aha sexton f e m t i / e m ().
jaha S13: bus line four hundred thirty five linje ]yrahundra tretti/em Figure 5: Dialogue fragment from a natural bus timetable interaction  Utterances are removed where the user discusses things that are in the environment.
For instance commenting the 'systems' clothes or hair.
This also includes other types of communicative signals such as laughter based on things outside the interaction, for instance, in the environment of the interlocuters.
 User utterances can also be added in order to make the dialogue continue.
In the dialogue in figure 5 there is nothing in the dialogue explaining why the system utters S13.
In such cases we need to add a user utterance, e.g.
Which bus is that?.
However, it might turn out that there are cues, such as intonation, found when listening to the tapes.
If such detailed analyses are carried out, we will, of course, not need to add utterances.
Furthermore, it is sometimes the case t h a t the telephone operator deliberately splits the information into chunks t h a t can be comprehended by the user, which then must be considered in the distillation.
5 Applying
the method To illustrate the m e t h o d we will in this section t r y to characterise the results from our distillations.
The illustration is based on 39 distilled dialogues from the previously mentioned corpus collected with a telephone operator having information on local bus time-tables and persons calling the information service.
The distillation took a b o u t three hours for all 39 dialogues, i.e. it is reasonably fast.
The distilled dialogues are on the average 27% shorter.
However, this varies between the dialogues, at most 73% was removed but there were also seven dialogues t h a t were not changed at all.
At the most 34 utterances where removed from one single dialogue and that was from a dialogue with discussions on where to find a parking lot, i.e. discussions outside the capabilities of the application.
There was one more dialogue where more t h a n 30 utterances were removed and that dialogue is a typical example of dialogues where distillation actually is very useful and also indicates what is normally removed from the dialogues.
This particular dialogue begins with the user asking for the telephone number to 'the Lost property office' for a specific bus operator.
However, the operator starts a discussion on what bus the traveller traveled on before providing the requested telephone number.
The reason for this discussion is probably t h a t the operator knows that different bus companies are utilised and would like to make sure that the user really understands his/her request.
The interaction t h a t follows can, thus, in t h a t respect be relevant, but for our purpose of developing systems based on an overall goal of providing information, not to understand human interaction, our dialogue system will not able to handle such phenomenon (JSnsson, 1996).
The dialogues can roughly be divided into five different categories based on the users task.
The discussion in twenty five dialogues were on bus times between various places, often one departure and one arrival but five dialogues involved more places.
In five dialogues the discussion was one price and various types of discounts.
Five users wanted to know the telephone number to 'the Lost property office', two discussed only bus stops and two discussed how they could utilise their season ticket to travel outside the trafficking area of the bus company.
It is interesting to note that there is no correspondence between the task being performed during the interaction and the amount of changes made to the d i a logue.
Thus, if we can assume that the amount of distillation indicates something about a user's interaction style, other factors t h a n the task are important when characterising user behaviour.
Looking at what is altered we find t h a t the most i m p o r t a n t distilling principle is that the 'system' provides all relevant information at once, c.f. figures 1 and 2.
This in turn removes utterances provided by both 'system' and user.
Most added utterances, both from the user and the 'system', provide explicit requests for information that is later provided in the dialogue, e.g. utterance $3 in figure 6.
We have added ten utterances in all 39 dialogues, five 'system' utterances and five user utterances.
Note, however, that we utilised the transcribed dialogues, without information on intonation.
We would probably not have needed to add this m a n y utterances if we had utilised the tapes.
Our reason for not using information on intonation is that we do not assume t h a t our system's speech recogniser can recognise intonation.
Finally, as discussed above, we did not utilise the full potential of multi-modality when distilling the dialogues.
For instance, some dialogues could be further distilled if we had assumed t h a t the system had presented a time-table.
One reason for this is t h a t we wanted to capture as m a n y interesting aspects intact as possible.
The advantage is, thus, that we have a better corpus for understanding humanYees hi Anna Nilsson is my name and I would like to take the bus from Ryd center to Resecentrum in LinkSping jaa hej Anna Nilsson heter jag och jag rill ~ka buss ~r~n Ryds centrum till resecentrum i LinkSping.
$3: U4: mm When do you want to leave? mm N~ir r i l l d u  k a ? 'n' I must be at Resecentrum before fourteen and thirty five ().
'cause we will going to the interstate buses ja ska va p~ rececentrum innan fjorton d trettifem ().
f5 vi ska till l~ngfiirdsbussarna Figure 6: Distilled dialogue fragment with added utterance computer interaction and can from t h a t corpus do a second distillation where we focus more on multimodal interaction.
One example of this is whether the system is meant to acquire information on the user's underlying motivations or goals or not.
In the examples presented, we have not assumed such capabilities, but this assumption is not an absolute necessity.
We believe, however, that the distilling process should be based on one such model, not the least to ensure a consistent t r e a t m e n t of similar recurring phenomena at different places in the corpora.
The validity of the results based on analysing distilled dialogues depends p a r t l y on how the distillation has been carried out.
Even when using natural dialogues we can have situations where the interaction is somewhat mysterious, for instance, if some of the dialogue participants behaves irrational such as not providing feedback or being too elliptical.
However, if careful considerations have been made to stay as close to the original dialogues as possible, we believe that distilled dialogues will reflect what a hum a n would consider to be a natural interaction.
Acknowledgments This work results from a n u m b e r of projects on development of natural language interfaces supported by The Swedish Transport & Communications Research Board (KFB) and the joint Research P r o g r a m for Language Technology ( H S F R / N U T E K ) . We are indebted to the participants of the Swedish Dialogue Systems project, especially to Staffan Larsson, Lena S a n t a m a r t a, and Annika Flycht-Eriksson for interesting discussions on this topic.
Discussion We have been presenting a method for distilling hum a n dialogues to make t h e m resemble h u m a n computer interaction, in order to utilise such dialogues as a knowledge source when developing dialogue systems.
Our own main purpose has been to use t h e m for developing multimodal systems, however, as discussed above, we have in this p a p e r rather assumed a speech-only system.
But we believe that the basic approach can be used also for multi-modal systems and other kinds of natural language dialogue systems.
It is i m p o r t a n t to be aware of the limitations of the method, and how 'realistic' the produced result will be, compared to a dialogue with the final system.
Since we are changing the dialogue moves, by for instance providing all required information in one move, or never asking to be reminded of what the user has previously requested, it is obvious t h a t what follows after the changed sequence would probably be affected one way or another.
A consequence of this is that the resulting dialogue is less accurate as a model of the entire dialogue.
It is therefore not an ideal candidate for trying out the systems over-all performance during system development.
But for the smaller sub-segments or sub-dialogues, we believe that it creates a good approximation of what will take place once the system is up and running.
Furthermore, we believe distilled dialogues in some respects to be more realistic than Wizard of Ozdialogues collected with a wizard acting as a computer.
Another issue, t h a t has been discussed previously in the description of the method, is t h a t the distilling is made based on a particular view of what a dialogue with a computer will look like.
While not necessarily being a detailed and specific model, it is at least an instance of a class of computer dialogue models.
Plan-Based Dialogue Management in a Physics Tutor Reva Freedman Learning Research and Development Center University of Pittsburgh Pittsburgh, PA 15260 freedrk+@pitt, edu http://www.pitt, edu/~freedrk Abstract This paper describes an application of APE (the Atlas Planning Engine), an integrated planning and execution system at the heart of the Atlas dialogue management system.
APE controls a mixedinitiative dialogue between a human user and a host system, where turns in the 'conversation' may include graphical actions and/or written text.
APE has full unification and can handle arbitrarily nested discourse constructs, making it more powerful than dialogue managers based on finitestate machines.
We illustrate this work by describing Atlas-Andes, an intelligent tutoring system built using APE with the Andes physics tutor as the host.
1 Introduction
The purpose of the Atlas project is to enlarge the scope of student interaction in an intelligent tutoring system (ITS) to include coherent conversational sequences, including both written text and GUI actions.
A key component o f Atlas is APE, the Atlas Planning Engine, a "just-intime" planner specialized for easy construction and quick generation of hierarchically organized dialogues.
APE is a domainand task-independent system.
Although to date we have used APE as a dialogue manager for intelligent tutoring systems, APE could also be used to manage other types of human-computer conversation, such as an advicegiving system or an interactive help system.
Planning is an essential component of a dialogue-based ITS.
Although there are many reasons for using natural language in an ITS, as soon as the student gives an unexpected response to a tutor question, the tutor needs to be able to plan in order to achieve its goals as well as respond appropriately to the student's statement.
Yet classical planning is inappropriate for dialogue generation precisely because it assumes an unchanging world.
A more appropriate approach is the "practical reason" approach pioneered by Bratman (1987, 1990).
According to Bratman, human beings maintain plans and prefer to follow them, but they are also capable of changing the plans on the fly when needed.
Bratman's approach has been introduced into computer science under the name of reactive planning (Georgeff and Ingrand 1989, Wilkins et al.1995). In this paper we discuss the rationale for the use of reactive planning as well as the use of the hierarchical task network (HTN) style o f plan operators.
Then we describe APE (the Atlas Planning Engine), a dialogue planner we have implemented to embody the above concepts.
We demonstrate the use of APE by showing how we have used it to add a dialogue capability to an existing ITS, the Andes physics tutor.
By showing dialogues that Atlas-Andes can generate, we demonstrate the advantages of this architecture over the finite-state machine approach to dialogue management.
Integrated planning and execution for dialogue generation 2.1 'Practical reason' and the BDI model For an ITS, planning is required in order to ensure a coherent conversation as well as to accomplish tutorial goals.
But it is impossible to plan a whole conversation in advance when the student can respond freely at every turn, just as human beings cannot plan their daily lives in advance because of possible changes in conditions.
Classical planning algorithms are inappropriate because the tutor must be able to change plans based on the This research was supported by NSF grant number 9720359 to CIRCLE, the Center for Interdisciplinary Research on Constructive Learning Environments at the University of Pittsburgh and Carnegie-Mellon University.
fistudent's responses.
For this reason we have adopted the ideas of the philosopher Michael Bratman (1987, 1990).
Bratman uses the term "practical reason" to describe his analysis since he is concerned with how to reason about practical matters.
For human beings, planning is required in order to accomplish one's goals.
Bratman's key insight is that human beings tend to follow a plan once they have one, although they are capable of dropping an intention or changing a partial plan when necessary.
In other words, human beings do not decide what to do from scratch at each turn.
Bratman and others who have adopted his approach use a tripartite mental model that includes beliefs, desires and intentions (Bratman, Israel and Pollack 1988, Pollack 1992, Georgeff et al.1998), hence the name "BDI model".
Beliefs, which are uninstantiated plans in the speaker's head, are reified by the plan library.
Desires are expressed as the agent's goals.
Intentions, or plan steps that the agent has committed to but not yet acted on, are stored in an agenda.
Thus the agent's partial plan for achieving a goal is a network of intentions.
A plan can be left in a partially expanded state until it is necessary to refine it further.
2.2 Implementation
via reactive planning can be achieved via a series of subgoals instead of relying on means-end reasoning.
Hierarchical decomposition is more appropriate to dialogue generation for a number of reasons.
First, decomposition is better suited to the type of largescale dialogue planning required in a real-world tutoring system, as it is easier to establish what a human speaker will say in a given situation than to be able to understand why in sufficient detail and generality to do means-end planning.
Second, Hierarchical decomposition minimizes search time.
Third, our dialogues are task-oriented and have a hierarchical structure (Grosz and Sidner 1986).
In such a case, matching the structure of the domain simplifies operator development because they can often be derived from transcripts of human tutoring sessions.
The hierarchy information is also useful in determining appropriate referring expressions.
Fourth, interleaved planning and execution is important for dialogue generation because we cannot predict the human user's future utterances.
In an HTN-based system, it is straightforward to implement interleaved planning and execution because one only needs to expand the portion of the plan that is about to be executed.
Finally, the conversation is in a certain sense the trace of the plan.
In other words, we care much more about the actions generated by the planner than the states involved, whether implicitly or explicitly specified.
Hierarchical decomposition provides this trace naturally.
3 Background: the Andes physics tutor Andes (Gertner, Conati and VanLehn 1998) is an intelligent tutoring system in the domain of firstyear college physics.
Andes teaches via coached problem solving (VanLehn 1996).
In coached problem solving, the tutoring system tracks the student as the latter attempts to solve a problem.
If the student gets stuck or deviates too far from a correct solution path, the tutoring system provides hints and other assistance.
A sample Andes problem is shown in midsolution in Figure 1.
A physics problem is given in the upper-left corner with a picture below it.
Next to the picture the student has begun to sketch the vectors involved using the GUI buttons along the left-hand edge of the screen.
As the fistudent draws vectors, Andes and the student cooperatively fill in the variable definitions in the upper-right corner.
Later the student will use the space below to write equations connecting the variables.
In this example, the elevator is decelerating, so the acceleration vector should face the opposite direction from the velocity vector.
(If the acceleration vector went the same direction as the velocity vector, the speed of the elevator would increase and it would crash into the ground).
This is an important issue in beginning physics; it occurs in five Andes problems.
When such errors occur, Andes turns the incorrect item red and provides hints to students in the lower-left corner of the screen.
A sample of these hints, shown in the order a student would encounter them, is shown in Fig.
2. But hints are an output-only form of natural language; the student can't take the initiative or ask a question.
In addition, there is no way for the system to ask the student a question or lead the student through a multi-step directed line of reasoning.
Thus there is no way to use some of the effective rhetorical methods used by skilled human tutors, such as analogy and reductio ad absurdum.
Current psychological research suggests that active methods, where students have to answer questions, will improve the performance of tutoring systems.
Structure of the Atlas Planning Engine Figure3 shows a sample plan operator.
For legibility, the key elements have been rendered in English instead of in Lisp.
The hiercx slot provides a way for the planner to be aware of the context in which a decomposition is proposed.
Items in the hiercx slot are instantiated and added to the transient database only so long as the operator which spawned them is in the agenda.
To initiate a planning session, the user invokes the planner with an initial goal.
The system searches the operator library to find all operators whose goal field matches the next goal on the agenda and whose filter conditions and preconAn elevator slows to a stop from an initial downward velocity of 10.0 m]s in 2.00 seconds.
A passenger in the elevator is holding a 3.00 kilogram package by a vertical string.
What is the tension in the string during the process? e',ev~o, at 10 m/s elev~or at a stop mass of p~:w'.,I,,~ magnitude of the inst~~taneous Velocity of pack,age ~ {rkneTO magnitude of the avelage Acceleratiorl of package,dudngTO... pkg Figure I: Screen shot of the Andes physics tutor fiS: T: S: T: S: T: S: T: S: (draws acceleration vector in same direction as velocity) Wrong.
What's wrongwith that?
Think about the direction of the acceleration vector.
Please explain further.
Remember that the direction of acceleration is the direction of the change in velocity.
Please explain further.
The'direction o f the acceleration vector is straight up.
(draws acceleration vector correctly) Figure 2: Andes hint sequence formatted as dialogue ditions are satisfied.
Goals are represented in first-order logic without quantifiers and matched via unification.
Since APE is intended especially for generation of hierarchically organized taskoriented discourse, each operator has a multi-step recipe in the style of Wilkins (1988).
When a match is found, the matching goal is removed from the agenda and is replaced by the steps in the recipe.
APE has two kinds of primitive actions; one ends a turn and the other doesn't.
From the point of view of discourse generation, the most important APE recipe items are those allowing the planner to change the agenda when necessary.
These three types of recipe items make APE more powerful than a classical planner.
 Fact: Evaluate a condition.
If false, skip the rest of the recipe.
Fact is used to allow run-time decision making by bypassing the rest o f an operator when circumstances change during its execution.
Fact can be used with retry-at to implement a loop just as in Prolog.
 Retry-at.
The purpose of retry-at is to allow the planner to back up to a choice point and make a new decision.
It removes goals sequentially from the top of the agenda, a full operator at a time, until the supplied argument is false.
Then it restores the parent goal of the last operator removed, so that further planning can choose a new way to achieve it.
Retry-at implements a Prolog-like choice of alternatives, but it differs from backtracking in that the new operator is chosen based on conditions that apply when the retry operation is executed, rather than on a list of possible operators formed when the original operator was chosen.
For retry-at to be useful, the author must provide multiple operators for the same goal.
Each operator must have a set of preconditions enabling it to be chosen at the appropriate time.
 Prune-replace: The intent of prune-replace is (def-operator handle-same-direction :goal ()... :filter () :precond ()...
We h a v e a s k e d a q u e s t i o n a b o u t a c c e l e r a t i o n ;...
a n d t h e s t u d e n t h a s g i v e n an a n s w e r ; ...
f r o m w h i c h we c a n d e d u c e t h a t s / h e t h i n k s a c c e l, a n d v e l o c i t y go in ; the same direction ; a n d we h a v e n o t g i v e n t h e e x p l a n a t i o n below yet : r e c i p e ()...
Tell the student: "But if the a c c e l e r a t i o n went the same direction as t h e v e l o c i t y, t h e n t h e e l e v a t o r w o u l d be s p e e d i n g u p . " ; M a r k t h a t we a r e g i v i n g t h i s e x p l a n a t i o n ; T e l l t h e s t u d e n t t h a t t u t o r is r e q u e s t i n g another answer ("Try again").
Edit the agenda ( u s i n g prune-replace) so t h a t r e s p o n d i n g to a n o t h e r a n s w e r is at t h e t o p of t h e a g e n d a :hiercx ()) Figure 3: Sample plan operator 55 fito allow the planner to remove goals from the agenda based on a change in circumstances.
It removes goals sequentially from the top of the agenda, one at a time, until the supplied argument becomes false.
Then it replaces the removed goals with an optional list of new goals.
Prune-replace allows a type of decision-making frequently used in dialogue generation.
When a conversation partner does not give the expected response, one would often like to remove the next goal from the agenda and replace it with one or more replacement goals.
Prune-replace implements a generalized version of this concept.
APE is domain-independent and communicates with a host system via an API.
As a partner in a dialogue, it needs to obtain information from the world as well as produce output turns.
Preconditions on plan operators can be used to access information from external knowledge sources.
APE contains a recipe item type that can be used to execute an external program such as a call to a GUI interface.
APE also has recipe items allowing the user to assert and retract facts in a knowledge base.
Further details about the APE planner can be found in (Freedman, 2000).
I m p l e m e n t a t i o n of Atlas-Andes 5.1 Architecture of Atlas-Andes The first system we have implemented with APE is a prototype Atlas-Andes system that replaces the hints usually given for an incorrect acceleration vector by a choice of generated subdialogues.
Figure 4 shows the architecture of Atlas-Andes; any other system built with APE would look similar.
Robust natural language understanding in Atlas-Andes is provided by Ros6's CARMEL system (Ros6 2000); it uses the spelling correction algorithm devised by Elmi and Evens (1998).
5.2 Structure
of human tutorial dialogues In an earlier analysis (Kim, Freedman and Evens 1998) we showed that a significant portion of human-human tutorial dialogues can be modeled with the hierarchical structure o f task-oriented dialogues (Grosz and Sidner 1986).
Furthermore, a main building block o f the discourse hierarchy, corresponding to the transaction level in Conversation Analysis (Sinclair and Coulthard 1975), matches the tutoring episode defined by VanLehn et al.(1998). A tutoring episode consists of the turns necessary to help the student make one correct entry on the interface.
NLU (CARMEL) Plan Library User Interface Host (Andes) GUI Interpreter (Andes) Transient Knowledge Base Figure 4: Interface between Atlas and host system fiTo obtain empirical data for the Atlas-Andes plan operators, we analyzed portions of a corpus of human tutors helping students solve similar physics problems.
Two experienced tutors were used.
Tutor A was a graduate student in computer science who had majored in physics; tutor B was a professional physics tutor.
The complete corpus contained solutions to five physics problems by 41 students each.
We analyzed every tutoring episode dealing with the acceleration vector during deceleration, totaling 29 examples divided among 20 students and both tutors.
The tutors had very different styles.
Tutor A tended to provide encouragement rather than content, making those transcripts less useful for deriving an information-based approach.
Tutor B used an information-based approach, but after one wrong answer tended to complete the solution as a monologue.
Largely following tutor B's approach to sequence and content, we isolated six ways of teaching the student about direction of acceleration.
Tutoring schemata Switching between schemata API and GUI handling Answer handling Domain-dep.
lex. insertion Domain-indep.
lex. insertion TOTAL 5.3 Sample output and evaluation Figure 5 shows an example of text that can be generated by the Atlas-Andes system, showing an analogy-based approach to teaching this content.
The operator library used to generate this text could generate a combinatorially large number of versions of this dialogue as well as selected examples of other ways o f teaching about direction of acceleration.
This operator library used to generate this text contained 1 l 1 plan operators, divided as follows: We are currently working on components that will allow us to increase the number of physics concepts covered without a corresponding increase in the number of operators.
The schema switching operators prevent the tutor from repeating itself during a physics problem.
They could be reduced or eliminated by a general discourse history component that tutoring schema operators could refer to.
Domain-dependent lexical insertion refers to the choice of lexical items such as car and east in the sample dialogue, while domain-independent iexical insertion refers to items such as O K and exactly.
Both categories could be eliminated, or at least severely reduced, through the use of a text realization package.
Together that would provide a one-third reduction in the number o f operators needed.
As the set of API and GUI handling operators is fixed, that would reduce by half the number of application operators needed.
The largest remaining category of operators is the answer handlers.
These operators handle a variety of answers for each o f the five questions that the system can ask.
The answers we recognize include categories such as "don't know" as well as specific answers (e.g.
a direction perpendicular to the correct answer) which we recognize because the tutor has specific replies for them.
In order to reduce the number o f S: T: S: T: S: T: S: (draws acceleration vector in same direction as velocity) What is the definition of acceleration?
Don't know.
OK, let's try this.
If a car was driving along east, which way would you have to push on it to make it stop?
West. Exactly.
The opposite direction.
So the net force goes the opposite direction, and so does the acceleration.
Try to draw the acceleration vector again now.
(draws acceleration vector correctly) Figure 5: Example of generated dialogue 57 fioperators further, we must investigate more general methods of handling student errors.
In particular, we plan to investigate error-classifying predicates that apply to more than one question as well as the use of intention-based predicates.
Since the system only covers one rule of physics, albeit in a variety of ways, we plan to make some of these efficiency improvements before adding new rules o f physics and testing it with users.
Preconditions for the operators in the plan library utilize discourse or interaction history, the current goal hierarchy, recent information such as the tutor's current goal and the student's latest response, shared information such as a model o f objects on the screen, and domain knowledge.
As an example of the latter, if the student draws an acceleration vector which is incorrect but not opposite to the velocity vector, a different response will be generated.
Related work Wenger (1987), still the chief textbook on ITSs, states that using a global planner to control an ITS is too inefficient to try.
This is no longer true, if indeed it ever was.
Vassileva (1995) proposes a system based on AND-OR graphs with a separate set of rules for reacting to unexpected events.
Lehuen, Nicolle and Luzzati (1996) present a method of dialogue analysis that produces schemata very similar to ours.
Earlier dialoguebased ITSs that use augmented finite-state machines or equivalent include CIRCSIM-Tutor (Woo et al.1991, Z h o u e t al.
1999) and the system described by Woolf (1984).
Cook (1998) uses levels of finite-state machines.
None of these systems provides for predicates with variables or unification.
Conclusions 5.4 Discussion Many previous dialogue-based ITSs have been implemented with finite-state machines, either simple or augmented.
In the most common finite state mode[, each time the human user issues an utterance, the processor reduces it to one of a small number of categories.
These categories represent the possible transitions between states.
Thus history can be stored, and context considered, only by expanding the number o f states.
This approach puts an arbitrary restriction on the amount of context or depth of conversational nesting that can be considered.
More importantly, it misses the significant generalization that these types of dialogues are hierarchical: larger units contain repeated instances of the same smaller units in different sequences and instantiated with different values.
Furthermore, the finite-state machine approach does not allow the author to drop one line of attack and replace it by another without hardcoding every possible transition.
It is also clear that the dialogue-based approach has many benefits over the hint-sequence approach.
In addition to providing a multi-step teaching methods with new content, it can respond flexibly to a variety of student answers at each step and take context into account when generating a reply.
In this paper we described APE, an integrated planner and execution system that we have implemented as part o f the Atlas dialogue manager.
APE uses HTN-style operators and is based on reactive planning concepts.
Although APE is intended largely for use in domains with hierarchical, multi-turn plans, it can be used to implement any conversation-based system, where turns in the 'conversation' may include graphical actions and/or text.
We illustrated the use of APE with an example from the Atlas-Andes physics tutor.
We showed that previous models based on finite-state machines are insufficient to handle the nested subdialogues and abandoned partial subdialogues that occur in practical applications.
We showed how APE generated a sample dialogue that earlier systems could not handle.
Acknowledgments We thank Abigail Gertner for her generous assistance with the Andes system, and Michael Ringenberg for indispensible programming support.
Carolyn Ros6 built the CARMEL natural language understanding component.
Mohammed EImi and Michael Glass of Illinois Institute o f Technology provided the spelling correction code.
We thank Pamela Jordan and the referees for their comments.
Bratman's approach has been elaborated in a computer science context by subsequent researchers (Bratman, Israel and Pollack 1988, Pollack 1992, Georgeff et al.1998). Reactive planning (Georgeff and Ingrand 1989, Wilkins et al.1995), originally known as "integrated planning and execution," is one way of implementing Bratman's model.
Originally developed for real-time control of the space shuttle, reactive planning has since been used in a variety of other domains.
For the Atlas project we have developed a reactive planner called APE (Atlas Planning Engine) which uses these ideas to conduct a conversation.
After each student response, the planner can choose to continue with its previous intention or change something in the plan to respond better to the student's utterance.
Like most reactive planners, APE is a hierarchical task network (HTN) style planner (Yang 1990, Erol, Hendler and Nau 1994).
A Framework for MT and Multilingual NLG Systems Based on Uniform Lexico-Structural Processing Benoit Lavoie CoGenTex, Inc.
840 Hanshaw Road Ithaca, NY USA, 14850 benoit@cogentex.com Richard Kittredge CoGenTex, Inc.
840 Hanshaw Road Ithaca, NY USA, 14850 richard @cogentex.com Tanya Korelsky CoGenTex, Inc.
840 Hanshaw Road Ithaca, NY USA, 14850 tanya @cogentex.com Owen Rambow * ATT Labs-Research, B233 180 Park Ave, PO Box 971 Florham Park, NJ USA, 07932 rambow @research.att.com Abstract In this paper we describe an implemented framework for developing monolingual or multilingual natural language generation (NLG) applications and machine translation (MT) applications.
The framework demonstrates a uniform approach to generation and transfer based on declarative lexico-structural transformations of dependency structures of syntactic or conceptual levels ("uniform lexico-structural processing").
We describe how this framework has been used in practical NLG and MT applications, and report the lessons learned.
1 Introduction
The framework consists of a portable Java environment for building NLG or MT applications by defining modules using a core tree transduction engine and single declarative ASCII specification language for conceptual or syntactic dependency tree structures 1 and their transformations.
Developers can define new modules, add or remove modules, or modify their connections.
Because the processing of the transformation engine is restricted to transduction of trees, it is computationally efficient.
Having declarative rules facilitates their reuse when migrating from one programming environment to another; if the rules are based on functions specific to a programming language, the implementation of these functions might no longer be available in a different environment.
In addition, having all lexical information and all rules represented declaratively makes it relatively easy to integrate into the framework techniques for generating some of the rules automatically, for example using corpus-based methods.
The declarative form of transformations makes it easier to process them, compare them, and cluster them to achieve proper classification and ordering.
In this paper we present a linguistically motivated framework for uniform lexicostructural processing.
It has been used for transformations of conceptual and syntactic structures during generation in monolingual and multilingual natural language generation (NLG) and for transfer in machine translation (MT).
Our work extends directions taken in systems such as Ariane (Vauquois and Boitet, 1985), FoG (Kittredge and Polgu6re, 1991), JOYCE (Rainbow and Korelsky, 1992), and LFS (Iordanskaja et al., 1992).
Although it adopts the general principles found in the abovementioned systems, the approach presented in this paper is more practical, and we believe, would eventually integrate better with emerging statistics-based approaches to MT.
* The work performed on the framework by this coauthor was done while at CoGenTex, Inc.
1 In
this paper, we use the term syntactic dependency (tree) structure as defined in the Meaning-Text Theory (MTT; Mel'cuk, 1988).
However, we extrapolate from this theory when we use the term conceptual dependency (tree) structure, which has no equivalent in MTT (and is unrelated to Shank's CD structures proposed in the 1970s).
Thus, the framework represents a generalized processing environment that can be reused in different types of natural language processing (NLP) applications.
So far the framework has been used successfully to build a wide variety of NLG and MT applications in several limited domains (meteorology, battlefield messages, object modeling) and for different languages (English, French, Arabic, and Korean).
In the next sections, we present the design of the core tree transduction module (Section 2), describe the representations that it uses (Section 3) and the linguistic resources (Section 4).
We then discuss the processing performed by the tree transduction module (Section 5) and its instantiation for different applications (Section 6).
Finally, we discuss lessons learned from developing and using the framework (Section 7) and describe the history of the framework comparing it to other systems (Section 8).
2 The
Framework's Tree Transduction Module Input Lexico-Structm'al Processing Dependency SUucturc Lexico-Structural Postprocessing Figure 1: Design of the Tree Transduction Module 3 The Framework's Representations The core processing engine of the framework is a generic tree transduction module for lexicostructural processing, shown in Figure 1.
The module has dependency stuctures as input and output, expressed in the same tree formalism, although not necessarily at the same level (see Section 3).
This design facilitates the pipelining of modules for stratificational transformation.
In fact, in an application, there are usually several instantiations of this module.
The transduction module consists of three processing steps: lexico-structural preprocessing, main lexico-structural processing, and lexico-structural post-processing.
Each of these steps is driven by a separate grammar, and all three steps draw on a common feature data base and lexicon.
The grammars, the lexicon and the feature data base are referred to as the linguistic resources (even if they sometimes apply to a conceptual representation).
All linguistic resources are represented in a declarative manner.
An instantiation of the tree transduction module consists of a specification of the linguistic resources.
The representations used by all instantiations of the tree transduction module in the framework are dependency tree structures.
The main characteristics of all the dependency tree structures are:  A dependency tree is unordered (in contrast with phrase structure trees, there is no ordering between the branches of the tree).
 All the nodes in the tree correspond to lexemes (i.e., lexical heads) or concepts depending on the level of representation.
In contrast with a phrase structure representation, there are no phrase-structure nodes labeled with nonterminal symbols.
Labelled arcs indicate the dependency relationships between the lexemes.
The first of these characteristics makes a dependency tree structure a very useful representation for MT and multilingual NLG, since it gives linguists a representation that allows them to abstract over numerous crosslinguistic divergences due to language specific ordering (Polgu~re, 1991).
We have implemented 4 different types of dependency tree structures that can be used for NLG, MT or both:  Deep-syntactic structures (DSyntSs);  Surface syntactic structures (SSyntSs); Conceptual structures (ConcSs); Parsed syntactic structures (PSyntSs).
The DSyntSs and SSyntSs correspond closely to the equivalent structures of the Meaning-Text Theory (MTT; Mel'cuk, 1988): both structures are unordered syntactic representations, but a DSyntS only includes full meaning-bearing lexemes while a SSyntS also contains function words such as determiners, auxiliaries, and strongly governed prepositions.
In the implemented applications, the DSyntSs are the pivotal representations involved in most transformations, as this is also often the case in practice in linguistic-based MT (Hutchins and Somers, 1997).
Figure 2 illustrates a DSyntS from a meteorological application, MeteoCogent (Kittredge and Lavoie, 1998), represented using the standard graphical notation and also the RealPro ASCII notation used internally in the framework (Lavoie and Rambow, 1997).
As Figure 2 illustrates, there is a straightforward mapping between the graphical notation and the ASCII notation supported in the framework.
This also applies for all the transformation rules in the framework which illustrates the declarative nature of our approach, Figure 3 illustrates the mapping between an interlingua defined as a ConcS and a corresponding English DSyntS.
This example, also taken from MeteoCogent, illustrates that the conceptual interlingua in NLG can be closer to a database representation of domain data than to its linguistic representations.
As mentioned in (Polgu~re, 1991), the high level of abstraction of the ConcSs makes them a suitable interlingua for multilingual NLG since they bridge the semantic discrepancies between languages, and they can be produced easily from the domain data.
However, most off-the-shelf parsers available for MT produce only syntactic structures, thus the DSyntS level is often more suitable for transfer.
Cones TO ItlGH LOW Low 5 to Mlgh 20 Figure 3: ConcS Interlingua and English DSyntS Finally, the PSyntSs correspond to the parser outputs represented using RealPro's dependency structure formalism.
The PSyntSs may not be valid directly for realization or transfer since they may contain unsupported features or dependency relations.
However, the PSyntSs are represented in a way to allow the framework to convert them into valid DSyntS via lexicostructural processing.
This conversion is done via conversion grammars customized for each parser.
There is a practical need to convert one syntactic formalism to another and so far we have implemented converters for three off-theshelf parsers (Palmer et al., 1998).
4 The
Framework's Linguistic Resources 't Low S to high 20 Figure 2: DSyntS(Graphicaland ASCIINotation) The ConcSs correspond to the standard framelike structures used in knowledge representation, with labeled arcs corresponding to slots.
We have used them only for a very limited meteorological domain (in MeteoCogent), and we imagine that they will typically be defined in a domain-specific manner.
As mentioned previously, the framework is composed of instantiations of the tree fitransduction module shown in Figure 1.
Each module has the following resources:  Feature Data-Base: This consists of the feature system defining available features and their possible values in the module.
 Lexicon: This consists of the available lexemes or concepts, depending on whether the module works at syntactic or conceptual level.
Each lexeme and concept is defined with its features, and may contain specific lexico-structural rules: transfer rules for MT, mapping rules to the next level of representation for surface realization of DSyntS or lexicalization of ConcS.
 Main Grammar: This consists of the lexicostructural mapping rules that apply at this level and which are not lexemeor conceptspecific (e.g.
DSynt-rules for the DSyntmodule, Transfer-rules for the Transfer module, etc).
 Preprocessing grammar: This consists of the lexico-structural mapping rules for transforming the input structures in order to make them compliant with the main grammar, if this is necessary.
Such rules are used to integrate new modules together when discrepancies in the formalism need to be fixed.
This grammar can also be used for adding default features (e.g.
setting the default number of nouns to singular) or for applying default transformations (e.g.
replacing non meaning-bearing lexemes with features).
Postprocessing grammar: This consists of lexico-structural mapping rules for transforming the output structures before they can be processed by the next module.
As for the preprocessing rules, these rules can be used to fix some discrepancies between modules.
Our representation of the lexicon at the lexical level (as opposed to conceptual) is similar to the one found in RealPro.
Figure 4 shows a specification for the lexeme SELL.
This lexeme is defined as a verb of regular morphology with two lexical-structural mappings, the first one introducing the preposition TO for its 3r actant, and the preposition FOR for its 4 th actant: (a seller) X1 sells (merchandise) X2 to (a buyer) X3 f o r (a price) X4.
What is important is that 63 each mapping specifies a transformation between structures at different levels of representation but that are represented in one and the same representation formalism (DSyntS and SSyntS in this case).
As we will see below, grammar rules are also expressed in a similar way.
( c o m p l e t i v e 3 FOR ( prepositional Figure 4: Specification of Lexeme SELL At the conceptual level, the conceptual lexicon associates lexical-structural mapping with concepts in a similar way.
Figure 5 illustrates the mapping at the deep-syntactic level associated with the concept #TEMPERATURE.
Except for the slight differences in the labelling, this type of specification is similar to the one used on the lexical level.
The first mapping rule corresponds to one of the lexico-structural transformations used to convert the interlingual ConcS of Figure 3 to the corresponding DSyntS.
SY SX Note that since each lexicon entry can have more than one lexical-structural mapping rule, the list of these rules represents a small grammar specific to this lexeme or concept.
Realization grammar rules of the main grammar include generic mapping rules (which are not lexeme-specific) such as the DSyntS-rule illustrated in Figure 6, for inserting a determiner.
DSYNT-RULE: More general lexico-structural rules for transfer can also be implemented using our grammar rule formalism.
Figure 8 gives an English-French transfer rule applied to a weather domain for the transfer of a verb modified by the adverb ALMOST: It almost rained.
--o II a failli pleuvoir.
Figure 6: Deep-Syntactic Rule for Determiner Insertion The lexicon formalism has also been extended to implement lexeme-specific lexico-structural transfer rules.
Figure 7 shows the lexicostructural transfer of the English verb lexeme MOVE to French implemented for a military and weather domain (Nasr et al., 1998): Cloud will move into the western regions.
Des nuages envahiront les rdgions ouest.
They moved the assets forward.
-.9 lls ont amen~ les ressources vers l 'avant.
The 79 dcg moves forward.
---~La 79 dcg a v a n c e vers l'avant.
A disturbance will move north of Lake Superior.
--~ Une perturbation se diplacera au nord du lac supdrieur.
Figure 8: English to French Lexico-Structural Transfer Rule with Verb Modifier ALMOST More details on how the structural divergences described in (Dorr, 1994) can be accounted for using our formalism can be found in (Nasr et al., 1998).
5 The
Rule Processing Before being processed, the rules are first compiled and indexed for optimisation.
Each module applies the following processing.
The rules are assumed to be ordered from most specific to least specific.
The application of the rules to the structures is top-down in a recursive way from the f'n-st rule to the last.
For the main grammar, before applying a grammar rule to a given node, dictionary lookup is carried out in order to first apply the lexemeor conceptspecific rules associated with this node.
These are also assumed to be ordered from the most specific to the least specific.
If a lexico-structural transformation involves switching a governor node with one of its dependents in the tree, the process is reapplied with the new node governor.
When no more rules can be applied, the same process is applied to each dependent of the current governor.
When all nodes have been processed, the processing is completed, 6 Using the Framework to build Applications Figure 7: Lexico-Structural Transfer of English Lexerne MOVE to French Figure 9 shows how different instantiations of the tree transduction module can be combined to fibuild NLP applications.
The diagram does not represent a particular system, but rather shows the kind of transformations that have been implemented using the framework, and how they interact.
Each arrow represents one type of processing implemented by an instantiation of the tree transduction module.
Each triangle represents a different level of representation.
Sentence interlingua can also support the generation of French but this functionality has not yet been implemented).
MT:  Transfer on the DSyntS level and realization via SSyntS level for English--French, English--Arabic, English---Korean and Korean--English.
Translation in the meteorology and battlefield domains (Nasr et al., 1998).
 Conversion of the output structures from off-the-shelf English, French and Korean parsers to DSyntS level before their processing by the other components in the framework (Palmer et al., 1998).
7 Lessons
Learned Using the Framework PI "ng Scopeof the Framework SSyntSLI Parsing Input Sentence LI yntS ealization Generated Sentence 1.2 Generated Sentence LI Sentence SSyntS Figure 9: Scope of the Framework's Transformations For example, in Figure 9, starting with the "Input Sentence LI" and passing through Parsing, Conversion, Transfer, DSyntS Realization and SSyntS Realization to "Generated Sentence L2" we obtain an Ll-to-L2 MT system.
Starting with "Sentence Planning" and passing through DSyntS Realization, and SSyntS Realization (including linearization and inflection) to "Generated Sentence LI", we obtain a monolingual NLG system for L1.
So far the framework has been used successfully for building a wide variety of applications in different domains and for different languages: NLG:  Realization of English DSyntSs via SSyntS level for the domains of meteorology (MeteoCogent; Kittredge and Lavoie, 1998) and object modeling (ModelExplainer; Lavoie et al., 1997).
 Generation of English text from conceptual interlingua for the meteorology domain (MeteoCogent).
(The design of the Empirical results obtained from the applications listed in Section 6 have shown that the approach used in the framework is flexible enough and easily portable to new domains, new languages, and new applications.
Moreover, the time spent for development was relatively short compared to that formerly required in developing similar types of applications.
Finally, as intended, the limited computational power of the transduction module, as well as careful implementation, including the compilation of declarative linguistic knowledge to Java, have ensured efficient run-time behavior.
For example, in the MT domain we did not originally plan for a separate conversion step from the parser output to DSyntS.
However, it quickly became apparent that there was a considerable gap between the output of the parsers we were using and the DSyntS representation that was required, and furthermore, that we could use the tree transduction module to quickly bridge this gap.
Nevertheless, our tree transduction-based approach has some important limitations.
In particular, the framework requires the developer of the transformation rules to maintain them and specify the order in which the rules must be applied.
For a small or a stable grammar, this does not pose a problem.
However, for large or rapidly changing grammar (such as a transfer grammar in MT that may need to be adjusted when switching from one parser to another), the fiburden of the developer's task may be quite heavy.
In practice, a considerable amount of time can be spent in testing a grammar after its revision.
Another major problem is related to the maintenance of both the grammar and the lexicon.
On several occasions during the development of these resources, the developer in charge of adding lexical and grammatical data must make some decisions that are domain specific.
For example, in MT, writing transfer rules for terms that can have several meanings or uses, they may simplify the problem by choosing a solution based on the context found in the current corpus, which is a perfectly natural strategy.
However, later, when porting the transfer resources to other domains, the chosen strategy may need to be revised because the context has changed, and other meanings or uses are found in the new corpora.
Because the current approach is based on handcrafted rules, maintenance problems of this sort cannot be avoided when porting the resources to new domains.
An approach such as the one described in (Nasr et al., 1998; and Palmer and al., 1998) seems to be solving a part of the problem when it uses corpus analysis techniques for automatically creating a first draft of the lexical transfer dictionary using statistical methods.
However, the remaining work is still based on handcrafting because the developer must refine the rules manually.
The current framework offers no support for merging handcrafted rules with new lexical rules obtained statistically while preserving the valid handcrafted changes and deleting the invalid ones.
In general, a better integration of linguistically based and statistical methods during all the development phases is greatly needed.
8 History
of the Framework and Comparison with Other Systems realization of deep-syntactic structures in NLG (Lavoie and Rambow, 1997).
It was later extended for generation of deep-syntactic structures from conceptual interlingua (Kittredge and Lavoie, 1998).
Finally, it was applied to MT for transfer between deep-syntactic structures of different languages (Palmer et al., 1998).
The current framework encompasses the full spectrum of such transformations, i.e. from the processing of conceptual structures to the processing of deep-syntactic structures, either for NLG or MT.
Compared to its predecessors (Fog, LFS, JOYCE), our approach has obvious advantages in uniformity, declarativity and portability.
The framework has been used in a wider variety of domains, for more languages, and for more applications (NLG as well as MT).
The framework uses the same engine for all the transformations at all levels because all the syntactic and conceptual structures are represented as dependency tree structures.
In contrast, the predecessor systems were not designed to be rapidly portable.
These systems used programming languages or scripts for the implementation of the transformation rules, and used different types of processing at different levels of representation.
For instance, in LFS conceptual structures were represented as graphs, whereas syntactic structures were represented as trees which required different types of processing at these two levels.
Our approach also has some disadvantages compared with the systems mentioned above.
Our lexico-structural transformations are far less powerful than those expressible using an arbitrary programming language.
In practice, the formalism that we are using for expressing the transformations is inadequate for long-range phenomena (inter-sentential or intra-sentential), including syntactic phenomena such as longdistance wh-movement and discourse phenomena such as anaphora and ellipsis.
The formalism could be extended to handle intrasentential syntactic effects, but inter-sentential discourse phenomena probably require procedural rules in order to access lexemes in The framework represents a generalization of several predecessor NLG systems based on Meaning-Text Theory: FoG (Kittredge and Polgu~re, 1991), LFS (Iordanskaja et al., 1992), and JOYCE (Rambow and Korelsky, 1992).
The framework was originally developed for the fiother sentences.
In fact, LFS and JOYCE include a specific module for elliptical structure processing.
Similarly, the limited power of the tree transformation rule formalism distinguishes the framework from other NLP frameworks based on more general processing paradigms such as unification of FUF/SURGE in the generation domain (Elhadad and Robin, 1992).
9 Status
The framework is currently being improved in order to use XML-based specifications for representing the dependency structures and the transformation rules in order to offer a more standard development environment and to facilitate the framework extension and maintenance.
Acknowledgements A first implementation of the framework (C++ processor and ASCII formalism for expressing the lexico-structural transformation rules) applied to NLG was developed under SBIR F30602-92-C-0015 awarded by USAF Rome Laboratory.
The extensions to MT were developed under SBIR DAAL01-97-C-0016 awarded by the Army Research Laboratory.
The Java implementation and general improvements of the framework were developed under SBIR DAAD17-99-C-0008 awarded by the Army Research Laboratory.
We are thankful to Ted Caldwell, Daryl McCullough, Alexis Nasr and Mike White for their comments and criticism on the work reported in this paper.
REES: A Large-Scale Relation and Event Extraction System Abstract This paper reports on a large-scale, end-toend relation and event extraction system.
At present, the system extracts a total of 100 types of relations and events, which represents a much wider coverage than is typical of extraction systems.
The system consists of three specialized pattem-based tagging modules, a high-precision coreference resolution module, and a configurable template generation module.
We report quantitative evaluation results, analyze the results in detail, and discuss future directions.
Introduction One major goal of information extraction (IE) technology is to help users quickly identify a variety of relations and events and their key players in a large volume of documents.
In contrast with this goal, state-of-the-art information extraction systems, as shown in the various Message Understanding Conferences (MUCs), extract a small number of relations and events.
For instance, the most recent MUC, MUC-7, called for the extraction of 3 relations (person-employer, maker-product, and organization-location) and 1 event (spacecraft launches).
Our goal is to develop an IE system which scales up to extract as many types of relations and events as possible with a minimum amount of porting effort combined with high accuracy.
Currently, REES handles 100 types of relations and events, and it does so in a modular, configurable, and scalable manner.
Below, Section 1 presents the ontologies of relations and events that we have developed.
Section 2 describes REES' system architecture.
Section 3 evaluates the system's performance, and offers a qualitative analysis of system errors.
Section 4 discusses future directions.
1 Relation
and Event Ontologies As the first step in building a large-scale relation and event extraction system, we developed ontologies of the relations and events to be extracted.
These ontologies represent a wide variety of domains: political, financial, business, military, and life-related events and relations.
"Relations" covers what in MUC-7 are called Template Elements (TEs) and Template Relations (TRs).
There are 39 types of relations.
While MUC TE's only dealt with singular entities, REES extracts both singular and plural entities (e.g., "five executives").
The TR relations are shown in italic in the table below.
Relations 'Artifact Relations Artifact-Name&Aliases Artifact-Type Artifact-Subtype Artifact-Descriptor Place Relations Place-Name&Aliases Place-Type Place-Subtype Place-Descriptor Place-Country Artifact-Maker Artifact-Owner Person Relations Person-Name&Aliases Person-Type Person-Subtype Person-Descriptor Person-Honorific Person-Age Person-PhoneNumber Person-Nationality Organization Relations Org-Name&Aliases Org-Descriptor Org-FoundationDate Org-Nationality Org-TickerSymbol Org-Location Org-ParentOrg Org-Owner Org-Founder Org-StockMarket Person-Affiliation Person-Sibling Person-Spouse Person-Parent Person-Grandparent Person-OtherRelative Person-BirthPlace Person-BirthDate Table 1: Relation Ontology "Events" are extracted along with their event participants, e.g., "who did what to whom when and where"?
For example, for a BUYING event, REES extracts the buyer, the artifact, the seller, and the time and location of the BUYING event.
REES currently covers 61 types of events, as shown below.
Figures 1 and 2 show sample relation and event templates.
Figure 1 shows a Person-Affiliation relation template for "Frank Ashley, a spokesman for Occidental Petroleum Corp'".
<PERSON TYPE: PERSON: ORG: AFFILIATION-AP8802230207-54> := PERSON AFFILIATION [TE for"Frank Ashley"] [TE for "Occidental Petroleum"] Figure 1: Example of Relation Template Figure 2 shows an Attack Target event template for the sentence "an Iraqi warplane attacked the frigate Stark with missiles May 17, 1987.
" <ATTACK TARGET-AP8804160078-12>: = TYPE: CONFLICT SUBTYPE: ATTACK TARGET ATTACKER: [TE for "an Iraqi warplane"] TARGET: [TE for "the frigate Stark"] WEAPON: [TE for "missiles"] TIME: "May 17, 1987" PLACE: [TE for "the gulf'] COMMENT: "attacked" Events Vehicle Vehicle departs Vehicle arrives Spacecraft launch Vehicle crash Personnel Change Hire Terminate contract Promote Succeed Start office Transaction Buy artifact Sell artifact Import artifact Export artifact Give money Business Start business Close business Make artifact Acquire company Sell company Sue organization Merge company Financial Currency moves up Currency moves down Stock moves up Stock moves down Stock market moves up Stock market moves down Stock index moves up Stock index moves down Conflict Kill Injure Hijack vehicle Hold hostages Attack target Fire weapon Weapon hit Invade land Move forces Retreat Surrender Evacuate Figure 2: Example of Event Template Crime Sexual assault Steal money Seize drug Indict Arrest Try Convict Sentence Jail Political Nominate Appoint Elect Expel person Reach agreement Hold meeting Impose embargo Topple Family Die Marry System Architecture and Components Figure 3 illustrates the REES system architecture.
REES consists of three main components: a tagging component (cf.
Section 2.1), a co-reference resolution module (cf.
Section 2.2), and a template generation module (cf.
Section 2.3).
Figure 3 also illustrates that the user may run REES from a Graphical User Interface (GUI) called TemplateTool (cf.
Section 2.4).
Tagging Modules The tagging component consists of three modules as shown in Figure 3: NameTagger, NPTagger and EventTagger.
Each module relies on the same pattern-based extraction engine, but uses different sets o f patterns.
The NameTagger recognizes names o f people, organizations, places, and artifacts (currently only vehicles).
Table 2: Event Ontology GUI interaction Figure 3: The REES System Architecture syntactically-based generic patterns.
These The NPTagger then takes the XML-tagged output of the NameTagger through two phases.
First, it recognizes non-recursive Base Noun Phrase (BNP) (our specifications for BNP resemble those in Ramshaw and Marcus 1995).
Second, it recognizes complex NPs for only the four main semantic types of NPs, i.e., Person, Organization, Location, and Artifact (vehicle, drug and weapon).
It makes postmodifier attachment decisions only for those NPs that are crucial to the extraction at hand.
During this second phase, relations which can be recognized locally (e.g., Age, Affiliation, Maker) are also recognized and stored using the XML attributes for the NPs.
For instance, the XML tag for "President of XYZ Corp".
below holds an AFFILIATION attribute with the ID for "XYZ Corp".
<PNP ID="03" AFFILIATION="O4">Presidentof <ENTITY ID="04">XYZ Corp.</ENTITY> </PNP> patterns tag events in the presence of at least one of the arguments specified in the lexical entry for a predicate.
Subsequent pattems try to find additional arguments as well as place and time adjunct information for the tagged event.
As an example of the EventTagger's generic patterns, consider the simplified pattern below.
This pattem matches on an event-denoting verb that requires a direct object of type weapon (e.g., "fire a gun") (& {AND $VP {ARG2_SYN=DO} {ARG2_SEM=WEAPON}} {AND $ARTIFACT {SUBTYPE=WEAPON}})1 The important aspect of REES is its declarative, lexicon-driven approach.
This approach requires a lexicon entry for each event-denoting word, which is generally a I &=concatenation, AND=Boolean operator, $VP and SARTIFACT are macro references for complex phrases.
71:1 Building upon the XML output of the NPTagger, the EventTagger recognizes events applying its lexicon-driven, fiverb.
The lexicon entry specifies the syntactic and semantic restrictions on the verb's arguments.
For instance, the following lexicon entry is for the verb "attack".
It indicates that the verb "attack" belongs to the CONFLICT ontology and to the ATTACK_TARGET type.
The first argument for the verb "attack" is semantically an organization, location, person, or artifact (ARGI_SEM), and syntactically a subject (ARGI_SYN).
The second argument is semantically an organization, location, person or artifact, and syntactically a direct object.
The third argument is semantically a weapon and syntactically a prepositional phrase introduced by the preposition "with".
ATTACK {{{CATEGORY VERB} {ONTOLOGY CONFLICT} {TYPE ATTACK_TARGET} {ARGI_SEM {ORGANIZATION LOCATION PERSON ARTIFACT} } {ARGI_SYN {SUBJECT}} {ARG2_SEM {ORGANIZATION LOCATION PERSON ARTIFACT} } {ARG2_SYN {DO}} {ARG3_SEMWEAPON} } {ARG3_SYN {WITH}}}} About 50 generic event extraction patterns, supported by lexical information as shown above, allow extraction of events and their arguments in cases like: An lraqi warplane attacked the frigate Stark with missiles May 17, 1987.
This generic, lexicon-driven event extraction approach makes REES easily portable because new types of events can be extracted by just adding new verb entries to the lexicon.
No new patterns are required.
Moreover, this approach allows for easy customization capability: a person with no knowledge of the pattern language would be able to configure the system to extract new events.
While the tagging component is similar to other pattern-based IE systems (e.g., Appelt et al.1995; Aone et al.1998, Yangarber and Grishman 1998), our EventTagger is more portable through a lexicon-driven approach.
Co-reference Resolution After the tagging phase, REES sends the XML output through a rule-based co-reference resolution module that resolves:   definite noun phrases of Organization, Person, and Location types, and singular person pronouns: he and she.
Only "high-precision" rules are currently applied to selected types of anaphora.
That is, we resolve only those cases of anaphora whose antecedents the module can identify with high confidence.
For example, the pronoun rules look for the antecedents only within 3 sentences, and the definite NP rules rely heavily on the head noun matches.
Our highprecision approach results from our observation that unless the module is very accurate (above 80% precision), the coreference module can hurt the overall extraction results by over-merging templates.
Template Generation Module A typical template generation module is a hard-coded post-processing module which has to be written for each type of template.
By contrast, our Template Generation module is unique as it uses declarative rules to generate and merge templates automatically so as to achieve portability.
Declarative Template Generation REES outputs the extracted information in the form of either MUC-style templates, as illustrated in Figure 1 and 2, or XML.
A crucial part of a portable, scalable system is to be able to output different types of relations and events without changing the template generation code.
REES maps XML-tagged output of the co-reference module to templates using declarative template definitions, which specifies the template label (e.g., ATTACK_TARGET), XML attribute names (e.g., ARGUMENT l), corresponding template slot names (e.g., ATTACKER), and the type restrictions on slot values (e.g., string).
Event Merging One of the challenges of event extraction is to be able to recognize and merge those event descriptions which refer to the same event.
The Template Generation module uses a set of declarative, customizable rules to merge coreferring events into a single event.
Often, the rules reflect pragmatic knowledge of the world.
For example, consider the rule below for the DYING event type.
This rule establishes that if two die events have the same subject, then they refer to the same event (i.e., a person cannot die more than once).
{merge {EVENT 1 {AND {SUBTYPE DIE} {PERSON training set (200 texts) and the blind set (208 texts) from about a dozen news sources.
Each set contains at least 3 examples of each type of relations and events.
As we mentioned earlier, "relations" includes MUC-style TEs and TRs.
Text Set Task Train Blind Rel.
Events Rel.
& Events Rel.
Events Rel.
& Events Templates in keys 9955 2525 10707 F-M {EVENT 2 {AND {SUBTYPE DIE} {PERSON Table 3: Evaluation Results 2.4 Graphical User Interface (GUI) For some applications such as database population, the user may want to validate the system output.
REES is provided with a Javabased Graphical User Interface that allows the user to run REES and display, delete, or modify the system output.
As illustrated in Figure 4, the tool displays the templates on the bottom half of the screen, and the user can choose which template to display.
The top half of the screen displays the input document with extracted phrases in different colors.
The user can select any slot value, and the tool will highlight the portion of the input text responsible for the slot value.
This feature is very useful in efficiently verifying system output.
Once the system's output has been verified, the resulting templates can be saved and used to populate a database.
3 System
Evaluation The blind set F-Measure for 31 types of relations (73.95%) exceeded our initial goal of 70%.
While the blind set F-Measure for 61 types o f events was 53.75%, it is significant to note that 26 types of events achieved an FMeasure over 70%, and 37 types over 60% (cf.
Table 4).
For reference, though not exactly comparable, the best-performing MUC-7 system achieved 87% in TE, 76% in TR, and 51% in event extraction.
F-M in blind set 90-100 80-89 Event types 2 : Buy artifact.
Marry 9 : Succeed, Merge company, Kill, Surrender, Arrest, Convict, Sentence, Nominate, Expel.
15 : Die, Sell artif~/ct,Export Artifact, Hire, Start office, Make artifact, Acquire company, Sue organization, Stock Index moves down, Steal money, Indict, Jail, Vehicle crash, Elect, Hold meeting.
Table 4: Top-performing Event Types The table below shows the system's recall, precision, and F-Measure scores for the Regarding relation extraction, the difference in the score between the training and blind sets was very small.
In fact, the total F-Measure on the blind set is less than 2 points lower than that of the training set.
It is also interesting to note that for 8 of the 12 relation types where the F-Measure dropped more than 10 points, the training set includes less than 20 instances.
In other words, there seems to be a natural correlation between low number of instances in the training set and low performance in the blind set.
There was a significant drop between the training and blind sets in event extraction: 11 points.
We believe that the main reason is that the total number of events in the training set is fairly low: 801 instances of 61 types of events (an average of 13/event), where 35 o f the event types had fewer than 10 instances.
In fact, 9 out of the 14 event types which scored lower than 40% F-Measure had fewer than I0 examples.
In comparison, there were 34,000 instances of 39 types of relations in the training set.
The contribution o f the co-reference module is illustrated in the table below.
Co-reference resolution consistently improves F-Measures both in training and blind sets.
Its impact is larger in relation than event extraction.
Text set Task Coreference rules No coreference rules Training Blind Relations Events Relations & Events Relations Events Relations & Events Table 5: Comparative results with and without co-reference rules In the next two sections, we analyze both false positives and false negatives.
False Positives (or Precision Errors) REES produced precision errors in the following cases:  Most of the errors were due to overgeneration of templates.
These are mostly cases of co-referring noun phrases that the system failed to resolve.
For example: "Panama...
the nation ...
this country.., his country" Rules for the co-reference module are still under development, and at present REES handles only limited types of plural noun phrase anaphora.
Spurious events resulted from verbs in conditional constructions (e.g., "if ...
then")... or from ambiguous predicates.
For instance, "appoint" as a POLITICAL event vs.
a PERSONNEL CHANGE event.
The subject of a verb was misidentified.
This is particularly frequent in reduced relative clauses.
Kabul radio said the latest deaths brought to 38 the number o f people killed in the three car bomb explosions, (Wrong subject: "the number of people" as the KILLER instead of the victim) False Negatives (or Recall Errors) Below, we list the most frequent recall errors in the training set.
 Some event arguments are mentioned with event nouns instead of event verbs.
The current system does not handle noun-based event extraction.
India's acquisition last month of the nuclear submarine from the Soviet Union...
(SELLER="Soviet Union" and TIME="last month'" come with the nounbased event "acquisition").
 Pronouns "it" and "they," which carry little semantic information, are currently not resolved by the co-reference module.
It also has bought three late-1970s vintage ICilo class Soviet submarines and two West German HDW 209 subs (Missed BUYER=India because of unresolved it).
Verb arguments are a conjunction of noun phrases.
The current system does not handle coordination of verb arguments.
Hezbollah killed 21 lsraelis and 43 o f Lahad's soldiers (The system gets only the first object: 21 Israelis.
) Ellipsis cases.
The current system does not handle ellipsis.
The two were sentenced to five-year prison terms with hard labor by the state security court...
(Missed PERSON_SENTENCED fill because of unresolved the two).
The subject of the event is relatively far from the event-denoting verb: Vladislav Listyev, 38, who brought television interview shows in the style of Phil Donahue or Larry King to Russian viewers and pioneered hard-hitting television journalism in the 1980s, was shot in the heart by unknown assailants and died immediately...
(The system missed subject Vladislav Listyev for attack event shot) Missed ORG LOCATION relations for locations that are part o f the organization's name.
Larnaca General Hospital (Missed ORG_LOCATION TR for this and Larnaca.
) We asked a person who is not involved in the development of REES to review the event extraction output for the blind set.
This person reported that:  In 35% of the cases where the REES system completely missed an event, it was because the lexicon was missing the predicate.
REES's event predicate lexicon is rather small at present (a total of 140 verbs for 61 event types) and is mostly based on the examples found in the training set,  In 30% of the cases, the subject or object was elliptical.
The system does not currently handle ellipsis.
In 25% of the cases, syntactic/semantic argument structures were missing from existing lexical entries.
It is quite encouraging that simply adding additional predicates and predicate argument structures to the lexicon could significantly increase the blind set performance.
Desmond Tutu and Albertina Sisulu are important...
We plan to develop a generic set of patterns for noun-based event extraction to complement the set of generic verb-based extraction patterns.
5 4 Future Directions We believe that improving co-reference resolution and adding noun-based event extraction capability are critical to achieving our ultimate goal of at least 80% F-Measure for relations and 70% for events.
4.1 Co-reference Resolution Conclusions As discussed in Section 3.1 and 3.2, accurate co-reference resolution is crucial to improving the accuracy of extraction, both in terms of recall and precision.
In particular, we identified two types of high-payoff coreference resolution:  definite noun phrase resolution, especially plural noun phrases  3 rd person neutral pronouns "it" and "they".
4.2 Noun-based Event Extraction In this paper, we reported on a fast, portable, large-scale event and relation extraction system REES.
To the best of our knowledge, this is the first attempt to develop an IE system which can extract such a wide range of relations and events with high accuracy.
It performs particularly well on relation extraction, and it achieves 70% or higher F-Measure for 26 types of events already.
In addition, the design of REES is highly portable for future addition of new relations and events.
Acknowledgements This project would have not been possible without the contributions of Arcel Castillo, Lauren Halverson, and Sandy Shinn.
Our thanks also to Brandon Kennedy, who prepared the hand-tagged data.
REES currently handles only verb-based events.
Noun-based event extraction adds more complexity because: Nouns are often used in a generic, nonreferential manner (e.g., "We see a m e r g e r as being in the consumer's interest"), and When referential, nouns often refer to verb-based events, thus requiring nounverb co-reference resolution ("An F-14 crashed shortly after takeoff...
The crash").
PROBLEMS IN NATURAL-LANGUAGE INTERFACE WITH EXAMPLES FROM EUFID Marjorie T e m p l e t o n John Burger S y s t e m Development Corporation Santa Mortice, California TO DSMS ABSTRACT For five years t h e End-User Friendly Interface to Data management (EUFID) project team at System Development Corporation worked on the design and implementation of a Natural-Language Interface (NLI) system that was to be independent of both the application and the database management system.
In this paper we describe application, n a t u r a l -l a n g u a g e and d a t a b a s e management problems involved in NLI development, with specific reference to the EUFID system as an example.
I INTRODUCTION users.
Tools that could assist in automating this process are badly needed.
The second set of issues involves language processing techniques: how to assign constituent structure and interpretation to queries using robust and general methods that allow extension to additional lexical items, sentence types and semantic relationships.
Some NLI systems d i s t i n g u i s h the assignment of syntactic structure, o r parsing, from the interpretation.
Other systems, including EUFID, combine information about constituent and semantic structure into an integrated semantic grammar.
The third class involves database issues: how to actually perform the intent of the natural-language question by formulating the correct structured query and e f f i c i e n t l y n a v i g a t i n g through the database to retrieve the right answer.
This involves a thorough understanding of the DBMS structure underlying the a p p l i c a t i o n, the operations and functions the query language supports, and the nature and volatility of the database.
Obviously issues in these three areas are related, and the knowledge needed to deal with them may be distributed throughout a natural-language interface system.
The purpose of this paper is to show how such issues might be addressed in NLI development, with illustrations from EUFID.
The next section includes a brief review of related work, and an o v e r v i e w of the EUFID system.
The third section describes the goals that EUFID achieved, and section four discusses in detail ~ome of the major application, language, and database problems that arose.
Section five suggests guidelines for determining whether an application is an appropriate target for a n a t u r a l l a n g u a g e interface.
From 1976 t o 1981 SDC was involved in the development of the End-User Friendly Interface to Data management (EUFID) system, a n a t u r a l l a n g u a g e interface (NLI) that is designed to be independent of both the application and the underlying d a t a b a s e management system (DBMS).
[TEMP79, TEMP80, BURG80, BURG82].
The EUFID system permits users to communicate with database management systems in natural English rather than formal query languages.
It is assumed that the application domain is well defined and bounded, that users share a common language to address the application, and that users may have little experience with computers or DBMSs but are competent in the application area.
At least three broad categories of issues had to be addressed during EUFID development, and it is apparent that they are common to any general naturallanguage interface to database management systems.
The first category involves the application: how to c h a r a c t e r i z e the requirements of the human-machine dialogue and interaction, capture that information efficiently, formalize the information and incorporate that knowledge into a framework that can be used by the system.
The major problems in this area are knowledge acquisition and representation.
For many NLI systems, bringing up a new application requires extensive effort by system designers with cooperation from a representative set of endfiII BACKGROUND Over the past two decades a considerable amount of work has gone into the d e v e l o p m e n t of natural-language systems.
Early developments were in the areas of text processing, syntactic parsing techniques, machine translation, and early attempts at English-language question answering systems.
Several early question-answering experiments are reviewed by R.
F. Simmons in [SIMM65].
Waltz has edited a collection of short papers on topics related to naturallanguage and artificial intelligence in a survey of NLI research [WALT77].
A survey of NLIs and evaluation of several systems with respect t o their applicability to command and control environments can be found in [OS179].
A. RELATED WORK involved with problems of semantics and has three separate layers of semantic u n d e r s t a n d i n g. The layers are called "English Formal Language", "World Model Language", and "Data Base Language" and appear to c o r r e s p o n d roughly to the "external", "conceptual", and "internal" views of data as d e s c r i b e d by C.
J. Date [DATE77].
PHLIQAI can interface to a v a r i e t y of d a t a b as e structures and DBMSs.
5. The Programmed LANguage-based Enquiry System (PLANES) [WALT78] uses an ATN based parser and a semantic case frame analysis to understand questions.
Case frames are used to handle pronominal and elliptical reference and to g e n e r a t e responses to clarify partially interpreted questions.
REL [THOM69], initially written entirely in assembler code for an IBM36@, has been in continuous development since 1967.
REL allows a user to make interactive extensions to the g r a m m a r and semantics of the system.
It uses a formal grammar expressed as a set of general re-write rules with semantic transformations attached to each rule.
Answers are obtained from a b u i l t i n database.
RENDEZVOUS [CODD74] addresses the problem of c e r t a i n t y regarding the machine's understanding of the user's question.
It engages the user in d i a l o g u e to specify and disambiguate the question and will not route the formal query to the relational DBMS until the user is satisfied with the machine's interpretation.
ROBOT [HARR78] is one of the few NLI systems currently a v a i l a b l e on the commercial market.
It is the basis for Cullinane's OnLine English [CULL80] and Artificial Intelligence C o r p o r a t i o n ' s Intellect [EDP82].
It uses an extracted version of the database for lexical data to assist the ATN parser.
TORUS [MYLO76], like RENDEZVOUS, engages the user in a d i a l o g u e to specify and d i s a m b i g u a t e the user's question.
It is a research o r i e n t e d system looking at the problems of knowledge representation, and some effort has been spent on the understanding of text as well as questions.
While few NLIs have reached the commercial marketplace, many systems have c o n t r i b u t e d to advancing the state of the art.
Several representative systems and the problems they addressed are described in this section.
i. CONVERSE [KELLT1] used formal syntactic analysis to g e n e r a t e surfaceand d e e p s t r u c t u r e parsings together with formal semantic t r a n s f o r m a t i o n rules to produce queries for a built-in relational DBMS.
It was written in SDC LISP and ran on IBM 37@ computers.
Started in 1968, it was one of the first naturallanguage processors to be built for the purpose of querying a separate data m a n a g e m e n t system.
LADDER [HEND77] was designed to access large d i s t r i b u t e d databases.
it is implemented in INTERLISP, runs on a PDP-I@, and can interface to different DBMSs with proper configuration.
It uses a semantic g r a m mar and, like EUFID and most NLIs, a different grammar must be defined for each application.
The Lunar Rocks system LSNLIS [WOOD72] was the first to use the Augmented Transition Network (ATN) grammar.
Wrl~ten in LISP, it transformed formally parsed questions into representations of the first-order predicate calculus for deductive processing against a built-in DBMS.
PHLIQAI [SCHA77] uses a syntactic parser which runs as a separate pass from the semantic understanding passes.
This system is mainly fiB.
OVERVIEW OF EUFID EUFID is a general purpose naturallanguage front-end for database management.
The original design goals for EUFID were: to b e application independent.
This means that the program must be table driven.
The tables contain the dictionary and semantic information and are loaded with a p p l i c a t i o n s p e c i f l c data.
It was desired that the tables could be constructed by someone other than the EUFID staff, so t h a t users could build new applications on their o w n . to be database independent.
This means that the organization of the data in the database must be representable in tables that drive the query generator.
~ A database reorganization that does not change the semantics of the application should be transparen~ to the user.
written in a high level language; initially a customer required code to be written in FORTRAN, later we were able to use the "C" programming language.
to support different views data for security purposes.
of the The design which met these requirements is a modular system which uses an Intermediate Language (IL) as the output of the natural-language analysis system [BURG82].
This language represents, in many ways, the union of the c a p a b i l i t i e s of many "target" DBMS q u e r y languages.
The EUFID system consists of three major modules, not counting the DBM3 (see Figure I).
The analyzer (parser) module is table driven.
It is n e c e s s a r y only to properly build and load the tables to interface EUFID to a new application.
Mapping a question from its d i c t i o n a r y (user) representation to DBMS representation is handled by mapping functions contained in a table and applied by a separate module, t h e "mapper".
Each c o n tent (application dependent) word in the d i c t i o n a r y has one or more mapping functions defined for it.
A final stage of the mapper is a q u e r y l a n g u a g e generator containing the syntax of IL.
This stage writes a query in IL using the group/field names found by the mapper t o represent the user's concepts and the structural relationships between them.
This design satisfies t h e requirement of application independence.
ENGLISH QUESTION to be DBMS independent.
This means that it must be able to generate requests to different DBMSs in the DBMS's query language and that the interface of EUF~D to a different DBMS should not require changes to t h e NLI modules.
Transferring the same database with the same semantic content to another DBMS should be transparent to the natural-language users.
to run on a mini-computer that might possibly be different from the computer with the DBMS.
to have a fast response time, even when the question cannot be interpreted.
This means it must be able quickly to recognize unanalyzable constructs.
Figure i: EUFID Block Diagram to handle nonstandard or poorlyformed (but, nevertheless, meaningful) questions.
to be portable to various machines.
This means that the system had to be * We make a technical distinction between the words "question" and "query".
A question is any string entered by the user to the EUFID analyzer, regardless of the terminating punctuation.
This is consistent with the design since EUFID treats all input as a request for information.
A query is a formal representation of a question in either the EUFID intermediate language IL, or in the formal query language of a DBMS.
For each different DBMS used by a EUFID application, a "translator" module needs to be written to convert a query in IL to the equivalent in the DBMS query language.
This design satisfies the requirement of DBMS independence.
Other modules are the system controller, a "help" module, and a " s y n o n y m editor".
An "Application Definition Module" is used off-line to assist in the creation of the run-time application description tables.
The following subsections descrloe each of the modules of the EUFID system, and give our m o t i v a t i o n for design.
i. A~plication Definitions Bringing up a new a p p l i c a t i o n is a long and complex process.
The d a t a b a s e d e f i n i t i o n must be transmitted to EUFID.
A large corpus of "typical" user questions must be collected from a representative set of users and from these the dictionary and mapping tables are designed.
A "semantic graph" is defined for the application.
This graph is implicitly realized in t h e dictionary where the nodes of the graph are the definitions of English content words and the c o n n e c t i v i t y of the graph is implied by the case-structure relationships defined for the nodes.
All d i c t i o n a r y and mapping-function are then entered into computer files which are processed by the Application Definition Module (ADM) to produce t h e run-time tables.
These final tables are complex structures of pointers, character strings, and index tables, designed to decrease access time to the information required by the analyzer and mapper modules.
data considered.
Frequently, desig~ :o,~s i d e r a t i o n s in the m a p p i n g f u n c t i o n list necessitate going back and m o d i f y i n g the content of the d i c t i o n a r y . This is an example of the o v e r l a p of the l i n g u i s t i c and database issues in assigning an interpretation to a question.
c. Database Representation The ADM, typically, needs to be run several times to "debug" the tables.
EUFID interfaces to three applications currently exist, and building tables for each new a p p l i c a t i o n took less time than the previous one, b u t it still requires several staff-months to bring up a new application.
a. User-View Representation The structure o f the data in the user's database is represented in two tables, called the CAN (for canonical) and REL (for relationships) tables.
Taking advantage of the fact that any database can be represented in relational form, EUFID lists each d a t a b a s e g r o u p as if it were a relation.
Group-to-group linkage (represented in the REL table) is d e a l t with as if a join* were necessary to implement the link.
For h i e r a r c h i c a l and network DBMSs the join will not be needed: the link is "wired in" to the d a t a b a s e structure.
EUFID nevertheless assumes a join m a i n l y in order to facilitate the writing of g r o u p t o g r o u p links in IL, which is a relational language.
The CAN table includes database-specific information for each field (attribute) of each group (relation), such as field name, containing group, name of d o m a i n from which attributed gets its values, and a pointer to a set of c o n v e r s i o n functions for numeric v a l u e s which can be be used to convert from one unit of m e a s ure to another (e.g., feet to meters).
These data are used by the run-time modules which map and translate the t r e e s t r u c t u r e d output of the analyzer to IL on the actual g r o u p / f i e l d names of the database, and then co the language of the DBMS.
These modules are d i s c u s s e d in the next sections.
2. The EUFID Analyzer All information on the user's view of the database is kept in the d i c t i o n ary.
The dictionary consists of two kinds of words and definitions.
Function words, such as p r e p o s i t i o n s and Conjunctions, are pre-stored in each a p p l i c a t i o n ' s d i c t i o n a r y and are used by the analyzer for direction on how to connect the semantic-graph nodes during analysis.
Content words are application dependent.
The d c r O o n s of content words are semantic-graph nodes.
The connectivity o the graph is indicated by semantic case slots and pointers contained in the nodes.
A form of semantic-case is used to indicate the attributes of an entity (e.g., adjectives, prepositional phrases, and other modifiers of a noun).
b. Mapping Functions The current version of the EUFID analyzer employs a variant of the CockeK a s a m i Y o u n g e r algorithm for parsing its input.
This classical nonpredictive b o t t o m u p algorithm has been used in a family of "chart parsers" developed by Kay, Earley, and others [AHO72].
The main features of these parsers are: (i) They use a r b i t r a r y c o n t e x t f r e e grammars.
There are no r e s t r i c t i o n s on rules which have l e f t r e c u r s i o n or other c h a r a c t e r i s tics which sometimes cause difficulty.
(2) They produce all possible parses of a given input string.
The g r a m m a r s they use may be ambiguous at either the nonterminalor t e r m i n a l s y m b o l levels.
In natural-language processing, this allows for a precise r e p r e s e n t a t i o n of * The t e r m "join" refers to a composite o p e r a t i o n between two relations in a relational DBMS.
The list of mapping functions is derived from the dictionary.
Every possible connection of every node has to be fiboth the syntactic and lexical ambiguities which may be present in an input sentence.
(3) They provide partial parses of the input.
Each non-terminal symbol derives some input substring.
Even if no such substring spans the entire sentence, i.e., no complete parse is achieved, analyses of various regions o f t h e s e n t e n c e a r e available.
(4) They are conceptually straightforward and easy t o implement.
The speed and storage considerations which have kept such parsers from being widely used in compilers are less relevant in the analysis o f short strings such as queries to a DBMS.
The grammar used b y the EUFID parser is essentially semantic.
The symbols of the grammar r e p r e s e n t t h e concepts underlying lexical items, and the rules specify the ways in which these concepts can be combined.
More s p e c i f i c a l l y, the concepts are o r g a n i z e d into a case system.
Each rule states that a given pair of constituents can be linked if the conc e p t u a l head of o n e constituent fills a case on the conceptual head of t h e other.
A degree of context sensitivity is achieved b y attaching predicates to the rules.
These predicates b l o c k application of t h e rules unless certain (usually syntactic) conditions hold true.
The parser uses syntactic information only "on demand", that is, only when such information is necessary to resolve semantic ambiguities.
This a d d s to its coverage and robustness, and makes it relatively insensitive to the phrasing variations which must be explicitly accounted for in many other systems.
3. Mapping to-field and g r o u p t o g r o u p tions of t h e database.
connecThe mapper makes use of a table of mapping functions.
The table contains at least one mapping function for every content word in the dictionary.
The analyzer's tree is traversed bottom up, applying mapping functions to each node on t h e way.
Mapping f u n c t i o n s are context sensitive with respect to those nodes below it in the tree: nodes that have already been mapped.
A new tree is g r a d u a l l y formed and connected this way.
Mapping functions may indicate that the map of a semantic-graph node is a database node (that is, a group or field name), o r a pre-connected sub-tree of database nodes.
The mapping function may also indicate removal of a database node or m o d i f i c a t i o n to the existing structure of the tree being constructed.
The new t r e e i s c r e a t e d in terms of the database groups and f i e l d s and i t s structure reflects the connectivity of the database.
A final stage of the mapper traverses this new tree and generates the EL statement of the query using a table of the syntax and keywords of EL and the database names from the tree.
The mapper module converts the output of the analyzer to input for the translator module.
Analyzer output is a tree structure where the nodes are semantic-graph nodes corresponding to the content words in the user's question and obtained from the dictionary.
An alternative method of mapping that is now being investigated involves breaking the process into two basic parts.
The first step would be to map the tree o u t p u t o f the analyzer t o an IL query on what C.
J. Date calls the "conceptual schema" of the database [DATE77].
A second step would take this IL input and re-arrange the schema connectivity (and names of groups and fields) from that of the conceptual schema to that of the actual target database, generating another IL query as input to the current translators.
Input to the translator module is a string in the syntax of IL which contains the names of actual groups and fields in the database.
The mapping algorithm, thus, has to make several levels of conversion simultaneously: it must convert a into a linear string it must convert into database names, and tree structure of tokens, semantic-graph nodes groupand fieldit must convert the connectivity of the tree (representing concept-toconcept linkage in English) into the (frequently very different) groupThe final run-time module in EUFID is a syntax translator that converts IL to the actual DBMS query language.
If necessary, the translator can also add access-path information related t o database search.
Currently, two translators have been written.
One converts IL to QUEL, a relatively simple conversion into the language of the relational database management system INGRES [STONY6].
The other translator converts IL into the query language of the World-Wide Data Management System (WWDMS) [HONE76] used by the Department of Defense, and also handles additional access path information.
This translator was quite difficult to design and build because of the highly procedural nature of the WWDMS query system.
The output of a translator is sent to the appropriate DBMS.
In the EUFID system running at SDC, a QUEL query is submitted directly to INGRES running on the same PDP-II/70 as EUFID.
For testing purposes, queries generated by the WWDMS translator were transmitted from a PDP11/70 to a Honeywell H6000 with a WWDMS database.
5. Application Description some coming from open-ended domains.
A I R E P has a network database structure and contains the same data s t r u c t u r e in four d i f f e r e n t files.
III LEVEL OF SUCCESS EUFID runs o n three d i f f e r e n t application databases.
The METRO a p p l i c a t i o n involves monitoring of shipping transactions between companies in a city called "Metropolis".
There are ten companies located in any one of three n e i g h b o r hoods.
Each company rents warehouse space for shipping/recelving transactions, and has local offices which receive goods.
The data is organized telationally using the INGRES database m a n a g e m e n t system.
That means that there are no n a v i g a t i o n a l links stored in the records (called "relations") and there is no predefined "root" to the database structure.
Access may be made from any relation to any other relation as long as there is a field in each of the two relations which has the same "domain" (set of values).
AIREP (ADP Incident REPorting) is a network database, implemented in WWDMS.
It c o n t a i n s reports about hardware and software failures and resolution of the problems in a large computer system.
Active problems are maintained in an active file and old, solved problems are moved to an historical file.
If a problem [s reported more than once, an abbreviated record is made for the additional report, called the "duplicate incident" record.
This means that there are four basic type of report: active incidents, duplicate incidents, historical incidents, and historical duplicate incidents.
In addition, there are records about sites, problems, and solutions.
The A P P L I C A N T database is a relational database implemented in INGRES that contains information about job applicants and their backgrounds.
The central entity is the "applicant", while other relations describe the a p p l i c a n t ' s specialties, education, previous employment, computer experience, and interviews.
Each database has d i f f e r e n t features chat may present problems for a naturallanguage interface but which are typical of 'real-world' applications.
METRO has relatively few entities but has complex relationships among them.
APPLICANT has many updates and many different values, Most of the EUFID d e s i g n g o a l s were actually met.
EUFID runs on a minicomputer, a DEC PDP 11/70.
It is application, database, and DBMS independent.
A typical q u e s t i o n is analyzed, mapped and translated in five to fifteen seconds even with g r a m m a t i c a l l y incorrect input.
The analyzer c o n t a i n s a good spelling corrector and a good morphology a l g o r i t h m that strips inflectional endings so that all inflected forms of words need not be stored explicitly.
A "synonym editor" permits the user to replace any word or string of words in the dicionary with another word or string, to accommodate personal jargon and expressability.
A "Concept Graph Editor s allows a database administrator to m o d i f y tables and define user profiles so that d i f f e r e n t users may have limited views of the data for s e c u r i t y purposes.
The analysis strategy, based on a semantic grammar, permits easy and natural paraphrase recognition, although there are linguistic c o n s t r u c t s it cannot handle.
These are d i s c u s s e d below.
An English word may have more than one definition without c o m p l i c a t i n g the analysis strategy.
For example, "ship" as a vessel and as a verb meaning "to send" can be defined in the same d i c t i o n ary.
Words used as database values, such as names, may also have m u l t i p l e definitions, e.g., "New York" used as the name of both a city and a state.
The mapper, despite its many limitations, can c o r r e c t l y map almost all trees output by the analyzer.
It is able to handle English c o n j u n c t i o n s, mapping them a p p r o p r i a t e l y to logical ANDs or ORs, and understanding that some "ands" may need to be interpreted as OR and vice-versa under certain c i r c u m s t a n c e s . It is able to g e n e r a t e calls on DBMS calculations (e.g., average) and user-defined functions (e.g., marine great-circle distance) if the user-function exists and is supported by the DBMS.
Questions involving time are interpreted in a reasonable way.
Functions are defined for "between" and "during" in the METRO application.
The AIREP application allows time comparisons such as "What system was running when incident J123 occurred" which require a test to see if a point in time is within an interval.
The mapper can translate "user values" (e.g., "Russian") to database values (e.g., "USSR"), and convert one unit of measure (e.g., feet) to another (e.g., meters).
EUFID c a n i n t e r f a c e to very complex relational and CODASYL-type databases having difficult n a v i g a t i o n and parallel structures.
In t h e AIREP application a consistent WWDMS navigational m e t h o d o l o g y is used to access non-key records.
The system c a n also map to t h e parallel, but not identical, structures for duplicate and historical incidents.
I n the INGRES applications, EUFID is able to use and correctly map to = r e l a tionship relations" which relate two or more other relations.
For example, the METRO relation =cw" contains a company name, a warehouse name, a n d a date.
This represents the initial business contact.
A user might ask, =When d i d C o l o n i a l start t o do b u s i n e s s w i t h Superior?
= or  When d i d b u s i n e s s b e g i n b e t w e e n C o l o n i a l and S u p e r i o r ? =, e i t h e r of which must ~oin both t h e c o m p a n y ( " c =) a n d t h e w a r e h o u s e ('w') relations t o the =cw" relation.
The system c o n t r o l module keeps a journal of all user-system interaction together with internal module-to-module data such as the IL for the user's question and the generated DBMS query.
The system also employs a very effective HELP module which, under certain circumstances, is context sensitive t o the problem affecting the user.
IV PROBLEMS APPLICANT database may wish to fill a specific Job opening while others may collect statistics on types of appli~ cants.
The language used for these two functions can be quite different, and it is n e c e s s a r y to have extensive interaction with cooperative users in order to characterize the kinds of dialogues they will have with the system.
Not only must representative language protocols be collected, but desired responses must be understood.
For example, to answer a question such as =What is t h e status of our forces in Europe =, the system must know whether 'our' refers to U.S. or NATO or some other unit.
The importance of this interaction between potential users and system developers should n o t b e underestimated, as it is the basis for defining much of the knowledge base needed by the system, and may also be t h e basis for eventual user acceptance o r rejection of the NLI system.
2. Value R e c o g n i t i o n This section describes problems associated with EUFID development that appear to be common to natural-language interfaces to database management systems.
They are loosely classified into the major areas Of application, language and database management issues, although there may be overlap.
Criteria for evaluating whether an application is appropriate for a natural-language front-end are also described.
A. APPLICATION DEFINITION PROBLEMS A "value = is a specific datum stored in the database, and is the smallest piece of data obtainable as the result o f a database query.
For example, in response to the question "What companies in North Hills shipped light freight to Superior?
= the METRO DBMS returns two values: "Colonial" and "Supreme'.
Values can also be used in a query to qualify or select certain records for output, e.g., in t h e above question "North Hills" and "Superior" are values that must be represented in the query to the DBMS.
As long as the alphanumeric values used in a particular database field are the same as words in t h e English questions, there are no difficult problems involved in recognizing values as selectors in a query.
There are three basic ways to recognize these value words in a question.
They can be explicitly listed in the dictionary, recognized by a pattern or context, or found in the database itself.
If the value words are stored in the dictionary, they can be subject to spelling correction because the spelling corrector uses the dictionary to locate words which are a close match to unrecognized words in a question.
This means, though, that all possible values and variant legitimate spellings of values for a concept must be put either into the dictionary or into the synonym list.
This is reasonable for concepts which have a small and controlled set of _values* such as the names of the * A set of v a l u e s is called a "domain,r.
The primary issue in this area is concerned with problems of defining, creating, and bringing up the necessary data for a new application.
The discussion points out the difficulties associated with systematic knowledge acquisition.
I. User Model A single database may be used by different groups of users for different purposes.
For example, some users of the ficompanies in METRO, but may u n w i e l d y for large sets of values.
become If a value can be recognized by a pattern, it is not n e c e s s a r y to itemize all instances in the dictionary.
For example, a date may be entered as "yy/mm/dd" so that any input matching the pattern "nn/nn/nn" is recognized as a date.
This is the approach used for dates and for names of applicants in the A P P L I C A N T database, where names of people match the pattern "I.I.Lastname".
In another approach, OnLine English [CULL80] and Intellect [HARR78, EDP82] (two v a r i a t i o n s of ROBOT) used the database to recognize values.
This is a s a t i s f a c t o r y solution if the database is small or if the small number of d i f f e r e n t values is stored in an index accessible to the NLI, and if the values in the database are suitable for use in English questions.
Each of these solutions has disadvantages.
If values are stored in the d i c t i o n a r y there may be many different ways to spell each particular value.
For example, the company name for "System Development Corporation" may also be given as "S.D.C.", "S D C", or "System Development Cotp".
While each d i f f e r e n t spelling could be entered as a synonym for the "correct" spelling in the database, this would result in an enormous proliferation of the d i c t i o n a r y entries and problems with concurrency control between the updates directed to the data m a n a g e m e n t system and the updates to the dictionary.
A creative solution might he to define rules for synonym generation and apply them to database updates.
A somewhat different example is from the A P P L I C A N T application which has many open ended domains, such as names of applicants and previous employers.
In this case, the application designer may have to treat certain fields as "retrieve-only", meaning that the data can be asked ~or but not used as a selection criterion.
A database with a large number of retrieve-only fields may be a poor candidate for an NLI.
Patterns can be used only if they can be enforced, and probably few values really fit the patterns nicely.
Proper names ate a poor choice for patterns because of variations such as middle initial or title such as "Dr".
or "Jr.".
Also, spelling correction cannot be performed unless the value is stored in the dictionary.
Finally, the solution of using the database itself to recognize v a l u e s is u n s a t i s f a c t o r y to a general NLI for anything other than trivial databases, unless an inverted index of values is easily accessible.
There are the problems of spelling c o r r e c t i o n and synonyms for database values, the inefficiency involved in accessing the DBMS for every unrecognized word, and the d i f f i culty of knowing which fields in the d a t a b a s e to search.
3. Semantic Variation By Value Databases are generally designed with a m i n i m u m number of d i f f e r e n t record types.
When there are entities which are similar, but p o s s i b l y have a small number of a t t r i b u t e s which are not shared, the entities will be stored in the same record type with null values for the attributes that do not apply.
The user, in his questions, may view these similar entities as very d i f f e r e n t e nt i t i e s and talk about them d i f f e r e n t l y . We did not encounter the problem with METRO or AIREP.
For example, in METRO, the user asks the same type of questions about the c o m p a n y named "Colonial" as about the company named "Supreme".
In APPLICANT, however, each a p p l i c a n t has a set of "specialties" such as "computer programmer", "a c c o u n t i n g clerk", or "gardener".
These are all stored as values of the s p e c i a l t y field in the database.
Unfortunately, in this case different specialties evoke completely d i f f e r e n t concepts to the end user.
The user may ask q u e s t i o n s such as, "What p r o g r a m m e r s know COBOL?", "Who can program in COBOL?", and "How m a n y a p p l i c a n t s with a s p e c i a l t y in computer programming applied in 1982?".
Notice the new nouns and verbs that are introduced by this s p e c i a l t y name.
A value domain such as specialties should be handled with an ISA hierarchy.
Each d i f f e r e n t type of s p e c i a l t y such as gardener or programmer could have a different concept that is a subset of the concept "specialty".
Some questions could be asked about all s p e c i al t i e s and others could be directed only to certain subconcepts.
However, there is no [SA hierarchy in EUFID, and it would have been inefficient to treat each specialty and subspecialty as a separate concept since there are 30 specialties and 196 subspecialties.
Therefore, we required the users to know the exact values, to know which values are for s p e c i a l t i e s and which are for subspecialties, and to ask q u e s t i o n s using the values only as nouns.
This is not "user friendly".
Even if it were possible to build a different concept for each different skill, there is an update problem.
When a new value is a d d e d to a v a l u e domain where there ace uniform semantics (as in adding a new company name in METRO), the new value is simply attached to the existing concept, when the new value has different semantics, t h e newly associated concepts, nouns, and verbs cannot be added automatically.
If t h e NLI supports an ISA hierarchy, someone w i l l need to categorize t h e new value and add a new node to the hierarchy or specify a position in the hierarchy.
4. Automation of D e f i n i t i o n subset who l i v e in Nevada.
One s o l u t i o n is to provide commands that allow u s e r s to d e f i n e s u b s e t s of the database to which to address questions.
This removes the ambiguity and speeds up retrieval time on a large d a t a b a s e . However, it moves the NLI interaction toward that of a structured query language, and forces the user to be a w a r e of the level of subset b e i n g accessed.
It is also difficult to implement because a subset may involve projections and joins to build a new relation containing the subset.
The NLI must be able dynamically and temporarily to change the mapping tables t o map t o this new relation.
2. Intelll~ent Interaction A natural-language interface system will not be practical u n t i l a new a p p l i c a t i o n can b e installed easily.
"Easily" means that the end-user organization must be able to create and modify the driving tables for the application relatively quickly without the help of the NLI developer, and must b e able to use the NLI without restructuring the d a t a b a s e . Each EUFID application required "handcrafted" tables that were built by the development staff.
Each new application was done in less time than the previous one, but still required several staff-months to bring up.
Clearly, the goal of facilitating the building of the tables by end users was not met.
Computer-assisted tools for defining new applications are a prerequisite for practical NLIs.
B. LANGUAGE PROBLEMS One of the EUFID design goals was to r e s p o n d promptly either with an answer or with a message that the question could not be interpreted.
The system handles spelling or typographical errors by interacting with the user t o select the correct word.
However, when all of the words are recognized but do n o t connect semantically, It is difficult to identify a single point in analysis which caused the failure.
It is i n this a r e a that the absence of a syntactic mechanism for determining well-formedness was most noticeable.
There are times when a question has a proper syntactic structure, but co n t a i n s semantic relationships u n r e c o g n i z a b l e to the application as in "What is the locatlon of North Hills?".
A response of "Location is not defined f o r North Hills in this appllcacion" should be derivable from the recognizable semantic failure.
Similarly, it would be useful to have a framework for interpreting partial trees, as in the question "What companies does Mohawk ship to"? where Mohawk is not a recognized word within the application.
An appropriate response might be "Companies ship to receiving offices and companies; Mohawk is neither a receiving office nor a company.
The names of offices and companies are ...".
Interpretation of partial a n a l y s e s is not possible within the EUFID system; it either succeeds or fails completely.
3. Yes/No Questions The basic approach to language analysis in EUFID involves a bottom up parser using a semantic grammar.
The symbols of the grammar are concepts underlying lexical items, and the rules of the grammar ace based o n a case framework.
Essentially syntactic information is used only when needed to resolve ambiguity.
The language features that this technique has t o handle are common to any NLI, and some of the problem areas are described in the following sections.
I. Anaphora and Ellipsis To support natural interaction it is desirable to allow the use of anaphoric reference and elliptical constructions across sentence sequences, such as "What applicants know Fortran and C?", "Which of them live in California?", "In Nevada?", "How many know Pascal?'.
One of the biggest problems is to define the scope of the reference in such cases.
In the example, it is not clear whether the user wishes to retrieve the set of all applicants who know Pascal or only the II In normal NLI interaction users may wish to ask "yes/no" questions, yet no DBMS has the ability to answer "yes" or "no" explicitly.
The EUFID mapper maps a yes/no question into a query which will retrieve some data, such as an " o u t p u t identifier" or default name for a concept, if the answer is "yes" and no data if the answer if "no".
However, the answer may be "no" for several reasons.
For example, a "no" response to the question "Has John Smith been interviewed"? may mean that the database has knowledge about John Smith and about interviews and Smith is not listed as having had an interview*, or the database knows about John Smith and no data about interviews is available.
A third p o s s i b i l i t y could be that the database has information about John Smith and his employment situation (already hired), and the response might include that information, as in "No, but he has already been hired'.
4. Conjunctions uncertain whether they should be returned in the answer.
It is also d i f f i c u l t to take a c o m p l e m e n t of a set of data using the m a n y data m a n a g e m e n t systems that do not support set o p e r a t o r s between relations.
Questions which require a "yes" or "no" response are difficult to answer because often the "no" is due to a p r e s u p p o s i t i o n which is invalid.
This is e s p e c i a l l y true with negation.
For example, if the user asks, "Does e v e r y company in North Hills except Supreme use NH2?", the answer may be "no" because Supreme is not in North Hills.
The current i m p l e m e n t a t i o n of EUFID does not allow explicit negation, a l t h o u g h some n e g a t i v e concepts are handled such as "What c o m p a n i e s ship to companies other than Colonial?".
"Other than" is interpreted as the "!-" o p e r a t o r in e x a c t l y the same way that "greater than" is interpreted as ">".
C. INTERPRETATION AND DATABASE ISSUES T h e s c o p e of c o n j u n c t i o n s is a difficult problem for any parsing or analyzing algorithm.
The n a t u r a l l a n g u a g e use of "and" and "or" does not n e c e s s a r i l y correspond to the logical meaning, as in the question "List the applicants who live in C a l i f o r n i a a n d Arizona.".
Multiple c o n j u n c t i o n s in a single q u e s t i o n can be ambiguous as in "which minority and female applicants know Fortran and Cobol?'.
This could be interpreted with logical "and" or with logical "or" as in "Which a p p l i c a n t s who are minority or female know either Fortran or Cobol?".
The EUFID mapper will change English "and" to logical "or" when the two phrases within the scope of the conjunction are values for the same field.
In the example above, an applicant has only one state of residence.
Many q u e s t i o n s make perfect sense semantically but are difficult to map into DBMS q u e r i e s because of the d a t a b a s e structure.
The problems become worse when access is through an NLI because of increased e x p e c t a t i o n s on the part of the user and because it may be d i f f i c u l t for a help system a d e q u a t e l y to d e s c r i b e the problem to the user who is unaware of the database structure.
I. IL Limitations Nepption Negative requests may contain explicit negative words such as "not" and "never" or may contain implicit negatives such as "only", "except" and "other than" [OLNE78].
The interpretation of negatives can be very difficult.
For example, "Which c o m p a n i e s did not ship any perishable freight in 1976" could mean either "Which (of all the companies) shipped no perishable freight in 1976"? or "Which (of the companies that ship perishable freight) shipped none in 1976?'.
Moreover, if some companies were only receivers and never shippers it is "-"~e is the important d i s t i n c t i o n between a "closed world" database in which the assumption is that the database covers the whole world (of the application) and an "open world" database in which it is understood that the database does not represent all there is to the real world of the application.
In the open world database, which we encounter most of the time, a response of "not that this database knows of" might be more appropriate.
~Z The design of the IL is critical.
It must be rich enough to support retrieval from all the underlying DBMSs.
However, if it c o n t a i n s c a p a b i l i t i e s that do not exist in a specific DBMS, it is difficult to d e s c r i b e this d e f i c i e n c y to the user.
In APPLICANT, the user cannot get both the major and minor fields of study by asking "List applicants and field of study", because a limitation in the EUFID IL prevents making two joins between education and subject records.
This problem was corrected in a subsequent version of IL with the addition of a "range" statement similar to that used by QUEL [STON76].
The current IL does not contain an "EXISTS" or "FAILS" operator which can test for the existence of a record.
Such an operator is frequently used to test an interrecord link in a network or hierarchical DBMS.
It is needed to express "What problems are unsolved"? to the AIREP application, which requires a test for a database link between a set and a solution Mixed Case Values set.
generate the IL q u e r y EUFID allows a value in the database to be upper or lower case and will c o n v e r t a value in the question either to all upper or all lower case in the IL, or leave it as input b y the user.
If the d a t a b a s e values are mixed case, it is not possible to convert the user's input to a single case.
If the user does not enter each letter in t h e p r o p e r c a s e, t h e v a l u e will n o t match.
3. Granularit~ Differences retrieve [cct.scname] where (cct.date  198~) and (cct.lf >{retrieve [avg (cct.lf)] where (cct.date 1980)}) Here, =cct" i s t h e name o f the companyto-company transaction relation.
" S c n a m e " is the name of a shipping company in this relation.
Note again that the qualification on " 1 9 8 ~ " n e e d s to be done both inside and o u t s i d e the nested p a r t o f t h e query.
In the query language for INGRES such a request is expressed in a manner very similtar t o t h e IL e x p r e s s i o n s . For WWDMS a very complex procedure is generated.
In all cases, t h e DBMS n e e d s to answer the inner request and s a v e t h e result for usa in qualifying the outer request.
There are many database management systems that cannot handle such questions and t h e s e I L s t a t e m e n t s cannot be translated into the system's query language.
5. Inconsistency In Retrieval The NLI user is n o t expected to understand exactly how d a t a is stored, and yet must understand something about the g r a n u l a r i t y of the data.
Time fields often cause problems because time m a y be given by year or by fractions of a second.
U s e r s may make t i m e comparisons that require more granularity than is stored in t h e database.
For example, t h e user can ask "What incidents were reported at SAC while system release 3.4 was installed?".
If incidents were reported by day but system release dates were given by month, the system would return i n c i d e n t s which occurred in the days of the month before the system release was i n s t a l l e d . 4.
Nested Queries A very simple question in English can turn into a very complicated request in t h e query language if it involves retrieval of data which must b e used f o r qualification in another part of the same query.
In IL these are called "nested queries".
Most o f t e n some qualification needs to be done b o t h "inside" and "outside" t h e clause of the query that does the internal retrieve.
For example, t h e question "What i n c i d e n t at SAC had the longest d o w n t i m e ? " f r o m o u r AIREP a p p l i cation i s e x p r e s s e d i n I L as retrieve [INCA.
ID] where (INCA.SITENAME = "SAC") and (INCA.DNTM [retrieve [ max (INCA.DNTM)] where (INCA.SITENAME = "SAC")}) The nested part of t h e query is enclosed in braces.
"INCA" is the database name of the active incident records.
Notice that removing the "INCA.SITENAME = 'SAC'" clause from either the inner or outer query would result in an incorrect formulation of the question.
A similar example from the METRO application is the question, "What company shipped more than the average amount of light freight in 198~"? which will 13 The NLI presents a uniform view of all d a t a b a s e s a n d DBMSs, but it is difficult to truly mask all differences in the behavior o f t h e DBMSS b e c a u s e t h e y d o n o t all process the equivalent query in the same way.
For example, when data are retrieved from two relations in a relational database, the two relations must be J o i n e d on a common attribute.
The answer forms a new relation which may be displayed to t h e user o r stored.
Since the join clause acts as qualification, a record (tuple) in either relation which has no corresponding t u p l e in t h e other relation does not participate in the result.
This is a different concept from the hierarchical and network models where the system retrieves all records from a master record and then retrieves corresponding records from a subfile.
This difference can cause anomalies with retrieval.
For example, in a pure relational system "List applicants and thei~ interviews" would be treated as "List applicants who have had interviews together with their interview information".
A h i e r a r c h i c a l or network DBMS would treat it as "List all applicants (whether or n o t they have been interviewed) plus any interview information that exists".
This second interpretation is more likely to be the correct one.
fiD. OVERALL NLI DESIGN There are several problems that affect the selection of a p p l i c a t i o n s for the NLI.
Some d a t a b a s e s and data m a n a g e ment systems may not be a p p r o p r i a t e targets for natural-language interfaces.
Some DBMS functions may be d i f f i c u l t to support.
It is important to have a clear understanding of these problems so that the NLI can mediate between the user view, as represented by the naturallanguage questions, and the underlying d a t a b a s e structure.
i. ~ Design C o n s i d e r a t i o n map q u e r i e s and t o explain problems to t h e u s e r when t h e m a p p i n g c a n n o t b e m a d e . However, there can be "reasonable" queries that cannot be answered d i r e c t l y because of the database structure.
Hierarchical DBMSs present the most problems with n a v i g a t i o n because access must start from the root.
For example, if the APPLICANT database were under an hierarchical DBMS, the q u e s t i o n "List t h e s p e c i a l t i e s for each applicant" could be answered directly but not "What are the specialties"? as there would be no way to get to the s p e c i a l t y records except via particular applicant records.
An array allows more than one instance of a field or set of fields in a single record.
There may be arrays of values or even arrays of sets of values in nonrelatlonal databases.
When the user retrieves a field that is an array the DBMS requires a subscript into the array.
Either the user must s p e c i f l y this s u b s c r i p t or the NLI must map to all members of the array with a test for missing data.
3. Class of DBMS to Supp%rt For any d a t a b a s e there are naturallanguage q u e s t i o n s that cannot be interpreted because the concepts involved lle outside the world of the database.
Questions can also involve structural complexity that is n o t r e p r e s e n t a b l e in the DBMS q u e r y language.
A p a r t i c u l a r l y difficult d e c i s i o n in the overall design of an NLI is the issue of where in the chain of events of processing a user's question into a DBMS q u e r y to trap these q u e s t i o n s and stop processing.
One approach is to decide that if a question is not meaningful to the world of the d a t a b a s e it should not be m e a n i n g ful to the NLI and, therefore, not analyzable on semantic grounds.
Another assumes that if the NLI can analyze a question that cannot be asked of the database, it has a much better chance of d e s c r i b i n g to the user what is wrong with the question and how it might be rephrased to get the desired information.
Codd made good use of the dialogue procedures of the RENDEZVOUS [CODD74] system to avoid questions that the DBMS could not handle, as well as avoiding g e n e r a t i o n of DBMS queries that did not represent the user's intent.
Such a system, however, requires a very large semantic base (much larger than that of the database) in order to make meaningful communication with the user during the dialogue.
2. Class of Database to Support For systems such as EUFID, the database must be organized within a data m a n a g d m e n t system so that the data is structured and individual fields are named.
If the data is just text, the EUFID approach cannot be used.
Current NLI systems are de s i g n e d to be used interactively by a user, which means that the DBMS should also have an interactive query language.
However, noc all data m a n a g e m e n t systems are interactive.
WWDMS [HONE76] has a user query language, b u t queries are entered into a batch job queue and answers may not return for many minutes.
If an Nil front end is to be added to such a DBMS, i~ must have the capability to generate query programs without any access to the database for parsing or for processing the returned answer.
The query language should support operations equivalent to the relational o p e r a t i o n s of select, project, and join.
Also, the query language should support some arithmetic capability.
Most have aggregate functions such as SUM and COUNT.
WWDMS does not have an easy-touse average operation, but it does have a procedural language with arithmetic operators so that EUFID can produce a "query" that p r o c e d u r a l l y calculates an average.
Basic c a l c u l a t i o n s should be supported such as " a g e = t o d a y b i r t h d a t e " . It is also d e s i r a b l e to be able to call special functions to do complex c a l c u l a t i o n s Some databases are simply not good candidates for an NLI because of characteristics mentioned in previous sections such as many retrieve-only fields, or domains that have a high update rate but cannot be recognized by a pattern.
There are also some structural problems chat must be recognized.
If the database contains "flat" files about one basic entity, it is reasonably easy to fisuch as required in navigational calculations a naval database.
the input standardize must be values, controlled to Support for Metadata Metadata is data about the data in the database.
It would be able to tell the user of the METRO application, for example, the kind of information the database has for warehouses and other entities in the application.
Such metadata might be extensions of active integrated data dictionaries now available i n some DBMSs.
I n an a p p l i c a t i o n l e v e l system the user should be able to query the metadata to learn about the structure of the database.
A different mode, such as the menus used by the EUFID help system, could be used to access metadata, or English language questions to both meta information and the database could be supported.
there should be few fields than have values that change rapidly, cannot be recognized by a pattern, and that must be used in qualification, the users of the NLI should have a common use for the data and a common vlew of the data, and there must be some user who understands the questions that will be asked and is available to work with the d e v e l o p e r s of the NLI.
Updates Some potential users would like a n a t u r a l l a n g u a g e interface to include the capability to update the database.
Currently, updating through any high level view of the database should be avoided, especially when the view contains joins or derlve4 data, because of the risk of inadvertently entering incorrectly-interpreted data.
SUMMARY AND CONCLUSIONS We believe that current system development is limited by the need for good semantic modelling techniques and the length of time needed to build the knowledge base required to interface with a new application.
When the knowledge base for the NLI is developed, the database as well as sample input must be considered in the design.
Parsing of questions to a database cannot be divorced from the database contents since semantic interpretation can only be determined in the context of that database.
On the other hand, a robust system cannot be developed by considering only database structure and content, because the range of the questions allowed would not accurately reflect the user view of the application and also would not account for all the information that is inferred at some level.
For many years, researchers have been attempting to build robust systems for natural-language access to databases.
It is not clear that such a system exists for general use [0SI79].
There are problems that need to be solved on both the front end, the parsing of the English question, and the back end, the translation of the question into a data management system query.
It is important to understand the types of requests, types of functions, and types of databases that can be supported by a specific NLI.
Some general guidelines that can be applied to the selection of applications for current NLI front ends are suggested below: lo the underlying DBMS should interactive query language, have an the DMS view should be relational or at least support multiple access paths, the database arrays either tures, should not contain of values or of strucACKNOWLEDGEMENTS We would like to acknowledge the many people who have contributed to EUFID development: David Brill, Marilyn Crilley, Dolores Dawson, LeRoy Gates, Iris Kameny, Philip Klahr, Antonio Leal, Charlotte Linde, Eric Lund, Fillp Machi, Kenneth Miller, Eileen Lepoff, Beatrice Oshika, Roberta Peeler, Douglas Pintar, Arie Shoshani, Martin Vago, and Jim Weiner.
REFERENCES [AHO72] Aho, A.
V. and J.
D. Ullman.
"The Theory of Parsing, Translation, and Compiling", Vol.
I: Parsing, Prentice-Hall, 1972, pp.
314-23Z. [BURGBff] Burger, J.
F . "Semantic Database Mapping in EUFID", Proceedings of the 198Z ACM/SIGMOD Conference, ~3"n~-a'-o~caY-'-Ca~., May 14-16, 198ff.
[BURG82] Burger, J.
F. and Marjorie Templeton.
"Recommendations for an Internal Input Language Eor the Knowledge-Based System', System Development Corporation internal paper N-(L)-24890/021/00, January 5, 1982.
[CODD74] Codd, E.
F., "Seven Steps to Rendezvous with the Casual User', Proc.
IFIP TC-2 Working Conference on Data-'5"~e'-~a~a~emen~ ~ystems, Car ~ gese, Corsica, April 1-5, 1974, in J.
W. Kimbie and K.
I. Koffeman (Eds.), "Data Base Management" North-Holland, 1974.
[CULL80] Cullinane Corporation, "IQS Summary Description", May 1980.
[DATE77] Date, C.
J., "An Introduction to Database Systems', second edition, Addison-Wesley Publishing, Menlo Park, CA, 1977.
[EDP82] "Query Systems for End Users", EDP Analyzer, Vol.
20, No.
9, September, 1982.
[HARR78] Harris, L.
R., "The ROBOT System: Natural Language Processing Applied to Data Base Query', Proceedings ACM 78 Annual Conference, 1978.
[HEND77] Hendrix, G.
G., E.
D. Sacerdoti, D.
Sagalowicz, and J.
Slocum, "Developing a Natural Language Interface to Complex Data" SRI Report 78-305, August 1977.
[HONE76] Honeywell, WWMCCS: World Wide Data Management System User's Guide, Honeywell DE97 Ray.3, April 1976.
[KELL71] Kellogg, C.
H., J.
F. Burger, T.
billet, and K.
Fogt, "The CONVERSE Natural Language Data management System: Current Status and Plans", Proceedings of the ACM SZmposium on :ntormation ~ ~ a n d ~etrleval-~, University o Maryland, College Park, MD, 1971, pp.
33-46. [MYLO76] Mylopoulos, J., A.
8 o r g i d a, P.
Cohen, N.
Roussopoulos, J.
Tsotsos, and H.
Wong, "TORUS: A Step Towards Bridging the Gap between Data Bases and the Casual User", in Information Volume 2 1976, Pergamon Press, pp 49-64.
[OLNE78] Olney, John, "Enabling EUFID to Handle Negative Expressions", SDC SP-3996, August 1978.
[OS179] Operating Systems, Inc., "An Assessment of Natural Language Interfaces for Command and Control Database Query", Logicon/OSI Division report for WWMCCS System 16 [SCHA77] Scha, R.
J. H., "Phillips Question-Answering System PHLIQAI", in SIGART Newsletter Number 61, February 1977, Association for Computing machinery, New York.
[SIMM65] Simmons, R.
F., "Answering English Questions by Computer -a Survey', Comm.
ACM 8,1, January 1965, 53-70.
[STON76] Stonebraker, M., et.
al., "The Design and Implementation of INGRES', Electronics Research Laboratory, College of Engineering, University of California at Berkeley, Memorandum No.
ERL-M577, 27 January 1976.
[TEMP79] Templeton, M.
P., "EUFID: A Friendly and Flexible Frontend for Data Management Systems", Proceedings of the 1979 National Conference Association of Computational Linguistics, August, 1979.
[TEMP80] Templeton, M.
P., "A Natural Language User Interface", Proceedings of "Pathwazs ~o System rn~ri%7", washington DYC.
C a h ~ o ACM, 1980.
[THOM69], Thompson, F.
B., P.
C. Lockemann, B.
H. Dostert, and R.
Deverill, "REL: A Rapidly Extensible Language System", in Proceedings of the 24th ACM National Conference, s~ociation--"~or Computing machinery, New York, 1969, pp 399-417.
[WALT77] Waltz, D.
L., " N a t u r a l Language Interfaces", in SIGART Newsletter Number 61, F e b r u a r y ' ~ 7, Association for Computing machinery, New York.
[WALT78] Waltz, D.
L., "An English language Question Answering System for a Large Relational Database", Communications of the ACM 21, 7(July 1978), pp 526-539.
[WOOD72] Woods, W.
A., R.
M. Kaplan, B.
Nash-Webber, The Lunar Sciences N a t u r a l L a n @ u a ~ e " r n f o r m a t i o n ' System ~'~Report, Report number~, Bolt, Beranek, and Newman, Inc., Cambridge, MA, 15 June 1972 .
INTRODUCING ASK, A SIMPLE KNOWLEDGEABLE SYSTEM Bozenn H.
Thompson F r e d e r i c k B.
Thompson California Inatitnce of Technology Pasadena, California 91125 ABSTRACT ASK, ~ ~ i m p l e K n o w l e d g e a b l e S y s t e m, i s a t o t a l system for the structuring, manipulation and communication of information.
It is a simple system in t h e sense thaC its development concentrated on c l e a n e n g i n e e r i n g solutions to w h a t c o u l d be d o n e now w i t h g o o d r e s p o n s e t i m e s. The user interface is a limited dialect of English.
In contrast to expert systems, in which experts build the knowledge base and users make u s e o f t h i s e x p e r t k n o w l e d g e, ASK i s a i m e d a t t h e u s e r who w i s h e s t o c r e a t e, test, modify, extend a n d m a k e u s e o f h i s own k n o w l e d g e b a s e . It is a s y s t e m for a research team, a m a n a g e m e n t or military staff, or a business office.
some h a v e t h e f o l l o w i n g n u m b e r a t t r i b u t e s : speed length beam >List the destinations a n d home p o r t o f each ship, ship destination home p o r t Ubu New York Naples Tokyo --Morn 0slo Tokyo Kittyhawk Naples Boston Boston -London This paper is designed to give you a feel for the general performance of t h e ASK S y s t e m a n d overview of its operational capabilities.
To Chin end, the movie you see will continue throughout the talk.
Indeed, the talk itself is a commentary on t h i s b a c k g r o u n d m o v i e . The m o v i e i s bona f i d e and in real time, i t i s o f t h e ASK S y s t e m i n action.
(Many o f t h e i l l u s t r a t i o n s from the movie are reproduced in the written paper.) I.
ASK AS A DATABASE SYSTEM A.
Examples o f ASK English To i n t r o d u c e a few examples you to ASK, we w i l l s t a r t o u t w i t h of queries of a simple data base The uninitiated user may wish London London N e w York --North Scar London New York gimitz London Norfolk Saratoga unknown Norfolk >What c i t i e s a r e t h e home p o r t s o f s h i p s whose d e s t i n a t i o n i s London?
Boston London New York Norfolk >Are t h e r e s h i p s t h a t do n o t h a v e a c a r g o ? yes >What i s t h e number o f New York s h i p s ? There are 2 answers: ( 1 ) New York ( d e s t i n a t i o n ) ships 2 ( 2 ) New York (home p o r t ) s h i p s 1 >How many s h i p s a r e t h e r e w i t h l n e g t h g r e a t e r t h a n 600 f e e t ? Spelling correction: " l n e g t h " to " l e n g t h " 4 >What ships t h a t carry wheat go to London or Alamo Oslo? ships that carry wheat London Maru Oslo Alamo >Does the Maru carry wheat and go co London? yes concerning ships.
simply to ask: >How many ships are there? 7 >What is known about ships? some are in the following classes: Navy freighter old S.
The ASK Data Structures A l t h o u g h in the t e r m i n o l o g y of data base theory, ASK can be considered as an "entityrelation" system, ASK retains its information in records w h i c h are interlinked in a s e m a n t i c net.
One reason we refer to ALE as simple is because ic uses only a few kinds of nodes in its s e m a n t i c tanker a l l have t h e f o l l o w i n g a t t r i b u t e s : destination home p o r t some have t h e f o l l o w i n g a t t r i b u t e s : cargo a l l have t h e f o l l o w i n g number a t t r i b u t e s : age 17 net, namely: fio Attributes Relations and the ctbvious c o r r e s p o n d i n g arcs.
We speak of this as the COAR structure.
A~tributes are single valued, e.g., "father", "home port", " t i t l e " ; relations may be m u l t i p l e valued, e.g., "child"~ "cargo", "author".
The d i f f e r e n c e between attributes and relations can be seen in the following p r o t o c o l . >What is the cargo and home port of the Maru? cargo home port wheat London >The home port of Maru is Boston.
London has been replaced by Boston as the home port of Maru.
>The cargo of Maru is coal.
coal has been added as the cargo of Maru.
>What i s the cargo and home port of the Maru? cargo home port wheat BosCon coal -->definition:long:paper whose number of pages e x c e e d s 49 Defined.
>definition:long:book whose number o f p a g e s e x c e e d s 800 Defined.
>What AI bibliography i t e m s a r e long?
There are 2 answers: (1) long:paper whose number of pages exceeds 49 Physical Symbol Systems A General Syntactic P r o c e s s o r (2) long:book whose number of pages exceeds 800 Human Problem Solving >What long books were written in 19727 long:book whose number of pages exceeds 800 Human Problem Solving Family relationships make for a g o o d illustration of definitions; we switch to a small family relationship context.
>What are attributes? individual/individual attributes : spouse >What are relations? individua I/individual relations : parent >What are classes? individual classes : male female >What are definitions? definition:mother :female parent definition: father :male parent definition:child:converse of parent definition:sibling:child of parent bur not oneself definition'cousin:child of sibling of parent >List the father and mother of each of Billy Smith's cousins.
Billy Smith's cousins father mother Baby Boyd R o b e r t Boyd J i l l Boy C.
Extendin K and Hodifyin~ I.
Definitions t h e Dat~ To make such a system more knowledgeable, one needs to be able co add d e f i n i t i o n s that e m b o d y interrelationships a m o n g the basic classes, objects, a t t r i b u t e s and relations of the data.
The simplest form of definition is synonym: >definition:tub:old Defined.
ship Although this form of definition allows one to introduce abbreviations and many forms of jargon, more extensive forms of definition are desirable.
Here are three illustrations using the same "ship" file as above.
In the third definition, note the use of quotes to create local '~ariables".
>definition:area:length * beam Defined >List the length, beam and area of each tub.
tub length beam area foot foot foot**2 Ubu 231.667 48 11120.016 Alamo 564.5 84 47418.
>definition:meter:39.37 * (foot / 12) Defined.
>beam of the Alamo squared in square meters? 655.526472343 square meters >definition:longest "ship":"ship" whose length is the maximum length of "ship"s Defined.
>What is the length in meters of the longest ship whose home port is Naples? 121.920243840 meters T h e n o t i o n of w h a t is l o n g m a y be q u i t e different in another context, say in the context of b i b l i o g r a p h y of a r t i f i c i a l intelligence literature.
18 2.
Verbs Most verbs e m b o d y k n o w l e d g e specific to the application in which they are used, the exceptions being the copula verbs.
Therefore the only verbs initially known to the ASK System are "to be" and "to have".
The user c a n add n e w v e r b s by paraphrase.
>verb:ships "go" to New York:destination of ships is New York Defined.
>verb:ships "carry" coal from London to Boston:ships have coal as cargo, have L o n d o n as home port and go to Boston Defined.
>Each old ship carries what cargo to each port? old ship port cargo Ubu New York oil Tokyo oil Alamo London wheat coal fi>What i s c a r r i e d by t h e Alamo? wheat coal >Wheat i s c a r r i e d to London from what p o r t s ? New York >What c i t i e s does t h e Alamo c a r r y wheat to?
London Pronouns and Ellinses >Create t h e a t t r i b u t e : r a t i n g The a t t r i b u t e r a t i n g h a s been a d d e d . >Create i n d i v i d u a l s : s e m i n a l, e x c e l l e n t, f a i r and i m p o s s i b l e The f o l l o w i n g i n d i v i d u a l s have been added: seminal excellent fair impossible >The r a t i n g o f W i n o g r a d ' s 1980 p a p e r i n Cognitive Science is excellent.
e x c e l l e n t h a s been added a s t h e r a t i n g o f W i n o g r a d ' 8 1980 p a p e r in C o g n i t i v e S c i e n c e >Rating o f A Framework f o r R e p r e s e n t i n g In p r a c t i c a l s y s t e m s f o r e x p e r t s, a b b r e v i a t e d f o r m s of a d d r e s s i n g t h e c o m p u t e r a r e common.
Thus the ability to h a n d l e p r o n o m i n a l and e l l i p t i c a l constructions are of considerable importance.
A l t h o u g h t h e r e has been p r o g r e s s i n t h e l a s t few years in the linguistic understanding of these c o n s t r u c t i o n s, many d i f f i c u l t i e s r e m a i n . However, b u i l d i n g on t h e work t h a t ham been a c c o m p l i s h e d, many o f t h e s e c o n s t r u c t i o n s can be h a n d l e d by t h e ASK System.
In o r d e r to a v o i d m i s l e a d i n g t h e u s e r when t h e c o m p u t a t i o n a l a l g o r i t h m does not make t h e c o r r e c t i n t e r p r e t a t i o n, echo i s u s e d t o i n f o r m t h e u s e r of t h e i n t e r p r e t a t i o n t h a t h a s been t a k e n . >Is t h e r e a s h i p whose d e s t i n a t i o n i s unknown? yes >What is it?
What is it [ship whose destination is ..knov.] ? Saratoga >Is its cargo wheat or c o a l ? I s i t s [ s h i p whose d e s t i n a t i o n i s unknown] cargo wheat or c o a l ? wheat no coal yes >Does t h e A l a m o ' s l e n g t h exceed t h a t of t h e Ubu? yes >What about t h e N o r t h e r n S t a r ? [the Northern Star?] does t h e A l a m o ' s l e n g t h exceed t h a t of t h e Northern Star? no >Is i t s cargo wheat?
Is its [Northern Star] cargo wheat? no >Is it that of the Ubu?
Is i t [Norther, Star cargo] that [cargo] of the Obu? yes >Wheat is carried by how many ships? 2 >Coal and oil? c o a l and o i l i s c a r r i e d by how many ship*? coal I oil 2 >by the Ubu? c o a l and o i l i s c a r r i e d by t h e Ubu? coal no oil yes Knowledge i s i m p o s s i b l e . i m p o s s i b l e h a s been added as t h e r a t i n g o f A remework f o r R e p r e s e n t i n g Knowledge.
>Scripts, P l a n s, Goals and U n d e r s t a n d i n g ' s rating is se~.nal.
s e m i n a l h a s been added a s t h e r a t i n g o f S c r i p t s, P l a n s, Goals and U n d e r s t a n d i n g . >The r a t i n g o f M i n s k y ' s paper i n The P s y c h o l o g y of Computer V i s i o n is seminal.
i m p o s s i b l e has been r e p l a c e d by s e m i n a l as t h e r a t i n g o f M i n s k y ' s p a p e r i n The P s y c h o l o g y o f Computer V i s i o n . > L i s t t h e a u t h o r of e a c h paper t h a t h a s a r a t i n g o f e i t h e r s e m i n a l or e x c e l l e n t . paper S c r i p t s, Plans, Goals and Understanding R.
C. Schauk A Framework f o r R e p r e s e n t i n g Knowledge M.
Minsky What Does I t Mean to U n d e r s t a n d N a t u r a l Language To Winograd > r e l a t i o n : keyword The r e l a t i o n keyword h a s been added.
>individuals:context, natural language, knowledge r e p r e s e n t a t i o n The f o l l o w i n g i n d i v i d u a l s have been added: c o n t e x t n a t u r a l l a n g u a g e knowledge representation >Context and knowledge r e p r e s e n t a t i o n a r e k e ~ o r d a of S c r i p t s, P l a n s, Goals and U n d e r s t a n d i n g and A Framework f o r R e p r e s e n t i n g Knowledge.
c o n t e x t knowledge r e p r e s e n t a t i o n have been added as keywords o f S c r i p t s, P l a n s, Goals and U n d e r s t a n d i n g . c o n t e x t knowledge r e p r e s e n t a t i o n have been added as keywords o f A Framework f o r R e p r e s e n t i n g Knowledge.
> N a t u r a l l a n g u a g e i s a keyword of S c r i p t s, P l a n s, Goals and U n d e r s t a n d i n g . n a t u r a l l a n g u a g e h a s been added a s keyword of Scripts, Plans, Goals and Understanding.
>definition:about "booka'*:converse of keyword of "books" Defined.
>What AI Sibliosraphy items are about knowledge r e p r e s e n t a t i o n ? S c r i p t s, P l a n s, Goals and U n d e r s t a n d i n g A Framework f o r R e p r e s e n t i n g Knowledge D.
Inheritanc~ 4.
E x t e n d i n 2 th_...eeVocabular 7 an...~dDa~a Bas~ New o b j e c t s, c l a s s e s, a t t r i b u t e s and r e l a t i o n s may be a d d e d a t w i l l . T h i s w i l l be i l l u s t r a t e d using the AI Bibliography.
19 Classes, as well as objects, may be t h e a r g u m e n t s or v a l u e s o f a t t r i b u t e s and r e l a t i o n s . T h i s r a i s e s t h e q u e s t i o n of i n h e r i t a n c e of properties and attributes.
The a n s w e r is to be fifound in the following protocol, using attribute of color; inheritance for relations h a n d l e d i n s i m i l a r ways.
>class: r a c i n g sloop, sports b o a t, Norwegian The following classes have been added: racing sloop sports boat Norwegian >attribute: color The a t t r i b u t e c o l o r h a s been a d d e d . >individuals: white, blue, b l a c k, g r a y The following i n d i v i d u a l s have b e e n added: white blue black gray >Saratoga is a racing sloop.
S a r a t o g a has b e e n added to r a c i n g s l o o p . >Racing s l o o p s a r e s p o r t s b o a t s . r a c i n g s l o o p s have b e e n added to s p o r t s boats.
>Alamo is industrial and Norwegian.
Alamo has b e e n added to i n d u s t r i a l Norwegian.
>The c o l o r o f s p o r t s b o a t s i s w h i t e . w h i t e h a s b e e n added a s c o l o r o f s p o r t s boats  >Maru's color is gray.
g r a y has b e e n added a s c o l o r o f Maru.
>Black i s t h e c o l o r of i n d u s t r i a l . b l a c k has b e e n added as t h e c o l o r o f industrial.
>Blue is the color of Norwegian.
b l u e h a s b e e n added a s t h e color of Norwegian.
>What i s the color of each s h i p ? There are 3 answers: (t) ship color Maru gray Saratoga white (2) Alamo as industrial ship color Alamo black (3) Alamo as Norwegian ship color Alamo blue the is There are 2 answers: ( i ) T h e r e a r e no p o r t s ( 2 ) T h e r e a r e no U.S. d e s t i n a t i o n s o f Maru.
> I s some E u r o p e a n p o r t a p o r t o f Maru?
The f o l l o w i n g word i s n o t i n t h e v o c a b u l a r y : portof Correction: Is some European port a port of Maru?
There is no port.
>London is Alamo's port.
London h a s b e e n added a s t h e p o r t o f Alamo.
> I s som E u r o p e a n p o r t a p r o t o f Maru?
Spelling corrections: "son" to "some" "prot" tO " p o r t " T h e r e i s no p o r t o f Maru.
>New York i s M a r u ' s p o r t . New York h a s b e e n added a s p o r t o f Maru.
> I s some E u r o p e a n p o r t a p o r t o f Maru.
I s some E u r o p e a n p o r t a p o r t o f Maru? no II.
INTEGRATION OF MULTIPLE OBJECT TYPES A.
Extension of COAR ~o Multiple Object Types So far we have i l l u s t r a t e d ASK using only two types of objects: capabilities individuals, e.g., "John Jones", "Maru" numbers, e.g., "34.6 feet", "length of Maru", "number of ships".
ASK has been designed, however, to facilitate many kinds of objects.
This is a capability orthogonal to the simple COAR s t r u c t u r e in that for any types of objects there m a y be c o r r e s p o n d i n g classes, attributes and relations.
B. An Examvle: E.
DiaKnostics Our objectives in the design respond to the experienced user: o o of ASK are to with the responses s/he desires in at l e a s t 90% o f t h e c a s e s ; w i t h a r e s p o n s e that includes what s/he desires, but perhaps additional information also, in 90% of t h e remaining cases; with a response, although oot the desired one, but one which clearly indicates the system's interpretation of the request in the remaining cases.
We will illustrate this m u l t i p l e object type capability with the additional object type: text.
Once this new object type was added (together with p r o c e d u r e s t o m a n i p u l a t e texts, i.e., a "word processor") then text classes, individual/text and text/individual a t t r i b u t e s and r e l a t i o n s w e r e immediately available.
It was a small task to add an e l e c t r o n i c mail s y s t e m to ASK; all that w a s required was an a d d i t i o n to the a u t h o r i z a t i o n procedure that assigned to each newly authorized person a new text class as his/her mail box.
>Create the t e x t / t e x t relation:comment The t e x t / t e x t r e l a t i o n co-~.ent has been added.
>Create a file: budget correspondence The text class budget correspondence has been added.
>File the Budget Proposal in budget correspondence.
Budget Proposal has been added to the text class budget correspondence.
>Who have I received mail from?
J o h n Smith Peter Jackson 20 This third objective calls for good diagnostics.
The diagnostic capabilities of ASK are illustrated in the following protocol.
>attribute:port The a t t r i b u t e p o r t has been added.
>What a r e t h e p o r t s and U.S. d e s t i n a t i o n s t h e Maru? of fi> D i s p l a y my m a i l f r o m J o h n S m i t h . F r e d, Your B u d g e t P r o p o s a l l o o k s good t o me.
S u g g e s t you s u b m i t i t a s i s . John > F i l e i t i n my b u d g e t c o r r e s p o n d e n c e f i l e . F i l e i t [my m a i l f r o m J o h n S m i t h ] i n my budget correspondence file.
my m a i l f r o m J o h n S m i t h h a s b e e n a d d e d co the text class budget correspondence.
>amm-va i t f r o m my m a i l b o x . Bemove i c [my m a i l f r o m J o h n S m i t h ] f r o m my m a i l box.
my m a i l f r o m J o h n S m i t h h a s b e e n r e m o v e d from your mail.
> C r e a t e a b u d g e t c o r r e s p o n d e n c e named Budget Plans Please e n t e r t e x t : S t a f f l e v e l b u d g e t m e e t i n g on Wed.
a t 3 i n Tom's o f f i c e . P l e a s e s e n d me y o u r c o m m e n t s b e f o r e t h e m e e t i n g ; f i l e t h e m a s "commenCe on B u d g e t P l a n e " . \ Budget Plane class budget >Mail Budget Budget plane manager.
h a s b e e n a d d e d Co t h e t e x t correspondence.
Plans to each section manager.
h a s b e e n s e n t to e a c h s e c t i o n Ill.
MORE GENERAL ASPECTS OF THE ASK SYSTEM A.
R e s v o n s e Times The movie, which accompanied the oral presentation of this paper, demonstrated that the response rime, i.e., the time between completion of t h e t y p i n g of t h e i n p u t by t h e u s e r Co t h e appearance of t h e r e s p o n s e on t h e t e r m i n a l, is very good.
But the data bases used in the illustrations have been small, Coy d a t a b a s e s . The f o l l o w i n g t a b l e g i v e s a v e r a g e r e s p o n s e t i m e s for a few cases using larger data bases.
The query used for this illustration is: >What arm t h e d e s t i n a t i o n s of tankers?
The r e s p o u s e t i m e i s r a t h e r i n s e n s t i t i v e to the Coral number of individuals, classes, attributes and relations in the data base, depending primarily on the size of the relation (destination) and i t s a r g u m e n t ( C a n k e r s ) . Suppose t h a t t h e r e a r e m t a n k e r s i n t h e d a t a b a s e and t h a t n individuals have destinations, i.e., the size of the destination relation i s n.
T h e t a b l e g i v e s time in seconds.
no. of tankers > D i s p l a y t h e commence on B u d g e t P l a n s by e a c h section manager.
D i s p l a y i n g commence on B u d g e t P l a n s by e a c h section manager: J o h n Dobbs: D ( i s p l a y ), S(kip), o r Q(uit): 2 2 a 9 dastinscions I I I I C.
A d d i n z New O b i e c t T y ~ e s A l t h o u g h t h e ASK S y s t e m h a s b e e n d e s i g n e d t o allow the addition o f new o b j e c t t y p e s, t h i s c a n be d o n e o n l y by a n a p p l i c a t i o n programmer.
The major obstacle is the necessity to provide a procedure to initialize instances of the new object type and procedures that carry out their intrinsic manipulation.
However, we expect the addition of new object types to be a c o m m o n occurrence in the applications of the ASK System.
In any potential applicaion areas, using groups have accumulations of data already structured in specific ways and families of procedures that they have developed to manipulate these structures.
In ASK, they can identify these data structures as a new object type, design simple syucax for them to invoke their procedures, and thus embed their familar objects and manipulations within the ASK English dialect and within the same context as other associated aspects of their tasks.
The class, attributed and relation constructions become immediately available.
B e s p o n e e Time i n S e c o n d s f o r : >What a r e t h e d e s t i n a t i o n s of tankers?
B. The C q n c e v t o f A Use ~ C o n t e x t an_...dd the Basing Ooeration In the t e r m i n o l o g y of ASK, a user "Context" is a knowledge base together with the vocabulary and definitions that S o with it.
A given user will usually have several Contexts for v a r i o u s purposes, some of which may be the small "Ships" Context, a (truncated) bibliography of Artificial Intelligence literature and an a d m i n i s t r a t i v e Context concerning budget matters.
When one initiates a session with the ASK System, one is initially in the Command Context: >Welcome to ASK Please identify yourself.
>Fred >Pass word: You have mail.
Fred is in COMMAND, proceed.
At this point, you can list the Directory of Contexts available to you, create or delete Contexts, authorize others to use Contexts which you have created, and enter any of the Contexts in 21 fi>Directory context BASE Ships AI Bibliography Family Management Matters creator MASTER Fred Fred Fred Fred enter no yes yes yes yes b~s~ yes yes yes yes yes >enter Management Matters You are in Management Matters, proceed.
>Who have I received mail from?
Peter Jackson John Dobbs A new C o n t e x t is c r e a t e d by basing it on an already existing one.
Consider a u s e r who h a s b e e n a u t h o r i z e d f o r b a s i n g on t h e AI B i b l i o g r a p h y Context illustrated a b o v e and who w a n t s t o b u i l d a w i d e r b i b l i o g r a p h y C o n t e x t ( a d d i n g new i n f o r m a t i o n --vocabulary, data and definitions), however, without disturbing the old one.
To do s o, a l l s / h e n e e d s t o do i s s e l e c t a new n a m e, s a y CS B i b l i o g r a p h y, and t y p e : >exit You a r e >Base CS The new created >individual: E x p e r i e n c e w i t h ROBOT, L.
H a r r i s The f o l l o w i n g i n d i v i d u a l s have been added: E x p e r i e n c e w i t h ROBOT L.
H a r r i s >The a u t h o r o f E x p e r i e n c e w i t h ROBOT i s L.
Harris. L.
H a r r i s h a s b e e n a d d e d a s a u t h o r o f E x p e r i e n c e w i t h ROBOT.
>Keyword o f E x p e r i e n c e w i t h ROBOT i s d a t a b a s e . database has been added as keyword of E x p e r i e n c e with ROBOT.
>Who wrote what about databases? author D.
L. W a l t z N a t u r a l L a n g u a g e A c c e s s t o a Large Data Base L.
H a r r i s E x p e r i e n c e w i t h ROBOT > e x i t t o CB B i b l i o g r a p h y, You a r e i n CS B i b l i o g r a p h y, proceed.
>Who w r o t e w h a t a b o u t d a t a b a s e s ? author D.
L. W a l t z N a t u r a l L a n g u a g e A c c e s s t o a Large Data Base C.
J. D a t e An I n t r o d u c t i o n to Database Systems L.
H a r r i s E x p e r i e n c e w i t h ROBOT Several C o n t e x t s can be based on a g i v e n one, and one C o n t e x t can be b a s e d on several, thus a hierarchical structure of Contexts can be realized.
All Contexts are directly or indirectly based upon the BASE Context, w h i c h c o n t a i n s the f u n c t i o n words and g r a m m a r of the ASK d i a l e c t of English, the mathematical and statistical capabilities, and the word processor.
i n COMMAND, p r o c e e d . Bibliography on AI Bibliography context CS Bibliography has been b a s e d on AI B i b l i o g r a p h y basing action is t h i s new C o n t e x t : a ne w The r e s u l t of this Context.
Upon e n t e r i n g > E n t e r CS B i b l i o g r a p h y You a r e in CS Bibliography, one c a n make a d d i t i o n s : proceed.
C. T~anspo~tabilitv It is easy and fast to apply ASK to a n e w domain, given that a data base for this new domain is a v a i l a b l e in m a c h i n e r e a d a b l e form.
The vehicle is t h e ASK dialogue-driven Bulk Data Input capability, w h i c h can be called upon to build an existing database into one's Context.
The result not only i n t e g r a t e s this n e w data w i t h that already in the C o n t e x t and under the ASK d i a l e c t of English, but in m a n y c i r c u m s t a n c e s w i l l make the use of this data m o r e r e s p o n s i v e to users" > i n d i v i d u a l s :An I n t r o d u c t i o n to Database S y s t e m s, C.
J . D a t e The f o l l o w i n g i n d i v i d u a l s h a v e b e e n a d d e d : An I n t r o d u c t i o n to D a t a b a s e S y s t e m s C.
J . D a t e >The a u t h o r o f An I n t r o d u c t i o n to Database S y s t e m s i s C.
J . D a t e . C.
J . D a t e h a s been added a s a u t h o r of An Introduction to Database Systems.
>Keyword o f An I n t r o d u c t i o n t o D a t a b a s e Systems is database.
d a t a b a s e h a s been a d d e d a s k e y w o r d o f An Introduction to Database Systems.
>Who w r o t e w h a t a b o u t d a t a b a s e s ? author D.
L. W a l t z N a t u r a l L a n g u a g e A c c e s s t o a L a r g e D a t a Base C.
J. D a t e An I n t r o d u c t i o n to D a t a b a s e Systems These additions to the CS B i b l i o g r a p h y would not, of c o u r s e, e f f e c t She AI B i b l i o g r a p h y Context.
However, a d d i t i o n s and m o d i f i c a t i o n s that are subsequently made in the AI Bibliography Context would automatically be reflected in the CS Bibliography.
>exit You are in COMMAND, proceed.
>Enter AI Bibliography You are in AI Bibliography, proceed.
22 needs.
The Bulk Data Input D i a l o g u e p r o m p t s the user for n e c e s s a r y i n f o r m a t i o n to (i) e s t a b l i s h t h e physical structure of the d a t a b a s e to be included, (2) add necessary classes and attributes as needed for the new data entries.
The user also indicates, using E n g l i s h c o n s t r u c t i o n s, the i n f o r m a t i o n a l r e l a t i o n s h i p s a m o n g the fields in the p h y s i c a l records of the d a t a b a s e file that s/he wishes carried over to the ASK Context.
IV. DIALOGUES IN ASK Some have raised the question whether natural language is always the most desirable medium for a user to c o m m u n i c a t e w i t h the computer.
Expert systems, for example, have tended to use computer guided dialogues.
One simple form such a dialogue fimight take is illustrated by t h e f o l l o w i n s in w h i c h a new e n t r y i s a d d e d t o t h e AI B i b l i o g r a p h y : >New b i b l i o g r a p h y i t e m >Add to what b i b l i o g r a p h y ? AI B i b l i o g r a p h y >Title: Natural Language Processing >Author: Harry Tennant >Keyword: n a t u r a l l a n g u a g e >Keyword: s y n t a x p r o c e s s i n g >Keyword: s p e e c h a c t s >Keyword: Natural Language Processing has been added t o AI B i b l i o g r a p h y . >Title: The "new b i b l i o g r a p h y item" dialogue i8 completed.
>What A I B i b l i o g r a p h y items were written by Harry Tennant?
E x p e r i e n c e with the Evaluation of Natural Language Question Answerers Natural Language Processing necessary, respond with a diagnostic, (2) f i l l in other fields with data developed from the knowledge base, (3) extend the knowledge base, adding to the vocabulary and adding or changing the data itself, (4) file the completed form in p r e s c r i b e d f i l e s o r i n t h o s e i n d i c a t e d by t h e u s e r and a l s o m a i l it t o a s p e c i f i e d d i s t r i b u t i o n list through the electronic mail subsystem.
Since the Form p r o c e s s i n g c a n c h e c k c o n s i s t e n c y and m o d i f y the knowledge base, Forms can be used to facilitate data input.
S i n c e Form p r o c e s s i n g c a n fill f i e l d s in t h e Form, the forms c a p a b i l i t y includes the functions of a report generator.
L e t t e r s and memos c a n be written a s s p e c i a l c a s e s of Form filling, automatically adding dates, addresses, etc.
and filing and dispatching the result.
It must be easy and natural to add new Forms, if they are to be a convenient tool.
That is the function of the Forms Designing Dialogue.
Much like the Bulk Data Input Dialogue, the Forms Designing Dialogue holds a dialogue with the the user through which s/he can specify the fields of the Form itself and the processing of the above k i n d s t o be a u t o m a t i c a l l y accomplished at the time the Form is filled in.
Here is a simple example of a from that was designed using the Forms Designing Dialogue.
>What i s t h e bona p o r t and c o ~ a n d e r old ship?
There are 2 answers: (i) The~e is no c o ~ . n d e r . of each Other alternative media for user/system communication are menu boards, selection arrays and q u e r y by e x a m p l e . Many o t h e r c r y p t i c w a y s to communicate user needs to a knowledgeable system c a n be t h o u g h t o f ; o f t e n t h e m o s t u s e f u l m e a n s will be highly specific to the particular application.
For e x a m p l e, i n p o s i t i o n i n g c a r g o i n t h e h o l d o f a s h i p, o n e w o u l d l i k e t o be a b l e t o display the particular cargo space, showing its current cargo, and call for and move into place o t h e r i t e m s t h a t a r e to be i n c l u d e d . In the past, enabling the system to respond more intelligently to the user's needs required the provision of elaborate programs since the u s e r ' s t a s k s m a y be q u i t e i n v o l v e d, w i t h c o m p l e x decision structures.
The introduction of terse, effective communication has incurred lout delays and thus the changing needs of a user had little c h a n c e o f b e i n g m e t . I n t h e ASK S y s t e m, t h e u s e r s themselves can provide this knowledge.
They c a n i n s t r u c t t h e system on how to e l i c i t the necessary i n f o r m a t i o n and how to c o m p l e t e t h e r e q u i r e d t a s k . This ASK capability is quite facile, opening the way f o r i t s u b i q u i t o u s use in extending the knowledgeable responsiveness of the computer to user's immediate needs.
ASK i n c l u d e s two s y s t e m guided dialogues, similar to the Bulk Data Input d i a l o g u e by w h i c h u s e r s c a n i n s t r u c t t h e S y s t e m on how to be more r e s p o n s i v e t o t h e i r n e e d s . A.
Forms Desi~nin2 Dialogue The Form is an efficient means of communication with which we are all familiar.
A number of computer systems include a Forms package.
For most of these, however, filling in a Form results only in a document; the Form does not constitute a medium for interacting with the knowledge base or controllin K the actions of the system.
The ASK Forms capability enlarges the roles and ways in which Forms can be used as a m e d i u m for user interaction.
As the user fills in the fields of a Form, the System can make use of the information being supplied to (1) check its consistency with the data already in the k n o w l e d g e base and, if old ship hone port Ubu Naples Alamo London >Who i s J o h n S m i t h ? The f o l l o w i n s w o r d s a r e n o t i n t h e v o c a b u l a r y : John Smith > I n v e n t o r y o f wheat and c o r n o i l ? w h e a t and c o r n o i l i n v e n t o r y wheat 86.7 corn oil 123~00.
Note that the home port of the Alamo is London and that it does not have a commander, further that John Smith is not known to the System.
>Fill s h i p p i n g (For the purposes of the published paper, in contrast to the film shown at the presentation of the paper, only the initial and final copies of the form are given, under~ines indicate fields filled in by the "user", the o t h e r f i e l d s automatically being filled by the System).
(before) Shipping Form ship: port: quantity item $ price $ total commander: 23 fi(after) S h i p p i n g Form ship: port: A;amQ London item whvac corn oi~ J@hn SmiC~ price $ 35.75 $ 2.50 total $ 107.25 $1250.00 quantity ! 500 colmander: natural language programming capabiltty.
We hasten to add that it is not a general purpose program environment.
It is for "ultra-high" level programming, gaining its programming efficiency t h r o u g h t h e a s s u m p t i o n o f an e x t e n s i v e v o c a b u l a r y and knowledge base on which it can draw.
The illustrative d i a l o g u e a b o v e, w h i c h a d d s ' a new i t e m to a bibliography, is an example of a simple d i a l o g u e d e s i g n e d u s i n g DDD.
V. ACKNOWLEDGEMENTS AND CURRENT STATUS Shipping List for Alamo has been filed in Shipping Invoice File.
S h i p p i n g L i s t for Alamo h a s b e e n m a i l e d to J o n e s . mail t o : Fill shipping has been completed.
> L i s t t h e home p o r t and co-w,a n d e r o f e a c h old ship.
old ship home p o r t commander Ubu Naples -Alamo London John Smith >Inventory of wheat and corn oil? w h e a t and c o r n o i l i n v e n t o r y wheat 83.7 c o r n oil 122900.
>What is in the Shipping Invoice File?
Shipping List for Alamo The three System guided dialogues, Bulk Data Input, Dialogue Designing Dialogue and Forms D e s i g n i n g D i a l o g u e, are f r o m the d o c t o r a l dissertation of Tai-Ping Ho.
The aspects of ASK c o n c e r n i n g b a s i n g o n e C o n t e x t on a n o t h e r a r e f r o m the doctoral dissertation o f K w a n 8 I Yu.
The methods for handling anaphora, fragments and correction of inputs are from the doctoral dissertation of David Trawick.
ASK is implemented on the Hewlett Packard HP9836 desktop computer.
To handle Contexts of r e a s o n a b l e s i z e, one n e e d s a b a r d d i s k . An HP9836 with an HP9725 disk was used in the illustrations in this paper.
Our work is supported by the Hewlett Packard Corporation, Desktop Computer Division.
B. DialoKue Desi~nin~ Dialogue In the day-by-day use of an interactive system, users are very often involved in repetitive tasks.
They c o u l d be r e l i e v e d o f much o f t h e d r u d g e r y o f such tasks if the system were more knowledgeable.
Such a knowledgeable system, as it goes about a t a s k f o r t h e u s e r, may need a d d i t i o n a l information from the user.
What information it needs aCa particular point may depend on earlier user inputs and the current state of the database.
The user must provide the system with knowledge of a particular cask; more precisely s/he must program this knowledge into t h e system.
The result of this programming will be a system guided dialogue which the user can subsequently initiate and which will then elicit the necessary inputs.
Using these inputs in c o n j u n c t i o n w i t h the knowledge already available, particularly the data base, the system completes the task.
It is this system-guided dialogue chat the user needs to be able to d e s i g n . In the ASK System, there is a special dialogue w h i c h can be used co d e s i g n s y s t e m g u i d e d dialogues Co accomplish particular casks.
We call this the Dialogue Designing Dialogue (DDD).
Using DDD, the user becomes a computer-aided designer.
Since DDD, in conducting its dialogue with the user, only requires simple responses or responses phrased in ASK English, the user need have little programming skill or experience.
Using DDD, the user alone can replace a tedious, repetitive cask with an efficient system guided dialogue, all in a natural language environment.
The ASK Dialogue Designing Dialogue constitutes a high level, 24
A Robust P o r t a b l e N a t u r a l L a n g u a g e D a t a B a s e I n t e r f a c e Jerrold M.
Ginsparg Bell Laboratories Murray Hill, New Jersey 07974 A BSTRA C T This paper describes a NL data base interface which consists oF two parts: a Natural Language Processor (NLP) and a data base application program (DBAP).
The NLP is a general pur!~se language processor which builds a formal representation of the meaning of the English utterances it is given.
The DBAP is an algorithm with builds a query in a augmented relational algebra from the output of the NLP.
This approach yields an interface which is both extremely robust and portable.
where "colored", "'color" and "'house" are system primitives called concepts.
Each concept is an extended case frame, [Fillmore 2].
The meaning of each concept to the system is implicit in its relation to the other system concepts and the way the system manipulates it.
Each concept has case preferences associated with =IS cases.
For example, the case preference of color is "color and the case preference of coloredis "physical-object.
The case preferences induce a network among the concepts.
For example, "color is connected to "physical-object via the path: ['physical-object colored'colored color "color].
In addition.
"color is connected to "writing,implement, a refinement ot" "physicalobject, by a path whose meaning is that the writing implement writes with that color.
This network is used by the NLP to determine the meaning of many modifications, For example, "red pencil" is either a pencil which is red or a pencil that writes red, depending on which path is chosen.
In the absence of contextual information, the NLP chooses the shortest path.
In normal usage, case preferences are often broken.
The meaning of the broken preference involves coercing the offending concept to another one via a path in the network.
Examples are: "Turn on the soup".
"Turn on the burner that has soup on it".
"My car will drink beer".
"The passengers in my car will drink beer" This paper describes an extremely robust and portable NL data base interface which consists of two parts: a Natural Language Processor (NLP) and a data base application program (DBAP).
The NLP is a general purpose language processor which builds a formal representation of the meaning of the English utterances it is given.
The DBAP is an algorithm with builds a query in an augmented relational algebra from the output of the NLP.
The system is portable, or data base independent, because all that is needed to set up a new data base interface are definitions for concepts the NLP doesn't have, plus what I will call the +data base connection", i.e,, the connection between the relations in the data base and the NLP's concepts.
Demonstrating the portability and the robustness gained from using a general purpose NLP are the main subjects of this paper Discussion of the NLP will be limited to its interaction with the DBAP and the data base connection, which by design, is minimal.
[Ginsparg 5] contains a description of the NLP parsing algorithm.
3. The Data Base Connection 2.
NLP overview The formal language the NLP uses to represent meaning is a variant of semantic nets [Quillian 8].
For example, the utterances "The color of the house is green," "The house's color is green".
"Green,~ the color that the house is".
would all be ~ransformed to: Consider the data base given by the following scheme: Parts(pno,pname,color.cosl,weight) Spj( sno,pno,jno.quantity,m, y ) Suppliers and proiects have a number, )~ame and c~tV Parts ha'.,: a number, name, color, cost and weight Supplier wl(~,,unphe,, a quanntYof parts pno to prolect /no in month,nor year The data base connection has four parts: gl Isa: "colored Tense: present Colored: g2 Color: g3 lsa: "house Definite: the Isa: "color Value: green I.
Connecting each relation to the appropriate concept: Suppliers > "supplier fi2.
Connecting each attribute to the appropriate concept: leg., Spj(sno,pno,jno,cost,quantity)) depended on the supplier in which the cost ol a part 4.
C r e a t i n g pseudo relations Pseudo Cities jcity,scity This creates a pseudo relation, Cities(cname), so that the query building algorithm can treat all attributes as if they belong to a relation.
The query produced by the system will refer to the Cities relation.
A postprocessor is used to remove references to pseudo relations from the final query.
Pseudo relations are important because they ensure uniform handling of attributes.
With the pseudo Cities relation, questions like "Who supplies every city?
= and "List the cities".
can be treated identically to "Who supplies every project'"? and "List the suppliers".
The remainder of the data base connection is a set of switches which provide information on how to print out the relations.
whether all proper nouns have been defined or are to be inferred.
whether relations are multivalued, etc.
The switch settings and the four components above constitute the entire data base connection, Nothing else iS needed.
The network of concepts in the N L P should only be augmented for a particular data base; never changed.
Yet different data base schemes will require different representations for the same word.
For example, depending on the data base scheme, it could be correct to represent "box" as either, gl g2 g3 [sa: "part Conditions: "named(gl,box) Isa: "container Conditions: "named(g2.box) [sa: "box 3.
Capturing the information implicit in each relation: Parts(pno,pname,color,cost,weight ) "indexnumberp i n d e x n u m b e r > pno n u m b e r e d > Parts "named n a m e > pname n a m e d > Parts "colored color > color c o l o r e d > Parts costobj > Parts "weighs w e i g h t > weight w e i g h t o b j > Parts Projects(jno.jnamedcity) "indexnumberp indexnumber > jno n u m b e r e d > Projects "named name > jname n a m e d > Projects "located location > jetty located > Prolects Suppliers(sno,sname,scity) "indexnumberp indexnumber > sno n u m b e r e d > Suppliers "named name > sname n a m e d > Suppliers "located location > sctty located > Suppliers %pl O~no.pno.lno.quant Hv.m.y ) "supply supplier > '.no supplied > pno suppliee > mo (cardinality-of pno) > quantity u m e > m.y "spend spender > 1no s p e n d f o r -> pno amount (" cost quantity) The a m o u m case of "spend maps to a c o m p u t a t i o n rather than a,~mgle a t t r i b u t e It' all the attributes in the c o m p u t a h o n are not present,n the relation being defined, the query building program ioms,n the necessary extra relations.
So the definition of "spend ~mrks equally well irl tile example scheme as well as in a scheme 26 The solution is to define each word to map to the lowest possible concept.
W h e n a concept is e n c o u n t e r e d that has a data base relation associated with )t.
there is no problem.
If there )s no relauon associated with a concept, the N L p searchs For a concept that d o e s correspond to a relation and is also a generalization ot" the concept in question.
I f one is found, it is used with an appropriate condilion, usually "tilled or "named.
So "box" has a definition which m a p s to "box.
In the data base c o n n e c t i o n given above.
"box" would be instantiated as a "=part" since " ' b o x " is a r e f i n e m e n t of "'part" and no relation maps to "box," Using the Connection The information in the data base connection ts primarily used m building the query (section.~).
But It IS ~llso used Io augment the knowledge base of Ihe N L P The data base connection is used to overwrite the NLP's ca~e preferences.
Since I o c a w d > S u p p h e r s ()r Projects.
the preference ot" localed ts spec)fied to "suppliers or "protects.
This enables the NLP to interpret the first noun group )n "Do,m', suppliers that supply widgets located nl london also supply,~cre',vs )" as "'suppliers in London that supply widgets" rather than "supphers that,;upph London wldgets" This )s in contrast to [Gawron 31 which u'..es,i separate "disambiguator" phase to ehmlnale parses that do 11()i make sense =n the conceptual scheme of the dala base.
Tile additional preference informamm supplied bv the data base connection is used to induce coercions (section 2).
thai would rlot be made in the absence of the connection (~r under,mother data fibase scheme.
"Who supplies London" does not break any real world preferences, but does break one of the preferences induced by this data base scheme, namely that Suppliee is a "project.
London. a "city, is coerced to "project via the path [*project located *located /ocanon cityl and the question is understood to mean "Who supplies projects which are in London".
As mentioned in Section 2., the NLP determines the meanin~ of many modifications by searching for connections in a semantic net.
The data base connection is used to augment and highlight the existing network of the NLP.
I f the user says, "What colors do parts come in?', the NLP can infer that the meaning of "come-in" intended by the user is "colored since the only path through the net between "color and "part derived from the case preferences induced by the data base connection is ['part colored "colored color "color] Similarly, when given the noun group "London suppliers" the meaning is determined by tracing the shortest path through the highlighted net, ['supplier located'located Iocanon "city] The longer path connecting "supplier and "city, ['supplier supplier "supply suppliee *project located "location location *city] which means "the suppliers that supply to london projects" is found when the NLP rejects the first meaning because of context, If the user says "What are the locations of the London suppliers" the system assumes the second meaning since the first (in the domain of this data base scheme) leads to a tautological reading.
The NLP is able to infer that "The locations of the suppliers located in London" is tautological while "The locations of the suppliers located in England" is not, because the data base connection has specified "located to be a single valued concept with its Iocarton case typed to "city.
I f the system were asked for the locations of suppliers in England, and it knew England was a country, the question would be interpreted as "the cities of the suppliers that are located in cities located in England." The NLP treats most true-l'aise questions with indefinites as requests for the data which would make the statement true.
The question's meaning is "to show the subset of london proiects that are supplied by Blake".
The query building algorithm builds up the query recursively Given an instantiated concept with cases, =t expands the contents of each case and links the results together with the relation corresponding to the concept.
Given an instantiated concept with conditions, it expands each condition.
For the example, we have.
Expand gl Expand g2, the Element of gl Expand gg, the Condition of g2.
Expand g3, the Supplier case of gg.
Expand g9, the Condition of g3.
From the data base connection, a "named whose named case is a *supplier is realized by the Suppliers relation using the sname attribute So we have, g9 select tram Suppliers where sname -blake From the data base connection, a "supply is realized by the Spj relation.
This results in, gga -project]no/i'om.joinSpj to g9 g8 -joingga toProjects g8 is the projects supplied by Blake.
Expand 84, the set gl is a subset of, by expanding its element.
g6 Expand glO.
the Condition of gb Expand g7, the location case of glO yielding g l l -select #am Cities wherecname london A "located with a "project in the Iocotedcase ~s realized by the Projects relation using the ]city attribute.
So we have.
glOa -join Projects Io gl I where]city = cname glOb proiect ]no /'romglOa glO ]oinglOb toProjects g[0 is the projects in London.
Intersect the expansions of g2 and g4 and project the prolect names.
gl3 = pro/eel]name lrom imersectton g 8 glO 5.
A trtee of the query building algorithm.
The query budding algorithm is illustrated by tracmg its operation on the question, "Does blake supply any prolects in london'?" The entire query is, The NLP's meaning representation I'or this question ts shown below.
gO Isa: "show g5 Isa: "name Value: blake g9 Isa: "named Tense: present Named: g3 Name: g5 Isa: "tocated Tense: present Located: gb Location: g7 Isa: "named Tense: present Named: g7 Name: g12 Isa: *name Value: london Tense: present Toshow: g l gO [sa: "set Element: 2 Subset-of': g4 Isa: "protect Isa: "project Element-of: g4 Conditions: glO glO lsa: city Conditions: gll Isa: "supply Tense: Present Suppler: g3 Suppliee: g2 gl [ g9 = select/romSuppliers where s n a m e = blake g8a -/~'oiecrjno #om ioin Spj to g9 g8 = loin gga to Projects gl0 = select #am Projects where icily = london g 13 -prelect iname lrom mter'~e('tlo~t g8 g I0 where the: extra loin resulting f'rom the pseudo (:h=e~ relation ha', been rernoved by the post processor (section 3 ) Entirely as a side effe,'t of the way the query rs generated, the -,,,,,tern can easily correct any l'alse assumptions made by the u~,,2r [Kaplan 71.
For example, if there were no projects in London.
gill would be empty and system would respond, generating Irom the instantiated concept glO li.e., the names used in query correspond to the names used in the knowledge representatmnL "There arc no suppliers located in London".
No additional "'.=oiated presupposition" mechanism is requ+red.
The remainder of this section discusses several aspects o the query building process that the trace does not show.
Negations are handled by introducing a set difference when necessary If the example query were "Does Blake supply any projects that aren't in London?", the expansion of g7 would have been.
I f we ask.
"Who frequents a bar that serves a beer John likes?".
we get the following query.
81 82 g3 84 85 =" select from Likes where drinker john project beer l'rom g 1 .join Serves to 82 =" project bar I~om g3 "" join Frequents to 84 Expand g7.
the location case of glO yielding g i l a select [romCities wherecname -london gl 1 difference o f Cities a n d g l la Conjunctions are handled by introducing an an intersection or union.
I f the example query were "Does Blake supply any projects in London or Paris'?', the /ocanon case of g10 would have.
been the conjunction 813.
I f we ask "Who frequents a bar that serves a beer that he likes"? the correct query, is.
isa "conjunction Type: or Conjoins: g7 g14 [sa: "city Conditions: g l 5 lsa: "named Named: g15 Name: g l 6 Isa: "name Value: paris glb In the first query "beer" was the only attribute projected from g l [n the second, the system projected both "beer" and "drinker", because in expanding "a beer he likes" it needed to expand an instantiated concept (the one representing "who") that was already being expanded.
All of these cases interact gracefully with one another.
For example.
there is no problem in handling "Who supplies every project that is not supplied by blake and bowles".
The result of expanding gl3 would be, [n general, "or" becomes a union and "and" becomes an intersection.
However, if an "and" conjunction is in a single valued case (information obtained from the data base connection), a union is used instead.
Thus "Who supplies london and paris"? is interpreted as "Who supplies both London and Paris'"? and "Who is in London and Pans"? is interpreted as "Who is in London and who ~s m Paris"?
)n the example data base scheme.
6. Advantages of this approach The system can understand anything it has a concept about.
regardless o f whether the concept is attached to a relation in the data base scheme.
In the Suppliers data base from Secuon 4., parts had costs and weights associated with them, but not sizes.
I f a user asks "How big are each of the parts"? and the interface has a "size primitive (which it does), the query building process wdl attempt to find the relation which "size maps to and on fading wdl report back to the user.
"There is no information in the data base about the size of the parts".
This gives the user some informatmn about the what the data base contains, An answer like "1 don't know what "big" means".
would leave the user wondering whether size information was in the data base and obtainable if only the "right" word was used.
The system can interpret user statements that are not queries.
If the user says "A big supplier is a supplier that supplies more than 3 projects" the NLP can use, the definition qn answering later queries.
The definition is not made on a "string" basis e.g., substttuting the words of one side of the definition for the other Instead.
whenever the query building algorithm encounters an mstantiated concept that is a supplier wnh the condition "size~x.
big) it builds a query substnuting the condiuon from the definition that it can expand as a data base query Thus the .~vstern can handle "big london suppliers" and answer "Which sunpliers are big" which it couldn't if ~t were doing strlct string substitution.
This Facility can be used to bootstrap common definitions In,~ commercial flights application, with data base scheme, Flights(fl#,carrier,from.to,departure,arrival.stops.cost ) the word "nonstop" is defined to the system in English as, "A nonstop flight is a night that does not make any stops " and then saved along wuh the rest of the system's defimt~ons.
28 Quantifiers are handled by a post processing phase.
"Does blake supply every project in London"? is handled identically to "Does Blake supply a prolect in London'"? except that the expansion of "projects m London" is marked so that the post processor will be called.
The post processor adds on a set of commands which check that the set difference of London projects and London prolects that Blake supplies is empty.
The rasulhn 8 query is.
gl = =_2 g3 = g4 = =_5 = gO = g7 = g8 = ~e/ect lrom Suppliers w/weresname = blake ~elect l m m Projects where jcity london /otnSpl togl tomg3 to g2 protect jno from g2 protect ino /tom g4 {hl]~'rem'e org5 andgO empn, g7 ] h e first tour commands are the query for "Does Blake supply a llrolect m London'?".
The last tour check that no project in London is not supplied by Blake.
-\ minor modification is needed to cover cases in which the query building algorithm is expanding an instantiated concept that refercnces an instuntiated concept that is being expanded in a higher recursmve call The following examples illustrate this.
Consider the data base scheme below, taken from [Ullman ql.
Coercions (section 2).
can be used solve problems that may require inferences in other systems.
[Grosz 6] discusses the query "Is there a doctor within 200 miles of Philadelphia" in the context of a scheme in which doctors are on ships and ships have distances from cities, and asserts that a system which handles this query must be able to inter that if a doctor is on a ship, and the ship is with 200 miles of Philadelphia, then the doctor is within 200 miles of Philadelphia.
Using coercions, the query would be understood as "is there a ship with a doctor on it that is within 200 miles of Philadelphia?', which solves the problem immediately.
Since the preference information is only used to choose among competing interpretations, broken preferences can still be understood and responded to.
The preference for the supplier case is specified to supplier but if the user says "How many parts does the sorter project supply"? the NLP will find the only interpretation and respond "projects do not supply parts, suppliers do".
Ambiguities inherent in attribute values are handled using the same methods which handles words with multiple definitions.
For example, 1980 may be an organization number, a telephone extension, a number, or a year.
The NLP has a rudimentary (so far) expert system inference mechanism which can easily be used by the DBAP.
One of the rules it uses is "If x is a precondition of y and z knows y is true then z knows x was and may still be true" One of the ['acts in the NLP knowledge base is that being married is a precondition of being divorced or widowed.
I f a user asks "Did Fred Smith used to be married"? in a data base with the relation Employees(name, marital-status) the system can answer correctly by using its inference mechanism.
The exact method is as follows.
The data base application receives the true-false question: "Fred Smith was married and Fred Smith is no longer married" The system handles all the examples in this paper as well as a wide range of others (Appendix A.).
Several different data bases schemes have been connected to the system for demonstrations, including one "real data base" abstracted from the on-line listing of the Bell Laboratories Company Directory.
9. Since the data base includes only current marital status information.
the only way to answer the first part of the question is to inl'cr it from some other information in the data base.
The data base application sends the query to the NLP inference mechanism which would ordinarily attempt to answer it by matching it against its knowledge base or by finding a theorem which would gives it something else to match ['or When called by the data base application, the inference mechanism simply uses its rules base to decide what it should match ['or, and then returns to the data base program.
In this, example, the inference mechanism receives "Fred Smith was married" and using the precondition rule mentioned above, returns to the data base program, "Is Fred Smith divorced" or "is Fred Smith widowed", which can be answered by the data base.
The DBAP can call the inference mechanism recursively if necessary.
Appendix A: Sample Questions and Answers  does every department head in 1135 have an office in holmde[?
No. all heads Ihat work For center number 11.]5 are not located in an office in ho  who isn't alles,h g is the head not located in an ofi~ce in ho that works for center number [ 135  who has been with us for longer than fred smith? 7.
Implementation Status and Details The DBAP ~s fully implemented and debugged.
The NLP is ~mplemented and sail growing.
Both are implemented in Franz Lisp.
a dialect of LISP Language processing and query generai~on are performed m virtually real time (average 1-3 cpu seconds) on a Vax I 1-780 The system ~s intended to be used with u Data Base Management system.
The interface between the DBAP and the I-)BMS is a,,tralghtforward translator from relational algebra to the query language of Ihe DflMS I have written a Ir;.mslator I'or Polaris [Gielan 41.
There are no employees that have worked ('or you ['or more than the length or" the time fred smith has worked for ~.'~'~u  list the employees who used to be married and are not married now, paul rochester, verlon biggs and willie davis are the empin~ee,~ that were married and that are not married now.
TEAM: A TRANSPORTABLE NATURAL-LANGUAGE INTERFACE SYSTEM B a r b a r a J.
G r o s z Artificial Intelligence Center SRI I n t e r n a t i o n a l Menlo P a r k, CA 94025 A.
Overview A major benefit of u s i n g n a t u r a l language to the i n f o r m a t i o n in a database is that it shifts o n t o t h e system t h e b u r d e n of m e d i a t i n g b e t w e e n two v i e w s o f t h e d a t a : t h e way i n which t h e d a t a i s s t o r e d ( t h e " d a t a b a s e v i e w " ), and t h e way i n which an e n d u s e r thinks about it (the "user*s view").
Database information is recorded in terms of files, r e c o r d s, and fields, while natural-language expressions refer t o the same information i n terms of entities and relationships in the world.
A major problem in constructing a natural-language interface is determining how to encode and use the information needed to bridge these two views.
Current natural-language interface systems require extensive efforts by specialists in natural-language processing to p r o v i d e them w i t h t h e i n f o r m a t i o n t h e y need t o do the bridging.
The systems are, in effect, handtallored to provide access to particular databases.
access how Co o b t a i n t h e information requested.
Moving s u c h s y s t e m s to a new d a t a b a s e r e q u i r e s c a r e f u l handcrafting that involves d e t a i l e d knowledge o f such things ae p a r s i n g p r o c e d u r e s, t h e p a r t i c u l a r way i n which domain i n f o r m a t i o n i s stored, and data-access procedures.
To provide for transportability, TEAM s e p a r a t e s i n f o r m a t i o n a b o u t language, about the domain, and a b o u t the database.
The d e c i s i o n t o p r o v i d e t r a n s p o r t a b i l i t y to existing conventional databases (which d i s t i n g u i s h e s TEAM from CHAT [ W a r r e n, 1981]) means that t h e d a t a b a s e c a n n o t be r e s t r u c t u r e d t o make t h e way i n w h i c h i t s t o r e s d a t a more c o m p a t i b l e w i t h t h e way i n which a u s e r may a s k a b o u t t h e data.
A l t h o u g h many p r o b l e m s can be a v o i d e d i f one i s a l l o w e d t o d e s i g n t h e d a t a b a s e a s w e l l a s the natural-language system, given the prevalence of existing conventional databases, approaches w h i c h make t h i s assumption are likely t o have limited applicability in the near-term.
This paper f o c u s e s on the p r o b l e m of constructing transportable natural-language interfaces, i. e ., s y s t e m s t h a t can be a d a p t e d t o p r o v i d e a c c e s s t o d a t a b a s e s f o r which t h e y were not specifically handtailored.
It describes an initial version of a transportable system, called TEAM (for ~ransportable E_ngllsh A_ccess Data manager).
The hypothesis underlying the research described in this paper is that the i n f o r m a t i o n required for the adaptation can be obtained through an Lnteractlve dialogue with database management personnel who are not familiar with natural-language processing techniques.
The TEAM s y s t e m h a s three major components: ( 1 ) an a c q u Z s t t i o n component, ( 2 ) t h e DIALOGIC language system [Grosz, et al., 1982], and (3) a data-access ccaponent.
Section C descrlbes how the language and data-access components were designed to accommodate the needs of transportability.
S e c t i o o D d e s c r i b e s the d e s i g n of the acquisition component to allow flexible interaction ~rlth a database expert and discusses acquisition problems caused by the differences between the database view and user view.
Section E shows how end-user queries are interpreted after an acquisition has been completed.
Section F describes the current state of development of TEAM and lists several problems currently under investigation.
B. I s s u e s of T r a n s p o r t a b i l i t y C.
System Design The insistence on transportability distinguishes TEAM from previous systems such as LADDER [Hendrlx ec al., [978] LUNAR [Woods, Kaplan, and Webber, 1972], PLANES [Waltz, 1975], REL [Thompson, [975], and has affected ~he design of the natural-language processln~ system in several ways.
Most previously built naturallanguage interface systems have used techniques that make them inherently difficult to transfer to new domains and databases.
The internal representations [n these systems typically intermix (in their data structures and procedures) information about language with information about the domain and the database.
In addition, in Interpretln~ a query, the systems conflate what a user is requesting (what hls query "means") with 39 I n TEAM, t h e t r a n s l a t i o n o f an E n g l i s h q u e r y into a database query takes place in two s t e p s . First, the DIALOGIC system constructs a representation of the literal meaning or "logical form" of the query [Moore, 1981].
Second, the data-access component translates the logical form into a formal database query.
Each of these steps requires a combination of some information that is dependent on the domain or the database wlth some information that is not.
To provide for transportability, the TEAM system carefully separates these two kinds of information.
fiI. Domainand Database-Dependent Information To adapt TEAM to a new database three kinds of information must be acquired: information about words, about concepts, and about the structure of the database.
The data structures that encode this information--and the language processing and data-access procedures that use them--are designed to allow for acquiring new information automatically.
Information about words, lexlcal information, includes the syntactic properties of the words that will be used in querying the database and semantic information about the kind of concept t o which a particular word refers.
TEAM records the lexlcal information specific to a given domain in a lexicon.
Conceptual information includes information about taxonomic relationships, about the kinds of objects that can serve as arguments to a predicate, and a b o u t t h e k i n d s o f p r o p e r t i e s an object can have.
I n TEAM, t h e internal representation of information about the entities in the domain of discourse and the relationships that can hold among them is provided by a conceptual schema.
This schema includes a sort hierarchy encoding the taxonomic relationships among objects in the domain, information about constraints on arguments to predicates, and information about relationships among certain types of predicates.
database schema encodes information about how concepts in the conceptual schena map onto the structures of a particular database.
In particular, it links conceptual-schema representations of entities and relationships in the domain to their realization in a particular database.
TEAM currently assumes a relational database with a number of f i l e s . (No languageprocesslng-related problems are entailed in moving TEAM to other database models).
Each file is about some kind of object (e.g., employees, students, ships, processor chips); the fields of the file record properties of the object (e.g., department, age, length).
A To provide access to the informa=,on in a particular database, each of the components of DIALOG~C must access domain-speciflc information about the words and concepts relevant to that database.
The information required by the syntactic rules is found in the lexicon.
Information required by the semantic and pragmatic rules is found in the lexicon or the conceptual schema.
The rules themselves however do not include such domain-dependent information and therefore do not need to be changed for different databases.
In a similar manner, the data-access component separates general rules for translating logical forms into database queries from information about a particular database.
The rules access information i n the conceptual and database schemata to interpret queries for a particular database.
D. Acquisition TEAM i s d e s i g n e d t o i n t e r a c t w i t h two k i n d s o f u s e r s : a d a t a b a s e e x p e r t (DBE) and an e n d u s e r . The DBE provides information about the files and fields in the database through a system-dlrected acquisition dialogue.
As a result of this dlaloEue, the language-processlng and data-access components are extended so that the end-user may query the new database in natural-language.
i. Acquisition Questions Because the DBE is assumed to be familiar with database structures, but not with language-processlng techniques, the acquisition dialogue is oriented around database structures.
That is, the questions are about the kinds of things in the files and fields of the database, rather than about lexlcal entries, sort hierarchies, and predicates.
The disparity between the database view of the data and the end-user's view make the acquisition process nontrlvlal.
For instance, consider a database of information about students in a university.
From the perspective of an enduser "sophomore" refers to a subset of all of the students, those who are in their second year at the university.
The fact that a particular student is a sophomore might be recorded in the database in a number of ways, including: (l) in a separate file containing information about the sophomore students; (2) by a special value in a symbolic field (e.g., a CLASS field [n which the value SOPH indicates "sophomore"); (3) by a "true" value in a Boolean field (e.g., a * in an [S-$O?H field).
For natural-language querying to be useful, the end-user must be protected from having to know which type of representation was chosen.
The questions posed to the DBE for each kind of database construct must be sufficient to allow DIALOGIC to handle approximately the same range of Domain-lndependent Information The language executive [Grosz, e t a l ., 1982; Walker, 1978|, DIALOGIC, coordinates syntactic, semantic, and basic pragmatic rules in translating an English query into logical form.
DIALOGIC's syntactic rules provide a general grammar of English [Robinson, 1982].
A semantic "translation" rule associated with each syntactic phrase rule specifies how the constituents of the phrase are to be interpreted.
Basic pragmatic functions take local context into account in providing the interpretation of such things as noun-noun combinations.
DIALOGIC also includes a quantlfler-scoping algorithm.
filinguistic expressions (e.g., for referring to "students i n t h e sophomore c l a s s ' ) r e g a r d l e s s o f the particular database implementation chosen.
In all c a s e s, TEAM w i l l c r e a t e a l e x i c a l e n t r y f o r " s o p h o m o r e " and an e n t r y i n t h e c o n c e p t u a l schema to represent the concept of sophomores.
The database attachment for thls concept will depend on t h e p a r t i c u l a r d a t a b a s e s t r u c t u r e, as w i l l the kinds of predicates f o r which i t can be an argument.
Example of Acquisition Queeclons I n d e s i g n i n g TEAM we f o u n d i t i m p o r t a n t to distinguish three differanc kinds of fields N arlthmeCic, feature (Boolean), and s y m b o l l c o n the b a s i s of t h e r a n g e of l i n g u i s t i c expressions to which each gives r i s e . AriChmetic fields contain numeric values on which comparisons and computations llke averaging are likely to be done.
(Fields containing dates a r e n o t y e t h a n d l e d by TEAM).
Feature fields contain true/false values w h i c h r e c o r d w h e t h e r o r n o t some a t t r i b u t e i s a property of the object d e s c r i b e d by t h e file.
Symbolic f i e l d s typically contain values that c o r r e s p o n d to n o u n s o r a d j e c t i v e s t h a t d e n o t e t h e s u b t y p e s o f t h e domain d e n o t e d by t h e f i e l d . D i f f e r e n t a c q u i s i t i o n q u e s t i o n s a r e asked f o r each type of field.
These are illustrated in the example i n S e c t i o n D.3.
To illustrate the acquisition of information, consider a database, called CHIP, containing information about processor chips.
In particular, the fields in this database contain the following information: the identification number o f a c h i p ( I D ), its m a n u f a c t u r e r (MAKER) its width i n b i t s (WIDTH), ice speed in m e g a h e r t z (SPEED), its cost i n d o l l a r s (PRICE), the kind of technology (FAMILY), and a flag indicating wheCher o r noc t h e r e is an e x p o r t l i c e n s e f o r t h e c h i p (EXP).
In the figures discussed below, the DBE's r e s p o n s e is indicated in uppercase.
For many quesClone the DBE is presented wlch a llst of options from which ha can choose.
For these questions, the complete llst is shown and the answer indicated in boldface.
F i g u r e i shows t h e short-form of the questions asked about the file itself.
In r e s p o n s e to q u e s t i o n ( 1 ), t h e DBE t e l l s TEAM w h a t fields are in the file.
Responses to the r e m a i n i n g quesCloms allow TEAM t o identify t h e kind of object the file contains information about (2), types of linguistic expressions used to refer to It [ (6) and (7)], how to identify individual objects in the database (4), and how to s p e c i f y i n d i v i d u a l o b j e c t s to the u s e r ( 5 ) . These responses result in the words "chip" and " p r o c e s s o r " b e i n g added t o t h e l e x i c o n, a new s o r t added to the taxonomy (providing the interpretation f o r t h e s e w o r d s ), and a l i n k made i n t h e d a t a b a s e schema b e t w e e n t h i s sort and records i n the file CHIP.
Figure 2 gives the short-form of the most central questions asked about symbolic fields, using the field MAKER (chip manufacturers) as exemplar.
These questions are used to determine the kinds of properties represented, how t h e s e r e l a t e t o p r o p e r t i e s i n o t h e r f i e l d s, and the k i n d s of linguistic expressions the field values can give rise to.
Question (4) allows TEAM to determine that individual field values refer to manufacturers rather than chips.
The long-form of Q u e s t i o n (7) i s : Will you want to ask, for example, "How many MOTOROLA processors are there"? to get a count of the number of PROCESSORS with CHIP-MAKER-MOTOROLA?
Question (8) expands to: Will you want to ask, for example, "How many HOTOROLAS are there"? to get a count of the number of PROCESSORS with CHIP-MAKER-MOTOROLA?
Acquisition Strategy The ~ a J o r features of the s tra te gy developed for acquiring information about a database from a DBE include: (1) providiu E multiple levels of detail for each question posed to the DBE; (2) allowing a DBE to review previous answers and change them; and (3) checking for legal answers.
At present, TEAM initially presents the DBE wlth the short-form of a quesclou.
A more detailed version ("long-form') of the question, including examples illustratlng different kinds of responses, can be requested by the DBE.
An obvious excenslon to this strategy would be to present different Inltial levels t o different users ( d e p e n d i n g, f o r e x a m p l e, on t h e i r p r e v i o u s experience wlth the system).
A c q u i s i t i o n I s e a s i e r i f e a c h new p i e c e of information is immediately i n t e g r a t e d into the u n d e r l y i n g knowledge s t r u c t u r e s o f t h e p r o g r a m . 8 o w e v e r, we a l s o wanted Co a l l o w t h e DSE t o change a n s w e r s to p r e v i o u s q u e s t i o n s ( t h i s has t u r n e d o u t to be an essential feature of TEAM).
Some questions (e.g., those about irregular plural forms and synonyms) affect only a single part of TEAM (the lexicon).
Other questions (e.g., those about feature fields) affect all components of the system.
Because of the complex interaction between acquisition questions and components of the system to be updated, immediate integration of new information is not possible.
As a result, updating of the lexicon, conceptual schema, and database schema Is not done until an acqulsition dialogue is completed.
In t h i s ease, t h e a n s w e r to q u e s t i o n ( 7 ) I s " y e s " and to q u e s t i o n ( 8 ) " n o " ; the field has v a l u e s that can be used as explicit, but not implicit, classifiers.
Contrast this wlth a symbolic field in a file about students that contains the class of a student; in this case the answer to both fiauesclons would be affirmative because, for example, the phrases "sophomore woman" and "sophomores" can be used to refer to refer to STUDENTS with CLASS=SOPHOMORE.
In other cases, the values may serve neither as explicit nor as implicit classifiers.
For example, one cannot say *"the shoe employees" or *"the shoes" to mean "employees in the SHOE department".
For both questions (7) and (8) a positive answer i s the default.
It i s i m p o r t a n t to allow the user to override thls default, because TEAM must be able to avoid spurious ambiguities (e.g., where two fields have identical field values, but where the values can be classifiers for only one field.).
Following acquisition of this field, lexical entries are made for "maker" and any synonyms supplied by the user.
Again a new s o n is created.
It i s marked a s h a v i n g v a l u e s t h a t can be explicit, b u t not implicit, classifiers.
Later, when the actual connection to the database is made, individual field values (e.g., "Motorola") will be made individual instances of this new sort.
Figure (3) presents the questions asked about arithmetic fields, using the PRICE field as exemplar.
Because dates, measures, and count quantities are all handled differently, TEAM must first determine which kind of arithmetic object is in the field (2).
In this case we have a unit of "worth" (6) measured in "dollars" (4).
Questions (8) and (9) supply information needed for interpreting expressions Involvlng comparatives (e.g., "What chips are more expensive than the Z8080")? and superlatives (e--~7, "What is the cheapest chip?").
Figure 4 gives the expanded version of these questions.
As a result of thls acquisition, a new subsort of the (measure) sort WORTH i s added to the taxonomy for PRICE, and is noted as measured in dollars.
In addition, lexlcal entries are created for adjectives indicating positive ("expensive") and negative ("cheap") degrees of price and are linked to a binary predicate that relates a chip to its price.
Feature fields are the most difficult fields to handle.
They represent a single (arbitrary) property of an entity, with values that indicate whether or not the entity has the property, and they give rise to a wide range of linguistic expresslons--adJectlvals, nouns, phrases.
The short-form of the questions asked about feature fields are given in Figure 5, using the field EXP; the value YES indicates there is an export license for a given processor, and NO indicates there is not.
Figures 6, 7, and 8 give the expanded form of questions (4), (6), and (B) respectively.
The expanded form illustrates the kinds of end-user queries that TEAM can handle after the DBE has answered these questions (see also Figure 9).
Providing thls kind of illustration has turned out to be essential for getting these questions answered correctly.
Each of these types of expression leads to new lexlcal, conceptual schema, and database schema entries.
I n general in the conceptual schema, feature field adJectlvals and abstract nouns result in the creation of new predicates (see Section E for an example); count nouns result in the creation of new subsorts of the file subject sort.
The database schema contains informatlon about which field to access and what field value is required.
TEAM also includes a limlted capability for acqulrln8 verbs.
At present, only transitive verbs can be acquired.
One of the arguments to the predicate cozTespondlng to a verb must be of the same sort as the file subject.
The other argument must correspond to the sort of one of the fields.
For the CHIP database, the DBE could specify that the verb "make" (and/or "manufacture") takes a CHIP as one argument and a MAKER as the second argument.
E. Sample Q u e r i e s and T h e i r [nterpretatlons After the DBE has completed an acquisition session for a file, TEAM can interpret and respond Co end-user queries.
Figure 9 lists some sample end-user queries for the file illustrated in the previous section.
The role of the different kinds of informatlon acquired above can be seen by considering the logical forms produced for several queries and the database attachments for the sorts and predicates that appear in them.
The following examples illustrate the information acquired for the three different fields described in the preceding section.
Given the query, What are the Motorola chips?
DIALOGIC produces the following logical form: (Query (WHAT tl (THING tl) (THE p2 (AND (PROCESSOR p2) (MAKER-OF p2 MOTOROLA)) (EQ p2 tl)))) where WHAT and THE are quantifiers; 1 tl and p2 are variables; AND and EQ have their usual interpretation.
The predicates PROCESSOR and MAKER-OF and the constant MOTOROLA were created as a result of acquisition.
The schema: PROCESSOR: MAKER-OF: following information in the database 1 Because the current version of DIALOGIC takes no account of the slngular/plural distinction, the uniqueness presupposition normally associated with "the" is not enforced.
42 fii s u s e d, a l o n g with s o r ~ h i e r a r c h y i n f o r m a t i o n i n the conceptual schema, t o g e n e r a t e the actual database query.
Similarly, t h e e n d u s e r query chips? new acqulslClon component allows t h e user more flexibility i n answering questions and provides a wider range of default answers.
TEAM c u r r e n t l y h a n d l e s m u l t i p l e files and provides transportability to a l i m i t e d r a n g e o f databases.
As menCloned previously, a relational database model is assumed.
Currently, TEAM also assumes all files are In third normal form.
The acquisition of verbs is limited Co allowing t h e DBE Co s p e c i f y t r a n s I C l v e v e r b s, as described in S e c t i o n D.3.
We a r e c u r r e n t l y excending TEAM t o What a r e t h e e x p o r t a b l e would l e a d to t h e l o g i c a l form: ( Q u e r y (WHAT t l (THING cl) (THE p2 (AND (PROCESSOR p2) where EXP-POS is a predlcace created by acquisIClon; it is true if its argumanC is exportable.
In thls case the relevant database scheme information I s : PROCESSOR: EXP-POS: file-CHIP keyfleld-[D file-CHIP fleld-EXP fieldvalue-T (I) Provide for interpretation of expressions involving such things as mass terms, aggregates, quantified c o a m a n d s, and commands t h a c r e q u i r e t h e s y s t e m Co p e r f o r m f u n c t i o n s o t h e r t h a n q u e r y i n g che d a t a b a s e . Provide for efficient p r o c e s s i n g of the m o s t common f o r m s o f c o n j u n c t i o n . Generalize the verb acquisition p r o c e d u r e s and e x t e n d TEAM t o h a n d l e more complex verbs, including such Chings as verbs wlth mulClple delineations, verbs chat require special prepositions, and verbs that allow senCenclel complements.
Handle d a t a b a s e s encoding time-related information and e x t e n d DIALOGIC to handle expressions involving clme and tense.
Finally, co illustrate how TEAM h a n d l e s arithmetic f i e l d s, and I n p a r t i c u l a r the use of comparatives, consider the query: What c h i p i s c h e a p e r chart 5 d o l l a r s ? The l o g i c a l form f o r Chin q u e r y I s ( Q u e r y (WHAT pl (PROCESSOR pl) ((MORE C ~ A P ) pl (DOLLAH 5)))) The conceptual schema encodes the relationship between the predicates CHEAP and PRICE-OF (again, both concepts created as a result of acquisition), wlCh t h e following information CHEAP: measure-predlcate-PRICE-OF scale-negative G.
Acknowledgments The d e v e l o p m e n t of TEAM has involved the efforts of many people.
Doug Appelc, Armar Archbold, Bob Moore, Jerry Hobbs, Paul Marcln, Pernando Pereira, Jane Robinson, Daniel Sagalowicz, and David Warren have made ~ a J o r contributions.
This research was supported by the Defense Advanced Research Projects Agency with the Naval Electronic Systems Command under Contract N0003980-'<:-0645.
The views and conclusions contained in Chin document are chose of the author and should not be interpreted as representative of the official policies, either expressed or implied, of the Defense Advanced Research Projects Agency or the United States Government.
And the relevant database schema Informaclon is: PROCESSOR: PRICE-OF: file-CHIP keyfield-[D flit-CHIP field(argl)=[D fleld(arg2)-PRICE F.
Status and Future Research An initial version of TEAM was implemented in a combination of Incerlisp (acquisition and DIALOGIC components) and Prolog (data access component) on the DEC2060, but address space llmicatlons made continued development difficult.
Current research on TEAM is being done on the Symbolics LISP machine.
The acquisition component has been redesigned co cake advantage of capabilities provided by che blcmap display.
The 43 File nameC H ~ (1} Fields (ID MAKER WIDTH SPEED PRICE FAMILY EXP) (2) Subject P R O C E S S O R (31 Synonyms for P R O C E S S O R C H I P (4} Primazy key ID {5} IdentifyingfieldsM A K E R ID (8) Can one say W h o are the P R O C E S S O R S ? Y E S N O (7) Pronouns for filesubject H E S H E IT T H E Y (8) Field containing the name of each file subject ID Figure 1: Questions About File Field P R I C E ( 1) Type of field SYMBOLIC A R I T l t M E T I C FEATURE (2) Value t y p e . DATES M E A S U R E S COUNTS [3) Are the units implicit?
Y E S N O (4) Enter implicit unit DOLLAR (5) Abbreviation for this unit.~ (6) Measure type of this trait TIME WEIGHT SPEED VOLUME LINEAR AREA W O R T H OTHER {7) Minimum and maximum numeric valucs(1,100) (8} Positive adjectives (EXPENSIVE COSTLY) (9) Negative adjective (CHEAP) Figure 3: Questions for Arithmetic Field P R I C E Please specify any adjectives that can be used in their comparative or superlative form to indicate how much each P R O C E S S O R is in a positivedirectionon the scale measured by the values of CHIP-PRICE.
In a file about machine-tools with a numeric field called PRICE, one could ask: How E X P E N S I V E is each tool? to mean What is the price of each tool.~ EXPENSIVE, COSTLY, AND (HIGH PRICED) ~re positive adjectives designating the upper range of the PRICE scale.
C H E A P and (LOW PRICED), which designate the lower range of the PRICE scale, are negative adjectives.
Field M A K E R ( I ) Type of field S Y M B O L I C ARITHMETIC FEATURE (2) .Axe field values units of measure?
YES N O (3} Noun subvategory P R O P E R COUNT MASS (4} Domain of field value's reference SUBJECT F I E L D (5) Can you say W h o is the C H I P M A K E R t Y E S N O (6) Typical value M O R T O R O L A (7) Will values of this field be used as cia~sifers.~ E S N O Y {8) Will the values in this field be used alone as implicit classifiers?
YES N O Figure 2: Questions for Symbolic Field M A K E R Please enter any such adjectives you will want to ~ querying the database.
Figure 4: Expanded Version of Adjective Questions (Arithmetic Field} in Field E X P (I) Type of field SYMBOLIC ARITHMETIC F E A T U R E (2) Positive value YES (3) Negative value NO (4) Positive adjectives EXPORTABLE (5) Negative adjectives UNEXPORTABLE (6) Positive abstraA't nouns EXPORT AUTHORIZATION (7) Negative abstract no~.1 (8) Pmitive common nouns (9) Negative common nouns Figure 5: Questions for Feature Field ]gXP List any count nous~ ammciated with positive field value YES.
In general, this is any word wwww such that you might want to u k : What PROCESSORS are wwww-s! to mean What PROCESSORS have a CHIP-EXP of YES?
For example, in a file about EMPLOYEEs with  feature field CITIZEN having a positive field value Y and n e ~ t i v e field value N, you might want to aek: Which employees are citizens? instead of Which employees have a CITIZEN of Y?
Figure 8: Feature Field Count Nouns What adjectivab are aasoeiated with the field values YES in this field?
In general these are word.5 wwww such that you might want to Mk: Which PROCESSORS are www~' Which PROCESSORS have  CHIP-EXP of YES!
For example, in s medical file about PATIENTs with a feature field IMM having a positive field value Y and a negative filed value N, you might want to ask: Which patients are IMMUNE (or RESISTANT, PROTECTED)!
Figure 6: Feature Field Adjectivals ~,Vhat 8 bit chips are cheaper than the fastest exportable chip made by Zilogt Who makes the fastest exportable N M O $ chip costing less than 10 dollars!
By whom is the most expensive chip reader Who b the cheapest exportable chip made by!
Who is the most expensive chip made?
What is the fastest exportable chip that Motorola makes?
What 16 bit chips does Zilog make?
Who makes the fastest exportable N M O S chip?
Who makes the faatest exportable chip.~ Does Zilog make a chip that is faster than every chip that Intel makes?
Are there any 8 bit Ziiog chipe? is some exportable chip faster than 12 mhz?
Is every Ziiog chip that is f ~ t e r than 5 mhz exportable?
How faat is the faate~t exportable chip?
How expensive is the f~stest ~'~MOS chipt Figure 9: Sample questions for CHIP databaae List any abstrart nouns ~k~tociated with the positive feature value YES.
In general this is any word wwww such that you might want to ask a question of the form: Which PROCESSORS hove wwww? tO m e a n Which PROCESSORS have CHIP-EXP of YES!
For example, in a medical databaae about PATIENTs with a feature field IMM having a positive field value Y and a negative field value N, you might want to a~k: ~,Vhich patients have IMMUNITY? instead of Which patients have aa IMM of Y?
Figure 7: Feature Field Abstract Nouns REFERENCES Grosz, B.
et al . [1982] "DIALOGIC: A Core Natural Language Processing System," Proceedings of the Ninth International Conference on Computational Linguistics, Prague, Czechoslovakia (July 1982).
Moore, R.
C. [1981] "Problems in Logical Form," in Proceedings of the 19th Annual Meeting of the Association for Computaional Linguistics, pp.
117-L24. The Association for Computaional Linguistics, SRI International, Menlo Park, Californla (June 1981)..
Waltz, D.
[1975] "Natural Language Access to a Large Data Base: An Engineering Approach," Proc.
4th International Joint Conference on Artificial Intelligence, Tbillsl, USSR, pp.
868-872 (September 1975).
Warren, D . R . [1981] "Efficient Processing of Interactive Relational Database Queries Expressed in Logic," Proc.
Seventh International Conference on Very Large DataBases, Cannes, France, pp.
2"'2~-2--~', Robinson, J.
[1982] "DIAGRAM: A Grammar for Dialogues," Communications of the ACM, Vol.
25, No.
1, pp.
27-47 (January 1982).
Thompson, g . B . and Thompson, B . H . [1975] "Practical Natural Language Processing: The REL System as Prototype," H.
Rubinoff and M.
C. Yovlts, eds., pp.
109-168, Advances in Computers 13, Academic Press, New York, (New York 1975).
Woods, W.
A., R.
M. Kaplan, and B.
N-Nebber [I972] "The Lunar Sciences Natural Language Information System," BBN Report 2378, Bolt Beranek and Newman, Cambridge, Massachusetts (1972).
Walker, D.
E. (ed).
[1978] Understanding Spoken Language, Elsevier North-Hollam~, New York, New York, (1978) .
Customizable Descriptions of Object-Oriented Models Benoit Lavoie CoGenTex, Inc.
840 Hanshaw Road Ithaca, NY 14850, USA benoitOcogentex, com Owen Rambow CoGenTex, Inc.
840 Hanshaw Road Ithaca, NY 14850, USA owen~cogentex, com Ehud Reiter Department of Computer Science University of Aberdeen Aberdeen AB9 2UE, Scotland ereiter~csd, abdn.
ac. uk 1 Introduction: Object Models With the emergence of object-oriented technology and user-centered software engineering paradigms, the requirements analysis phase has changed in two important ways: it has become an iterative activity, and it has become more closely linked to the design phase of software engineering (Davis, 1993).
A requirements analyst builds a formal object-oriented (OO) domain model.
A user (domain expert) validates the domain model.
The domain model undergoes subsequent evolution (modification or adjustment) by a (perhaps different) analyst.
Finally, the domain model is passed to the designer (system analyst), who refines the model into a OO design model used as the basis for implementation.
Thus, we can see that the OO models form the basis of many important flows of information in OO software engineering methodologies.
How can this information best be communicated?
It is widely believed that graphical representations are easy to learn and use, both for modeling and for communication among the engineers and domain experts who tqgether develop the OO domain model.
This belief is reflected by the large number of graphical OO modeling tools currently in research labs and on the market.
However, this belief is not accurate, as some recent empirical studies show.
For example, Kim (1990) simulated a modeling task with experienced analysts and a validation task with sophisticated users not familiar with the particular graphical language.
Both user groups showed semantic error rates between 25% and 70% for the separately scored areas of entities, attributes, and relations.
Relations were particularly troublesome to both analysts and users.
Petre (1995) compares diagrams with textual representations of nested conditional structures (which can be compared to OO modeling in the complexity of the "paths" through the system).
She finds that "the intrinsic difficulty of the graphics mode was the strongest effect observed" (p.35).
We therefore conclude that graphics, in order to assure maximum communicative efficiency, needs to be complemented by an alternate view of the data.
We claim that the alternate view should be provided by an explanation tool that represents the data in the form of a fluent English text.
This paper presents such a tool, the MODELEXPLAINER, or MODEx for short, and focuses on the customizability of the system.1 Automatically generating natural-language descriptions of software models and specifications is not a new idea.
The first such system was Swartout's GIST Paraphraser (Swartout, 1982).
More recent projects include the paraphraser in ARIES (Johnson et al., 1992); the GEMA data-flow diagram describer (Scott and de Souza, 1989); and Gulla's paraphraser for the PPP system (Gulla, 1993).
MoDEx certainly belongs in the tradition of these specification paraphrasers, but the combination of features that we will describe in the next section (and in particular the customizability) is, to our knowledge, unique.
2 Features
of MoDEx MODEx was developed in conjunction with Andersen Consulting, a large systems consulting company, and the Software Engineering Laboratory at the Electronic Systems Division of Raytheon, a large Government contractor.
Our design is based on initial interviews with software engineers working on a project at Raytheon, and was modified in response to feedback during iterative prototyping when these software engineers were using our system.
 MoDEx output integrates tables, text generated automatically, and text entered freely by the user.
Automatically generated text includes paragraphs describing the relations between classes, and paral(Lavoie et al., 1996) focuses on an earlier version of MoDEx which did not yet include customization.
253 graphs describing examples.
The human-anthored text can capture information not deducible from the model (such as high-level descriptions of purpose associated with the classes).
 MoDEx lets the user customize the text plans at run-time, so that the text can reflect individual user or organizational preferences regarding the content and/or layout of the output.
 MoDEx uses an interactive hypertext interface (based on standard HTML-based WWW technology) to allow users to browse through the model.
 Input to MoDEx is based on the ODL standard developed by the Object Database Management Group (Cattell, 1994).
This allows for integration with most existing commercial off the shelf OO modeling tools.
Some previous systems have paraphrased complex modeling languages that are not widely used outside the research community (GIST, PPP).
 MODEX does not have access to knowledge about the domain of the OO model (beyond the OO model itself) and is therefore portable to new domains.
3 A
MoDEx Scenario Suppose that a university has hired a consulting company to build an information system for its administration.
Figure 1 shows a sample object model for the university domain (adapted from (Cattell, 1994, p.56), using the notation for cardinality of Martin and Odell (1992)) that could be designed by a requirements analyst.
Figure 1: The University OoO Diagram Once the object model is specified, the analyst must validate her model with a university administrator (and maybe other university personnel, such as dataentry clerks); as domain expert, the university administrator may find semantic errors undetected by the analyst.
However, he is unfamiliar with the "crow's foot" notation used in Figure 1.
Instead, he uses MoDEx to generate fluent English descriptions of the model, which uses the domain terms from the model.
Figure 2 shows an example of a description generated by MoDEx for the university model.
Suppose that in browsing through the model 254 using the hypertext interface, the university administrator notices that the model allows a section to belong to zero courses, which is in fact not the case at his university.
He points out the error to the analyst, who can change the model.
Suppose now that the administrator finds the texts useful but insufficient.
To change the content of the output texts, he can go to the Text Plan Configuration window for the text he has been looking at, shown in Figure 3.
He can add to the text plan specification one or more constituents (paragraphs) from the list of pre-built constituents (shown in the lower right corner of Figure 3).
After saving his modifications, he can return to browsing the model and obtain texts with his new specifications.
File Edit View Go Bookmarks Options Directory ~indow Help [List of Classes] [List of Models] [Reload Models] [Configuration] ~ [About ModeIF.xolame,] Description of the Class" Section' General Observations: A Section must be taught by exactly one F$ofesso, and may ~clong to zezo oz more Cqu~e s.
It must be tako by one ca more Students and may have at most one TA.
Examples: For example, Sectl is a Section and is taught by the professor Jolm Brown.
It belongs to two Courses, Math165 and Math201, and is take~ by two Students.
Frank Belfo~d and Sue Jones.
It has the TA Sally Blake.
Figure 2: Description Used for Validation............,-.,m~ .................
= ....................
I;|? i[Jlc Edll ~ew Go Bookmarks ~Jans Dlrc~r/ ~qndow Help Text Plsm Conflgm'aflon Tat Plmv V -'~'4'~"-(2~  ..,:L ~..cr=,.on o= = .=.,c~s ] 0 z~.~ ~.: ~===~==) i --=~'~ ~omponent I . -[ ~ose ~butes 3peretions :telafions-Teble :~elQ~ons-Te)d -:xemples-Long :xemples-Shod ~~ ~ ~'~ " Rle-Reference Figure 3: Text Plan Configuration Interface Once the model has been validated by the univerFile Edit View Go Bookmarks Options Directory Window _Help [List of Classes] [List of Model.~] [Reload Models] [Co:ffi~otation] [H~ [About ModelEx~01amer] [Q3_~] ~==:==~=~=~=~==::~==~==~:~:~====~===~::::::::::::::::::::::::::::~=~====~ Business Class: "Section' Purpose/Role: Course unit a student can take.
Ed11. Pu~o.~e Attributes: ii Am~u~ JiDeser~ t~n . iiTY~e .................. i i i ...................................... n~ber iSecUo n T'--"T""'7""" identifier ~#1NTF~3 ~ .................
]~'~ :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: Edit Attdbutee Relationships: A Section must be taught by exactly one Ptofee~ot and may belong to zero or more Cotuses.
It must b e taken by one or more Stud~nt.~ and may have at most one TAD server which receives requests via a standard Web CGI interface and returns HTML-formatted documents which can be displayed by any standard Web browser.
The documents generated by MoDEx are always generated dynamically in response to a request, and are composed of human-authored text, generated text and/or generated tables.
The main requests are the following: ModEx m Request i Figure 4: Description Used for Documentation sity administrator, the analyst needs to document it, including annotations about the purpose and rationale of classes and attributes.
To document it, she configures an output text type whose content and structure is compatible with her company's standard for OO documentation.
An example of a description obtained in modifying the text plan of Figure 3 is shown in Figure 4.
(This description follows a format close to Andersen Consulting's standard for documentation).
This description is composed of different types of information: text generated automatically (section Relationships), text entered manually by the analyst because the information required is not retrievable from the CASE tool object model (section Purpose), and tables composed both of information generated automatically and information entered manually (section Attributes).
The analyst then saves the text plan under a new name to use it subsequently for documentation purposes.
Note that while the generated documentation is in hypertext format and can be browsed interactively (as in the I-DOC system of Johnson and Erdem (1995)), it can of course also be printed for traditional paperbased documentation and/or exported to desktop publishing environments.
4 How
MODEX Works As mentioned above, MODEx has been developed as a WWW application; this gives the system a platform-independent hypertext interface.
Figure 5 shows the MoDEx architecture.
MoDEx runs as a Figure 5: MODEx Server Architecture  Text Plan Editing.
This generates an HTML document such as that shown in Figure 3 which allows a user to load/edit/save a text plan macro-structure specification.
A representation corresponding to the text plan of Figure 3 is shown in Figure 6.
Once edited, this representation can be stored permanently in the library of text plans and can be used to generate descriptions.
In this representation, User Text indicates free text entered for a title, while RelationsText and Examples-Short are schema names referring to two of the eight predefined text functions found in a C++ class library supplied with MoDEx.
alidation-Class) Ti~e, User Text Ti~e Schema ~itle Schema i I I I User Text Relations-Text User Text Examples-Short Figure 6: Macro-Stucture for Text Plan of Figure 3  Object Model Loading.
This loads an object model specification and generates a document displaying the list of classes found in the model.
 Description Generation.
This returns a description such as that shown in Figures 2 or 4.
To generate a description, the text planner creates a text structure corresponding to the text plan configuration selected by the user.
This text structure is a constituency tree where the internal nodes define the text organization, while the bottom nodes define its content.
The text content can be specified as syntactic repre255 sentations, as table specification and/or as humanauthored text for the titles and the object model annotations.
The text structure is transformed by the sentence planner which can aggregate the syntactic representations (cf.
conjunctions and in description on Figure 2) or introduce cue words between constituents (cf.
expression For example on Figure 2).
The resulting text structure is then passed to the text realizer which uses REALPRO (Lavoie and Rambow, 1997), a sentence realizer, to realize each individual syntactic representation in the text structure.
Finally, a formatter takes the final text structure to produce an HTML document.
 Object Model Annotation Editing.
This allows the user to edit human-authored annotations of the object model.
This editing can be done via links labelled Edit ...
which appear in Figure 4.
These human-authored texts are used by some of the predefined text functions to generate the descriptions.
5 Outlook
MoDEx is implemented in C++ on both UNIX and PC platforms.
It has been integrated with two object-oriented modeling environments, the ADM (Advanced Development Model) of the KBSA (Knowledge-Based Software Assistant) (Benner, 1996), and with Ptech, a commercial off-the-shelf object modeling tool.
MoDEx has been fielded at a software engineering lab at Raytheon, Inc.
The evaluation of MoDEx is based on anecdotal user feedback obtained during iterative prototyping.
This feedback showed us that the preferences regarding the content of a description can vary depending on the organization (or type of user).
The control that MoDEx gives over the text macro-structure is one step toward satisfying different types of text requirements.
We are currently extending MoDEx in order to give the user a better control over the text micro-structure, by replacing the set of predefined C++ text functions with customizable ASCII specifications.
This feature should make MODEx more easely portable among different types of users.
In addition, we intend to port MODEX to at least two new OO modeling environments in the near future.
Acknowledgments The first version of MoDEx for ADM was supported by USAF Rome Laboratory under contract F30602-92-C0015.
General enhancements to the linguistic machinery were supported by SBIR F30602-92-C-0124, awarded by USAF Rome Laboratory.
Current work on MODEx is supported by the TRP-ROAD cooperative agreement F30602-95-2-0005 with the sponsorship of DARPA and Rome Laboratory.
We are thankful to K.
Benner, M.
DeBellis, J.
Silver and S.
Sparks of Andersen Consulting, and to F.
Ahmed and B.
Bussiere of Raytheon Inc., for their comments and suggestions made during the development of MoDEx.
We also thank T.
Caldwell, R.
Kittredge, T.
Korelsky, D.
McCullough, A.
Nasr and M.
White for their comments and criticism of MoDEx.
Identifying Terms by their Family and Friends Diana Maynard Sophia Ananiadou Dept.
of Computer Science University of Sheffield Regent Court, 211 Portobello St Sheffield, $1 4DP, UK d.
maynard0dcs, shef.
ac. uk Computer Science, School of Sciences University of Saltbrd, Newton Building Saltbrd, M5 4WT, U.K. s.
ananiadou@salf ord.
ac. uk Abstract Multi-word terms are traditionally identified using statistical techniques or, more recently, using hybrid techniques combining statistics with shallow linguistic information.
Al)proaches to word sense disambiguation and machine translation have taken advantage of contextual information in a more meaningflfl way, but terminology has rarely followed suit.
We present an approach to t e r m recognition which identifies salient parts of the context and measures their strength of association to relevant candidate terms.
The resulting list of ranked terms is shown to improve on that produced by traditional methods, in terms of precision and distribution, while the information acquired in the process can also be used for a variety of other applications, such as disambiguation, lexical tuning and term clustering.
Introduction Although contextual information has been previously used, e.g. in general language (Grefenstette, 1994) mid in the NC-Value method for term recognition (Frantzi, 1998; Frantzi and Ananiadou, 1999), only shallow syntactic information is used in these cases.
The T R U C K S approach identifies different; elements of the context which are combined to form the Information Weight, a measure of how strongly related the context is to a candidate term.
The hffbrmation Weight is then combined with the statistical information about a candidate t e r m and its context, acquired using the NC-Value method, to form the SNC-Value.
Section 2 describes the NCValue method.
Section 3 discusses the importance of contextual information and explains how this is acquired.
Sections 4 and 5 describe the hffbrmation Weight and the SNC-VMue respectively.
We finish with an evaluation of the method and draw some conclusions about the work and its fllture.
Although statistical approaches to automatic term recognition, e.g.
(Bourigault, 1992; Daille et al., 1994; Enguehard and Pantera, 1994; 3usteson and Katz, 1995; Lauriston, 1996), have achieved relative success over the years, the addition of suitable linguistic information has the potential to enhance results still further, particularly in the case of small corpora or very specialised domains, where statistical information may not be so accurate.
One of the main reasons for the current lack of diversity in approaches to term recognition lies in the difficulty of extracting suitable semantic information from speeialised corpora, particularly in view of the lack of appropriate linguistic resources.
The increasing development of electronic lexieal resources, coupled with new methods for automatically creating and fine-tuning them from corpora, has begun to pave the way for a more dominant appearance of natural language processing techniques in the field of terminology.
The T R U C K S approach to t e r m recognition (Term Recognition Using Combined Knowledge Sources) focuses on identifying relevant contextual information from a variety of sources, in order to enhance traditional statistical techniques of t e r m recognition.
The NC-Value m e t h o d The NC-Value method uses a combination of linguistic and statistical information.
Terms are first extracted from a corpus using the C-Value method (Frantzi and Ananiadou, 1999), a measure based on frequency of occurrence and term length.
This is defined formally as: is not nested l~('n,) ~b~T~f(b)) a is nested where a is the candidate string, f(a) is its frequency in the corpus, eT, is the set of candidate terms that contain a, P(Ta) is the number of these candidate terms.
Two different cases apply: one for terms t h a t are found as nested, and one for terms that are not.
If a candidate string is not found as nested, its termhood is calculated from its total frequency and length.
If it is found as nested, termhood is calculated from its total frequency, length, frequency as a nested string, fiand the tmmber of longer candidate terms it; ai)l)ears in.
The NC-Value metho(1 builds oil this by incorl)orating contextual information in the form of a context factor for each candidate term.
A context word can be any noun, adjective or verb apI)earing within a fixed-size window of tim candidate term.
Each context word is assigned a weight, based on how frequently it appears with a ca lldidate term.
Ttmse weights m'e titan SUllslned for all colltext words relative to a candidate term.
The Context l"actor is combined with the C-Value to form tlm NC-Value: Category Verb Prep Noun Adj Weight 1.2 1.1 0.9 0.7 Table 1: We.ights for categories of boundary words where a is tile candidate term, Cvahte(a) is the Cvalue fin' tlm candidate term, CF(a) is the context factor tbr the candidate term.
Terminological knowledge Ternfinological knowledge concerns the terminological sta.tus of context words.
A context word whicll is also a term (whicll we call a context term) is likely to 1)e a better indicator than one wlfich is not.
The terminological status is determined by applying the NC-Value at)proach to the corlms, and considering tile top third of the list; of ranked results as valid terms.
A context term (CT) weight is then produced fin" each candidate term, based on its total frequency of occurrence with all relewmt context terms.
The CT weight is formally described as follows: Contextual Information: a Term's where a is the candidate term, 7', is the set: of context terms of a, d is a word from Ta, fa(d) is the frequency of d as a context term of a.
Semantic knowledge Semantic knowledge is obtained about context terms using the UMLS Metathesaurus and Semantic Network (NLM, 1997).
The former provides a semantic tag for each term, such as Acquired Abnormality.
The latte, r provides a hierarchy of semantic types, from wlfich we compute the similarity between a candidate term and the context I;erms it occurs with.
An example of part of tim network is shown in Figure Social Life Just as a person's social life can provide valuable clues al)out their i)ersonality, so we can gather much information about the nature of a term by investigating the coral)any it keeps.
We acquire this knowledge by cxtra:ting three different types of contextual information: 1.
syntactic; 2.
terminologic~fl; Syntactic knowledge Syntactic knowledge is based on words in the context which occur immediately t)efore or afl;er a candidatc term, wtfich we call boundary words.
Following "barrier word" al)proaches to term recoglfition (Bourigault, 1992; Nelson et al., 1995), where partitular syntactic categories are used to delimit era> didate terms, we develop this idea fllrther by weighting boundary words according to tlmir category.
The weight for each category, shown in Table 1, is all)cate(1 according to its relative likelihood of occurring with a term as opposed to a non-term.
A verb, therefore, occurring immediately before or after a candidate, term, is statistically a better indicator of a term than an adjective is.
By "a better indicator", we mean that a candidate term occurring with it is more likely to be valid.
Each candidate term is assigned a syntactic weight, calculated by summing the category weights tbr the context bomsdary words occurring with it.
Similarity is measured because we believe that a context term which is semantically similar to a candidate term is more likely to be significant than one wlfieh is less similar.
We use tim method for semantic distance described in (M~\ynard and Ananiadou, 1999a), wtfich is based on calculating the vertical position and horizontal distance between nodes in a hierarchy.
Two weights are cMculated:  positionah measured by the combined distance from root to each node measured by the number of shared common ancestors multiplied by the munber of words (usuMly two).
Similarity between the nodes is calculated by dividing tim commomflity weight by the 1)ositional weight to t)roduce a figure between 0 and 1, I being the ease The Information Weight The three individual weights described above are calculated for all relevant context words or context terms.
The total weights for the context are then combined according to the following equation: beC.
[TAIII OIIGANISM ITAIIlll ALGA Figure 1: Fragment of the Semantic Network where tile two nodes are identical, and 0 being the case where there is no common ancestor.
This is formally defined as follows: where a is the candidate term, Cais the set of context words of a, b is a word from C,, f,(b) is tlm frequency of b as a context word of a, syn~(b) is the syntactic weight of b as a context word of a, T.
is the set of context terms of a, d is a word fl'om T., fi,(d) is the frequency of d as a context term of a, sims(d) is the similarity weight of d as a context term of a.
This basically means t h a t the Infornlation Weight is composed of the total terminological weight, 511151tiplied by tile total semantic weight, and then added to the total syntactic weight of all the context words or context terms related to the candidate term.
where corn(w1...w,~) is the commonality weight of words The SNC-Value pos('wl...w,~) is the positional weight of words Let us take an example from the UMLS.
The similarity between a term t)elonging to the semantic category Plant and one belonging to the category Fungus would be calculated as follows:Tile Information Weight gives a score for each candidate term based on the ilnt)ortance of the contextual intbrmation surrounding it.
To obtain the final SNCValue ranking, the Information Weight is combined with the statistical information obtained using the NC-Vahm nmthod, as expressed formally below: where  Plant has the semantic code T A l l l and Fungus has the semantic code T A l l 2 .  The commonality weight is the number of nodes in common, multiplied by the number of terms we are considering.
T A l l l and T A l l 2 have 4 nodes in common (T, TA, TA1 and T A l l ) . So the weight will be 4 * 2 = 8.
 The positional weight is the total height of each of the terms (where tile root node has a height of 1).
T A l l l has a height of 5 (T, TA, TA1, T A l l and T A l l 1 ), and TAl12 also has a height of 5 (T, TA, TA1, T A l l and T A l l 2 ) . The weight will therefore be 5 + 5 = 10.
 The similarity weight is tile comlnonality weight divided by the positional weight, i.e. a is the candidate t e r m NCValue(a) is the NC-Value of a I W is the Inqmrtance Weight of a For details of the NC-Value, see (l:5'antzi and Ananiadou, 1999).
An example of the final result is shown in Table 2.
This corot)ares tile top 20 results from the SNCValue list with the top 20 from the NC-Value list.
The terms in italics are those which were considered as not valid.
We shall discuss the results in more detail in the next section, but we can note here three points.
Firstly, the weights for the SNC-Value are substantially greater than those for the NC-Vahm.
This, in itself, is not important, since it, is the position in the list, i.e. the relative weight, rather t h a n the absolute weight, which is important.
Secondly, we can see that there are more valid terms in the SNC-Value results than in the NC-Value results.
It Table 2: Top 20 results for the SNC-VaIue and NC-Value in hard to make flu:ther judgements based on this list alone, 1)ecause we cmmot s~3; wlmther on(; ter]u is 1)etter than another, if tiE(; two terms are both valid.
Thirdly, we can nee that more of the top 20 terms are valid tin' tim SNC-Vahm than for the NCValue: 17 (851X,) as ot)t)osed to 10 (50%).
discrei)an(:y 1)etween this lint and the lint validated by the manual experts (only 20% of the terms they judged valid were fOtlEl(1 ill the UMLS).
There are also further limitations to the UMLS, such as the fact that it is only nl)e(:ific to medicine in general, 1)ut not to eye t)athology, and the fact that it; is organised ill nllch a way that only the preferred terms, and not lexical variants, m'e actively and (:onnistently 1)r(~sent.
We first evaluate the similarity weight individually, since this is the main 1)rinciple on which the SNC-\Sflue method relies.
We then ewduate the SNC-VaIue as a whole t)y comparing it with the NCValue, so I;hat we can ewfluate the impact of tile addition of the deel)er forms of linguistic information incorl)orated in {:he hnI)ortance Weight.
Evaluation The SNC-Value method wan initially t(;sted on a eorl)US of 800,000 eye t)athoh)gy reI)ortn, which had 1)een tagged with the Brill t)art-of-nl)eeeh tagger (Brill, 1992).
The ca.ndidate terms we,'e first extracted using the NC-Value method (lhantzi, 1998), and the SNC-Value was then (:alculated.
To exvduate the results, we examined the p(.'rformanee of the similarity weight alone, and the overall 1)erformance of the system.
Similarity Weight Evaluation m e t h o d s The main evaluation i)rocedure was carried out with resl)ect to a manual assessment of tim list of terms l)y 2 domain exI)erts.
There are, however, 1)roblems associated with such an evaluation.
Firstly, there ix no gold standm:d of evaluation, and secondly, manual evaluation is both fallil)le and sul)jective.
To avoid this 1)rol)lem, we measure the 1)erformance of the system ill relative termn rather than in absolute terms, by measuring the improveln(mt over the results of tile NC-Value as eomt)ared with mmmal evahlation.
Although we could have used the list of terms 1)rovided in the UMLS, instead of a manu~ ally evahlated list, we found that there was a huge One of the 1)roblems with our method of calculating similarity is that it relies on a 1)re-existing lexi(:al resource, which Eneans it is 1)rone to errors and omissions.
Bearing in mind its innate inadequacies, we can nevertheless evaluate the expected theoretical performance of tilt measure by concerning ourselves only with what is covered by the thesaurus.
This means that we assume COml)leteness (although we know that this in not the case) and evahtate it accordingly, ignoring anything which may be inissing.
The semantic weight ix based on the premise that tile more similar a context term is to the candidate term it occurs with, the better an indicator that context term is.
So the higher the total semantic weight Section top set middle set b o t t o m set Table 3: Semantic weights of terms and non-terms for the candidate term, the higher the ranking of the term and the better the chance that the candidate term is a valid one.
To test the performmme of the semantic weight, we sorted the terms in descending order of their semantic weights and divided the list into 3, such that the top third contained the terms with the highest semantic weights, and the b o t t o m third contained those with the lowest.
We then compared how m a n y valid and non-valid terms (according to the manual evaluation) were contained in each section of the list,.
Tile results, depicted in Table 3, can be interpreted as follows.
In the top third of the list;, 76% were terms and 24% were non-terms, whilst in the middle third, 56% were terms and 44% were non-terms, and so on.
This means that most of the valid terms are contained in the top third of tile list mid the fewest valid terms are contained in the bottom third of the list.
Also, the proportion of terms to non-terms in tile top of tile list is such that there are more terms than non-terms, whereas in the b o t t o m of the list; there are more non-terms than ternis.
This therefore demonstrates two things:  more of' the terms with the highest semantic weights are valid, and fewer of those with the lowest semmitic weights are valid;  more valid terms have high semantic weights than non-terms, mid more non-terms have lower semantic weights than valid terms.
We also tested the similarity measure to see whether adding sosne statistical information would improve its results, and regulate any discrepancies in tile uniformity of the hierarchy.
The methods which intuitively seem most plausible are based on information content, e.g.(Resnik, 1995; Smeaton and Quigley, 1996).
The informatiosl content of a node is related to its probability of occurrence in the corpus.
Tile snore fi'equently it appears, the snore likely it is to be important in terms of conveying information, and therefore the higher weighting it should receive.
We performed experiments to cosnpare two such methods with our similarity measure.
The first considers the probability of the MSCA of the two terms (the lowest node which is an ancestor of both), whilst the second considers the probability of the nodes of the terms being colnpared.
However, the tindings showed a negligible difference between the three methods, so we conchlde that there is no Table 4: Precision of SNC-Vahle and NC-Value advantage to be gained by adding statistical int'ormation, fbr this particular corpus.
It; is possible that with a larger corlms or different hierarchy, this might slot be the case.
Overall E v a l u a t i o n of t h e S N C V a l u e We first; compare the precision rates for the SNCValue and the NC-Value (Table 4), by dividing tile ranked lists into 10 equal sections.
Each section contains 250 terms, marked as valid or invalid by the manual experts.
In the top section, the precision is higher for the SNC-Value, and in the b o t t o m section, it is lower.
This indicates that the precision span is greater fl~r the SNC-Value, and therefore that the ranking is improved.
The distribution of valid terms is also better for the SNC-Value, since of the valid terms, more appear at the top of the list than at the bottom.
Looking at Figure 2, we can see that the SNCValue graph is smoother than that of the NC-Vahle.
We can compare the graphs niore accurately using a method we call comparative upward trend.
Becruise there is no one ideal graph, we instead measure how much each graph deviates from a monotonic line downwards.
This is calculated by dividing the total rise in precision percentage by the length of the graph.
A graph with a lower upward trend will therefore be better than a graph with a higher upward trend.
If we compare the upward trends of the two graphs, we find that the trend for the SNCValue is 0.9, whereas the trend for the NC-Value is 2.7.
This again shows that the SNC-Value rmiking is better thmi the NC-Value ranking, since it is more consistent.
Table 5 shows a more precise investigation of the top portion of the list, (where it is to be expected that ternis are most likely to be wflid, and which is therefore the inost imi)ortant part of the list) We see that the precision is most iml)roved here, both in terms of accuracy and in terms of distribution of weights.
At the I)ottom of the top section, the PlccJshm T~ T T I Scctionollist tics for creating such a thesaurus automatically, or entrancing an existing one, using the contextual information we acquire (Ushioda, 1996; MaynaM and Anmfiadou, 1999b).
There is much scope tbr filrther extensions of this research.
Firstly, it; could be extended to other (lomains and larger corpora, in order to see the true benefit of such a.n apl)roach.
Secondly, the thesaurus could be tailored to the corpus, as we have mentioncd.
An incremental approach might be possible, whereby the similarity measure is combined with statistical intbrmation to tune an existing ontology.
Also, the UMLS is not designed as a linguistic resource, but as an information resource.
Some kind of integration of the two types of resource would be usefifl so that, for example, lexical variation could be more easily handled.
Table 5: Precision of SNC-\Sdue and NC-Vahm for top 250 terms precision is much higher for the SNC-Value.
This is important because ideally, all the terms in this part of the list should be valid, 7 Conclusions In this paper, we have described a method for multiword term extraction which improves on traditional statistical at)proaches by incorporating more specific contextual information.
It focuses particularly on measuring the strength of association (in semantic terms) l)etween a candidate term and its context.
Evahlation shows imi)rovement over the NC-Vahm approach, although the percentages are small.
This is largely l)ecmlse we have used a very small corpus for testing.
The contextuM information acquired can also be used for a mmlber of other related tasks, such as disambiguation and clustering.
C1D2D8CTD6D0CTCPDACTCS D7CTD1CPD2D8CXCR CXD2D8CTD6D4D6CTD8CPD8CXD3D2 CXD2 CTD2DACXD6D3D2D1CTD2D8B9CQCPD7CTCS D4CPD6D7CXD2CV A3 CFCXD0D0CXCPD1 CBCRCWD9D0CTD6 BVD3D1D4D9D8CTD6 CPD2CS C1D2CUD3D6D1CPD8CXD3D2 CBCRCXCTD2CRCT BWCTD4D8BA CDD2CXDACTD6D7CXD8DD D3CU C8CTD2D2D7DDD0DACPD2CXCP C8CWCXD0CPCSCTD0D4CWCXCPB8 C8BT BDBLBDBCBF D7CRCWD9D0CTD6BSD0CXD2CRBACRCXD7BAD9D4CTD2D2BACTCSD9 BTCQD7D8D6CPCRD8 CCCWCXD7 D4CPD4CTD6 CTDCD8CTD2CSD7 CP D4D3D0DDD2D3D1CXCPD0B9D8CXD1CT D4CPD6D7CXD2CV CPD0B9 CVD3D6CXD8CWD1 D8CWCPD8 D6CTD7D3D0DACTD7 D7D8D6D9CRD8D9D6CPD0 CPD1CQCXCVD9CXD8DD CXD2 CXD2D4D9D8 D7CTD2D8CTD2CRCTD7 CQDD CRCPD0CRD9D0CPD8CXD2CV CPD2CS CRD3D1D4CPD6CXD2CV D8CWCT CSCTD2D3B9 D8CPD8CXD3D2D7 D3CU D6CXDACPD0 CRD3D2D7D8CXD8D9CTD2D8D7B8 CVCXDACTD2 D7D3D1CT D1D3CSCTD0 D3CU D8CWCT CPD4D4D0CXCRCPD8CXD3D2 CTD2DACXD6D3D2D1CTD2D8 B4CBCRCWD9D0CTD6B8 BEBCBCBDB5BA CCCWCT CPD0CVD3D6CXD8CWD1 CXD7 CTDCD8CTD2CSCTCS D8D3 CXD2CRD3D6D4D3D6CPD8CT CP CUD9D0D0 D7CTD8 D3CU D0D3CVCXCRCPD0 D3D4CTD6CPD8D3D6D7B8 CXD2CRD0D9CSCXD2CV D5D9CPD2D8CXACCTD6D7 CPD2CS CRD3D2CYD9D2CRB9 D8CXD3D2D7B8 CXD2D8D3 D8CWCXD7 CRCPD0CRD9D0CPD8CXD3D2 DBCXD8CWD3D9D8 CXD2CRD6CTCPD7CXD2CV D8CWCT CRD3D1D4D0CTDCCXD8DD D3CU D8CWCT D3DACTD6CPD0D0 CPD0CVD3D6CXD8CWD1 CQCTDDD3D2CS D4D3D0DDD2D3B9 D1CXCPD0 D8CXD1CTB8 CQD3D8CW CXD2 D8CTD6D1D7 D3CU D8CWCT D0CTD2CVD8CW D3CU D8CWCT CXD2B9 D4D9D8 CPD2CS D8CWCT D2D9D1CQCTD6 D3CU CTD2D8CXD8CXCTD7 CXD2 D8CWCT CTD2DACXD6D3D2D1CTD2D8 D1D3CSCTD0BA BD C1D2D8D6D3CSD9CRD8CXD3D2 CCCWCT CSCTDACTD0D3D4D1CTD2D8 D3CU D7D4CTCPCZCTD6B9CXD2CSCTD4CTD2CSCTD2D8 D1CXDCCTCSB9 CXD2CXD8CXCPD8CXDACT D7D4CTCTCRCWCXD2D8CTD6CUCPCRCTD7B8 CXD2 DBCWCXCRCW D9D7CTD6D7 D2D3D8 D3D2D0DD CPD2D7DBCTD6 D5D9CTD7D8CXD3D2D7 CQD9D8 CPD0D7D3 CPD7CZ D5D9CTD7D8CXD3D2D7 CPD2CS CVCXDACT CXD2B9 D7D8D6D9CRD8CXD3D2D7B8 CXD7 CRD9D6D6CTD2D8D0DD D0CXD1CXD8CTCS CQDD D8CWCT CXD2CPCSCTD5D9CPCRDD D3CU CTDCCXD7D8CXD2CV CRD3D6D4D9D7B9CQCPD7CTCS CSCXD7CPD1CQCXCVD9CPD8CXD3D2 D8CTCRCWD2CXD5D9CTD7BA CCCWCXD7 D4CPD4CTD6 CTDCD4D0D3D6CTD7 D8CWCT D9D7CT D3CU D7CTD1CPD2D8CXCR CPD2CS D4D6CPCVB9 D1CPD8CXCR CXD2CUD3D6D1CPD8CXD3D2B8 CXD2 D8CWCT CUD3D6D1 D3CU D8CWCT CTD2D8CXD8CXCTD7 CPD2CS D6CTD0CPD8CXD3D2D7 CXD2 D8CWCT CXD2D8CTD6CUCPCRCTCS CPD4D4D0CXCRCPD8CXD3D2B3D7 D6D9D2B9D8CXD1CT CTD2B9 DACXD6D3D2D1CTD2D8B8 CPD7 CPD2 CPCSCSCXD8CXD3D2CPD0 D7D3D9D6CRCT D3CU CXD2CUD3D6D1CPD8CXD3D2 D8D3 CVD9CXCSCT CSCXD7CPD1CQCXCVD9CPD8CXD3D2BA C1D2 D4CPD6D8CXCRD9D0CPD6B8 D8CWCXD7 D4CPD4CTD6 CTDCD8CTD2CSD7 CPD2 CTDCCXD7D8CXD2CV D4CPD6D7B9 CXD2CV CPD0CVD3D6CXD8CWD1 D8CWCPD8 CRCPD0CRD9D0CPD8CTD7 CPD2CS CRD3D1D4CPD6CTD7 D8CWCT CSCTB9 D2D3D8CPD8CXD3D2D7 D3CU D6CXDACPD0 D4CPD6D7CT D8D6CTCT CRD3D2D7D8CXD8D9CTD2D8D7 CXD2 D3D6CSCTD6 D8D3 D6CTD7D3D0DACT D7D8D6D9CRD8D9D6CPD0 CPD1CQCXCVD9CXD8DD CXD2 CXD2D4D9D8 D7CTD2D8CTD2CRCTD7 B4CBCRCWD9D0CTD6B8 BEBCBCBDB5BA CCCWCT CPD0CVD3D6CXD8CWD1 CXD7 CTDCD8CTD2CSCTCS D8D3 CXD2CRD3D6B9 D4D3D6CPD8CT CP CUD9D0D0 D7CTD8 D3CU D0D3CVCXCRCPD0 D3D4CTD6CPD8D3D6D7 CXD2D8D3 D8CWCXD7 CRCPD0CRD9B9 D0CPD8CXD3D2 D7D3 CPD7 D8D3 CXD1D4D6D3DACT D8CWCT CPCRCRD9D6CPCRDD D3CU D8CWCT D6CTD7D9D0D8CXD2CV CSCTD2D3D8CPD8CXD3D2D7 DF CPD2CS D8CWCTD6CTCQDD CXD1D4D6D3DACT D8CWCT CPCRCRD9D6CPCRDD D3CU D4CPD6D7CXD2CV DF DBCXD8CWD3D9D8 CXD2CRD6CTCPD7CXD2CV D8CWCT CRD3D1D4D0CTDCCXD8DD D3CU D8CWCT D3DACTD6CPD0D0 CPD0CVD3D6CXD8CWD1 CQCTDDD3D2CS D4D3D0DDD2D3D1CXCPD0 D8CXD1CT B4CQD3D8CW CXD2 D8CTD6D1D7 D3CU D8CWCT D0CTD2CVD8CW D3CU D8CWCT CXD2D4D9D8 CPD2CS D8CWCT D2D9D1CQCTD6 D3CU CTD2D8CXD8CXCTD7 CXD2 D8CWCT CTD2DACXD6D3D2D1CTD2D8 D1D3CSCTD0B5BA CCCWCXD7 D4CPD6D7CXD1D3D2DD CXD7 CPCRCWCXCTDACTCS CQDD D0D3CRCPD0CXDECXD2CV CRCTD6D8CPCXD2 CZCXD2CSD7 D3CU D7CTD1CPD2D8CXCR D6CTD0CPD8CXD3D2D7 CSD9D6CXD2CV D4CPD6D7CXD2CVB8 D4CPD6D8CXCRD9D0CPD6D0DD D8CWD3D7CT CQCTD8DBCTCTD2 D5D9CPD2D8CXACCTD6D7 CPD2CS D8CWCTCXD6 D6CTD7D8D6CXCRD8D3D6 CPD2CS CQD3CSDD CPD6CVD9D1CTD2D8D7 A3 CCCWCT CPD9D8CWD3D6 DBD3D9D0CS D0CXCZCT D8D3 D8CWCPD2CZ BWCPDACXCS BVCWCXCPD2CVB8 C3CPD6CXD2 C3CXD4B9 D4CTD6B8 CPD2CS BTD0CTDCCPD2CSCTD6 C3D3D0D0CTD6B8 CPD7 DBCTD0D0 CPD7 D8CWCT CPD2D3D2DDD1D3D9D7 D6CTDACXCTDBCTD6D7 CUD3D6 CRD3D1D1CTD2D8D7 D3D2 D8CWCXD7 D1CPD8CTD6CXCPD0BA CCCWCXD7 DBD3D6CZ DBCPD7 D4CPD6D8CXCPD0D0DD D7D9D4B9 D4D3D6D8CTCS CQDD C6CBBY C1C1CBB9BLBLBCBCBEBLBJ CPD2CS BWBTCAC8BT C6BIBIBCBCBDB9BCBCB9BDB9BKBLBDBHBA B4D7CXD1CXD0CPD6 D8D3 D8CWCT DBCPDD CSCTD4CTD2CSCTD2CRCXCTD7 CQCTD8DBCTCTD2 D4D6CTCSCXCRCPD8CT CPD2CS CPD6CVD9D1CTD2D8 CWCTCPCS DBD3D6CSD7 CPD6CT D0D3CRCPD0CXDECTCS CXD2 D0CTDCCXCRCPD0CXDECTCS CUD3D6D1CPD0CXD7D1D7 D7D9CRCW CPD7 D8D6CTCT CPCSCYD3CXD2CXD2CV CVD6CPD1D1CPD6D7B5B8 CXD2 D3D6B9 CSCTD6 D8D3 CPDAD3CXCS CRCPD0CRD9D0CPD8CXD2CV CTDCD4D3D2CTD2D8CXCPD0 CWCXCVCWCTD6B9D3D6CSCTD6 CSCTB9 D2D3D8CPD8CXD3D2D7 CUD3D6 CTDCD4D6CTD7D7CXD3D2D7 D0CXCZCT CVCTD2CTD6CPD0CXDECTCS D5D9CPD2D8CXACCTD6D7BA BE BUCPD7CXCR CPD0CVD3D6CXD8CWD1 CCCWCXD7 D7CTCRD8CXD3D2 CSCTD7CRD6CXCQCTD7 D8CWCT CQCPD7CXCR CTD2DACXD6D3D2D1CTD2D8B9CQCPD7CTCS D4CPD6D7CTD6 B4CBCRCWD9D0CTD6B8 BEBCBCBDB5 DBCWCXCRCW DBCXD0D0 CQCT CTDCD8CTD2CSCTCS CXD2 CBCTCRB9 D8CXD3D2 BFBA BUCTCRCPD9D7CT CXD8 DBCXD0D0 CRD6D9CRCXCPD0D0DD D6CTD0DD D3D2 D8CWCT CSCTD2D3D8CPB9 D8CXD3D2D7 B4D3D6 CXD2D8CTD6D4D6CTD8CPD8CXD3D2D7B5 D3CU D4D6D3D4D3D7CTCS CRD3D2D7D8CXD8D9CTD2D8D7 CXD2 D3D6CSCTD6 D8D3 CVD9CXCSCT CSCXD7CPD1CQCXCVD9CPD8CXD3D2B8 D8CWCT D4CPD6D7CTD6 DBCXD0D0 CQCT CSCTACD2CTCS D3D2 CRCPD8CTCVD3D6CXCPD0 CVD6CPD1D1CPD6D7 B4BTCYCSD9CZCXCTDBCXCRDEB8 BDBLBFBHBN BUCPD6B9C0CXD0D0CTD0B8 BDBLBHBFB5B8 DBCWD3D7CT CRCPD8CTCVD3D6CXCTD7 CPD0D0 CWCPDACTDBCTD0D0 CSCTB9 ACD2CTCS D8DDD4CTD7 CPD2CS DBD3D6D7D8B9CRCPD7CT CSCTD2D3D8CPD8CXD3D2D7BA CCCWCTD7CT CRCPD8B9 CTCVD3D6CXCTD7 CPD6CT CSD6CPDBD2 CUD6D3D1 CP D1CXD2CXD1CPD0 D7CTD8 D3CU D7DDD1CQD3D0D7 BV D7D9CRCW D8CWCPD8BM C6C8 BEBVCPD2CS CB BEBVBN CXCU ADBN BEBVD8CWCTD2 ADBP BEBVCPD2CS ADD2 BEBVBM C1D2D8D9CXD8CXDACTD0DDB8 D8CWCT CRCPD8CTCVD3D6DD C6C8 CSCTD7CRD6CXCQCTD7 CP D2D3D9D2 D4CWD6CPD7CT CPD2CS D8CWCT CRCPD8CTCVD3D6DD CB CSCTD7CRD6CXCQCTD7 CP D7CTD2D8CTD2CRCTB8 CPD2CS D8CWCT CRD3D1D4D0CTDC CRCPD8CTCVD3D6CXCTD7 ADBPCPD2CS ADD2 CSCTD7CRD6CXCQCT COCP AD D0CPCRCZCXD2CV CP  D8D3 D8CWCT D6CXCVCWD8B3 CPD2CS COCP AD D0CPCRCZCXD2CV CP  D8D3 D8CWCT D0CTCUD8B3 D6CTD7D4CTCRD8CXDACTD0DDBN D7D3 CUD3D6 CTDCCPD1D4D0CT CBD2C6C8 DBD3D9D0CS CSCTD7CRD6CXCQCT CP CSCTCRD0CPD6CPD8CXDACTDACTD6CQ D4CWD6CPD7CT D0CPCRCZCXD2CV CPD2 C6C8 D7D9CQCYCTCRD8 D8D3 CXD8D7 D0CTCUD8 CXD2 D8CWCT CXD2D4D9D8BA CCCWCT D8DDD4CT CC CPD2CS DBD3D6D7D8B9CRCPD7CT B4D1D3D7D8 CVCTD2CTD6CPD0B5 CSCTD2D3D8CPB9 D8CXD3D2 CF D3CU CTCPCRCW D4D3D7D7CXCQD0CT CRCPD8CTCVD3D6DD CPD6CT CSCTACD2CTCS CQCTD0D3DBB8 CVCXDACTD2 CP D7CTD8 D3CU CTD2D8CXD8CXCTD7 BX CPD7 CPD2 CTD2DACXD6D3D2D1CTD2D8BM CCB4CBB5 BP D8 BM D8D6D9D8CW DACPD0D9CT CFB4CBB5 BP CUCCCACDBXBNBYBTC4CBBXCV CCB4C6C8B5BPCT BMCTD2D8CXD8DD CFB4C6C8B5 BP BX CCB4ADBPB5BPCWCCB4B5BNCCB4ADB5CX CFB4ADBPB5BPCFB4B5 A2CFB4ADB5 CCB4ADD2B5BPCWCCB4B5BNCCB4ADB5CX CFB4ADD2B5BPCFB4B5 A2CFB4ADB5 CCCWCT CSCTD2D3D8CPD8CXD3D2 BW D3CU CPD2DD D4D6D3D4D3D7CTCS CRD3D2D7D8CXD8D9CTD2D8 CXD7 CRD3D2D7D8D6CPCXD2CTCS D8D3 CQCT CP D7D9CQD7CTD8 D3CU D8CWCT DBD3D6D7D8B9CRCPD7CT CSCTD2D3B9 D8CPD8CXD3D2 CF D3CU D8CWCT CRD3D2D7D8CXD8D9CTD2D8B3D7 CRCPD8CTCVD3D6DDBN D7D3 CP CRD3D2B9 D7D8CXD8D9CTD2D8 D3CU CRCPD8CTCVD3D6DD C6C8 DBD3D9D0CS CSCTD2D3D8CT CP D7CTD8 D3CU CTD2B9 D8CXD8CXCTD7B8 CUCT BD BNCT BE BNBMBMBMCVB8 CPD2CS CP CRD3D2D7D8CXD8D9CTD2D8 D3CU CRCPD8CTCVD3D6DD CBD2C6C8 DBD3D9D0CS CSCTD2D3D8CT CP D7CTD8 D3CU CTD2D8CXD8DD A2 D8D6D9D8CW DACPD0D9CT D4CPCXD6D7B8 CUCWCT BD BNCCCACDBXCXBNCWCT BE BNBYBTC4CBBXCXBNBMBMBMCVBA C6D3D8CT D8CWCPD8 D2D3 CSCTD2D3D8CPD8CXD3D2 D3CU CP CRD3D2D7D8CXD8D9CTD2D8 CRCPD2 CRD3D2D8CPCXD2 D1D3D6CT D8CWCPD2 C7B4CYBXCY DA B5 CSCXABCTD6CTD2D8 CTD0CTD1CTD2D8D7B8 DBCWCTD6CT DA CXD7 CP DACPD0CTD2CRDD D1CTCPB9 D7D9D6CT D3CU D8CWCT D2D9D1CQCTD6D3CUC6C8D7DDD1CQD3D0D7 D3CRCRD9D6D6CXD2CV DBCXD8CWCXD2 D8CWCT CRD3D2D7D8CXD8D9CTD2D8B3D7 CRCPD8CTCVD3D6DDBA CCCWCXD7 D4CPD4CTD6 DBCXD0D0 D9D7CT D8CWCT CUD3D0D0D3DBCXD2CV CSCTACD2CXD8CXD3D2 D3CU CP CRCPD8CTCVD3D6CXCPD0 CVD6CPD1D1CPD6 B4BVBZB5BM BWCTACD2CXD8CXD3D2 BT CRCPD8CTCVD3D6CXCPD0 CVD6CPD1D1CPD6 BZ CXD7 CP CUD3D6D1CPD0 CVD6CPD1D1CPD6 B4C6BNA6BNC8B5 D7D9CRCW D8CWCPD8BM AF A6 CXD7 CP ACD2CXD8CT D7CTD8 D3CU DBD3D6CSD7 DBBN AF C8 CXD7 CP ACD2CXD8CT D7CTD8 D3CU D4D6D3CSD9CRD8CXD3D2D7 CRD3D2D8CPCXD2CXD2CVBM AD AX DB CUD3D6 CPD0D0 DBBEA6B8 DBCXD8CW AD BEBVB8 AD AX ADBP  CUD3D6 CTDACTD6DD D6D9D0CT ADBP AX BMBMBM CXD2 C8B8 AD AX  ADD2 CUD3D6 CTDACTD6DD D6D9D0CT ADD2 AX BMBMBM CXD2 C8B8 CPD2CS D2D3D8CWCXD2CV CTD0D7CTBN AF C6 CXD7 D8CWCT D2D3D2D8CTD6D1CXD2CPD0 D7CTD8 CUAD CY AD AX BMBMBM BE C8CVBA CPD2CS D8CWCT CUD3D0D0D3DBCXD2CV CSCTCSD9CRD8CXDACT D4CPD6D7CTD6B8 BD DBCWCXCRCW DBCXD0D0 CQCT CTDCD8CTD2CSCTCS D0CPD8CTD6 D8D3 CWCPD2CSD0CT CP D6CXCRCWCTD6 D7CTD8 D3CU D7CTD1CPD2D8CXCR D3D4B9 CTD6CPD8CXD3D2D7BA CCCWCT D4CPD6D7CTD6 CXD7 CSCTACD2CTCS DBCXD8CWBM AF CRD3D2D7D8CXD8D9CTD2D8CRCWCPD6D8 CXD8CTD1D7 CJCXBNCYBNADCL CSD6CPDBD2 CUD6D3D1 C1 D2 BC A2 C1 D2 BC A2C6B8 CXD2CSCXCRCPD8CXD2CV D8CWCPD8 D4D3D7CXD8CXD3D2D7 CX D8CWD6D3D9CVCW CY CXD2 D8CWCT CXD2D4D9D8 CRCPD2 CQCT CRCWCPD6CPCRD8CTD6CXDECTCS CQDD CRCPD8CTCVD3D6DD ADBN AF CP D0CTDCCXCRCPD0 CXD8CTD1 CJCXBNCYBNADCL CUD3D6 CTDACTD6DD D6D9D0CT AD AX DB BE C8 CXCU DB D3CRCRD9D6D7 CQCTD8DBCTCTD2 D4D3D7CXD8CXD3D2D7 CX CPD2CS CY CXD2 D8CWCT CXD2D4D9D8BN AF CP D7CTD8 D3CU D6D9D0CTD7 D3CU D8CWCT CUD3D6D1BM CJCXBNCZBNADBPCLCJCZBNCYBNCL CJCXBNCYBNADCL CUD3D6 CPD0D0 AD AX ADBP  BE C8BN CXBNCYBNCZ BE C1 D2 BC B8 CJCZBNCYBNADD2CLCJCXBNCZBNCL CJCXBNCYBNADCL CUD3D6 CPD0D0 AD AX  ADD2 BE C8BN CXBNCYBNCZ BE C1 D2 BC BA CPD2CS CRCPD2 D6CTCRD3CVD2CXDECT CPD2 D2B9D0CTD2CVD8CW CXD2D4D9D8 CPD7 CP CRD3D2D7D8CXD8D9CTD2D8 D3CU CRCPD8CTCVD3D6DD AD B4CUD3D6 CTDCCPD1D4D0CTB8 CPD7 CPD2 CBB5 CXCU CXD8 CRCPD2 CSCTCSD9CRCT D8CWCT CRCWCPD6D8 CXD8CTD1 CJBCBND2BNADCLBA CCCWCXD7 D4CPD6D7CTD6 CRCPD2 CQCT CXD1D4D0CTD1CTD2D8CTCS CXD2 CP CSDDD2CPD1CXCR D4D6D3B9 CVD6CPD1D1CXD2CV CPD0CVD3D6CXD8CWD1B8 D9D7CXD2CV D8CWCT D6CTCRD9D6D7CXDACT CUD9D2CRD8CXD3D2BM BYB4DCB5BP CN CP BD BMBMBMCP CZ D7BMD8BM CP BD BMBMBMCP CZ DC CZ CM CXBPBD BYB4CP CX B5 B4DBCWCTD6CT DCBNCP BD BMBMBMCP CZ CPD6CT D4D6D3D4D3D7CTCS CRD3D2D7D8CXD8D9CTD2D8D7 CSD6CPDBD2 CUD6D3D1 C1 D2 BC A2C1 D2 BC A2C6B8 CF BN BPBYBTC4CBBXB8 CPD2CS CE BN BPCCCACDBXB5B8 CQDD D6CTCRD3D6CSCXD2CV D8CWCT D6CTD7D9D0D8 D3CU CTDACTD6DD D6CTCRD9D6D7CXDACT D7D9CQB9CRCPD0D0 D8D3 BYB4DCB5CXD2CPCRCWCPD6D8B8 D8CWCTD2 CRD3D2D7D9D0D8CXD2CV D8CWCXD7 CRCWCPD6D8 D3D2 D7D9CQB9 D7CTD5D9CTD2D8 CRCPD0D0D7 D8D3 BYB4DCB5 CUD3D6 D8CWCT D7CPD1CT DC CRD3D2D7D8CXD8D9CTD2D8BA BE CBCXD2CRCT D8CWCT CXD2CSCXCRCTD7 CXD2 CTDACTD6DD D6D9D0CTB3D7 CPD2D8CTCRCTCSCTD2D8 CRD3D2B9 D7D8CXD8D9CTD2D8D7 CP BD BMBMBMCP CZ CTCPCRCW CRD3DACTD6 D7D1CPD0D0CTD6 D7D4CPD2D7 D8CWCPD2 D8CWD3D7CT CXD2 D8CWCT CRD3D2D7CTD5D9CTD2D8 DCB8 D8CWCT CPD0CVD3D6CXD8CWD1 DBCXD0D0 D2D3D8 CTD2D8CTD6 CXD2D8D3 CPD2 CXD2ACD2CXD8CT D6CTCRD9D6D7CXD3D2BN CPD2CS D7CXD2CRCT D8CWCTD6CT CPD6CT D3D2D0DD D2 BE CYC6CY CSCXABCTD6CTD2D8DACPD0D9CTD7 D3CU DCB8 CPD2CS D3D2D0DD BED2 CSCXABCTD6B9 CTD2D8 D6D9D0CTD7 D8CWCPD8 CRD3D9D0CS D4D6D3DACTCPD2DDCRD3D2D7CTD5D9CTD2D8 DC B4D8DBD3D6D9D0CT CUD3D6D1D7 CUD3D6 BP CPD2CS D2B8 CTCPCRCW DBCXD8CW D2 CSCXABCTD6CTD2D8DACPD0D9CTD7 D3CU CZB5B8 D8CWCT CPD0CVD3D6CXD8CWD1 D6D9D2D7 CXD2 D4D3D0DDD2D3D1CXCPD0 D8CXD1CTBM C7B4D2 BF CYC6CYB5BA CCCWCT D6CTD7D9D0D8CXD2CV CRCWCPD6D8 CRCPD2 D8CWCTD2 CQCT CPD2D2D3D8CPD8CTCS DBCXD8CW CQCPCRCZ D4D3CXD2D8CTD6D7 D8D3 D4D6D3CSD9CRCT CP D4D3D0DDD2D3D1CXCPD0B9D7CXDECTCS D7CWCPD6CTCS CUD3D6CTD7D8 BD BYD3D0D0D3DBCXD2CV CBCWCXCTCQCTD6 CTD8 CPD0BA B4BDBLBLBHB5BA BE BYD3D0D0D3DBCXD2CV BZD3D3CSD1CPD2 B4BDBLBLBLB5BA D6CTD4D6CTD7CTD2D8CPD8CXD3D2 D3CU CPD0D0 D4D3D7D7CXCQD0CT CVD6CPD1D1CPD8CXCRCPD0 D8D6CTCTD7 B4BUCXD0B9 D0D3D8 CPD2CS C4CPD2CVB8 BDBLBKBLB5BA CCD6CPCSCXD8CXD3D2CPD0 CRD3D6D4D9D7B9CQCPD7CTCS D4CPD6D7CTD6D7 D7CTD0CTCRD8 D4D6CTCUCTD6D6CTCS D8D6CTCTD7 CUD6D3D1 D7D9CRCW CUD3D6CTD7D8D7 CQDD CRCPD0CRD9D0CPD8CXD2CV CECXD8CTD6CQCX D7CRD3D6CTD7 CUD3D6 CTCPCRCW D4D6D3D4D3D7CTCS CRD3D2D7D8CXD8D9CTD2D8B8 CPCRCRD3D6CSCXD2CV D8D3 D8CWCT D6CTB9 CRD9D6D7CXDACT CUD9D2CRD8CXD3D2BM CB CE B4DCB5BP D1CPDC CP BD BMBMBMCP CZ D7BMD8BM CP BD BMBMBMCP CZ DC AW CZ CH CXBPBD CB CE B4CP CX B5 AX A1C8B4CP BD BMBMBMCP CZ CY DCB5 CCCWCTD7CT D7CRD3D6CTD7 CRCPD2 CQCT CRCPD0CRD9D0CPD8CTCS CXD2 D4D3D0DDD2D3D1CXCPD0 D8CXD1CTB8 D9D7CXD2CV D8CWCT D7CPD1CT CSDDD2CPD1CXCR D4D6D3CVD6CPD1D1CXD2CV CPD0CVD3D6CXD8CWD1 CPD7 D8CWCPD8 CSCTD7CRD6CXCQCTCS CUD3D6 D4CPD6D7CXD2CVBA BT D8D6CTCT CRCPD2 D8CWCTD2 CQCT D7CTB9 D0CTCRD8CTCSB8 CUD6D3D1 D8CWCT D8D3D4 CSD3DBD2B8 CQDD CTDCD4CPD2CSCXD2CV D8CWCT CWCXCVCWCTD7D8B9 D7CRD3D6CXD2CV D6D9D0CT CPD4D4D0CXCRCPD8CXD3D2 CUD3D6 CTCPCRCW CRD3D2D7D8CXD8D9CTD2D8BA CCCWCT CTD2DACXD6D3D2D1CTD2D8B9CQCPD7CTCS D4CPD6D7CTD6 CSCTD7CRD6CXCQCTCS CWCTD6CT D9D7CTD7 CP D7CXD1CXD0CPD6D1CTCRCWCPD2CXD7D1 D8D3 D7CTD0CTCRD8 D4D6CTCUCTD6D6CTCSD8D6CTCTD7B8 CQD9D8 D8CWCT D7CRD3D6CTD7 CPD6CT CQCPD7CTCS D3D2 D8CWCT D4D6CTD7CTD2CRCT D3D6 CPCQD7CTD2CRCT D3CU CTD2D8CXB9 D8CXCTD7 CXD2 D8CWCT CSCTD2D3D8CPD8CXD3D2 B4CXD2D8CTD6D4D6CTD8CPD8CXD3D2B5 D3CU CTCPCRCW D4D6D3B9 D4D3D7CTCS CRD3D2D7D8CXD8D9CTD2D8BM BF CB BW B4DCB5BP D1CPDC CP BD BMBMBMCP CZ D7BMD8BM CP BD BMBMBMCP CZ DC AW CZ CG CXBPBD CB BW B4CP CX B5 AX B7 B4 BD CXCU BWB4DCB5BIBPBN BC D3D8CWCTD6DBCXD7CT DBCWCTD6CT D8CWCT CSCTD2D3D8CPD8CXD3D2 BWB4DCB5 D3CU CP D4D6D3D4D3D7CTCS CRD3D2D7D8CXD8D9CTD2D8 DC CXD7 CRCPD0CRD9D0CPD8CTCS D9D7CXD2CV CPD2D3D8CWCTD6 D6CTCRD9D6D7CXDACT CUD9D2CRD8CXD3D2BM BWB4DCB5BP CJ CP BD BMBMBMCP CZ D7BMD8BM CP BD BMBMBMCP CZ DC AW AP CZ D3D2 CXBPBD BWB4CP CX B5 AX D3D2 B4 CAB4DCB5 CXCU CZ BPBC CUCWCXCV D3D8CWCTD6DBCXD7CT CXD2 DBCWCXCRCW CAB4DCB5 CXD7 CP D0CTDCCXCRCPD0 D6CTD0CPD8CXD3D2 CSCTACD2CTCS CUD3D6 CTCPCRCW CPDCCXD3D1 DC D3CU CRCPD8CTCVD3D6DD AD CTD5D9CPD0 D8D3 D7D3D1CT D7D9CQD7CTD8 D3CU ADB3D7 DBD3D6D7D8B9CRCPD7CT CSCTD2D3D8CPD8CXD3D2 CFB4ADB5B8 CPD7 CSCTACD2CTCS CPCQD3DACTBA BG CCCWCT D3D4CTD6CPD8D3D6 D3D2 CXD7 D2CPD8D9D6CPD0 B4D6CTD0CPD8CXD3D2CPD0B5 CYD3CXD2 D3D2 D8CWCT ACCTD0CSD7 D3CU CXD8D7 D3D4CTD6CPD2CSD7BM BTD3D2BU BP CUCWCT BD BMBMBMCT D1CPDCB4CPBNCQB5 CXCYCWCT BD BMBMBMCT CP CXBEBTBNCWCT BD BMBMBMCT CQ CXBEBUCV DBCWCTD6CT CPBNCQ AL BCBN CPD2CS AP CXD7 CP D4D6D3CYCTCRD8CXD3D2 D8CWCPD8 D6CTD1D3DACTD7 D8CWCT ACD6D7D8 CTD0CTD1CTD2D8 D3CU D8CWCT D6CTD7D9D0D8 B4CRD3D6D6CTD7D4D3D2CSCXD2CV D8CWCT D1D3D7D8 D6CTCRCTD2D8D0DD CSCXD7CRCWCPD6CVCTCS CPD6CVD9D1CTD2D8 D3CU D8CWCT CWCTCPCS D3D6 CUD9D2CRD8D3D6 CRCPD8CTCVD3D6DDB5BM APBT BP CUCWCT BE BMBMBMCT CP CXCYCWCT BD BMBMBMCT CP CXBEBTCV CCCWCXD7 CXD2D8CTD6D0CTCPDACXD2CV D3CU D7CTD1CPD2D8CXCR CTDACPD0D9CPD8CXD3D2 CPD2CS D4CPD6D7B9 CXD2CV CUD3D6 D8CWCT D4D9D6D4D3D7CT D3CU CSCXD7CPD1CQCXCVD9CPD8CXD3D2 CWCPD7 D1D9CRCW CXD2 CRD3D1D1D3D2 DBCXD8CW D8CWCPD8 D3CU BWD3DBCSCXD2CV CTD8 CPD0BA B4BDBLBLBGB5B8 CTDCCRCTD4D8 BF C0CTD6CTB8 D8CWCT D7CRD3D6CT CXD7 D7CXD1D4D0DD CTD5D9CPD0 D8D3 D8CWCT D2D9D1CQCTD6 D3CU D2D3D2B9 CTD1D4D8DD CRD3D2D7D8CXD8D9CTD2D8D7 CXD2 CPD2 CPD2CPD0DDD7CXD7B8 CQD9D8 D3D8CWCTD6 D1CTD8D6CXCRD7 CPD6CT D4D3D7B9 D7CXCQD0CTBA BG CBD3 CP D0CTDCCXCRCPD0 D6CTD0CPD8CXD3D2 CUD3D6 D8CWCT CRD3D2D7D8CXD8D9CTD2D8 COD0CTD1D3D2B3 D3CU CRCPD8CTCVD3D6DD C6C8 DBD3D9D0CS CRD3D2D8CPCXD2 CPD0D0 CPD2CS D3D2D0DD D8CWCT D0CTD1D3D2D7 CXD2 D8CWCT CTD2DACXD6D3D2D1CTD2D8B8 CPD2CS CP D0CTDCCXCRCPD0 D6CTD0CPD8CXD3D2 CUD3D6 D8CWCT CRD3D2B9 D7D8CXD8D9CTD2D8 COCUCPD0D0CXD2CVB3 D3CU CRCPD8CTCVD3D6DD CBD2C6C8 DBD3D9D0CS CRD3D2D8CPCXD2 CP D1CPD4B9 D4CXD2CV CUD6D3D1 CTDACTD6DD CTD2D8CXD8DD CXD2 D8CWCT CTD2DACXD6D3D2D1CTD2D8 D8D3 D7D3D1CT D8D6D9D8CW DACPD0D9CT B4CCCACDBX CXCU D8CWCPD8 CTD2D8CXD8DD CXD7 CUCPD0D0CXD2CVB8 BYBTC4CBBX D3D8CWCTD6DBCXD7CTB5BM CTBACVBA CUCWD0CTD1D3D2 BD BNCCCACDBXCXBNCWD0CTD1D3D2 BE BNBYBTC4CBBXCXBNBMBMBMCVBA C6C8CJD0CTD1D3D2CL CUD0 BD BND0 BE BND0 BF BND0 BG CV C8BMC6C8D2C6C8BBC6C8CJCXD2CL CUCWCQ BD BNCWD0 BD BND0 BD CXCXBNCWD1 BD BNCWD0 BE BND0 BE CXCXCV C6C8CJCQCXD2CL CUCQ BD BNCQ BE CV C8BMC6C8D2C6C8BBC6C8CJCQDDCL CUCWD1 BD BNCWCQ BD BNCQ BD CXCXBNCWD1 BE BNCWCQ BE BNCQ BE CXCXCV C6C8CJD1CPCRCWCXD2CTCL CUD1 BD BND1 BE BND1 BF CV C8C8BMC6C8D2C6C8CJCXD2CL CUCWD0 BD BND0 BD CXCV C8C8BMC6C8D2C6C8CJCQDDCL CUCWCQ BD BNCQ BD CXBNCWCQ BE BNCQ BE CXCV C6C8CJD0CTD1D3D2CL CUD0 BD CV C6C8CJCQCXD2CL CUCQ BD BNCQ BE CV C8C8BMC6C8D2C6C8CJCXD2CL CUCWD0 BD BND0 BD CXCV C6C8CJD0CTD1D3D2CL CUD0 BD CVCJBN BYCXCVD9D6CT BDBM BWCTD2D3D8CPD8CXD3D2B9CPD2D2D3D8CPD8CTCS CUD3D6CTD7D8 CUD3D6 COD0CTD1D3D2 CXD2 CQCXD2 CQDD D1CPCRCWCXD2CTBAB3 D8CWCPD8 CXD2 D8CWCXD7 CRCPD7CTB8 CRD3D2D7D8CXD8D9CTD2D8D7 CPD6CT D2D3D8 D3D2D0DD D7CTD1CPD2B9 D8CXCRCPD0D0DD D8DDD4CTB9CRCWCTCRCZCTCSB8 CQD9D8 CPD6CT CPD0D7D3 CUD9D0D0DD CXD2D8CTD6D4D6CTD8CTCS CTCPCRCW D8CXD1CT D8CWCTDD CPD6CT D4D6D3D4D3D7CTCSBA BYCXCVD9D6CT BD D7CWD3DBD7 CP D7CPD1D4D0CT CSCTD2D3D8CPD8CXD3D2B9CPD2D2D3D8CPD8CTCS CUD3D6CTD7D8 CUD3D6 D8CWCT D4CWD6CPD7CT COD8CWCT D0CTD1D3D2 CXD2 D8CWCT CQCXD2 CQDD D8CWCT D1CPCRCWCXD2CTB3B8 D9D7CXD2CV D8CWCT D0CTDCCXCRCPD0CXDECTCS CVD6CPD1D1CPD6BM D0CTD1D3D2B8 CQCXD2B8 D1CPCRCWCXD2CT BM C6C8 D8CWCTBMC6C8BPC6C8 CXD2B8 CQDDBMC6C8D2C6C8BPC6C8 CXD2 DBCWCXCRCW D8CWCT CSCTD2D3D8CPD8CXD3D2 D3CU CTCPCRCW CRD3D2D7D8CXD8D9CTD2D8 B4D8CWCT D7CTD8 CXD2 CTCPCRCW D6CTCRD8CPD2CVD0CTB5 CXD7 CRCPD0CRD9D0CPD8CTCS D9D7CXD2CV CP CYD3CXD2 D3D2 D8CWCT CSCTD2D3D8CPD8CXD3D2D7D3CU CTCPCRCWD4CPCXD6D3CU CRD3D2D7D8CXD8D9CTD2D8D7D8CWCPD8 CRD3D1CQCXD2CT D8D3 D4D6D3CSD9CRCT CXD8BA C1D2 D8CWCXD7 CTDCCPD1D4D0CTB8 D8CWCT D6CXCVCWD8B9CQD6CPD2CRCWCXD2CV D8D6CTCT DBD3D9D0CS CQCT D4D6CTCUCTD6D6CTCS CQCTCRCPD9D7CT D8CWCT CSCTD2D3D8CPD8CXD3D2 D6CTB9 D7D9D0D8CXD2CV CUD6D3D1 D8CWCT CRD3D1D4D3D7CXD8CXD3D2 CPD8 D8CWCT D6D3D3D8 D3CU D8CWCT D3D8CWCTD6 D8D6CTCT DBD3D9D0CS CQCT CTD1D4D8DDBA CBCXD2CRCT D8CWCXD7 D9D7CT D3CU D8CWCT CYD3CXD2 D3D4CTD6CPD8CXD3D2 CXD7 D0CXD2CTCPD6 D3D2 D8CWCT D7D9D1 D3CU D8CWCT CRCPD6CSCXD2CPD0CXD8CXCTD7 D3CU CXD8D7 D3D4CTD6CPD2CSD7B8 CPD2CS D7CXD2CRCT D8CWCT CSCTD2D3D8CPD8CXD3D2D7 D3CU D8CWCT CRCPD8CTCVD3D6CXCTD7 CXD2 CP CVD6CPD1D1CPD6 BZ CPD6CT CQD3D9D2CSCTCS CXD2 CRCPD6CSCXD2CPD0CXD8DDCQDD C7B4CYBXCY DA B5 DBCWCTD6CT DA CXD7 D8CWCT D1CPDCCXD1D9D1 DACPD0CTD2CRDD D3CU D8CWCT CRCPD8CTCVD3D6CXCTD7 CXD2 BZB8 D8CWCT D8D3D8CPD0 CRD3D1D4D0CTDCCXD8DD D3CU D8CWCT CPCQD3DACT CPD0CVD3D6CXD8CWD1 CRCPD2 CQCT D7CWD3DBD2 D8D3 CQCT C7B4D2 BF CYBXCY DA B5BM D4D3D0DDD2D3D1CXCPD0 D2D3D8 D3D2D0DD D3D2 D8CWCT D0CTD2CVD8CW D3CU D8CWCT CXD2D4D9D8 D2B8 CQD9D8 CPD0D7D3D3D2 D8CWCT D7CXDECT D3CU D8CWCT CTD2DACXD6D3D2D1CTD2D8BX B4CBCRCWD9D0CTD6B8 BEBCBCBDB5BA BF BXDCD8CTD2CSCTCS CPD0CVD3D6CXD8CWD1 CCCWCT CPCQD3DACT CPD0CVD3D6CXD8CWD1 DBD3D6CZD7 DBCTD0D0 CUD3D6 CPD8D8CPCRCWCXD2CV D3D6CSCXB9 D2CPD6DD CRD3D1D4D0CTD1CTD2D8D7 CPD2CS D1D3CSCXACCTD6D7B8 CQD9D8 CPD7 CP D7CTD1CPD2D8CXCR D8CWCTD3D6DD CXD8 CXD7 D2D3D8 D7D9CRCXCTD2D8D0DD CTDCD4D6CTD7D7CXDACTD8D3 D4D6D3CSD9CRCT CRD3D6B9 D6CTCRD8 CSCTD2D3D8CPD8CXD3D2D7CXD2 CPD0D0CRCPD7CTD7BA BYD3D6 CTDCCPD1D4D0CTB8 D8CWCT D0CTDCCXCRCPD0 D6CTD0CPD8CXD3D2D7 CSCTACD2CTCS CPCQD3DACT CPD6CT CXD2D7D9CRCXCTD2D8 D8D3 D6CTD4D6CTD7CTD2D8 D5D9CPD2D8CXACCTD6D7 D0CXCZCT COD2D3B3 B4D9D7CXD2CV CRCPD8CTCVD3D6DD C6C8BPC6C8B5CXD2D8CWCT D4CWD6CPD7CT COD8CWCT CQD3DD DBCXD8CW D2D3 CQCPCRCZD4CPCRCZBAB3 BH BT D7CXD1CXD0CPD6 D4D6D3CQB9 D0CTD1 D3CRCRD9D6D7 DBCXD8CW CRD3D2CYD9D2CRD8CXD3D2D7BN CUD3D6 CTDCCPD1D4D0CTB8 D8CWCT DBD3D6CS COCPD2CSB3 B4D9D7CXD2CV CRCPD8CTCVD3D6DDC6C8D2C6C8BPC6C8B5 CXD2 D8CWCT D4CWD6CPD7CT COD8CWCT CRCWCXD0CS DBCTCPD6CXD2CV CVD0CPD7D7CTD7 CPD2CS CQD0D9CT D4CPD2D8D7B3B8 CPD0D7D3 CRCPD2D2D3D8 CQCT D4D6D3D4CTD6D0DD D6CTD4D6CTD7CTD2D8CTCS CPD7 CP D0CTDCCXCRCPD0 D6CTD0CPD8CXD3D2BA BI CCCWCXD7 D6CPCXD7CTD7 D8CWCT D5D9CTD7D8CXD3D2BM CWD3DB D1D9CRCW CTDCD4D6CTD7D7CXDACXD8DD CRCPD2 CQCT CPD0D0D3DBCTCS CXD2 CP D7CWCPD6CTCS D7CTD1CPD2D8CXCR CXD2D8CTD6D4D6CTD8CPD8CXD3D2 DBCXD8CWD3D9D8 CTDCCRCTCTCSCXD2CV D8CWCT D8D6CPCRD8CPCQD0CT D4CPD6D7CXD2CV CRD3D1D4D0CTDCCXD8DD D2CTCRCTD7B9 D7CPD6DD CUD3D6 D4D6CPCRD8CXCRCPD0 CTD2DACXD6D3D2D1CTD2D8B9CQCPD7CTCS D4CPD6D7CXD2CVBR C1D2 D8D6CPCSCXD8CXD3D2CPD0 CRCPD8CTCVD3D6CXCPD0 D7CTD1CPD2D8CXCRD7 B4C5D3D2D8CPCVD9CTB8 BDBLBJBFBN BUCPD6DBCXD7CT CPD2CS BVD3D3D4CTD6B8 BDBLBKBDBN C3CTCTD2CPD2 CPD2CS CBD8CPDACXB8 BDBLBKBIB5 D5D9CPD2D8CXACCTD6D7 CPD2CS D2D3D9D2 D4CWD6CPD7CT CRD3D2CYD9D2CRD8CXD3D2D7 CSCTB9 D2D3D8CT CWCXCVCWCTD6B9D3D6CSCTD6 D6CTD0CPD8CXD3D2D7BM D8CWCPD8 CXD7B8 D6CTD0CPD8CXD3D2D7 CQCTB9 D8DBCTCTD2 DBCWD3D0CT D7CTD8D7 D3CU CTD2D8CXD8CXCTD7 CXD2D7D8CTCPCS D3CU CYD9D7D8 CQCTB9 D8DBCTCTD2 CXD2CSCXDACXCSD9CPD0D7BA CDD2CSCTD6 D8CWCXD7 CXD2D8CTD6D4D6CTD8CPD8CXD3D2B8 CP D5D9CPD2D8CXACCTD6 D0CXCZCT COD2D3B3 DBD3D9D0CS CSCTD2D3D8CT CP D7CTD8 D3CU D4CPCXD6D7 CUCWBT BD BNBU BD CXBNCWBT BE BNBU BE CXBNBMBMBMCV DBCWCTD6CT CTCPCRCW BT CX CPD2CS BU CX CPD6CT CSCXD7CYD3CXD2D8 D7D9CQD7CTD8D7 D3CU BXB8 CRD3D6D6CTD7D4D3D2CSCXD2CV D8D3 CPD2 CPCRCRCTD4D8B9 CPCQD0CT D4CPCXD6 D3CU D6CTD7D8D6CXCRD8D3D6 CPD2CS CQD3CSDD D7CTD8D7 D7CPD8CXD7CUDDCXD2CV D8CWCT D5D9CPD2D8CXACCTD6 COD2D3B3BA CDD2CUD3D6D8D9D2CPD8CTD0DDB8 D7CXD2CRCT D8CWCT CRCPD6CSCXD2CPD0CXD8CXCTD7 D3CU D8CWCTD7CT CWCXCVCWCTD6B9D3D6CSCTD6 CSCTD2D3D8CPD8CXD3D2D7 CRCPD2 CQCT CTDCD4D3D2CTD2D8CXCPD0 D3D2 D8CWCT D7CXDECT D3CU D8CWCT CTD2DACXD6D3D2D1CTD2D8 BX B4D8CWCTD6CT CPD6CT BE CYBXCY D4D3D7B9 D7CXCQD0CT D7D9CQD7CTD8D7 D3CU BX CPD2CS BE BECYBXCY D4D3D7D7CXCQD0CT CRD3D1CQCXD2CPD8CXD3D2D7 D3CU D8DBD3 D7D9CRCW D7D9CQD7CTD8D7B5B8 D7D9CRCW CPD2 CPD4D4D6D3CPCRCWDBD3D9D0CS CSCTD7D8D6D3DD D8CWCT D4D3D0DDD2D3D1CXCPD0 CRD3D1D4D0CTDCCXD8DD D3CU D8CWCT CTD2DACXD6D3D2D1CTD2D8B9CQCPD7CTCS D4CPD6D7CXD2CV CPD0CVD3D6CXD8CWD1BA BH BTD7D7CXCVD2CXD2CV D8CWCT CXCSCTD2D8CXD8DD D6CTD0CPD8CXD3D2 CUCWCT BD BNCT BD CXBNCWCT BE BNCT BE CXBNBMBMBMCV D8D3 D8CWCT D5D9CPD2D8CXACCTD6 DBD3D9D0CS CXD2CRD3D6D6CTCRD8D0DD DDCXCTD0CS D8CWCT D7CTD8 D3CU CQD3DDD7 DBCXD8CW CP CQCPCRCZD4CPCRCZ CPD7 CP CSCTD2D3D8CPD8CXD3D2 CUD3D6 D8CWCT CUD9D0D0 D2D3D9D2 D4CWD6CPD7CTBN CPD2CS CPD7D7CXCVD2B9 CXD2CV D8CWCT CRD3D2DACTD6D7CT D6CTD0CPD8CXD3D2 B4CUD6D3D1 CTCPCRCWCTD2D8CXD8DD CXD2 D8CWCT CTD2DACXD6D3D2D1CTD2D8 D8D3 CTDACTD6DD D3D8CWCTD6 CTD2D8CXD8DD CUCWCT BD BNCT BE CXBNCWCT BD BNCT BF CXBNBMBMBMCVB5DBD3D9D0CS CXD2CRD3D6D6CTCRD8D0DD DDCXCTD0CS D8CWCT D7CTD8 D3CU CQD3DDD7 DBCXD8CW CPD2DDD8CWCXD2CV D8CWCPD8 CXD7 D2D3D8 CP CQCPCRCZD4CPCRCZBA BI CCCWCT CXCSCTD2D8CXD8DD D6CTD0CPD8CXD3D2 CUCWCT BD BNCT BD BNCT BD CXBNCWCT BE BNCT BE BNCT BE CXBNBMBMBMCVB8 DBCWCXCRCW DDCXCTD0CSD7 CP CRD3D6D6CTCRD8 CXD2D8CTD6D4D6CTD8CPD8CXD3D2 CXD2 DACTD6CQ D4CWD6CPD7CT CRD3D2CYD9D2CRD8CXD3D2B8 DBD3D9D0CS DDCXCTD0CS CPD2 CXD2CRD3D6D6CTCRD8 CSCTD2D3D8CPD8CXD3D2 CUD3D6 D8CWCT D2D3D9D2 D4CWD6CPD7CT COCVD0CPD7D7CTD7 CPD2CS CQD0D9CT D4CPD2D8D7B8B3 CRD3D2D8CPCXD2CXD2CV D3D2D0DD CTD2D8CXD8CXCTD7 DBCWCXCRCW CPD6CT CPD8 D3D2CRCT CQD3D8CW CVD0CPD7D7CTD7 CPD2CS D4CPD2D8D7BA C0D3DBCTDACTD6B8 CXCU D8CWCT D2D9D1CQCTD6 D3CU D4D3D7D7CXCQD0CT CWCXCVCWCTD6B9D3D6CSCTD6 CUD9D2CRD8CXD3D2D7 CXD7 D6CTD7D8D6CXCRD8CTCS D8D3 CP ACD2CXD8CT D7CTD8 B4D7CPDDB8 D8D3 D7D3D1CT D7D9CQD7CTD8 D3CU DBD3D6CSD7 CXD2 CP D0CTDCCXCRD3D2B5B8 CXD8 CQCTCRD3D1CTD7 D8D6CPCRD8CPCQD0CT D8D3 D7D8D3D6CT D8CWCTD1 CQDD D2CPD1CT D6CPD8CWCTD6 D8CWCPD2 CQDD CSCTD2D3D8CPD8CXD3D2 B4CXBACTBA CPD7 D7CTD8D7B5BA CBD9CRCW CUD9D2CRD8CXD3D2 CRCPD2 D8CWCTD2 CSCXD7CRCWCPD6CVCT CPD0D0 D8CWCTCXD6 ACD6D7D8B9D3D6CSCTD6 CPD6CVD9D1CTD2D8D7 CXD2 CP D7CXD2CVD0CT CSCTD6CXDACPD8CXD3D2CPD0 D7D8CTD4 D8D3 D4D6D3CSD9CRCT CP ACD6D7D8B9D3D6CSCTD6 D6CTD7D9D0D8B8 CXD2 D3D6CSCTD6 D8D3 CPDAD3CXCS CVCTD2CTD6CPD8CXD2CV D3D6 CTDACPD0D9CPD8CXD2CV CPD2DD CWCXCVCWCTD6B9D3D6CSCTD6 D4CPD6D8CXCPD0 D6CTB9 D7D9D0D8D7BA CBDDD2D8CPCRD8CXCRCPD0D0DDB8 D8CWCXD7 DBD3D9D0CS CQCT CPD2CPD0D3CVD3D9D7 D8D3 CRD3D1B9 D4D3D7CXD2CV CP D5D9CPD2D8CXACCTD6 DBCXD8CW CQD3D8CW CP D2D3D9D2 D4CWD6CPD7CT D6CTD7D8D6CXCRB9 D8D3D6 CPD2CS CP CQD3CSDD D4D6CTCSCXCRCPD8CT B4CTBACVBA CP DACTD6CQ D3D6 DACTD6CQ D4CWD6CPD7CTB5 CPD8 D8CWCT D7CPD1CT D8CXD1CTB8 D8D3 D4D6D3CSD9CRCT CPD2D3D8CWCTD6 ACD6D7D8B9D3D6CSCTD6 D4D6CTCSCXCRCPD8CT B4CTBACVBA CP DACTD6CQ D4CWD6CPD7CT D3D6 D7CTD2D8CTD2CRCTB5BA CBCXD2CRCT CP CVCTD2CTD6CPD0CXDECTCS D5D9CPD2D8CXACCTD6 CUD9D2CRD8CXD3D2 D1CTD6CTD0DD CRD3D9D2D8D7 CPD2CS CRD3D1D4CPD6CTD7 D8CWCT CRCPD6CSCXD2CPD0CXD8CXCTD7 D3CU CXD8D7 CPD6CVD9D1CTD2D8D7 CXD2 CP D0CXD2B9 CTCPD6 D8CXD1CT D3D4CTD6CPD8CXD3D2B8 D8CWCXD7 CPD2CPD0DDD7CXD7 D4D6D3DACXCSCTD7 CP D8D6CPCRD8CPCQD0CT D7CWD3D6D8CRD9D8 D8D3 D8CWCT CTDCD4D3D2CTD2D8CXCPD0 CRCPD0CRD9D0CPD8CXD3D2D7 D6CTD5D9CXD6CTCS CXD2 D8CWCT CRD3D2DACTD2D8CXD3D2CPD0 CPD2CPD0DDD7CXD7BA C6D3D8CT D8CWCPD8 D8CWCXD7 CPD2CPD0DDD7CXD7 CQDD CXD8D7CTD0CU CSD3CTD7 D2D3D8 CPCSD1CXD8 D4D6D3CSD9CRD8CXDACT D1D3CSCXACCRCPD8CXD3D2 D3CU D5D9CPD2D8CXACCTD6D7 B4CQCTCRCPD9D7CT D8CWCTCXD6 CUD9D2CRD8CXD3D2D7 CPD6CT CSD6CPDBD2 CUD6D3D1 D7D3D1CT ACD2CXD8CT D7CTD8B5 D3D6 D3CU D5D9CPD2B9 D8CXACCTCS D2D3D9D2 D4CWD6CPD7CTD7 B4CQCTCRCPD9D7CT D8CWCTDD CPD6CT D2D3 D0D3D2CVCTD6 CSCTB9 D6CXDACTCS CPD7 CP D4CPD6D8CXCPD0 D6CTD7D9D0D8B5BA CCCWCXD7 CRCPD9D7CTD7 D2D3 CSCXD7D6D9D4D8CXD3D2 D8D3 D8CWCT CPD8D8CPCRCWD1CTD2D8 D3CU D2D3D2B9CRD3D2CYD9D2CRD8CXDACT D1D3CSCXACCTD6D7B8 CQCTB9 CRCPD9D7CT D3D6CSCXD2CPD6DD D7DDD2D8CPCRD8CXCR D1D3CSCXACCTD6D7 D3CU D5D9CPD2D8CXACCTD6 CRD3D2B9 D7D8CXD8D9CTD2D8D7 CPD6CT D7CTD0CSD3D1 D4D6D3CSD9CRD8CXDACT B4CXD2 D8CWCT D7CTD2D7CT D8CWCPD8 D8CWCTCXD6 CRD3D1D4D3D7CXD8CXD3D2 CSD3CTD7 D2D3D8 DDCXCTD0CS CUD9D2CRD8CXD3D2D7 D3D9D8D7CXCSCT D7D3D1CT ACD2CXD8CT D7CTD8B5B8 CPD2CS D7DDD2D8CPCRD8CXCR D1D3CSCXACCTD6D7 D3CU C6C8 CRD3D2B9 D7D8CXD8D9CTD2D8D7 D9D7D9CPD0D0DD D3D2D0DD D1D3CSCXCUDD D8CWCT D6CTD7D8D6CXCRD8D3D6 D7CTD8 D3CU D8CWCT D5D9CPD2D8CXACCTD6 D6CPD8CWCTD6 D8CWCPD2 D8CWCT CTD2D8CXD6CT D5D9CPD2D8CXACCTCS CUD9D2CRD8CXD3D2B8 CPD2CS CRCPD2 D8CWCTD6CTCUD3D6CT D7CPCUCTD0DD CQCT D8CPCZCTD2 D8D3 CPD8D8CPCRCW CQCTD0D3DB D8CWCT D5D9CPD2D8CXACCTD6B8 D8D3 D8CWCT D9D2D5D9CPD2D8CXACCTCS C6C8BA BUD9D8 D8CWCXD7 CXD7 D2D3D8 D8D6D9CT CXD2 CRCPD7CTD7 CXD2DAD3D0DACXD2CV CRD3D2CYD9D2CRB9 D8CXD3D2BA BVD3D2CYD3CXD2CTCS D5D9CPD2D8CXACCTD6D7B8 D0CXCZCT COD7D3D1CT CQD9D8 D2D3D8 CPD0D0B8B3 CRCPD2D2D3D8 CPD0DBCPDDD7CQCT CSCTACD2CTCS D9D7CXD2CV CP D7CXD2CVD0CT D7D8CPD2CSCPD6CS D0CTDCB9 CXCRCPD0 CUD9D2CRD8CXD3D2BN CPD2CS CRD3D2CYD9D2CRD8CXD3D2D7 D3CU D5D9CPD2D8CXACCTCS D2D3D9D2 D4CWD6CPD7CTD7B8 D0CXCZCT COD3D2CT D3D6CPD2CVCT CPD2CS D3D2CT D0CTD1D3D2B3B8 CRCPD2D2D3D8 CQCT CPD4D4D0CXCTCS D8D3 D9D2D5D9CPD2D8CXACCTCS D7D9CQCRD3D2D7D8CXD8D9CTD2D8D7 B4D7DDD2D8CPCRB9 D8CXCRCPD0D0DDB8 CQCTCRCPD9D7CT D8CWCXD7 DBD3D9D0CS CUCPCXD0 D8D3 D7D9CQD7D9D1CT D8CWCT D7CTCRB9 D3D2CS D5D9CPD2D8CXACCTD6B8 CPD2CS D7CTD1CPD2D8CXCRCPD0D0DDB8 CQCTCRCPD9D7CT CXD8 CXD7 D2D3D8 D8CWCT D6CTD7D8D6CXCRD8D3D6 D7CTD8D7 DBCWCXCRCW CPD6CT CRD3D2CYD3CXD2CTCSB5BA C3CTCTD2CPD2 CPD2CS CBD8CPDACX B4BDBLBKBIB5 D1D3CSCTD0 CRD3D2CYD9D2CRD8CXD3D2D7 D3CU D5D9CPD2D8CXACCTD6D7 CPD2CS D5D9CPD2D8CXACCTCS D2D3D9D2 D4CWD6CPD7CTD7 D9D7CXD2CV D0CPD8D8CXCRCT D3D4CTD6CPD8CXD3D2D7 D3D2 CWCXCVCWCTD6B9D3D6CSCTD6 D7CTD8D7B8 CQD9D8 CPD7 D4D6CTDACXD3D9D7D0DD D7D8CPD8CTCSB8 D8CWCTD7CT CWCXCVCWCTD6B9D3D6CSCTD6 D7CTD8D7 D4D6CTCRD0D9CSCT D8D6CPCRD8CPCQD0CT CXD2D8CTD6D0CTCPDACXD2CV D3CU D7CTD1CPD2D8CXCR CXD2D8CTD6D4D6CTD8CPD8CXD3D2 DBCXD8CW D4CPD6D7CXD2CVBA CCCWCT D7D3D0D9D8CXD3D2 D4D6D3D4D3D7CTCS CWCTD6CT CXD7 D8D3 D8D6CTCPD8 CTCPCRCW D5D9CPD2B9 D8CXACCTD6 D3D6 D5D9CPD2D8CXACCTCS D2D3D9D2 D4CWD6CPD7CT CRD3D2CYD9D2CRD8CXD3D2 CPD7 CPD2 CTD0B9 D0CXD4D8CXCRCPD0 CRD3D2CYD9D2CRD8CXD3D2 D3CU D8DBD3 CRD3D1D4D0CTD8CT ACD6D7D8B9D3D6CSCTD6 D4D6CTCSB9 CXCRCPD8CTD7 B4CTBACVBA DACTD6CQ D4CWD6CPD7CTD7 D3D6 D7CTD2D8CTD2CRCTD7B5B8 CTCPCRCW D7D9CQD7D9D1B9 CXD2CV CP CSCXABCTD6CTD2D8 D5D9CPD2D8CXACCTD6 CPD2CS D2D3D9D2 D4CWD6CPD7CT D6CTD7D8D6CXCRD8D3D6 B4CXD2 D8CWCT CRCPD7CT D3CU C6C8 CRD3D2CYD9D2CRD8CXD3D2B5B8 CQD9D8 D7CWCPD6CXD2CV D3D6 CSD9B9 D4D0CXCRCPD8CXD2CV CP CRD3D1D1D3D2 CQD3CSDD D4D6CTCSCXCRCPD8CTBA CCCWCXD7 CPD2CPD0DDD7CXD7 D6CTD5D9CXD6CTD7 D1D9D0D8CXD4D0CT CRD3D1D4D3D2CTD2D8D7 D8D3 CZCTCTD4 D8D6CPCRCZ D3CU D8CWCT CSD9D4D0CXCRCPD8CTCS D1CPD8CTD6CXCPD0 CPCQD3DACT D8CWCT CRD3D2CYD9D2CRD8CXD3D2B8 CQD9D8 CPD7 D0D3D2CV CPD7 D8CWCT D2D9D1CQCTD6 D3CU CRD3D1D4D3D2CTD2D8D7 CXD7 CQD3D9D2CSCTCSB8 D8CWCT D4D3D0DDD2D3D1CXCPD0 CRD3D1D4D0CTDCCXD8DD D3CU D8CWCT D4CPD6D7CXD2CV CPD0CVD3D6CXD8CWD1 CXD7 CRD3D2D8CPCXD2CXD2CV B4CSD9D4D0CXCRCPD8CTCSB5 D3D2CT D3D6CPD2CVCT B4D9D2CSD9D4D0CXCRCPD8CTCSB5 CPD2CS D3D2CT D0CTD1D3D2 B4D9D2CSD9D4D0CXCRCPD8CTCSB5 BYCXCVD9D6CT BEBM BWD9D4D0CXCRCPD8CTCS DACTD6CQ CXD2 C6C8 CRD3D2CYD9D2CRD8CXD3D2BA D6CTD8CPCXD2CTCSBA BJ BYCXCVD9D6CT BE D7CWD3DBD7 CP CSD9D4D0CXCRCPD8CTCS DACTD6CQ D4D6CTCSCXCRCPD8CT CXD2 D8CWCT CSCTD6CXDACPD8CXD3D2 D3CU CPD2 C6C8 CRD3D2CYD9D2CRD8CXD3D2BA CCCWCT CRD3D2CYD3CXD2CTCS CRD3D2D7D8CXD8D9CTD2D8D7 B4D8CWCT D7CWCPCSCTCS D6CTCVCXD3D2D7 CXD2 D8CWCT ACCVD9D6CTB5 CPD6CT CTCPCRCW CRD3D1D4D3D7CTCS D3CU D8DBD3 CRD3D1D4D3D2CTD2D8D7BM D3D2CT CUD3D6 D8CWCT C6C8 CXD8D7CTD0CUB8 CRD3D2D8CPCXD2CXD2CV D8CWCT D5D9CPD2D8CXACCTD6 CPD2CS D8CWCT D6CTD7D8D6CXCRD8D3D6 D4D6CTCSCXCRCPD8CTB8 CPD2CS D3D2CT CUD3D6 D8CWCT DACTD6CQ DBCWCXCRCW D7D9D4D4D0CXCTD7 D8CWCT CQD3CSDD D4D6CTCSCXCRCPD8CT D3CU D8CWCT D5D9CPD2D8CXACCTD6BA CBCXD2CRCT D8CWCT CRD3D2CYD3CXD2CTCS CRD3D2D7D8CXD8D9CTD2D8D7 CQD3D8CW CRD3D6D6CTD7D4D3D2CS D8D3 CRD3D1D4D0CTD8CT D5D9CPD2D8CXB9 ACCTD6 CTDCD4D6CTD7D7CXD3D2D7 DBCXD8CW D2D3 D9D2D7CPD8CXD7ACCTCS ACD6D7D8B9D3D6CSCTD6 CPD6CVD9B9 D1CTD2D8D7B8 D8CWCTCXD6 CRCPD8CTCVD3D6CXCTD7 CPD6CT D8CWCPD8 D3CU D7CXD1D4D0CT ACD6D7D8B9D3D6CSCTD6 D4D6CTCSCXCRCPD8CTD7 B4D8CWCTDD CPD6CT CTCPCRCW CRD3D1D4D0CTD8CT DACTD6CQ D4CWD6CPD7CTD7 CXD2 CTD7D7CTD2CRCTBM COCRD3D2D8CPCXD2CXD2CV D3D2CT D3D6CPD2CVCTB3 CPD2CS COCRD3D2D8CPCXD2CXD2CV D3D2CT D0CTD1D3D2B3B5BA CCCWCT CRD3D2CYD9D2CRD8CXD3D2 D8CWCTD2 CUD3D6D1D7 CP D0CPD6CVCTD6 CRD3D2B9 D7D8CXD8D9CTD2D8 D3CU D8CWCT D7CPD1CT CUD3D6D1 B4D8CWCT D9D2D7CWCPCSCTCS D3D9D8D0CXD2CT CXD2 D8CWCT ACCVD9D6CTB5B8 DBCXD8CW CP D0D3DBCTD6 CRD3D1D4D3D2CTD2D8 CRD3D2D8CPCXD2CXD2CV D8CWCT CRD3D2CYD3CXD2CTCS CRD3D2D7D8CXD8D9CTD2D8D7B3 C6C8 CRD3D1D4D3D2CTD2D8D7 CRD3D2CRCPD8CTB9 D2CPD8CTCS CXD2 D8CWCT D9D7D9CPD0 DBCPDDB8 CPD2CS CPD2 D9D4D4CTD6 CRD3D1D4D3D2CTD2D8CXD2 DBCWCXCRCW D8CWCT CRD3D2CYD3CXD2CTCS CRD3D2D7D8CXD8D9CTD2D8D7B3 D2D3D2B9C6C8 CRD3D1D4D3B9 D2CTD2D8D7 CPD6CT CXCSCTD2D8CXACCTCS D3D6 D3DACTD6D0CPD4D4CTCSBA C1CU D8CWCT CSD9D4D0CXCRCPD8CTCS CRD3D1D4D3D2CTD2D8D7 CSD3 D2D3D8 CRD3DACTD6 D8CWCT D7CPD1CT D7D8D6CXD2CV DDCXCTD0CSB8 D8CWCT CRD3D2CYD9D2CRD8CXD3D2 CSD3CTD7 D2D3D8 CPD4D4D0DDBA C6D3D8CT D8CWCPD8B8 D7CXD2CRCT D8CWCTDD CPD6CT D3D2D0DD CPD4D4D0CXCTCS D8D3 D3D6CSCXD2CPD6DD ACD6D7D8B9D3D6CSCTD6 D4D6CTCSCXCRCPD8CTD7 B4CTBACVBA D7CTD2D8CTD2CRCTD7 D3D6 DACTD6CQ D4CWD6CPD7CTD7B5 CXD2 D8CWCXD7 CPD2CPD0DDD7CXD7B8 CRD3D2CYD9D2CRD8CXD3D2D7 CRCPD2 D2D3DB D7CPCUCTD0DD CQCT CPD7B9 D7CXCVD2CTCS D8CWCT CUCPD1CXD0CXCPD6 D8D6D9D8CWB9CUD9D2CRD8CXD3D2CPD0 CSCTD2D3D8CPD8CXD3D2D7 CXD2 CTDACTD6DD CRCPD7CTBA BK BTD0D7D3B8 D7CXD2CRCT D8CWCT D6CTD7D9D0D8CXD2CV CRD3D2D7D8CXD8D9CTD2D8 CWCPD7 D8CWCT D7CPD1CT D2D9D1CQCTD6 D3CU CRD3D1D4D3D2CTD2D8D7 CPD7 D8CWCT CRD3D2CYD3CXD2CTCS CRD3D2D7D8CXD8D9CTD2D8D7B8 D8CWCTD6CT CXD7 D2D3D8CWCXD2CV D8D3 D4D6CTDACTD2D8 CXD8D7 D9D7CT CPD7 CPD2 CPD6CVD9D1CTD2D8 CXD2 D7D9CQD7CTD5D9CTD2D8 CRD3D2CYD9D2CRD8CXD3D2 D3D4CTD6CPD8CXD3D2D7BA BT D7CPD1D4D0CT D1D9D0D8CXB9CRD3D1D4D3D2CTD2D8 CPD2CPD0DDD7CXD7 CUD3D6 D5D9CPD2D8CXACCTD6D7 CXD7 D7CWD3DBD2 CQCTD0D3DBB8 CPD0D0D3DBCXD2CV D1CPD8CTD6CXCPD0 D8D3 CQCT CSD9D4D0CXCRCPD8CTCS CQD3D8CW D8D3 D8CWCT D0CTCUD8 CPD2CS D8D3 D8CWCT D6CXCVCWD8 D3CU CP CRD3D2CYD3CXD2CTCS C6C8BM D7D3D1CTB8CPD0D0B8D2D3B8CTD8CRBA BM CGD2C6C8 D5 A1 C6C8 D5 D2C6C8 D5 A1C6C8 D5 BPC6C8 AF CGBPC6C8 D5 A1 C6C8 D5 D2C6C8 D5 A1C6C8 D5 BPC6C8 AF CCCWCT D0CTDCCXCRCPD0 CTD2D8D6DD CUD3D6 CP D5D9CPD2D8CXACCTD6 CRCPD2 CQCT D7D4D0CXD8 CXD2 D8CWCXD7 BJ BWCPCWD0 CPD2CS C5CRBVD3D6CS B4BDBLBKBFB5 D4D6D3D4D3D7CT CP D7CXD1CXD0CPD6 CSD9D4D0CXCRCPD8CXD3D2 D1CTCRCWCPD2CXD7D1 D8D3 D4D6D3CSD9CRCT CPD4D4D6D3D4D6CXCPD8CT D7CTD1CPD2D8CXCR D6CTD4D6CTD7CTD2D8CPD8CXD3D2D7 CUD3D6 C6C8 CPD2CS D3D8CWCTD6 CRD3D2CYD9D2CRD8CXD3D2D7B8 CQD9D8 CUD3D6 CSCXABCTD6CTD2D8 D6CTCPD7D3D2D7BA BK CTBACVBA CUD3D6 D8CWCT DBD3D6CS COCPD2CSB3BM CUCWBMBMBMCCCACDBXBNBMBMBMCCCACDBXBNBMBMBMCCCACDBXCXBN CWBMBMCCCACDBXBNBMBMBYBTC4CBBXBNBMBMBYBTC4CBBXCXBN CWBMBMBYBTC4CBBXBNBMBMCCCACDBXBNBMBMBYBTC4CBBXCXBN CWBMBMBYBTC4CBBXBNBMBMBYBTC4CBBXBNBMBMBYBTC4CBBXCXCV DBCPDDCXD2D8D3CPD2D9D1CQCTD6 D3CU CRD3D1D4D3D2CTD2D8D7B8 D8CWCT D0CPD7D8 B4D3D6 D0D3DBB9 CTD7D8B5 D3CU DBCWCXCRCW CXD7 D2D3D8 CSD9D4D0CXCRCPD8CTCS CXD2 CRD3D2CYD9D2CRD8CXD3D2 DBCWCXD0CT D3D8CWCTD6D7 D1CPDD D3D6 D1CPDD D2D3D8 CQCTBA CCCWCTD7CT CXD2CRD0D9CSCT CP CRD3D1B9 D4D3D2CTD2D8 CUD3D6 D8CWCT D5D9CPD2D8CXACCTD6 C6C8 D5 BPC6C8 AF B4DBCWCXCRCW DBCXD0D0 D9D0D8CXB9 D1CPD8CTD0DD CPD0D7D3 CRD3D2D8CPCXD2 CP D2D3D9D2 D4CWD6CPD7CT D6CTD7D8D6CXCRD8D3D6 D3CU CRCPD8CTB9 CVD3D6DD C6C8 AF B5B8 CP CRD3D1D4D3D2CTD2D8 CUD3D6 D6CTD7D8D6CXCRD8D3D6 C8C8D7 CPD2CS D6CTD0CPB9 D8CXDACT CRD0CPD9D7CTD7 D3CU CRCPD8CTCVD3D6DD C6C8 D5 D2C6C8 D5 D8CWCPD8 CPD6CT CPD8D8CPCRCWCTCS CPCQD3DACT D8CWCT D5D9CPD2D8CXACCTD6 CPD2CS CSD9D4D0CXCRCPD8CTCS CXD2 D8CWCT CRD3D2CYD9D2CRB9 D8CXD3D2B8 CPD2CS CP CRD3D1D4D3D2CTD2D8 CUD3D6 D8CWCT CQD3CSDD B4CP DACTD6CQ D3D6 DACTD6CQ D4CWD6CPD7CT D3D6 D3D8CWCTD6 D4D6CTCSCXCRCPD8CTB5 D3CU CRCPD8CTCVD3D6DD CGD2C6C8 D5 D3D6 CGBPC6C8 D5 BA CCCWCT D7D9CQD7CRD6CXD4D8 D5 D7D4CTCRCXACCTD7 D3D2CT D3CU CP ACD2CXD8CT D7CTD8 D3CU D5D9CPD2D8CXACCTD6D7B8 CPD2CS D8CWCT D7D9CQD7CRD6CXD4D8 AF CXD2CSCXCRCPD8CTD7 CPD2 D9D2D5D9CPD2D8CXACCTCS C6C8BA CCCWCT CSCTCSD9CRD8CXDACT D4CPD6D7CTD6 D4D6CTD7CTD2D8CTCS CXD2 CBCTCRD8CXD3D2 BE CRCPD2 D2D3DB CQCT CTDCD8CTD2CSCTCS CQDD CXD2CRD3D6D4D3D6CPD8CXD2CV D7CTD5D9CTD2CRCTD7 D3CU D6CTCRB9 D3CVD2CXDECTCS CPD2CS D9D2D6CTCRD3CVD2CXDECTCS CRD3D1D4D3D2CTD2D8D7 CXD2D8D3 D8CWCT CRD3D2B9 D7D8CXD8D9CTD2D8 CRCWCPD6D8 CXD8CTD1D7BA BTD7 CRD3D2D7D8CXD8D9CTD2D8D7 CPD6CT CRD3D1B9 D4D3D7CTCSB8 CRD3D1D4D3D2CTD2D8D7 CPD6CT D7CWCXCUD8CTCS CUD6D3D1 D8CWCT D9D2D6CTCRD3CVB9 D2CXDECTCS D7CTD5D9CTD2CRCT AD BD A1A1A1AD CR D8D3 D8CWCT D6CTCRD3CVD2CXDECTCS D7CTD5D9CTD2CRCT CWCX BD BNCY BD BNAD BD CXA1A1A1CWCX CR BNCY CR BNAD CR CXB8 D9D2D8CXD0 D8CWCT D9D2D6CTCRD3CVD2CXDECTCS D7CTB9 D5D9CTD2CRCT CXD7 CTD1D4D8DDBA CCCWCT CTDCD8CTD2CSCTCS D4CPD6D7CTD6 CXD7 CSCTACD2CTCS DBCXD8CWBM AF CRCWCPD6D8 CXD8CTD1D7 D3CU D8CWCT CUD3D6D1 CJCXBNCYBNA1BNA6CLB8 DBCWCTD6CT A1 CXD7 CP D7CTD5D9CTD2CRCT D3CU D9D2D6CTCRD3CVD2CXDECTCS CRD3D1D4D3D2CTD2D8D7 ADB8A6CXD7 CP D7CTD5D9CTD2CRCT D3CU D6CTCRD3CVD2CXDECTCS CRD3D1D4D3D2CTD2D8D7 CWCPBNCQBNADCXB8 CPD2CS CXBNCYBNCZBNCPBNCQBNCR CPD6CT CXD2CSCXCRCTD7 CXD2 D8CWCT CXD2D4D9D8BA BXCPCRCW CXD8CTD1 CJCXBNCYBNA1A1ADBNCWCX BD BNCY BD BNAD BD CXA1A1A1CWCX CR BNCY CR BNAD CR CXCL CXD2CSCXCRCPD8CTD7 D8CWCPD8 D8CWCT D7D4CPD2 CUD6D3D1 CX D8D3 CY CXD2 D8CWCT CXD2D4D9D8 CRCPD2 CQCT CRCWCPD6CPCRD8CTD6CXDECTCS CQDD D8CWCT CRCPD8CTCVD3D6CXCTD7 AD BD D8CWD6D3D9CVCW AD CR CPD8 D4D3D7CXD8CXD3D2D7CX BD D8D3CY BD D8CWD6D3D9CVCWCX CR D8D3CY CR D6CTD7D4CTCRD8CXDACTD0DDB8D7D3 D8CWCPD8 CXCU D8CWCTD7CT D7D4CPD2D7 CPD6CT CRD3D2CRCPD8CTD2CPD8CTCS CXD2 DBCWCPD8CTDACTD6 D3D6CSCTD6 D8CWCTDD D3CRCRD9D6 CXD2 D8CWCT CXD2D4D9D8 D7D8D6CXD2CVB8 D8CWCTDD CUD3D6D1 CP CVD6CPD1D1CPD8CXCRCPD0 CRD3D2D7D8CXD8D9CTD2D8 D3CU CRCPD8CTCVD3D6DD AD DBCXD8CW D9D2D6CTCRD3CVD2CXDECTCS CRD3D1D4D3D2CTD2D8D7 A1BA AF CP D0CTDCCXCRCPD0 CXD8CTD1 CJCXBNCYBNADBNCWCXBNCYBNADCXCL CUD3D6 CTDACTD6DD D6D9D0CT AD AX DB BE C8 CXCU DB D3CRCRD9D6D7 CQCTD8DBCTCTD2 D4D3D7CXD8CXD3D2D7 CX CPD2CS CY CXD2 D8CWCT CXD2D4D9D8BN AF CP D7CTD8 D3CU D6D9D0CTD7 CUD3D6 CPD0D0 CXBNCYBNCZBNCPBNCQBNCR BE C1 D2 BC CPD7 CQCTD0D3DBBA CCDBD3 D6D9D0CTD7 D8D3 CXD2DAD3CZCT D0CTCUD8 CPD2CS D6CXCVCWD8 CUD9D2CRD8CXD3D2 CPD4B9 D4D0CXCRCPD8CXD3D2 D8D3 CPD2 CTDCCXD7D8CXD2CV CRD3D1D4D3D2CTD2D8BM CJCXBNCZBNADBPBNCWCXBNCZBNADBPCXCLCJCZBNCYBNA1A1BNCWCZBNCQBNBPAYCXA1A6CL CJCXBNCYBNA1A1ADBNCWCXBNCQBNADBPAYCXA1A6CL ADAXADBP BEC8B8 CJCZBNCYBNADD2BNCWCZBNCYBNADD2CXCLCJCXBNCZBNA1A1BNCWCPBNCZBND2AYCXA1A6CL CJCXBNCYBNA1A1ADBNCWCPBNCYBNADD2AYCXA1A6CL ADAXADD2BEC8B8 CCDBD3 D6D9D0CTD7 D8D3 CXD2DAD3CZCT D0CTCUD8 CPD2CS D6CXCVCWD8 CUD9D2CRD8CXD3D2 CPD4B9 D4D0CXCRCPD8CXD3D2 D8D3 CP CUD6CTD7CW CRD3D1D4D3D2CTD2D8BM CJCXBNCZBNADBPBNCWCXBNCZBNADBPCXCLCJCZBNCYBNA1A1ADBPA1BNA6CL CJCXBNCYBNA1A1ADBNCWCXBNCZBNADBPCXA1A6CL ADAXADBP BEC8B8 CJCZBNCYBNADD2BNCWCZBNCYBNADD2CXCLCJCXBNCZBNA1A1ADD2A1BNA6CL CJCXBNCYBNA1A1ADBNCWCZBNCYBNADD2CXA1A6CL ADAXADD2BEC8B8 CCDBD3 D6D9D0CTD7 D8D3 CSCXD7CRCWCPD6CVCT CTD1D4D8DD CRD3D1D4D3D2CTD2D8D7BM CJCXBNCYBNA1A1ADBPA1BNA6CL CJCXBNCYBNA1A1ADBNA6CL CJCXBNCYBNA1A1ADD2A1BNA6CL CJCXBNCYBNA1A1ADBNA6CL CCCWD6CTCT D6D9D0CTD7 D8D3 D7CZCXD4 CRD3D2CYD9D2CRD8CXD3D2D7B8 CQDD CPCSCSCXD2CV CP CVCPD4 CQCTD8DBCTCTD2 D8CWCT CRD3D1D4D3D2CTD2D8D7 CXD2 CP CRD3D2D7D8CXD8D9CTD2D8 B4D8CWCT ACD6D7D8 D6D9D0CT CRD3D2D7D9D1CTD7 D8CWCT CRD3D2CYD9D2CRD8CXD3D2 D8D3 CRD6CTB9 CPD8CT CP D4CPD6D8CXCPD0 D6CTD7D9D0D8 D3CU CRCPD8CTCVD3D6DD BVD3D2CY BC  B8 CPD2CS D8CWCT D0CPD8D8CTD6 D8DBD3 D9D7CT D8CWCXD7 D8D3 D7CZCXD4 D8CWCT D3D4D4D3D7CXD2CV C6C8B5BM CJCZBNCYBNA1A1BNA6CL CJCXBNCYBNA1A1BVD3D2CY BC  BNA6CL CJCXBNCZBNBVD3D2CYBNCWCXBNCZBNBVD3D2CYCXCL CJCZBNCYBNA1A1BVD3D2CY BC  BNA6CL CJCXBNCYBNA1A1BNA6CL CJCXBNCZBNA1A1BN CL CJCXBNCZBNA1A1BNA6CL CJCXBNCYBNA1A1BNA6CL CJCZBNCYBNA1A1BVD3D2CY BC  BN CL CCDBD3 D6D9D0CTD7 D8D3 D6CTCPD7D7CTD1CQD0CT CSCXD7CRD3D2D8CXD2D9D3D9D7 CRD3D2B9 D7D8CXD8D9CTD2D8D7 B4CPCVCPCXD2B8 D9D7CXD2CV CP D4CPD6D8CXCPD0 D6CTD7D9D0D8 BVD3D2CY BC  D8D3 D6CTCSD9CRCT D8CWCT D2D9D1CQCTD6 D3CU D6CPD2CVCXD2CV DACPD6CXCPCQD0CTD7B5BM CJCPBNCRBNBVD3D2CYBNCWCPBNCRBNBVD3D2CYCXCLCJCXBNCYBNADBNA6A1CWCRBNCQBNCXCL CJCXBNCYBNADBNA6A1CWCPBNCQBNBVD3D2CY BC  CXCL CJCXBNCYBNADBNA6A1CWCRBNCQBNBVD3D2CY BC  CXCLCJCXBNCYBNADBNA6A1CWCPBNCRBNCXCL CJCXBNCYBNADBNA6A1CWCPBNCQBNCXCL CCDBD3 D6D9D0CTD7 D8D3 CRD3D1CQCXD2CT CPCSCYCPCRCTD2D8 CRD3D1D4D3D2CTD2D8D7BM CJCXBNCYBNADBNA6A1CWCPBNCRBNBPAYCXA1CWCRBNCQBNAYCXCL CJCXBNCYBNADBNA6A1CWCPBNCQBNCXCL CJCXBNCYBNADBNA6A1CWCRBNCQBND2AYCXA1CWCPBNCRBNAYCXCL CJCXBNCYBNADBNA6A1CWCPBNCQBNCXCL BTD2CS D3D2CT D6D9D0CT D8D3 CPD4D4D0DD D5D9CPD2D8CXACCTD6 CUD9D2CRD8CXD3D2D7BM CJCXBNCYBNADBNA6A1CWCPBNCQBN D5 CXCL CJCXBNCYBNADBNA6A1CWCPBNCQBN AF CXCL CCCWCT D4CPD6D7CXD2CV CPD2CS D7CRD3D6CXD2CV CUD9D2CRD8CXD3D2D7 D6CTD1CPCXD2 CXCSCTD2D8CXB9 CRCPD0 D8D3 D8CWD3D7CT CXD2 CBCTCRD8CXD3D2 BEB8 CQD9D8 CPD2 CPCSCSCXD8CXD3D2CPD0 CZ BP BD CRCPD7CT CRD3D2D8CPCXD2CXD2CV CP D1D3CSCXACCTCS D4D6D3CYCTCRD8CXD3D2 CUD9D2CRD8CXD3D2 AP CXD7 D2D3DB CPCSCSCTCS D8D3 D8CWCT CXD2D8CTD6D4D6CTD8CPD8CXD3D2 CUD9D2CRD8CXD3D2B8 CXD2 D3D6CSCTD6 D8D3 D1CPCZCT D8CWCT CSCTD2D3D8CPD8CXD3D2D7 D3CU D5D9CPD2D8CXACCTCS CRD3D2D7D8CXD8D9CTD2D8D7 CSCTD4CTD2CS D3D2 D8CWCTCXD6 CPD7D7D3CRCXCPD8CTCS D5D9CPD2D8CXACCTD6D7BM BWB4DCB5BP CJ CP BD BMBMBMCP CZ D7BMD8BM CP BD BMBMBMCP CZ DC BK BQ BQ BQ BQ BQ BQ BQ BO BQ BQ BQ BQ BQ BQ BQ BM CAB4DCB5 CXCU CZ BPBC AP D5 BWB4CP BD B5 CXCU CZ BP BD CPD2CS CP BD DC BP CJBMBMBMCWBMBMBM D5 CXCL CJBMBMBMCWBMBMBM AF CXCL CZ D3D2 CXBPBD BWB4CP CX B5 D3D8CWCTD6DBCXD7CT CCCWCT D1D3CSCXACCTCS D4D6D3CYCTCRD8CXD3D2 CUD9D2CRD8CXD3D2 CTDACPD0D9CPD8CTD7 CP D5D9CPD2B9 D8CXACCTD6 CUD9D2CRD8CXD3D2 D5 D3D2 D7D3D1CT CPD6CVD9D1CTD2D8 CSCTD2D3D8CPD8CXD3D2 BTB8 CRD3D1D4CPD6CXD2CV D8CWCT CRCPD6CSCXD2CPD0CXD8DD D3CU D8CWCT CXD1CPCVCT D3CU D8CWCT D6CTB9 D7D8D6CXCRD8D3D6 D7CTD8 CXD2 BT DBCXD8CW D8CWCT D8CWCT CRCPD6CSCXD2CPD0CXD8DD D3CU CXD1CPCVCT D3CU D8CWCT CXD2D8CTD6D7CTCRD8CTCS D6CTD7D8D6CXCRD8D3D6 CPD2CS CQD3CSDD D7CTD8D7 CXD2 BTBM BL AP D5 BT BP CUCWCT BE BMBMBMCT CP BND8CXCYCW BNCT BE BMBMBMCT CP BN CXBEBTBN D8 BP D5B4CYCACYBNCYCBCYB5 CA BP BTD3D2CUCW BNCT BE BMBMBMCT CP BN CXCVBN CB BP BTD3D2CUCW BNCT BE BMBMBMCT CP BNCCCACDBXCXCVCV CCCWCXD7 CPD0CVD3D6CXD8CWD1 D4CPD6D7CTD7 CP CRCPD8CTCVD3D6CXCPD0 CVD6CPD1D1CPD6 CXD2 D8CWCT D9D7D9CPD0 DBCPDD DF CRD3D2D7D8CXD8D9CTD2D8D7 CPD6CT CXD2CXD8CXCPD0D0DD CPCSCSCTCS D8D3 D8CWCT CRCWCPD6D8 CPD7 D7CXD2CVD0CT CRD3D1D4D3D2CTD2D8D7 CRD3DACTD6CXD2CV CP CRCTD6D8CPCXD2 DDCXCTD0CS CXD2 D8CWCT CXD2D4D9D8 D7D8D6CXD2CV B4D8CWCT CXD2CSCXCRCTD7 D3CU D8CWCT CRD3D1D4D3D2CTD2D8 CPD6CT D8CWCT D7CPD1CT CPD7 D8CWCT CXD2CSCXCRCTD7 D3CU D8CWCT CRD3D2D7D8CXD8D9CTD2D8 CXD8D7CTD0CUB5B8 CPD2CS D8CWCTDD CPD6CT CRD3D1CQCXD2CTCS CQDD CRD3D2CRCPD8CTD2CPD8CXD2CV D8CWCT DDCXCTD0CSD7 D3CU D7D1CPD0D0CTD6 CRD3D2D7D8CXD8D9CTD2D8D7 D8D3 D1CPCZCT D0CPD6CVCTD6 D3D2CTD7 DF D9D2D8CXD0 CP CRD3D2CYD9D2CRD8CXD3D2 CXD7 CTD2CRD3D9D2D8CTD6CTCSBA CFCWCTD2 CP CRD3D2CYD9D2CRD8CXD3D2 CXD7 BL BYD3D0D0D3DBCXD2CV C3CTCTD2CPD2 CPD2CS CBD8CPDACX B4BDBLBKBIB5BA BC BD BE BF BG CRD3D2D8CPCXD2CXD2CV D3D2CT D3D6CPD2CVCT CPD2CS D3D2CT D0CTD1D3D2 CJBCBNBDBNCBD2C6C8 D5 BPC6C8 D5 BCBN CJBDBNBEBNCGD2C6C8 BL A1 C6C8 BL D2C6C8 BL A1 C6C8 BL BN CJBEBNBFBNBVD3D2CYBN CJBFBNBGBNCGD2C6C8 BL A1 C6C8 BL D2C6C8 BL A1 C6C8 BL BN CWBCBNBDBNCBD2C6C8 D5 BPC6C8 D5 BCCXCL CWBDBNBEBNC6C8 BL CXCL CUD3 BD BND3 BE BND3 BF BND3 BG CV CWBEBNBFBNBVD3D2CYCXCL CWBFBNBGBNC6C8 BL CXCL CUD0 BD BND0 BE BND0 BF CV CUCWD3 BD BNDC BD CXBNCWD0 BE BNDC BD CXBNCWD0 BF BNDC BF CXCV BABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABA B4BDB5 CJBDBNBGBNCGD2C6C8 BL A1 C6C8 BL D2C6C8 BL A1 C6C8 BL BNCWBDBNBEBNC6C8 BL CXCL CUD3 BD BND3 BE BND3 BF BND3 BG CV BABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABA B4BEB5 CJBDBNBGBNCGD2C6C8 BL A1 C6C8 BL D2C6C8 BL A1 C6C8 BL BNCWBFBNBGBNC6C8 BL CXCL CUD0 BD BND0 BE BND0 BF CV BABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABA B4BFB5 CJBDBNBGBNCGD2C6C8 BL A1 C6C8 BL BNCWBDBNBEBNC6C8 BL CXCL CUD3 BD BND3 BE BND3 BF BND3 BG CV BABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABA B4BGB5 CJBDBNBGBNCGD2C6C8 BL A1 C6C8 BL BNCWBFBNBGBNC6C8 BL CXCL CUD0 BD BND0 BE BND0 BF CV BABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABA B4BHB5 CJBCBNBGBNCBD2C6C8 D5 BNCWBCBNBDBNCBD2C6C8 D5 BPC6C8 BL CXA1CWBDBNBEBNC6C8 BL CXCL CUCWD3 BD BNDC BD CXCV BABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABA B4BIB5 CJBCBNBGBNCBD2C6C8 D5 BNCWBCBNBDBNCBD2C6C8 D5 BPC6C8 BL CXA1CWBFBNBGBNC6C8 BL CXCL CUCWD0 BE BNDC BD CXBNCWD0 BF BNDC BF CXCV BABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABA B4BJB5 CJBCBNBGBNCBD2C6C8 D5 BNCWBCBNBDBNCBD2C6C8 D5 BPC6C8 AF CXA1CWBDBNBEBNC6C8 AF CXCL CUDC BD CV BABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABABA B4BKB5 CJBCBNBGBNCBD2C6C8 D5 BNCWBCBNBDBNCBD2C6C8 D5 BPC6C8 AF CXA1CWBFBNBGBNC6C8 AF CXCL CUDC BD BNDC BF CV B4BLB5 CJBCBNBGBNCBD2C6C8 D5 BNCWBCBNBDBNCBD2C6C8 D5 BPC6C8 AF CXA1CWBDBNBGBNC6C8 AF CXCL CUDC BD CV B4BDBCB5 CJBCBNBGBNCBD2C6C8 D5 BNCWBCBNBGBNCBD2C6C8 D5 CXCL CUDC BD CV BYCXCVD9D6CT BFBM CBCPD1D4D0CT CSCTD6CXDACPD8CXD3D2 D3CU CRD3D2CYD3CXD2CTCS C6C8BA CTD2CRD3D9D2D8CTD6CTCS CXD1D1CTCSCXCPD8CTD0DD D8D3 D8CWCT D0CTCUD8 D3D6 D6CXCVCWD8 D3CU CP D6CTCRB9 D3CVD2CXDECTCS CRD3D2D7D8CXD8D9CTD2D8 CRD3D2D7D8CXD8D9CTD2D8 DCB8 CPD2CS CPD2D3D8CWCTD6 CRD3D2B9 D7D8CXD8D9CTD2D8 D3CU D8CWCT D7CPD1CT CRCPD8CTCVD3D6DD CXD7 CUD3D9D2CS CXD1D1CTCSCXCPD8CTD0DD CQCTDDD3D2CS D8CWCPD8 CRD3D2CYD9D2CRD8CXD3D2B8 D8CWCT D4CPD6D7CTD6 CRD6CTCPD8CTD7 CP D2CTDB CRD3D2D7D8CXD8D9CTD2D8 D8CWCPD8 CWCPD7 D8CWCT CRD3D1CQCXD2CTCS DDCXCTD0CS D3CU CQD3D8CW CRD3D2B9 D7D8CXD8D9CTD2D8D7B8 CQD9D8 CRD3D4CXCTD7 DCB3D7 CRD3D1D4D3D2CTD2D8 DDCXCTD0CS B4D8CWCT D7D8D6CXD2CV CXD2CSCXCRCTD7 D3CU DCB3D7 D3D6CXCVCXD2CPD0 CRD3D1D4D3D2CTD2D8D7B5 DBCXD8CW D2D3 CRCWCPD2CVCTBA CCCWCXD7 CWCPD7 D8CWCT CTABCTCRD8 D3CU CRD6CTCPD8CXD2CV D8DBD3 D2CTDB CRD3D2D7D8CXD8D9CTD2D8D7 CTDACTD6DD D8CXD1CT D8DBD3 CTDCCXD7D8CXD2CV CRD3D2D7D8CXD8D9CTD2D8D7 CPD6CT CRD3D2CYD3CXD2CTCSBM CTCPCRCW DBCXD8CW CP CSCXABCTD6CTD2D8 CRD3D1D4D3D2CTD2D8 DDCXCTD0CSB8 CQD9D8 CQD3D8CW DBCXD8CW D8CWCT D7CPD1CT B4CRD3D1CQCXD2CTCSB5 CRD3D2D7D8CXD8D9CTD2D8 DDCXCTD0CSBA CCCWCTD7CT D2CTDB CSCXD7CRD3D2D8CXD2D9D3D9D7 CRD3D2D7D8CXD8D9CTD2D8D7 B4DBCXD8CW CRD3D1D4D3D2CTD2D8 DDCXCTD0CSD7 D8CWCPD8 CSD3 D2D3D8 CTDCCWCPD9D7D8 D8CWCTCXD6 CRD3D2D7D8CXD8D9CTD2D8 DDCXCTD0CSD7B5 CPD6CT D7D8CXD0D0 D8D6CTCPD8CTCS CPD7 D3D6CSCXD2CPD6DDCRD3D2D7D8CXD8D9CTD2D8D7 CQDD D8CWCT D4CPD6D7CTD6B8 DBCWCXCRCW CRD3D1CQCXD2CTD7 D8CWCTD1 DBCXD8CW CPD6CVD9D1CTD2D8D7 CPD2CS D1D3CSCXACCTD6D7 D9D2D8CXD0 CPD0D0 D3CU D8CWCTCXD6 CPD6CVD9D1CTD2D8 D4D3D7CXD8CXD3D2D7 CWCPDACT CQCTCTD2 D7D9CRCRCTD7D7B9 CUD9D0D0DD CSCXD7CRCWCPD6CVCTCSB8 CPD8 DBCWCXCRCW D4D3CXD2D8 D4CPCXD6D7 D3CU CSCXD7CRD3D2D8CXD2D9B9 D3D9D7 CRD3D2D7D8CXD8D9CTD2D8D7 DBCXD8CW D8CWCT D7CPD1CT CRD3D2D7D8CXD8D9CTD2D8 DDCXCTD0CS CRCPD2 CQCT D6CTCPD7D7CTD1CQD0CTCS CXD2D8D3 DBCWD3D0CT DF D3D6 CPD8 D0CTCPD7D8 D0CTD7D7 CSCXD7CRD3D2B9 D8CXD2D9D3D9D7 DF CRD3D2D7D8CXD8D9CTD2D8D7 CPCVCPCXD2BA BT D7CPD1D4D0CT CSCTD6CXDACPD8CXD3D2 CUD3D6 D8CWCT DACTD6CQ D4CWD6CPD7CT COCRD3D2B9 D8CPCXD2CXD2CV D3D2CT D3D6CPD2CVCT CPD2CS D3D2CT D0CTD1D3D2B8B3 CXD2DAD3D0DACXD2CV CRD3D2B9 CYD9D2CRD8CXD3D2 D3CU CTDCCXD7D8CTD2D8CXCPD0D0DD D5D9CPD2D8CXACCTCS D2D3D9D2 D4CWD6CPD7CTD7B8 CXD7 D7CWD3DBD2 CXD2 BYCXCVD9D6CT BFB8 D9D7CXD2CV D8CWCT CPCQD3DACT D4CPD6D7CT D6D9D0CTD7 CPD2CS D8CWCT D0CTDCCXCRCPD0CXDECTCS CVD6CPD1D1CPD6BM CRD3D2D8CPCXD2CXD2CV BM CBD2C6C8 D5 BPC6C8 D5 BC D3D2CT BM CGD2C6C8 D5 A1 C6C8 D5 D2C6C8 D5 A1 C6C8 D5 BPC6C8 AF CGBPC6C8 D5 A1 C6C8 D5 D2C6C8 D5 A1C6C8 D5 BPC6C8 AF D3D6CPD2CVCTB8 D0CTD1D3D2 BM C6C8 AF CPD2CS BM BVD3D2CY BYCXD6D7D8 D8CWCT D4CPD6D7CTD6 CPD4D4D0CXCTD7 D8CWCT D7CZCXD4 CRD3D2CYD9D2CRD8CXD3D2 D6D9D0CTD7 D8D3 D3CQD8CPCXD2 D8CWCT CSCXD7CRD3D2D8CXD2D9D3D9D7 CRD3D2D7D8CXD8D9CTD2D8D7 D7CWD3DBD2 CPCUB9 D8CTD6 D7D8CTD4D7 B4BDB5 CPD2CS B4BEB5B8 CPD2CS CP CRD3D1D4D3D2CTD2D8 CXD7 CSCXD7CRCWCPD6CVCTCS CUD6D3D1 CTCPCRCW D3CU D8CWCT D6CTD7D9D0D8CXD2CV CRD3D2D7D8CXD8D9CTD2D8D7 D9D7CXD2CV D8CWCT CTD1D4D8DD CRD3D1D4D3D2CTD2D8 D6D9D0CT CXD2 D7D8CTD4D7 B4BFB5 CPD2CS B4BGB5BA CCCWCT CRD3D2D7D8CXD8D9CTD2D8D7 D6CTD7D9D0D8CXD2CV CUD6D3D1 B4BFB5 CPD2CS B4BGB5 CPD6CT D8CWCTD2 CRD3D1B9 D4D3D7CTCS DBCXD8CW D8CWCT DACTD6CQ CRD3D2D7D8CXD8D9CTD2D8 CUD3D6 COCRD3D2D8CPCXD2CXD2CVB3 CXD2 D7D8CTD4D7 B4BHB5 CPD2CS B4BIB5B8 D9D7CXD2CV D8CWCT D0CTCUD8 CPD8D8CPCRCWD1CTD2D8 D6D9D0CT CUD3D6 CUD6CTD7CW CRD3D1D4D3D2CTD2D8D7BA CCCWCT D5D9CPD2D8CXACCTD6D7 CPD6CT D8CWCTD2 CPD4D4D0CXCTCS CXD2 D7D8CTD4D7 B4BJB5 CPD2CS B4BKB5B8 CPD2CS D8CWCT D6CTD7D9D0D8CXD2CV CRD3D2D7D8CXD8D9CTD2D8D7 CPD6CT D6CTCPD7D7CTD1CQD0CTCS D9D7CXD2CV D8CWCT CRD3D2CYD9D2CRD8CXD3D2 D6D9D0CTD7 CXD2 D7D8CTD4 B4BLB5BA CCCWCT CPCSCYCPCRCTD2D8 CRD3D1D4D3D2CTD2D8D7 CXD2 D8CWCT CRD3D2D7D8CXD8D9CTD2D8 D6CTD7D9D0D8CXD2CV CUD6D3D1 D7D8CTD4 B4BLB5 CPD6CT D8CWCTD2 D1CTD6CVCTCS D9D7CXD2CV D8CWCT CRD3D1CQCXD2CPD8CXD3D2 D6D9D0CT CXD2 D7D8CTD4 B4BDBCB5B8 D4D6D3CSD9CRCXD2CV CP CRD3D1D4D0CTD8CT CVCPD4D0CTD7D7 CRD3D2D7D8CXD8D9CTD2D8 CUD3D6 D8CWCT CTD2D8CXD6CT CXD2D4D9D8BA CBCXD2CRCT D8CWCT D4CPD6D7CTD6 D6D9D0CTD7 CPD6CT ACDCCTCSB8 CPD2CS D8CWCT D2D9D1CQCTD6 D3CU CRD3D1D4D3D2CTD2D8D7 CXD2 CPD2DDCRCWCPD6D8 CRD3D2D7D8CXD8D9CTD2D8 CXD7 CQD3D9D2CSCTCS CQDD D8CWCT D1CPDCCXD1D9D1 D2D9D1CQCTD6 D3CU CRD3D1D4D3D2CTD2D8D7 CXD2 CP CRCPD8CTCVD3D6DD B4CXD2CPD7D1D9CRCW CPD7 D8CWCT D6D9D0CTD7 CRCPD2 D3D2D0DD CPCSCS CP CRD3D1D4D3D2CTD2D8 D8D3 D8CWCT D6CTCRD3CVD2CXDECTCS D0CXD7D8 CQDD D7D9CQD8D6CPCRD8CXD2CV D3D2CT CUD6D3D1 D8CWCT D9D2D6CTCRD3CVD2CXDECTCS D0CXD7D8B5B8 D8CWCT CPD0CVD3D6CXD8CWD1 D1D9D7D8 D6D9D2 CXD2 D4D3D0DDB9 D2D3D1CXCPD0 D7D4CPCRCT CPD2CS D8CXD1CT D3D2 D8CWCT D0CTD2CVD8CW D3CU D8CWCT CXD2D4D9D8 D7CTD2D8CTD2CRCTBA CBCXD2CRCT D8CWCT CRCPD6CSCXD2CPD0CXD8DD D3CU CTCPCRCW CRD3D2D7D8CXD8D9CTD2D8B3D7 CSCTD2D3D8CPD8CXD3D2 CXD7 CQD3D9D2CSCTCS CQDD CYBXCY DA B4DBCWCTD6CT BX CXD7 D8CWCT D7CTD8 D3CU CTD2D8CXD8CXCTD7 CXD2 D8CWCT CTD2DACXD6D3D2D1CTD2D8 CPD2CS DA CXD7 D8CWCT D1CPDCCXB9 D1D9D1 DACPD0CTD2CRDD D3CU CPD2DD CRCPD8CTCVD3D6DDB5B8 D8CWCT CPD0CVD3D6CXD8CWD1 D6D9D2D7 CXD2 DBD3D6D7D8B9CRCPD7CT D4D3D0DDD2D3D1CXCPD0 D7D4CPCRCT D3D2 CYBXCYBN CPD2CS D7CXD2CRCT D8CWCTD6CT CXD7 D2D3 D1D3D6CT D8CWCPD2 D3D2CT D7CTD8 CRD3D1D4D3D7CXD8CXD3D2 D3D4CTD6CPD8CXD3D2 D4CTD6B9 CUD3D6D1CTCS DBCWCTD2 CP D6D9D0CT CXD7 CPD4D4D0CXCTCSB8 CPD2CS CTCPCRCW CRD3D1D4D3D7CXD8CXD3D2 D3D4CTD6CPD8CXD3D2 D6D9D2D7 CXD2 DBD3D6D7D8B9CRCPD7CT D5D9CPCSD6CPD8CXCR D8CXD1CT D3D2 D8CWCT D7CXDECT D3CU CXD8D7 CRD3D1D4D3D7CTCS D7CTD8D7 B4CSD9CT D8D3 D8CWCT D5D9CPD2D8CXACCTD6 D3D4CTD6B9 CPD8CXD3D2B5B8 D8CWCT CPD0CVD3D6CXD8CWD1 D6D9D2D7 CXD2 DBD3D6D7D8B9CRCPD7CT D4D3D0DDD2D3D1CXCPD0 D8CXD1CT D3D2 CYBXCY CPD7 DBCTD0D0BA BG BXDACPD0D9CPD8CXD3D2 CCCWCT CTDCD8CTD2CSCTCS D4CPD6D7CTD6 CSCTD7CRD6CXCQCTCS CPCQD3DACT CWCPD7 CQCTCTD2 CXD1B9 D4D0CTD1CTD2D8CTCS CPD2CS CTDACPD0D9CPD8CTCS D3D2 CP CRD3D6D4D9D7 D3CU BFBGBC D7D4D3B9 CZCTD2 CXD2D7D8D6D9CRD8CXD3D2D7 D8D3 D7CXD1D9D0CPD8CTCS CWD9D1CPD2B9D0CXCZCT CPCVCTD2D8D7 CXD2 CP CRD3D2D8D6D3D0D0CTCS BFB9BW CTD2DACXD6D3D2D1CTD2D8 B4D8CWCPD8 D3CU CRCWCXD0CSD6CTD2 D6D9D2B9 D2CXD2CV CP D0CTD1D3D2CPCSCT D7D8CPD2CSB8 DBCWCXCRCWDBCPD7 CSCTCTD1CTCS D7D9CXD8CPCQD0DD CUCPD1CXD0CXCPD6 D8D3 D9D2CSCTD6CVD6CPCSD9CPD8CT D7D8D9CSCTD2D8 D7D9CQCYCTCRD8D7B5BA CCCWCT D4CPD6D7CTD6 DBCPD7 D6D9D2 D3D2 D8CWCT DBD3D6CS D0CPD8D8CXCRCT D3D9D8D4D9D8 D3CU CPD2 D3ABB9D8CWCTB9D7CWCTD0CU D7D4CTCTCRCW D6CTCRD3CVD2CXDECTD6 B4BVC5CD CBD4CWCXD2DC C1C1B5 CPD2CS D8CWCT D4CPD6D7CTD6 CRCWCPD6D8 DBCPD7 D7CTCTCSCTCS DBCXD8CW CTDACTD6DD CWDDD4D3D8CWCTD7CXDECTCS DBD3D6CSBA CCCWCT D4CPD6D7CTD6 DBCPD7 CPD0D7D3 CRD3D1D4CPD6CTCS DBCXD8CW D8CWCT D6CTCRB9 D3CVD2CXDECTD6 CQDD CXD8D7CTD0CUB8 CXD2 D3D6CSCTD6 D8D3 CSCTD8CTD6D1CXD2CT D8CWCT CSCTCVD6CTCT D8D3 DBCWCXCRCW CPD2 CTD2DACXD6D3D2D1CTD2D8B9CQCPD7CTCS CPD4D4D6D3CPCRCW CRD3D9D0CS CRD3D1B9 D4D0CTD1CTD2D8 CRD3D6D4D9D7B9CQCPD7CTCS CSCXD7CPD1CQCXCVD9CPD8CXD3D2BA CCCWCT D7DDD7D8CTD1D7 DBCTD6CT CTDACPD0D9CPD8CTCS CPD7 DBD3D6CS D6CTCRD3CVD2CXDECTD6D7 B4CXBACTBA CXCVD2D3D6CXD2CV D8CWCT CQD6CPCRCZCTD8D7 CXD2 D8CWCT D4CPD6D7CTD6 D3D9D8D4D9D8B5 D3D2 D8CWCT ACD6D7D8 BDBCBC D7CTD2B9 D8CTD2CRCTD7 D3CU D8CWCT CRD3D6D4D9D7 B4CRD3D6D6CTD7D4D3D2CSCXD2CV D8D3 D8CWCT ACD6D7D8 D7CTDACTD2 D3CU BFBF D7D9CQCYCTCRD8D7B5BN D8CWCT D0CPD8D8CTD6 BEBGBC D7CTD2D8CTD2CRCTD7 DBCTD6CT D6CTB9 D7CTD6DACTCS CUD3D6 D8D6CPCXD2CXD2CV D8CWCT D6CTCRD3CVD2CXDECTD6 CPD2CS CUD3D6 CSCTDACTD0D3D4CXD2CV D8CWCT CVD6CPD1D1CPD6 CPD2CS D7CTD1CPD2D8CXCR D0CTDCCXCRD3D2BA CCCWCT CPDACTD6CPCVCT D9D8D8CTD6CPD2CRCT D0CTD2CVD8CW DBCPD7 CPD4D4D6D3DCCXD1CPD8CTD0DD D8CWD6CTCT D7CTCRD3D2CSD7 B4D7D9CQD7D9D1CXD2CV CPCQD3D9D8 BFBCBC CUD6CPD1CTD7 D3D6 D4D3D7CXB9 D8CXD3D2D7 CXD2 D8CWCT D4CPD6D7CTD6 CRCWCPD6D8B5B8 CRD3D2D8CPCXD2CXD2CV CPD2 CPDACTD6CPCVCT D3CU D2CXD2CT DBD3D6CSD7BA C8CPD6D7CXD2CV D8CXD1CT CPDACTD6CPCVCTCS D9D2CSCTD6 BGBC D7CTCRD3D2CSD7 D4CTD6 D7CTD2D8CTD2CRCT D3D2 CP C8BGB9BDBHBCBCC5C0DEB8 D1D3D7D8 D3CU DBCWCXCRCWDBCPD7 D7D4CTD2D8 CXD2 CUD3D6CTD7D8 CRD3D2D7D8D6D9CRD8CXD3D2 D6CPD8CWCTD6 D8CWCPD2 CSCTD2D3D8CPD8CXD3D2 CRCPD0CRD9D0CPD8CXD3D2BA BTCRCRD9D6CPCRDD D6CTD7D9D0D8D7 D7CWD3DB D8CWCPD8 D8CWCT D4CPD6D7CTD6 DBCPD7 CPCQD0CT D8D3 CRD3D6D6CTCRD8D0DD CXCSCTD2D8CXCUDD CP D7CXCVD2CXACCRCPD2D8D2D9D1CQCTD6 D3CU DBD3D6CSD7 D8CWCPD8 D8CWCT D6CTCRD3CVD2CXDECTD6 D1CXD7D7CTCS B4CPD2CS DACXCRCT DACTD6D7CPB5B8 D7D9CRCW D8CWCPD8 CP D4CTD6CUCTCRD8 D7DDD2D8CWCTD7CXD7 D3CU D8CWCT D8DBD3 B4CRCWD3D3D7CXD2CV D8CWCT CRD3D6D6CTCRD8 DBD3D6CS CXCU CXD8 CXD7 D6CTCRD3CVD2CXDECTCS CQDD CTCXD8CWCTD6 D7DDD7D8CTD1B5 DBD3D9D0CS D4D6D3B9 CSD9CRCT CPD2 CPDACTD6CPCVCT D3CU BK D4CTD6CRCTD2D8CPCVCT D4D3CXD2D8D7 D1D3D6CT D6CTCRCPD0D0 D8CWCPD2 D8CWCT D6CTCRD3CVD2CXDECTD6 CQDD CXD8D7CTD0CU D3D2 D7D9CRCRCTD7D7CUD9D0 D4CPD6D7CTD7B8 CPD2CS CPD7 D1D9CRCW CPD7 BDBL D4CTD6CRCTD2D8CPCVCT D4D3CXD2D8D7 D1D3D6CT CUD3D6 D7D3D1CT D7D9CQCYCTCRD8D7BM BDBC D6CTCRD3CVD2CXDECTD6 D4CPD6D7CTD6 CYD3CXD2D8 D7D9CQCYCTCRD8 D4D6CTCR D6CTCRCPD0D0 CUCPCXD0 D4D6CTCR D6CTCRCPD0D0 D6CTCRCPD0D0 BC BJBI BJBL BDBK BJBE BJBG BLBE BD BJBJ BJBH BEBK BIBF BHBH BKBF BE BJBC BJBD BFBF BGBL BHBG BIBL BF BJBD BIBJ BGBF BGBL BGBH BIBL BG BIBI BHBG BFBJ BGBG BFBL BIBJ BH BHBF BHBE BHBG BFBI BFBD BJBE BI BKBG BKBG BHBC BHBI BIBF BKBF CPD0D0 BIBK BIBJ BFBJ BHBF BHBC BJBH DBCWCXCRCW CXD2CSCXCRCPD8CTD7 D8CWCPD8 D8CWCT CTD2DACXD6D3D2D1CTD2D8 D1CPDD D3ABCTD6 CP D9D7CTCUD9D0 CPCSCSCXD8CXD3D2CPD0 D7D3D9D6CRCT D3CU CXD2CUD3D6D1CPD8CXD3D2 CUD3D6 CSCXD7CPD1B9 CQCXCVD9CPD8CXD3D2BA CCCWD3D9CVCW CXD8 D1CPDD D2D3D8 CQCT D4D3D7D7CXCQD0CT D8D3 CXD1D4D0CTB9 D1CTD2D8 CP D4CTD6CUCTCRD8 D7DDD2D8CWCTD7CXD7 D3CU D8CWCT CTD2DACXD6D3D2D1CTD2D8B9CQCPD7CTCS BDBC CBD9CRCRCTD7D7CUD9D0 D4CPD6D7CTD7 CPD6CT D8CWD3D7CT D8CWCPD8 D6CTD7D9D0D8 CXD2 D3D2CT D3D6 D1D3D6CT CRD3D1D4D0CTD8CT CPD2CPD0DDD7CTD7 D3CU D8CWCT CXD2D4D9D8B8 CTDACTD2 CXCU D8CWCT CRD3D6D6CTCRD8 D8D6CTCT CXD7 D2D3D8 CPD1D3D2CV D8CWCTD1BA CPD2CS CRD3D6D4D9D7B9CQCPD7CTCS CPD4D4D6D3CPCRCWCTD7B8 CXCU CTDACTD2 CWCPD0CU D3CU D8CWCT CPCQD3DACT CVCPCXD2D7 CRCPD2 CQCT D6CTCPD0CXDECTCSB8 CXD8 DBD3D9D0CS D1CPD6CZ CP D7CXCVB9 D2CXACCRCPD2D8 CPCSDACPD2CRCTBA BH BVD3D2CRD0D9D7CXD3D2 CCCWCXD7 D4CPD4CTD6 CWCPD7 CSCTD7CRD6CXCQCTCS CPD2 CTDCD8CTD2D7CXD3D2 D8D3 CPD2 CTD2DACXD6D3D2D1CTD2D8B9CQCPD7CTCS D4CPD6D7CXD2CV CPD0CVD3D6CXD8CWD1B8 CXD2CRD6CTCPD7CXD2CV CXD8D7 D7CTD1CPD2D8CXCR CRD3DACTD6CPCVCT D8D3 CXD2CRD0D9CSCT D5D9CPD2D8CXACCTD6 CPD2CS CRD3D2CYD9D2CRB9 D8CXD3D2 D3D4CTD6CPD8CXD3D2D7 DBCXD8CWD3D9D8 CSCTD7D8D6D3DDCXD2CV CXD8D7 D4D3D0DDD2D3D1CXCPD0 DBD3D6D7D8B9CRCPD7CT CRD3D1D4D0CTDCCXD8DDBA BXDCD4CTD6CXD1CTD2D8D7 D9D7CXD2CV CPD2 CXD1D4D0CTB9 D1CTD2D8CPD8CXD3D2 D3CU D8CWCXD7 CPD0CVD3D6CXD8CWD1 D3D2 CP CRD3D6D4D9D7 D3CU D7D4D3CZCTD2 CXD2D7D8D6D9CRD8CXD3D2D7 CXD2CSCXCRCPD8CT D8CWCPD8 BDB5 D8CWCT D3CQD7CTD6DACTCS CRD3D1D4D0CTDCB9 CXD8DD D3CU D8CWCT CPD0CVD3D6CXD8CWD1 CXD7 D7D9CXD8CPCQD0CT CUD3D6 D4D6CPCRD8CXCRCPD0 D9D7CTD6 CXD2B9 D8CTD6CUCPCRCT CPD4D4D0CXCRCPD8CXD3D2D7B8 CPD2CS BEB5 D8CWCT CPCQCXD0CXD8DD D8D3 CSD6CPDB D3D2 D8CWCXD7 CZCXD2CS D3CU CTD2DACXD6D3D2D1CTD2D8 CXD2CUD3D6D1CPD8CXD3D2 CXD2 CPD2 CXD2D8CTD6B9 CUCPCRCTCS CPD4D4D0CXCRCPD8CXD3D2 CWCPD7 D8CWCT D4D3D8CTD2D8CXCPD0 D8D3 CVD6CTCPD8D0DD CXD1B9 D4D6D3DACT D6CTCRD3CVD2CXD8CXD3D2 CPCRCRD9D6CPCRDD CXD2 D7D4CTCPCZCTD6B9CXD2CSCTD4CTD2CSCTD2D8 D1CXDCCTCSB9CXD2CXD8CXCPD8CXDACTCXD2D8CTD6CUCPCRCTD7BA CACTCUCTD6CTD2CRCTD7 C3CPDECXD1CXCTD6DE BTCYCSD9CZCXCTDBCXCRDEBA BDBLBFBHBA BWCXCT D7DDD2D8CPCZD8CXD7CRCWCT CZD3D2D2CTDCB9 CXD8CPD8BA C1D2 CBBA C5CRBVCPD0D0B8 CTCSCXD8D3D6B8 C8D3D0CXD7CW C4D3CVCXCR BDBLBEBCB9BDBLBFBLB8 D4CPCVCTD7 BEBCBJDFBEBFBDBA C7DCCUD3D6CS CDD2CXDACTD6D7CXD8DD C8D6CTD7D7BA CCD6CPD2D7D0CPD8CTCS CUD6D3D1 CBD8D9CSCXCP C8CWCXD0D3D7D3D4CWCXCRCP BDBM BDDFBEBJBA CHCTCWD3D7CWD9CP BUCPD6B9C0CXD0D0CTD0BA BDBLBHBFBA BT D5D9CPD7CXB9CPD6CXD8CWD1CTD8CXCRCPD0 D2D3D8CPB9 D8CXD3D2 CUD3D6 D7DDD2D8CPCRD8CXCR CSCTD7CRD6CXD4D8CXD3D2BA C4CPD2CVD9CPCVCTB8 BEBLBMBGBJDFBHBKBA C2D3D2 BUCPD6DBCXD7CT CPD2CS CAD3CQCXD2 BVD3D3D4CTD6BA BDBLBKBDBA BZCTD2CTD6CPD0CXDECTCS D5D9CPD2D8CXACCTD6D7 CPD2CS D2CPD8D9D6CPD0 D0CPD2CVD9CPCVCTBA C4CXD2CVD9CXD7D8CXCRD7 CPD2CS C8CWCXB9 D0D3D7D3D4CWDDB8BGBA CBDDD0DACXCT BUCXD0D0D3D8 CPD2CS BUCTD6D2CPD6CS C4CPD2CVBA BDBLBKBLBA CCCWCT D7D8D6D9CRD8D9D6CT D3CU D7CWCPD6CTCS CUD3D6CTD7D8D7 CXD2 CPD1CQCXCVD9D3D9D7 D4CPD6D7CXD2CVBA C1D2 C8D6D3CRCTCTCSCXD2CVD7 D3CU D8CWCT BEBJ D8CW BTD2D2D9CPD0 C5CTCTD8CXD2CV D3CU D8CWCT BTD7D7D3CRCXCPD8CXD3D2 CUD3D6 BVD3D1B9 D4D9D8CPD8CXD3D2CPD0 C4CXD2CVD9CXD7D8CXCRD7 B4BTBVC4 B3BKBLB5B8 D4CPCVCTD7 BDBGBFDFBDBHBDBA CECTD6AJD3D2CXCRCP BWCPCWD0 CPD2CS C5CXCRCWCPCTD0 BVBA C5CRBVD3D6CSBA BDBLBKBFBA CCD6CTCPD8CXD2CV CRD3D3D6CSCXD2CPD8CXD3D2 CXD2 D0D3CVCXCR CVD6CPD1D1CPD6D7BA BTD1CTD6CXCRCPD2 C2D3D9D6D2CPD0 D3CU BVD3D1D4D9D8CPD8CXD3D2CPD0 C4CXD2CVD9CXD7D8CXCRD7B8 BLB4BEB5BMBIBLDFBLBDBA C2D3CWD2 BWD3DBCSCXD2CVB8 CAD3CQCTD6D8 C5D3D3D6CTB8 BYD6CPD2AOCRD3CXD7 BTD2CSCTD6DDB8 CPD2CS BWD3D9CVD0CPD7 C5D3D6CPD2BA BDBLBLBGBA C1D2D8CTD6D0CTCPDACXD2CV D7DDD2D8CPDC CPD2CS D7CTD1CPD2B9 D8CXCRD7 CXD2 CPD2 CTCRCXCTD2D8 CQD3D8D8D3D1B9D9D4 D4CPD6D7CTD6BA C1D2 C8D6D3CRCTCTCSCXD2CVD7 D3CU D8CWCT BFBED2CS BTD2D2D9CPD0 C5CTCTD8CXD2CV D3CU D8CWCT BTD7D7D3CRCXCPD8CXD3D2 CUD3D6 BVD3D1B9 D4D9D8CPD8CXD3D2CPD0 C4CXD2CVD9CXD7D8CXCRD7 B4BTBVC4B3BLBGB5BA C2D3D7CWD9CP BZD3D3CSD1CPD2BA BDBLBLBLBA CBCTD1CXD6CXD2CV D4CPD6D7CXD2CVBA BVD3D1D4D9D8CPB9 D8CXD3D2CPD0 C4CXD2CVD9CXD7D8CXCRD7B8 BEBHB4BGB5BMBHBJBFDFBIBCBHBA BXBA C3CTCTD2CPD2 CPD2CS C2BA CBD8CPDACXBA BDBLBKBIBA BT D7CTD1CPD2D8CXCR CRCWCPD6CPCRD8CTD6CXDECPB9 D8CXD3D2 D3CU D2CPD8D9D6CPD0 D0CPD2CVD9CPCVCT CSCTD8CTD6D1CXD2CTD6D7BA C4CXD2CVD9CXD7D8CXCRD7 CPD2CS C8CWCXD0D3D7D3D4CWDDB8 BLBMBEBHBFDFBFBEBIBA CACXCRCWCPD6CS C5D3D2D8CPCVD9CTBA BDBLBJBFBA CCCWCT D4D6D3D4CTD6 D8D6CTCPD8D1CTD2D8D3CU D5D9CPD2B9 D8CXACCRCPD8CXD3D2 CXD2 D3D6CSCXD2CPD6DD BXD2CVD0CXD7CWBA C1D2 C2BA C0CXD2D8CXCZCZCPB8 C2BAC5BABXBA C5D3D6CPDACRD7CXCZB8 CPD2CS C8BA CBD9D4D4CTD7B8 CTCSCXD8D3D6D7B8 BTD4D4D6D3CPCRCWCTD7 D8D3 C6CPD8B9 D9D6CPD0 C4CPD2CVCPD9CVCTB8 D4CPCVCTD7 BEBEBDDFBEBGBEBA BWBA CACXCTCSCTD0B8 BWD3D6CSD6CTCRCWD8BA CACTD4D6CXD2D8CTCS CXD2 CABA C0BA CCCWD3D1CPD7D3D2 CTCSBAB8 BYD3D6D1CPD0 C8CWCXD0D3D7D3D4CWDDB8 CHCPD0CT CDD2CXDACTD6D7CXD8DD C8D6CTD7D7B8 BDBLBLBGBA CFCXD0D0CXCPD1 CBCRCWD9D0CTD6BA BEBCBCBDBA BVD3D1D4D9D8CPD8CXD3D2CPD0 D4D6D3D4CTD6D8CXCTD7 D3CU CTD2DACXD6D3D2D1CTD2D8B9CQCPD7CTCS CSCXD7CPD1CQCXCVD9CPD8CXD3D2BA C1D2 C8D6D3CRCTCTCSCXD2CVD7 D3CU D8CWCT BFBLD8CW BTD2D2D9CPD0 C5CTCTD8CXD2CV D3CU D8CWCT BTD7D7D3CRCXCPD8CXD3D2 CUD3D6 BVD3D1B9 D4D9D8CPD8CXD3D2CPD0 C4CXD2CVD9CXD7D8CXCRD7 B4BTBVC4 B3BCBDB5B8CCD3D9D0D3D9D7CTB8 BYD6CPD2CRCTBA CBD8D9CPD6D8 C5BA CBCWCXCTCQCTD6B8 CHDACTD7 CBCRCWCPCQCTD7B8 CPD2CS BYCTD6D2CPD2CSD3 BVBAC6BA C8CTD6CTCXD6CPBA BDBLBLBHBA C8D6CXD2CRCXD4D0CTD7 CPD2CS CXD1D4D0CTD1CTD2D8CPD8CXD3D2 D3CU CSCTB9 CSD9CRD8CXDACT D4CPD6D7CXD2CVBA C2D3D9D6D2CPD0 D3CU C4D3CVCXCR C8D6D3CVD6CPD1D1CXD2CVB8 BEBGBMBFDF BFBIBA References Kazimierz Ajdukiewicz.
1935. Die syntaktische konnexitat.
In S.
McCall, editor, Polish Logic 1920-1939, pages 207231.
Oxford University Press.
Translated from Studia Philosophica 1: 127.
Yehoshua Bar-Hillel.
1953. A quasi-arithmetical notation for syntactic description.
Language, 29:4758.
Jon Barwise and Robin Cooper.
1981. Generalized quanti ers and natural language.
Linguistics and Philosophy, 4.
Sylvie Billot and Bernard Lang.
1989. The structure of shared forests in ambiguous parsing.
In Proceedings of the 27th Annual Meeting of the Association for Computational Linguistics (ACL '89), pages 143151.
Veronica Dahl and Michael C.
McCord. 1983.
Treating coordination in logic grammars.
American Journal of Computational Linguistics, 9(2):6991.
John Dowding, Robert Moore, Francois Andery, and Douglas Moran.
1994. Interleaving syntax and semantics in an ecient bottom-up parser.
In Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics (ACL'94).
Joshua Goodman.
1999. Semiring parsing.
Computational Linguistics, 25(4):573605.
E. Keenan and J.
Stavi. 1986.
A semantic characterization of natural language determiners.
Linguistics and Philosophy, 9:253326.
Richard Montague.
1973. The proper treatment of quanti cation in ordinary English.
In J.
Hintikka, J.M.E.
Moravcsik, and P.
Suppes, editors, Approaches to Natural Langauge, pages 221242.
D. Riedel, Dordrecht.
Reprinted in R.
H. Thomason ed., Formal Philosophy, Yale University Press, 1994.
William Schuler.
2001. Computational properties of environment-based disambiguation.
In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics (ACL '01), Toulouse, France.
Stuart M.
Shieber, Yves Schabes, and Fernando C.N.
Pereira. 1995.
Principles and implementation of deductive parsing.
Journal of Logic Programming, 24:336.
 The Elimination of Grammatical Restrictions M.
Salkoff and in a String Grammar of English N.
Sager Institute for Computer Research in the Humanities New York University, New York i.
Sun~nary of String Theory In writing a grammar of a natural language, one is faced with the problem o f e x p r e s s i n g grammatica NVN number: sequence N1 and N 2 (N, noun: V, verb), the subject The boy eats the meat; Q N1 P N2 N For example, i n t h e s e n t e n c e form and the verb V must agree in Or, in the five feet in length, One of the ~ The boys eats the meat.
e.g., (Q a number; P, preposition), are of particular subclasses: theories of linguistic structure which is particularly relevant to this problem is linguistic string analysis[1].
In this theory, the major syntactic (a string is structures of English are stated as a set of elementary strings a sequence of word categories, e.g., N V____NN, N V P N, eta).
Each sentence of the language consists of one elementary sentence (its center string) plus zero or more elementary adjunct strings which are adjoined either to the right or left or in place of particular elements of other elementary strings in the sentence.
17.~ The elementary strings can be grouped into classes according to how and where they can be inserted into other strings.
an elementary string, X If Y = X 1 X 2. . . Xn is ranging over the category symbols, the following classes of strings are defined: left adjuncts of X: adjoined to a string Y to the left of X in Y, or to the left of an ~X adjoined to Y in this manner.
rX right adjuncts of X: adjoined to a string Y to the right of X in Y, or to the right of an rX adjoined to Y in this manner.
replacement strings of X: adjoined to a string Y, replacing X in Y.
sentences adjuncts of the string Y, adjoined to the left of X 1 or after X i in Y (l~ i ~ n), or to the right of an Sy adjoined to Y in this manner.
Cy, i conjunctional strings of Y, conjoined after X i in Y (i< i < n), or to _ _ the right of a Cy, i adjoined to Y in this manner.
z center strings, not adjoined to any string.
These string-class definitions, with various restrictions on the repetition ~and order of members of the classes, constitute rules of combination on the elementary strings to form sentences.
Roughly speaking, a center string is the skeleton of a sentence and the adjuncts are modifiers.
green we met in in An example of a left adjunct of N is the adjective A right adjunet of N is the clause whom the green blackboard.
the man whom we met.
in the sentence A replacement formula of N is, for example, The same sentence what he said What he said was interesting.
with a noun instead of a noun replacement string might be interesting.
since he left.
An example is are Examples of sentence adjuncts are The lecture was in general, at this time, The c strings have coordinating conjunctions at their head.
but left in He was here but left.
Examples of center strings He understood and also We wondered whether he understood.
The grammatical dependencies are expressed by restrictions on the strings as to the word subcategories which can occur together in a string or in strings related by the rules of combination.
Thus, in the center string N 1 V N2, the figrammatical dependency mentioned above is formulated by the restriction: if N1 is plural, theh V does not carry the singular morpheme -_ss.
The string grammar with restrictions gives a compact representation of the linguistic data of a language, and provides a framework within which it is relatively simple to incorporate more linguistic refinement, restrictions.
J i.e., more detailed One may ask whether it is possible to write such a string grammar without any restrictions at all, i.e., to express the grammatical dependencies (restrictions) in the syntactic structures themselves.
In the resulting restrictionless grammar, any elements which are related by a grammatical dependency w i l L b e e l e m e n t s relations, other of the same elementary string.
No grammatical than those given by the simple rule of string combination, The result of this paper is to obtain between two strings of a sentence.
demonstrate that such a restrictionless grammar can be written [4].
In order to obtain a restrictionless form of a string grammar of English, we take as a point of departure the grammar used by the computer program for string decomposition of sentences, developed at the University of Pennsylvania [2,3].
This gran~nar is somewhat more detailed than the sketch of an English A summary of the form of the computer grammar is In section 3 we show how the restrictions can be string grammar in Ill.
presented below in section 2.
eliminated from the gran~nar.
An example of a typical output obtained for a short sentence from a text of a medical abstract is shown in Figs.
1 and 2.
The decomposition of the sentence into a sequence of nested strings is indicated in the output by the numbering of the strings.
As indicated in line 1., the sentence consists of the two assertion centers in lines 2.and ~ ~ conjoined by and.
The line B  ficontains a sentence adjunct th~_~) on the assertion center as a whole . The assertion center 2 . is of the form N V A : Spikes would be effective . The noun spikes has a left adjunct (such enhanced) in line 5  as indicated by the appearance of 5 . to the left of spikes . The object effective has a left adjunct ~ 9 _ ~ ) in line 6 . and a right adjunct in line 7  In the same wsy, each of the elements of the adjunct strings may have its own left and right adjuncts.
Line IO . contains an assertion center in which the subject and the This zeroing is indicated in the modal verb (woul____dd)have been zeroed.
output by printing the zeroe~ element in parentheses.
The difference between the two analyses in Figs.
decomposition of the sequence in initiating analysis (Fig.
i an~ 2 lies in the In the first synaptlc action.
I), this sequence is taken as a P_~N right adjunct on of the effective, where initiating synaptlc is a left adjunct (onaction) form of a repeated adjective (parallel to escaping toxic in the sequence in eseap.ing toxic gases) . In the second analysis (~ig.
2), this same sequence is taken as a ~ right adjunct of effective, where initiating is the Ving, and synaptic action is the Object of initiating.
The Computer String Grammar.
In representing the string grammar in the computer, a generalized grammar where Y-.
= Y' IS where Y' is a grammar string like Y.
This system of nested gram~nar strings terminates when one of the grammar strings is equal to an atomic string (one of the word-category symbols).
The Y.
are called the options of Y, and each option Y.
consists of the elements Y... l l 13 Not every option of a grammar string Y will be well-formed each time the sentence analysis program finds an instance of Y in the sentence being analyzed.
Associated with each option Yi is a series of zero or more tests, called restrictions.
'If RiP is the set of tests associated with Yi then the grammar A restriction is a test (which will be descrfbed below) so written that if it does not give a positive result its attached option may not be chosen.
All of the restrictions in the grammar fall into two types: TypeA: The restrictions of type A enable one to avoid defining many The options of the grammar string Y similar related sets of grammar strings.
have been chosen so that Y represents a group of strings which have related filinguistic properties.
This allows the grammar to be written very compactly, and each grammar string can be formulated as best suits the linguistic data.
However, when a grammar string Y appears as a Y' ij of some other string Y', some of the options of Y may lead to . non-wellformed sequences.
In order to retain the group of options of Y and yet not allow non-wellformed sequences wherever options of Y which would have that effect are used, we attach a restriction of type A to th0s~ options of Y.
For example, let Y be where and YI = which Z V (e.g., which he chose) Y2 = what E V (e.g., what he chose) Then Y can appear in the subject Z of the linguistic center string CI: Cl = z v n What he chose was impDrtant.
This yields Which he chose was important; As it is defined here, Y can also be used to represent the wh-clauses in the right adjuncts of the noun: but in rN only the which option of Y gives wellformed sequences: 3 the book which he chose the book what he chose Hence a restriction R a is attached to the what option of Y (eq.
5) whose effect is to prevent that option from being used in rN.
Type B: With some given set of rather broadly defined major categories (noun, verb, adjective, etc).
it is always possible to express more detailed linguistic relations by defining sub-categories of the major categories.
These relations then appear as constraints on how the sub-categories may appear together in the grammar strings Y.
If some element Yij of Yi is an atomic string (hence a word-category symbol) representing some major category, say C, then Rb may exclude the subcategory Cj as value of Yij if some other element Yik of Yi has the value Ck.
Y i k m a y also be a grammar string, in which case R b m a y exclude a particular option of Yik when Yij has value C..
The restrictions Rb may be classified into three kinds: (a) Between elements of some string Y.
where the Y..
correspond to elements 1 i~ of a linguistic string.
For example, A noun in the sub-category singular cannot appear with a verb in the sub-category plural.
~ The man agree.
Only a certain sub-category of adjective can appear in the sentence adjunct P__AA : in general, (b) in particular, ~ in ha~py.
Between a Yij and a Yik where Yij corresponds to an element of a linguistic For example, string and Yik corresponds to a set of adjuncts of that element.
In rN, the string to V 2 cannot adjoin a noun of sub-categoryN 2 (proper names): the man to do the job ~ John to do the ~ob.
Only a certain adjective sub-category (e.g., re~/.e~, available) can appear in rN without any left or right adjunct of its own: the people present ; (c) ~ the people happy.
Between Yij and Yik ' where one corresponds to an element of a linguistic string and the other corresponds to an adjunct set which can repeat itself, i.e., which allows 2 or more adjuncts on the same linguistic element.
These restrictions enable one to express the ordering among adjuncts in some adjunct sets.
For example, Q (quantifier) and A (adjective) are both in the set N ' the left adjuncts of the noun.
However, _Q can precede A but A cannot precede _Q when both are adjuncts of the same N in a sentence: 3 Q A N books, but ~AQN e.g., five green e.g., green five books.
The string grammar defined by eqs.
i-3, together with the atomic strings (word-category symbols) have the form of a BNF definition.
The system with eq.
4, however, departs from a BNF definition in two important respects : (a) it contains restrictions (tests) on the options of a definition; (b) the atomic strings (word-categories) of the grammar have sub-classifications.
With the elimination of the restrictions, the computer grammar will again have the form of a BNF definition.
fi3. Elimination of the Restrictions The restrictionless string grammar is obtained from the grammar (in described above by the methods of (A) and (B) below.
Initially this paper), conjunctional restrictionless strings have not been included in the grammar.
We estimate that the addition of conjunctions/ grammar by a strings will increase the size of the restrictionless factor of about 5.
(A) The linguistic strings represented in the computer graz~,ar are reformulated in accordance with the following requirement.
any utterance of a language containing Given grammatical dependency obtains between A and B, the elementary strings of a restrictionless string grammar are defined so that A and B appear together in the same linguistic string, and any iterable sequence between A and B is an adjunct of that string.
Iterable sequences of the type seemed to begin to in It seemed to be~in to surprise him that we in It is said to be known worked seriously, or is said to be known to to surprise him that we worked seriuusly are analyzed as adjuncts.
If we place such sequences among the left adjuncts of the verb, v ' then the sentences above can be put in the form It~_v surprise him that we worked seriously fi~v = seemed to begin to ; However, when the adjunct by definition), surprise verb of ~v is said to be known to ; etc.
takes on the value zero (as can all adjuncts, sequence It then (9) above becomes the non-grammatical him that we worked seriously.
~v (seemed ~ This happens because the first and the latter is__) carries the tense morpheme, disappears when We separate the tense morpheme from the verb, and place it in the center string as one of the required elements.
(i0) C1 = Z t ~ V g; This formulation of the assertion center string C1 (lO), in which the tense morpheme is an independent element and iterable sequences are taken as adjuncts, is necessary in ord@r to preserve, for example, the dependence surprises him that we In the between the particle it and the succeeding sequence worked seriously: grammar~which ~ The book surprises him that we worked seriously.
includes restrictions, this formulation is not necessary because this dependence can be checked by a restriction.
(B) Turning to the computer form of the grammar, all the restrictions of the grammar are eliminated either by defining new grammar strings (for the elimination of the restrictions categories by the particular required by the restriction Ra) ' or by replacing the general wordsubclasses of those categories which are (to eliminate Rb).
The application of this procedure increases the number of strings in the grammar, of course.
The restrictions R a can be eliminated in the following manner.
Suppose the option Yi of Y has a restriction R a on it which prevents it from being chosen in Y' (Y is a Y'ij of Y').
Then define a new grammar string Y ' w h i c h ficontains all the options of Y but Y.
: Then the new gran~nar string Y* replaces Y in Y'.
R a on p.
5, the string Y* = which Z t fv V / ....
Thus, in the example of (in the modified treatment of tense and iterable sequences) would replace Y in r N.
The restrictions R b are eliminated in a different way, according to the types described on p.
6. (a) New strings must be written in which only the wellformed sequences In the example of subject-verb agreement, the of subcategories appear.
where N s and Np are singular and plural nouns, V s and Vp singular and plural verbs.
(b) If an element of a particular subcategory, say Ai, can take only a rAi is defined.
It subset of the adjuncts rA, then a new adjunct s~ring contains those options~_ of rA which can appear only with A i plus all the options of r A which are common to all the sub-categ0ries of A.
When this to rA, : has been done f0r  all A i having some particular behavior w i t h r e s p e c t all the remaining sub-categories A rA ~ AlrA1 of A will have a common adjunct string r a As many new sets rAi must be defined as there were special sub-categories A.
A similar argument holds for ~A and other adjunct sets which depend on A.
A new element corresponding to the/adjunct set must be defined in which the adjuncts appear correctly ordered with respect to each other, and each one must be able to take on the value zero.
This procedure for eliminating restrictions is also the algorithm for introducing further grammatical refinements into the restrictionless grammar.
Such a general procedure can be formulated because of an essential property of a string grammar: In terms of linguistic (elementary) strings, all a) between elements of a string, or b) between an restrictions are either element of the string and its adjunct, or same string.
c) between related adjuncts of the Further, there is no problem with discontinuous elements in a all elements which depend in some way on each other grammaticstring grammar: ally appear in the same string or in strings which are contiguous by adjunction.
The cost of the elimination of all restrictions in this way is about an order of magnitude increase in the number of strings of the grammar.
Instead of about 200 strings of the computer grammar, the grammar presented here has about 2000 strings.
It is interesting that the increase in the size of the This suggests that in a program Also, since grammar is not greater than roughly one order of magnitude.
there may be practical applications for such a grammar, e.g. designed to carry out all analyses of a sentence in real time.
the restrictionless grammar is equivalent to a B.N.F. grammar of English, it may prove useful in adding English-language features to programming languages which are written in B.N.F. fiSENTENCE N E U H I B  SUCE ENHANCED SPIKES WOULD BE MORE E F F E C T I V E IN I N I T I A T I N G SYNAPTIC ACTION AND THUS BE RESPONSIBLE FOR THE OBSERVED POST-TETANIC POTENTIATION  Ol I.
PARSE SENTENCE INTRODUCER CENTER AND Z, AND CI ASSERTION SUBJECT 5 . SPIKES VERB $ OBJECT gOULD BE 6.
EFFECTIVE RV T, ACVERB ADVERB THUS CONJUNCTION LN ARTICLE QUANTIFIER SUCH ADJECTIVE ENHANCED TYPE-NS" NOUN AEVERB PN PREPOSITION IN ACTION lO.
CI ASSERTION BE OBJECT RESPONSIBLE II.
LN ARTICLE QUANTIFIER ADJECTIVE INITIATING TYPE-MS SYNAPTIC NOUN PN POTENTIATION LN GUANTIFIER ADJECTIVE OBSERVED P O S T T E T A N I C TYPE-NS NOUN SENIENCE NEUH-.IB  SUCH ENHANCED SPIKES kOULD BE MORE E F F E C T I V E IN I N I | i A T I N G S Y N A P T I C A C T I O N AND THUS UE R E S P O N S I B L E FOR THE OBSERVED P O S T T E T A N I C P O T E N T I A T I O N  02 = |NTROOUCER CENTER AND Z.
AND 3 6 END MARK  PARSE SENTENCE CI VERB  kOULD BE RV T, ACVERB S ADVERB IHUS LN ARTICLE QUANTIFIER SUCH ADJECTIVE ENHANCED TYPE-NS NOUN lCVERB To P NS V I N G I O F | 0 = PREPOSITION IN SN INIIIATING ACTION CI ASSERTION VERB (WOULD) OBJECT RESPONSIBLE LN QUANTIFIER TYPE-NS NOUN PN = LP P R E P O S I T I C N FOR POTENTIATION QUANTIFIER ADJECTIVE OBSERVEO P O S T T E T A N I C TYPE-NS NOUN NG MCRE PARSES Conclusion 4.
This problem was suggested by Professor J.
Schwartz of the Courant institute of Mathematical Sciences, New York University.
5. The option Yi here corresponds to the linguistic string Y of the previous section.
The symbol / separates the options of a string definition.
Academic Press, REFERENCES 1.
Harris, Z.
S., . String Analysis of Sentence Structure.
Papers on Formal Linguistics, No.
l, Mouton and Co., The Hague, 1962.
2. Sager, N., Salkoff, M., Morris, J., and Raze, C., . Report on the String Analysis Programs.
Department of Linguistics, University of Pennsylvania, March 1966.
3. Sager, N., . Syntactic Analysis of Natural Language.
Advances in Computers (Alt, F.
and Rubinoff, M., eds.), vol.
8, pp.
153-188. New York, 1967 .
CONTEXTUAL GRAMMARS Solomon Marcus InsUtutul de Matematica Str, Mihal Eminescuo 47 BuchareSt 9, ROMANIA In the following, we shall introduce a type of generative grammars, called contextual grammars.
They are not comparable with regular grammarsBut every language generated by a contextual grammar is a context-ree language.
Generalized contextual grammars are introduced, which may generate non-cox,text-free languages.
Let V be a finite non-void set ; V lary.
Every finite sequence of elements in ia called a vocnbuV is said to be a string on V.
Given a string x = ala2...an, the number n is called the length of x.
The string of length zero is called the n tring and is denoted by r~J. Any set of strings on V is called a language on V.
The set of all strings on V (the null-string inclusively)is called the universal language on V.
By a nwe denote the string a...a, where a is iterated n times.
Any ordered pair (u,v~ of strings on V_ is said to be a contex~ on V.
The string x is admitted by the context <u,v> With respect to the language L if u~ G L.
Let .~ be a finite set of strings on the vocabulary V~ and let@be a finite se@ of contexts on V.
The triple (v,~, ~)) (1) is said to be a contextual l~rammar ; V is the vocabulary of the grammar, ~ is the ba_s_e_ of the grammar and ~is the co m~,-2textual ccmoonent of the grammar.
Let us denote by ~ the contextual grammar defined by (1).
Oonsider the smallest language L on Vj fulfilling the following two conditiom8 (~J Iz ~ and <u,v>,(~), th-~=,L.
The language L is said to be the lsmguage generated by the contextual grammar G.
This means that the language generated by G is the intersection of all languages L fulfilling the conai~ions (~) and (pj . A language ~L is said to be a eonteF~ual language if there exists a contextual grammar G which generates L.
Proposition i.
Eyer~ finite language is a cont~ual lanProo__f.
Let V be a vocabulary and let ~ be a finite lan.
guage on V.
It is obvious that the contextual grammar (V,L4jO), where 9 dauotes the void set of contexts, gauerates the language L I.
The same language may be gamerated by means of the .g  contextual grammar (V,I~, where is formed by the nu~ cont ex~ only.
Two contextual grammars are called e~uivalemt if they gemssame language.
The grammars CV,LI, O ) and (V,~,~ rate the are equivalent, since they both generate the language ~ The converse of Proposition 1 is not true.
Indeed, we have Proposition 2.
The universal language is a contextual language.
ProOf. Let V = ~alLa2,...~ ~.
De~ote by I~ the umiver.
Sal language on V.'T.et us put ~" S~.~.~ and t <~''i" " C -3~,a~,,...s(~,ian> ~ It is easy to see that thegrammar . (V,~ generates the universal language on V.
Remarks. If we put, in the proof Of Proposition 2, LI-V instead of h =~' then the grammar (V_,h,@) does not generate the universal language on V, since the language it generates dDes not contain the nu/l-strlng.
In order to illustrate the activity of the grammar (V,~, ~defined in the of let consider the proof proposition 2, US particular case when the vocabulary iS formed by two elements only : V =(a.b~.
The general form of a string x on V is x = a ~b ~a-~b~...a ~b~, where il, Jl, i2,j2,...,~,j ~ are arbitra~non-negative integers.
In order to generate the string x, we start with the null.string @@ and we apply il times the context ~,a~ . The result of this operation is the string a 11,to which we apply Jl times the context <~,b> and obtain the string al~ ~I . Now we apply i~ times the context <~,a>, than J2 ti~es the context ~,b_> and we continue so alternatively.
~hen, ~dter 2p-2 steps, we have obtained the J = ai bJlai b 2ooo LP" ib -i, it is ply .~ ti~es ~ne context ~@,~ and, to the string so obtained, jp times ~:e contex~ ~gb>, in order to generate completely Uhe string Xo Haskell Curry considered Ghe larlg~age L = {abn~ (n=l,2~..o) as a model of ~he set of natural numbers \[5~ o We call L the language of Curry.
Prooosiuion 3.
The language of Curry is a contextual langu~eo proof.
The considered language is generated by the grammar (V,LI,~), where V= ~a.b~, I~ =~a 3 -nd~ ~<~,b~.
We recall that a language is Said to be regular if it may be generated by means of a finite aatoma$on (or, equivalently, by means of a finite state grammar in the sense of Ohomsky).
Proposition 4.
There exis$~ a contextual language which is Proof.
Let us consider the language L = ~a-nb n} (n=l,2,)...
If we put V = {ab}, L 1 = ~ab~ and ~ ~<a.b>}, then it is easy to see that L is generated by the con~extuai grammar (V, LI, ~.
On the other hand, L is n~t a regular language.
This fact was assel~ed by Ghomsky in \[3~ and\[~\], but the proof he gives is wrong.
A correct proof of this assertion and a.discussion of Chomsky' s proof were given in \[~\].
and ~.
Propositions 2,3 and # show that there are many infinite languages w~ioh are oontextual.
This fact may be explained by means of P~posi~ion 5.
If the set ~ is non-void and if the set~ contains at least one non-nu/1 contex~ I ~hen the contextual gramma___r_r (V.Ll, ~ ~enerate s an infinite language.
Proof. Since L A is non-void, we may find a string x be@ longing to ~i o Since contains, at least one non-nu/\] context, @  let ~u,v~ be a non-null context belonging to . l~rom these assumptions, we infer that the strings, u2xv 2, . .,un~,,..
are mutually distinc~ and belong all to the language generated by the grammar (V,I~,).
Thus, ~his language is infinite.
The converse of Proposition 5 is true.
Indeed, we have / / -5Proposition 6.
If the contextual 6rammar (V, LI~ gau~ rates an infillite language, then ~Ll.
is non-void, whereas@ c0nrains a no~-nult context.
proof. Let L be the language generated by ~V)LI~.
If is void, L is void too, hence it cannot be infinite.
If contains no non-null context, we have L = L I.
But ~d is in any ease flni~e ; ~hus, L is finite, in contradictiom With the h vpothesis.
Since there are contextual language which are not regular (see Proposition 4 above), it would be interesting to establish whether all contextual languages are context-free ls~guages.
The amswer is affirmative : Proposition 7.
_Every contextua~ lan?.ua~e is a context-free PrP~oof.
Let b be a contextual language.
If L is finite, it is a regular language.
But i~ is well knowm that every regular language is a context-free language.
Therefore, L is a context-free language.
Nowe let us suppose that L is infinite.
Deao~e by G = (V,,L l, a contextual grammar which generates the language L, In view of Proposition 6, L I is non-void,wheream there exists an integer i, l~ i~p, such that the con~ext ~ui,vi~ is non-nu~ Joe.
at least one of the equalities ui =co, v i =~ is false.
Let us make a choice a~d suppose tha@ ~.i ~ ~ Let L~ = {xcA,xp_, ...
9~a} and (~) ={<ultVl>, ~.,U,.~,V."y} . We define a context-free grammar ~)..@| as follows.
The terminal vocabulary of ~ is V.
The nonterminal vocabulary of ~ contains one element onlydenoted by S which is, of course, the axiom of the grammar ~ . The ter-6minal ~ rul es o f ~' are, S -->_x 1, g--~x a, S.--* _Xn whereas uhe non-terminal rules are S ---> u~5% v-i ' S ---) uqS v~, It is obvious tha~ the number of terminal rules is equal to the number of strings in ~, whereas the number of non-terminal rules is precisely the number of conuexts in ~.
Among the nonterminal rules, there is one at least which is non-trivial : it is the rule S ---> UiS vv~., where '*4 {~ " It is not difficult to nrove that the grammar ~ generates the given language L.
Indeed, the general form of a string in L__ is where yG V and <~i, V~ >E~ for s = 1,2,...,p.
In order to generate the considered string we begin by applying --Jl $imes She rule In this way, we obtain the expression h The next step consists in applying J~2 times the rule v -7-a ~,~2 s vv~.~., which yields the expression J~ Ja -Ja -J~ s Ha N 1 ))t~..., -7! l Oontinuing in this way, we arrive, after pression,~z "ia ~-i s J~-\].
J2 ~a us-1 ~,a .... .'$1 "-%'i "'" ~12 ".% " Vie now apply j.p times the rule and thus we obtain the expression p-1 steps, to the ex--Jp.~ .~!2-1 . Ja ':ll ..J.l.,.i2. u jp-1 ~ S "Ull '~i2 ....
~-l . V~p ~-l "" vi2-V-il where, by applying the terminal rule S---@ Z, the considered string is completely generated, Thus, we have proved that L is contained in the language generated by ~, Conversely, let z be a string generated by ~ . The general form of this generation involves sev(ral consecutive applications of non-terminal rules (the number of these applications may be eventually equal to zero) followed by one and only one application of a terminal rule.
It is easy to see that the result of this generation  is always a string of the form (2).
Thus we have proved that the language generated by ~ is contaiued in L, In view of the precedim~ eonsiderations, L iS precisely the language generated by ~ o Proposition 7 easily permits to obtain simple examples of .....
J -8languages which are not contextual l~guages.
For instance, ~he l~~uage of Kleene~an~ (m=~,2,...), the first example of an infinite language which is not regular, is a very simple example of ~ contextual language.
It is enough to remark that the sequence ~n2} (~ = 1,2,)... contains nO subsequaucewhioh is an infinite ari~hmebio progression ~ (We have (n+l)2-n22~+l and lira (~+i)=~, therefore for every subsequence of ~n2} the difi'erance of two consecutive terms has the limiu equal to +oo wh~ n-@ ~ ).
But a result of\[4\] asserts, among others, that given am infinite contex~-f1~ee lan~ guage L, the set of integers which represent the len~hs of the strings in L contains an infinite arithmetic progression.
It follows uhab b~Je language of Kleene is not context-free and, in view of Prooosition 7, it is not a conbex~ual language.
T~ sa-~ ~a~T ~@low* ~,~ ~h~-,~ :3.A,~.
~ \[g'J, ~,,#.
A natural question now arrises : Do there exist non-contextual languages a~ong context-free languages 7 The affirmative answer follows fro~ the following remark : The converse of Proposition 7 is not true.
Indeed, we have Prooositiou 8.
There exists a.
cont e.~-free language which is not a contextual language.
Proof. Let V = ~a,b~.
In view of a theorem of Gru~Lkl ~ ~__.-----~there exists, for every positive integer _n~ a context-free language I~ on V, such that every context-free grammar of I~ contains at least n non-terminal symbols.
But, as we can see in the proof of Proposition 7, every contextual language may be generated with a context-free grammar containing only one non-~erminal symbol.
Therefore, if _n ~ 2, ~ is not a contex~usl l~guage.
Proposition 8 suggests the natural question whe~bsr ~bere exist regular languages which are not contextual lan~ages.
The I -9answer is affirmative : Pronosition 9There exists a regular language which is not a context ual language.
Proof~ Let us consider the laugaage L = {abm-~c~a.~ n,) ~,n= =1,2,...), which was used b~ H.B.Curry \[5\], in order to descrlbe the set of mathematical (true or not) propositions.
This language is regular, since it can be generated by the rules S--> Abj Ac->Ab, A.--~ Ba, B--> CCC., G_--~ ~, C--~ Db, .D_--~ a, We shall show that .L is not a contextual language, Tndeed, let us admit that the contrary holds and let G = <V,~, ~> be a contextual grammar of L_ 2 Here, the gene_.-al form of a string in L is ~ ""-us ~I x~ -~ ...
vi= (3), wh eas (t = 1,2,...,=) where "'',Pn are arbitrary positive integers.
This means that ul,~2,... .---,_Un, Vl,Y2,-..,v ~ in the expression (3) are formed only by those elements of V whnse number of occurences in the strings of L is unlimited.
Only h satisfies this requirement.
It follows that in any string of .L both occurrences of sand the occurence of ~ are terms of the string x in (3).
But this implies that the intermediate terms between the occurrences of a are terms of x, hence we can find two strings y and, m l The string y is obvioasly .the null-string ~o the form 11~., hence " z such that,whereas z is of But m may be here an arbitrary positive integer.
Therefore, since -loX6~, it follows that ~ is an infinite se~ of mtrimgs.
This fact contradicts the assus~tion concern_tug G ! v, is ~t a contextual language and Proposition 9 is proved.
The contextual grammars may be generalized in order to generate some lauguages which are not context-free.
A generalized contextual ~r~mmar is a quadruple G =~,,L2, ~, where V, L I and ~have the same meal~g as in bhe definition of a contextual grammar, whereas J'2 is a finite set of strings on the vocabulary V.
We define the language L G generabed by G in the following way : Y~ is a language on V a~d xe~ if and only if we may e~press x in the form .where z~, y~Le, <ui,Yi>~for i : 1,2,...,n and pl,P2,...,pn, p are positive integers such that pl+P2..,~n=p. Every language generated by a generalized contextual grammar is said to be a generalized contextual lsnguage.
I~, in the delini~ion of G, we take L~ =~c~}, G is equivalent ~o a contextual grammar ! the lang,.% is then precisely the language generated by the contextual grammar ~V,LI~.In_ deed, the general form of a string in the contextual language generated by ~Y~LA, ~ is l P~a Pn Pa P2 Pl p roy ed ~roposition lo.
\]~ery oontex~ual language ~s a ~eneralized context ual lan~uaKe, llWe may consider a conte~ual grammar as a parbicular case of generalized contextual grammar, .by ideatifyimg the contextual grammar ~'~1~ with the generalized contextual grammam~,V,,~, " It is interesting to point out that somet~imes a cont~ual language may be easy generated by a generalized contextual grammar which is not a contextual grammar.
For instance, let.
us consider the l~.~e L= (~=} (~X,2,)...
. ~ ~is, or the proof of ProDosition A, L is a contextual language.
We map generate L by the generalized contextual grammar (which is not a co=textual ~r~a~) <v, h~>, where v : {~,b}, .Li_\[c~}, ~ = Ibm, ~= \[a,~ . It is known that,~_ is not reS~L%ag.
We ma~ give a similar example, wi~h a language which is regular.
In this respect let us consider the language of G~x~V~.~.
In view of Proposition 5, it is a contextual language.
It is a regular language too~ since it may be generated by the regular gramm~r contain~ ~he following two rules : q--~ Sb and S--> a.
Now let us consider the generalized contextual grammar < ~i' This grammar generates the language of Curlew, but if'is not a cent ext,~ al gran~nar.
~ow let us show that generalized contextual languages are an effective generalization of contextual languages.
Propo .sit ion ii.
Th ere _ exist s a_g en=e=~ iaed_gA~nt ext ua! language which is ~IQ~ a eon~ext~sl language, ~, Let us consider the language T, = an_b.n~..
n} (n:=-l,2,.
4 It
is known that this language is not context-free (see,or instance,66\],p.~).
7n view of Proposition 7, every contextual 12language is a context-free language ; hence~ ~ is not a con.
textual language.
Now let us consider the generalized contextual gr~m~ G = <V,~,~2,~>, .here v = ~,~, ~ ~,,~{~ and~ ~(~a>~ . It is easy to see that G generate the ieaguage L.
Yrom the proof of Proposition ll it follows immediately; Proposition 12.
There exists a ~eneralized contextual lang u_~e which is not a ~.nnteYt-f~ee language.
We may now ask whether the converse of Proposition 12 is true.
The answer is given by Proposition 13.
Th ere exists a cont ext-free~a~e~ even a regular language,~ which is.,not a generalized contextual !~ua~e.-~ P#oof.
We may consider the language L = ~sbmc_abn-} (~,n= =1,2,)... used in the proof of Proposition 9.
It was showed in the proof of Proposition 9 that L is regular.
Let us admit that ~ is a generalized contextual language.
Given a string x in L, its representation is of the form Pl P2 Pn P P~ P2Pl ~m ~ : ui u~ ....~n..~.
y'v". ...
v2v i where ~ui,vi~ ~ (i = 1 .....,n),ZG~, y~L2,pl+...+pn = p end G = ~V, L1,L~, ~ is the grsmmar of L.
By a reasoning similar to "that used in the proof of Proposition 9, we find that for every positive integer m there exists a string z in \]i I such that z = abmcab s~, where s is a non.negative integer, depending mf m.
But thls means that ~ eontain~ infinitely ma~ strips.
This fact con... tradicts the definition of a generalized contextu~ grammar.
It / L 13 follows that L is not a generalized contextual language, It is to be expected ~hat every generalized contextual language is a contex~-s~itive language.
But the construction of the corresponding context-sensitive grammar seems to be very complicated, if we thin~ to the generation of the language ~u.A.~reider has introduced a new type of grammars, called gralamatlkl) and defined i~ neighborhood ~ira~.L~ars (okrestnostnye ' the following way (\[4o); see ~4\].
Our presentation is some what different).
Given a finite set V called vocabulary, two strings x and y on V, and a context <u,v> on V, We say that the pair ~u.v>,y) is a neighborhood of y with respect to x if we can find two strings z and w, such that x=zu~vw.
Every pair of the i or~ ~<u,v>, ~\], where ~u,v> is a context on ~, Whereas y is a string on V, is called a neighborhood on V.
Let us consider an element e which does not belong to V ; G will be called the bo~3dary element.
A neighborhood grammar is a triple of the form ~ V, e,~, where V is a vocabulary, is the boundary element and ~is a finite set of neighborhoods on the vocabulary VU(e} . Let L be a l~aguage on V.
2e say that L is generated by the considered neighborhood grammar if ~i every string x of the form x =~ye (with ymL).and only in such strings there ~ists in ~, far every tera a i of X=~la2...a s, a neighborhood of a i with respect to x.
Neighborhood gray, mrs are closely related to the notion of context, since this notion occurs in the definition of a neighborhood.
There is another notion, due to Ja.p.L.Vasilevski~ and 14 ~.V.Ghom~ak6v (see ~he refermnce in~2\],p,~o), which e~lains this fact.
Following these authors, a grammar of contexts (this name is imp_roper, since no context occurs among its objects) is a triple <V, e,9>, where .V and @ have the s-me meaning as in the definition of a neighborhood grammar, whereas Q is a finite set of strings on the vocabulary Vt3e~  This grammar generates the language _L on V in the following way : x6 if and only if for every string y and a~y strings z and w for which there exist strings u and v such that @ x@ = = uzyuv we have either l) y = rasp, where sE Q, whereas the strings m and p may be eventually or 2) (~x@ = urynt, where qr = z, n t = w mad ryn is a string belong~g to Q.
A string belonging to Q is said to be closed from t~ le~ (from the right) if its first (last) term is @ . A string belonging to Q is said to be ~ if it is closed bosh from the left and f~m the right.
A grammar of contexts is said ~o be k-bounded if every non-closed string of _~ is of length _k, whereas every Clesed string of ~ is of length not greater than _kj An important theorem of Bor~ev asserts the equivalance between languages generated by neighborhood grammars and languages generated by k-bounded grammars of con~s (~3,p.4o).
Since grammars of contexts and contextual grammars have some similarities in their definitions, it is Interesting to establish more ~xac~ly the relation b~een them.
v 15 Proposition 14.
There exists a contextual language ~hioh is regular, but which is not a neighborhood language.
Proof. Let us consider the language L = ~a~n~ (n=l,2,...).
This language is regular, since it is generated by the regular grammar consisting in the rules S ~ ~a, T--->Ua, U--->Ta, --->a, where ~ is the start symbol, La~ is the terminal vocabulary, whereas {S,T,U} is the non-terlainal vocabulary.
Let us consider the contextual gramnu~r G =~ {a},{CO}, {~a,a>~.
I@ is easy to see that G generates the language ~ $ therefore L is a contextual language.
We shall show that L is not a neighborhood language.
In this respect, our method will be the following.
We shall consider all systems of possible neighborhoods of the terms of ~he string 0aae and we shall show t~}at every such sysbem is either a system of aeighborhoods of the ~erms of every string Cane (n= = 2,3,4,)... or it is not a system of nei@\]borhoods of the terms 0t the string ea@e . It is easy to see that the first ~erm of the string @aa@ admits ~he following neighborhoods : 1)e, 2) Ca, 3) @aa, ~) eaa~ . The second term has the neighborhooas : l) G_a,~)-a~) aa, 4) ~e ., 5) e_a_a, 6) e_~ae.
The neighborhoods of the third term are : i) e@a, . 2) aa, ~) a, ~) _ae, 5) eaa8, 6)_aaE) . The lass term has the neighborhoods 1) 8, 2) _a~_, 3) a a@_, 4) @aa~ . The noration _u_xv.
represents hier the neighborh~d {<u,v>,x} . It is easy to see that the fourth neighborhood of the firs~ and of the lass term c~t b'e a neighborhood of e with respect @o @g48 . On She other hand, a is a neighborhood of .aa with respect to ea~@ for every n = 1,2, ....
It follows that no 16 neighborhood grammar of L = ~a2ZX 3 may contain one of She neigh.
borhoods _0a2@, Q a2~ and a.
Thus, if a neighborhood grammar of \]~ exists, it contains at leas~ one neighborhood from every group of the following four groups of neighborhoods : ~) _0, _~a, _ea 2 . ~) e_a, _aa, _aae, G~a, ~.aaO.
b') 6~-~, aa, ..aO, ea_a~, agO.
We shall consider all possible combinations betweau a neighborhood of the group ~ and a neighborhood of the group E . By mn we shall denote the combination formed by the m.th neighborhood of ~ and the n-th neighborhood of ~ . It is easy to see Chat every neighborhood grammar containing one of the combinations 12, 22, 23, 25, 42 generates a language whioh eontain~ every string a n with n $ 2.
On the other hand~ every neighborhood grammar containing one of the combinations ll, 13, 14, 15, 21, 24, 31, 32, 33, ~, 35, 41, 43, 44, 45, 51, 52, 53, 5~, 55 generates a language which either does not contain the string a 4 or contains every string a n with n~ 2  (This depends on the fact if the neighborhoods aa or aa belong or not to the considered neighborhood grammar).
Thus, there exists no neighborhood grammar which generates the language ~2n 3.
But the definition of (generalized) contextual grammars, though adequate to the investigation of the generative power of purely contextual operations, does not correspond to ~he situation existing in real (natural or artificial) l~guages, where every string is admired only by some contexts and every o~u~ / 17admits only some strings.
Let us try to obtain a type of grammar corresponding to this more complex situation.
We define a con___y textual grammar with choice as a system G_ =<V,L,~,~o>, where V, L1 and~are the objects of a contextual grammar, whereas is a mappi~ defined on the universal language on V and havi~ the values in the set of subsets of~.
We define the language generated by G as the smallest language L having the follow1  ~ L l x ~ L 2  ing properties : If x, ! If ye L, <u,y>6 ~(y) and Z&~l, then u~L, z v~L and ~L.
Thus, every strin~ chooses some contexts and every context chooses some strings.
We define a contextual language with choice a language which is generated by a contextual grammar wit~oioe.
The investigation of these grammars and languages would better show the generative power of contextual operations, in a manner which corresponds to the situation existing in real languages.
--~$ References i.
Y.BAR-HILLEL, ~I.PEEL~, E.SHA~R : On formal properties of simole phrase structure grammars.
Zei~schrift fur Phonetik, Sorachwissensc~aft und ~ommunikatio~forechung,vol.14,1961, p.145-172. 2.
V.B.BOP~EV : O krestnostn~e gram~atiki.
Nau~o-Techni~eskaja Informacija, Serija 2, 1967, ~o.ll, p.39-41. 3.
N.GHO~SKY : Three models for the description of language.IRE Transactions on Information Theory, IT-2, 3,1956, p.ll~-12@. 4.
N.~{O~KY : Syntactic Structures ~ Gravenhage,1957.
5. H.CURRY : Some logical aspects of ~ra~matical structure, proeeedings of the Symposium in Applied ~athematics, vol.12, S~ructure of language and its mathematical aspects, Amer~ath.
~oc., 1961, p.56-68. 6.
S.GI~SBURG : The mathe~atical ~heo~f context-free languages.
~cGraw-Hill Book Company, New York, 1966.
7. J~XA : On a classification of context-fre~lauguages.
Kybernetika, vol.3, me.l, 1967, p.22-29. 8.
S.~CUS : Gramatici ~i automate finite.
Editura Academiei R.P.R., Bucure~ti,196@.
9. S.~AR~JS : Su~_ les grammaires & un hombre d' ~tats fini.
Ca. hiers de lin~uistique th@orique et appliqu~%vole~,196~,p,~W~-~&@.
io, Ju,A.~REIDER : 0krestnos~naja model jazyka, Tru~ 8impoziuma pO primenenijam poro~.daju~ioh grammatik, Tar~u,septjabr~1967.
ii. Ju.A.~REIDER : Topologi~eskie mod~ll dazvka.
Vsesojuzz~yi stitu$ nau~noi i techni~eskoi informacii, ~oscou,1968 .,., , SERGE BOISVERT ANDI~ DUGAS DENISE BI'LANGER OBLING: A TESTER.
FOIL TR`ANSFORMATIONAL' GKAMMAKS ~.
INTRODUCTION Transformational grammars have developed with recent research in linguistics.
They appear to be a powerful and explicit device for characterizing the description of sentences; they also meet conditions of adequacy that can be applied to check that a sentence, or a set of rules, is well-formed.
A transformational grammar tester is part of a strategy for the selection of a well-formed grammar matching the data base.
To put it more explicitly, a tester of this sort should provide the linguist a class of the possible grammars which concerns precisely the linguistic theory.
These grammars have the form given by CUOMSKY in Aspects (see bibliograIShy).
2. GENERAL DESCRIPTION OF THE SYSTEM O~UNO is a .program for dealing with the structures of the French language: it performs the verification of phrase structure rules, the derivation of sentences according to the transformational component and the graphic illustration of the intermediate or final structures.
In the program, UNG is the routine that controls all the subroutines and the matching of the input structures with those allowed by the phrase structure rules.
If the matching is impossible, a comment is Acknowledgments.
This work was supported in part by Canada Council of Arts grants @69-0404 and @71-0819.
We are also indebted to the staff of the Computer Center of the Universit4 du Qu4bec ~ Montr4al for providing computing facilities, and giving this project high priority.
David Sankoff, of the Universit4 de Montr6al, is also responsible for the first version of the tree editing program, l~inaUy, Jossdyne G4rard helped debugging linguistic rules.
122 SERGE BOISVERTANDIL~ DUGASDENISE BI~,/ANGER ieeIIIItiIeletlIillllllelIlIlIllll~ : o :.
-*:: Iieeee~ ...........................~> ...........................9= ~z *,0,~o : .....
~Z ...................
~g o D~O o aO OUd 3N1 z o..~ ~ 3z O.
~ Z o k9 bO.
~3J ATd o:r =:~ o 0~3 qD_~  :: u.
0. tk NNN IOH U~ ~ Uj~ (~ ~ZD~-Z NUd ~dO NWZDU~ Fig.
1. Tree for an input sentence OBLING: A TESTER FOR TRANSFORMATIONAL GRAMMARS 123 made.
Otherwise, the output gives the graphic illustration of the tree for this sentence, or the input structures are immediately processed using transformational rules.
For example, General transformational rules are operated by a number of subroutines of which the main are explained hereafter.
3. GENERAL CAPACITIES OF THE SYSTEM The system OBLING is divided into four parts: a main program LING, the service subroutines, the phrase structure grammar tester and the transformational grammar testers.
LING and the service subroutines are stored in the central memory while the two grammars testers operate on disks.
The main program invokes the various linguistic rules and controls the application of these rules to the data base structure(s) or the derived structure(s).
The service subroutines are called by the routines concerning the application of the transformational rules and work in parallel with LING during the processing.
Phrase structure grammar tester " LING Service I Subroutines (processing memories) 4--1~ ' grammar testers Fig.
2. The OBLING system 4.
SPECIFIC CAPABILITIES OF THE PROGRAM LING The program LING will first initialize the working areas.
Then, it loads and operates the program V~rlCATEU~ which, after the reading and the verification of the input data, returns control to LINe.
124 SERGE BOISVERTANDI~ DUGASDENISE BELANGER ZING will then load and execute, using an overlay technique, the small control programs cYcH Q1, CYCLI Q2 ....., cYcLI Qi.
Each of these handles, in conjunction with HNG, the mapping on the input structure of a fixed number of transformation rules.
In the current version of the program, cYctI Q1 deals with the linguistic transformational rules T1 to Ts included, cYcrI Q2 the rules To to T10 included, etc.
The total number of these control programs cYcrI Q depends on the memory space allowed; processing is most efficient if the number of these control programs is as small as possible.
5. INFORMATION PATTERN BETWEEN LING AND VERIFICATEUR When VERI~CATEUR (the phrase structure grammar tester) is in memory, the structure to be analysed is read from the standard input unit (punched cards) and is processed by the subroutine Cr~RB~ to LING v V~ICATBD~ c'zcLi qO  T CKARBRE ARBRE verification printing of syntagmatic of the tree rules Fig.
3. The Vm~L~CAWSUa program (see figure 1 for updated tree and structure) OBLING: A TESTER FOR TRANSFORMATIONAL GRAMMARS 125 be validated.
This subroutine first checks if the phrase structure is consistent, then calls up eke which tests the names of the constituents describing the structure; finally, it compares this structure with those allowed by the phrase structure rules.
When errors are discovered during the processing, various sorts of comments are printed and followed if possible by a partial or full tree of the sentence.
When updating is done, the tree is printed and the program VERrFACATEUR passes control to LING.
The following illustrations concern first, the program VERIHCATEUR and second, an example of an updated tree and structure.
6. INFORMATION PATTERN BETWEEN LING AND THE TRANSFORMATIONAL GRAMMAR TESTERS Each time LING receives the control from VERIFICATEUR, that is, when no further errors have been detected, it loops in order to call successively the monitors CYCLI ql ....., CYCLI Q9 which contain up 45 different rules; we suppose that we are working now with a specific version of a grammar.
The first of these monitors has the following structure.
Transformational rule # 1 Transformational rule # 2 Transformational rule # 3 Transformational rule # 4 Transformational rule # 5 Fig.
4. The cYcLI Q1 program When CYCLI Q1 gets control, it is botmd to the application of 7'1,  .., Ts which correspond to the first five transformational rules; then control is switched to LING which calls cYCLI Q2.
The programs CYCLI qn process cyclic rules and the output structure is the input structure for the following rule.
When all the cyclic rules have been applied to the input structure, LING starts over again at CYCLI Q1.
If no modifications 126 SERGE BOISVERTANDR~ DUGASDENISE BI~LANGER to the already processed structures occur, or if new errors are discovered, control returns to LING.
After all the cyclic rules have been applied, the post-cyclic rules are processed in a similar manner: cYcu qA comprises the first five post-cyclic rules CYCLI Q~, the five following, and so on.
This chart illustrates the general interaction between the programs for the processing of cyclic or post-cyclic rules.
I_ cYcI.t Q1 cYcu Q2 CYCI, I Q9 CYCLI QA I CYCLI QB cYC~i Qi I End Fig.
5. Flow of Control between control programs under the direction of LInG 7.
SERVICE SUBROUTINES They are implemented within the main monitor ZING.
All but a few of these subroutines are called during the execution of the routines corresponding to the 88 rules, that is during the phrase structure analysis or the mapping of n structures.
A short description of the main subroutines follows: ^R~ (tree).
This subroutine is responsible for printing the tree.
At the input, we find a vector D of ND elements which represents the tree.
The horizontal distance for printing is calculated along with the total number and the relative position of these nodes; the vertical one is fixed.
OBLING: A TESTER FOR TRANSFORMATIONAL GRAMMARS For example, fACHE~ 2 # NOMRRE DE NOEUDS NOMBRE DE NOEUDS CHA/NE 1 = $ O(.
I) 2 = LE D( 21 3 = N D(3) 4 = V O( ~) 5 = $ D( 5\] 6 = $ D( 6) 7 = PRP D( 7) 8 = OIJE O( 8) g : LE O( 91 I0 = N D(IO) 11 = V O(ll 12 = $ D(12) 13 : DET D(13) 14 : DET 0(14) 15 : GN D(iS) 16 = GV D(16) 17 = C D(17) 18 = GN O(18) 19 = GV D(lg) ~0 = P O(~O) ~I = P D(21 21 TERMINAUX = 2'0 = 13 = 15 = 16 = 20 = 21 = 17 = 17 = 16 = 18 ) = Ig = 21 = 15 = 18 = 20 = 20 = 21 = 21 = -I ) = -I 12 ARBQRESCENCE NON PRODUITE SUR DEMANDE : AUCU~E REGLES IGNORFES SUR DENANDE t AIJCUNES Fig.
6a. Representation of the tree in memory 127 FIW~ f~ 7.1.
OT~ (Remove).
This subroutine is needed when nodes are erased; another subroutine, NEWTgF_~ will erase the nodes.
In the example below, oxv sets D(6), D(7), 9(13) to zero, and NEWTREE erases nodes numbered 6, 7 and 13.
If node 12 was also erased, OT~ and NEWT~E would have erased node 28 automatically.
The same holds for the node 32, where all the nodes between 6 and 13 would have been erased.
7.2. DFER, DFERX, GFER, GFERX.
Except for a few details, these four subroutines do the same work.
For example, Dr~RX \[I, J\] is applied to a structure J that has to be moved to the right under a dominating node L As illustrated below, Dr~Rx \[31, 30\] moves the structure headed by 30 to the right under the node 128 SERGE BOISVERTANDRE DUGASDENISE B~LANGER ....................~.
0":> ~ IJ-: .....
~g ............. 9~ : : ............
~ m : .....
~g ............
~ ~ ........... ..~z ~ : .....
~ ~w ....................~.
~Z~ ZU wz mz~wz ~ ~z~z m Fig.
6b. Corresponding printed tree OBLING: A TESTER FOR TRANSFORMATIONAL GRAMMARS 129 .......,.......,..,.....~........,.....~.~,     ,cu~ W~ud ~ : ".
...........o...............~ ....................~.
=> .~> g~ .............~z ~z ow .....
'.~ : ~J ......
~ : .....
~ ............. 9~  o ....~......,..................,...~> Fig.
7a. Sample tree before OTE and NEwra~ apply ~z~wz ~z~wz wz wz~o ~ w O~d 3NI II O~Do H~N ~ZD~ ION N~d dOD HN  NH" JI  + o=~Do 06d II ~NN ' I0~ O~DO 3~d dO0 ~AV ~I" ~ ~zz~ dN" c~o 130 SERGE BOISVERTANDP~ DUGASDENISE BELANGER,........,......,.......,................~, 8~ U oo.o o~ .oo*o--~ : ............
~ ...........................~ elost$ eset0 t eQ o o  " "  " o   o   "Z      oJo :     oz      .~ : ..... h~o :e ...... go ............
~ o . ~  --~ o.,' .......
., ...........  ....
.> m .....
0 ....  ........,..*0o2 ~z **.~,..,oo, o,,o-,o,~o.,,..,....o....,.oo.,~ ~ q~L0 tn>uz NgCW {gh.w DX~ 02 ~uu 08d JNr a.=~..=oc :~ o=II cz Frld 0~3 u~ .J m snN ION ado 0.
~--u o.
3Z :~d03 ~ 0.
N, u~-,x~..~h.Z NO" ~cxo..~ -~wl     oliN"  ~NI cc~ x'W-Jcc II Bo.
o_ ngd ~D~>O_:E0C GND r-o.J ~ :g uJ o_ HnN : o.
i.-.~ ~ u.
x: |ON H~d,o 3~d ~dO :g :~ ~ 0 dO3  ~ uJ .J~c EZZo.
~zzo--I + O~D W W Z D bJ .J O: _J,Xb.C~O.
Fig. 7b.
Sample tree where oT\]~ and N~WTREB have applied OBLING: A TESTER FOR TRANSFORMATIONAL GRAMMARS 131 31.
(Node 31 was created by rule T2 and DF~R was applied on the resuiting tree) \[I,/\] DFERX \[;r, j\] GF R \[1, J\] G RX \[I, j\] makes node J the next younger brother of node I makes node J the youngest son of node I makes node J the next older brother of node I makes node J the oldest son in node I The general technique for these four subroutines is the following.
Before modification, the tree is copied in another area of memory.
All the terminal nodes identified with the structure J take the place of the terminal nodes identified with the structure L Then, the terminal nodes of I are requested in the copied structure and parsed with their dominating nonterminal nodes at the right place.
Gr~R,permits the new numbering of the sequence and, if necessary, prunes the tree.
In the example illustrated below (Fig.
9a and 9b), Gr~R \[14, 13\] is applied and node CPL (13) has been attached to node 16, the father of node 14.
If GF~RX \[14, 13\] had been specified, node CPL would have been attached directly to node 14, rather than the father of node 14.
7.3. INTERV, This subroutine is used for the permutation of 2 structures.
For example, INT~RV.
\[I, J\] where I = 24 andJ = 28 gives rise to the structural change illustrated below.
7.4. INSERT.
This subroutine is used for the insertion of a new terminal node; for example, INSERT \[4, 1HE, 1HT, 1HR, 9\] introduces node with name ETR which becomes a new son of node 9.
7.5. Other subroutines.
There is a number of other subroutines concerning conditions specified within a rule, such as the presence or absence of a node or of a feature in the whole structure, the logical restrictions of loose equality or strict equality.
132 SERGE BOISVERTANDR~ DUGASDENISE B\]~LAlqGER ..................................S.
.o*~*~oi~*~*~Z ,~,..~~ ~W ~,*...**~  ~W :~.**~ ..................................~.
..................................~ .-~z : ...................
~.~ oi ............ ....~.,.,.,..~.........>   .  ......
                * .z ......
~_~ ~ : ~>~ ~Z~W 0~td O~ ~ g ~ 3NI II 177d N~N IOH H~d =l~d ~ldO  ~wz~w~ o .-INI  o0N33 flTd IOH un bJ z ~ h2 .-J ~ N~d ~o.o_ Od0 4" c3~ a~ zza-~x :~zo~co dO3 ~..~-a:Q.~ .-e~   j   ...aAV m~w~2w OFig.
8a. Sample tree before GFER applied OBLING~ A TESTER FOR TRANSFORMATIONAL GRAMMARS .........................................~.
d8 ......
~ *~ ...... g~> ............
"~> : .............
~z ......
~g  :.,.,.~..,. o,~ .~ : --z      m(  o      ~o ; .,-w .     . ,   .   ,.j ....................~,~: .~ ............
~.~ ......................0...........~.
.,..,,~.,~,,,,~,~,..,,,~...,..~ ......
~g ~  ,~ 0 , ., , .,., m m ,,,,,,,,,,,,,~ 133 =>~ ~z ~z~z ~z~z~o rOBd  4NI,o II H3.-I + HAN oz~o lOW 3~d ~ 0.
o o.
(~ < P..~ o(J =0 z dOO . ~IAV 30" eU NO" HN ~ * 3NI o~x~o II 0~ Ld z ~ W,J ~' .J  :~ h.
(l. ~ 1~3_4 fVld ~AN ION O~Z~O H~d hJ Z ~ ~J.Ja: ~"~  ~ h.
a.o. 3~d ~dO dO3,O ~AV 30"+ o~-~o NO'* .-I  ~ u.
0. 0.
HN" NH" Fig.
8b. Sample tree where Grsa has applied 134 SERGE BOISVERTANDRI~ DUGASDENISE B~LANGER .....................,,......,..........9~ :...................9~  ~ ~ m ~Z o O~ld JNI II nqd c k~RN e... ozc,~,~.~ zw~g 3aa ~dO 0=~ dO3 . ~ t,.
cL cL ~AV 30" Q.
t-.(.,.~ O.
~2 --)-Z NO" O.
C30. J ~ v.J 0 J ~ ~ HN* NH" ~O_ N  U..~ .:~oAI" e3 oz~ ha~ zh4 ha Fig.
9a. Input structure OBLING: A TESTER FOR TRANSFORMATIONAL GRAMMARS 135 ~i.
i le~eee ee$ lse eee eeeee~ e,e,eee,ee,,,~,,,le,e,~Z ~z ...........-.~z II  -g .......
~ ~ ......
~ , ~ ,1 ,, ,..
 ~ ~, , .,   ,.
1~ ozJ~z 2 08d II ~z~ W33 ~z~wz ~Id WnN 8~d 3~d HdO dO3~AV 30  NO" Fig.
9b. Output structure after cFm~ has applied 136 SERGE BOISVERTANDI~ DUGASDENISE BIILANGER ...................,.....................~, Ii J .~ : ....
~ ....... o~  ~~ ...........
~ ~ : ......
~  ~: .....
~ : .~ ~  ...
.,~.0,~... mz ~,~,,,,,,',,~,~,.,,,,,,,.~ Fig.
lOa. Input structure O~d 4N\] TT nqd HnN zoH HHd * dOC) 0~:~0 ~IAV NO" _~I.
'-)~_ N  b.~o:~ no" O~d JNI II N3J Flqd HnN IOH ~d 3~d ~dO OBLING: A TESTER POR TRANSFORMATIONAL GRAMMARS @ @ i@ Ii @@I@ @@@ @Ii@ I@ i oII iI @ iI i@I @Ii@ kU II~leo~$e~Ioo$oi@$~ ...... g ............. o,.~ ......
~g .....
~ ............
R~ ~d I M! ~ed .,,....,.,,..,,,~z o~ ...~..No .,.,~.,.....,......,,.
..................................~>,~..,,.~z . "-~ "''   "  "''''  "" "" " "" "  ''~ .....,..,,..,...........,...,.-,, .... ..~ 137 ~ ~z~o  m2~Nz m + O~DO  m oz~w zww~ 08d ..4NI II F mqd 083 k(nN IOn k4~d 38d 8dO dO:) SAY 30" NO" 8N  NH" 4IFIO" dN" 08d 3NI II H3../ f)ld 083 HNN ION HSd 38,:t tldO dO3 dAY :)0"4.
NO., NN" NH" AI" NO-~dN" Fig.
lob. Output structure after ~r~v has applied 138 SERGE BOISVERT ANDl~ DUGAS DENISE B\]~LANGER :...................~ u_ ,,*,0,,o$1,$1,,, ............~z >.
m ~Z .,-,,, : ~ "...  . . .............~, + oxx~O D.
Fig. 11a.
Insertion of a node (before) OBLING" A TESTER FOR TRANSFORMATIONAL GRAMMARS 139 .   . . ..
 ,,.........~.,,,,......,.....~.=.
***eeeoeo$ooe~ o e~ x tn mo~ o~ ~Z~WZ ~S~W m   Fig.
1lb. Insertion of a node (after) 140 SERGE BOISVERTANDRI~ DUGASDENISE BELANGER 8.
CONCLUSIONS OBJ-mC is a system which has been implemented in low-level tORTeN IV for the CDC 6400.
It occupies 55,000s 60-bit words of memory.
It has about 7000 lines of comments and instructions.
REFERENCES N.
CHOMSKY, Aspects of the Theory of syntax, Cambridge (Mass.), 1965.
A. Ducas, et al., Description syntaxique ~l/mentaire du franfais inspir~ des th/ories transformationnelles, Montr6al, 1969.
J. FIUEDM~, A Computer Model of Transformational Grammar, New York, 1971.
D. LIEBERMAN, (ed), Specification and Utilization of a Transformational Grammar, Yorktown Heights (N.Y.), 1966.
D. L.
LotrD~, W.
J. SCHO~N~, TOT: A Transformational Grammar Tester, in Proc.
Spring Joint Computer Conference, Part I, 1968, pp.
385-393. R.
PETRICK, A Recognition Procedure for Transformational Grammars, Ph.-D.
Dissertation, Cambridge (Mass.), 1965.
J. R.
Ross, A proposed rule of tree-pruning, NSF-17, Computation Laboratory, Harvard University, IV (1966), pp.
1-18. A.
M. 7.WICKY, J.
FRIEDMAN, \]3.
HALL, D.
E. W.~a.g.F.R, The MrrRE Syntactic Analysis Procedure for Transformational Grammars, in Proc.
Fall Joint Computer Conference, Vol.
27, Pt.
1, 1965, pp. 317-326 .
S$ I:Mct ur a 1 Cor r e AponfJet\]Ge S~ec \[ f I c_a t j O0_#DvLEonmer~ Yongfeng YAN Groupe d'Etudes pour la TradlJctlon Automatlque (GETA) B.P. 68 Unlverslty of Grenoble 38402 Saint Martln d'H~res FRANCE ABSTRACT This article presents tile Structural Correspondence Speclflcatlon Environment (S('SE) being Implemented at GETA The SCSE is designed to help linguists to develop, consult and verify the SCS Gr'alt~nar s (SCSG) which specify I lngulst ic models.
It Integrates the t eclln 1 clues of' data bases, structured edltors and language interpreters.
We argue that formalisms and tools of specification are as Important as the specification itself.
z NT ROD_UCT tqN For quite some time, It has been recognized that tile specification Is very important in tile development of large computer systems as well as the linguistic computer systenls.
But it ls very difficult to make good use of specification without a well defined formalism and convenient tool.
The Structural Correspondence Specification Gran~ar (SCSG) is a powerful linguist ic specification Formalism.
the SCSGs were ftrst studied in S.Chappuy's thesis (1}, under the supervision of Professor B.
VaLIqUOt s.
In their paper presented at Colgate University in 1985 {6} SCSG was called Static Greener, as opposed to dynamic grammars which are executable programs, because the 8CSG aims at specifying WI4AT the linguistic models are rather than IIOW they are calculated, A SCSG describes a llnqulstlc medel by specifying the correspondence between the valid surface strings of words and the multi=level structures or a language.
Thus, from a SCSG, one can obtain at the same tlme valid str lngs, valid structures and the relat ton between them.
A SCSG can be used for the synthesis of' dynamic gralr~}lars (analyser and generator) and as a reference for large linguistic systems.
An SOS Language (SCSL) has been designed at GETA, tn whlcll the SCSG can be \]lnearly written.
The SCS Environment (SCSE) presented here ts a compLIter aided SCSG des lgn system.
I t wl 1 1 al low lhlgulsts to create, modify, consult and verify their granlnars in a convenient way and therefore to augment their productivity.
Sect 1on I gives a outline of the system: Its architecture, pr Inciple, data structure and comdnand syntax.
Section II describes the malrl functions of the system.
We conclude by gtvtng a perspective for luther developments el' the system.
I=.AN OVERVIEW OF TI4E S YSTE_M 1.
ARC HI\]EC T URE The SCSE can be logically divided tn five parts: 1 SCSG base 2.
monitor 3.
input 4.
output 5.
procedures The SCSG base consists of a set of files Contalnlng tile grarrlnars, lhe base has a hlerarchtca\] structure.
A tree form directory describes tile relationship between the data of the base.
The monitor Is the interface between the system and the user.
It reads and analyses colTinands from the input and then calls the procedures to execute the cormlands.
1he input is the support containing the COlrrnands to be executed and the data to update the base.
rhere is a standard input (usually the keyboard) from which the data and cormlands sllould be read unless an Input ls explicitly specified by a conlnand.
The output is a supper t receiving the system's dialogue messages and execution results.
There is a standard output (usual ly the screen) to which tile message and results should be sent unless all output Is explicitly specified by a con~and.
The procedures are the most irnportant part of tl~e systenl.
It ls the execution of procedures that carries out a COn~land.
The procedures can communicate directly wtth the user and with other procedures.
2. THE_E.RJNCU}LE An SCSE session begins by loading the original SCSG base or the one saved from the last Session, Then the monitor reads lines from tile com~nand input and calls the corresponding procedures to execute the COmd~lands found.
When an SCSE session Is ended by the colm~and "QUIT", the current state of tlqe base Is saved.
The SCSG base can only be updated by the execution of c omrlland s, The original SCSG base contains two SCSGs : one describes the syntax of the SCSI_ and the other gives the correspondence between the directory's nodes and the syntactic units of the SCSL.
The first gralmlar ls read-only but the second one can be modified by a user.
This allows a user to have his prefered logical view over the base's physical data.
These two grammars serve also as all Oil-line reference of the system.
Several Interactive levels can be chosen by the user or by the system according to the number of errors in the con~aapd lines.
The system sends a prc~npt message only when a "RETURN" ls met in the CO~nand lines.
So gee carl avoid prompt messages by entering several cen~nands at a time.
;3. DATA S:\[f~UCTURE There are two data structure levels.
The lower one Is linear, supported by the host system.
Tile base Is a set of files containing a llst of strings of characters.
Tile base carl be seen as a single string of characters thai: Is the concatenation of all lines tn the ft\]es of the Llase so that tile structure is said to be llnear.
TIlls structure is the physical structure.
The higher one Is hierarchical, defined by the directory of the base.
Tile base is composed of a number of SCSGs ; each gral~ar contains a declaration sect Ion, a rule (chart) sect Ion...
etc. and the components of a gran~nar (declarat 1Ol1, rules . . . etc, ) have their own structure.
The hierarchical structure ts the logical structure of the base.
The directory has a tree form.
A node In the tree represents a logical data unit that ts its content (for instance a gran~nar).
Every node has a type and a list of attributes characterlslng the node's content, rhe lnternode's content is the composition of those of its descendents, \]he lear's content Is directly associated 81 with a physical data unit (a string o1' characters).
The following figure shows the relation between the two structures.
LOGICAL STRUCTURE (i) 7, 2Y LOGICAL S'\[RUCTURE (2) language date \[Grammar English -----i node type attributes The directory is slmllar to a UNIX directory.
But In our directory, tile leaves do not correspond to Flies but to loglcal data units and Furthermore an attribute list is attached to each node.
The correspondence between two structures is maintained by SCSE.
We shall see later that this organlsatlon allows a more efficient Information retrieval.
It ls possible For" users to have access to the data by means of both structures.
The logical one Is more convenient but the physical one may be more efficient in some cases.
4:~ _COMMANp__SyNTAX The general command format is : <operator> <operand> <options> The "operator" is a word or an abbreviation recalling the operation of tile colmland.
The "operand" is a pattern giving the range OF the operation.
The "options" is a list of optlonal parameters of the COw,land.
For example, the Con~nand : V GRAMMAR ( LANGUAGE = ENGLISH ) visualizes, at the standard output, all the English grammars In the base.
Here V is the operator, GRAMMAR(LANGUAGE=ENGLISti) ls tile operand pattern and no option Is given.
The operand being mostly a node in the directory tree, the pattern is USUally a tree pattern.
When the pattern matches a subtree of the directory, the part that matches a specially marked node Is the effective operand.
The pattern is expressed by a geometric structure and a constraint condition.
The structure ts a tree written in parenthesized form perhaps containing variables eacll representing a tree or a forest.
The coeditlon Is a first order logic predicate In terms of the attributes of the nodes occurring in the geometric structure.
More sophisticated conditions may be expressed by a predicate combined with geometric structure to efficiently select information from the base.
Pattern writing should be reduced to a minimum.
In the abeve example, the geometric structure is shnply a grammar type node and the constraint is the node's language attribote having the value= Erlgllsl\].
The use of a current node tn the directory allows not only the simplification of pattern writing but also the reduction of the pattern matching range.
The effective operand becomes the new current node after the execution of a command.
II. THE MAIN FUNCTIONS We shall Just descrlbe the functions ttiat seem essential, lhe functions may be divided Into four groups= 1.
general 2.
SCSG base updating 3.
SCSG base inquiry 4.
SCSG verification.
_1 ~ _GI~ t>\[E__R A L _F U_N__C__T._I.D_N S These functions Include: SCSE session options setting, the system's miscellaneous lnformatlon inquiry and access to host system's commands.
The following options can'be set by user co,hands: 1.
tnteractivtty 2.
dlalogue language 3.
auto--verlfilcatlon 4.
session trace 5.
standard Input/output.
One of the 4 Following Interactive modes may be chosen: 1.
non-interactive 2.
brief 3.
detalled 4.
system controled.
In non-interactive mode, no question is asked by tile system.
An error con~and Is ignored and a message will be sent but the process continues.
In brief mode, the current accesslble command names are displayed when a corm, and Is completed and a RETURN in the command lines is Found.
In detailed mode, the functton and parameters of the accessible commands are displayed and 1F an error ts Found in the user's Input data, the system will diagnose it and help him to complete the command.
A prompt message ls sent every time RETURN is Found in the COn~nand lines.
In the system controlled mode, the lnteractlvlty Is dynamically chosen by tile system according to the system=user dialogue.
For the tlme being, only French is used as the dialogue language.
But the mu.ltl-langueage dialogue is taken tnto account tn design.
It is simpler In PROLOG to add a new dialogue language.
The auto-verification option Indicates whether the static coherence (see 4.
SCSG verification) of a gra~nar will be verified each time it ls modified.
The trace option is a switch that turns on or off the trace of the session.
The standard Input/output option changes the standard input/output.
Some Inquiries about the system's general Information, such as the current options and directory content, are also ~ncluded in this group of Functions.
The access to host system's co~Ylands without leaving SCSE can augment the efficiency.
But any object modlfted out of SCSE is consided no more coherent.
2. SCSG BASE UPDATING This group of fiuectlons are: CREATE, COPY, CHANGE, LOCATE, DESTROY and MODIFY.
\]hey may be found In all the classic editors or file management systems.
The advantage of our system is that the operand of commands can be specified according to the logical structure of the base.
For example, the col~nand : DESTROY CI4ARTS(TYPE=NP) Destroys all the charts which describe a Noun Phrase.
82 The SCSE has a syntaci Ic editor that knows the logical structure of the texts being edited.
Ihls editor Is used by tile con'Jnands MODIF and CREATE.
The command CREA1 <operand> <options> calls the edltor, creating a logical data unit specified by tile operaod.
If the interactive option ts demanded, the editor will guide the user to write correct ly according to the nature of the data.
Following the same tdea of different interact lye levels, we try to improve on tile classical structural editor, Per instance that of Cornell University \]\[5}, so that one carl enter a piece of text longer than that prompted by the system.
If the interactive option Is not demanded, one Just enters into the editor wlth an empty work space.
The CO~T~nand "MODIF <logical unit>" calls the system's edltor with the logical data untt as the workspace.
The data ill the workspace may be displayed In a legible form which reflects Its logical structure.
The mul t l-w \]ndows facll ity of the editor makes it possible to see simultaneously on tile screen the source text and tile text In structured form.
The SCSE editor inherits the usual editing con~llands from the host editor.
Thus one can change all the occurrences Of a rule's name fn a grarrnlar without cilanglng the strlngs containing the same characters, using a loglcal structure change : C NAME(type=rule) old name new _nan/e, while tile physlcal structure command : C/o 1 d..
name/new .name/* * changes all the strings "old_name" In the workspace by new name.
When an obJect's deflnltloo Is modified, all Its occurrences may need to be revised and vice versa even if the modification does not cause a syntactic error.
A structure location command flndlng the definition and all the occurrences of an object can be used In this case.
Only tile logical units defined in the directory and the SCSL syntax can be manipulated by the structural COrr~land s.
SCSGBA=SI~_INQUIRY These functions allow users to express what they are interested ill and to get the Inquiry results In a legible form.
A part of the on-llne manual of usage in the form of SCSG may also be consulted by them.
The operand patterns discussed above are used to select the relevant data.
The operator and options of co~nands choose the output device and corresponding parameters.
A parametered output form for each logical data unit has been defined.
The data matching the operand pattern are shaped according to their output form.
The data may of course be obtained in their source form.
One may wish to examine an object at different levels (e.g.
Just tile abstract or some comments).
The options of the con~and can specify this.
If one Just wants to change the current node in the directory for factlltatlng the following retrieval, the same locating co~nand as before may be used.
4. SCSG VERIEICAT#ONS.
Two klnds of verifications may be distinguished : static and dynamic.
Tile static verification checks whether a grammar or a part of a gra~nar respects the syntax and semantics of the formalism.
The dynamic verification tests whether a given gran'mnar specifies what we want It to.
S tatlc_ve, r Ifica~ton All internal representation of the analyzed text ts produced and used by the system for structural manipulation, the analyser may produce a list of cross references of = nameable objects and a list of syntaxo-semantlc errors found In the text.
The exemples of nameable objects are the charts, tile macros, the attributes.
The list of cross-references reveals the objects which are used but never defined or those defined but never used.
A chart may refer to other charts.
This reference relation can be represented by an oriented graph where the nodes stand for a set of charts.
A hlerarciltcal reference graph is often given before writing the charts.
A program can calculate the effective graph of a grammar according to the result o analysis and compare It with the given one.
The cornlland options may cancel the output of tllese two llsts and the graph calculat Ion.
The graph calculation may also be executed alone.
One of optlons Indicates whether the analysis wtll be Interactive.
D.y.n ~!# J c.
v. ~gr :1 f i canon Tile dynamic verification Is tile calculatlon of a subset of the st ring-tree relation defined by a gr altrnar.
A member of the relation is a pair <string,tree>.
Ti)e command gives the granYnar and the subset to be calculated.
The subset may be one of the four following forms : I.
a pair with a given string and a given tree (to see whether It belongs to the relation) 2.
pairs with a given string and an arbitrary tree 3.
pairs with an arbitrary string and a given tree 4.
all possible pairs rhe calculation is carried out by all interpreter.
The user may give interpretation parameters Indicating interactive and trace modes, slze o the subset to be calculated and other constraints such as a list of passive (or active) charts during this interpretation, the depth and width of trees and length of the string etc..
As SCSGs are statlc gral~nars, no heuristic strategy wllt be used In the lnterprete's algorithm.
So the interpretation will not be efficient.
Since the goal ts rather to test gramnars than to apply them on a real scale, the efficiency of the interpreter Is of no import ance.
CONCLUS I0N The system presented Is being implemented at GETA.
In thls article, we Put emphasis on the system's design principles and specification rather tilan on the detalis of lmplementatlon.
We have to1 lowed three widely recommended des ign principles: a} early focus on users and tasks, b) empirical measurement and c) Interactive design \]\[2\]\[.
The specification of the functions are checked by the system's future users before implementation.
The user's advice Is taken into account.
This dtalogue continues during lhe implementation.
The top-down and modular programming approaches are followed so ttlat, even 1f the Implementation ls not completly acilieved, the implemented part can still be used.
The system Is designed for being rapidly implemented and east ly modt f led thanks to Its modular lty and especially to a htgh level logic programming language: PROLOG (3\].
We have tried our best to make the system as user-fr lendly as possible.
The system's most remarkable character is that the users manage their data according to the loglcal structure adapted to tile human be I rig.
What ts interesting In our system ls not that it shows sonle very original ideas or the most recent techniques In state-of-the-art but tt shows that tile combination of well-known techniques used orignally In different fields may flnd its application in other fields.
83 Long term perspectives of the system are numerous.
Wlth the evaluation o the SCSG, some strategic and heuristic meta.-rules may be added to a grammar.
Equipped by an expert system of SCSG, SCSE could lnterprete effclently a static grammar and synthetlse from It efficacious dynamic grammars.
It Is also interesting to integrate into SCSE an expert system which could compare two SCSGs of two languages and produce a transfer grammar or' at least glve some advice for constructing it.
Using its logical structure manipulation mechanism, SCSE can be extended to deal with other types of structured texts.
Thanks to Its efficient Interpreter or in Cooperation with a powerful machine translation system such as ARIANE, SCSE could be capable of offering multi-llngual editing facilities (4~.
-O--O--O-O--O-O-O-O84 BIBLIOGRAPHY S.Chappuy, "Formallsatlon de la Description des Niveaux d'Intepretation des Langues Nature\]les.
Etude Men~e en Vue de l'Analyse et de la G6n@ratlon au Moyeo de Transducteur.", Th~se de trotsl~me cycle & I'USMG-INPG, Juillet 1983.
2. John G.
Gould and Clayton Lewis.
"Designing for Useabllity: Key Principles and What Designers Think", Co~nunIcatlon of the ACM, March 1985 Volume 28 N .
Ph. Donz, "PROLOGCRISS, une extention du langage PROLOG", CRISS, Unlverslte II de Grenoble, Verston 4.0, Juillet 1985.
HEIDORN G.E., JENSEN K., MILLER L.A., BYRD R.J.0 CHODOROW M.S., "The EPISTLE text-crltlauing system.", IBM Syst.
Journal, 21/3, 1982.
TEITELBAUM 1.
et al, "The Cornell Program Synthesizer: a syntax directed pr'ogra~ntng environments.
", Co~nunicatlon of ACM, 24(9), Sept.
1981. VAUOOIS & S.
CHAPPUY, "Static Gran~ars : a formalism for the descrlbtion of linguistic models", Proceedings of the conference on theoretical and methodological issues in machtne translation of natural language, Colgate University, Hamilton N.-Y., USA, August 14-16, 1985 .
CondiLioned UnificaLiou for Natural l,an~uage Processinp, A\]\]STV~ACT This paper prescnLs what wc c.all a condiLiol'md unification, a r'm'w meLhod of unificatiol'~ for processing natural languages.
The key idea is to annotate Lhe patterns wiLh a cerLcdn sort of conditions, so that they carry abundant inforrnation.
'\]'his met.bed t.ransmits inforrnaLion frorn one pattern to another more efl'icienLly Lhan proecdurc aLLachmenLs, in which information cortLaincd in the procedure is embcddcd in the progranl rather Lhan dirccl./y aLLachcd Lo paLL(ms Coupled wilt techniques in forrnal linguistics> i\]\]orcovcr, conditiorled unification serves most.
types o1" opcrations for natlu'ai \]ar/guage processil'q~,.
KSiti f/asida \]'\]\]ecLroLechllica\[ 1,abe ' A.ory Ul\]lczorlo I } 4, 7~aktlra MtlFa, Niibari-Gurl, Ibaraki, \[tOb Japan (\[3) ptlt_tllS psrl nrnb(prcsonL, P, N) : notAlrd ~'-tng(P, N) l~ut_Lns, psn nl:nl)(T, l", N) : not_pres(T) noL_3rd sng(lst.,,N).
not pres(past) not_~rd~'-;ng(;~nd, N) not pres(past4~a'rtlclp\]e ) rlotA/rd, sr~g(,'Wd, plural) not pres(basc).
1. Introduction A currcr'd, major t.rcrY.t of naturul la~/guage processing is ehara.cterized by Lhc overall use o\[ unification (Sttiebc~r (198'l), Kay (1985), Proudir:~ and Pollard (1,985), Percira (198b), Shicbcr (1985), etc) reflecLing lhe recent develop merits in nonLra.nsformaLJonal linguistic \[ormalisrns, such as Lexical FuncUonal Grammar (}lrcsnan (198E)), Generalizcd Phrase St.r'tJcl.ur( (\]rarnrnar (GPS(\]) (Gazdar, Klein, Pulhlm and Sag (I 985)), i Icad Grammar (Pol}ard (19f1,1)), and tIcadl)riven Phrase Structure Grammar (lIPS(;) (Pc\]lard (1985a.,b)). These formalisnls dispense wiLt,qlobal opcraLioits sueh as t.ransfornlaLion, alld instead cxp!oit h~cal operations each C'Ollf'lrled wttJ/i\[l a local tree Such local operations ar'c forunulatcd in Lcrms of uni~caLion \]Iowevcr, Lhe ordinary unification as in Prolog is insufficient, seeu rrorn both scientific (here, alias liriguJsl,ic) and cngin(.'ering poilfl'. of vicw '\['he F, robh-'trl is that p,t tc\]~\[\]s Lo bc tl\[li(ie({ wiL\]l each other lack the cape.city rot carrying irfforrnaLion In Lhis papcr we \[)rcscnl a new mcLhod of unificaLion which we (call conditioned unification.
The essence of the method is t.o deal wit.h paLLcrns aimoLated by seine sort of condit, ioils.
These eondiLioi<ls are so cortsl, raincd /-Is Lo 'oe cfficicntly operated on, and yet to be able to carry rich enough informaLion t.o caDLure linguistic gcneralizations.
2. The Problem Ordinary patterns as it/ Pr(;h)g Is.el< cxprcssivc power, t)esatlSC var\[ablcs theFcirl arc Sil)i\[)ly il\](iClCl"tlliltdt(7 alld Ihtis car'ry almost no irffqrrnalion 'l'hercforc, stie}l palL(ms aud unification among thcm arc msuffiei0nt for' capturlng t\]le {~,i<'al/l rYlat ic al <!,>erm r'al ixat ior~ and tim process:n~> effici(ncy.
\],It us look a.t some c:<amph.~s below A ~,,l'anl matical catc>ory is assumed Lo be it llst of features A feature consisLs of a feature nalnc and a w~hic, and rcprcscnLcd as a t.cmn like tt~rn.e (vat,z().
'\['hc \]cxical entry of English vcrb p'u,t, for instance, can not.
be described as a I'roloc patLcrn, bill needs some arlllOLation (i.c.,p~zt Im.s~)s?t.~zmS(T, P, N)) as in (1) (1) k:xicorl(puL, I tensc('I'), p(msorl(\]')> number(N)I) : put_Lns_ psn nrnb(T, P, N) }let(?, fcaLLIICS olincr Lhan ten, se., perso?t, and ?lattnher arc omitLed, arm predicate p~ztmtm.spsTt~z?n.b is dcfinc.d c,s in (2) For a biL morc COIT/I)I i:aLcd instance, conmdcr the relationship between a synLacLic gap and iLs filler.
In GPSG, IIPSC, cte., tiffs relationship is; captured in terms of the SI,ASI\[ fea/.urc, which reprcscnts gaps in the category of \] U~.i~tk is craz U, for cxamplc, thc SI,ASII feature is spcciflcd as \[NI j\] ller'e SI,ASI is assumed to take as its wdue alist of catcgorncs.
SLaLcd below is a simplil3cd principle about the disti'ibution of this featqrc in I.yptca\] cascs (3) lu a local tr'ec, Lhc rllotl;cr catcgor/s S\],ASI\] tea.Lure is obl.aJncd by coneatcr~atir, g from h.fi\[.
Lo rip, ht the S I,ASII fcat,wcs of hey de.,.ightcrs In order to describe: this principle, s('nnetlting :uorc than a nlerc pat t.crn ts lcquir(x\] again: (i) IocalJr'cc.(lslc, sh(X)\], Ismsh()l, Islash(Z)\])append(Y, Z, X) l'eaturcs othcr thanSI,AS}l arc omitted herc.
The so called procedure altachmcnts is the most colnrnon way or conllflclncntJnp, the \])oor clcscriplivc capacM.y or ordinary patterns \["or instance, you may regard Lhc bodies of \]h)rn elaus(s (1) and (4) as at la,_hed procedures The dr'awbacl< of procedure atLachr~lcnl is ut the fact t.hnt the ouly way of using Lhc proccclurcs Is to execute thorn I"or t.his reason, proecdur,}s arc Irmrcly embedded lu programs, rcAhcr than at.lath(x\] to those paLterrls which th(sc itrotu'ams operate on The irtforrnaLion which \[)ro((durcs cantain car/rx~t {U.'nera\]\]y be I~.',rricd aFOlllld a( ross scvc;a/ part ial s\[rtlC\[ tlI( s ci\]ch Of which it pFoocc\]arc dircclly operates on, bccausc> oncc a procc(lurc is cxc cnt.td, the informs.lion whkh it c.ontainc:d is palqially lost For instance, when Icxical entry (1) is cxploiLecl, p~ztJ.n.s pstt.n;/m,6(?', I), /\i) is cxecut.cd and 7' and /~ arc il~stanliatcd Lo be preset~.t and Ist, icsp(cLivc\[y 'l'h'ds Ic\[L bchh~d is the informaLion abotlL the other ways Lo instanLiaLc those wwiablcs.
Actual procedure attaclu'ncrd.s musL be arr-ar<e, ed so that infornlat on shouhl not be it)st whelt procedures arc cxccutcd Freeze of Prolog (Colmcraucr (1982)), for instanc/, is a mcans of tins arr~ingerncnt.
\]\]y exc(tll.i\[\]g freeze(V, "~), atomic formula ~ is frozen; i.c, the exccuLlon of'~ is >-uspcnded until w~riable X is instanttat.cd \]f' contams.'(, thcl'cforc, }lop(fully uot.
so rnuch lrtforrnat.iol~ is test.
whcc  is cxecuLed Ncvc.rthcless, freeze is problematic in two rcspt(ts Virsk, irJorn\]ation cart still be lost when the frozen pro-ccdtll'CS LIFe cxccnted.
Seeond, too nltlCh illforrllatiol3 cat\] be accumulatcd whilc several procedures arc frozen Sup pose, for itlst.ance, thaL freeze IX, t~tet~ber(.Y, \[a, 6 })) and fr<,t~.~<~.
(r,,~.',~,.~.,'(}'. I~'.~ I)) have bccn execut, cd '\['herr, X and Y can be ulfif\]cd with each other witt~ouL awakening ciLbcr procedure.
In that (asc, Lho iifforn/at, ion that X may bc t) is redundant bctwccn Lhc I.wo proccdures, and Litc other part or irlfornmLion those Droecdtlres contain is Ill(Of\]" sistcitL What one might hope here is \[o Jrlstitntiatc )( (and Y) to be b If we had cxectitcd freeze(Y, member(Y, It, cL ) iristcad of freeze (Y, rn.ernber(Y, Ib, c I), computational 85 resources would be wasted as the price for a wrong processint.
After all, it is up to a programmer to Lake a deliberate care so that information should t)e efficiently transmitted across patterns This causes sewral problems interwoven with one another.
First, since those programs reflect the intended order of execution, they fad to straightforwardly capture the nniforrnitJes captured by rules or principles such as (3).
Accordingly, programnnng takes rnuch labor'.
Moreover, the resulting programs work efficiently only along t.he initially inLer~ded order.
3o Conditioned Unification 3.1.
Conditioned Patterns These problems will be.
settled if we earl attach information to patterns, instead of attaching procedures to programs l\[ere wc consider that such information is carried by some conditions on variables Variables are then regarded as carrying some information rather than remain:ing simply indcterminatc I-}y a conditioned pal.tern let.
us refer to a pair o\[a pat tern and a condition on the w~riables contained in that pat.tern.
l~'or simplicity, assume LhaL the condition of a conditioned pattern consists of atomic formulas of Pro/og whose argument positions are filled with variables appearing m tile pattx.'rn, and that the pre(hcates heading those atomic for mulas are defh~ed in l.erms of Horn clauses.
For instance, we would hkc to regard the whole tbing in (\[) or (4) as a condJtioncd pattern.
 3.2.
Modular Conditions The conditions in conditioned patterns must not be executed, or the contained information would be partially lost Tile conditions have to be somehow joined when conditioned patterns are unified, so t.hat the information they contain should be transmitted properly in tile sense that the resulting condit.ion is equivalent \[o the Logical conjunction of tam input renditions and contains nciCrmr rcdnndant nor ineon sistent information.
We call suet a unification a conditioned unification A simple way to reduce redundancy and inconsistency in a ('.ondiLion is to let each part of each possible value of each variable be sLlbjcct to at, most one constraint.
\],eL us formulate this below.
We say that a condition is superficially modular, when no variable appears twice in that rendition For instance, (Sa) is a superficially modular condition, whereas (Sb,c) are not.
(Conditions are some.
times wr'itterr as lists of atomic forrnulas ) (',9 a \[a(X, Y), b(Z), a(U, v)\] b.
l a(X, Y), b(Y)\] e \[a(X,Y,X)\] l,'urther we say that a condition ~I' is modular, when all the relevant renditions are superficially modular, lIere, the relevant, conditions are {I} and the bodies of Horn clauses reached by descending along the definitions of the predicat.es appearing in .
A predicate is said to be modular when its definition contains only those Iiorn clauses whose bodies are modular conditions.
A predicate is potentially modular when it is equivalent to some modular predicate A modular condition does not.
impose two constraints on any one part.
of any variable, and thcrcfore contains ne> kher redundancy nor ineonsistency, ltereaRer we consider that the condition m (.'very conditioned pattern should be modular.
a.a. l'Jxpressive Power Conditioned patterns can carry rich enough information for capturing the linguistic generality.
Obviously, at 86 'st., they can describe any finite set of finite patterns.
\];'or instance, (I) is regarded as a conditioned pattern with modular condition \[pztt_g'ms_pstt~q,r~zb (T, P, N)\].
Moreover, also some recursivc predicates are modular, as is demonstrated below.
(6) a appcnd(\[\], Y, Y): append(\[U I X\], Y, \[U I Z\]) :append(X, Y, Z).
b sublist(\[\], Y).
sub\]ist(\[U I<I, \[U I Y\]) :sublist(X, Y).
sublJst(X, \[U IY\]):-sublist(X, Y).
Thus, (4) is also a conditioned pattern.
\]lowever, some recursive predicates are not potentially modular.
They include reverse (the binary predieate which is satisfied i~r its two arguments are the reversals of each oilier, as in reverse(\[tot, b\], c, all, \[d, c,\[ct b\]\])), .perm (Lbe binary predicate satisfied iff its arguments arc permutat, ions of each other, as inperm(\[i, 2, 3\], \[2, 1, 3\])), subset (the binary predicate which obtains iff the first argument is a subset of the second, as in s~zbset(\[d! b\], to, b, c, all)), etc.
New.'rtheless, t.his causes no problem regarding natural language proeessing, because potentially infinite patterns corne up only out of features such as SLASt\[, which do not require those non ruodular predicates.
3.4. The Unifier Shown below is a'trace of the conditioned unification between conditioned patter'us (7) and (8) (here we use the same notation for eondit.ioned patterns as for IIorn clauses), where the predicates therein have been defied as in (9).
(The definitions of c0 and e3 are not exploited).
First, we unify iX, )2 Z, g/\] and \[A, 7\], C, D\] with one another and get.
XA, Y : /3, Z = C, and W = D \]n the environment under lifts unification, the two conditions are concatenated, resulting in \[c0(X), e I(Y, Z), e2(Z, W)\].
The major task of this conditioned unification is to obtain a modular condition equivalent to this rmn-rnodular conditiorl This is tire job of funcl.ion ~tod~zlayi, ze.
Mod~zla.~tze rails function ~;~ttegrctte, which r'eLtlrns an atomic formula equiwrlent Lo the gives condition.
The Lcrminatior~ of a ?rtodulct,'ize or anir~fegrate is indicated by ~ preceding the reLurn-waluc, with the same amount of indentation as the outset of this functionrail was indicated witb When an {~ztegro, te calls a ~zodula~'ize, the alphabetic identifier of the exploited Ilorn clause is indicated to the h.'ft hand side, and the temporal unification to the right-hand side.
Atomic formulas made in integrate is written following 4.
Each lIorn clause entered into the definition is shown following % and given an alphabetic identifier indicatedto the right-hand side.
(7) IX, Y, Z, W\] :-e0(X), el (Y, Z).
(8) \[A, \]~, C, D\] :e2(C, D).
(9) e*(0, \]).
(a) e ~ (q, e) (b) ca(l, P):-e:Xl').
(c) c~(e, 0).
(d) modularize(\[e0(X), cl(Y, Z), c2(Z, W)\]) integrate(\[e0(X) \]) cO(X) integPate(\[cl(Y, Z), e2(Z, W)\]) c4(Y, Z, W) (a) modularize(\[e2(1, W)\]) Y = 0, Z = 1 integrate(to2(1' W)\]) * eS(W) (c) rnodularize(\[e3(P)\]) W = P integrate(\[e3(P)\]) =~ e3(P) tea(p)\] c~(p) :ca(P).
(0 =:> eS(W) -~ \[c,~)(w)\] 1' o4(o, :, w) :.
~:',~(w).
(j) (b) n:odular:'zc(\[c2(2, W)i)  :q, '/, :~ i:,t.o~ra~,'.(Im<3(a W)\]) * cO(W) (d) nladularizc(l I) w =.: o =-~ \[\] cS(0) (k) =+ c6(W) > I cs(w)J " o,3(q, ~, w) : o6(w).
(I) => c4(Y, Z, W) > \[co(x), <:4(< z, W) l We CaN refine Lhe progra\]'n o\[ "btt~.grcs, ta so that it should avoid ally predicaLe w}iose definiLion coiuLains only one llorn clause.
For instance, Lhe definiLion of cb consisLs only o\[(i) InsLead of (j), LhereR)re, we may }rove cd(0, 1, P) : c3(P) Also (1) can bc replaced by c 4(0, 2> 0), based on (k) We are able Lo work out r'ccursivc condiLions from F, lvor; recursivc coI:dit.iolls, lVor example, considor how X and Z arc unifiod under" t, ha conclit,iol: (10), whore ~rte'n~be.r is defined as in (1 1) (10) \[n,e:nher(X, Y), o0(z)\] (11) n/cinber(A, IA I IJl).
(a) member(A, IC I i~i) :-i ....... her(A, it) (b) The Lracc of this ulfif\]cat.k~n is showl~ b('\]:'w, whc's'c prcdica.l~' c 1 is rccursivcly (\]o/~ll/Cd based on Lhc i'(,ctlrsiv(! dcfillJLioH of 77"~ ( 77}, t) I~, '? modularizc(lmcmbcr(X, Y), cO(X)I) int.cgraLo(I member(X, Y), cO(X)\]), el(X, Y) (a) modularize(\[cO(A)\]) X = A, V -.
\[A Ill\] int.e<~';ratc (I c O(A)I) = > oO(A) =~ 1 <:)(A)\] 1' c I(A, \[A I ~<J) :-c0(A) (1)) n:odularizc(lmcn,bcr(A, 11), c0(A)l) X :: A, Y :: \[c!i;I Jnl.c<qral.e(\[ nlernbcr(A, I~), cO(A)I) :~ el(A, 1~) ::> \[cl(A, 33)1 1'ci(A, Iclt<l): c~(A, 13).
.... > c:(X, Y) :.~ \[o:(x, Y)I IL Js a job of in, tegra, te, Lo handle re,cursive de,hiLton.
The lasL g?l, te.g?,ts, te.
above recognizes Lhat.
the first 4m.tegrate, which is Lrying Lo (\]cNr/c c 1, was called wit.h the same arguITlCrlI.S except, the variable narnes, llencc t.he last "inttegrctte simply reLul'ns c.
I(A, H), because t,hc conLent, or cl is now bring worked ouL tlrldoY Lhc J'\]rsl.
~?ttegro.te arid thus it is rednndanL fol' t, he lasL {~tfegrate Lo \[urLhcr examine c 1.
It is not.
a\]ways possible fro' the above unifier t.~ unify paLL(2i"\[/s tlrl(\](~r roc.
tlr'sivo Col\]d\[Liol/S \["or J//sLalloL', J\[ Cf/illIOL unify X with )" under \[appe~td.(X, Y, Z)\], becal_tsc Lhe result ing condiLion is noL potsnLia\]\]y rnodular, llowcver, such a situaLiol'l CtOCS FioL seoln t.o occur Jn actual \[al:g:lagc proccssir:g.
4. Conclusiori We have prc.'-~er, Led a new nle/hod a\[ umfiealion, wh,ch wc call o.
coildiLior~c(\] tltti(loaLioli, Whcl'e paLLorils to be uniPlc(\] "'re annoLaked by a certain sort.
of corldit.ions on lhe variables wifich octroi" ill those patt.crn.<;.
Theso condiLions are so r'est.ricted t.haL Lhey conlain as lit.Lie redundancy a<'; possible, and d'ms arc always assured to be satisfiable.
This method has Lhe fo/h)wtng welcome characteristics l"h'st, I.he \])attorns to bc unified can carry at)llllda\]'lL infos' mat.ion rcprcscnLcd by t.he conditions han:,~in!,; on t.hClll The expressive capacity of Lhe,<c condiLion,s is sl:fl'Jcen\[ for capt.uring \]JH~U, IIihLJ(: ~sCHCl'a\]i',,iOS ~ccorld, such irfformat.ion is cfreclivcly Ir'ansrnitLed, by h~t.egrat.\[n? the col~dil,ion.~ v;her, pat.'..crl:,<s o.ro unif'ied Unlike procedure aLLacl:ment.s, in thil~ COllne(:lion, Ll/c infornGaLioi~-conveying <.'fficicl:cy of our Colt dilioiued unif'icat.\[on is no afl'c'(gcd by the direct.ion of t.i~c daLa.flow Therefore, O/ll" col'l(\]{lioned unifies.Lion is oo;rnplel/ly r(ver'sJbk< and ',hns is \[n'on:ising its a Los\] for dcscril)h'T> <~{l'all/lllilrs fOF bolh SCllL(Hb':C comprel/ensiol: slid prochl(d toll Owing t.o Lhese cllar'act(!risLics, Otll conditioned unif'caLian l)r'avh|es a now prog, ra.unniiug 1.1aradigtn foi I/illt/l'/tl lar/y,/lag(".
\[)l'OCCSSil/lJ>, rcph~.cing proccd/1Fc aLt, o.ctlI3:ont.s which haw3 tradlLionally el2joyed i.\]lc Llbiq/lity Lhat.
t.hcy do noL descrvc References Bresnan, J.
(ed). (1982) The Mental Representation of Grammatical Relations, MIT Press, Cambridge, Massachusetts.
Cohnerauer, A.
(1982) Prolog II Reference Manual and Theoretical Model ERA CNRS 363, Groupe d'Intelligence Artificielle, Universit de Marseilic, Marselle.
Gazdar, G.
E. Klein, G.
K. Pullum, and J.
A. Sag (1985) Generalized Phrase Structure Grammar; Basil Blackwell.
Oxford. Kay, M.
(1985) "Parsing in Functional Unification Grammar".
Natural Language Parsing, pp.
251--278, Cambridge University Press, Cambridge, England.
Fernando C.
N. Pereira, A structure-sharing representation for unification-based grammar formalisms, Proceedings of the 23rd annual meeting on Association for Computational Linguistics, p.137-144, July 08-12, 1985, Chicago, Illinois Pollard, C.
J. (1984) Generalized Phrase Structure Grammar.
Head Grammars, and Natural Languages.
Doctoral dissertation, Stanford University, Stanford, California.
Pollard, C.
J. (1985a) Lecture Notes on Head-Driven Phrase Structure Grammar.
Center for the Study of Language and Information.
Pollard, C.
J. (1985b) "Phrase Structure Grammar without Metarules," Proceedings of the Fourth West Coast Conference on Formal Linguistics, University of Southern California, Los Angeles, California.
Derek Proudian, Carl Pollard, Parsing Head-driven Phrase Structure Grammar, Proceedings of the 23rd annual meeting on Association for Computational Linguistics, p.167-171, July 08-12, 1985, Chicago, Illinois Stuart M.
Shieber, The design of a computer language for linguistic information, Proceedings of the 22nd annual meeting on Association for Computational Linguistics, p.362-366, July 02-06, 1984, Stanford, California Stuart M.
Shieber, Using restriction to extend parsing algorithms for complex-feature-based formalisms, Proceedings of the 23rd annual meeting on Association for Computational Linguistics, p.145-152, July 08-12, 1985, Chicago, Illinois
LA RESOUTION D'ANAPHORE A PARTIR D'UN LEXIQUEGRAMMAIRE DE45 VERBES ANAPHORIQUES Blandine GEL.AIN & Gelestin SEDOGBO 26 place Ovale BULL cediag 94230 Cachan 78430 Leuveciennes (France) Abstract This paper presents a system which intends to resolve anaphora in the framework of the Discourse Representation Theory, arrd using a lexicon-grammar of anaphoric verbs, through the application of selection criteria for assignment of a referent to an anaphora.
From a semantic representation of text provided by a DRT system implemented in Prolog, the system uses several criteria of selection of referent.
One of these criteria is the anaphoric conditions of verbs described as a lexicon-grammar of anaphoric verbs.
The present paper investigates a transformational analysis of verbs related to their anaphoric behaviour, and the adequacy of extension of the lexicon~grammar of MGROSS to anaphonc conditions on verbs.
1. Introduction La Th~orie de la Representation du Discours (ou DRT 1) propose une approche unifiee de phenom~nes du langage naturel tels que le temps, I'evenernent, I'anaphore Elle se caracterise par sa filiation avec la semantique Iogique, et sa distance d'avec les niveaux de representations basees sur la Iogique des predieats et ses extensions.
Ainsi les notions de consequence Iogique et de validite (\[SEDO 87\]) peuvent s'appliquet naturellement aux structures maniputees par la DR1 Cette theorie propose une explication de la formation de I'anaphore, sans en proposer ta resolution.
Celle-ci passe en general par I'application de orit~res de selection syntaxiques, semantiques et pragmatiques, qui levent les ambiguites engendrees par t'usage de I'anaphore.
\[GUIN 85\], \[CARB 88\], \[RICH 88\] entre autres ont intloduit les notions de foyer et de contramtes successives 8 activer Cependant cos criteres sont paffois insufiisants pour etablir une relation evidente entre un nomet un pronom Dar~s sa theorie du Oouvernement-liage, 1 H.KAMP "A Theory of T\[uth and SemarY0c Interpretation" GroP.nendiik Amsterdam 1-(:JR t NCHOMSKY 2 explique I'anaphore ~ partir d'un mecanisme de liage et s'appuie sur la remarque que le liage d'une anaphore A son referent depend aussi des proprietes anaphoriques du vetbe.
Aucune etude empirique des proprietes anaphoriques n'a ete faite ~) ce jour, alors que toute approche de resolution d'anaphore devrait etre basee sur un texique des verbes et leurs proprietes anaphonques associees.
Le present article decdt une approche de resolution d'anaphore qui repose sur: la mise en oeuvre de ta DRT pour representer la semantique d'un discours; I'elaboration d'un lexique-.grammaire des verbes anaphotique@; un systeme de filtre base stir differents criteres de selection Ce systeme illustte la resolution automatique de certaines anaphores en partant de la representation semantique d'un texte obtenue d'apres la DRT los ptonoms que nous avons etudies font partie d'un type d'anaphore qui represente une relation pouvant s'etablir entre deux phrases saris mettre forcement en jeu une regle syntaxique (le pronom pout identifier un referent dans le discours precedent): Jean croit que Mane IU/ offre un //we Cet article est divise en cinq parties: introduction ~ notre travail, presentation de la DRT, puis de son implementation en Prolog, description des lexique-grammaires et leur extension aux proprietes anaphoriques, presentation generale de I'architecture de notre systeme de resolution, et enfin perspectives de creation systematique d'un lexique-grammaire.
2. La reprdsentatlon s~manticlue La DRT se fonde done sur un ensemble de regtes de construction traduisant un disoours en une representation semantique formelte: la Structure de Representation du Discours.
Pour chaque pattie de discours, une DRS est construite, boite pouvant err contenir d'autres, 2 "Government Binding", notee GB 3 Exlension des tables de verbes d#vetoppt~es au LADL, aux propri~tes anaphonques (cf \[GELA g2\]) Ac:iEs DE COLING-92.
NAtCI~S, 23-28 AO~ t992 90 1 PROC.
OI; COLING=92, NANI'E,'I.
AUG. 23-28, 1992 qui reprL~sente le contenu significatif de cette par'tie Une DRS complete est I'ensemble de plusieurs DRSs apparaissant t~ mesure que le discours continue.
La DRT etudie doric les contraintes sur cette continuation.
La forme d'une DRS consiste en une paire <U,Con> constituant deux z6nes, o0 U (univers) est un ensemble des r~fdrents #u discours representant les entites du disc, ours, et Con un ensemble de conditions qua doivent satisfaire ces referents.
Celles-ci sont des predicats et des relations de referents du discours mais peuvent etre plus complexes.
Notees comme en Iogique des pr~dicats, les conditions de verite sont definies par rapport & la possibilit~ d'incture la DRS dens un modele (pour plus de details, consulter \[GUEN 85\]).
D'autre part, I'extension d'une DRS ne peut changer les valeurs d(~j& assignees: tout Ce qui etait vrai auparavant restera vrai par la suite: Un aamion bansporte une charge u.K=\[xl,x2\], Con.K=\[carnion(Xl),charge(X2),t~'ansporte(Xl,X2)\].
Tout camion b'ansporte une charge U.K=\[ \], Con.K = \[:>,K1,K2\]; U.KI=\[Xl\], Con.K1= \[camion(X1)\]; U.K2=\[X2\], Con.
K2=\[charge(X2),transporte(Xl,X2.)\].
2. I La notion d'accessibilite On peut representer des restrictions configurationnelles sur les relations anaphoriques possibles entre les pronoms et leurs antecedents.
Ces restrictions sont obtenues en reduisant I'accessibilitd des referents.
L'accessibilit~ permet donc de determiner les liens anaphoriques entre un marqueur pronominal et un marqueur de discours.
Toute DRS est accessible d'eltem~me; son univets de marqueurs accessibles est I'unNers du discours de la DRS.
Dans une DRS implicative, la DRS antecedente est accessible de la DRS consequente Enfin, la relation d'accessJbilite est transitive.
Donc pour "tout camion qui transporte une charge la declare", I'antecedent du pronom obJet laest une charge.
Ici, U.K1 est accessible & K2.
Les conditions de continuite d'un discours sont aussi fonotion de I'accessibilite: la phrase: "il va & Berlin" ne peut continuer la precedente puisqu'aucun marqueur de diseours n'est accessible de la DRS K (voir ce sujet \[KASP 86\]) Ceci explique pourquoi une phrase comme: "Cheque chauffeur possC~de un camion, fl te conduit": doit etre formulae: "Chaque chauffeur qui poss~de un camion le conduit* (avec "qui poss~e un cam/on" comma extension de "cheque chauffeur") pour Otre representable.
Mais la DRT a des limites; elle n'explique pas la bonne formation de ce texte, par example: Cheque chauffeur transpo~te une charge.
II n)et plusieurs jours & la tivrer.
Ella ne sere livr~e qu'au bout de 3lOUtS Les cleux dernieres phrases, selon la DRT, ne peuvent suivre la premiere, & cause de la portee du quantificateur cheque.
Par contre la phrase "Cheque chauffeur fransporfe une charge qui ne sere livree qu'au bout de 3 jours" sere parfaitement representee par la DRT.
Ces r~gles obligeraient doric le Iocuteur & d~crire une situation en une seule phrase! 2.2 Imp.~.
mentation de la DRT Notre analyseur semantique demane avec des arbres syntaxiques resultant d'une grammaire de type GPSG, programmee en Prolog La grammaire semantique est bas~e sur les memes principes: unification de structures, augmentation de listes ordonnees, presentee sous forme de regles de reecriture suivies de contraintes, de type: ph -> gn gv <ph drs courante>=<gn drs courante> <gn suite drs>=<gv drs_courante> <gn argument>=<gv arg_sujet> <ph arg sujet>=<gv arg suJet> <ph arg objet>=<gv arg_objet> Ceci donne, 8 partir de regles DCG issues de la compilation des precedentes: traduire(ph(GN, G V), P) :~'aduire(G V, P2), traduire(GN, PI), imerge(P,\[courante\],Pl,\[courante), imerge(P l, \[suite\], F~2, \[courente\]), tmerge(Pl, \[arg\], P2,\[arg sujet\], imerge(P,\[arg sujet\], P2,\[erg_sulet), tmerge(P, \[arg_objet\], P2,\[arg_objet\]) soit la formule semantique: drs (arg sujet(Xl),arg objet(X2), cour(cond( \[imp(drs(cond(\[camion(X l)\]), univ(\[X1\])), drs(cond( \[charge(X2), transporte(X l, X2)\]),univ(\[X2\])) )\] )) ).
correspondant ~ la phrase "tout camion ffansporfe une charge".
C'est 8 partir d'une telle formula que commence la resolution anaphorique 3.Le lexique-clrammaire Le lexique-grammaire, represente sous forme de tables (matrices composees de colonnes ACIT~ DE COLING-92, NAN-IT~, 23-28 AOt~Zr 1992 9 0 2 PRoc.
OF COLING-92, NANTES, AUO.
23-28, 1992 et de rangees), contient les phrases strnples, les diff~rents emplois verbaux et los propri~tes qui leur sent assoei~es: nature semantique des arguments, trallsforrnations possibles et tours conditions, nombre et structure des complements, type de la preposition associ~e etc I/ consid~re la nominalisation comma la transformation d'une phrase contenant un op~rateur verbal, en une autre phrase contenarlt url op~rateur nominal.
On y introduit un verbe predicativement vide -verbe supportdent le r,~le est d'actualiser le substantif qui n'a pas de marques morphologiques susceptibles de le taire: l.uc complimente los acteurs = Luc fail des compliments aux acteuts 3 1 L'entoura~e lexical Nous nous limiterons dans cet article aux possessifs, sur lesquels \[GULL 81\], \[DANL 80\], \[GROS 89\] et \[VtVE 83\] notamment nous ont fourni des informations fort utiles.
L'examen des roots voisins du possessir est important, e.
g; Luci donne # L~.aj son i+ j argent Luc i donne a L~,a son i amour Dens le premier cas, donner est un verbe ordinaire (plein) alors qua dens le second, 41 est un verbe support (V-sup) Seut le substantif N2 change (\[NO donne ~ N1 N2jaoss\]).
Pourtant dens la premiere phrase, son peut ref~rer & trois personnes: si t'argent est & Lea, son est relie ~ L#a; si I'argent est ALuc, son est relie a Luc; si I'argent n'est ni ~ I'un ni ~ I'autre, son est relic,9 une tierce personne du discours pr~o~dent.
Dans la seconde phrase par centre il n'y a qu'un r#ferent: Luc, ~ cause du terme amour qui appartient aux roots "abstFaits" ou de sentiments, pour lesquels on ne peut pas trouver, dans ce type de structure, d'autre relation ~ sot\] qua le sujet, ici l,uc.
II s'agit de cor~f~rence obligatoire au sujet Dens "Luci cheque L~j par sos i id~'es ~ et "Luc i cheque Leajdans sos11rig, as", il y a le verbe chequer Pourtant dens ta pre.miere phrase sos est forcement relic 8 Luc.
II s'agit d'un cas de coreference obligatoire au sujet, induit par la preposition par.
Alors qua dens la seconde, la cor(~f~rence est oblJgMoire au cempl~ment d'objet sos est reli~ ~ L~4a, ~ cause de la preposition dens 3.2 Phrases construites aulour d'un V-sUlq On trouve des expressions verbales figees et d'autres mettant enjeu la paire Vsup/Npred mais sans 6tre des expressions figees.
I.es expressions verbMes fi~es sent de la torme \[NO V Nl-poss/, construites autour de variantes aspectuelles et d'op~.rateur causatif du verbe avozr, dent le N1 est teuioum "pattie du corps" ou "abstrait" ("Luc i rettent sos i tarmes'), et dent la hansformation en gnest impossible.
Elles peuvent aussi etre completees par url troisieme argument (\[NO V N1 Pr#p N2\] avec V support ou non.
L& encore, le nom (N1 ou N2) d~tenniue pal le possessif est "pantie du corps" ou "abstrait", et aucune restructuration n'est possible: L.ucHelte son i d#volu sur L~a l.uci #erda L#a sous sa i protection Si le possessif d~termine I'objet direct dens une structure INO V Nl-poss Prep N2\], \[Prep N2\] pout 0tre remplac# par une compl~tive I'infinitive, donnant \[NO V Nl-poss Pr~p Vlnf\]: Luc i passe son i temps au travail Luc~ passe son i temps ~ travailler Daris toutes ces phrases, la cor~ference est touIours obligatoire au sujet \[.es expressions non #g#es sent construites autaur de verbes support ou de variantes aspectuelles 1NO V N%poss\] ou \[NO V Nl-poss Prep N2\]: Luci a perdu ses i illusions (~ur L~a).
On ne peut pas transformer \[NO V Npred (Prep N1)\] en \[NO V Npred de N2 (Prep N1)\] (* Luc a pe~du les illusions de Paul sur L~a).
En d'autres termes, I'argument NO de Nprep est le sujet du verbe, mais ce verbene pout prendre une expression \[Npred Pr#p NO\] comme complement (ici: los illusions de Paul).
La presence ou non du complement d'objet indirect n'a pas d'incidence sur la relation qui lie le possessif au sujet.
Ces phrases nese construisent pas avec une infinitive.
Certaines expressions non fig~es se construisent avec le possessif comma d(~terminant de N3; dens cecas, los trois arguments sent obligatoires etla cor~f~rence n'est pas obtigatoire au suiet, II s'agit de cas de norPcor~f~rence obligatoire ~ I'objet ("Lucj met Lea ~ sai4 j disposition") On pout restructurer en reliant les complements par ~tre: Lea est ~ ta disposition de (L uc, Paul) Fin resume, parmi les phrases construites autour dt t Vsup, I'adjectif possessif qu'elles contieonent n'est jamals coref~rent ~ I'objet, AcrEs DE COLING-92, NANrHS, 23-28 AO~r 1992 9 0 3 l'rtOC.
Ot; C()I.ING-92, NAN'I'ES, AUG.
23-28, 1992 mais toulours au moins cor(~f~rent a.
sujet En reconnaissant d'emblee ces phrases et teur verbe comma Vsup, on pourra r/esoudre automatiquement I'anaphore Pour cela nous proposons de reperer les autres phrases, pu~s de considerer les phrases non reconnues comme ~tant de carte categorie 33 Phrases construites autour de verbes ordinalres Elles s'articulent autour d'un verbe ~ un ou deux arguments, rNement predicatif de la phrase puisqu'il definit la structure des arguments II est determin#, par: le nombre d'arguments I'articulation syntaxique de ces arguments les traits semantiques de ces aguments Dans la st\[ucture \[NO V Nl-poss\] que ron ne peut poursuivre avec \[&/de N2\], la coreference est obligatoire aun autre nero que le sujet NO (du discours anterieur) Luc approuve son choix Luc apptouve le choix de L#a Par centre, si une phrase a deux arguments et qu'elle peut etre completee par un troJsiCme, la presence ou non de ce dernier fait varier la coref~rence, ou tout au moins la preference entre lee antecedents possibles: Luc i avoue son i depit.
Lucj avoue soni+ j d~p/t a Lea k La relation de coreference existe toujours entre le possessif et le sujet dane ~es phrases simples \[NO V NI\]; ou complet~es par \[Pr~p N2\] oQ la relation peut aussi exister entre le poss et un referent du discours ant~rieur.
n a donc la un cas de non-cor#f~rence obligatoire ~ I'objet Tous les verbes qui donnent ces r~sultats dans une telle structure appartiennent a la table 9.
Quand le syntagme prepositionnel est obligatoire, on distingue les phrases ou I'adjeetif possessif determine le N1 et celles oO il d~terrnine le N2.
Parmi tes premieres, on trouve une cer~fdrence obligatoire au sujet Iorsqu'il y a possibilit~ de pronominalisation: Luc i consacre sa i vie a ta pemture.
Luc se consacre e la peinture OU de verbalisation simple: Luc i accorde son i pardon ~ L#a Luc pardonne a L#.~ Mais pour celles dent la transformation donne une completive ~nfinitive \[nO V N1 VinfJ, la coref~rence est obligatolre ~ I'ebjet: Luc i motive L~ajdans son 1 travail Luc motive Lea g~ travailter Tous ces verbes appartiennent a la table 11 Parmi les phrases de structure \[NO V NI Pr~p N2-poss\], la relation est obligatoire au sujet, ou obIigatoire ~ t'objet Dans les exemples suivants (verbe de la table 4), oQ la 1estructuration est possible en IN2 de NO V N1\], la relation est etablie entre le possessif et le sujet, Iorsque ta preposition est par ou avec: Luc i cheque L&aj paffavec see i idles.
Lea Ides de Luc choquent Lea.
Pa~ centre, la mC~me phrase avec clans ou pout; par exemple, donne \[a transformation \[NO V N2 de N1\], et on etablit alors la relation entre le possessif et le ~:ompldment d'ebjet: LUC I cheque Lea\] darts.~esj Ideas.
Luc cheque tee id#es de L&a.
4.Architecture .qdndralle du s.ystdme Notre systeme se compose donc d'un analyseur sfntaxirlue qui donne des arbres & paftir desquels un analyseur s~mantique produit des ORS.
C'est sur etles qu'oNrera le piogramme de ~euolution anaphorique Ce systerne se complete d'url fichier de verbes par tables, et d'un fichier "fonetionnel", constitue ~ mesure de I'arlalyse semantique, ou sent stockes tousles norns et pronoms, et leur forlction grammaticale.
La procedure de r~solution: apres reperage des pronoms, commence par une recherche des verbee (A chacun est associ~ un trait pour sa table d'appartenance) et de leur structure, dans le fichier lexique-grammaire.
Si cela est trouve, on cherche sila coreference est obligatoire.
Si oui, le traiternent est termine.
Sinon, il faut activer d'autres filtres syntaxicos~mantiques: en partant des listes ordonn~es de pronoms, univers et conditions, on verifie la compatibilite de fonction 4, de genre et de hombre, semantique 5.
II faut parfois chercher te verbe darts plusieurs tables.
Si I'identite de structure entre le texte etles fables n'est pas ~tabtie, on examine I'entuurage substantival du verbe si robjet est concret, il taut activer tes autres filtres.
S'il est abstrait ou "partie du corps", on a affaire ~ une phrase a verbe suppolt (peut-t~tle figee) dont le statut induit la (non) coreference obtigatoire.
&ConclUsion et perspectives \[~emarques sur Des travaux: 4 Un candidat sulet est pr~f~e aun autre pour tre reli~ & un pronom suJet, dans deux phrases dtes paralleles 5 Des traits semanhques sent associes aux roots lexicaux ACRES I)E C()LIN(;-92, NAm'~s, 23-28 aot~rr 1992 9 0 4 Pr~oc.
oJ; COLfNG-92, NANtES, AUrJ.
23-28, 1992 -lous les ver'~;t; donl~uHt lieH ~'~ Hn type de construction partmulier, appadiormuHt ~'~ k~ ~me table.
Sur chaque table on p~;\[IL contraindre la relation de (no~ 0 coiet~rence entre le possessif et Hn argurnent du w~'ibe.
..Tous les uornpl6ments d'obje/ d6termine par le possessif sent "abstraits" uu "pattie du colps".
Avec d'aubes 1~ulns, nun pr~dicatifs, les verbes sotR ordinailt;s et on ne peut resoudre I'ambiguRe anapholique Done en ajoutant ces caract~ristiques dabs la table en question on peat resoudrc, automatiquement I'anaptiofe Ccci ~)11i/iHi~: I'hypath~se que routes les tables peuvent, a priori, tre uinsi complete;as par les sp~.cillcites liees a remploi d'adjectif..
possessifs et permethe ainsi aH syst~me d'viter d'autres filtres plus co0teHx en calClll et pas toujours fiables.
I1 taut done ~.tablir HI~ lexique-grammaim des ve~bes anaphorique'., (pris darts une structure mettant en jeLl till pronom ou, ici, tin adjectif ~x~ssessif) Darts la table 4 du lexiquegran.nu.e, pal exemple, nous repaltissons leS verbes erl: roul~.~__J_: verL~+par (ou avec et pa~ft~isd~;), et cor~f~mnce obligatoite au a~jet (NO): \[ uc i d,~prime L g, aj par son i attilu&e.
r u.q.E~_~e~: verbe+darts, e.t co~ef~len(;u obligatoire ~ I'objet: \[.uc i d~lonne l.g~j dg~tla ~esj propo~.
NOUS avons ajot~te A la table 1me colol,le concernant la pr6sence ou non de #)t~p N2\], divisee en deux colorines: les deux cas,3u cor~ference obligatoile.
Les verbes de la table 11 suHi ~;partis an: ~: V N1 darts \[NO V NI & VOinfl puut etre remplace par pronomi~-~#sation (hi verbe Le possessif est tore.~.ment coref~lent au sujer Luc consacre se vie (e d~.ssme:) au d~s~it~ Luc se consacre (,~ dessJne 0 au dessin Si N1 n'est pas abstrait la pior~t~mirlalisation est imF~ssible:(*Luc con~a:m son hao#~ au dessm): Grou~: M6rne structt.e sans prouontina.lisation.
II peut y avoir simple ve~r-b~l/saiJ~a~ L.e possessit est toujol,s cor~f6rc'r~t au soj~ N1 est toujours abst~ait et pemiet M verbalisation: Luc appolle SOn,sogtie~l ~ c(flh ~.
',dfa#O Luc ~outJent celia ~nb6"prl~e; ~: Verbes qHi, clans la tlarlsknmatiu1~ de \[NO V N1 &/pour VOilffJ eH \[NO V Nf ~/dans N2\] oQ N2 est d,~terniin,} par un poss~ssif, induisent obligatoirement une I t ~~t.,!~fin Ittk; I.(~:? pou; #av~#liu'~ Nuuu avo~ls &t~;Hdll t;~tke tabk; (a~ y ajoutaHt ulle CLtla(..tk')if, ti(\]iit;i CXi'G\[t\](I(;(!
~)11 111011 d'Llll(; Stlucttll~; lllOllOlllilal(~, .~:;tl\[}~iJvik::k'~e {;11 110i14, pol_~r k;,,,,';|ltli;klli~tu i\]hrastiq111:,-,; (,~hldi(~e~ (;t I'oblig~ioil (:lt~ colOi:Or<~i .L, qtli k'H~ c(~lll.~,'.po|ld \[(:Ab',l ~ \[\]~q JCAFd ~,()1\11<l !, I-~ I~ROWN ~_~lq~//h,:v~\] Re.~o!~jti_u_t;: q mul(V :gha2?g~ A#pl~?:~uIE ( .:131 IN(;, l }uduHa.-~t.
AI tj 1988 \[CI IAN,L~TJ \].1 "4 I/\Nll !R, !C,! il All\J, (; SEDf)(;I t ) Ih~, A_~rc,.hu Uni~eyL't~ .SVq/~xe~ ~21 rift M,Mrn_a-f~J~Ll(~J!.{:c;,9 6s,'IFC(k I, Sofia Antipoti~a Nov 1987 \[I)ANL 89\] L,DANL(:),% Rep!~se.~jt~#90.~: d','ni.fm~#i~p~; huguL.4igU~L.~.
COf*St~O*~Ql*S /V t}~rt; t/*e~'p X.
I |10.~,t) de 3~;I m~ cycle, LADI Pail! 7, !i\]\[;U JGt I/~, 91} HGFAAIrq these de ductorat (~'~ p:aHii,t~) I ~aH.'; /, 199>' \[~z,t ~()~ 89\] (:; (~Ro,~.~; lug~t~J~.~ammair~_:.
!AUI.,::L Lh,v.
Paris; ? S\[fMANTICA f>afi:-: Juin igB.q \[GROS /sJ M GhtOSS M~t!ode.u.~jL~A/~{~x P.
L::d.{ k;in|arln, i'ari-u 1!)\[,*; \[k-Jk ILiN 85\] F.GI IENTI tNLR, P,'4ABAIli \]-~ ser~{qtjgp.
F:NS, I )nivel-sit0 t tlbingeu I )(.'-u 1985 \[GIlIN 85\] R GIJIN\[)ON Focusing.
MCC Austin AC.I.i.'185 \[Gt I1\[ 81\] A.Gt IILI.EI ~, CLECI,ERIZ f 3\[n~s.
~ e tpj~_ff;\]&; :;S3ff_(tntiq ~!.'..
\[.angages n"63.
Ed I alottsse Paris "H;WI \[I(AX;t > 8.5\] W KASPER Dtscourse R~#/es~/!t~liun 7hec~E.
Rapport ACORD, Ur~iv.Stuttgart, Mai 1986 \[IdCtl 88\] ERICH, S.LUPERFC>Y tir~ A.
MCC A u sti n, A.
';. l..
f#,v 1988 \[t;I \[)O 871 C SEI )( )GB( ) SEatet~le r~ueJ_.
~OJL-U~t2g)!!s~{. Thbse de DooLorat d'Etat \[J ive~sit#, dr; Ma~seille, 1:)87 \[VlVl/83J I VIVES ::~}rne Cyck; IAI)I Pad:; 7 1983 \[WAI)A 811 tt WAI\]A, N.AsI let4 /~e~o/(~hlo q t hfivn.~.ity Texas, Austin, .l~m 1.987 References 1 Jaime G.
Carbonell, Ralf D.
Brown, Anaphora resolution: a multi-strategy approach, Proceedings of the 12th conference on Computational linguistics, p.96-101, August 22-27, 1988, Budapest, Hungry 2 {CHAN 87} T.
CHAWIER, B.
GELAIN, C.
SEDOGBO Une Approcho Unifice de le Syntaxe et de la Smantigue.
Congios AFCET, Sofia Antipolis Nov 1987 3 {DANL 80} L.
DANLOS Reprsentations d'informations linguistigues, constructions N ire prep X.
These de 3eme cycle, LADL, Paris 7, 1980 4 {GFLA 91} B.
GELAIN Thse de doctorat ( paratre) Paris 7, 1992 5 {GROS 89} G.
GROSS Dsanbiguisation smantique  l'aido d'un lexique grammaire.
LADL et Univ.
Paris 7.
SEMANTICA. Paris Juin 1989 6 {GROS 75} M.
GROSS Mthodes en syntaxe.
Ed. Hermann, Paris 1975 7 {GUEN 85} F.
GUENTHNER, P.
SABATIER Formal Semantics and Knowledge Representation.
FNS, Univ.
Tubingen. Dc 1985 8 {GUIN 85} R.
GUINDON Anaphora Resolution: Short-Term Memory and Focusing.
MCC Austin.
A.C.I., 1985 9 {GUIL 81} A.
GUILLET, C.
LECLERE Formes syntaxiques et prdicats smantiques.
Languages n"63.
Ed Laroussa.
Paris 1981 10 {KASP 85} W.
KASPER Montague Grammar, Situation semantics and Discourse Representation Theory.
Rapport ACORD, Univ.
Stuttgart, Mai 1986 11 {RICH 88} E.
RICH, S.
LUPERFOY An Architeture Program for Anaphora Resolution.
MCC Austin.
A.C.I., fv 1988 12 {SEDO 87} C.
SEDOGBO De la Grammaire en Chaine du Franais  on Systme Question-Rponse.
Thse de Doctorat d'Etat.
Univ. de Marseille, 1987 13 {VIVE 83} R.
VIVES Avoir, prendre, perdre: constructions  verbe support et extensions aspactuelles.
Thse de 3me cycle.
LADI. Paris 7 1983 14 {WADA 87} H.
WADA, N.
ASHER A Computational Account of Syntactic, Semantic and Discourse Principles for Anaphora Resolution.
University Texas, Austin, Jan 1987
Parole et traduction automatique : le module de reconnaissance R A P H A E L
Mohammad AKBAR GEOD, CLIPS/IMAG Universitd Joseph Fourier, BP. 53 38041 Grenoble cedex 9, France Mohammad.Akbar@imag. fr Jean CAELEN GEOD, CLIPS/IMAG Universitd Joseph Fourier, BP. 53 38041 Grenoble cedex 9, France Jean.Caelen@imag.fr

R6sum6

Pour la traduction de parole, il est ndcessaire de disposer d'un syst~me de reconnaissance de la parole spontande grand vocabulaire, tournant en temps rdel. Le module RAPHAEL a dtd congu sur la plateforme logicielle de JANUS-III ddveloppde au laboratoire ISL (Interactive Systems Laboratory) des universitds Karlsruhe et Carnegie Mellon. Le corpus BREF-80 (textes lus extraits du Journal Le Monde) a 6td utilis6 pour le ddveloppement, l'apprentissage et l'dvaluation du module. Les rdsultats obtenus sont de l'ordre de 91% de bonne reconnaissance de mots. L'article ddcrit l'architecture du module de reconnaissance et son int6gration /~ un module de traduction automatique.
Introduction

La traduction des documents dcrits a fait de rdels progrbs pendant ces dcrni6res anndes. Nous pouvons constater l'6mergence de nouveaux syst6mes de traduction de textes qui proposent une traduction soignde en diffdrentes I Synthbse ~ de la parole ] ~

langues[1]. I1 semble envisageable de les adapter pour la traduction de l'oral, /t condition d'en amdliorer le temps de rdponse et la robustesse : c'est le <<challenge >7 pos6 fi ces systbmes mais aussi au module de reconnaissance de la parole. Un syst6me de traduction de l'oral repose sur l'intdgration des modules de reconnaissance et de synth6se de la parole et des modules de traduction, pour obtenir une boucle complbte d'analyse et de synth6se entre les deux interlocuteurs [Fig. 1]. Le projet CSTAR-II [3] est un projet international dans lequel toutes les dquipes travaillent sur tousles aspects de ce mod61e. Pour permettre /t deux personnes de communiquer, il faut deux sdries de processus symdtriques dans les deux langues : un module dc reconnaissance pour acqudrir et transcrire les dnoncds dits par un locuteur dans sa langue puis un module de traduction qui traduit la transcription dans la langue du destinateur ou dans un format d'dchange standard (IF = Interchange Format) et enfin un module de synth6se de la parole (et de gdndration si on utilise le format IF) dans la langue cible du

rReconnaissance Traduction la instantan_._____~ ) ~ ,___~de parole ._J

!/
(Reconnaissance'~_~ T r a d u c t i o n ' ~ ~ ~. instantan6 __) ~. de la p a r o l e )
Fig. 1. L'architecture d'un syst~me de traduction instantan~e.

36

destinateur. Dans le cadre du projet C-STAR II nous avons en charge la conception et la rdalisation du module de reconnaissance de la parole continue h grand vocabulaire pour le fiangais. Nous collaborons avec l'6quipe GETA du laboratoire CLIPS-IMAG et le laboratoire LATL pour la traduction automatique et le laboratoire LAIP pour la synth~se de la parole. Ce consortium s'est fix6 l'objeetif de r6aliser un syst6me de traduction de I'oral pour le frangais. Dans cet article nous allons tout d'abord presenter l'architecture du syst6me de traduction et la plate-forme de ddveloppement JANUS-III [2], puis les diff6rentes 6tapes du d6veloppement du module RAPHAEL et enfin, les premiers rdsultats obtenus. 1 R A P H A E L p o u r la T r a d u e t i o n L'architecture du syst6me de traduction de parole est compos6e de trois modules essentiels (la reconnaissance, la traduction et la synth~se de la parole) [Fig. 2]. Dans ee projet nous utilisons ARIANE et GB [3] pour la traduction ct LAIP-TTS [4] pour la synth6se. Le

point de vue de la robustesse) nous envisageons l'intdgration d'une seconde couche de contr61e pour permettre le <<rescoring >> des hypoth6ses en tenant compte des taux de confiance associds aux diff6rents mots de l'dnoncd reconnu.

1.1

Plate-forme de J A N U S I l l

I

Recolmaissance la Parole ] de RAPIIAEL(CLIPS/IMAG-ISL) Texte
V

Contr61e

Cette plate-forme de traduction a dtd ddvelopp6e dans le laboratoire d'ISL des universitds Carnegie Mellon et Karlsruhe et contient tous les composants ndcessaires au ddveloppement d'un syst6me de reconnaissance phondmique/t grand vocabulaire h base de Cha~nes de Markov Cach6es (CMC) et de rdseaux de neurones. La facilitd d'dcrire un module de reconnaissance en langage Tcl/Tk avec JANUS-III nous permet d'adapter ses capacitds selon les besoins d'application et les caractdristiques du frangais. De cette plate-forme, seul le moteur de reconnaissance est directement exploit& Mais le travail de pr6paration des bases de donndes, l'apprentissage des mod6les de phon6mes, l'dvaluation sont dgalement effectuds dans cet environnement de programmation. Le langage PERL est en grand partie utilisd parall61ement pour traitement du texte du corpus. Les d6tails techniques de JANUS-III sont donnds dans [2], [5], [6]. Cependant nous en prdsentons bri6vement quelques points ci-apr6s. 2 Le Module RAPHAEL L'architecture du module de reconnaissance RAPHAEL est pr6sent6e sur la [Fig. 3]. L'analyse de la parole produit une suite de vecteurs de param6tres acoustiques. Ces vecteurs sont utilis6s par un moteur de recherche base de CMC pour estimer la suite des phon6mes 6nonc6s. Un mod61e de langage stochastique h bigramme et trigramme, et un dictionnaire des variantes phon6tiques sont en parall61e exploit6s pour restreindre le champ de recherche I. ALl cours de la recherche le dictionnaire phon6tique fournit le(s) phon6me(s) suivant(s). Le modble probabiliste de langage base de bigramme et de trigramme est utilis6 Iors de la transition entre deux mots pour fournir un ensemble de roots [Fig. 4]. 1 Avec 45 phon6mes en moyenne une suite de cinq phon6mes se transforme th6oriquement en un arbre de d6cision de 455 = 184,528,125 feuilles ! 37

~_~Traduction Automatique IANE(GETA),GB(I,ATL) J


I Synth~se la Parole de LA1P-~VI'S (LAII') 1 Fig.2. Lescomposantsdu syst~me
d6veloppement du module de reconnaissance RAPHAEL a dt6 effectu6 sur la plate-forme iogicielle de JANUS-Ill. RAPHAEL donne en sortie un treillis de roots sous le protocole TCP/IP. Le traducteur utilise ce rdsultat pour en donner une version traduite. Cette version est ensuite envoyde au synthdtiseur de la parole. Dans cet article nous nous int6resserons seulement au module de reconnaissance RAPHAEL. Pour l'instant la stratdgie d'dchange entre les modules est enti6rement sdquentielle. Afin d'amdliorer le rdsultat final (surtout du

~_~__~ Acquisitionde 1 la parole

I,

Base de donndesdes paramdtres ] des ChaTnesde Markov Cachdes

J
~Z%%? ' o

I Traitementnumdrique,Estimationdes param~tresacoustiques ~ ModUlestochastiquede langage (bigrammeet trigramme)

Chainesde MarkovCachdespour la reconnaissancephondmique Dictionnairephondtique Dict (vocabulaire de reconnaissance)

Fig. 3. Sehdmadu modulede reconnaissance phondmiqueRAPHAEL.
2.1 C
h a i n e d e M a r k o v Cachdes cet alignement l'algorithme de Baum-Welch [5] procdde ~ l'estimation des paramdtres de chaque CMC prdsente dans la cha~ne. Ce procddd est rdpdt6 pour tous les 6noncds du corpus d'apprentissage et cela plusieurs fois. La prdsence des diffdrents contextes phondmiques permet /i ce procdd6 de minimiser le taux d'erreur de reconnaissance. L'dvaluation du taux d'erreur /l la fin de chaque itdration permet d'dtudier l'avancement de l'apprentissage.

Pour utiliser les CMC il faut conduire une phase d'apprentissage prdalable dans laquelle on adapte les probabilitds des transitions et des symboles sortis pour un phondme donnd de manidre ii ce que la probabilit6 du processus associd soit maximale. Les paramdtres des moddles et la transcription phondtique des 6noncds du corpus sont deux 616ments essentiels d'apprentissage. RAPHAEL comporte 45 CMC reprdsentant 42 phondmes de base du fran~ais et 3 moddles pour le silence et le bruit. A quelques exceptions prds les CMC se composent de trois 6tats. Le vecteur de paramdtres d'entrde est de dimension 122. Les CMC ont 16 distributions Gaussiennes pour chaque dtat. Lots de l'apprentissage nous produisons la transcription phondtique correspondante chaque dnoncd (cela se fait ~ l'aide du dictiomaaire phondtique). Pour chaque 6nonc~ les CMC correspondant aux phondmes sont concatdndes pour crder une longue chaine. Ensuite i'algorithme de Viterbi [5] propose un alignement de I'dnoncd avec cette chaine. Avec

2.2

Mod/~lede iangage stochastique

2 Les
coefficients MFCC [5] d'ordre 16 sont calculds sur une trame de 16 ms de parole, avec un pas d'avancement de 10ms. La parole est 6chantillonnde /l 16 kHz et sur 16 bits. Les MFCC, l'dnergie du signal, et leurs premiere et seconde ddrivdes (51 valeurs) subissent ensuite une analyse en composantes principales (ACP) pour rdduire la dimension du vecteur /l 12. La matrice d'ACP est calculde avant la phase d'apprentissage, sur un grand corpus enregistrd. 38

Afin de rdduire le champ de recherche, un moddle de langage doit ~tre utilisd. Bien que dans les systdmes /i commande vocale qui utilisent une syntaxe rdduite les grammaires finies ou rdcurrentes peuvent ~tre utilisdes, ceiles-ci ne sont pas capables de ddcrire tousles phdnomdnes de la langue par[de (ellipses, hdsitations, rdpdtitions, etc.). Pour cette raison il est souhaitable d'utiliser un moddle stochastique qui estime dans un contexte donnd, la probabilit6 de succession des mots. Dans le moddle actuel les contextes gauches d'ordres un et deux (bigramme et trigramme) Sont en marne temps exploitds. Le bigramme est utilisd dans la premidre phase de recherche pour crder un treillis de mots, puis le trigramme est utilisd pour raffiner le rdsultat et ddterminer les N meilleurs phrases plausibles. Le moddle de langage se charge en m~me temps de ia rdsolution de l'aceord en frangais. Le calcui des paramdtres de ce moddle a dt6 effectual /t partir des corpus enregistrds et transcrits. Dans l'6tat actuel un vocabulaire de 7000 mots a dt6 sdlectionnd.

-..

-

L'hypoth6se e mot #1

--:~,.

L'hypoth6se de mot #2

Repr6sentation d'un phoneme

Dans un mot le dictionnaire phon6tique est utilis6 pour trouver et enchMner les phonemes suivants selon les variantes phon6tiques disponibles.

Pour d6terminer les roots et les phon6mes suivants le module stochastique du langage et le vocabulairc transcrit en phon6tique sont en m6me temps utilis6s.

Fig. 4. Representation de I'algorithme de recherche

2.3 Dictionnaire
Phon~tique
La conversion d'une chMne d'hypoth~ses phon6tiques en une chMne orthographique se fair ~t partir d'un dictionnaire phon6tique. Pour couvrir un grand nombre de prononciations diff&entes dues aux diff&ents dialectes de la langue et aux habitudes des locuteurs, ce dictionnaire contient pour chaque mot un ensemble de variantes phon6tiques. A chaque hypoth6se de mot propos6 par le mod61e de langage on associe cet ensemble de variantes. Ind6pendamment donc de la variante utilis6e dans 1'6nonc6, nous obtenons la m6me transcription orthographique. Nous utilisons sp6cifiquement cette technique pour couvrir les variantes produites par ia liaison, par exemple : Je suis parti de la maison. Je suis all~ h la maison. 3 (Z& sHi paRti ...) (Z& sHiz ale ...)

ensemble de BREF-80 comprenant les 6nonc6s de 4 femmes et 4 hommes a 6t6 utilis6 pour l'6valuation 4. Le vocabulaire a 6t6 transcrit soit manuellement, soit ~ partir du dictionnaire phon6tique BDLEX-23000. Le module de langage a 6t6 estim6 fi partir de BREF-80 et un corpus de texte d'~ peu pr6s 10 millions de mots extrait du journal Le Monde. Pour l'initialisation des CMC, au lieu d'utiliser les valeurs al6atoires (technique habituelle), nous avons choisi d'utiliser les mod61es issus du projet GlobalPhone [7]. Pour chaque phon6me de notre module nous avons manuellement choisi un phon6me dans une des langues support6es par GlobalPhone (principalement allemande) et nous avons utilis6 ses param6tres comme valeurs initiales de nos CMC. Ensuite ces mod61es ont 6t6 adapt6s au frangais au moyen de l'algorithme d'apprentissage d6crit en 2.1. A la fin de chaque it6ration et ce pour 3

L'apprentissage
4 Les
sous-corpus de l'apprentissage et de l'6valuation n'ont aucun 6nonc6 et locuteur en commun. En r6alit6, nous avons enlev6 tousles 6nonc6s en communs entre ces deux sous corpus. Ainsi le sous-corpus d'apprentissage comprend 4854 6nonc6s et le sous-corpus d'6valuation 371 6nonc6s. Nous avons retir6 105 6noncds pour assurer la disjonction des deux sous-corpus. 39

Le corpus BREF-80 [8] comportant 5330 6nonc6s par 80 locuteurs (44 femmes et 36 hommes) 3 a 6t6 utilis6 pour les phases d'apprentissage et d'6valuation. Un sous3 BREF-80 contient 3747 textes diff6rents et environ 150,000 mots.

it6rations, le syst~me a 6t~ 6valu6 avec le sous corpus de l'6valuation.

4 R6sultats
Les r6sultats d'dvaluation en terme de taux de reconnaissance sont donn6s dans le [Tableau 1]. Systdmes M0dbles issus de GlobalPhone Premiere it6ration Troisi6me it6ration % mots reconnus 29 88,8 91,1

Tableau 1. Les r6sultats de 1'6valuation

4.1

Commentaires

obtenus. Notre but est d'am61iorer le taux de reconnaissance par l'utilisation des mod61es phon6tiques contextuels et d'61argir le vocabulaire utilis6/t plus de 10000 mots. Pour atteindre ce but nous allons sp6cialiser le vocabulaire dans le domaine du tourisme et utiliser d'autres corpus de la parole spontan6e dans ce domaine avec un nombre plus important de locuteurs. En mfime temps nous d6finirons un protocole d'6change plus 61abor6 avec le module de traduction afin de permettre la communication d'informations linguistiques et statistiques au module de traduction, toujour dans le but d'amdliorer les performances de notre syst6me.

Une tr6s bonne initialisation de certaines consonnes identiques dans des diff6rentes langues (p, t, k, b, d, g, etc.) a rapidement permis d'obtenir un syst6me fonctionnel. On constate une saturation tr6s rapide du taux de reconnaissance d6s la troisi+me it6ration. Nous pouvons distinguer trois types de probl6me qui nous empachent d'atteindre un meilleur taux de reconnaissance :  Fautes de frappe dans le texte du corpus,  Transcription erron6e ou insuffisamment d6taill6e des ~noncds, ,, La couverture partielle de toutes les variantes phon6tiques d'un mot. Ces trois probl~mes sont les causes d'un grand nombre d'erreurs d'alignement qui vont directement influencer le r6sultat final. Nous devons donc effectuer une v6rification compl6te du corpus et du dictionnaire phon6tique. Les mots hors du vocabulaire sont fi l'origine d'un pourcentage important d'erreurs. En effet, dans 371 6noncds du sous-corpus de l'6valuation nous rencontrons environ 300 mots hors vocabulaire. Ces mots repr6sentent environ 3,5 % de la taille du vocabulaire. I I n e sont pas reprdsentds dans le corpus d'apprentissage et leur transcription n'existe pas dans le dictionnaire phon6tique.

Remerciement
Nous remercions Alex Waibel pour la mise /t disposition de JANUS-III et Tanja Schultz pour son support scientifique et technique dans l'utilisation des r6sultats du projet GlobalPhone.

References

1 Hutchins
W. J. (1986) Machine Translation : Past, Present, Future. Ellis Horwood, John Wiley & Sons, Chichester, England, 382 p. 

2 Finke
M., Geutner P., Hild H., Kemp T., Ries K., Westphal M. (1997) : The KarlsruheVerbmobil Speech Recognition Engine, Proc. of ICASSP, Munich, Germany. 
																		
3 Boitet
Ch., (1986) GETA's MTmethodology and a blueprint for its adaptation to speech translation within C-STARI1, ATR International Workshop on Speech Translation, Kyoto, Japan. 

4 Keller, E. (1997). Simplification of TTS architecture versus Operational quality, Proceedings of EuroSpeech'97, Rhodes, Greece. 

5 Rabiner
L., Juang B.H. (1993), Fundamentals of Speech Recognition, Prentice Hall, 507 p. 

6 Haton
J.P., Pierrel J.M., Perennou G., Caelen J., Gauvain J.L. (1991), Reconnaissance automatique de laparole, BORDAS, Paris, 239 p. 

Schultz T. Waibel A., Fast Bootstrapping of LVCSR systems with multilingual phonem sets, Proceedings of EuroSpeech'97, Rhodes, Greece. 

Lamel L.F., Gauvain J.L., Eskenazi M. (1991), BREF, a Large Vocabulary Spoken Colpus for French, Proceedings of. EuroSpeech'91, Genoa, Italy.
References 1 Appelt D.
and Israel D.
(1999). Introduction to Information Extraction Technology.
(IJCAI-99) Tutorial, Stockholm, Sweden (available at: http://www.ai.sri.
com/~appelt/ie-tutorial/) 2 Masayuki Asahara, Yuji Matsumoto, Extended models and tools for high-performance part-of-speech tagger, Proceedings of the 18th conference on Computational linguistics, p.21-27, July 31-August 04, 2000, Saarbrcken, Germany 3 Frdric Bchet, Alexis Nasr, Franck Genet, Tagging unknown proper names using decision trees, Proceedings of the 38th Annual Meeting on Association for Computational Linguistics, p.77-84, October 03-06, 2000, Hong Kong 4 Daniel M.
Bikel, Scott Miller, Richard Schwartz, Ralph Weischedel, Nymble: a high-performance learning name-finder, Proceedings of the fifth conference on Applied natural language processing, p.194-201, March 31-April 03, 1997, Washington, DC 5 Andrew Eliot Borthwick, Ralph Grishman, A maximum entropy approach to named entity recognition, 1999 6 Collins M.
and Singer Y.
(1999) Unsupervised models for named entity classification.
In Proceedings of EMNLP/WVLC, 1999, MA, pp.
189--196. 7 Cucchiarelli A.
and Velardi P.
(1999) Adaptability of linguistic resources to new domains: an experiment with proper noun dictionaries.
In Proceedings of the Vextal Conference, Venice, Italy, pp.
25--30. 8 Andrei Mikheev, Marc Moens, Claire Grover, Named Entity recognition without gazetteers, Proceedings of the ninth conference on European chapter of the Association for Computational Linguistics, June 08-12, 1999, Bergen, Norway 9 Raymond J.
Mooney, Induction Over the Unexplained: Using Overly-General Domain Theories to Aid Concept Learning, Machine Learning, v.10 n.1, p.79-110, Jan.
1993 10 MUC-6 (1995) Proceedings of the Sixth Message Understanding Conference (DARPA), Morgan Kaufmann Publishers, San Francisco.
11 Poibeau
T and Kosseim L.
(2001) Proper-name Extraction from Non-Journalistic Texts.
Proceeding of the 11th Conference Computational Linguistics in the Netherlands, Tilburg.
Netherlands, Rodopi.
12 Satoshi
Sekine, Yoshio Eriguchi, Japanese named entity extraction evaluation: analysis of results, Proceedings of the 18th conference on Computational linguistics, July 31-August 04, 2000, Saarbrcken, Germany 13 Silberztein M.
(1993) Dictionnaires lectroniques.
Masson, Paris.
14 David
Yarowsky, Unsupervised word sense disambiguation rivaling supervised methods, Proceedings of the 33rd annual meeting on Association for Computational Linguistics, p.189-196, June 26-30, 1995, Cambridge, Massachusetts
References 1 Benson, M.
(1990). Collocations and general-purpose dictionaries.
International Journal of Lexicography, 3(1), 23--35.
2 Peter
F.
Brown, Jennifer C.
Lai, Robert L.
Mercer, Aligning sentences in parallel corpora, Proceedings of the 29th annual meeting on Association for Computational Linguistics, p.169-176, June 18-21, 1991, Berkeley, California 3 Catizone R., Russell G., and Warwick S.
(1989). Deriving Translation Data from Bilingual Texts.
In Proceedings of the First International Lexical Acquisition Workshop, Detroit.
4 Church, K., Gale, W., Hanks, P., and Hindle, D.
(1991). Using Statistics in Lexical Analysis.
In Zernick, U.
(ed.), Lexical Acquisition: Exploiting On-Line Resources to Build a Lexicon, Lawrence Erlbaum Associates, pp.
115--164. 5 Ted Dunning, Accurate methods for the statistics of surprise and coincidence, Computational Linguistics, v.19 n.1, March 1993 6 William A.
Gale, Kenneth W.
Church, A program for aligning sentences in bilingual corpora, Computational Linguistics, v.19 n.1, March 1993 7 Gross, G.
(1996). Les expressions figes en franais.
OPHRYS, Paris.
8 Pierre
Isabelle, Marc Dymetman, George Foster, Jean-Marc Jutras, Elliott Macklovitch, Francois Perrault, Xiaobo Ren, Michel Simard, Translation analysis and translation automation, Proceedings of the 1993 conference of the Centre for Advanced Studies on Collaborative research: distributed computing, October 24-28, 1993, Toronto, Ontario, Canada 9 Laenzlinger, C.
and Wehrli, E.
(1991). Fips, un analyseur interactif pour le franais.
TA informations, 32(2): 35--49.
10 Christopher
D.
Manning, Hinrich Schtze, Foundations of statistical natural language processing, MIT Press, Cambridge, MA, 1999 11 Melby A.
(1982). A Bilingual Concordance System and its Use in Linguistic Studies.
In Proceedings of the Eighth LACUS Forum, Columbia, SC, pp.
541--549. 12 Romary L.
and Bonhomme P.
(2000). Parallel alignment of structured documents.
Vronis J.
(Ed.). Parallel Text Processing.
Dordrecht: Kluwer.
13 Michel
Simard, George F.
Foster, Pierre Isabelle, Using cognates to align sentences in bilingual corpora, Proceedings of the 1993 conference of the Centre for Advanced Studies on Collaborative research: distributed computing, October 24-28, 1993, Toronto, Ontario, Canada 14 Frank Smadja, Retrieving collocations from text: Xtract, Computational Linguistics, v.19 n.1, March 1993 15 Eric Wehrli, Parsing and Collocations, Proceedings of the Second International Conference on Natural Language Processing, p.272-282, June 02-04, 2000
Classifying Biological Full-Text Articles for Multi-Database Curation Wen-Juan Hou, Chih Lee and Hsin-Hsi Chen Department of Computer Science and Information Engineering, National Taiwan University, Taipei, Taiwan {wjhou, clee}@nlg.csie.ntu.edu.tw; hhchen@csie.ntu.edu.tw Abstract In this paper, we propose an approach for identifying curatable articles from a large document set.
This system considers three parts of an article (title and abstract, MeSH terms, and captions) as its three individual representations and utilizes two domain-specific resources (UMLS and a tumor name list) to reveal the deep knowledge contained in the article.
An SVM classifier is trained and cross-validation is employed to find the best combination of representations.
The experimental results show overall high performance.
Track (http://ir.ohsu.edu/genomics) of TREC 2004 and 2005 organized categorization tasks.
The former focused on simplified GO terms while the latter included the triage for "tumor biology", "embryologic gene expression", "alleles of mutant phenotypes" and "GO" articles.
The increase of the numbers of participants at Genomics Track shows that biological classification problems attracted much attention.
This paper employs the domain-specific knowledge and knowledge learned from full-text articles to classify biological text.
Given a collection of articles, various methods are explored to extract features to represent a document.
We use the experimental data provided by the TREC 2005 Genomics Track to evaluate different methods.
The rest of this paper is organized as follows.
Section 2 sketches the overview of the system architecture.
Section 3 specifies the test bed used to evaluate the proposed methods.
The details of the proposed system are explained in Section 4.
The experimental results are shown and discussed in Section 5.
Finally, we make conclusions and present some further work.
1 Introduction
Organism databases play a crucial role in genomic and proteomic research.
It stores the up-to-date profile of each gene of the species interested.
For example, the Mouse Genome Database (MGD) provides essential integration of experimental knowledge for the mouse system with information annotated from both literature and online sources (Bult et al., 2004).
To provide biomedical scientists with easy access to complete and accurate information, curators have to constantly update databases with new information.
With the rapidly growing rate of publication, it is impossible for curators to read every published article.
Since fully automated curation systems have not met the strict requirement of high accuracy and recall, database curators still have to read some (if not all) of the articles sent to them.
Therefore, it will be very helpful if a classification system can correctly identify the curatable or relevant articles in a large number of biological articles.
Recently, several attempts have been made to classify documents from biomedical domain (Hirschman et al., 2002).
Couto et al.(2004) used the information extracted from related web resources to classify biomedical literature.
Hou et al.(2005) used the reference corpus to help classifying gene annotation.
The Genomics System Overview Figure 1 shows the overall architecture of the proposed system.
At first, we preprocess each training article, and divide it into three parts, including (1) title and abstract, (2) MeSH terms assigned to this article, and (3) captions of figures and tables.
They are denoted as "Abstract", "MeSH", and "Caption" in this paper, respectively.
Each part is considered as a representation of an article.
With the help of domain-specific knowledge, we obtain more detail representations of an article.
In the model selection phase, we perform feature ranking on each representation of an article and employ cross-validation to determine the number of features to be kept.
Moreover, we use cross-validation to obtain the best combination of all the representations.
Finally, a support vector machine (SVM) (Vapnik, 1995; Hsu et al., 2003) classifier is obtained.
Abstract AbsSEM/TM Full-Text Training Articles Preprocessing MeSH MeSHSEM Model Selection Caption CapSEM/TM Domain-Specific Knowledge A New Full-Text Article Preprocessing Multiple Parts PartsSEM/TM SVM Classifier Yes/No Figure 1.
System Architecture Experimental Data We train classifiers for classifying biomedical articles on the Categorization Task of the TREC 2005 Genomics Track.
The task uses data from the Mouse Genome Informatics (MGI) system (http://www.informatics.jax.org/) for four categorization tasks, including tumor biology, embryologic gene expression, alleles of mutant phenotypes and GO annotation.
Given a document and a category, we have to identify whether it is relevant to the given category.
The document set consists of some full-text data obtained from three journals, i.e., Journal of Biological Chemistry, Journal of Cell Biology and Proceedings of the National Academy of Science in 2002 and 2003.
There are 5,837 training documents and 6,043 testing documents.
Methods Document Preprocessing In the preprocessing phase, we perform acronym expansion on the articles, remove the remaining tags from the articles and extract three parts of interest from each article.
Abbreviations are often used to replace long terms in writing articles, but it is possible that several long terms share the same short form, especially for gene/protein names.
To avoid ambiguity and enhance clarity, the acronym expansion operation replaces every tagged abbreviation with its long form followed by itself in a pair of parentheses.
4.2 Employing
Domain-Specific Knowledge can identify the gene names contained in an article.
Moreover, by further consulting organism databases, we can get the properties of the genes.
Two domain-specific resources are exploited in this study.
One is the Unified Medical Language System (UMLS) (Humphreys et al., 1998) and the other is a list of tumor names obtained from Mouse Tumor Biology Database (MTB)1.
UMLS contains a huge dictionary of biomedical terms  the UMLS Metathesaurus and defines a hierarchy of semantic types  the UMLS Semantic Network.
Each concept in the Metathesaurus contains a set of strings, which are variants of each other and belong to one or more semantic types in the Semantic Network.
Therefore, given a string, we can obtain a set of semantic types to which it belongs.
Then we obtain another representation of the article by gathering the semantic types found in the part of the article.
Consequently, we get another three much deeper representations of an article after this step.
They are denoted as "AbstractSEM", "MeSHSEM" and "CaptionSEM".
We use the list of tumor names on the Tumor task.
We first tokenize all the tumor names and stem each unique token.
With the resulting list of unique stemmed tokens, we use it as a filter to remove the tokens not in the list from the "Abstract" and "Caption", which produce "AbstractTM" and "CaptionTM".
4.3 Model
Selection As mentioned above, we generate several representations for an article.
In this section, we explain how feature selection is done and how the best combination of the representations With the help of domain-specific knowledge, we can extract the deeper knowledge in an article.
For example, with a gene name dictionary, we fiof an article is obtained.
For each representation, we first rank all the tokens in the training documents via the chi-square test of independence.
Postulating the ranking perfectly reflects the effectiveness of the tokens in classification, we then decide the number of tokens to be used in SVM classification by 4-fold cross-validation.
In cross-validation, we use the TF*IDF weighting scheme.
Each feature vector is then normalized to a unit vector.
We set C+ to ur* Cbecause of the relatively small number of positive examples, where C+ and Care the penalty constants on positive and negative examples in SVMs.
After that, we obtain the optimal number of tokens and the corresponding SVM parameters Cand gamma, a parameter in the radial basis kernel.
In the rest of this paper, "Abstract30" denotes the "Abstract" representation with top-30 tokens, "CaptionSEM10" denotes "CaptionSEM" with top-10 tokens, and so forth.
After feature selection is done for each representation, we try to find the best combination by the following algorithm.
Given the candidate representations with selected features, we start with an initial set containing some or zero representation.
For each iteration, we add one representation to the set by picking the one that enhances the cross-validation performance the most.
The iteration stops when we have exhausted all the representations or adding more representation to the set doesn't improve the cross-validation performance.
For classifying the documents with better features, we run the algorithm twice.
We first start with an empty set and obtain the best combination of the basic three representations, e.g., "Abstract10", "MeSH30" and "Caption10".
Then, starting with this combination, we attempt to incorporate the three semantic representations, e.g., "Abstract30SEM", "MeSH30SEM" and "Caption10SEM", and obtain the final combination.
Instead of using this algorithm to incorporate the "AbstractTM" and "CaptionTM" representations, we use them to replace their unfiltered counterparts "Abstract" and "Caption" when the cross-validation performance is better.
Results and Discussions Utility (NU)2 measure).
For category Allele, "Caption" and "AbstractSEM" perform the best among the basic and semantic representations, respectively.
For category Expression, "Caption" plays an important role in identifying relevant documents, which agrees with the finding by the winner of KDD CUP 2002 task 1 (Regev et al., 2002).
Similarly, MeSH terms are crucial to the GO category, which are used by top-performing teams (Dayanik et al., 2004; Fujita, 2004) in TREC Genomics 2004.
For category Tumor, MeSH terms are important, but after semantic type extraction, "AbstractSEM" exhibits relatively high cross-validation performance.
Since only 10 features are selected for the "AbstractSEM", using this representation alone may be susceptible to over-fitting.
Finally, by comparing the performance of the "AbstractTM" and "Abstract", we find the list of tumor names helpful for filtering abstracts.
We list the results for the test data in Table 2.
Column "Experiment" identifies our proposed methods.
We show six experiments in Table 2: one for Allele (AL), one for Expression (EX), one for GO (GO) and three for Tumor (TU, TN and TS).
Column "cv NU" shows the cross-validation NU measure, "NU" shows the performance on the test data and column "Combination" lists the combination of the representations used for each experiment.
In this table, "M30" is the abbreviation for "MeSH30", "CS10" is for "CaptionSEM10", and so on.
The combinations for the first 4 experiments, i.e., AL, EX, GO and TU, are obtained by the algorithm described in Section 4.3, while the combination for TN is obtained by substituting "AbstractTM30" for "Abstract30" in the combination for TU.
The experiment TS only uses the "AbstractSEM10" because its cross-validation performance beats all other combinations for the Tumor category.
The combinations of the first 5 experiments illustrate that adding other inferior representations to the best one enhances the performance, which implies that the inferior ones may contain important exclusive information.
The cross-validation performance fairly predicts the performance on the test data, except for the last experiment TS, which relies on only 10 features and is therefore susceptible to over-fitting.
Table 1 lists the cross-validation results of each representation for each category (in Normalized Please refer to the TREC 2005 Genomics Track Protocol (http://ir.ohsu.edu/genomics/2005protocol.html).
Abstract MeSH Caption AbstractSEM MeSHSEM CaptionSEM AbstractTM CaptionTM Table 1.
Partial Cross-validation Results.
Experiment AL (for Allele) EX (for Expression) GO (for GO) TU (for Tumor) TN (for Tumor) TS (for Tumor) cv NU 0.8717 0.7691 0.5402 0.8742 0.8764 0.8814 NU 0.8423 0.7515 0.5332 0.8299 0.8747 0.5699 Recall 0.9488 0.8190 0.8803 0.9000 0.9500 0.6500 Precision 0.3439 0.1593 0.1873 0.0526 0.0518 0.0339 F-score 0.5048 0.2667 0.3089 0.0994 0.0982 0.0645 Combination M30+C10+A10+CS10+AS10+MS10 M10+C10+CS10+MS10 M10+C10+MS10 M30+C30+A30+AS10+CS30 M30+C30+AT30+AS10+CS30 AS10 Table 2.
Evaluation Results.
Subtask Allele Expression GO Annotation Tumor NU (Best/Median) 0.8710/0.7773 0.8711/0.6413 0.5870/0.4575 0.9433/0.7610 Recall (Best/Median) 0.9337/0.8720 0.9333/0.7286 0.8861/0.5656 1.0000/0.9500 Precision (Best/Median) 0.4669/0.3153 0.1899/0.1164 0.2122/0.3223 0.0709/0.0213 F-score (Best/Median) 0.6225/0.5010 0.3156/0.2005 0.3424/0.4107 0.1325/0.0417 Table 3.
Best and Median Results for Each Subtask on TREC 2005 (Hersh et al., 2005).
To compare with our performance, we list the best and median results for each subtask on the genomics classification task of TREC 2005 in Table 3.
Comparing to Tables 2 and 3, it shows our experimental results have overall high performance.
Conclusions and Further Work In this paper, we demonstrate how our system is constructed.
Three parts of an article are extracted to represent its content.
We incorporate two domain-specific resources, i.e., UMLS and a list of tumor names.
For each categorization work, we propose an algorithm to get the best combination of the representations and train an SVM classifier out of this combination.
Evaluation results show overall high performance in this study.
Except for MeSH terms, we can try other sections in the article, e.g., Results, Discussions and Conclusions as targets of feature extraction besides the abstract and captions in the future.
Finally, we will try to make use of other available domain-specific resources in hope of enhancing the performance of this system.
Acknowledgements Research of this paper was partially supported by National Science Council, Taiwan, under the contracts NSC94-2213-E-002-033 and NSC94-2752-E-001-001-PAE.
References Bult, C.
J., Blake, J.
A., Richardson, J.
E., Kadin, J.
A., Eppig, J.
T. and the Mouse Genome Database Group.
The Mouse Genome Database (MGD): Integrating Biology with the Genome.
Nucleic Acids Research, 32, D476D481, 2004.
Couto, F.
M., Martins, B.
and Silva, M.
J . Classifying Biological Articles Using Web Resources.
Proceedings of the 2004 ACM Symposium on Applied Computing, 111-115, 2004.
Dayanik, A., Fradkin, D., Genkin, A., Kantor, P., Lewis, D.
D., Madigan, D.
and Menkov, V . DIMACS at the TREC 2004 Genomics Track.
Proceedings of the Thirteenth Text Retrieval Conference, 2004.
Fujita, S., . Revisiting Again Document Length Hypotheses TREC-2004 Genomics Track Experiments at Patolis.
Proceedings of the Thirteenth Text Retrieval Conference, 2004.
Hersh, W., Cohen, A., Yang, J., Bhuptiraju, R.T., Toberts, P.
and Hearst, M . TREC 2005 Genomics Track Overview.
Proceedings of the Fourteenth Text Retrieval Conference, 2005.
Hirschman, L., Park, J., Tsujii, J., Wong, L.
and Wu, C.
H . Accomplishments and Challenges in Literature Data Mining for Biology.
Bioinformatics, 18(12): 1553-1561, 2002.
Hou, W.
J., Lee, C., Lin, K.
H. Y.
and Chen, H.
H . A Relevance Detection Approach to Gene Annotation.
Proceedings of the First International Symposium on Semantic Mining in Biomedicine, http://ceur-ws.org, 148: 15-23, 2005.
Hsu, C.
W., Chang, C.
C. and Lin, C.
J . A Practical Guide to Support Vector Classification.
http://www.csie.ntu.edu.tw /~cjlin/libsvm/index.html, 2003.
Humphreys, B.
L., Lindberg, D.
A., Schoolman, H.
M. and Barnett, G.
O . The Unified Medical Language System: an Informatics Research Collaboration.
Journal of American Medical Information Association, 5(1):1-11, 1998.
Regev, Y., Finkelstein-Landau, M.
and Feldman, R . Rule-based Extraction of Experimental Evidence in the Biomedical Domain the KDD Cup (Task 1).
SIGKDD Explorations, 4(2):90-92, 2002.
Vapnik, V . The Nature of Statistical Learning Theory, Springer-Verlag, 1995 .
Multidocument Summarization via Information Extraction Michael White and Tanya Korelsky CoGenTex, Inc.
Ithaca, NY Claire Cardie, Vincent Ng, David Pierce, and Kiri Wagstaff Department of Computer Science Cornell University, Ithaca, NY mike,tanya@cogentex.com We present and evaluate the initial version of RIPTIDES, a system that combines information extraction, extraction-based summarization, and natural language generation to support userdirected multidocument summarization.
IE system and the Summarizer in turn.
2.1 IE
System The domain for the initial IE-supported summarization system and its evaluation is natural disasters.
Very briefly, a top-level natural disasters scenario template contains: document-level information (e.g.
docno, date-time); zero or more agent elements denoting each person, group, and organization in the text; and zero or more disaster elements.
Agent elements encode standard information for named entities (e.g.
name, position, geo-political unit).
For the most part, disaster elements also contain standard event-related fields (e.g.
type, number, date, time, location, damage sub-elements).
The final product of the RIPTIDES system, however, is not a set of scenario templates, but a user-directed multidocument summary.
This difference in goals influences a number of template design issues.
First, disaster elements must distinguish different reports or views of the same event from multiple sources.
As a result, the system creates a separate disaster event for each such account.
Disaster elements should also include the reporting agent, date, time, and location whenever possible.
In addition, damage elements (i.e.
human and physical effects) are best grouped according to the reporting event.
Finally, a slight broadening of the IE task was necessary in that extracted text was not constrained to noun phrases.
In particular, adjectival and adverbial phrases that encode reporter confidence, and sentences and clauses denoting relief effort progress appear beneficial for creating informed summaries.
Figure 2 shows the scenario template for one of 25 texts tracking the 1998 earthquake in Afghanistan (TDT2 Topic 89).
The texts were also manually annotated for noun phrase coreference; any phrase involved in a coreference relation appears underlined in the running text.
The RIPTIDES system for the most part employs a traditional IE architecture [4].
In addition, we use an in-house implementation of the TIPSTER architecture [8] to manage all linguistic annotations.
A preprocessor first finds sentences and tokens.
For syntactic analysis, we currently use the Charniak [5] parser, which creates Penn Treebank-style parses [9] rather than the partial parses used in most IE systems.
Output from the parser is converted automatically into TIPSTER parse and part-of-speech annotations, which are added to the set of linguistic annotations for the document.
The extraction phase of the system identifies domain-specific relations among relevant entities in the text.
It relies on Autoslog-XML, an XSLT implementation of the Autoslog-TS system [12], to acquire extraction patterns.
Autoslog-XML is a weakly supervised learning system that requires two sets of texts for training -one set comprises texts relevant to the domain of interest and the other, texts not relevant Although recent years has seen increased and successful research efforts in the areas of single-document summarization, multidocument summarization, and information extraction, very few investigations have explored the potential of merging summarization and information extraction techniques.
This paper presents and evaluates the initial version of RIPTIDES, a system that combines information extraction (IE), extraction-based summarization, and natural language generation to support userdirected multidocument summarization.
(RIPTIDES stands for RapIdly Portable Translingual Information extraction and interactive multiDocumEnt Summarization).
Following [10], we hypothesize that IE-supported summarization will enable the generation of more accurate and targeted summaries in specific domains than is possible with current domain-independent techniques.
In the sections below, we describe the initial implementation and evaluation of the RIPTIDES IE-supported summarization system.
We conclude with a brief discussion of related and ongoing work.
Figure 1 depicts the IE-supported summarization system.
The system first requires that the user select (1) a set of documents in which to search for information, and (2) one or more scenario templates (extraction domains) to activate.
The user optionally provides filters and preferences on the scenario template slots, specifying what information s/he wants to be reported in the summary.
RIPTIDES next applies its Information Extraction subsystem to generate a database of extracted events for the selected domain and then invokes the Summarizer to generate a natural language summary of the extracted information subject to the user's constraints.
In the subsections below, we describe the fiuser information need Summarizer multi-document template merging event-oriented structure text collection IE System slot filler slot slot filler filler slot filler slotslot filler filler slot filler slot filler...
... slot filler slot filler filler slot slot filler slot filler slot filler ...
... slot filler slot filler scenario templates content selection event-oriented structure with slot importance scores A powerful earthquake struck Afghanistan on May 30 at 11:25...
Damage VOA (06/02/1998) estimated that 5,000 were killed by the earthquake, whereas AP (APW, 06/02/1998) instead reported ...
Relief Status NLG of summary CNN (06/02/1998): Food, water, medicine and other supplies have started to arrive.
[...] summary Figure 1.
RIPTIDES System Design to the domain.
Based on these and a small set of extraction pattern templates, the system finds a ranked list of possible extraction patterns, which a user then annotates with the appropriate extraction label (e.g.
victim). Once acquired, the patterns are applied to new documents to extract slot fillers for the domain.
Selectional restrictions on allowable slot fillers are implemented using WordNet [6] and BBN's Identifinder [3] named entity component.
In the current version of the system, no coreference resolution is attempted; instead, we rely on a very simple set of heuristics to guide the creation of output templates.
The disaster scenario templates extracted for each text are provided as input to the summarization component along with all linguistic annotations accrued in the IE phase.
No relief slots are included in the output at present, since there was insufficient annotated data to train a reliable sentence categorizer.
Selected News Excerpts, as shown in the two sample summaries appearing in Figures 3 and 4, and discussed further in Section 2.2.5 below.
2.2.1 Summarization
Stages The Summarizer produces each summary in three main stages.
In the first stage, the output templates are merged into an eventoriented structure, while keeping track of source information.
The merge operation currently relies on simple heuristics to group extracted facts that are comparable; for example, during this phase damage reports are grouped according to whether they pertain to the event as a whole, or instead to damage in the same particular location.
Heuristics are also used in this stage to determine the most relevant damage reports, taking into account specificity, recency and news source.
Towards the same objective but using a more surface-oriented means, simple word-overlap clustering is used to group sentences from different documents into clusters that are likely to report similar content.
In the second stage, a base importance score is first assigned to each slot/sentence based on a combination of document position, document recency and group/cluster membership.
The base importance scores are then adjusted according to user-specified preferences and matching 2.2 The Summarizer In order to include relief and other potentially relevant information not currently found in the scenario templates, the Summarizer extracts selected sentences from the input articles and adds them to the summaries generated from the scenario templates.
The extracted sentences are listed under the heading Document no.: ABC19980530.1830.0342 Date/time: 05/30/1998 18:35:42.49 Disaster Type: earthquake location: Afghanistan date: today magnitude: 6.9 magnitude-confidence: high epicenter: a remote part of the country PAKISTAN MAY BE PREPARING FOR ANOTHER TEST Thousands of people are feared dead following...
(voiceover) ...a powerful earthquake that hit Afghanistan today.
The quake registered 6.9 on the Richter scale, centered in a remote part of the country.
(on camera) Details now hard to come by, but reports say entire villages were buried by the quake.
human-effect: victim: Thousands of people number: Thousands outcome: dead confidence: medium confidence-marker: feared physical-effect: object: entire villages outcome: damaged confidence: medium confidence-marker: Details now hard to come by / reports say Figure 2.
Example scenario template for the natural disasters domain criteria.
The adjusted scores are used to select the most important slots/sentences to include in the summary, subject to the userspecified word limit.
In the third and final stage, the summary is generated from the resulting content pool using a combination of top-down, schema-like text building rules and surface-oriented revisions.
The extracted sentences are simply listed in document order, grouped into blocks of adjacent sentences.
(2) any intermediate estimates that are lower than the maximum estimate.1 In the content determination stage, scores are assigned to the derived information units based on the maximum score of the underlying units.
In the summary generation stage, a handful of text planning rules are used to organize the text for these derived units, highlighting agreement and disagreement across sources.
2.2.2 Specificity
of Numeric Estimates In order to intelligently merge and summarize scenario templates, we found it necessary to explicitly handle numeric estimates of varying specificity.
While we did find specific numbers (such as 3,000) in some damage estimates, we also found cases with no number phrase at all (e.g.
entire villages).
In between these extremes, we found vague estimates (thousands) and ranges of numbers (anywhere from 2,000 to 5,000).
We also found phrases that cannot be easily compared (more than half the region's residents).
To merge related damage information, we first calculate the numeric specificity of the estimate as one of the values NONE, VAGUE, RANGE, SPECIFIC, or INCOMPARABLE, based on the presence of a small set of trigger words and phrases (e.g.
several, as many as, from ...
to). Next, we identify the most specific current estimates by news source, where a later estimate is considered to update an earlier estimate if it is at least as specific.
Finally, we determine two types of derived information units, namely (1) the minimum and maximum estimates across the news sources, and 2.2.3 Improving the Coherence of Extracted Sentences In our initial attempt to include extracted sentences, we simply chose the top ranking sentences that would fit within the word limit, subject to the constraint that no more than one sentence per cluster could be chosen, in order to help avoid redundancy.
We found that this approach often yielded summaries with very poor coherence, as many of the included sentences were difficult to make sense of in isolation.
To improve the coherence of the extracted sentences, we have experimented with trying to boost coherence by favoring sentences in the context of the highest-ranking sentences over those with lower ranking scores, following the hypothesis that it is better to cover fewer topics in more depth than to change topics excessively.
In particular, we assign a score to a set of sentences by summing the base scores plus increasing coherence boosts for adjacent sentences, sentences that precede ones with an initial Less specific estimates such as "hundreds" are considered lower than more specific numbers such as "5000" when they are lower by more than a factor of 10.
Earthquake strikes Afghanistan A powerful earthquake struck Afghanistan last Saturday at 11:25.
The earthquake was centered in a remote part of the country and had a magnitude of 6.9 on the Richter scale.
Earthquake strikes quake-devastated villages in northern Afghanistan A earthquake struck quake-devastated villages in northern Afghanistan Saturday.
The earthquake had a magnitude of 6.9 on the Richter scale on the Richter scale.
Damage Estimates of the death toll varied.
VOA (06/02/1998) provided the highest estimate of 5,000 dead.
CNN (05/31/1998) and CNN (06/02/1998) supplied lower estimates of 3,000 and up to 4,000 dead, whereas APW (06/02/1998) gave the lowest estimate of anywhere from 2,000 to 5,000 dead.
People were injured, while thousands more were missing.
Thousands were homeless.
Quake-devastated villages were damaged.
Estimates of the number of villages destroyed varied.
CNN (05/31/1998) provided the highest estimate of 50 destroyed, whereas VOA (06/04/1998) gave the lowest estimate of at least 25 destroyed.
In Afghanistan, thousands of people were killed.
Damage Estimates of the death toll varied.
CNN (06/02/1998) provided the highest estimate of 4,000 dead, whereas ABC (06/01/1998) gave the lowest estimate of 140 dead.
In capital: Estimates of the number injured varied.
Selected News Excerpts CNN (06/01/98): Thousands are dead and thousands more are still missing.
Red cross officials say the first priority is the injured.
Getting medicine to them is difficult due to the remoteness of the villages affected by the quake.
PRI (06/01/98): We spoke to the head of the international red cross there, Bob McCaro on a satellite phone link.
He says it's difficult to know the full extent of the damage because the region is so remote.
There's very little infrastructure.
PRI (06/01/98): Bob McCaro is the head of the international red cross in the neighboring country of Pakistan.
He's been speaking to us from there on the line.
APW (06/02/98): The United Nations, the Red Cross and other agencies have three borrowed helicopters to deliver medical aid.
Figure 4.
200 word summary of actual IE output, with emphasis on Red Cross Further Details Heavy after shocks shook northern afghanistan.
More homes were destroyed.
More villages were damaged.
Landslides or mud slides hit the area.
Another massive quake struck the same region three months earlier.
Some 2,300 victims were injured.
Selected News Excerpts ABC (05/30/98): PAKISTAN MAY BE PREPARING FOR ANOTHER TEST Thousands of people are feared dead following...
ABC (06/01/98): RESCUE WORKERS CHALLENGED IN AFGHANISTAN There has been serious death and devastation overseas.
In Afghanistan...
CNN (06/02/98): Food, water, medicine and other supplies have started to arrive.
But a U.N. relief coordinator says it's a "scenario from hell".
Figure 3.
200 word summary of simulated IE output, with emphasis on damage cases.
We then perform a randomized local search for a good set of sentences according to these scoring criteria.
2.2.4 Implementation
The Summarizer is implemented using the Apache implementation of XSLT [1] and CoGenTex's Exemplars Framework [13].
The Apache XSLT implementation has provided a convenient way to rapidly develop a prototype implementation of the first two processing stages using a series of XML transformations.
In the first step of the third summary generation stage, the text building component of the Exemplars Framework constructs a "rough draft" of the summary text.
In this rough draft version, XML markup is used to partially encode the rhetorical, referential, semantic and morpho-syntactic structure of the text.
In the second generation step, the Exemplars text polishing component makes use of this markup to trigger surfacepronoun, and sentences that preceded ones with strongly connecting discourse markers such as however, nevertheless, etc.
We have also softened the constraint on multiple sampling from the same cluster, making use of a redundancy penalty in such fioriented revision rules that smooth the text into a more polished form.
A distinguishing feature of our text polishing approach is the use of a bootstrapping tool to partially automate the acquisition of application-specific revision rules from examples.
2.2.5 Sample
Summaries Figures 3 and 4 show two sample summaries that were included in our evaluation (see Section 3 for details).
The summary in Figure 3 was generated from simulated output of the IE system, with preference given to damage information; the summary in Figure 4 was generated from the actual output of the current IE system, with preference given to information including the words Red Cross.
While the summary in Figure 3 does a reasonable job of reporting the various current estimates of the death toll, the estimates of the death toll shown in Figure 4 are less accurate, because the IE system failed to extract some reports, and the Summarizer failed to correctly merge others.
In particular, note that the lowest estimate of 140 dead attributed to ABC is actually a report about the number of school children killed in a particular town.
Since no location was given for this estimate by the IE system, the Summarizer's simple heuristic for localized damaged reports -namely, to consider a damage report to be localized if a location is given that is not in the same sentence as the initial disaster description -did not work here.
The summary in Figure 3 also suffered from some problems with merging: the inclusion of a paragraph about thousands killed in Afghanistan is due to an incorrect classification of this report as a localized one (owing to an error in sentence boundary detection), and the discussion of the number of villages damaged should have included a report of at least 80 towns or villages damaged.
Besides the problems related to slot extraction and merging mentioned above, the summaries shown in Figures 3 and 4 suffer from relatively poor fluency.
In particular, the summaries could benefit from better use of descriptive terms from the original articles, as well as better methods of sentence combination and rhetorical structuring.
Nevertheless, as will be discussed further in Section 4, we suggest that the summaries show the potential for our techniques to intelligently combine information from many articles on the same natural disaster.
earlier version of the Summarizer uses the simulated output of the IE system as its input, including the relief annotations; in the second variant (RIPTIDES-SIM2), the current version of the Summarizer uses the simulated output of the IE system, without the relief annotations; and in the third variant (RIPTIDES-IE), the Summarizer uses the actual output of the IE system as its input.2 Summaries generated by the RIPTIDES variants were compared to a Baseline system consisting of a simple, sentence-extraction multidocument summarizer relying only on document position, recency, and word overlap clustering.
(As explained in the previous section, we have found that word overlap clustering provides a bare bones way to help determine what information is repeated in multiple articles, thereby indicating importance to the document set as a whole, as well as to help reduce redundancy in the resulting summaries).
In addition, the RIPTIDES and Baseline system summaries were compared against the summaries of two human authors.
All of the summaries were graded with respect to content, organization, and readability on an A-F scale by three graduate students, all of whom were unfamiliar with this project.
Note that the grades for RIPTIDES-SIM1, the Baseline system, and the two human authors were assigned during a first evaluation in October, 2000, whereas the grades for RIPTIDESSIM2 and RIPTIDES-IE were assigned by the same graders in an update to this evaluation in April, 2001.
Each system and author was asked to generate four summaries of different lengths and emphases: (1) a 100-word summary of the May 30 and May 31 articles; (2) a 400-word summary of all test articles, emphasizing specific, factual information; (3) a 200-word summary of all test articles, focusing on the damage caused by the quake, and excluding information about relief efforts, and (4) a 200-word summary of all test articles, focusing on the relief efforts, and highlighting the Red Cross's role in these efforts.
The results are shown in Tables 1 and 2.
Table 1 provides the overall grade for each system or author averaged across all graders and summaries, where each assigned grade has first been converted to a number (with A=4.0 and F=0.0) and the average converted back to a letter grade.
Table 2 shows the mean and standard deviations of the overall, content, organization, and readability scores for the RIPTIDES and the Baseline systems averaged across all graders and summaries.
Where the differences vs.
the Baseline system are significant according to the t-test, the p-values are shown.
Given the amount of development effort that has gone into the system to date, we were not surprised that the RIPTIDES variants fared poorly when compared against the manually written summaries, with RIPTIDES-SIM2 receiving an average grade of C, vs.
Aand B+ for the human authors.
Nevertheless, we were pleased to find that RIPTIDES-SIM2 scored a full grade ahead of the Baseline summarizer, which received a D, and that 3.
EVALUATION AND INITIAL RESULTS To evaluate the initial version of the IE-supported summarization system, we used Topic 89 from the TDT2 collection -25 texts on the 1998 Afghanistan earthquake.
Each document was annotated manually with the natural disaster scenario templates that comprise the desired output of the IE system.
In addition, treebank-style syntactic structure annotations were added automatically using the Charniak parser.
Finally, MUC-style noun phrase coreference annotations were supplied manually.
All annotations are in XML.
The manual and automatic annotations were automatically merged, leading to inaccurate annotation extents in some cases.
Next, the Topic 89 texts were split into a development corpus and a test corpus.
The development corpus was used to build the summarization system; the evaluation summaries were generated from the test corpus.
We report on three different variants of the RIPTIDES system here: in the first variant (RIPTIDES-SIM1), an Note that since the summarizers for the second and third variants did not have access to the relief sentence categorizations, we decided to exclude from their input the two articles (one training, one test) classified by TDT2 Topic 89 as only containing brief mentions of the event of interest, as otherwise they would have no means of excluding the largely irrelevant material in these documents.
Table 1 Baseline D RIPTIDES-SIM1 C/CRIPTIDES-SIM2 C RIPTIDES-IE D+ Person 1 APerson 2 B+ RIPTIDES-IE managed a slightly higher grade of D+, despite the immature state of the IE system.
As Table 2 shows, the differences in the overall scores were significant for all three RIPTIDES variants, as were the scores for organization and readability, though not for content in the cases of RIPTIDESSIM1 and RIPTIDES-IE.
our efforts in this area on attempting to balance coherence and informativeness in selecting sets of sentences to include in the summary.
In ongoing work, we are investigating techniques for improving merging accuracy and summary fluency in the context of summarizing the more than 150 news articles we have collected from the web about each of the recent earthquakes in Central America and India (January, 2001).
We also plan to investigate using tables and hypertext drill-down as a means to help the user verify the accuracy of the summarized information.
By perusing the web collections mentioned above, we can see that trying to manually extricate the latest damage estimates from 150+ news articles from multiple sources on the same natural disaster would be very tedious.
Although estimates do usually converge, they often change rapidly at first, and then are gradually dropped from later articles, and thus simply looking at the latest article is not satisfactory.
While significant challenges remain, we suggest that our initial system development and evaluation shows that our approach has the potential to accurately summarize damage estimates, as well as identify other key story items using shallower techniques, and thereby help alleviate information overload in specific domains.
4. RELATED AND ONGOING WORK The RIPTIDES system is most similar to the SUMMONS system of Radev and McKeown [10], which summarized the results of MUC-4 IE systems in the terrorism domain.
As a pioneering effort, the SUMMONS system was the first to suggest the potential of combining IE with NLG in a summarization system, though no evaluation was performed.
In comparison to SUMMONS, RIPTIDES appears to be designed to more completely summarize larger input document sets, since it focuses more on finding the most relevant current information, and since it includes extracted sentences to round out the summaries.
Another important difference is that SUMMONS sidestepped the problem of comparing reported numbers of varying specificity (e.g.
several thousand vs.
anywhere from 2000 to 5000 vs.
up to 4000 vs.
5000), whereas we have implemented rules for doing so.
Finally, we have begun to address some of the difficult issues that arise in merging information from multiple documents into a coherent event-oriented view, though considerable challenges remain to be addressed in this area.
The sentence extraction part of the RIPTIDES system is similar to the domain-independent multidocument summarizers of Goldstein et al.[7] and Radev et al.[11] in the way it clusters sentences across documents to help determine which sentences are central to the collection, as well as to reduce redundancy amongst sentences included in the summary.
It is simpler than these systems insofar as it does not make use of comparisons to the centroid of the document set.
As pointed out in [2], it is difficult in general for multidocument summarizers to produce coherent summaries, since it is less straightforward to rely on the order of sentences in the underlying documents than in the case of single-document summarization.
Having also noted this problem, we have focused We thank Daryl McCullough for implementing the coherence boosting randomized local search, and we thank Ted Caldwell, Daryl McCullough, Corien Bakermans, Elizabeth Conrey, Purnima Menon and Betsy Vick for their participation as authors and graders.
This work has been partially supported by DARPA TIDES contract no.
N66001-00-C-8009. References [1] The Apache XML Project.
2001. "Xalan Java." [2] Barzilay, R., Elhadad, N.
and McKeown, K . 2001.
"Sentence Ordering in Multidocument Summarization".
In Proceedings of HLT 2001.
[3] Bikel, D., Schwartz, R.
and Weischedel, R . 1999.
"An Algorithm that Learns What's in a Name".
Machine Learning 34:1-3, 211-231.
[4] Cardie, C . 1997.
"Empirical Methods in Information [5] Charniak, E . 1999.
"A maximum-entropy-inspired parser".
Brown University Technical Report CS99-12.
[6] Fellbaum, C . 1998.
WordNet: An Electronic Lexical Database.
MIT Press, Cambridge, MA.
[7] Goldstein, J., Mittal, V., Carbonell, J.
and Kantrowitz, M . 2000.
"Multi-document summarization by sentence extraction".
In Proceedings of the ANLP/NAACL Workshop on Automatic Summarization, Seattle, WA.
[8] Grishman, R . 1996.
"TIPSTER Architecture Design Document Version 2.2".
DARPA, available at http://www.tipster.org/.
[9] Marcus, M., Marcinkiewicz, M.
and Santorini, B . 1993.
"Building a Large, Annotated Corpus of English: The Penn Treebank".
Computational Linguistics 19:2, 313-330.
[10] Radev, D.
R. and McKeown, K.
R . 1998.
"Generating natural language summaries from multiple on-line sources".
Computational Linguistics 24(3):469-500.
[11] Radev, D.
R., Jing, H.
and Budzikowska, M . 2000.
"Summarization of multiple documents: clustering, sentence extraction, and evaluation".
In Proceedings of the ANLP/NAACL Workshop on Summarization, Seattle, WA.
[12] Riloff, E . 1996.
"Automatically Generating Extraction Patterns from Untagged Text".
In Proceedings of the Thirteenth National Conference on Artificial Intelligence, Portland, OR, 1044-1049.
AAAI Press / MIT Press.
[13] White, M.
and Caldwell, T . 1998.
"EXEMPLARS: A Practical, Extensible Framework for Dynamic Text Generation".
In Proceedings of the Ninth International Workshop on Natural Language Generation, Niagara-onthe-Lake, Canada, 266-275 .

