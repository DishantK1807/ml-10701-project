In the following section, we also improve on Klementiev and Roth (2006) by using a character-based string alignment to focus the features for discrimination.
N06-1011
6Following Evert (2004), signi cance was computed using Fisher’s exact test (at p = 0.05) to compare the n-best word pairs from the scored test sets, where n was taken as the number of positive pairs in the set.
C04-1136
Knowledge of cognates is useful for a number of applications, including sentence alignment (Melamed, 1999) and learning translation lexicons (Mann and Yarowsky, 2001; Koehn and Knight, 2002).
J99-1003 N01-1020 W02-0902
For example, Brill and Moore (2000) combine a character-based alignment with the Expectation Maximization (EM) algorithm to develop an improved probabilistic error model for spelling correction.
P00-1037
Tiedemann (1999) used various measures to learn the recurrent spelling changes between English and Swedish, and used these changes to re-weight LCSR to identify more cognates, with modest performance improvements.
W99-0626
Our evaluation metric is 11-pt average precision on the score-sorted pair lists (also used by Kondrak and Sherif (2006)).
W06-1107
We also use the log of the edit probability from the stochastic decoder of Ristad and Yianilos (1998) (normalized by the length of the longer word) and Tiedemann (1999)’s highest performing system (Approach #3).
W99-0626
Strube et al.(2002) use Edit Distance as a feature for determining if two words are coreferent.
W02-1040
Klementiev and Roth (2006), although using a discriminative approach, do not provide their in nite-attribute perceptron with competitive counter-examples.
N06-1011
Semantic and string similarity might be learned jointly with a co-training or bootstrapping approach (Klementiev and Roth, 2006).
N06-1011
This is in contrast to previous comparisons which have only demonstrated minor improvements with adaptive over traditional similarity measures (Kondrak and Sherif, 2006).
W06-1107
The original Klementiev and Roth (2006) (KR) system can 660 Bitext Dictionary System Fr Es De Fr Es De Gr Jp Rs PREFIX 34.7 27.3 36.3 45.5 34.7 25.5 28.5 16.1 29.8 DICE 33.7 28.2 33.5 44.3 33.7 21.3 30.6 20.1 33.6 LCSR 34.0 28.7 28.5 48.3 36.5 18.4 30.2 24.2 36.6 NED 36.5 31.9 32.3 50.1 40.3 23.3 33.9 28.2 41.4 PREFIX+DICE+LCSR+NED 38.7 31.8 39.3 51.6 40.1 28.6 33.7 22.9 37.9 Kondrak (2005): LCSF 29.8 28.9 29.1 39.9 36.6 25.0 30.5 33.4 45.5 Ristad & Yanilos (1998) 37.7 32.5 34.6 56.1 46.9 36.9 38.0 52.7 51.8 Tiedemann (1999) 38.8 33.0 34.7 55.3 49.0 24.9 37.6 33.9 45.8 Klementiev & Roth (2006) 61.1 55.5 53.2 73.4 62.3 48.3 51.4 62.0 64.4 Alignment-Based Discriminative 66.5 63.2 64.1 77.7 72.1 65.6 65.7 82.0 76.9 Table 3: Bitext, Dictionary Foreign-to-English cognate identi cation 11-pt average precision (%).
N06-1011 W99-0626
Brill and Moore (2000) learn misspelled-word to correctly-spelled-word similarities for spelling correction.
P00-1037
Tiedemann (1999) and others have shown the importance of using the mismatching portions of cognate pairs to learn the recurrent spelling changes between two languages.
W99-0626
Rappoport and Levent-Levi (2006) apply this approach to learn substring correspondences for cognates.
W06-2003
Mann and Yarowsky (2001) saw little improvement over Edit Distance when applying this transducer to cognates, even when ltering the transducer’s probabilities into different weight classes to better approximate Edit Distance.
N01-1020
Taskar et al.(2005) use French-English common letter sequences as a feature for discriminative word alignment in bilingual texts.
H05-1010
2The cognate data sets used in our experiments are available at http://www.cs.ualberta.ca/ bergsma/Cognates/ 659 5.1 Bitext Experiments For the bitext-based annotation, we use publiclyavailable word alignments from the Europarl corpus, automatically generated by GIZA++ for FrenchEnglish (Fr), Spanish-English (Es) and GermanEnglish (De) (Koehn and Monz, 2006).
W06-3114
One system that can potentially provide this exibility is a discriminative string-similarity approach to named-entity transliteration by Klementiev and Roth (2006).
N06-1011
Klementiev and Roth (2006) generate features for a pair of words by splitting both words into all possible substrings of up to size two: sutoresu )f s, u, t, o, r, e, s, u, su, ut, to, ...
N06-1011
For example, researchers have automatically developed translation lexicons by seeing if words from each language have similar frequencies, contexts (Koehn and Knight, 2002), burstiness, inverse document frequencies, and date distributions (Schafer and Yarowsky, 2002).
W02-0902 W02-2026
In Section 6, we show signi cant improvements over traditional approaches, as well as signi cant gains over more recent techniques by Ristad and Yianilos (1998), Tiedemann (1999), Kondrak (2005), and Klementiev and Roth (2006).
N06-1011 W06-1107 W99-0626
Other popular measures include Dice’s Coefcient (DICE) (Adamson and Boreham, 1974), and the length-normalized measures Longest Common Subsequence Ratio (LCSR) (Melamed, 1999), and Longest Common Pre x Ratio (PREFIX) (Kondrak, 2005).
J99-1003
Our labelled set is then generated from pairs with LCSR 0.58 (using the cutoff from Melamed (1999)).
J99-1003
We adopt an improved de nition (suggested by Melamed (1999) for the French-English Canadian Hansards) that does not over-propose shorter word pairs: (e, f) are cognate if they are translations and their LCSR 0.58.
J99-1003
For example, Mann and Yarowsky (2001) de ne a word pair (e, f) to be cognate if they are a translation pair (same meaning) and their Edit Distance is less than three (same form).
N01-1020
A similar use of the term phrase exists in machine translation, where phrases are often pairs of word sequences consistent with word-based alignments (Koehn et al., 2003).
N03-1017
Zelenko and Aone (2006) recently showed a Klementiev and Roth (2006)-style discriminative approach to be superior to alignment-based generative techniques for name transliteration.
N06-1011 W06-1672
