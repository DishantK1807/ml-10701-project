<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>J Lin</author>
<author>D Demner-Fushman</author>
</authors>
<title>Automatically evaluating answers to definition questions</title>
<date>2005</date>
<booktitle>In Proceedings of the Human Language Technology Conference (HLT-EMNLP</booktitle>
<contexts>
<context>, and as part of the evaluation, human annotators “nuggetize” the responses, i.e. identify relevant nuggets of information. As opposed to “computationally straightforward” approaches to nuggets (e.g. Lin and Demner-Fushman, 2005; Marton and Radul, 2006; Zhou and Hovy, 2007), nuggetization in GALE is defined “procedurally”, based on a small set of predefined rules. Whereas some of these rules are linguistic in nature, others </context>
</contexts>
<marker>Lin, Demner-Fushman, 2005</marker>
<rawString>Lin, J. and D. Demner-Fushman, 2005. Automatically evaluating answers to definition questions. In Proceedings of the Human Language Technology Conference (HLT-EMNLP 2005).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lin</author>
<author>P Zhang</author>
</authors>
<title>Deconstructing Nuggets: The Stability and Reliability of Complex Question Answering Evaluation</title>
<date>2007</date>
<booktitle>In Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR</booktitle>
<pages>327--334</pages>
<location>Amsterdam, the Netherlands</location>
<contexts>
<context>veral papers, on the other hand, have raised the question of whether human-based nugget annotations are stable and whether it is possible to define the appropriate granularity level for nuggets (e.g. Lin and Zhang, 2007). The answers have important implications for the reliability of system scores. The paper presents an approach to nuggetization which has been employed by BAE Systems Advanced Information Technologie</context>
</contexts>
<marker>Lin, Zhang, 2007</marker>
<rawString>Lin J. and P. Zhang. 2007. Deconstructing Nuggets: The Stability and Reliability of Complex Question Answering Evaluation. In Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2007), pages 327-334, Amsterdam, the Netherlands Marton, G. and A. Radul, 2006. Nuggeteer: automatic nugget-based evaluation using description and judgments. In Proceedings of NAACL-HLT 2006 Voorhees, E. 2003. Overview of the TREC 2003 question answering track. In Proceedings of TREC 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Shamber</author>
</authors>
<title>Relevance and information behavior</title>
<date>1994</date>
<booktitle>In Annual Review of Information Science and Technology</booktitle>
<pages>29--3</pages>
<contexts>
<context>illation systems. This interaction between nuggetization and assessing relevance of nuggets presents a big challenge for Distillation evaluation given that judging relevance is inherently subjective (Shamber, 1994 and Voorhees, 2003). The approach to nuggetization adopted in the paper views nuggetization and relevance as separate tasks, where annotators first use nuggetization rules to define nuggets of fixed </context>
</contexts>
<marker>Shamber, 1994</marker>
<rawString>Shamber L. 1994.  Relevance and information behavior. In Annual Review of Information Science and Technology. 29:3-48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L N Kwon Zhou</author>
<author>E H Hovy</author>
</authors>
<title>A Semi-Automated Evaluation Scheme: Automated Nuggetization for Manual Annotation</title>
<date>2007</date>
<booktitle>In Proceedings of the Human Language Technology / North American Association of Computational Linguistics conference (HLT-NAACL 2007</booktitle>
<location>Rochester, NY</location>
<contexts>
<context>getize” the responses, i.e. identify relevant nuggets of information. As opposed to “computationally straightforward” approaches to nuggets (e.g. Lin and Demner-Fushman, 2005; Marton and Radul, 2006; Zhou and Hovy, 2007), nuggetization in GALE is defined “procedurally”, based on a small set of predefined rules. Whereas some of these rules are linguistic in nature, others are based on “relevance” or importance of cre</context>
</contexts>
<marker>Zhou, Hovy, 2007</marker>
<rawString>Zhou, L. N. Kwon, and E.H. Hovy. 2007. A Semi-Automated Evaluation Scheme: Automated Nuggetization for Manual Annotation. In Proceedings of the Human Language Technology / North American Association of Computational Linguistics conference (HLT-NAACL 2007). Rochester, NY White J.V., D. Hunter, and J.D.Goldstein, 2008.</rawString>
</citation>
</citationList>
</algorithm>

