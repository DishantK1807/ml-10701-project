<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<title>The Berkeley FrameNet project</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL</booktitle>
<location>Montreal, Canada</location>
<marker>1998</marker>
<rawString>1998. The Berkeley FrameNet project. In Proceedings of COLING-ACL, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roy Bar-Haim</author>
<author>Idan Szpektor</author>
<author>Oren Glickman</author>
</authors>
<title>Definition and analysis of intermediate entailment levels. In Definition and Analysis of Intermediate Entailment Levels</title>
<date>2005</date>
<location>Ann Arbor, Michigan</location>
<contexts>
<context>l are in the same frame KILLING, and that for this frame the patterns “VICTIM kill in TIME” and “assassination of VICTIM in TIME” represent a meaning preserving transformation. Several studies (e.g. (Bar-Haim et al., 2005; Clark et al., 2007; Garoufi, 2007)) have shown that large parts of the RTE-challenges corpora can be solved only relying on repositories of semantic knowledge at the predicateargument structure leve</context>
</contexts>
<marker>Bar-Haim, Szpektor, Glickman, 2005</marker>
<rawString>Roy Bar-Haim, Idan Szpektor, and Oren Glickman. 2005. Definition and analysis of intermediate entailment levels. In Definition and Analysis of Intermediate Entailment Levels, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Basili</author>
<author>Marco Cammisa</author>
<author>Alfio Gliozzo</author>
</authors>
<title>Integrating domain and paradigmatic similarity for unsupervised sense tagging</title>
<date>2006</date>
<booktitle>In 17th European Conference on Artificial Intelligence (ECAI06), Riva del Garda</booktitle>
<location>Italy</location>
<contexts>
<context> concepts implicit in the dimensionality reduction of LSA better promote paradigmatic relations. This confirms previous studies on the application of an LSAbased method for word sense disambiguation (Basili et al., 2006) where predominant senses were better captured over latent semantic spaces. As for the different parameterizations, there are no significant differences. In general, windows size of 5 words seem slig</context>
</contexts>
<marker>Basili, Cammisa, Gliozzo, 2006</marker>
<rawString>Roberto Basili, Marco Cammisa, and Alfio Gliozzo. 2006. Integrating domain and paradigmatic similarity for unsupervised sense tagging. In 17th European Conference on Artificial Intelligence (ECAI06), Riva del Garda, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H C Boas</author>
</authors>
<title>Semantic frames as interlingual representations for multilingual lexical databases</title>
<date>2005</date>
<journal>International Journal of Lexicography</journal>
<volume>18</volume>
<contexts>
<context>nually adapt the resource to specific languages – e.g. German (Burchardt et al., 2006), Spanish (Subirats and Petruck, 2003). Unlike PropBank, FrameNet is in fact suitable to cross-lingual induction (Boas, 2005), as frames are mostly defined at the conceptual level, thus allowing cross-lingual interpretation. Yet, all these projects consist in manually defining frame linguistic knowledge (e.g. lexical units</context>
</contexts>
<marker>Boas, 2005</marker>
<rawString>H. C. Boas. 2005. Semantic frames as interlingual representations for multilingual lexical databases. International Journal of Lexicography, 18(4):445–478.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Budanitsky</author>
<author>Graeme Hirst</author>
</authors>
<title>Evaluating wordnet-based measures of semantic distance</title>
<date>2006</date>
<journal>Computational Linguistics</journal>
<volume>32</volume>
<contexts>
<context>seem to indicate the following. Syntax-based spaces. Syntax-based spaces are good at modeling semantic similarity. Two target words close in the space are likely to be close also in a is-a hierarchy (Budanitsky and Hirst, 2006), i.e. they are synonyms, antonyms, hyperonyms, cousins, etc. (e.g. human/man, dog/animal, good/bad). This is explained by the fact that contexts are syntactic relations, and then targets with the sa</context>
</contexts>
<marker>Budanitsky, Hirst, 2006</marker>
<rawString>Alexander Budanitsky and Graeme Hirst. 2006. Evaluating wordnet-based measures of semantic distance. Computational Linguistics, 32(1):13–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aljoscha Burchardt</author>
<author>Anette Frank</author>
</authors>
<title>Approximating Textual Entailment with LFG and FrameNet Frames</title>
<date>2006</date>
<booktitle>In Proceedings of PASCAL RTE2 Workshop</booktitle>
<contexts>
<context>t the frame level (such as nominalizations and argument variations). Yet, so far systems based on these resources did not achieve significantly better performance than pure syntactic approaches (e.g.(Burchardt and Frank, 2006)). One of the main reasons is that these resources are manually built: then they are highly accurate but often they have a poor coverage on the test collections. Despite this is a critical issue for </context>
</contexts>
<marker>Burchardt, Frank, 2006</marker>
<rawString>Aljoscha Burchardt and Anette Frank. 2006. Approximating Textual Entailment with LFG and FrameNet Frames. In Proceedings of PASCAL RTE2 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aljoscha Burchardt</author>
<author>Katrin Erk</author>
<author>Anette Frank</author>
<author>Andrea Kowalski</author>
<author>Sebastian Pad</author>
<author>Manfred Pinkal</author>
</authors>
<title>The salsa corpus: a german corpus resource for lexical semantics</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th International Conference on Language Resources and Evaluation</booktitle>
<location>Genova, Italy</location>
<contexts>
<context> important in real Natural Language Processing (NLP) applications. Recently, many researches have focused on using English FrameNet to manually adapt the resource to specific languages – e.g. German (Burchardt et al., 2006), Spanish (Subirats and Petruck, 2003). Unlike PropBank, FrameNet is in fact suitable to cross-lingual induction (Boas, 2005), as frames are mostly defined at the conceptual level, thus allowing cros</context>
<context> of each new predicate, which limits its practical usefulness. Other researches have focused on manually creating frame annotated corpora for languages different from English, these including German (Burchardt et al., 2006), Spanish (Subirats and Petruck, 2003), Japanese (Ohara et al., 2004) and French (Pitel, 2006). Recent works propose to semi-automate this long and costly manual process, by using annotation projecti</context>
</contexts>
<marker>Burchardt, Erk, Frank, Kowalski, Pad, Pinkal, 2006</marker>
<rawString>Aljoscha Burchardt, Katrin Erk, Anette Frank, Andrea Kowalski, Sebastian Pad, and Manfred Pinkal. 2006. The salsa corpus: a german corpus resource for lexical semantics. In Proceedings of the 5th International Conference on Language Resources and Evaluation, Genova, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Clark</author>
<author>Phil Harrison</author>
<author>John Thompson</author>
<author>William Murray</author>
<author>Jerry Hobbs</author>
<author>Christiane Fellbaum</author>
</authors>
<title>On the role of lexical and world knowledge in rte3</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing</booktitle>
<pages>54--59</pages>
<location>Prague</location>
<contexts>
<context> KILLING, and that for this frame the patterns “VICTIM kill in TIME” and “assassination of VICTIM in TIME” represent a meaning preserving transformation. Several studies (e.g. (Bar-Haim et al., 2005; Clark et al., 2007; Garoufi, 2007)) have shown that large parts of the RTE-challenges corpora can be solved only relying on repositories of semantic knowledge at the predicateargument structure level, such as FrameNet </context>
</contexts>
<marker>Clark, Harrison, Thompson, Murray, Hobbs, Fellbaum, 2007</marker>
<rawString>Peter Clark, Phil Harrison, John Thompson, William Murray, Jerry Hobbs, and Christiane Fellbaum. 2007. On the role of lexical and world knowledge in rte3. In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing, pages 54–59, Prague, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Oren Glickman</author>
<author>Bernardo Magnini</author>
</authors>
<date>2006</date>
<contexts>
<context>d for these units, the proposed framework has a much wider application. 1. Introduction In recent years, NLP research has been focusing on complex tasks, such as Recognizing Textual Entailment (RTE) (Dagan et al., 2006; Giampiccolo et al., 2007), requiring a large amount of semantic knowledge. Part of this knowledge lies at the predicate-argument structure level, in between the syntactic and the deep semantic level</context>
</contexts>
<marker>Dagan, Glickman, Magnini, 2006</marker>
<rawString>Ido Dagan, Oren Glickman, and Bernardo Magnini. 2006.</rawString>
</citation>
<citation valid="true">
<title>The pascal recognising textual entailment challenge</title>
<booktitle>LNAI 3944: MLCW 2005</booktitle>
<pages>177--190</pages>
<editor>In Quionero-Candela et al., editor</editor>
<publisher>Springer-Verlag</publisher>
<location>Milan, Italy</location>
<marker></marker>
<rawString>The pascal recognising textual entailment challenge. In Quionero-Candela et al., editor, LNAI 3944: MLCW 2005, pages 177–190, Milan, Italy. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles J Fillmore</author>
</authors>
<title>Frames and the semantics of understanding</title>
<date>1985</date>
<journal>Quaderni di Semantica</journal>
<volume>4</volume>
<contexts>
<context>ion between the geometry of a vector space model and the linguistic notion of frame? How is the distance in the space correlated with the notion of similarity between frame predicates? As defined in (Fillmore, 1985), a frame is a conceptual structure modeling a prototypical situation. A frame is evoked in texts through the occurrence of its lexical units (LU). A lexical unit is a predicate (a noun, a verb, an a</context>
</contexts>
<marker>Fillmore, 1985</marker>
<rawString>Charles J. Fillmore. 1985. Frames and the semantics of understanding. Quaderni di Semantica, 4(2):222–254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Garoufi</author>
</authors>
<title>Towards a better understanding of applied textual entailment: Annotation and evaluation of the rte-2 dataset. M.Sc. thesis, saarland university</title>
<date>2007</date>
<contexts>
<context>or this frame the patterns “VICTIM kill in TIME” and “assassination of VICTIM in TIME” represent a meaning preserving transformation. Several studies (e.g. (Bar-Haim et al., 2005; Clark et al., 2007; Garoufi, 2007)) have shown that large parts of the RTE-challenges corpora can be solved only relying on repositories of semantic knowledge at the predicateargument structure level, such as FrameNet and PropBank. F</context>
</contexts>
<marker>Garoufi, 2007</marker>
<rawString>K. Garoufi. 2007. Towards a better understanding of applied textual entailment: Annotation and evaluation of the rte-2 dataset. M.Sc. thesis, saarland university.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danilo Giampiccolo</author>
<author>Bernardo Magnini</author>
<author>Ido Dagan</author>
<author>Bill Dolan</author>
</authors>
<title>The third pascal recognizing textual entailment challenge</title>
<date>2007</date>
<booktitle>In Proceedings of the ACLPASCAL Workshop on Textual Entailment and Paraphrasing</booktitle>
<pages>1--9</pages>
<location>Prague</location>
<contexts>
<context>he proposed framework has a much wider application. 1. Introduction In recent years, NLP research has been focusing on complex tasks, such as Recognizing Textual Entailment (RTE) (Dagan et al., 2006; Giampiccolo et al., 2007), requiring a large amount of semantic knowledge. Part of this knowledge lies at the predicate-argument structure level, in between the syntactic and the deep semantic level. Predicateargument resour</context>
</contexts>
<marker>Giampiccolo, Magnini, Dagan, Dolan, 2007</marker>
<rawString>Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, and Bill Dolan. 2007. The third pascal recognizing textual entailment challenge. In Proceedings of the ACLPASCAL Workshop on Textual Entailment and Paraphrasing, pages 1–9, Prague, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic labeling of semantic roles</title>
<date>2002</date>
<journal>Computational Linguistics</journal>
<volume>28</volume>
<contexts>
<context>ches have focused on expanding FrameNet knowledge using semi-supervised method. Most of these deal with semantic role labeling, i.e. annotate raw text with frame knowledge. Along the seminal work of (Gildea and Jurafsky, 2002), many machine learning approaches have been proposed, achieving good performance, in strictly supervised settings. Recently, more weakly supervised methods are being explored, using automatic data e</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>Daniel Gildea and Daniel Jurafsky. 2002. Automatic labeling of semantic roles. Computational Linguistics, 28(3):245–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Gordon</author>
<author>Reid Swanson</author>
</authors>
<title>Generalizing semantic role annotations across syntactically similar verbs</title>
<date>2007</date>
<booktitle>In Proceedings of ACL</booktitle>
<pages>192--199</pages>
<contexts>
<context>ecently, more weakly supervised methods are being explored, using automatic data expansion techniques, i.e. leveraging existing annotations to generate new annotations for similar unseen predicates. (Gordon and Swanson, 2007) show that the approach is applicable for syntactically similar verbs. However, their method requires at least one annotated instance of each new predicate, which limits its practical usefulness. Oth</context>
</contexts>
<marker>Gordon, Swanson, 2007</marker>
<rawString>Andrew Gordon and Reid Swanson. 2007. Generalizing semantic role annotations across syntactically similar verbs. In Proceedings of ACL, pages 192–199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Green</author>
<author>John A Swets</author>
</authors>
<title>Signal Detection Theory and Psychophysics</title>
<date>1996</date>
<publisher>John Wiley and Sons</publisher>
<location>New York, USA</location>
<contexts>
<context>etting the algorithm would have to deal with a much higher ratio of false positives than the 50% random pairs. We evaluate the different spaces using Receiver Operating Characteristic ROC analysis (Green and Swets, 1996), mixing Sensitivity and Specificity. Given a threshold t applied to the similarity measure S, Sensitivity Se(t) represents the probability of accepting pairs in the true set at threshold t. Specific</context>
</contexts>
<marker>Green, Swets, 1996</marker>
<rawString>David M. Green and John A. Swets. 1996. Signal Detection Theory and Psychophysics. John Wiley and Sons, New York, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zellig Harris</author>
</authors>
<title>Distributional structure</title>
<date>1964</date>
<booktitle>The Philosophy of Linguistics</booktitle>
<editor>In Jerrold J. Katz and Jerry A. Fodor, editors</editor>
<publisher>Oxford University Press</publisher>
<location>New York</location>
<contexts>
<context>representing the meaning of words or other lexical entities. The basic intuition is that the meaning of a target word is somehow defined by the context in which it appears (Distributional Hypothesis (Harris, 1964)). The context can be defined in different ways: as the set of words surrounding the target word, as the paragraph in which it appears, the document, and so on. Vector spaces are used to model this i</context>
</contexts>
<marker>Harris, 1964</marker>
<rawString>Zellig Harris. 1964. Distributional structure. In Jerrold J. Katz and Jerry A. Fodor, editors, The Philosophy of Linguistics, New York. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom Landauer</author>
<author>Sue Dumais</author>
</authors>
<title>A solution to plato’s problem: The latent semantic analysis theory of acquisition, induction and representation of knowledge</title>
<date>1997</date>
<journal>Psychological Review</journal>
<pages>104--211</pages>
<contexts>
<context>y measures, such as the cosine between vectors or their Euclidean Distance. The original matrix representing the space can be reduced in dimensionality by applying Singular Value Decomposition (SVD) (Landauer and Dumais, 1997), a matrix decomposition process that creates an approximation of the original matrix, aiming to capture semantic dependencies between contexts. The original space is replaced by a lower dimensional </context>
<context>, each one representing an emerging meaning component as a linear combination of many different words (or contexts). SVD is widely applied in Latent Semantic Analysis (LSA) for Information Retrieval (Landauer and Dumais, 1997) and usually improves similarity computation. This can be explained by three different reasons. First, SVD tends to remove the random noise, that is implicitly spread in the original matrix and biase</context>
</contexts>
<marker>Landauer, Dumais, 1997</marker>
<rawString>Tom Landauer and Sue Dumais. 1997. A solution to plato’s problem: The latent semantic analysis theory of acquisition, induction and representation of knowledge. Psychological Review, 104:211–240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>DIRT-discovery of inference rules from text</title>
<date>2001</date>
<booktitle>In Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD-01</booktitle>
<location>San Francisco, CA</location>
<contexts>
<context>thesis have been widely and successfully applied to different language related tasks, such as information retrieval (Salton et al., 1975), harvesting thesauri (Lin, 1998) and paraphrase repositories (Lin and Pantel, 2001). A rich survey is discussed in (Weeds, 2007). As regards frame semantic resource expansion, many researches have focused on expanding FrameNet knowledge using semi-supervised method. Most of these d</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Dekang Lin and Patrick Pantel. 2001. DIRT-discovery of inference rules from text. In Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD-01), San Francisco, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar word</title>
<date>1998</date>
<booktitle>In Proceedings of the Joint International Conference on Computational Linguistics and Annual Meeting of the Association for Computational Linguistics (COLING-ACL</booktitle>
<location>Montreal, Canada</location>
<contexts>
<context>mantic space and the distributional hypothesis have been widely and successfully applied to different language related tasks, such as information retrieval (Salton et al., 1975), harvesting thesauri (Lin, 1998) and paraphrase repositories (Lin and Pantel, 2001). A rich survey is discussed in (Weeds, 2007). As regards frame semantic resource expansion, many researches have focused on expanding FrameNet know</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Automatic retrieval and clustering of similar word. In Proceedings of the Joint International Conference on Computational Linguistics and Annual Meeting of the Association for Computational Linguistics (COLING-ACL), Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif Mohammad</author>
<author>Graeme Hirst</author>
</authors>
<title>Distributional measures as proxies for semantic relatedness. Submitted for publication</title>
<date>2005</date>
<contexts>
<context>perspective, they tend to model different types of relations. Even though the nature of these relations and how they are captured by different spaces is still a matter of debate (see (Sahlgren, 2006; Mohammad and Hirst, 2005) for an in-depth discussion), most recent studies seem to indicate the following. Syntax-based spaces. Syntax-based spaces are good at modeling semantic similarity. Two target words close in the spac</context>
<context>/animal, good/bad). This is explained by the fact that contexts are syntactic relations, and then targets with the same Part of Speech are much closer than targets of different types. Experiments in (Mohammad and Hirst, 2005; Pado, 2007) support this claim. In other terms, syntax-based spaces tend to capture paradigmatic relations and to disregard syntagmatic relations. According to Saussure, paradigmatic relations relat</context>
</contexts>
<marker>Mohammad, Hirst, 2005</marker>
<rawString>Saif Mohammad and Graeme Hirst. 2005. Distributional measures as proxies for semantic relatedness. Submitted for publication.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Ohara</author>
<author>S Fujii</author>
<author>T Ohori</author>
<author>R Suzuki</author>
<author>H Saito</author>
<author>S Ishizaki</author>
</authors>
<title>The Japanese FrameNet project: An introduction</title>
<date>2004</date>
<booktitle>In Proceedings of the Workshop on Building Lexical Resources from Semantically Annotated Corpora at LREC</booktitle>
<contexts>
<context>arches have focused on manually creating frame annotated corpora for languages different from English, these including German (Burchardt et al., 2006), Spanish (Subirats and Petruck, 2003), Japanese (Ohara et al., 2004) and French (Pitel, 2006). Recent works propose to semi-automate this long and costly manual process, by using annotation projection techniques on parallel corpora (Yarowsky et al., 2001; Pado and La</context>
</contexts>
<marker>Ohara, Fujii, Ohori, Suzuki, Saito, Ishizaki, 2004</marker>
<rawString>K. Ohara, S. Fujii, T. Ohori, R. Suzuki, H. Saito, and S. Ishizaki. 2004. The Japanese FrameNet project: An introduction. In Proceedings of the Workshop on Building Lexical Resources from Semantically Annotated Corpora at LREC 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Pado</author>
<author>Mirella Lapata</author>
</authors>
<title>Dependencybased construction of semantic space models</title>
<date>2007</date>
<journal>Computational Linguistics</journal>
<volume>33</volume>
<contexts>
<context>t al., 2004) and French (Pitel, 2006). Recent works propose to semi-automate this long and costly manual process, by using annotation projection techniques on parallel corpora (Yarowsky et al., 2001; Pado and Lapata, 2007). Yet, so far, to our knowledge there has been no attempt to induce FrameNet knowledge using VSMs, a part from some partial exploratory studies on using LSA spaces for FrameNet induction reported in </context>
</contexts>
<marker>Pado, Lapata, 2007</marker>
<rawString>Sebastian Pado and Mirella Lapata. 2007. Dependencybased construction of semantic space models. Computational Linguistics, 33(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Pado</author>
</authors>
<title>Cross-Lingual Annotation Projection Models for Role-Semantic Information</title>
<date>2007</date>
<institution>Saarland University</institution>
<contexts>
<context>s explained by the fact that contexts are syntactic relations, and then targets with the same Part of Speech are much closer than targets of different types. Experiments in (Mohammad and Hirst, 2005; Pado, 2007) support this claim. In other terms, syntax-based spaces tend to capture paradigmatic relations and to disregard syntagmatic relations. According to Saussure, paradigmatic relations relate two words </context>
<context>operated the patient in hospital”, sharing the same contexts “operated”) and substitutional words (e.g. doctor and surgeon in “the (doctor—surgeon) operated the patient in hospital”). Experiments in (Pado, 2007) support this idea, showing that word-based spaces capture syntagmatic relations such as meronimy (door/house), conceptual association (doctor/hospital) and phrasal association (private/property), be</context>
</contexts>
<marker>Pado, 2007</marker>
<rawString>Sebastian Pado, 2007. Cross-Lingual Annotation Projection Models for Role-Semantic Information. Saarland University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
<author>D Gildea</author>
<author>P Kingsbury</author>
</authors>
<title>The proposition bank: An annotated corpus of semantic roles</title>
<date>2005</date>
<journal>Computational Linguistics</journal>
<volume>31</volume>
<contexts>
<context>Part of this knowledge lies at the predicate-argument structure level, in between the syntactic and the deep semantic level. Predicateargument resources (e.g. FrameNet (Baker et al., 1998), PropBank (Palmer et al., 2005)) allow to identify meaningpreserving transformations, such as active/passive, verb alternations and nominalizations, which are crucial in inference based tasks, such as RTE. In the contexts of RTE, </context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>M. Palmer, D. Gildea, and P. Kingsbury. 2005. The proposition bank: An annotated corpus of semantic roles. Computational Linguistics, 31(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Depak Ravichandran</author>
</authors>
<title>Automatically labeling semantic classes</title>
<date>2004</date>
<booktitle>In Proceedings of HLTNAACL-04, Boston,MA</booktitle>
<contexts>
<context>mi. SVD dimension for LSaWord and LsaDoc is 100. around the targets. Three different association measures are used: conditional probability, pmi, and corrected pmi (cpmi) according to the formula in (Pantel and Ravichandran, 2004). Two different window sizes have been applied in the experiments: 5 and 10. LsaWord : reduced spaces obtained by applying SVD reduction onto the word-based spaces. Different LsaWord spaces have been</context>
</contexts>
<marker>Pantel, Ravichandran, 2004</marker>
<rawString>Patrick Pantel and Depak Ravichandran. 2004. Automatically labeling semantic classes. In Proceedings of HLTNAACL-04, Boston,MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guillaume Pitel</author>
</authors>
<title>Cross-lingual labeling of semantic predicates and roles: A low-resource method based on bilingual L(atent) S(emantic) A(nalysis). Mouton De Gruyter</title>
<date>1998</date>
<location>Berlin/New York</location>
<contexts>
<context>. Yet, so far, to our knowledge there has been no attempt to induce FrameNet knowledge using VSMs, a part from some partial exploratory studies on using LSA spaces for FrameNet induction reported in (Pitel, 1998). 3. Vector Space Models for LUs FrameNet modelling Using VSM for modeling a FrameNet-like resource poses a fundamental question. What is the relation between the geometry of a vector space model and</context>
</contexts>
<marker>Pitel, 1998</marker>
<rawString>Guillaume Pitel, 1998. Cross-lingual labeling of semantic predicates and roles: A low-resource method based on bilingual L(atent) S(emantic) A(nalysis). Mouton De Gruyter,, Berlin/New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guillaume Pitel</author>
</authors>
<title>Using bilingual lsa for framenet annotation of french text from generic resources</title>
<date>2006</date>
<booktitle>In Workshop on Multilingual Semantic Annotation: Theory and Applications</booktitle>
<location>Saarbrcken, Germany</location>
<contexts>
<context>creating frame annotated corpora for languages different from English, these including German (Burchardt et al., 2006), Spanish (Subirats and Petruck, 2003), Japanese (Ohara et al., 2004) and French (Pitel, 2006). Recent works propose to semi-automate this long and costly manual process, by using annotation projection techniques on parallel corpora (Yarowsky et al., 2001; Pado and Lapata, 2007). Yet, so far,</context>
</contexts>
<marker>Pitel, 2006</marker>
<rawString>Guillaume Pitel. 2006. Using bilingual lsa for framenet annotation of french text from generic resources. In Workshop on Multilingual Semantic Annotation: Theory and Applications, Saarbrcken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Magnus Sahlgren</author>
</authors>
<title>The Word-Space Model</title>
<date>2006</date>
<institution>Department of Linguistics, Stockholm University</institution>
<contexts>
<context>from a semantic perspective, they tend to model different types of relations. Even though the nature of these relations and how they are captured by different spaces is still a matter of debate (see (Sahlgren, 2006; Mohammad and Hirst, 2005) for an in-depth discussion), most recent studies seem to indicate the following. Syntax-based spaces. Syntax-based spaces are good at modeling semantic similarity. Two targ</context>
<context>), conceptual association (doctor/hospital) and phrasal association (private/property), better than syntax-based spaces, while still capturing paradigmatic relations. The same conclusion is drawn in (Sahlgren, 2006), where word-based space are demonstrated to be highly correlated with a thesaurus containing both syntagmatic and paradigmatic relations. Document-based spaces. Document spaces are historically used</context>
<context>ity mainly involves co-occurring words (e.g. doctor/hospital for the medical topic). Document-based spaces should then better capture syntagmatic relations. Notwithstanding, experimental evidence in (Sahlgren, 2006) have shown that these spaces capture both paradigmatic and syntagmatic relations, as it happens in word-based spaces. From our perspective, the notion of frame has both a syntagmatic and paradigmati</context>
</contexts>
<marker>Sahlgren, 2006</marker>
<rawString>Magnus Sahlgren. 2006. The Word-Space Model. Department of Linguistics, Stockholm University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Salton</author>
<author>A Wong</author>
<author>C Yang</author>
</authors>
<title>A vector space model for automatic indexing</title>
<date>1975</date>
<journal>Communications of the ACM</journal>
<pages>18--613</pages>
<contexts>
<context>omputational speed-up. 2.2. Related Work Semantic space and the distributional hypothesis have been widely and successfully applied to different language related tasks, such as information retrieval (Salton et al., 1975), harvesting thesauri (Lin, 1998) and paraphrase repositories (Lin and Pantel, 2001). A rich survey is discussed in (Weeds, 2007). As regards frame semantic resource expansion, many researches have f</context>
</contexts>
<marker>Salton, Wong, Yang, 1975</marker>
<rawString>G. Salton, A. Wong, and C. Yang. 1975. A vector space model for automatic indexing. Communications of the ACM, 18:613–620.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Subirats</author>
<author>M Petruck</author>
</authors>
<title>Surprise! Spanish FrameNet</title>
<date>2003</date>
<booktitle>In Proceedings of the Workshop on Frame Semantics at the XVII. International Congress of Linguists</booktitle>
<location>Prague</location>
<contexts>
<context>e Processing (NLP) applications. Recently, many researches have focused on using English FrameNet to manually adapt the resource to specific languages – e.g. German (Burchardt et al., 2006), Spanish (Subirats and Petruck, 2003). Unlike PropBank, FrameNet is in fact suitable to cross-lingual induction (Boas, 2005), as frames are mostly defined at the conceptual level, thus allowing cross-lingual interpretation. Yet, all the</context>
<context>ts its practical usefulness. Other researches have focused on manually creating frame annotated corpora for languages different from English, these including German (Burchardt et al., 2006), Spanish (Subirats and Petruck, 2003), Japanese (Ohara et al., 2004) and French (Pitel, 2006). Recent works propose to semi-automate this long and costly manual process, by using annotation projection techniques on parallel corpora (Yar</context>
</contexts>
<marker>Subirats, Petruck, 2003</marker>
<rawString>C. Subirats and M. Petruck. 2003. Surprise! Spanish FrameNet! In Proceedings of the Workshop on Frame Semantics at the XVII. International Congress of Linguists, Prague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Weeds</author>
<author>D Weir</author>
<author>D McCarthy</author>
</authors>
<title>Characterising measures of lexical distributional similarity</title>
<date>2004</date>
<booktitle>In Proceedings of CoLing</booktitle>
<location>Geneva, Switzerland</location>
<contexts>
<context>ords. In all we obtained 49,890 context words for the OrgWord space. Vectors represent individual target LUs and co-occurrence values are computed within text windows centered 2Some studies, such as (Weeds et al., 2004), argue that other measures can emphasize different characteristics of the space, but this aspect is out of the scope of the present work. SYSTEM PARAMETERS AROC BEST ACCURACY OrgWord measure=cpmi , </context>
</contexts>
<marker>Weeds, Weir, McCarthy, 2004</marker>
<rawString>J. Weeds, D. Weir, and D. McCarthy. 2004. Characterising measures of lexical distributional similarity. In Proceedings of CoLing 2004, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julie Weeds</author>
</authors>
<title>Measures and applications of lexical distributional similarity. PhD thesis</title>
<date>2007</date>
<editor>David Yarowsky, Grace Ngai, and Roger Wicentowski</editor>
<contexts>
<context>fferent language related tasks, such as information retrieval (Salton et al., 1975), harvesting thesauri (Lin, 1998) and paraphrase repositories (Lin and Pantel, 2001). A rich survey is discussed in (Weeds, 2007). As regards frame semantic resource expansion, many researches have focused on expanding FrameNet knowledge using semi-supervised method. Most of these deal with semantic role labeling, i.e. annotat</context>
</contexts>
<marker>Weeds, 2007</marker>
<rawString>Julie Weeds. 2007. Measures and applications of lexical distributional similarity. PhD thesis. David Yarowsky, Grace Ngai, and Roger Wicentowski.</rawString>
</citation>
</citationList>
</algorithm>

