Proceedings of NAACL HLT 2009: Short Papers, pages 145–148,
Boulder, Colorado, June 2009. c 2009 Association for Computational Linguistics
Evaluating the Syntactic Transformations in Gold Standard Corpora 
for Statistical Sentence Compresion 
 
 
Naman K. Gupta, Sourish Chaudhuri, Carolyn P. Rosé 
Language Technologies Institute 
Carnegie Melon University 
Pitsburgh, PA 15213, USA 
{nkgupta,sourishc,cprose}@cs.cmu.edu 
 
 
Abstract 
We present a policy-based eror analysis 
aproach that demonstrates a limitation to 
the curent comonly adopted paradigm 
for sentence compresion.  We demon-
strate that these limitations arise from the 
strong asumption of locality of the deci-
sion making proces in the search for an 
aceptable derivation in this paradigm. 
1 Introduction

In this paper we present a policy-based eror analy-
sis aproach that demonstrates a limitation to the 
curent comonly adopted paradigm for sentence 
compresion (Knight and Marcu, 200; Turner and 
Charniak, 205; McDonald, 206; Clark and La-
pata 206).  
  Specificaly, in typical statistical compresion 
aproaches, a simplifying asumption is made that 
compresion is acomplished strictly by means of 
word deletion. Furthermore, each sequence of con-
tiguous words that are droped from a source sen-
tence is considered independently of other 
sequences of words droped from other portions of 
the sentence, so that the features that predict 
whether deleting a sequence of words is prefered 
or not is based solely on local considerations. This 
simplistic aproach alows al posible derivations 
to be modeled and decoded eficiently within the 
search space, using a dynamic programing algo-
rithm.  
  In theory, it should be posible to learn how to 
generate efective compresions using a corpus of 
source-target sentence pairs, given enough exam-
ples and suficiently expresive features.  How-
ever, our analysis casts doubt that this framework 
with its strong asumptions of locality is sufi-
ciently powerful to learn the types of example 
compresions frequently found in corpora of hu-
man generated gold standard compresions regard-
les of how expresive the features are. 
  Work in sentence compresion has ben some-
what hampered by the tremendous cost involved in 
producing a gold standard corpus. Because of this 
tremendous cost, the same gold standard corpora 
are used in many diferent published studies almost 
as a black box. This is done with litle scrutiny of 
the limitations on the learnability of the desired 
target systems. These limitations result from in-
consistencies due to the subtleties in the proces by 
which humans generate the gold standard compres-
sions from the source sentences, and from the 
strong locality asumptions inherent in the frame-
works. 
  Typicaly, the humans who have participated in 
the construction of these corpora have ben in-
structed to preserve gramaticality and to produce 
compresions by deletion.  Human ratings of the 
gold standard compresions by separate judges 
confirm that the human developers have literaly 
folowed the instructions, and have produced com-
presions that are themselves largely gramatical. 
Nevertheles, what we demonstrate with our eror 
analysis is that they have used meaning preserving 
transformation that didn't consistently preserve the 
gramatical relations from the source sentence 
while transforming source sentences into target 
sentences. This places limitations on how wel the 
prefered paterns of compresion can be learned 
using the curent paradigm and existing corpora. 
  In the remainder of the paper, we discus rele-
vant work in sentence compresion.  We then in-
troduce our policy-based eror analysis technique. 
Next we discus the eror analysis itself and the 
conclusions we draw from it. Finaly, we conclude 
145
with future directions for broader aplication of 
this eror analysis technique. 
2 Related
Work  
Knight and Marcu (200) present two aproaches 
to the sentence compresion problemone using a 
noisy chanel model and the other using a deci-
sion-based model. Subsequent work (McDonald, 
206) has demonstrated an advantage for a soft 
constraint aproach, where a discriminative model 
learns to make local decisions about droping a 
sequence of words from the source sentence in or-
der to produce the target compresion. Features in 
this system are defined over pairs of words in the 
source sentence, with the idea that the pair of 
words would apear adjacent in the resulting com-
presion, with al intervening words droped. 
Thus, the features represent this transformation, 
and the feature weights are meant to indicate 
whether the transformation is asociated with god 
compresions or not. 
  We use McDonald’s (206) proposed model as a 
foundation for our work because its soft constraint 
aproach alows for natural integration of a variety 
of clases of features, even overlaping features. 
In our prior work we have explored the potential 
for improving the performance of a compresion 
system by including aditional, more sophisticated 
syntacticaly motivated features than those in-
cluded in previously published models. In this pa-
per, we evaluate the gold standard corpus itself 
using similar syntactic gramar policies. 
3 Grammar
Policy Extraction 
In the domain of Sentence Compresion, the cor-
pus consists of source sentences each paired with a 
gold standard compresed sentence. Most of the 
above related work has ben evaluated using the 
folowing 2 corpora, namely the Zif-Davis (ZD) 
set (Knight and Marcu, 202) consisting of 105 
sentences, and a partial Broadcast News Corpus 
(CL Corpus) (Clarke and Lapata, 206) originaly 
consisting of 1619 sentences, of which we used 
1070 as the training set in our development work 
as wel as in the eror analysis below. Hence, we 
use these two popular corpora to present our work. 
We hypothesize certain gramar policies that in-
tuitively should be folowed while deriving the 
target-compresed sentence from the source sen-
tence if the maping betwen source and target 
sentences is produced via gramatical transforma-
tions. The basic idea behind these policies grows 
out of the same ideas motivating the syntactic fea-
tures used in McDonald (206). These policies, 
extracted using the MST (McDonald, 205) de-
pendency parse structure of the source sentence, 
are as folows: 
 
1. The syntactic rot word of a sentence 
should be retained in the compresed sen-
tence. 
2.  If a verb is retained in the compresed 
sentence, then the dependent subject of 
that verb should also be retained. 
3. If a verb is retained in the compresed sen-
tence, then the dependent object of that 
verb should also be retained. 
4. If the verb is droped in the compresed 
sentence then its arguments, namely sub-
ject, object, prepositional phrases etc., 
should also be droped. 
5. If the Preposition in a Prepositional phrase 
(P) is retained in the compresed sen-
tence, then the dependent Noun Phrase 
(NP) of that Preposition should also be re-
tained. 
6. If the head noun of a Noun phrase (NP) 
within a Prepositional phrase is retained in 
the compresed sentence, then the syntac-
tic parent Preposition of the NP should 
also be retained. 
7. If a Preposition, the syntactic head of a 
Prepositional phrase (P), is droped in 
the compresed sentence, then the whole 
P, including dependent Noun phrase in 
that P, should also be droped. 
8. If the head noun of a Noun phrase within a 
Prepositional phrase (P) is droped in the 
compresed sentence, then the syntactic 
parent Preposition of the P should also be 
droped. 
 
These gramar policies make predictions about 
where, in the phrase structure, constituents are 
likely to be droped or retained in the compres-
sion. Thus, these policies have similar motivation 
to the syntactic features in the McDonald (206) 
model. However, there is a fundamental diference 
in the way these policies are computed. In the 
McDonald (206) model, the features are com-
146
puted localy over adjacent words y
i-1 
& y
i
 in the 
compresion and the words droped from the 
original sentence betwen that word range y
i-1 
& 
y
i
. In cases where the syntactic structure of the in-
volved words extends beyond this range, the ex-
tracted features are not able to capture al of the 
relevant syntactic dependencies. On the other hand, 
in our analysis the policies are computed globaly 
over the complete sentence without specifying any 
range of words. As an ilustrative example, let us 
consider the folowing sentence from the CL Cor-
pus (bold represents droped words): 
1. The
1
 leaflet
2
 given
3
 to
4
 Labour
5
 activists
6
 
mentions
7
 none
8 
of
9
 these
10 
things
1
. 
Acording to Policy 2, since the verb 'mentions' 
is retained, the subject of the verb ‘the leaflet’ 
should also be retained. In the McDonald (206) 
model, by loking at the local range y
i-1 
= 5 and y
i 
= 7 for the verb 'mentions', we wil not be able to 
compute whether the subject(1,2) was retained in 
the compresion or not. So this policy can be cap-
tured only if the global context is taken into ac-
count while evaluating the verb 'mentions'. 
Now we evaluate each sentence in the corpus to 
determine whether a particular policy was aplica-
ble and if aplicable then whether it was violated. 
Table 1 shows the sumary of the evaluation of al 
the sentences in the two corpora. Column 2 in the 
table shows the percentage of sentences in the ZD 
Corpus where the respective policies were aplica-
ble. And column 3 shows the percentage of sen-
tences where the respective policies were violated, 
whenever aplicable. Columns 4 and 5 show re-
spective percentages for the CL corpus. 
4 Evaluation

In this section we discus the results from evaluat-
ing the 8 gramar policies discused in Section 3 
over the ZD and CL corpora, as discused above.  
The policies were evaluated with respect to 
whether they aplied in a sentence, i.e., whether 
the premise of the “if … then” rule is true in the 
sentence, and whether the policy was broken when 
aplied, i.e., if the premise is true but the conse-
quent is false. The striking finding is that for every 
one of the policies discused in the previous sec-
tion, they are violated for at least 10% of the sen-
tences where they aplied, and sometimes as much 
as 72%. For most policies, the proportion of sen-
tences where the policy is violated when aplied is 
a minority of cases.  Thus, based on this, we can 
expect that gramar oriented features motivated 
by these policies and derived from a syntactic 
analysis of the source and/or target sentences in the 
gold standard could be used to improve the per-
formance of compresion systems that don’t make 
use of syntactic information to that extent.  How-
ever, the noticeable proportion of violations with 
respect to some of the policies indicate that there is 
a limited extent to which these types of features 
can contribute towards improved performance. 
One observation we make from Table 1 is that 
while the proportion of sentences where the poli-
cies (Columns 2 and 4) aply as wel as the propor-
tion of sentences where the policies are broken 
when aplied (Columns 3 and 5) are highly core-
lated betwen the two corpora.  Nevertheles, the 
distributions are not identical. Thus, again, while 
we predict that using this style of dependency syn-
tax features might improve performance of com-
presion systems within a single corpus, we would 
not expect trained models that rely on these syntac-
tic dependency features to generalize in an ideal 
way betwen corpora. 
 
 ZD (% 
Apli-
cable) 
ZD (% 
Viola-
tions 
when 
Apli-
cable) 
CL (% 
Apli-
cable) 
CL (% 
Viola-
tions 
when 
Apli-
cable) 
Policy1 10% 34% 10% 14% 
Policy2 6% 18% 84% 18% 
Policy3 50% 10% 61% 24% 
Policy4 59% 59% 46% 72% 
Policy5 62% 17% 7% 27% 
Policy6 65% 2% 79% 29% 
Policy7 57% 25% 58% 40% 
Policy8 5% 16% 58% 36% 
Table 1: Sumary of evaluation of gramar policies 
over the Zif-Davis (ZD) training set and Clark-Lapata 
(CL) training set. 
 
Beyond the above evaluation ilustrating the extent 
to which gramar inspired policies are violated in 
human generated gold standard corpora, interesting 
insights into chalenges that must be adresed in 
order to improve performance can be obtained by 
taking a close lok at typical examples from the 
CL corpus where the policies are broken in the 
147
gold standard corpora (bold represents droped 
words). 
 
1. The atempt to put flesh and blod on the 
skeleton structure of a posible united 
Europe emerged. 
2. Anely has used the galery ’s thre 
flors to divide the exhibits into thre dis-
tinct groups. 
3. Labor has said it wil scrap the system. 
4. Montenegro ’s suden rehabilitation of 
Nicholas ’s memory is a popular move. 
 
In Sentence 1, retaining the dependent Noun struc-
ture of the droped Preposition on in the P vio-
lates Policy 7. Such a NP to Infinitive Phrase 
transformation changes the syntactic structure of 
the sentence. Sentence 2 also breaks several poli-
cies, namely Policies 1, 4 and 7. The syntactic rot 
has is droped. Also the main verb has used is 
droped while retaining the Subject Anely. In 
Sentence 3, breaking Policies 1, 2 and 4, the hu-
man anotators replaced the pronoun it with the 
noun Labor, the subject of a droped verb ‘has 
said’. Such anaphora resolution canot be done 
without relevant context, which is not available in 
strictly local paradigms of sentence compresion. 
In Sentence 4, policies 3. 5 and 8 are violated. 
Transformations like substituting Nicholas’s mem-
ory by the metonym Nicholas and popular move by 
popular ned to be identified and analyzed. Such 
varied transformations, made in the syntactic struc-
ture of the sentences by human anotators, are 
counter-intuitive, making them hard to be captured 
in the linear models learned in asociation with the 
syntactic features in curent compresion systems. 
5 Conclusions
and Current Directions 
In this paper we have introduced a policy-based 
eror analysis technique that was used to investi-
gate the potential impact and limitations of ading 
a particular style of dependency parse features to 
typical statistical compresion systems.  We have 
argued that the reason for the limitation arises from 
the strong asumption of the local nature of the 
decisions that are made in obtaining the system-
generated compresion from a source sentence.  
  Other related technologies such as statistical 
machine translation and statistical paraphrase are 
based on similar paradigms with similar asump-
tions of the local nature of decisions that are made 
in the search for an aceptable derivation. We con-
jecture both that it is likely that the same isues 
related to the construction of the gold standard 
corpora likely aply and that a similar policy-based 
eror analysis aproach could be used in order to 
ases the extent to which this is true and identify 
posible directions for improving performance. In 
our ongoing work, we plan to conduct a similar 
eror analysis for these problems in order to evalu-
ate the generality of the findings reported here.  
Acknowledgments 
This work was funded in part by the Ofice of Na-
val Research grant number N001451043. 
References  
James Clarke and Mirela Lapata. 206. Constraint-
Based Sentence Compresion: An Integer Program-
ming Aproach. Procedings of the COLING/ACL 
206 Main Conference Poster Sesions (ACL-206), 
pages 14-151, 206. 
James Clarke and Mirela Lapata. 206. Models for Sen-
tence Compresion: A Comparison acros Domains, 
Training Requirements and Evaluation Measures. 
Procedings of the 21st International Conference on 
Computational Linguistics and 4th Anual Meting 
of the Asociation for Computational Linguistics, 
37-384. Sydney, Australia. 
Kevin Knight and Daniel Marcu. 200. Statistics-Based 
Sumarization – Step One: Sentence Compresion. 
Procedings of AAI-200, Austin, TX, USA. 
Knight, Kevin and Daniel Marcu. 202. Sumarization 
beyond sentence extraction: a probabilistic aproach 
to sentence compresion. Artificial Inteligence 
139(1):91–107. 
Ryan McDonald, Koby Cramer, and Fernando 
Pereira. 205. Online large-margin training of de-
pendency parsers. Proc. ACL. 
Ryan Mcdonald, 206. Discriminative sentence com-
presion with soft syntactic constraints. Procedings 
of the 1th EACL. Trento, Italy, pages 297-304. 
Jenine Turner and Eugene Charniak. 205. Supervised 
and unsupervised learning for sentence compresion. 
Proc. ACL. 
148

