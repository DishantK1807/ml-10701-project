<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>N Badler</author>
<author>R Bindiganavale</author>
<author>J Bourne</author>
<author>M Palmer</author>
<author>J Shi</author>
<author>W Schuler</author>
</authors>
<title>A Parameterized Action Representation for Virtual Human Agents</title>
<date>1998</date>
<booktitle>Proceedings of the Workshop on Embodied Conversational Characters. Lake Tahoe, CA. Bechhofer</booktitle>
<contexts>
<context>s, we would have to ground the semantics in our agent’s world model, which is a considerable amount of work. Our use of generic action templates is similar to the Parameterized Action Representation (Badler et al., 1998; Bindiganavale et al., 2000). The Parameterized Action Representation is used as a means of communication between users and the agents. Our underlying representation is tied to a different agent cont</context>
</contexts>
<marker>Badler, Bindiganavale, Bourne, Palmer, Shi, Schuler, 1998</marker>
<rawString>Badler, N., R. Bindiganavale, J. Bourne, M. Palmer, J. Shi, and W. Schuler. 1998. A Parameterized Action Representation for Virtual Human Agents. Proceedings of the Workshop on Embodied Conversational Characters. Lake Tahoe, CA. Bechhofer S., F. van Harmelen, J. Hendler, I. Horrocks, D. L. McGuinness, P. F. Patel-Schneider and L. A. Stein.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Bhagat</author>
<author>A Leuski</author>
<author>E H Hovy</author>
</authors>
<title>OWL Web Ontology Language: Reference, W3C Recommendation</title>
<date>2004</date>
<booktitle>Proceedings of the 9th International Workshop on Parsing Technologies (ACL/SIGPARSE'05</booktitle>
<tech>http://www.w3.org/TR/owl-ref</tech>
<location>Vancouver, B.C</location>
<marker>Bhagat, Leuski, Hovy, 2004</marker>
<rawString>2004. OWL Web Ontology Language: Reference, W3C Recommendation.  http://www.w3.org/TR/owl-ref/ Bhagat, E., A. Leuski, and E.H. Hovy. 2005. Statistical shallow semantic parsing despite little training data. Proceedings of the 9th International Workshop on Parsing Technologies (ACL/SIGPARSE'05). Vancouver, B.C.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Bindiganavale</author>
<author>W Schuler</author>
<author>J Allbeck</author>
<author>N Badler</author>
<author>A Joshi</author>
<author>M Palmer</author>
</authors>
<title>Dynamically Altering Agent Behaviors using Natural Language Instructions</title>
<date>2000</date>
<contexts>
<context>round the semantics in our agent’s world model, which is a considerable amount of work. Our use of generic action templates is similar to the Parameterized Action Representation (Badler et al., 1998; Bindiganavale et al., 2000). The Parameterized Action Representation is used as a means of communication between users and the agents. Our underlying representation is tied to a different agent control system, and the contents</context>
</contexts>
<marker>Bindiganavale, Schuler, Allbeck, Badler, Joshi, Palmer, 2000</marker>
<rawString>Bindiganavale, R., W. Schuler, J. Allbeck, N. Badler, A. Joshi, and M. Palmer. 2000. Dynamically Altering Agent Behaviors using Natural Language Instructions.</rawString>
</citation>
<citation valid="true">
<date>2000</date>
<booktitle>Proceedings of Autonomous Agents Conference</booktitle>
<pages>293--300</pages>
<marker>2000</marker>
<rawString>Proceedings of Autonomous Agents Conference 2000, pp. 293–300.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J L Chercheur</author>
</authors>
<title>Case-Based Reasoning</title>
<date>1994</date>
<publisher>Morgan Kaufman Publishers</publisher>
<location>San Mateo, CA</location>
<marker>Chercheur, 1994</marker>
<rawString>Chercheur, J.L. 1994. Case-Based Reasoning. San Mateo, CA: Morgan Kaufman Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Castor</author>
<author>L E Pollux</author>
</authors>
<title>The use of user modelling to guide inference and learning</title>
<date>1992</date>
<journal>Applied Intelligence</journal>
<volume>2</volume>
<pages>37--53</pages>
<note>to appear</note>
<marker>Castor, Pollux, 1992</marker>
<rawString>Castor, A. and L.E. Pollux. 1992. The use of user modelling to guide inference and learning. Applied Intelligence, 2(1), pp. 37–53. DeVault, D., D. Traum, and R. Artstien, “Making Grammar-Based Generation Easier to Deploy in Dialogue Systems”, to appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet: An Electronic LexicalDatabase</title>
<date>1998</date>
<publisher>MIT Press</publisher>
<location>Cambridge, MA</location>
<marker>Fellbaum, 1998</marker>
<rawString>Fellbaum, C. (ed.) 1998. WordNet: An Electronic LexicalDatabase. Cambridge, MA: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Fikes</author>
<author>N Nilsson</author>
</authors>
<title>STRIPS: A New Approach to the Application of Theorem Proving to Problem Solving</title>
<date>1971</date>
<journal>Artificial Intelligence</journal>
<pages>2--189</pages>
<marker>Fikes, Nilsson, 1971</marker>
<rawString>Fikes, R., and N. Nilsson. 1971. STRIPS: A New Approach to the Application of Theorem Proving to Problem Solving. Artificial Intelligence, 2:189-208.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L B Grandchercheur</author>
</authors>
<title>Vers une modélisation cognitive de l'être et du néant</title>
<date>1983</date>
<booktitle>Fondement des Sciences Cognitives. Hillsdale, NJ: Lawrence Erlbaum Associates</booktitle>
<pages>6--38</pages>
<editor>In S.G. Paris, G.M. Olson, and H.W. Stevenson (eds</editor>
<marker>Grandchercheur, 1983</marker>
<rawString>Grandchercheur, L.B. 1983. Vers une modélisation cognitive de l'être et du néant. In S.G. Paris, G.M. Olson, and H.W. Stevenson (eds.), Fondement des Sciences Cognitives. Hillsdale, NJ: Lawrence Erlbaum Associates, pp. 6–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Gratch</author>
<author>J Rickel</author>
<author>E André</author>
<author>N Badler</author>
<author>J Cassell</author>
<author>E Petajan</author>
</authors>
<title>Creating Interactive Virtual Humans: Some Assembly Required</title>
<date>2002</date>
<journal>IEEE Intelligent Systems, July/August</journal>
<pages>54--63</pages>
<marker>Gratch, Rickel, André, Badler, Cassell, Petajan, 2002</marker>
<rawString>Gratch, J., J. Rickel, E. André, N. Badler, J. Cassell, and E. Petajan. 2002. Creating Interactive Virtual Humans: Some Assembly Required. IEEE Intelligent Systems, July/August, PP. 54–63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Gratch</author>
<author>S Marsella</author>
</authors>
<title>A domain independent framework for modeling emotion</title>
<date>2004</date>
<journal>Journal of Cognitive Systems Research</journal>
<volume>5</volume>
<pages>269--306</pages>
<contexts>
<context>well as plans that combine the two in causal networks. • An emotion module that appraises the state of the world in relation to beliefs and goals, resulting in emotion and specific coping strategies (Gratch and Marsella, 2004). The emotion model makes direct use of the task model representations, as well as factors such as temporal status, likelihood, controllability, and changeability. • A Dialogue Manager (DM), which re</context>
</contexts>
<marker>Gratch, Marsella, 2004</marker>
<rawString>Gratch, J. and S. Marsella. 2004. A domain independent framework for modeling emotion. Journal of Cognitive Systems Research 5(4): 269–306.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Kenny</author>
<author>A Hartholt</author>
<author>J Gratch</author>
<author>W R Swartout</author>
<author>D Traum</author>
<author>S Mareslla</author>
<author>D Piepol</author>
</authors>
<title>Building Interactive Virtual Humans for Training Environments</title>
<date>2007</date>
<booktitle>Proceedings of the Interservice/Industry Training, Simulation, and Education Conference (I/ITSEC</booktitle>
<contexts>
<context>ialogue Manager are developed in SOAR and TCL (Newell, 1990). Other modules are developed in Java and C++. For a more in-depth discussion of the general architecture and some of its application, see (Kenny et al., 2007). Below we describe some of the modules and the ways they use knowledge: • An Automated Speech Recognizer (ASR), converting vocalizations into words (Pellom, 2001). ASR needs the words (spelling and </context>
</contexts>
<marker>Kenny, Hartholt, Gratch, Swartout, Traum, Mareslla, Piepol, 2007</marker>
<rawString>Kenny, P., A. Hartholt, J. Gratch, W.R. Swartout, D. Traum, S. Mareslla, and D. Piepol. 2007. Building Interactive Virtual Humans for Training Environments. Proceedings of the Interservice/Industry Training, Simulation, and Education Conference (I/ITSEC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Knublauch</author>
<author>R W Fergerson</author>
<author>N F Noy</author>
<author>M A Musen</author>
</authors>
<title>The Protégé OWL Plugin: An Open Development Environment for Semantic Web Applications</title>
<date>2004</date>
<booktitle>Proceedings of the Third International Semantic Web Conference</booktitle>
<location>Hiroshima, Japan</location>
<marker>Knublauch, Fergerson, Noy, Musen, 2004</marker>
<rawString>Knublauch, H., R.W. Fergerson, N.F. Noy, and M.A. Musen. 2004. The Protégé OWL Plugin: An Open Development Environment for Semantic Web Applications. Proceedings of the Third International Semantic Web Conference. Hiroshima, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kopp</author>
<author>B Krenn</author>
<author>S Marsella</author>
<author>A Marshall</author>
<author>C Pelachaud</author>
<author>H Pirker</author>
<author>K Thorisson</author>
<author>H Vilhjalmsson</author>
</authors>
<title>Towards a Common Framework for Multimodal Generation: The Behavior Markup Language</title>
<date>2006</date>
<booktitle>6th International Conference on Intelligent Virtual Agents</booktitle>
<location>Marina</location>
<contexts>
<context>entations from the dialogue, task, and emotion models, as well as the NLG output and the body’s current position, orientation, and behaviors. The generator outputs a Behavioral Markup Language (BML) (Kopp et al, 2006). • A behavior blending system, SmartBody, which takes directives for motions and allocates resources (Thiebaux et al, 2008). This requires BML input and knowledge of the character’s attributes in th</context>
</contexts>
<marker>Kopp, Krenn, Marsella, Marshall, Pelachaud, Pirker, Thorisson, Vilhjalmsson, 2006</marker>
<rawString>Kopp, S., Krenn, B., Marsella, S., Marshall, A., Pelachaud, C., Pirker, H., Thorisson, K., Vilhjalmsson, H. &amp;quot;Towards a Common Framework for Multimodal Generation: The Behavior Markup Language&amp;quot;. 6th International Conference on Intelligent Virtual Agents (Marina del Rey, CA, August 21-23 2006).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lee</author>
<author>S Marsella</author>
</authors>
<title>Nonverbal Behavior Generator for Embodied Conversational Agents</title>
<date>2006</date>
<booktitle>Proceedings of the 6th International Conference on Intelligent Virtual Agents, pp 243–255</booktitle>
<location>Marina del Rey, CA</location>
<contexts>
<context>• A non-verbal behavior generator, which decides what body movements should be performed in order to convey the appropriate meaning of NLG output, emotions, perception and conversational regulation. (Lee &amp; Marsella, 2006). This requires representations from the dialogue, task, and emotion models, as well as the NLG output and the body’s current position, orientation, and behaviors. The generator outputs a Behavioral </context>
</contexts>
<marker>Lee, Marsella, 2006</marker>
<rawString>Lee, J. and S. Marsella. 2006. Nonverbal Behavior Generator for Embodied Conversational Agents. Proceedings of the 6th International Conference on Intelligent Virtual Agents, pp 243–255, Marina del Rey, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D McGuinness</author>
<author>F van Harmelen</author>
<author>eds</author>
</authors>
<title>OWL Web Ontology Language Overview, W3C Recommendation</title>
<date>2004</date>
<booktitle>Proceedings of the Twelfth Annual Conference of the Cognitive Science Society. Hillsdale, NJ: Lawrence Erlbaum Associates</booktitle>
<pages>252--262</pages>
<location>http://www.w3.org/TR/owl-features/ Martin, L.E</location>
<marker>McGuinness, van Harmelen, eds, 2004</marker>
<rawString>McGuinness, D., F. van Harmelen, eds. 2004. OWL Web Ontology Language Overview, W3C Recommendation, http://www.w3.org/TR/owl-features/ Martin, L.E. 1990. Knowledge Extraction. Proceedings of the Twelfth Annual Conference of the Cognitive Science Society. Hillsdale, NJ: Lawrence Erlbaum Associates, pp. 252–262.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Newell</author>
</authors>
<title>Unified Theories of Cognition</title>
<date>1990</date>
<location>Cambridge, MA: Harvard</location>
<contexts>
<context>out knowledge in different ways. Figure 2 shows a conceptual organization and information flow for these modules. The task reasoner, emotion module and Dialogue Manager are developed in SOAR and TCL (Newell, 1990). Other modules are developed in Java and C++. For a more in-depth discussion of the general architecture and some of its application, see (Kenny et al., 2007). Below we describe some of the modules </context>
</contexts>
<marker>Newell, 1990</marker>
<rawString>Newell, A. (1990) Unified Theories of Cognition. Cambridge, MA: Harvard.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Onyshkevych</author>
<author>S Nirenburg</author>
</authors>
<title>A Lexicon for Knowledge-Based MT</title>
<date>1995</date>
<journal>Machine Translation</journal>
<volume>10</volume>
<pages>5--57</pages>
<marker>Onyshkevych, Nirenburg, 1995</marker>
<rawString>Onyshkevych, B. and S. Nirenburg. 1995. A Lexicon for Knowledge-Based MT. Machine Translation 10(1–2): 5–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bryan Pellom</author>
</authors>
<title>SONIC: The University of Colorado Continuous Speech Recognizer&amp;quot;, University of Colorado, tech report #TR-CSLR-2001-01</title>
<date>2001</date>
<booktitle>Proceedings of the ONTOLEX Workshop at the International Conference on Natural Language Processing (IJCNLP). Jeju Island</booktitle>
<location>Boulder, Colorado</location>
<contexts>
<context> some of its application, see (Kenny et al., 2007). Below we describe some of the modules and the ways they use knowledge: • An Automated Speech Recognizer (ASR), converting vocalizations into words (Pellom, 2001). ASR needs the words (spelling and pronunciations) that appear in the domain, as well as their frequencies (Unigram, bigrams, and trigrams). • A Natural Language Understanding module (NLU), converti</context>
</contexts>
<marker>Pellom, 2001</marker>
<rawString>Bryan Pellom, &amp;quot;SONIC: The University of Colorado Continuous Speech Recognizer&amp;quot;, University of Colorado, tech report #TR-CSLR-2001-01, Boulder, Colorado, March, 2001 Philpot, A., E.H. Hovy, and P. Pantel. 2005. The Omega Ontology. Proceedings of the ONTOLEX Workshop at the International Conference on Natural Language Processing (IJCNLP). Jeju Island, Korea. October 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Rickel</author>
<author>J Gratch</author>
<author>R Hill</author>
<author>S Marsella</author>
<author>W R Swartout</author>
</authors>
<title>Steve Goes to Bosnia: Towards a New Generation of Virtual Humans for Interactive Experiences</title>
<date>2001</date>
<booktitle>Symposium on Artificial Intelligence and Interactive Entertainment</booktitle>
<publisher>AAAI Spring</publisher>
<location>Stanford University, CA</location>
<marker>Rickel, Gratch, Hill, Marsella, Swartout, 2001</marker>
<rawString>Rickel, J., J. Gratch, R. Hill, S. Marsella, and W.R. Swartout. 2001. Steve Goes to Bosnia: Towards a New Generation of Virtual Humans for Interactive Experiences. AAAI Spring Symposium on Artificial Intelligence and Interactive Entertainment. Stanford University, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Ruppenhofer</author>
<author>M Ellsworth</author>
<author>M R L Petruck</author>
<author>C R Johnson</author>
<author>J Scheffszyk</author>
</authors>
<title>FrameNet II: Extended Theory and Practice, version 1.3</title>
<date>2006</date>
<institution>Berkeley FrameNet Project, University of California</institution>
<location>Berkeley, CA</location>
<contexts>
<context>ly do not provide the amount of information that our modules need. Even slightly smaller and more semantically oriented ontologies, such as Mikrokosmos (Onyshkevych and Nirenberg, 1995) and FrameNet (Ruppenhofer et al., 2006) base their semantics purely on linguistic principles. While very useful for generic NLP, and for us for NLU and NLG, they do not provide enough information to support the more detailed reasoning req</context>
</contexts>
<marker>Ruppenhofer, Ellsworth, Petruck, Johnson, Scheffszyk, 2006</marker>
<rawString>Ruppenhofer, J., M. Ellsworth, M.R.L. Petruck, C.R. Johnson, and J. Scheffszyk. 2006. FrameNet II: Extended Theory and Practice, version 1.3. Berkeley FrameNet Project, University of California, Berkeley, CA.</rawString>
</citation>
<citation valid="true">
<title>SQWRL: Semantic Query-enhanced Web Rule Language</title>
<date>2008</date>
<note>Website http://protege.cim3.net/cgi-bin/wiki.pl?SQWRL</note>
<marker>2008</marker>
<rawString>SQWRL: Semantic Query-enhanced Web Rule Language. 2008. Website http://protege.cim3.net/cgi-bin/wiki.pl?SQWRL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W R Swartout</author>
<author>J Gratch</author>
<author>R Hill</author>
<author>E H Hovy</author>
<author>S Marsella</author>
<author>J Rickel</author>
<author>D Traum</author>
</authors>
<title>Toward Virtual Humans</title>
<date>2006</date>
<journal>AI Magazine</journal>
<volume>27</volume>
<contexts>
<context>y of Southern California (USC), which has built virtual agents for the Mission Rehearsal Exercise (MRE) (Rickel at al., 2001) and Stability And Support Operations – Simulation and Training (SASO-ST) (Swartout et al., 2006). 2. The Virtual Human Project 2.1 Project Overview The Virtual Humans Project, at USC’s Institute for Creative Technologies (ICT) and Information Sciences Institute (ISI), has the main goal of desig</context>
</contexts>
<marker>Swartout, Gratch, Hill, Hovy, Marsella, Rickel, Traum, 2006</marker>
<rawString>Swartout, W.R., J. Gratch, R. Hill, E.H. Hovy, S. Marsella, J. Rickel, and D. Traum. 2006. Toward Virtual Humans. AI Magazine 27(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>W R Swartout</author>
</authors>
<title>Virtual Humans</title>
<date>2006</date>
<booktitle>Proceedings of the Twenty-First National Conference on Artificial Intelligence (AAAI-06) (senior paper</booktitle>
<location>Boston, MA</location>
<marker>Swartout, 2006</marker>
<rawString>Swartout, W.R. 2006. Virtual Humans, Proceedings of the Twenty-First National Conference on Artificial Intelligence (AAAI-06) (senior paper). Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Thiebaux</author>
<author>A Marshall</author>
<author>S Marsella</author>
<author>M Kallmann</author>
</authors>
<title>SmartBody: Behavior Realization for Embodied Conversational Agents</title>
<date>2008</date>
<booktitle>Proc. 7th International Conference on Autonomous Agents and Multiagent Systems</booktitle>
<note>to appear</note>
<contexts>
<context>ation, and behaviors. The generator outputs a Behavioral Markup Language (BML) (Kopp et al, 2006). • A behavior blending system, SmartBody, which takes directives for motions and allocates resources (Thiebaux et al, 2008). This requires BML input and knowledge of the character’s attributes in the virtual environment. • The virtual environment, displaying the characters and their surroundings. We currently use the Unr</context>
</contexts>
<marker>Thiebaux, Marshall, Marsella, Kallmann, 2008</marker>
<rawString>Thiebaux, M., A. Marshall, S. Marsella, M. Kallmann. 2008. SmartBody: Behavior Realization for Embodied Conversational Agents. Proc. 7th International Conference on Autonomous Agents and Multiagent Systems. (to appear).</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Schubert</author>
<author>M Poesio</author>
<author>N Martin</author>
<author>M Light</author>
<author>C Hwang</author>
<author>P Heeman</author>
<author>G Ferguson</author>
<author>J Allen</author>
</authors>
<date>1996</date>
<booktitle>Knowledge Representation in the TRAINS-93 Conversation System, in International Journal of Expert Systems</booktitle>
<pages>9--1</pages>
<marker>Schubert, Poesio, Martin, Light, Hwang, Heeman, Ferguson, Allen, 1996</marker>
<rawString>Traum, D. , L. Schubert, M. Poesio, N. Martin, M. Light, C. Hwang, P. Heeman, G. Ferguson and J. Allen. 1996. Knowledge Representation in the TRAINS-93 Conversation System, in International Journal of Expert Systems 9(1):173-223.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Traum</author>
</authors>
<title>Semantics and Pragmatics of Questions and Answers for Dialogue Agents</title>
<date>2003</date>
<booktitle>in proceedings of the International Workshop on Computational Semantics</booktitle>
<pages>380--394</pages>
<contexts>
<context>es the NLU output to the context of previous conversation and other internal state, including the task and emotion models, updates the internal state, and plans new communications (Traum et al 2003b, Traum 2003). The dialogue manager uses both the task model representations as well as more structured abstractions of actions related to natural language. • A Natural Language Generation module (NLG), which con</context>
</contexts>
<marker>Traum, 2003</marker>
<rawString>Traum, D. 2003. Semantics and Pragmatics of Questions and Answers for Dialogue Agents in proceedings of the International Workshop on Computational Semantics, pp 380-394.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Fleischman</author>
<author>E Hovy</author>
</authors>
<title>NL Generation for Virtual Humans in a Complex Social Environment</title>
<date>2003</date>
<booktitle>in Papers from the AAAI spring symposium on Natural Language Generation in Spoken and Written Dialogue</booktitle>
<pages>151--158</pages>
<marker>Fleischman, Hovy, 2003</marker>
<rawString>Traum, D. , M. Fleischman, and E. Hovy. 2003. NL Generation for Virtual Humans in a Complex Social Environment in Papers from the AAAI spring symposium on Natural Language Generation in Spoken and Written Dialogue, pp. 151-158.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Traum</author>
<author>J Rickel</author>
<author>J Gratch</author>
<author>S Marsella</author>
</authors>
<title>Negotiation over Tasks in Hybrid Human-Agent Teams for Simulation-Based Training</title>
<date>2003</date>
<booktitle>in proceedings of the Second International Joint Conference on Autonomous Agents and Multi-Agent Systems</booktitle>
<pages>441--448</pages>
<location>Melbourne, Australia</location>
<contexts>
<context>nce texts and semantic representations from the domain (that we call a Framebank). • A task reasoner that can plan how to achieve goals and reason about alternatives and utilities of various actions (Traum et al, 2003b). The task reasoner focuses on states (that can have utilities for different agents) and tasks (that can have states as preconditions and effects), as well as plans that combine the two in causal ne</context>
<context>r (DM), which relates the NLU output to the context of previous conversation and other internal state, including the task and emotion models, updates the internal state, and plans new communications (Traum et al 2003b, Traum 2003). The dialogue manager uses both the task model representations as well as more structured abstractions of actions related to natural language. • A Natural Language Generation module (NL</context>
</contexts>
<marker>Traum, Rickel, Gratch, Marsella, 2003</marker>
<rawString>Traum, D., J. Rickel, J. Gratch, and S. Marsella. 2003. Negotiation over Tasks in Hybrid Human-Agent Teams for Simulation-Based Training, in proceedings of the Second International Joint Conference on Autonomous Agents and Multi-Agent Systems, Melbourne, Australia, pp. 441-448.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wahlsterm</author>
</authors>
<title>SmartKom: Foundations of Multimodal Dialogue Systems</title>
<date>2006</date>
<publisher>Springer</publisher>
<marker>Wahlsterm, 2006</marker>
<rawString>Wahlsterm W (Ed.), SmartKom: Foundations of Multimodal Dialogue Systems”, Springer, 2006.</rawString>
</citation>
</citationList>
</algorithm>

