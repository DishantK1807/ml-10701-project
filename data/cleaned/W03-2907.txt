Unsupervised Learning of Bulgarian POS Tags
Derrick Higgins
Educational Testing Service
dchiggin@alumni.uchicago.edu
Abstract
This paper presents an approach to the
unsupervised learning of parts of speech
which uses both morphological and syn-
tactic information.
While the model is more complex than
those which have been employed for un-
supervised learning of POS tags in En-
glish, which use only syntactic infor-
mation, the variety of languages in the
world requires that we consider mor-
phology as well. In many languages,
morphology provides better clues to a
word’s category than word order.
We present the computational model for
POS learning, and present results for ap-
plying it to Bulgarian, a Slavic language
with relatively free word order and rich
morphology.
1 Preliminaries
In designing a model to induce parts of speech
(POS categories) from a corpus, the first question
which arises is exactly what sort of entities the
target categories are. Depending on exactly how
these categories are defined, and which words are
taken to be members of each, different sorts of lin-
guistic information will clearly be relevant to their
identification.
For concreteness, we will be concerned with
the part-of-speech categories used in tagging
electronic texts such as the Bulgarian Treebank
(Simov et al., 2002). Since the goal of this paper
is to devise a model which will induce POS cate-
gories automatically from an untagged text, with
no prior knowledge of the structure of the lan-
guage, we will be using these tagged corpora as a
gold standard to evaluate the performance of com-
peting models.
2 Previous
approaches
While this study is unique in attempting to in-
corporate both syntactic and morphological fac-
tors, previous work by other researchers has ex-
plored unsupervised methods of deriving clusters
of words based on their linguistic behavior.
(Brown et al., 1992) is one of the first works
to use statistical methods of distributional analysis
to induce clusters of words. These authors define
an initial, very fine categorization of the vocabu-
lary of a corpus, in which each word is the sole
member of its own category, and then iteratively
merge these word classes until the desired level
of granularity is achieved. The objective func-
tion which they use to determine the optimal set
of word classes a0 for a corpus is the inter-class
mutual information between adjacent words in the
corpus. Since there is no practical way of deter-
mining the classification a0 which maximizes this
quantity for a given corpus, (Brown et al., 1992)
use a greedy algorithm which proceeds from the
initial classification, performing the merge which
results in the least loss in mutual information at
each stage. (Lee, 1997) pursues a similar ap-
proach in clustering nouns which occur as direct
objects to verbs, but uses a soft clustering algo-
rithm in place of the agglomerative clustering al-
gorithm used by Brown et al., and Lee uses the KL
divergence between the nouns’ distributions as a
measure of closeness, rather than the loss in inter-
class mutual information. (McMahon and Smith,
1996) employ a similar algorithm to that of Brown
et al., but use a top-down search in determining
word clusters, rather than a bottom-up one.
A number of other studies have attempted to use
distributional analysis to derive POS categories.
(Brill et al., 1990) use an ad-hoc similarity met-
ric to cluster words into POS-like classes, but the
problem is significantly simplified by their pre-
processing of the data to replace infrequent open-
class words with their correct POS tags. Finch
& Chater (1994) describe a model based on clus-
tering words in a vector space derived from their
corpus contexts, but perform this analysis only
for 1,000–2,000 common words in their USENET
corpus. Hinrich Sch¨utze (1995) presents perhaps
the most sophisticated model of word clustering
for POS identification. Sch¨utze first constructs
a context vector to represent each word’s co-
occurrence properties, and then trains a recurrent
neural network to predict the word’s location in the
space based on the context vectors for surrounding
words. The output vectors of the network are then
clustered to produce POS-like classes. This model
architecture, which classifies a word in context, al-
lows the same word to be tagged differently, de-
pending on how it is used.
3 Model
components
The approach to the identification of POS cate-
gories which we pursue in this paper attempts to
incrementally home in on an optimal set of cat-
egories through the incorporation of morpholog-
ical information and local syntactic information.
The procedure is uses gradient descent training of
a hidden neural network model, including an em-
bedded morphological model based on informa-
tion from the Linguistica (Goldsmith, 2001) en-
gine for unsupervised morphological analysis. Be-
cause this morphological information is the output
of a completely unsupervised process of induction,
our model of POS category induction is also an un-
supervised one.
In the following subsections, we provide a short
summary of each of these components of our
model of part-of-speech learning, and in Section
4, we present the results of testing our model on a
tagged Bulgarian corpus.
3.1 Hidden
neural networks
The model which we use for inducing clusters of
word tokens in a corpus (which ought to corre-
spond to parts of speech) is actually a generaliza-
tion of a hidden Markov model, called a hidden
neural network (HNN) (Baldi and Chauvin, 1996;
Riis, 1998). Each state in the HNN corresponds to
a single word cluster, and the category to which a
word belongs is determined by Viterbi decoding.
In a hidden neural network, either the transition
probabilities, or the observation probabilities, or
both, may be replaced with a feed-forward neural
network which computes these values on the fly,
possibly as a function of information from else-
where in the observation sequence. This gives an
HNN considerably more expressive power than an
HMM, because it is not tied strictly to the inde-
pendence assumptions which are inherent in the
architecture of a hidden Markov model.
Gradient descent training of the embedded net-
works and HNN parameters is entirely straight-
forward, and is described by (Baldi and Chauvin,
1996).
3.2 Linguistica
While the syntactic information in our model is
derived from the state transition and observa-
tion parameters through HNN training, the mor-
phological information available to our model of
POS category induction is provided by the Lin-
guistica (Goldsmith, 2001) system for unsuper-
vised morphological learning. Linguistica apples
a minimum-description length criterion to induce
the morphological categories of a language, such
as stems and suffixes, from an unlabeled corpus
of text from that language. It is important that
the morphological analysis which Linguistica pro-
vides is not informed by prior knowledge of the
language, since this allows our method to remain
an unsupervised approach to POS learning.
In Goldsmith’s framework, a morphological
analysis consists of three primary components: a
list of stems, a list of suffixes, and a list of signa-
tures. A signature, in Goldsmith’s conception, is
similar to the notion of a morphological paradigm,
but more general, and automatically determined
from an analysis of a corpus. A stem’s signature
consists of a list of all of the suffixes which may
occur with that stem. Table 1 illustrates some of
the highest-ranked signatures found in Linguistica
analyses of text from Bulgarian. The occurrence
of the string “NULL” in a signature indicates that
the stem may also occur with no suffix.
Notable in these signatures is the identification
of the gender-markings a0 a1a3a2 a0a5a4 a2 a0a7a6 .
Table 1: Top-ranked signatures found by Linguis-
tica, for Bulgarian
Signature Exemplars
a0 .
a1 .a2
a0a4a3
a1
a0a6a5a4a7a9a8a11a10a13a12a4a0a15a14a17a16a13a10
a18a20a19 a0a15a12a21a10a13a22a24a23 a19 a16 ,
a25a26a25a26a25
NULL.a5a6a0 a27a20a0a4a3a28a0a21a10a21a29 a2a31a30 a16a32a0a21a10 , a25a26a25a26a25
a30a32a1a21a33
a27a20a0a21a10a13a7a34a12
a2
a27
a2
a29a35a0 ,
a25a26a25a26a25
NULL.a5a15a23 a27a4a23 a30a32a1 a10a36a8 a2 a16a20a5a15a0a37a8a15a5 a1 a10 , a25a26a25a26a25
a7a38a23a39a8a15a5
a2
a19
a1
a10a24a40 a18
a2
a16a41a7a9a8
a1 , a25a26a25a26a25
NULL.a5 a2 a29 a2 a8 a2a31a30 a8 a2 a10 a19 a0a15a42 a2 a10 , a25a26a25a26a25
a7a37a43a45a44a46a23a38a7a9a5a15a12a15a47a32a12a4a0a15a16a41a23a31a10a35a48
a1
a19
a2
a8
a2 , a25a26a25a26a25
3.3 Classification
The morphological analysis provided by Linguis-
tica, however, does not directly make a prediction
about a word’s part of speech, however. It only
tells us whether a word is morphologically simple
or complex, and if it is complex, what its stem and
suffix are. In order to derive a way of predicting
a word’s part of speech from this morphological
information, we constructed neural network clas-
sifiers. The input features for the networks are
comprised of the morphological features induced
by Linguistica’s unsupervised learning algorithm,
and the target classes are POS categories of the
sort used in tagged corpora.
More precisely, the input features are:
a49 The word’s length, in letters
a49 The length of the stem, in letters
a49 The length of the suffix, in letters
a49 A binary feature indicating whether the word
contains punctuation characters
a49 For each suffix identified by Linguistica,
there is a binary feature indicating whether
that suffix is used in the word.
a49 For each suffix identified by Linguistica (in-
cluding NULL), there is a binary feature in-
dicating whether that suffix occurs in the
word’s signature.
Ultimately, we are interested in the unsuper-
vised learning of POS categories, so the training
data used by our classifiers will be provided by
our hidden Markov model, rather than directly by
a tagged corpus. In this section, though, we pro-
vide the results of training the classifiers on a gold
Table 2: Results on prediction of Bulgarian POS
tags from morphological information
Training Validation Test
Baseline 21.7% 23.8% 21.1%
Single-layer 65.6% 66.8% 64.9%network
Multi-layer 68.0% 67.9% 67.9%network
standard tagged corpus, in order to demonstrate to
what degree POS tags are predictable on the basis
of morphology alone.
Our Bulgarian corpus consists of about 76,000
words of text collected as part of the develop-
ment of the Bulgarian Treebank project (Simov
et al., 2002). The tagset used for this project is
very small, consisting of only 11 tags. Bulgar-
ian makes a good test case because it has a high
degree of inflection, which necessitates the use
of morphological information in determining POS
classes, where this might be deemed superfluous
in a language like English, which encodes so much
through word order.
Table 2 shows the performance of our classifiers
on the Bulgarian data set. The classifiers each used
36,000 items for training, 10,000 for validation,
and 15,000 as a test set.
4 Learning
parts of speech
In this section, we present the results of a mod-
eling experiment designed to assess the usefulness
of employing both syntactic and morphological in-
formation in the automatic induction of parts of
speech from a corpus of text.
In evaluating this model, we will use the mea-
surement of mutual information between the gold
standard POS tagging and the model’s assignment
of induced tags. Since the classes induced by each
model will not correspond perfectly to any POS
tag found in the target distribution, such as noun,
verb, or adverb, we cannot use a simple perfor-
mance statistic such as “percent correctly classi-
fied”. The mutual information allows us to mea-
sure how closely two distinct distributions match,
and is given by Equation 1, where a50a38a51 and a50a53a52 range
over the classes in the induced and target classifi-
cations, respectively,
a54
a55a57a56
a50a59a58 refers to the empirical
frequency of word tokens tagged with category a50 ,
and
a54
a55a57a56
a50a39a51a41a50a53a52a28a58 refers to the empirical frequency of
word tokens tagged as category a50a38a51 by the model,
and having category a50a59a52 in the gold standard.
a0a2a1a4a3a6a5a8a7a10a9 a11
a12a14a13a8a15a17a16a6a18 a19a8a20a8a21a8a22a24a23a25a20a2a26
a12a28a27a29a15a30a16a32a31a34a33a4a35a37a36 a23 a31
a54
a55a57a56
a50a39a51a32a50a53a52a26a58a39a38a41a40a43a42
a54
a55a57a56
a50 a51 a50 a52 a58
a54
a55a57a56
a50a39a51a53a58
a54
a55a57a56
a50a53a52a28a58
(1)
A high value for the mutual information indi-
cates good agreement between the distributions,
and this statistic will tend to zero if the distribu-
tions are uncorrelated. The mutual information
metric has the advantages that it does not require
any human intervention in the evaluation process,
and it does not make any assumptions regarding
exactly how the two distributions must match up.
(Brill and Marcus, 1992) use a native informant
to derive a set of categories from a hierarchical
clustering of words, and explicitly label them (as
“noun”, “verb”, etc.). Given this explicit human
intervention in the induction procedure (and a cer-
tain shuffling of the Penn Treebank category la-
bels), they are able to give evaluation statistics
for their method in terms of a simple “percent-
age correct”. Both (Hughes and Atwell, 1994)
and (Sch¨utze, 1995) also evaluate their systems by
means of a statistic which approximately measures
the percentage of words tagged correctly. As in
our system, of course, there is no necessary rela-
tionship between the induced set of categories and
the target categories in the gold standard corpus.
However, these authors attempt to avoid this prob-
lem by identifying each induced cluster of words
with the target category it most often represents.
So, for example, if the model induces a class of
words which includes many nouns, but only a few
verbs, all of the nouns will be counted as correct,
and the verbs as incorrect. One difficulty for this
method of evaluation is that it is very sensitive
to the number of classes induced by a model. In
the most extreme case, if every word token is as-
signed to its own cluster, this evaluation metric
will judge that the model has provided a classi-
fication which is 100% correct. (Sch¨utze, 1995)
simply deals with classifications of words with ex-
actly 200 clusters, so that the question does not
arise. This sensitivity of the evaluation metric to
the number of clusters induced is also a problem
using mutual information, since the mutual infor-
mation between distributions increases not only
with the similarity of the distributions, but also
with their entropies. Since we consider induced
classifications of only one size, as in Sch¨utze’s
work, the problem is not crucial in this context.
A shortcoming which is common to all of these
approaches using a “percent correct” measurement
to evaluate models of part-of-speech induction is
that in assigning an induced word cluster to a
known target category, such as noun, and evalu-
ating the goodness of the cluster according to how
well it represents the class noun, the assumption
is made that it is fine for a target class to be rep-
resented by multiple induced clusters, but it is un-
acceptable for a single induced category to repre-
sent a combination of multiple target categories.
Of course, this issue does not arise for our ap-
proach. Using the mutual information as our eval-
uation metric, the target and induced tag distribu-
tions are treated on a par.
4.1 HNN
training
In this section, we present the results of applying a
ten-state HNN model of syntactic and morpholog-
ical factors relating to POS categories to the Bul-
garian Treebank corpus.
In Section 3.3, we constructed networks which
learned to map words to their POS tags on the
basis of morphological information about each
word (provided by the Linguistica automatic mor-
phological analysis engine). Using a single-layer
or multi-layer perceptron as our model of mor-
phological information, and the parameters of an
HNN to represent information about word order,
the combined model can be trained using gradient
descent. As discussed above, an HNN is distin-
guished from a hidden Markov model in that cer-
tain HMM parameters are replaced by the outputs
of feed-forward neural networks. Commonly, the
observation probabilities associated with a state
are calculated on the fly by a neural network.
Thus, while the probability of a string a44a20a51a36a25a26a25a26a25a17a44a46a45 ac-
cording to an HMM is computed as in (2), in this
common type of HNN the probability would be
calculated as in (3), where the observation proba-
bility a47a2a48a14a49a28a50a51a6a49a53a52 a13 has been replaced by a function a54a55a48a14a49
defined by the neural network associated with state
a0a2a1 .
a55a4a3a6a5a7a5 a56
a44a6a51a24a25a26a25a26a25 a44 a45a4a58
a9 a11
a48a9a8a11a10a12a10a12a10a48a9a13
a14
a48a9a8
a45
a15
a1a17a16a19a18a21a20
a48 a49a28a50 a48a14a49a53a52
a13
a47 a48a14a49a28a50a51a6a49a53a52
a13 (2)
a55a4a3a6a22a23a22 a56
a44a6a51a24a25a26a25a26a25 a44 a45a4a58
a9 a11
a48 a8 a10a12a10a12a10a48 a13
a14
a48 a8
a45
a15
a1a17a16a19a18a21a20
a48 a49a28a50 a48a14a49a53a52
a13
a54 a48 a49
a56
a44
a1a17a24
a51 a58 (3)
The model introduced in this section differs in
two ways from the sort of HNN defined by Equa-
tion 3. First, in the general formulation it is per-
fectly acceptable for the networks a54 a48 to be entirely
different for each state a0 in the model. However, in
the HNN model of this section, there is only a sin-
gle neural network used for all ten states. It there-
fore fulfills the function of a match network (Riis,
1998), expressing a probability that the observed
symbol is generated by a certain state. Since the
network is no longer specific to a certain state, we
re-write a54 a48 a56 a44a4a58 as a54 a56 a0a26a25 a44a4a58 .
Second, in addition to the match network which
uses morphological features to predict the likeli-
hood of a word belonging to a certain class, the
model of this section also employs a set of obser-
vation probabilities for each state, exactly as in a
normal HMM. The idea is that the morphological
match networks express broad form-based corre-
lations which hold over parts of speech, for exam-
ple, that English words with an -ing suffix tend to
be verbs. The use of observation probabilities in
addition to the match networks allows for lexical
exceptions to these morphological generalizations.
For example, the most common use of the word ic-
ing is as a noun. With this final addition of a “lexi-
cal component” to this section’s model of POS in-
duction, the probability equation takes on the form
in (4), where a54 a56 a0a26a25 a44a4a58 is the morphologically-based
likelihood of a word belonging to the class ex-
pressed by state a0 , and a47 a48a6a50a51 is the corresponding
lexical likelihood.
a55a27a3a23a22a6a22 a56
a44a6a51a24a25a26a25a26a25 a44 a45a4a58
a9
a11
a48 a8 a10a12a10a12a10a48 a13
a14
a48 a8
a45
a15
a1a17a16a19a18a21a20
a48a14a49a28a50 a48a14a49a53a52
a13
a54
a56
a0a2a1a28a25
a44
a1a17a24
a51 a58a8a47 a48 a49 a50a51a6a49a53a52
a13 (4)
Exploratory analysis revealed that the cluster-
ing algorithm of Brown et al. proved to be useful
in defining the initial state of our model, so we use
this clustering method to define the initial state of
our HNN parameters. The observation probabili-
ties for a given state, representing a certain word
class, are determined by the relative frequencies
of words belonging to that class (as determined by
the algorithm of (Brown et al., 1992)); the prob-
abilities of other words are set to a small initial
value. The transition probabilities and initial prob-
abilities for each state are initialized to uniform
values. Determining the initial state of the model
in this manner guarantees that the HMM’s perfor-
mance will be equal to that of Brown et al.’s clus-
tering method before we begin training, since the
two models assign tags to the corpus identically.
We have found that Baum-Welch training of a
model initialized in this way is counterproductive
over the long run for determining POS categories.
However, a small amount of Baum-Welch train-
ing can be useful in remedying misclassifications
in the model’s initial state. For this reason, in
the experiments of this section we first train our
HMM for ten epochs using the Baum-Welch algo-
rithm, only then incorporating the neural network
as our morphological component, and commenc-
ing HNN training using gradient descent.
The final piece of information lacking is the ini-
tial state of the embedded neural network. For
the experiments described here, we used a single-
layer perceptron as the morphological component.
We could randomly initialize the weights of these
models, but that would be detrimental to the initial
performance of the model, and training the HNN
from that state would be very slow and likely to get
caught in local maxima of the corpus likelihood.
Therefore, we use the model’s initial state to train
the initial parameters of the embedded networks
off-line. To do this, we present each word token
in the corpus as a training example to the network,
and using the quickprop algorithm, cause the net-
work to learn a mapping between the morphologi-
cal features of a word and the class assigned to that
word by the network. Since these morphological
generalizations are based on the initial categoriza-
tion provided by the algorithm of (Brown et al.,
1992), we hope that they will foster speedy con-
vergence of HNN training.
4.1.1 Results
The results of this combined HNN model, mak-
ing use of both morphological and syntactic in-
formation in constructing linguistic categories, are
presented in Figures 1–2 on the following pages.
In Figure 1 we present the evolution of the mu-
tual information metric over the course of training
our model on Bulgarian data. The graph repre-
sents the change in mutual information between
target classifications and induced classifications
for the model, which uses a single-layer morpho-
logical network. The mutual information begins at
about a25a1a0a3a2 for the model, seeded by the algorithm
of Brown et al., and after ten epochs of Baum-
Welch training, this sinks to around a25a5a4a6a0a3a7 . It then
rises to about a25a1a0a3a8 after morphological information
is added, and HNN training improves this value to
over a25a1a0a3a9 , showing that the consistency of the in-
duced word clusters with respect to the target tag
assignment is improving.
In Figure 2 we present the categories con-
structed by the same HNN model. For each state in
the hidden neural network model, Figure 2 shows
a breakdown of the words assigned to that cluster
according to the tags they are assigned in the gold
standard. Some categories, such as those num-
bered 1 and 4, are entirely homogeneous. Others
show tendencies of different strengths toward dif-
ferent target classes. In any event, the mutual in-
formation criterion shows that this clustering, al-
though not ideal, is an improvement over the clus-
ters derived using syntactic information alone.
In sum, adding morphological information to
these models of part-of-speech acquisition leads
to an increase in performance on Bulgarian data,
as measured by our criterion of mutual informa-
tion. It is somewhat difficult to draw firm conclu-
sions from experiments on a single language, but
we hope that this approach will be useful in ana-
lyzing other languages which have complex mor-
phology.
5 Future
directions
What we hope to have accomplished is a demon-
stration that the use of morphological information
in a model of part-of-speech induction can be of
value, and more specifically that the combination
of morphological and syntactic generalizations ac-
cording to the hidden neural network models pre-
sented here is a practical way of implementing this
approach.
However, the results of the preceding section
represent only a first step in exploring how dis-
parate sources of linguistic information may be put
to use in deriving POS classes. While we have
shown an increase in performance over a purely
syntactic baseline model (the algorithm of (Brown
et al., 1992)), there are a number of avenues to
pursue in extending this work.
First, the quality of the clusters produced will
certainly be increased by using a larger training
corpus. The corpus used for training our models
was on the order of 100,000 words, whereas that
used by (Brown et al., 1992) was around 1,000
times this size.
Second, it is worth exploring the parameter of
the number of clusters assumed in our model. We
have chosen to limit ourselves to ten induced parts
of speech, for efficiency of training; however, most
previous work in this area has assumed a larger set
of clusters.
A third area for improvement is to try different
initial syntactic clustering algorithms as a way to
seed the HMM on which our HNN model is based.
In this article, we used the algorithm of (Brown et
al., 1992) to initialize the model. However, this
is not the only syntactically-based method for pro-
ducing word clusters. Since the final state of the
model is dependent on the quality of the initial set
of clusters, it seems worthwhile to try out other
initialization procedures.
Fourth, it is worth investigating whether our ap-
proach could be improved upon by attempting to
“bootstrap” generalizations from frequent words
before attempting to analyze less-frequent ones.
After an initial round of HNN training using only
high-frequency words, low-frequency words could
be added with small initial observation probabili-
ties in each state, and the model could be retrained.
Finally, an important direction for further re-
search is the investigation of a larger set of lan-
guages. For our models to be convincing as
language-independent ways of acquiring linguistic
information, we need to address a broader survey
of languages.
Figure 1: Mutual information of Bulgarian word classes induced with respect to the target distributions,
over the course of HNN training.
0.78
0.79
0.8
0.81
0.82
0.83
0.84
0.85
0.86
0.87
0 800 1600 2400 3200 4000 4800 5600 6400 7200 8000
Mutual Information
Training epochs
Single-layer network
HMM initialized with MI clustering algorithm
After 10 epochs Baum-Welch training
After incorporation of classifier
After 8000 epochs of HNN training
References
Pierre Baldi and Yves Chauvin. 1996. Hybrid mod-
eling, HMM/NN architectures, and protein applica-
tions. Neural Computation, 8:1541–1565.
Eric Brill and Mitch Marcus. 1992. Tagging an un-
familiar text with minimal human supervision. In
Proceedings of the AAAI Symposium on Probabilis-
tic Approaches to Natural Language, pages 10–16.
Eric Brill, David Magerman, Mitch Marcus, and Beat-
rice Santorini. 1990. Deducing linguistic structure
from the statistics of large corpora. In Proceedings
of the DARPA Speech and Natural Language Work-
shop, pages 275–282.
Peter F. Brown, Vincent J. Della Pietra, Peter V. deS-
ouza, Jennifer C. Lai, and Robert L. Mercer. 1992.
Class-based n-gram models of natural language.
Computational Linguistics, 18(4):467–479.
Steven Finch and Nick Chater. 1994. Distributional
bootstrapping: From word class to proto-sentence.
In Proceedings of the Sixteenth Annual Conference
of the Cognitive Science Society, pages 301–306.
John Goldsmith. 2001. Unsupervised learning of the
morphology of a natural language. Computatial Lin-
guistics, 27(2):153–198.
John Hughes and Eric Atwell. 1994. The automated
evaluation of inferred word classifications. In Eu-
ropean Conference on Artificial Intelligence, pages
535–539.
Lillian Lee. 1997. Similarity-Based Approaches to
Natural Language Processing. Ph.D. thesis, Har-
vard University, Cambridge, Massachusetts.
John G. McMahon and Francis J. Smith. 1996. Im-
proving statistical language model performance with
automatically generated word hierarchies. Compu-
tational Linguistics, 22(2):217–247.
Søren Kamaric Riis. 1998. Hidden Markov Models
and Neural Networks for Speech Recognition. Ph.D.
thesis, Technical University of Denmark.
Hinrich Sch¨utze. 1995. Distributional part-of-speech
tagging. In Proceedings of the 7th Conference of the
European Chapter of the Association for Computa-
tional Linguistics (EACL’95), pages 141–148.
Kiril Simov, Petya Osenova, Milena Slavcheva, Sia
Kolkovska, Elisaveta Balabanova, Dimitar Doikoff,
Krassimira Ivanova, Alexander Simov, and Milen
Kouylekov. 2002. Building a linguistically inter-
preted corpus of bulgarian: the bultreebank. In Pro-
ceedings of LREC 2002, Canary Islands, Spain.
Figure 2: Bulgarian word clusters induced through HNN training (single-layer network)
0
1000
2000
3000
4000
5000
6000
Frequency
POS tag
Cluster 0
PT
PREPOS
CONJ
ADJ
VERB NOUN
0
500
1000
1500
2000
2500
3000
Frequency
POS tag
Cluster 1
PREPOS 0
500
1000
1500
2000
2500
3000
Frequency
POS tag
Cluster 2
VERB NOUN PRON
ADJ
PT
ADV
0
500
1000
1500
2000
2500
Frequency
POS tag
Cluster 3
CONJ PART
0
500
1000
1500
2000
2500
Frequency
POS tag
Cluster 4
PT
0
200
400
600
800
1000
1200
1400
1600
1800
Frequency
POS tag
Cluster 5
PRON VERB
0
500
1000
1500
2000
2500
3000
Frequency
POS tag
Cluster 6
NOUN VERB
ADJ
PRON CONJ
ADV
PREPOS
PART
NUM
0
50
100
150
200
250
300
350
400
450
500
Frequency
POS tag
Cluster 7
VERB NOUN
0
500
1000
1500
2000
2500
3000
Frequency
POS tag
Cluster 8
PART CONJ PRON
ADV
VERB
ADJ
NOUN
PREPOS
0
1000
2000
3000
4000
5000
6000
7000
8000
9000
Frequency
POS tag
Cluster 9
NOUN
ADJ
VERB PRON
NUM ADV

