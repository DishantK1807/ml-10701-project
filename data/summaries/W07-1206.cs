Work In previous work addressing nested entities, Shen et al.(2003), Zhang et al.(2004), Zhou et al.(2004), Zhou (2006), and Gu (2006) considered the GENIA 2Both corpora are represented in XML with standoff annotation, potentionally allowing overlapping NEs.
P06-1112
Together with Shen et al.(2006) it is one of the first results to confirm the potential of the factored model.
P06-1112
Setup Experiments aimed at extracting protein-protein interactions for Bakers yeast (Sacharomyces Cerevesiae) to assess BioNoculars (Cherry et al., 1998).
P98-1013
State of the art decoders provide the ability of handling different word forms directly in what has been called factored translation models (Shen et al., 2006).
P06-1112
This approach significantly outperforms the multi-class perceptron on the same dataset based on WORDNET 1.6 and 1.7.1. 1 Introduction Lexical-semantic resources have been applied successful to a wide range of Natural Language Processing (NLP) problems ranging from collocation extraction (Pearce, 2001) and class-based smoothing (Clark and Weir, 2002), to text classification (Baker and McCallum, 1998) and question answering (Pasca and Harabagiu, 2001).
P98-1013
This paper illustrates the above claims with respect to three lexical resources ??FrameNet (Baker et al., 1998), PropBank (Palmer et al., 2005) and VerbNet (Schuler, 2005) ??that convey information about lexical predicates and their arguments.
J05-1004 P98-1013
Novischi and Moldovan (2006) use a technique that builds on a combination of lexical chains and verb argument structures extracted from VerbNet to re-rank answer candidates.
P06-1113
Ding and Palmer (2005) introduced a version of probabilistic extension of Synchronous Dependency Insertion Grammars (SDIG) to deal with the pervasive structure divergence.
J05-1004
Secondly, Shen and Klakow (2006) use dependency relation paths to rank answer candidates.
P06-1112
Dependency trees have been used in a variety of NLP applications, such as relation extraction (Culotta and Sorensen, 2004) and machine translation (Ding and Palmer, 2005).
J05-1004
This input type has been used successfully for speech to text translation (Shen et al.2006). Every factor on the target language can have its own language model.
P06-1112
Moses has shown that it achieves results comparable to the most competitive and widely used statistical machine translation systems in translation quality and run-time (Shen et al.2006). It features all the capabilities of the closed sourced Pharaoh decoder (Koehn 2004).
P06-1112
