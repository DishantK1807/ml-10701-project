Many LTAG parsers were proposed, such as the head-driven Earley style parser (Lavelli and Satta, 1991) and the head-corner parser (van Noord, 1994).
E91-1006
Both left-corner strategy (Ratnaparkhi, 1997; Roark, 2001; Prolo, 2003; Henderson, 2003; Collins and Roark, 2004) and head-corner strategy (Henderson, 2000; Yamada and Matsumoto, 2003) were employed in incremental parsing.
J01-2004 P04-1015 W97-0301
Researches in statistical CFG parsing (Ratnaparkhi, 1997; Collins, 1999) and psycholinguistics 812 (Shieber and Johnson, 1993) showed that this strategy is desirable for NLP.
W97-0301
In fact, the idea of incremental parsing with LTAG is closely related to the work on Supertagging (Joshi and Srinivas, 1994).
C94-1024
A=adjoin, T=attach, C=conjoin, G=generate In this paper, we use the perceptron-like algorithm proposed in (Collins, 2002) which does not suffer from the label bias problem, and is fast in training.
W02-1001
It appears that by carefully modifying the definition of visible spines, we can represent scrambling structures, which at present can only be represented by MultiComponent TAG (Becker et al., 1991).
E91-1005
Conjunction is similar to what was originally proposed in (Sarkar and Joshi, 1996).
C96-2103
We use the LTAG-spinal treebank described in (Shen and Joshi, 2005), which was extracted from the Penn Treebank (PTB) (Marcus et al., 1994) with Propbank (Palmer et al., 2005) annotations.
C94-1024 J05-1004
We also employ the voted perceptron algorithm (Freund and Schapire, 1999) and the early update technique as in (Collins and Roark, 2004).
P04-1015
Attachment in LTAG-spinal is similar to sister adjunction (Chiang, 2000) in Tree Insertion Grammar (TIG) (Schabes and Waters, 1995).
J95-4002 P00-1058
Vijay-Shanker and Joshi (1985) introduced the first TAG parser in a CYK-like algorithm.
P85-1011
and Future Work The parser proposed in this paper is an incremental parser, so the accuracy on dependency is lower than that for chart parsers, for example like those reported in (Collins, 1999; Charniak, 2000).
A00-2018
There is also some relationship of LTAG-spinal to the spinal form context-free tree grammar, as in (Fujiyoshi and Kasai, 2000) 2In (Riezler et al., 2002), the MaxEnt model was used to rerank the K-best parses generated by a rule-based LFG parser.
P02-1035
Thus, the LTAGspinal parsing model to be proposed in Section 3 can be viewed as a parser at the meta-grammar (Candito, 1998; Kinyon and Prolo, 2002) level for traditional LTAG.
P98-1033 W02-1507
Learning Algorithm Many machine learning algorithms have been successfully applied to parsing, incremental parsing, or shallow parsing (Ratnaparkhi, 1997; Punyakanok and Roth, 2001; Lafferty et al., 2001; Taskar et al., 2003), which can be applied to our incremental parsing algorithm.
W97-0301
