Following Moore (2005), we divide links in an alignment into four categories:
H05-1011
log-linear combination of the IBM models and the HMM model. Cherry and Lin (2003)
P03-1012
Moore, Yih, and Bode (2006) to introduce a linked word count feature that simply counts
P06-1065
for the source and target languages, respectively. Please refer to Brown et al. (1993) for
J93-2003
Blunsom, Phil and Trevor Cohn. 2006.
P06-1009
AER scores achieved by GIZA++, Cross-EM (Liang, Taskar, and Klein 2006), and Vigne.
N06-1014
often the same in both languages, Taskar, Lacoste-Julien, and Klein (2005) use a feature
H05-1010
such as the IBM Models 1–5 (Brown et al. 1993) as features in a discriminative model.
J93-2003
proves to be effective in machine translation (Rosti, Matsoukas, and Schwartz 2007;
P07-1040
Moore, Robert C. 2005. A discriminative
H05-1011
Chiang, David. 2005. A hierarchical
P05-1033
semi-supervised algorithm. Ayan and Dorr (2006b) use a maximum entropy model to
N06-1013 P06-1002
J. Och is the most popular alignment system nowadays. Liang, Taskar, and Klein (2006)
N06-1014
Och, Franz J. and Hermann Ney. 2004.
J04-4002
Liu, Yang, Qun Liu, and Shouxun Lin. 2005.
P05-1057
Och, Franz J. and Hermann Ney. 2002.
P02-1038
ror rate training (MERT) algorithm proposed by Och (2003) to find feature weights
J03-1002 P03-1021
each sub-model as a feature as suggested by Fraser and Marcu (2006). We distinguish
P06-1097 W06-1606
Ayan, Necip Fazil and Bonnie J. Dorr. 2006b.
N06-1013 P06-1002
Koehn, Philipp and Hieu Hoang. 2007.
D07-1091
Moore (2005) 500K 223 7.5
H05-1011
Ney 2003), (6) grow-diag-final (Koehn, Och, and Marcu 2003), and (7) Cross-EM (Liang,
J03-1002 N03-1017 P03-1021
combine word alignments. Cherry and Lin (2006) show that introducing soft syntactic
P06-2014
Melamed, I. Dan. 2000. Models for
J00-2004
Liang, Taskar, and Klein (2006) 1.1M 347 4.9
N06-1014
similar to those of Och and Ney (2003).
J03-1002 P03-1021
Och, Franz J. and Hermann Ney. 2003. A
J03-1002 P03-1021
than before, Och (2003) suggests only evaluating the loss at values in between the
J03-1002 P03-1021
Moses to improve rule coverage (Liu, Liu, and Lin 2006). The best generative alignment
P06-1077
methods. As a first attempt, Och and Ney (2003) proposed the Model 6, which is a
J03-1002 P03-1021
Och and Ney (2003) 1.5M 500 5.2
J03-1002 P03-1021
Moore (2005) finds that word alignments between closely related languages tend to be
H05-1011
Vogel, Stephan and Hermann Ney. 1996.
C96-2141
et al. (1993). Vogel and Ney (1996) propose a first-order Hidden Markov model (HMM)
C96-2141
Chiang, David. 2007. Hierarchical
J07-2003
machine translation (Brown et al. 1993).
J93-2003
Fraser, Alexander and Daniel Marcu. 2007b.
D07-1006 J07-3002
1. HLT/NAACL 2003 shared task (Mihalcea and Pedersen 2003). As part of
W03-0301
information sources. Our linear model is similar to that of Moore, Yih, and Bode (2006).
P06-1065
Lacoste-Julien et al. (2006) 1.1M 247 3.8
N06-1015
Our work can be seen as an application of the linear model (Och 2003) in word
J03-1002 P03-1021
(Koehn, Och, and Marcu 2003; Och and Ney 2004; Chiang 2005, 2007), but also for
D07-1091 J03-1002 J04-4002 J07-2003 N03-1017 P03-1021 P05-1033
Niehues, Jan and Stephan Vogel. 2008.
W08-0303
Blunsom and Cohn (2006) 1.1M 347 5.2
P06-1009
Brown et al. (1993) propose two distortion models for Model 4: d
J93-2003
way, our approach uses asymmetric generative models (Brown et al. 1993) as the major
J93-2003
(Niehues and Vogel 2008; Cromier`es and Kurohashi 2009). Haghighi et al. (2009) investi-
P09-1104 W08-0303
He et al. 2008). In word alignment, a link should be aligned if it appears in most
D08-1011
Fraser, Alexander and Daniel Marcu. 2006.
P06-1097 W06-1606
words. Brown et al. (1993) call the number of target words to which a source word f is
J93-2003
and Lin 2006; Marcu et al. 2006). Besides machine translation, many applications for
W06-1606
Cherry, Colin and Dekang Lin. 2003. A
P03-1012
Och, Franz J. 2003. Minimum error rate
J03-1002 P03-1021
2. Hiero (Chiang 2007), a state-of-the-art hierarchical phrase-based system;
J07-2003
texts. Among them, generative alignment models (Brown et al. 1993; Vogel and Ney
J93-2003
Ayan, Necip Fazil and Bonnie J. Dorr. 2006a.
N06-1013 P06-1002
ing Moore, Yih, and Bode’s (2006) claim that model structure and feature selection are
P06-1065
using minimum-error-rate training (Och 2003), we adopt balanced F-measure (Fraser
J03-1002 P03-1021
2. ACL 2005 shared task (Martin, Mihalcea, and Pedersen 2005). As part of
W05-0809
Och and Ney (2003). AER has been used as official evaluation criterion in most word
J03-1002 P03-1021
tion quality (Ayan and Dorr 2006a; Fraser and Marcu 2007b). In other words, lower AER
D07-1006 J07-3002 N06-1013 P06-1002
system predictions. Taskar, Lacoste-Julien, and Klein (2005) include the IBM Model 4
H05-1010
Taskar, Lacoste-Julien, and Klein (2005) 1.1M 347 5.4
H05-1010
Liu, Yang, Qun Liu, and Shouxun Lin. 2006.
P06-1077
Mihalcea, Rada and Ted Pedersen. 2003.
W03-0301
Note that we follow Brown et al. (1993) in replacing
J93-2003
syntax-based models (Quirk, Menezes, and Cherry 2005; Galley et al. 2006; Liu, Liu,
P05-1034 P06-1121 P06-2014
the one-to-one assumption to simplify the modeling problem (Melamed 2000; Taskar,
J00-2004
Cherry, Colin and Dekang Lin. 2006. Soft
P06-2014
1. Moses (Koehn and Hoang 2007), a state-of-the-art phrase-based SMT
D07-1091
Moore, Yih, and Bode (2006) 1.1M 223 3.7
P06-1065
of context-specific features. Liu, Liu, and Lin (2005) apply the log-linear model used
P05-1057
in SMT (Och and Ney 2002) to word alignment and report significant improvements
P02-1038
Fraser and Marcu (2007b)
D07-1006 J07-3002
t(e|f ) by training the IBM models using GIZA++ (Och and Ney 2003).
J03-1002 P03-1021
(Fraser and Marcu 2006). In either case, a generative model can be regarded as a special
P06-1097 W06-1606
3. Lynx (Liu, Liu, and Lin 2006), a linguistically syntax-based system that
P06-1077
To capture such monotonicity, we follow Lacoste-Julien et al. (2006) to encourage
N06-1015
Brown et al. (1993) treat n
J93-2003
value. Please refer to Och (2003) for more details.
J03-1002 P03-1021
over the IBM models. Moore (2005) presents a discriminative framework for word
H05-1011
et al. 2006; Moore, Yih, and Bode 2006).
P06-1065
Fraser, Alexander and Daniel Marcu. 2007a.
D07-1006 J07-3002
The problem results from the absence of empty cepts. Following Brown et al. (1993),
J93-2003
alignment (Ayan, Dorr, and Monz 2005a, 2005b). Blunsom and Cohn (2006) propose a
H05-1009 H05-1024 N06-1013 P06-1002 P06-1009
