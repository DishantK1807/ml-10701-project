Methods Two classification algorithms were used in the study: Naïve Bayes and Rocchio, which were previously shown to be quite robust on highly dimensional representations on tasks including word classification (e.g., Tokunaga et al., 1997, Ciaramita, 2002).
W02-0903 W97-0803
The approach is now being actively explored for a wide range of semantics-related tasks including automatic construction of thesauri (Lin, 1998; Caraballo, 1999), their enrichment (Alfonseca and Manandhar, 2002; Pekar and Staab, 2002), acquisition of bilingual lexica from nonaligned (Kay and Röscheisen, 1993) and nonparallel corpora (Fung and Yee, 1998), learning of information extraction patterns from un-annotated text (Riloff and Schmelzenbach, 1998).
C02-1090 J93-1006 P98-1069 P98-2127 P99-1016 W98-1106
Grefenstette (1993) studied two context delineation methods of English nouns: the window-based and the syntactic, whereby all the different types of syntactic dependencies of the nouns were used in the same feature space.
W93-0113
This particular size of the context window was chosen following findings of a number of studies indicating that small context windows, i.e. 2-3 words, best capture the semantic similarity between words (e.g., Levy et al., 1998; Ciaramita, 2002).
W02-0903
Ciaramita (2002) looked at how the performance of automatic classifiers on the word classification task is affected by the decomposition of target words into morphologically relevant features.
W02-0903
The typical practice of preprocessing distributional data is to remove rare word co-occurrences, thus aiming to reduce noise from idiosyncratic word uses and linguistic processing errors and at the same time form more compact word representations (e.g., Grefenstette, 1993; Ciaramita, 2002).
W02-0903 W93-0113
