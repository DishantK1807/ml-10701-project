<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>Srinivas Bangalore</author>
<author>Anoop Sarkar</author>
<author>Christy Doran</author>
<author>Beth-Ann Hockey</author>
</authors>
<title>Grammar and parser evaluation in the xtag project</title>
<date>1998</date>
<booktitle>In Proceedings of LREC Workshop on Evaluation of Parsing Systems</booktitle>
<contexts>
<context>arser makes an attachment mistake, attaching high up a constituent which should have been attached low down, this implies span errors all along the path between the high and the low attachment sites (Bangalore et al., 1998). This is illustrated by the E-mapping to the left below, which incurs a cost of 6, and E Dice score of 0.25. 1 A A&lt; A 2 A&lt; 3 A&lt; 4 5 1 &gt;A 5 2 &gt;A 3 &gt;A 4 1 A A A 2 A 3 A 4 5&lt; 1 A &gt;5 2 A 3 A 4 The T-map</context>
</contexts>
<marker>Bangalore, Sarkar, Doran, Hockey, 1998</marker>
<rawString>Srinivas Bangalore, Anoop Sarkar, Christy Doran, and Beth-Ann Hockey. 1998. Grammar and parser evaluation in the xtag project. In Proceedings of LREC Workshop on Evaluation of Parsing Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Bille</author>
</authors>
<title>A survey on tree edit distance and related problems</title>
<date>2005</date>
<journal>Theor. Computer. Sci</journal>
<pages>337--1</pages>
<marker>Bille, 2005</marker>
<rawString>Philip Bille. 2005. A survey on tree edit distance and related problems. Theor. Computer. Sci., 337(1-3):217– 239.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ezra Black</author>
<author>Steven P Abney</author>
<author>D Flickenger</author>
<author>Claudia Gdaniec</author>
<author>Ralph Grishman</author>
<author>P Harrison</author>
<author>Donald Hindle</author>
<author>Robert Ingria</author>
<author>Frederick Jelinek</author>
<author>Judith L Klavans</author>
<author>Mark Liberman</author>
<author>Mitchell P Marcus</author>
<author>Salim Roukos</author>
<author>Beatrice Santorini</author>
<author>Tomek Strzalkowski</author>
</authors>
<title>A procedure for quantitatively comparing the syntactic coverage of english grammars</title>
<date>1991</date>
<booktitle>In Proceedings of HLT</booktitle>
<contexts>
<context>. It is argued that the tree-distance measure ameliorates a problem that has been noted concerning over-penalisation of attachment errors. 1. Introduction The PARSEVAL measures of parser performance (Black et al., 1991), as refined and implemented by the evalb program (Sekine and Collins, 1997; Collins, 1997) have become a widely adopted standard. Fundamentally this approach treats gold-standard and parser-generate</context>
</contexts>
<marker>Black, Abney, Flickenger, Gdaniec, Grishman, Harrison, Hindle, Ingria, Jelinek, Klavans, Liberman, Marcus, Roukos, Santorini, Strzalkowski, 1991</marker>
<rawString>Ezra Black, Steven P. Abney, D. Flickenger, Claudia Gdaniec, Ralph Grishman, P. Harrison, Donald Hindle, Robert Ingria, Frederick Jelinek, Judith L. Klavans, Mark Liberman, Mitchell P. Marcus, Salim Roukos, Beatrice Santorini, and Tomek Strzalkowski. 1991. A procedure for quantitatively comparing the syntactic coverage of english grammars. In Proceedings of HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>A maximum-entropy-inspired parser</title>
<date>2000</date>
<booktitle>In Proceedings of NAACL</booktitle>
<pages>132--139</pages>
<marker>Charniak, 2000</marker>
<rawString>Eugene Charniak. 2000. A maximum-entropy-inspired parser. In Proceedings of NAACL 2000, pages 132–139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Three generative, lexicalized models for statistical parsing</title>
<date>1997</date>
<booktitle>In Proceedings of ACL 97</booktitle>
<contexts>
<context> noted concerning over-penalisation of attachment errors. 1. Introduction The PARSEVAL measures of parser performance (Black et al., 1991), as refined and implemented by the evalb program (Sekine and Collins, 1997; Collins, 1997) have become a widely adopted standard. Fundamentally this approach treats gold-standard and parser-generated trees G and T , as sets of labelled spans, GS and T S. The similarity of t</context>
</contexts>
<marker>Collins, 1997</marker>
<rawString>Michael Collins. 1997. Three generative, lexicalized models for statistical parsing. In Proceedings of ACL 97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-driven statistical models for natural language parsing</title>
<date>2003</date>
<journal>Computational Linguistics</journal>
<volume>29</volume>
<marker>Collins, 2003</marker>
<rawString>Michael Collins. 2003. Head-driven statistical models for natural language parsing. Computational Linguistics, 29(4):589–637.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Emms</author>
</authors>
<title>Clustering by tree distance for parse tree normalisation</title>
<date>2006</date>
<booktitle>In Proceedings of NLUCS</booktitle>
<pages>91--100</pages>
<contexts>
<context> efficient algorithms for the computation of this measure. Though tree-distance has been applied to questionanswering and entailment recognition (Punyakanok et al., 2004; Kouylekov and Magnini, 2005; Emms, 2006a; Emms, 2006b) it has not been applied to parser evaluation. The main aim of the work reported below is to compare outcomes using tree-distance to the outcomes using the standard evalb measures. Some</context>
</contexts>
<marker>Emms, 2006</marker>
<rawString>Martin Emms. 2006a. Clustering by tree distance for parse tree normalisation. In Proceedings of NLUCS 2006, pages 91–100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Emms</author>
</authors>
<title>Variants of tree similarity in a question answering task</title>
<date>2006</date>
<booktitle>In Proceedings of the Workshop on Linguistic Distances</booktitle>
<pages>100--108</pages>
<location>Sydney, Australia</location>
<contexts>
<context> efficient algorithms for the computation of this measure. Though tree-distance has been applied to questionanswering and entailment recognition (Punyakanok et al., 2004; Kouylekov and Magnini, 2005; Emms, 2006a; Emms, 2006b) it has not been applied to parser evaluation. The main aim of the work reported below is to compare outcomes using tree-distance to the outcomes using the standard evalb measures. Some</context>
</contexts>
<marker>Emms, 2006</marker>
<rawString>Martin Emms. 2006b. Variants of tree similarity in a question answering task. In Proceedings of the Workshop on Linguistic Distances, pages 100–108, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Emms</author>
</authors>
<title>Tree distance software at www.cs.tcd.ie/Martin.Emms/tdist</title>
<date>2008</date>
<marker>Emms, 2008</marker>
<rawString>Martin Emms. 2008. Tree distance software at www.cs.tcd.ie/Martin.Emms/tdist.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Milen Kouylekov</author>
<author>Bernardo Magnini</author>
</authors>
<title>Recognizing textual entailment with tree edit distance algorithms</title>
<date>2005</date>
<booktitle>Pascal Challenges Workshop on Recognising Textual Entailment</booktitle>
<editor>In Ido Dagan, Oren Glickman, and Bernardo Magnini, editors</editor>
<contexts>
<context>identical, and for details of efficient algorithms for the computation of this measure. Though tree-distance has been applied to questionanswering and entailment recognition (Punyakanok et al., 2004; Kouylekov and Magnini, 2005; Emms, 2006a; Emms, 2006b) it has not been applied to parser evaluation. The main aim of the work reported below is to compare outcomes using tree-distance to the outcomes using the standard evalb me</context>
</contexts>
<marker>Kouylekov, Magnini, 2005</marker>
<rawString>Milen Kouylekov and Bernardo Magnini. 2005. Recognizing textual entailment with tree edit distance algorithms. In Ido Dagan, Oren Glickman, and Bernardo Magnini, editors, Pascal Challenges Workshop on Recognising Textual Entailment.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Zhang</author>
<author>D Shasha</author>
</authors>
<title>Simple fast algorithms for the editing distance between trees and related problems</title>
<date>1989</date>
<marker>Zhang, Shasha, 1989</marker>
<rawString>K.Zhang and D.Shasha. 1989. Simple fast algorithms for the editing distance between trees and related problems.</rawString>
</citation>
<citation valid="false">
<journal>SIAM Journal of Computing</journal>
<pages>18--1245</pages>
<marker></marker>
<rawString>SIAM Journal of Computing, 18:1245–1262.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of english: The penn treebank</title>
<date>1994</date>
<journal>Computational Linguistics</journal>
<volume>19</volume>
<contexts>
<context> and the T-mapping incurs a cost of 2, and T Dice score of 0.75. 3. Comparing Collins, Charniak and Petrov For 6 different parsers we took the test parses produced on Section 23 of the Penn Treebank (Marcus et al., 1994) to see if the alternatives to the standardevalb scoring that were noted in section 1. give a different relative ordering of the parsers than that obtained by the standard evalb measures3. The parser</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1994</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1994. Building a large annotated corpus of english: The penn treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Leon Barret</author>
<author>Romain Thibaux</author>
<author>Dan Klein</author>
</authors>
<title>Learning accurate, compact, and interpretable tree annotation</title>
<date>2006</date>
<booktitle>In Proceedings of COLING/ACL</booktitle>
<pages>433--440</pages>
<marker>Petrov, Barret, Thibaux, Klein, 2006</marker>
<rawString>Slav Petrov, Leon Barret, Romain Thibaux, and Dan Klein. 2006. Learning accurate, compact, and interpretable tree annotation. In Proceedings of COLING/ACL 2006, pages 433–440.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasin Punyakanok</author>
<author>Dan Roth</author>
<author>Wen tau Yih</author>
</authors>
<title>Natural language inference via dependency tree mapping: An application to question answering. Computational Linguistics</title>
<date>2004</date>
<contexts>
<context>ement effectively assigns a unit cost to each individual deletion, insertion or swap. There are applications of tree-distance in which the costs are parametrized according to the labels of the nodes (Punyakanok et al., 2004). so one can also say that the mappings are required to be homomorphisms on the two dimensions of structure characteristic of a tree. Call a T1/T2-conformant mapping a T-mapping. The tree-distance be</context>
<context>t costly edit-script are identical, and for details of efficient algorithms for the computation of this measure. Though tree-distance has been applied to questionanswering and entailment recognition (Punyakanok et al., 2004; Kouylekov and Magnini, 2005; Emms, 2006a; Emms, 2006b) it has not been applied to parser evaluation. The main aim of the work reported below is to compare outcomes using tree-distance to the outcome</context>
</contexts>
<marker>Punyakanok, Roth, Yih, 2004</marker>
<rawString>Vasin Punyakanok, Dan Roth, and Wen tau Yih. 2004. Natural language inference via dependency tree mapping: An application to question answering. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ines Rehbein</author>
<author>Josef van Genabith</author>
</authors>
<title>Treebank annotation schemes and parser evaluation for German</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL</booktitle>
<pages>630--639</pages>
<marker>Rehbein, van Genabith, 2007</marker>
<rawString>Ines Rehbein and Josef van Genabith. 2007. Treebank annotation schemes and parser evaluation for German. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 630–639.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Roark</author>
</authors>
<title>Evaluating parser accuracy using edit distance</title>
<date>2002</date>
<booktitle>In Proceedings of the LREC</booktitle>
<pages>30--36</pages>
<marker>Roark, 2002</marker>
<rawString>B. Roark. 2002. Evaluating parser accuracy using edit distance. In Proceedings of the LREC 2002 workshop: Beyond PARSEVAL: Towards Improved Evaluation Measures for Parsing Systems, pages 30–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey Sampson</author>
<author>Anna Babarczy</author>
</authors>
<title>A test of the leaf-ancestor metric for parse accuracy</title>
<date>2003</date>
<journal>Nat. Lang. Eng</journal>
<volume>9</volume>
<marker>Sampson, Babarczy, 2003</marker>
<rawString>Geoffrey Sampson and Anna Babarczy. 2003. A test of the leaf-ancestor metric for parse accuracy. Nat. Lang. Eng., 9(4):365–380.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoshi Sekine</author>
<author>Michael Collins</author>
</authors>
<date>1997</date>
<note>evalb software at nlp.cs.nyu.edu/evalb</note>
<contexts>
<context>at has been noted concerning over-penalisation of attachment errors. 1. Introduction The PARSEVAL measures of parser performance (Black et al., 1991), as refined and implemented by the evalb program (Sekine and Collins, 1997; Collins, 1997) have become a widely adopted standard. Fundamentally this approach treats gold-standard and parser-generated trees G and T , as sets of labelled spans, GS and T S. The similarity of t</context>
</contexts>
<marker>Sekine, Collins, 1997</marker>
<rawString>Satoshi Sekine and Michael Collins. 1997. evalb software at nlp.cs.nyu.edu/evalb.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Siegel</author>
<author>N J Castellan</author>
</authors>
<title>Non-Parametric Statistics for the Behavioural Sciences</title>
<date>1988</date>
<publisher>McGraw-Hill</publisher>
<marker>Siegel, Castellan, 1988</marker>
<rawString>S.Siegel and N.J.Castellan. 1988. Non-Parametric Statistics for the Behavioural Sciences. McGraw-Hill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J van Rijsbergen</author>
</authors>
<title>Information Retrieval, 2nd edition</title>
<date>1979</date>
<institution>Dept. of Computer Science, University of Glasgow</institution>
<marker>van Rijsbergen, 1979</marker>
<rawString>C. J. van Rijsbergen. 1979. Information Retrieval, 2nd edition. Dept. of Computer Science, University of Glasgow.</rawString>
</citation>
</citationList>
</algorithm>

