<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>A Abbasi</author>
<author>H Chen</author>
</authors>
<title>Affect intensity analysis of dark web forums</title>
<date>2007</date>
<booktitle>In Proceedings of IEEE International Conference on Intelligence and Security Informatics (ISI</booktitle>
<pages>282--288</pages>
<contexts>
<context>tions and others express anger, frustration, dislike. More and more, research in computer processing of text recognizes the interest in being able to recognize this emotional level. For example, see (Abbasi and Chen, 2007). Most automated text processing systems identify this level by referring to a lexicon of affect-bearing words, such as the General Inquirer. Few other languages possess such linguistic resources. Fo</context>
</contexts>
<marker>Abbasi, Chen, 2007</marker>
<rawString>A. Abbasi and H. Chen. 2007. Affect intensity analysis of dark web forums. In Proceedings of IEEE International Conference on Intelligence and Security Informatics (ISI), pages 282–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: a library for support vector machines. Software available at http://www.csie.ntu.edu</title>
<date>2001</date>
<pages>tw/˜cjlin/libsvm.</pages>
<contexts>
<context> of its POS-tag and its lemma (for instance “mice” becomes “NNmouse”), and finally filtered to keep only nouns, verbs, adjectives and adverbs. Using these 12600-dimensions LSA vectors and the LibSVM (Chang and Lin, 2001) package5, we trained a 44 class SVM classifier6. Applying this classifier to our gold standard L3 (3513 words minus the 881 words already appearing in L2 or L1, leaving 2632 words that were the set </context>
</contexts>
<marker>Chang, Lin, 2001</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin, 2001. LIBSVM: a library for support vector machines. Software available at http://www.csie.ntu.edu. tw/˜cjlin/libsvm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Deerwester</author>
<author>S Dumais</author>
<author>G W Furnas</author>
<author>T K Landauer</author>
<author>R Harshman</author>
</authors>
<title>Indexing by latent semantic analysis</title>
<date>1990</date>
<journal>Journal of the Society for Information Science</journal>
<volume>41</volume>
<contexts>
<context>ords, L1 and L2, we want to automatically assign new words from the L3 set in our 44 classes. In a first experiment, we evaluate the classification power of a combination of Latent Semantic Analysis (Deerwester et al., 1990) and Support Vector Machines, which have been successfully used, independently, in sentiment analysis research (Pang et al., 2002; Turney and Littman, 2002). We call this method Semantic Likeliness f</context>
</contexts>
<marker>Deerwester, Dumais, Furnas, Landauer, Harshman, 1990</marker>
<rawString>S. Deerwester, S. Dumais, G. W. Furnas, T. K. Landauer, and R. Harshman. 1990. Indexing by latent semantic analysis. Journal of the Society for Information Science, 41(6):391–407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Grefenstette</author>
<author>Y Qu</author>
<author>D A Evans</author>
<author>J G Shanahan</author>
</authors>
<title>Validating the coverage of lexical resources for affect analysis and automatically classifying new words along semantic axes</title>
<date>2006</date>
<booktitle>Computing Attitude and Affect in Text: Theory and Applications</booktitle>
<pages>93--106</pages>
<editor>In Y. Qu, J. Shanahan, and J. Wiebe, editors</editor>
<publisher>Springer</publisher>
<contexts>
<context>ee value axes: PositiveNegative, Strong-Weak, Active-Passive, but hundreds of more specific axes of human values1 can be defined. For our new language, we started from the 43 paired axes detailed in (Grefenstette et al., 2006), translating them by hand into French as shown in table 2.1. (adding an additional dimension Admiration-Denigration). This initial investment took three hours for one person. 2.2. Creating seed word</context>
</contexts>
<marker>Grefenstette, Qu, Evans, Shanahan, 2006</marker>
<rawString>G. Grefenstette, Y. Qu, D.A. Evans, and J.G. Shanahan. 2006. Validating the coverage of lexical resources for affect analysis and automatically classifying new words along semantic axes. In Y. Qu, J. Shanahan, and J. Wiebe, editors, Computing Attitude and Affect in Text: Theory and Applications, pages 93–106. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Grefenstette</author>
</authors>
<title>Conquering Language: Using NLP on a Massive Scale to Build High Dimensional Language Models from the Web</title>
<date>2007</date>
<booktitle>Proc of the 8th CICLing Conference</booktitle>
<pages>35--49</pages>
<location>Mexico City, Mexico</location>
<contexts>
<context>mber of queries required for the evaluation of this method is more than 2 millions, we found it impractical to use a web search engine. Instead, we used the French SemanticMap: a resource of our own (Grefenstette, 2007), currently under construction, in which we collect the results of syntactic analysis of web pages, as well as window cooccurrence information for sizes 5, 10 and 20. At the moment of the experiment,</context>
</contexts>
<marker>Grefenstette, 2007</marker>
<rawString>G. Grefenstette. 2007. Conquering Language: Using NLP on a Massive Scale to Build High Dimensional Language Models from the Web. Proc of the 8th CICLing Conference (Mexico City, Mexico, Feb. 18-24, 2007), pages 35–49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Hatzivassiloglou</author>
<author>K R McKeown</author>
</authors>
<title>Predicting the semantic orientation of adjectives</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics and the 8th Conference of the European Chapter of the ACL</booktitle>
<pages>174--181</pages>
<location>New Brunswick, NJ</location>
<contexts>
<context>d negative paradigm words (bad, nasty, poor, negative, unfortunate, wrong, inferior) to the classify the valence of new words, achieving 98.2% accuracy with the 334 most frequent adjectives from the (Hatzivassiloglou and McKeown, 1997) test set. Grefenstette et al. (2006) described a similar method for classifying new words into an existing, richer set of affect classes. We extend this line of work here to unresourced languages. T</context>
</contexts>
<marker>Hatzivassiloglou, McKeown, 1997</marker>
<rawString>V. Hatzivassiloglou and K.R. McKeown. 1997. Predicting the semantic orientation of adjectives. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics and the 8th Conference of the European Chapter of the ACL., pages 174–181, New Brunswick, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hindle</author>
</authors>
<title>Noun classification from predicateargument structures</title>
<date>1990</date>
<booktitle>In Proceedings of the 28th Annual Meeting of the Association of Computational Linguistics</booktitle>
<pages>268--275</pages>
<location>Pittsburgh, Pennsylvania</location>
<contexts>
<context>f words was considered as having negative polarity. They achieved 92% accuracy over a set of 236 adjectives. Wiebe (2000) used a seed set of “subjective” adjectives and a thesaurus generation method (Hindle, 1990) to find more subjective adjectives. Turney and Littman (2003) developed the SO-PMI approach, using sets of known positively charged paradigm words (good, nice, excellent, positive, fortunate, correc</context>
</contexts>
<marker>Hindle, 1990</marker>
<rawString>D. Hindle. 1990. Noun classification from predicateargument structures. In Proceedings of the 28th Annual Meeting of the Association of Computational Linguistics., pages 268–275, Pittsburgh, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation</title>
<date>2005</date>
<booktitle>In Proceedings of the 10th Machine Translation</booktitle>
<location>Summit</location>
<contexts>
<context>e thematic or pragmatic relations. We created a total of forty-two 300-dimension semantic spaces for our language using Latent Semantic Analysis 4 from 40 million words in the French EuroParl Corpus (Koehn, 2005), varying the word windows in forty-two ways, viz., for each size in the set 2[1::10;15;20;25;30], we considered the windows [0;+ ], [ ;+ ], [ ;0]. Each of the words was then associated with a concat</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>P. Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In Proceedings of the 10th Machine Translation Summit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C E Osgood</author>
<author>W H May</author>
<author>M S Miron</author>
</authors>
<title>CrossCultural Universals in Affective Meaning</title>
<date>1975</date>
<institution>University of Illinois Press. Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan</institution>
<marker>Osgood, May, Miron, 1975</marker>
<rawString>C. E. Osgood, W.H. May, and M.S. Miron. 1975. CrossCultural Universals in Affective Meaning. University of Illinois Press. Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.</rawString>
</citation>
<citation valid="true">
<title>Thumbs up? Sentiment classification using machine learning techniques</title>
<date>2002</date>
<booktitle>In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<pages>79--86</pages>
<marker>2002</marker>
<rawString>2002. Thumbs up? Sentiment classification using machine learning techniques. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 79–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Ploux</author>
<author>B Victorri</author>
</authors>
<title>Construction d’espaces s´emantiques `a l’aide de dictionnaires informatis´es des synonymes. Traitement Automatique des Langues</title>
<date>1998</date>
<volume>39</volume>
<contexts>
<context>h. 2.3. Creating a gold standard for evaluation. For subsequent evaluation purposes, we also produced a gold standard (L3) by first expanding the initial seed list (L1) using a synonyms dictionary 2 (Ploux and Victorri, 1998), and then manually deleting words that the human annotator felt intuitively did not belong to the class being built. During its construction, a few words not proposed by the synonym dictionary were </context>
</contexts>
<marker>Ploux, Victorri, 1998</marker>
<rawString>S. Ploux and B. Victorri. 1998. Construction d’espaces s´emantiques `a l’aide de dictionnaires informatis´es des synonymes. Traitement Automatique des Langues, 39(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schmidt</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees</title>
<date>1994</date>
<booktitle>In Proceedings of International Conference on New Methods in Language Processing</booktitle>
<location>Manchester</location>
<contexts>
<context>vectors with 12600 dimensions (raw cooccurence matrices would have totalized some 5.3 million dimensions). The corpus was also prepared in the following way: it was first POS-tagged using TreeTagger (Schmidt, 1994), then transformed so that each term was a concatenation of its POS-tag and its lemma (for instance “mice” becomes “NNmouse”), and finally filtered to keep only nouns, verbs, adjectives and adverbs. </context>
</contexts>
<marker>Schmidt, 1994</marker>
<rawString>H. Schmidt. 1994. Probabilistic part-of-speech tagging using decision trees. In Proceedings of International Conference on New Methods in Language Processing., Manchester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlo Strapparava</author>
<author>Rada Mihalcea</author>
</authors>
<title>Semeval2007 task 14: Affective text</title>
<date>2007</date>
<booktitle>In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007</booktitle>
<pages>70--74</pages>
<location>Prague, Czech Republic</location>
<contexts>
<context>to unresourced languages. The problem of multiclass classification has been recently evaluated on 6 classes (Anger, Disgust, Fear, Joy, Sadness, Surprise) for multiword news headlines classification (Strapparava and Mihalcea, 2007), with middling results. 2. Manually Built Resources 2.1. Defining Semantic Dimensions of Affect Osgood et al. (1975) defined three value axes: PositiveNegative, Strong-Weak, Active-Passive, but hund</context>
</contexts>
<marker>Strapparava, Mihalcea, 2007</marker>
<rawString>Carlo Strapparava and Rada Mihalcea. 2007. Semeval2007 task 14: Affective text. In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007), pages 70–74, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P D Turney</author>
<author>M L Littman</author>
</authors>
<title>Unsupervised learning of semantic orientation from a hundred-billion-word corpus</title>
<date>2002</date>
<tech>Technical Report ERB-1094</tech>
<institution>National Research Council Canada</institution>
<contexts>
<context>f a combination of Latent Semantic Analysis (Deerwester et al., 1990) and Support Vector Machines, which have been successfully used, independently, in sentiment analysis research (Pang et al., 2002; Turney and Littman, 2002). We call this method Semantic Likeliness from diversified LSA and SVM, because we use different LSA spaces as input features for SVM. In our approach, LSA is used for its ability to reduce the numbe</context>
<context> for each class improves the classification. 3.2. Classifying with SL-PMI measure In a second experiment, we used a measure inspired by the SO-PMI (Semantic Orientation Pointwise Mutual Information) (Turney and Littman, 2002). The original SO-PMI measure is intended to evaluate the positiveness/negativeness of a given word W. It is based on calculating the difference of the PMI of W with a set of arbitrarily chosen posit</context>
<context>in table 7, but the technique requies less effort, since no semantic spaces are built. 3.3. Classifying with SL-LSA measure In a third experiment, we used a measure inherited from the SO-LSA measure (Turney and Littman, 2002). As for the SO-PMI, the original SO-LSA measure is intended to evaluate the positiveness/negativeness of a given word W. Instead of using the difference of the pointwise mutual information, it makes</context>
</contexts>
<marker>Turney, Littman, 2002</marker>
<rawString>P.D. Turney and M.L. Littman. 2002. Unsupervised learning of semantic orientation from a hundred-billion-word corpus. Technical Report ERB-1094, National Research Council Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P D Turney</author>
<author>M L Littman</author>
</authors>
<title>Measuring praise and criticism: Inference of semantic orientation from association</title>
<date>2003</date>
<journal>ACM Transactions on Information Systems</journal>
<volume>21</volume>
<marker>Turney, Littman, 2003</marker>
<rawString>P.D. Turney and M.L. Littman. 2003. Measuring praise and criticism: Inference of semantic orientation from association. ACM Transactions on Information Systems, 21(4):315–346.</rawString>
</citation>
</citationList>
</algorithm>

