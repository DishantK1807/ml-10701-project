<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<title>The ACL anthology reference corpus: A reference dataset for bibliographic research</title>
<date>2008</date>
<booktitle>In Language Resources and Evaluation Conference</booktitle>
<marker>2008</marker>
<rawString>2008. The ACL anthology reference corpus: A reference dataset for bibliographic research. In Language Resources and Evaluation Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert D Cameron</author>
</authors>
<title>A universal citation database as a catalyst for reform in scholarly communication</title>
<date>1997</date>
<journal>First Monday</journal>
<volume>2</volume>
<contexts>
<context>tely. We plan on incorporating some preprocessing heuristics to ParsCit to correct for such errors. 8. Related Work The problem of citation parsing has been the focus of several research initiatives (Cameron, 1997; Lawrence et al., 1999). We examine existing citation parsers, which can be generally divided into two categories: template matching and machine learning based approaches. A template matching approac</context>
</contexts>
<marker>Cameron, 1997</marker>
<rawString>Robert D. Cameron. 1997. A universal citation database as a catalyst for reform in scholarly communication. First Monday, 2(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eli Cortez</author>
<author>Altigran S da Silva</author>
<author>Marcos Andr´e Gonc¸alves</author>
<author>Filipe Mesquita</author>
<author>Edleno S de Moura</author>
</authors>
<title>Fluxcim: flexible unsupervised extraction of citation metadata</title>
<date>2007</date>
<booktitle>In JCDL ’07: Proceedings of the 2007 Conference on Digital Libraries</booktitle>
<pages>215--224</pages>
<location>New York, NY, USA</location>
<marker>Cortez, Silva, Gonc¸alves, Mesquita, de Moura, 2007</marker>
<rawString>Eli Cortez, Altigran S. da Silva, Marcos Andr´e Gonc¸alves, Filipe Mesquita, and Edleno S. de Moura. 2007. Fluxcim: flexible unsupervised extraction of citation metadata. In JCDL ’07: Proceedings of the 2007 Conference on Digital Libraries, pages 215–224, New York, NY, USA. ACM. C. Lee Giles, Kurt D. Bollacker, and Steve Lawrence.</rawString>
</citation>
<citation valid="true">
<title>Citeseer: an automatic citation indexing system</title>
<date>1998</date>
<booktitle>In DL ’98: Proceedings of the third ACM conference on Digital libraries</booktitle>
<pages>89--98</pages>
<publisher>ACM Press</publisher>
<location>New York, NY, USA</location>
<marker>1998</marker>
<rawString>1998. Citeseer: an automatic citation indexing system. In DL ’98: Proceedings of the third ACM conference on Digital libraries, pages 89–98, New York, NY, USA. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I-Ane Huang</author>
<author>Jan-Ming Ho</author>
<author>Hung-Yu Kao</author>
<author>WenChang Lin</author>
</authors>
<title>Extracting citation metadata from online publication lists using BLAST</title>
<date>2004</date>
<booktitle>In Proc. of the Eighth Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD-04</booktitle>
<location>Sydney, Australia</location>
<contexts>
<context>of ParsCit, a system that uses a core of machine learned methods coupled with a heuristic processing framework. While many methods that use machine learning have been proposed for this exact problem (Huang et al., 2004; Cortez et al., 2007), our contribution lies in 1) devising new features useful for this problem, 2) automatically extracting citation contexts, 3) packaging our results as a software module that can</context>
<context>rence strings that do not adhere to the templates also diminishes this utility. A further weakness of ParaTools is that it tags ambiguous fields as “Any”, equivalent to not tagging the token at all. (Huang et al., 2004) report ParaTool’s precision as approximately 30%. This level of performance and lack of portability make the approach unsuitable for high volume data processing. The limitations of the template-base</context>
</contexts>
<marker>Huang, Ho, Kao, Lin, 2004</marker>
<rawString>I-Ane Huang, Jan-Ming Ho, Hung-Yu Kao, and WenChang Lin. 2004. Extracting citation metadata from online publication lists using BLAST. In Proc. of the Eighth Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD-04), Sydney, Australia, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Jewell</author>
</authors>
<title>ParaCite: An overview</title>
<date>2000</date>
<contexts>
<context>ic pattern against known templates. The template with the best fit to the input is then used to label the citation’s tokens as fields. The canonical example of a template based approach is ParaTools (Jewell, 2000), a set of Perl modules to perform reference string parsing. ParaTools contains 400 templates to match reference strings to, but even this large amount manifests coverage problems. While users may ch</context>
</contexts>
<marker>Jewell, 2000</marker>
<rawString>Michael Jewell. 2000. ParaCite: An overview. http://paracite.eprints.org/docs/overview.html. John D. Lafferty, Andrew McCallum, and Fernando C. N.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
<date>2001</date>
<booktitle>In ICML ’01: Proceedings of the Eighteenth International Conference on Machine Learning</booktitle>
<pages>282--289</pages>
<publisher>Morgan Kaufmann Publishers Inc</publisher>
<location>San Francisco, CA, USA</location>
<marker>Pereira, 2001</marker>
<rawString>Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In ICML ’01: Proceedings of the Eighteenth International Conference on Machine Learning, pages 282–289, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve Lawrence</author>
<author>C Lee Giles</author>
<author>Kurt Bollacker</author>
</authors>
<title>Digital libraries and autonomous citation indexing</title>
<date>1999</date>
<journal>IEEE Computer</journal>
<volume>32</volume>
<contexts>
<context>n incorporating some preprocessing heuristics to ParsCit to correct for such errors. 8. Related Work The problem of citation parsing has been the focus of several research initiatives (Cameron, 1997; Lawrence et al., 1999). We examine existing citation parsers, which can be generally divided into two categories: template matching and machine learning based approaches. A template matching approach takes an input citati</context>
</contexts>
<marker>Lawrence, Giles, Bollacker, 1999</marker>
<rawString>Steve Lawrence, C. Lee Giles, and Kurt Bollacker. 1999. Digital libraries and autonomous citation indexing. IEEE Computer, 32(6):67–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yong Kiat Ng</author>
</authors>
<title>Citation parsing using maximum entropy and repairs. Undergraduate thesis</title>
<date>2004</date>
<institution>National University of Singapore</institution>
<contexts>
<context>trong learning model for this task. This work motivates our choice of a CRF as the base learning model for ParsCit. The first version of ParsCit used Maximum Entropy (ME) training to compute a model (Ng, 2004). Aside from using ME, which can be seen as a step towards a discriminative version of Hidden Markov Models, this work featured two rounds of prediction: a first round to label a reference string its</context>
</contexts>
<marker>Ng, 2004</marker>
<rawString>Yong Kiat Ng. 2004. Citation parsing using maximum entropy and repairs. Undergraduate thesis, National University of Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fuchun Peng</author>
<author>Andrew McCallum</author>
</authors>
<title>Accurate information extraction from research papers using conditional random fields. In</title>
<date>2004</date>
<booktitle>In Proceedings of Human Language Technology Conference / North American Chapter of the Association for Computational Linguistics annual meeting</booktitle>
<pages>329--336</pages>
<contexts>
<context>y different communities, coupled with inadvertent errors on the part of authors, makes this process difficult to automate. Many methods have been proposed to deal with this sequence labeling problem (Peng and McCallum, 2004; Giles et al., 1998). In this paper we describe our implementation of ParsCit, a system that uses a core of machine learned methods coupled with a heuristic processing framework. While many methods t</context>
<context>ields that might be used to generate the references themselves. Table 1 gives the field accuracy and F1 of ParsCit, trained using ten-fold cross validation, compared to the original CRF-based system (Peng and McCallum, 2004) that inspired our work. Note that the Cora dataset does not further segment the author field into individual authors; so our evaluation is done by regarding any contiguous “author” fields as a singl</context>
<context>98 Average* 95.7 95.7 .95 – .91 Table 1: Field reference string parsing performance on the Cora dataset using 10-fold cross validation. Averages are micro averages for ParsCit and macro averages for (Peng and McCallum, 2004). We follow the the experimental methodology of the original experiments done in (Peng and McCallum, 2004) as closely as possible, using ten-fold cross validation with 50line slices of the training d</context>
</contexts>
<marker>Peng, McCallum, 2004</marker>
<rawString>Fuchun Peng and Andrew McCallum. 2004. Accurate information extraction from research papers using conditional random fields. In In Proceedings of Human Language Technology Conference / North American Chapter of the Association for Computational Linguistics annual meeting, pages 329–336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brett Powley</author>
<author>Robert Dale</author>
</authors>
<title>Evidence-based information extraction for high accuracy citation and author name identification. Recherche d’Information Assist</title>
<date>2007</date>
<contexts>
<context>me” and “number” are prevalent. Retrieving citation contexts has been a key feature in CiteSeer and nascent digital libraires. Approaches continue to be heuristically-driven, in both this system and (Powley and Dale, 2007). Work continues in the community to utilize citation contexts to discern a citation’s function and compile a summary of how a work influences or is described by others (Teufel et al., 2006; Wu et al</context>
</contexts>
<marker>Powley, Dale, 2007</marker>
<rawString>Brett Powley and Robert Dale. 2007. Evidence-based information extraction for high accuracy citation and author name identification. Recherche d’Information Assist.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ariel Schwartz</author>
<author>Anna Divoli</author>
<author>Marti Hearst</author>
</authors>
<title>Multiple alignment of citation sentences with conditional random fields and posterior decoding</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL</booktitle>
<pages>847--857</pages>
<location>Rosenfeld</location>
<contexts>
<context>ontinues in the community to utilize citation contexts to discern a citation’s function and compile a summary of how a work influences or is described by others (Teufel et al., 2006; Wu et al., 2006; Schwartz et al., 2007). 9. Conclusion We have introduced ParsCit, an open-source package for locating reference strings, parsing them and retrieving their citation contexts3. ParsCit employs state-of-the-art machine learn</context>
</contexts>
<marker>Schwartz, Divoli, Hearst, 2007</marker>
<rawString>Ariel Schwartz, Anna Divoli, and Marti Hearst. 2007. Multiple alignment of citation sentences with conditional random fields and posterior decoding. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 847–857, June. Kristie Seymore, Andrew McCallum, and Roni Rosenfeld.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Tidhar</author>
</authors>
<title>Learning hidden markov model structure for information extraction</title>
<date>1999</date>
<booktitle>In AAAI’99 Workshop on Machine Learning for Information Extraction. Simone Teufel, Advaith Siddharthan, and</booktitle>
<marker>Tidhar, 1999</marker>
<rawString>1999. Learning hidden markov model structure for information extraction. In AAAI’99 Workshop on Machine Learning for Information Extraction. Simone Teufel, Advaith Siddharthan, and Dan Tidhar.</rawString>
</citation>
<citation valid="true">
<title>Automatic classification of citation function</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing</booktitle>
<pages>103--110</pages>
<location>Sydney, Australia</location>
<marker>2006</marker>
<rawString>2006. Automatic classification of citation function. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 103–110, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>

