Automatic Acquisition of Hierarchical Transduction Models 
for Machine Translation 
Hiyan Alshawi Srinivas Bangalore Shona Douglas 
XI'&T I~abs llcsear(h 
l S(t Park AveJme, P.O. Box 9711 
l"lorham l>a.rk, NJ 07932 \[.;SA 
Abstract 
\Ve describe a method for the fully automatic 
learning of hierarchical Iinite state translation 
models. The input to lhe method is transcribed 
sl)eech utterances and th(>ir corre.~l)on(ling hu. 
man translations, and the output is a set of 
head transducers, i.e. statistical leÃ—ical head
outward transducers. A word-alignment func
tion and a head-ranking funcl, ion are \[irst ob
tained, and then counts are generated for hy
pothesized stale transitions of head transduc
ers whose lexical translations and word order 
chauges are consislent with the alignment. The 
method has been applied to create au English
Spanish translation model for ~t speech tI'ans
lation application, with word accuracy of over 
75% a,s measured by a string-dislauce compari
son to three reference tra.nslations. 
1 Introduction

The fully automatic constructiol, r.)f' translation 
lnodels offers benelits in ternls of develol)ment 
effort and i)otentially in robustness over met}> 
ods requiring hand-coding of linguistic informa
tion. Itowevei', there art disadvantages to the 
automatic approaches proposed so far. The var
ious methods described by P, rown el. al (1990; 
1993) do not take into account tile natural strllc
turing of strings into phrases. Examph>based 
translation, exemplified hy tile work of Sumita 
and lida (1995), requires very large amounts 
o\[ lraiiling luatcrial. The number o\[' stales 
in a sinlple finite state model such as those 
used by Viler et el. (1996) becomes extremely 
large when faced with languages with large word 
order ditferences. The work reported in \'Vu 
(1997), which uses an inside-outside type of 
training algorithm to learn statistical context
free transduction, has a similar motivation to 
tilt, Clli'l'(?l\]{ \Vol'k~ but the models \re describe 
here, being fully lexica.1, are more suitable for 
direct, statistical modelling. 
lu this paper, we show that both the net
work topology and parameters of a head trans
ducer translation model (Alshawi, t996b) can 
t)e Darned fully automatically from a bilingual 
corpus. It has already been S}lOWll (Alshawi eL 
el., i997) that a. head transducer model with 
hand-coded structure, can be trained to give bet
ter accuracy than a comparable transfer-based 
system, with snmller model size, computational 
requirements, and development ef\['ort. 
\Ve have applied the learning method to el'e
ate an English-Spanish translation model for a 
limited domain, with word a.ccuracy of over 75% 
measured by a string distance comparison (as 
used in speech recognition) to three reference 
translations. The resulting translation model 
has been used as a comI)Ol,ent o\[' an I';nglish
Spanish speech tra.nslation system. 
\'~)' first present the atet)s of tile 'brallbd/lc
t.io,, lraining method in Section 2. In Section 3 
we describe how we obtain an alignment func
tion froHl SOllree word subsequences to target 
word subsequences \['or each transcribed utter
a nce and its translation. The construction of 
states and transitions is specitied in Section 4; 
the method for selecting phrase head words is 
described in Section 5. The string comparison 
eva.htatiol~ metric we use. is described in Sec
lion 6, atl(l the results o\[ testing the method in 
a limited domain of l';nglish-Spanish translation 
are reported in Section 7. 
2 Overview

2.1 Lexlcal
head transducers 
In our training method, we follow tile simple 
lexical head transduction model described by 
Alshawi (1996b) which can be regarded as a 
type of .~ta.tistical dependency gra.ntmar trans
41 
duction. This type of transduction model con
sists of a collection of head transducers; the pur
pose of a particular transducer is to translate 
a specific source word w into a target word v, 
and further to translate tile pair of sequences of 
dependent words to the left and right of w to 
sequences of dependents to the left and right of 
c. When applied recursively, a set of such trans
ducer> effects a hierarchical transduction of the 
source string into the target string. 
A distinguishing property of head transduc
ers, as compared to 'standard' finite state trans
ducers is that they perform a transduction out
wards fi'om a 'head' word in the input string 
rather than by traversing the input string froln 
left to right. A head transducer for translating 
source word w to target word v consists of a set 
of states q0(w: v).qt(w : v).q2(w : v) .... and 
lransilions of the forln: 
(viii. : ,,). qj(l,, : ~,), .<~, <:, ,~,, 5) 
where the transition is from state qi(w : v) to 
state qj(w : v), reading the next source depen
dent 'wd at position o. relat:ive to w and writing 
a target dependent t, d a l position /~ relative to 
v. Positions left of a head (in the source or tar
get) are indicated with negative integers, while 
those right of the head are indicated with posi
tive integers. 
The head transducers we use also include tile 
following probability parameters for start, tran
sition, and stop events: 
P(start, q(w: v)lw ) 
P(qj(.w : v), wd, vd, o,, /31qi( w : v) ) 
t'(,~tol, lq( ~. : v) ) 
In the present work, when a model is ap
plied to translate a source sentence, the cho
sen derivation of the target string is the deriva
tion that maximizes tile product of tlle above 
transducer event probabilities. The transduc
tion search Mgorithm we use to apply the trans
lation model is a bottom-up dynamic program
ruing algorithm similar to the analysis algorithm 
for relational head acceptors described by AI
sham (1996a). 
2.2 Training
method 
The training method is organized into two main 
stages, an alignment stage followed by a trans
ducer construction stage as shown in Figure 1. 
f(w) ... f(w~) ... \[ ... f(~) ... 
Figure 2: Partitioning the source and target 
around a head w with respect to f 
The single input to the training process is a 
bitext corpus, constructed by taking each ut
terance in a corpus of transcribed speech and 
having it manually translated. We use the ternl 
bitcxt in what follows to refer to a pair consist
ing of the transcription of a single utterance and 
its translation. 
The steps in the training procedure are as fol
lows: 
1. For each bitext, compute an alignment func
tion f from source words to target words, using 
the method described in Section 3. 
2. Partition the source into a head word w and 
substrings to the left and right of w (as shown 
in Figure 2). The extents of the partitions pro
jected onto the target by f must not overlap. 
Any selection of tile head satisfying this con
straint is valid but the seleclion method used 
influences accuracy (Section 5). 
3. Continue partitioning the left and right sub
strings recursively around sub-heads wl and w,,. 
4. Trace hypothesized head-transducer transi
tions that would output the translations of the 
left and right dependents of w (i.e. wl and iv,,) 
at the appropriate positions in the target string, 
indicated by f. This step is described in more 
detail below in Section 4. 
5. Apply step 4 recursively to partitions headed 
by wl aim w~, and then their dependents, until 
all left and right partitions have at most one 
word. 
6. Aggregate hypothesized transitions to form 
tile counts of a maximum likelihood head trans
duction model. 
The recursive partioning of the source and tar
get strings gives the hierarchical decomposition 
for head transduction, in step 2, tile constraint 
42 
bitexts bitexts bitexts source text 
l'airmg l Extraction 
event 
trace 
Model Builder 
alignment 
model 
Alignment 
Search 
alignments 
Head 
Selection 
l ranked 
heads 
Transducer 
Construction 
trace 
Model Builder 
translation 
model 
Transduction 
Search 
translated text 
Figure it: l-lead transducer training method 
on target partitions ellsures that the transduc
tion hylmthesized ill training does not contain 
ClOSSl::g dependency strtlcttlres ill the target. 
3 Alignment

The first sta.ge in the training process is ob
taining, for each bitext, an alignment flmction 
f : W ~+ V mapping word subsequences W in 
the source to word subsequences V in the tar
get. In this process a.n alignment model is con
structed which specifies a cost for each pairing 
(!IV, V) of source and target subseqtlences, and 
an alignment search is carried out to minimize 
the sum of the costs of a set of pairings which 
completely maps the bitext source to its target. 
3.1 Alignment
model 
The cost of a pairing is composed of a weighted 
combination of cost, functioIls. We currently use 
two. 
The first cost function is tile 05 correlation 
ineasure (cf the use of 0 2 h: Gale and Church 
(1991)) computed as follows: 
c) = (be a d) ,/(a + b)(c + d)(a + + ,l) 
w here 
(t ~ 7IV -I/W,V 
b ~ '/l ~ v v 
c -IV 'tz V ~,!.I' + 7tW, V 
d ~ll, jv 'ii,,{.v, V 
N is tile total nunfl)er of bitexts, nv the number 
of bitexts in which V appears in the target, nw 
the number of bitexts in which FV appears ill 
the source, and ~twy the nulnber of bitexts ill 
which IU appears in the source and V al)pears 
ill the target. 
We tried using the log probabilities of tar
get subsequences given source subsequences (cf 
Brown et al. (1990)) as a cost function instead 
of05 but 05 resulted in better performance of our 
translation models. 
The second cost. function used is a distance 
measure which penalizes pairings in which the 
source subsequence and target subsequence are 
in very different positions in their respective 
sentences, l)ifferent weightings of distance to 
correlation costs can be used to bias the model 
towards more or less parallel alignments for dif
ferent language pairs. 
43 
3.2 Alignment
search 
The agenda-based alignment search makes use 
of dynamic programming to record the best cost 
seen for all partial alignments covering the same 
source and target subsequence; partial align
ments coming off the agenda that have a higher 
cost for the same coverage are discarded and 
take no further part in the search. An effort 
limit on the number of agenda items processed is 
used to ensure reasonable speed in the search re
gardless of sentence length. An iterative broad
ening strategy is used, so that at breadth i only 
the i lowest cost pairings for each source subse
quence are allowed in the search, with ttle result 
that most optimal alignments are found well be
fore tlle effort limit is reached. 
In the experiment reported in Section 7, 
source and target subsequences of lengths 0, 1 
and 2 were allowed in pairings. 
4 Transducer
construction 
Building a head transducer inw)lves creating ap
propriate head transducer states and tracing hy
pothesized head-transducer transitions between 
them that are consistent with tile occurrence 
of the pairings (W, f(W)) in each aligned bi
text. When a source sequence W in an align
ment pairing consists of more than one word, 
the least frequent of these words in the train
ing corpus is takml to be the p~'imaw word of 
the subsequence. It is convenient to extend the 
domain of an alignment function f to include 
primary words w by setting f(w) = f(W). 
The main transitions that are traced in our 
construction are those that map heads, wt and 
w~, of the the right and left dependent phrases 
of w (see Figure 2) to their translations as indi
cated in tile alignment. The positions of these 
dependents in the target string are computed 
t) 3' comparing the positions of f(wl) and f(w,.) 
to the position of' V = f(w). The actual states 
and transitions in the constrnction are specified 
below. 
Additional transitions are included for cases 
of compounding, i.e. those for which the source 
subsequence in an alignment function pairing 
consists of more than one word. Specifically, 
the source subsequence W may be a compound 
consisting of a primary word w together with 
a secor~.daT" 9 word w'. There are no additional 
transitions for cases in which the target subse
quence V = f(w) of an alignment function pair
ing has more than one word. For the purposes of 
the head-transduction model constructed, such 
compound target subsequences are effectively 
treated as single words (containing space char
acters). That is, we are constructing a tran
ducer for (w : V). 
We use the notation Q(w : V) for states of 
the constructed head transducer. IIere Q is an 
additional symbol e.g. "initial" for identifying 
a specific state of this transducer. A state such 
~s initial(w : V) mentioned in the construction 
is first looked up in a table of states created 
so far in the training procedure; and created if 
necessary. A bar above a substring denotes the 
number of words preceding the substring in the 
source or target string. 
We give tile construction for the case illus
trated in Figure 2, i.e. one left dependent wt, 
one right dependent w~, and a single secondary 
word w' to the left of w. Figure 3 shows the 
result as part of a finite state transition dia
gram. The other transition arrows shown in the 
diagram wilt arise from other bitext alignments 
containing (w : V) pairings. Other cases cov
ered by our algorithm (e.g. a single left, depen
dent but no right dependent) are simple vari
ants. 
"l/J l 
lOt :C 
f(wt) 
/ 
--I:0 
') left~,,(w 
-1 :/31 
') mid~ I (w 
wr f(w~) \]+1:/32 
v) 
v) 
v) 
v) 
Figure 3: States and transitions constructed for 
tile partition shown in Figure 2 
1. Mark initial(w : V) as an initial state for 
the transducer. 
2. Include a transition consuming the secondary 
44 
word ~/without any target output: 
(in.trial(w: V), left,~,,(w: V), w', (,-1,0), 
where ~: is the empty string. 
3. Include a transition for mapping tile source 
dol)en(lent tL;l to the target dependent f(w/): 
(le ft,:,(w : V), mid+~(w : V), wl, f(wl), -1,9l) 
where/~z = f(wl) V. 
4. Include a transition for real)ping the source 
deI)endent wr to tile target dependent f('w,.): 
(mid~,(,,+ : V), firz(d(w : V), w,., f(w,.), +1,/J,.) 
where/3,. = f(w,,) V. 
5. Marl( fincd(w : V) as a tinal state tot" tile 
transd u{;er. 
The inclusion of transitions, and the marking 
of states as initial or final, are treated as event 
observation counts for a statistical head trans
duction model. More specifically, they are used 
as counts for maxinmm likelihood estimation of 
the transducer start., transition, and stop prob
abilities specified in Section 2. ,5 Head selection 
We have l>een using the following monolingual 
metrics which can t)e at)plied to either the 
source or target Iangllage. to predict the likeli
hood of a word being the head word of a string. 
DistaT~ce: The distance between a dependent 
and its head. In general, the likelihood of a 
head:dependent relation decreases as distance 
increases (Collins, 1996). 
I'l/ord frequcncg: The frequency of occurrence 
of a word in the training corpus. 
IVor<t 'complexity': I'k}r languages with pho
netic orthography such as t~;nglish, 'complexity' 
of a word can be measured in terms of number 
of characters in that word. 
Optionalit9: This metric is intended to iden
tify optional modifiers which are less likely to 
be heads. For each word we lind trigrams with 
the w<)r(t of interest as the middle word and 
compare tile distribution of these trigrams with 
the distribution of the bigrams formed from the 
outer pairs of words. If these two distributions 
are strongly correlated then tile word is highly 
optional. 
Each of the above metrics provides a score for 
the likelihood of a word being a head word. A 
weighted sum of these scores is used to produce 
a ranked list of head words given astring for use 
in step 2 of the training algorithm in Section 2. 
If the metrics are applied to the target language 
instead of the source, the ranking of a source 
word is taken from tile ranking of the target 
word it is aligned with. 
In Section 7, we show the effectiveness of ap
propriate head selection in terms of the trans
lation performance and size of tile head trans
ducer model in tile context of an English
Spanish translation system. 
6 Evaluation
method 
There is no agreed-upon measure of machine. 
translation quality. For our current purposes 
we require a. measure that is o\[>.jective, reliable, 
and that can be calculated automatically. 
We use. here the word accuracg measure of 
tile string distance between a reference string 
and a result string, a measure standardly used 
in the automatic speech recognition (ASR) corn: 
munity. While for ASR the reference is a human 
transcription of tile original speech and the re: 
sull tile output of the speech recognition process 
run on the. original sl)eech , we use. the measure 
to compare two different traIlslations of' a given 
source, tyl>ically a truman translation and a ma
chine translation. 
The string distance metric is computed by 
first finding a transformation of one string into 
another that minimizes the total weight, of sub
stitutions, insertions and deletions. (We use 
the same weights for these operations as in the 
NIST ASR evaluation software (NIS, 1997).) If 
we write ,5' for the resulting number of substi
tions, I for insertions, 1) for deletions, and \]g 
for number of words in the reference translation 
string, we can express the metric as follows: 
D + s + i ) word accuracy = (\[ /~ 
This measure has tile ,nerit of being coin
pletely automatic and non-subjective. How
ever, taking any single translation as reference 
is unrealistically nnfavourable, since there is a 
range of acceptable translations. To increase 
the reliability of the measure, therefore, we give 
each system translation tile best score it receives 
against any of a nuInber of independent human 
translations of the same source. 
4,5 
max source length 
5 10 15 20 >20 
wfw 45.8 46.5 4512 44.5 44.0 
sys 79.4 78.3 77.3 75.2 74.1 
Table 1: Word accuracy (percent) against the 
single held-out human translation 
7 English-Spanish experiment 
Tile training and test data for the experiments 
reported here were taken from a set of tran
scribed utterances from the air travel infor
mation system (ATIS) corpus together with a 
translation of each utterance to Spanish. An 
utterance is typically a single sentence but is 
sometimes more than one sentence spoken in se
quence. There were 14418 training utterances, 
a total of 140788 source words, corresponding to 
167865 target words. This training set was used 
as input to alignment model construction; align
ment search was carried out only on sentences 
up to length 15, a total of 11542 bitexts. Trans
duction training (including head ranking) was 
carried out on the 11327 alignments obtained. 
The test set used in the evaluations reported 
here consisted of 336 held-out English sentences. 
We obtained three separate human translations 
of this test set: 
trl was translated by tile same translation 
bureau as the training data; 
tr2 was translated by a different translation 
bureau; 
erl was a correction of tile output of the 
trained system by a professional translator. 
The models evaluated are 
sys: the automatically trained head trans
duction model; 
wfw: a baseline word-for-word model in 
which each English word is translated by the 
Spanish word most highly correlated with it in 
the corpus. 
Table 1 shows the word accuracy percent
ages (see Section 6) for the trained system sys 
and the word-for-word baseline wfw against trl 
(the original held-out translations) at various 
source sentence lengths. The trained system 
has word accuracy of 74.1% on sentences of all 
lengths; on sentences up to length 15 (the length 
on which the transduction model was trained) 
the score was 77.3%. 
max source length 
5 10 15 20 >20 
~--fw 46.2 47.5 46.6 45.8 45~ 
sys 80.1 81.6 81.0 79.3 78.5 
Table 2: Word accuracy (percent) against the 
closest of three human translations 
Head selector 
Baseline 
(Random Heads) 
Word 
accuracy 
64.7% 
Nuinber of 
parameters 
108K 
In Source 71.4% 67K 
In Target (sys) 74.1% 66f( 
Table a: Translation performance with different 
head selection methods 
Table 2 shows the word accuracy percentages 
for the trained system sys and the word-fbr
word baseline wfw against any of the three ref
erence translations trl, erl, and tr2. That is, 
for each output string the huinan translation 
closest to it is taken as the reference transla
tion. With this more accurate measure, the sys
tem's word accuracy is 78.5% on sentences of all 
lengths. 
Table 3 compares the performance of the 
translation system when head words are se
lected (a) at random (baseline), (b) with head 
selection in the source language, and (c) with 
head selection in the target language, i.e., select
ing source heads that are aligned with the high
est ranking target head words. The reference for 
word accuracy here is the single reference trans
lation trl. Note that the 'ln Target' head selec
tion method is the one used in training trans
lation model sys. The use of head selection 
metrics improves on random head selection in 
terms of translation accuracy and number of pa
rameters. An interesting twist, however, is that 
applying the metrics to target strings performs 
better than applying the metrics to the source 
words directly. 
8 Concluding
remarks 
We have described a method for learning a head 
transduction model automatically from trans
lation examples. Despite the simplicity of the 
current version of this method, the experiment 
46 
we reported in this paper demonstrates that 
the method leads to reasonable performance 
for English-Spanish translation in a limited do
main. We plan to increase the accuracy of the 
model using the kind of statistical modeling 
techniques that have contributed to improve
ments in automatic learning of speech recogni
tion models in recent years. We have started 
to experiment, with learning models for more 
challenging language pairs such as I;2nglish to 
Japanese that exhibit more variation in word 
order and complex lexical transformations. 

References 

tt. Alshawi, A.L. Buchbaum, and F. Xia. 1997. A Comparison of Ilead Trandsucers and Transfer for a Limited Domain Translation Application. in :15 Â°~ Amzual Alcetizzg of the Association for Computational Li~guistics. Madrid, Spain, August. 

11. Alshawi. 1996a. Head automata and bilingual tiling: Tr,~nslation with minimal representations. In 3/tth AnT~ual A4eeli~g of the As,~ociation for Comp.tatior~al LiT~quistics, pages 167176, Santa Cruz, California. 

I1. Alshawi. 1996t). llead automata for speech transl~tion, in lnternal~ional Conference oTz Â£'poL'~ l;al~g~lagc l)l'ocessing, Philadelphia, Pennsylvania. 

P.J. Brown, J. Cocke, S. Della Pietra, V. Della Pietra, a. Lafl'erty, R. Mercer, and P. Rossin. 1990. A Statistical Approach to Machine Translation. Computational Linguistics, 16(2):79-85. 

P.J. Brown, S.A. Della Pietra, V.J. Della Pietra, and R.L. Mercer. 1993. The mathematics of machine translation: Parameter estimation. Computatio~al Lil~guistics, 16(2):263 312. 

Michael John Collins. 1996. A new statistical  parser based on bigrmn lexical dependencies. In 34th Meeting of the Associations for Computational Linguistics, pages 184-191, Santa Cruz. 

W.A. Gale and K.W. Church. 1991. Identifying word correspondences in parallel texts. In Proceedings of the Fourth DAI~PA Speech and Natural Language Processing Workshop, pages 152-157, Pacific Grove, California. National Institute of Standards and Technology, http://www.itl.nist.gov/div894, 1997. Â£'po47 ken NatuTul Language Processing Group Web page. 

Eiichiro Sumita and Hitoshi Iida. 1995. tleterogeneous computing for example-bmsed translation of spoken language. In 6 th International Conference on Theoretical and Methodological Issues in Machine Translation, pages 273-286, Leuven, Belgium. 
 
J.M. Vilar, V. M. Jimdnez, J.C. Amengnal, A. Castellanos, 1). Llorens, and B. Vidal. 1996. Text and speech translation by means or sut)sequential transducers. Natural Language Engineeri~ ~g, 2(4):351-354. 
																																							Dekai Wu. 1997. Stochastic inversion transduction grammars and bilingu,~l parsing of parallel corpora. Computational Linguistics, 23(3):377-404. 

