\documentclass{article} % For LaTeX2e
\usepackage{nips12submit_e,times}
%\documentstyle[nips12submit_09,times,art10]{article} % For LaTeX 2.09
\newcommand{\tab}{\hspace*{2em}}

\title{Citation Prediction with Weighted Citation Network Links and Contextual Semantic Information}


\author{
Jonathan C. Barker\tab Kartik Goyal\tab Zhengzhong Liu \\
Language Technologies Institute \\
Carnegie Mellon University \\
Pittsburgh, PA 15213 \\
\texttt{\{jcbarker, kartikgo, liu\}@cs.cmu.edu} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

%\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle

\begin{abstract}
 In this work, we address the problem of missing citation prediction. Current approaches to this problem includes making prediction through the citation network structure and identifying them through semantic similarity. In this work, we attempt to incorporate both these information to help make better prediction. We spot the phenomenon that not all cited papers are equally important to the citing paper. Thus we adopt a supervised random walk method to learn the appropriate weights on these links using textual semantic information and cross-document topic models. We evaluate our weighted network by predicting missing citations for a paper, given the paper's current citations.
\end{abstract}

\section{Introduction}
Identifying relevant literature from electronic collection is becoming difficult with the rapid growth of the collection. This makes it very challenging for researchers to conduct efficient and comprehensive literature review. Thus automation of such process become necessary. We consider the problem as a traditional network link prediction problem. Existing citation networks only provide the links between citing and cited papers. Such networks can provide us binary information about whether a link exists between two papers, but fail to encode information about the relative importance and relevance. As a result, it is difficult to draw profound conclusions from these networks about the relationships between different network nodes. We address this problem by assigning weights to network links according to their importance and relevance to the cited paper in order to mine deep information. Tasks like automatic paper recommendation and missing citation prediction can be made possible. Authors can use it to detect any papers they might not have cited in their initial draft, while journal reviewers can be aided in detecting any relevant works which are not cited by the submitted papers.\\
In practice, various techniques like random walks \cite{Sarkar2009,Tong2006} have been employed to find node relevance in networks. These techniques generally work with a uniformly weighted network and utilize information encoded in graph structure. Our belief is that these techniques can be used more effectively if the network graph were to contain weighted links. The weights on the links would represent the similarity between citing and cited papers according to their semantic correlation, citing patterns, shared authors and temporal proximity. Using these weights should provide more meaningful results for tasks like missing citation prediction when the existing network based techniques are applied.\\
The major challenge in this approach is figuring out how various sources of information can be combined with the network structure. In doing so we must determine the relative importance of these sources/features with respect to the relationship score of two papers. When have finally synthesized this information to create our weighted network we aim to show that we can use it to produce more meaningful results for tasks such as missing citation prediction.
\section{Related Work}
Nallapati et al. \cite{nallapati2008joint} use topic models created with Latent Dirichlet Allocation(LDA) \cite{Blei2003} to predict the existence of a citation link between two papers. Apart from generating words, they also generate the reference links from the topic model, thus creating a topical dependency between cited and citing papers. \\
Backstorm and Leskovec \cite{Backstrom:2011:SRW:1935826.1935914} perform supervised random walks on networks to learn the weights on the links between community members. They use this weighted network to predict future links between the members of the social network. The weights are learnt by minimizing an error function on the probability of predicting incorrect and correct future links. \\
LDA can be used for determining semantic correlations between two documents. Celikyilmaz et.al describe some of the similarity measures based upon LDA which they used in the QA systems. These similarity measures used both, topic proportions and importance of similar words for estimating similarity.
\section{Method}
A major challenge of this work is how to learn the relevant weights of features of according, we aim to learn a function that can properly assign weights based on the dataset. Here we adopt a method similar to \cite{Backstrom:2011:SRW:1935826.1935914} which optimize a function that can assign higher random walk score to real missing nodes versus other nodes.
The network we will attempt to create weights for is the ACL Anthology Network (AAN). Since this citation network does not have weights on links, intrinsic evaluation is not feasible. Instead we will perform an extrinsic evaluation of our weighted network by predicting missing citations.\\
\\
The weights on the network are determined by various features which depend on citation patterns, semantic correlation and the network metadata. These features are defined for a citing and cited paper:
\begin{enumerate}
  \item Number of citances for the cited paper. ("citance" refers to a citing sentence in a paper)
  \item Co-citance score. This is defined as the number of times another paper is cited in the same citance as the target cited paper.
  \item The number of common papers which both citing and cited papers cite.
  \item Topical similarity between the citing and cited paper, calculated using topic proportions from Latent Dirichlet Allocation(LDA).
  \item Number of common authors.
  \item The difference between time of publication, measured in years.
\end{enumerate}
To extract features 3, 5 and 6, we used the metadata from the AAN. To determine 1 and 2 we used regular expressions to extract citances and match them with the cited papers. Mallet toolkit was used for running LDA, which uses gibbs sampling for parameter inference, on the raw text of all the papers. The topic proportion vectors were created and were used to calculate cosine similarity between documents.
\section{Experiment}
As shown in table :\ref{results-table}
\begin{table}[t]
\caption{Results}
\label{results-table}
\begin{center}
\begin{tabular}{ll}
\multicolumn{1}{c}{\bf PART}  &\multicolumn{1}{c}{\bf DESCRIPTION}
\\ \hline \\
Dendrite         &Input terminal \\
Axon             &Output terminal \\
Soma             &Cell body (contains cell nucleus) \\
\end{tabular}
\end{center}
\end{table}

We observe that self-citation also have impact on the performance

\section{Conclusion}

\bibliographystyle{plain}
\bibliography{midrep}
\nocite{*}
\end{document}
