English-Chinese Machine Translation System IMT/EC Chert Zhsoxlong and Gee Qingshi Institute of Computing Technology Chinese Academy of Science BelJlng, PRC.
Abstract IM'I/EC is an English-Chinese machine translation system ~,hich integrates some outstanding features of the case grammar end semantic grammar lnto a uniform frame, LISeS various kuowledgo In the disamblguation, and tries to modify the object language by itself.
In this poF,er,we first introduce IMT/EC's design motivetiorl and overall architecture, then describe the deslgn philosophy of its translation mechanisms and thelr procesging algorithms.
J,The design nlotivation \]'he design of the IMT/EC system are motivated to develop new approaches to the Engllsh-Chinese machine translation, such as, to provide the system with powerful analysis meohanisnls end MT knowledge base menagonlerit system, as well as some exceptional processing and learning meohanlsms, that is, to make the system ba intelligent.
In addition, it also tries to inregret9 as many advantages of conventional machine translation systems into a single system as possible, such as, to provide the system with powerful mechon-.
Isms for the processing of various ambiguities and contextu,~l relations.
The design of the IMT's translation mechanisms are based on the following conslderQti on ~;, (1) St-analysis In the development of machine translation system, in order to disambiguato the source language, we have to {molyze the input deeply to get the internal meonlng representation of the source language.
However, the deeper we aaalyze the input, the more we lose the clues about how to express the translation, also, th(it it results in extremely poor or no translations ef sentences for which complete analyses can not be (h~rlved\[Slocum 85\].
To find a suitable analysis depth so as to get both clues about how to express the trorl~;lation of the input and to disombiguate the input conlpletely Is almost impossible.
In the IMT/EC, we try t(, design a simple grammar analysis mechanism -SC-gr'(~mmar auulysls mechanism to inherit both the outstanding features of case grammar analysis and semantic grammar analysis so as to produce a high quality translation, (2) Multl-language translations oriented In present technical conditions, it is impossible to design a general internal meaning representation for all natural languages.
Thus, the knowledge based multl-language oriented machine translation system is difficult to be marketed in the near future.
A feaslble way ~or designing multl--longuage oriented machine translatJorl systems might be to separate the processing mechanisms from the language specific rules |as King et oI.
~5\], thet ie, t O apply the same processing meotlonlsm with different language specific rules for d~ffErent natural language pair translations.
In the 1NI'/EC, we develop a general rule representation form for the representation of various knowledges used in the translotlon.
Knowledges for different language palr translations are stored in the differant packages of the knowledge base IMT-KB.
The knowledge base are organized In multi-package end multilevel way so as to store rules for the translation of different language pairs and different phases of the processing.
Thus, the system can be easily extended for' multi-language trarlslatlon purposes.
(3) Diversity processing As the dlsemblguation rules are rather words specific, ±% is difficult to manage them in the same way.
To deal wlth this problem, we store these rules in their respected word entries end classify them es several categories in the IMT/EC, Each category corresponds tO 0 general subroutine epplleatlon mechanism, which apply the word specific rules and subroutines in the processing of translation.
The subroutines are stored in a natural language specific subroutine package.
Some word specific subroutines are directly stored in the respected word entry.
(~) Powerful exceptional processing Since the natural language phenomena ore so abundant that any existed machine translation system can not process all the phenomena, it is essential to provide an exceptional processing mechanism in the system to deal wlth exceptional phenomena.
As IMT/EC incorporates some learning mechanisms, thus, it is more powerful in dealing with the exceptions than others.
(5) Automatic modification of the translation Generally speaking, machine translation system can only produce rigid translatlons, it is a desire that MT systems be able to modify the output by itself so as to produce more fluent translations.
IMT/EC tries to apply same common sense knowledge and linguistic knowledge of object language to disamblguate the input end modify the translations, thus, to improve the translatlon quality.
In the following paragraph, we focus on the translation procedure of the system end the algorithms related to it ignoring the knowledge base organization and management mechanisms.
2. The overall architecture of the system The architecture of the IMT/EC system is as follow, \] knowledge base management Engllsh Input System IMT-KB \[ ~ f Knowledge~ Morphological Analysis l. I I ~ Applicatzon J & Dictionary Retrlving~ / p._I_T_T..~1~ t I ~;n:l;;";'s ' L \~/ ___ B°se.~_ 7 \[ --~~ /~ / Augmentation-~ _ / Dlsambigu~on r / I\k & Modifiootio~ f*~ | & Transfer L / I \~ ' ....
',, I I Acquisitioo ) I the Tren?lotlonJ / t / / Fig.
The architecture of the IMT/EC 117 As the rule bose and dlctlonarv in a machine trenslatlon system is so vast that it ls impossible for human beings to find the confllotion end implication among the rules.
To modify a rule in the knowledge base often results In many side effects on other rules.
Thus, it Is necessary to provide a self reorganization and refinement mechanisms in the knowledge bose.
In the IMT/EC, we design a special knowledge base management system IMT-KB to manage ell the knowledge used In varlous processing phases of the translation.
In addition, IMT/EC also provides o knowledge bose augmentation and knowledge acquisition environment for the system to augment system performance by itself and for the users to improve the knowledge base.
The col1 relations connected by dotted llnes in the figure above ore executed only when the user sets the learning mechanisms in working status.
These mechanisms can acquire new knowledge in the dynamic interactive, static interactive,or disconnected ways.
They ore primarily used to resolve the exaeDtlenel phenomena in the translation.
Dynamic Interactive Learning (DIL): Whenever the system encounters c sentence out of its processing range, it produces various possible translations for each segment of the sentence and interacts with human beings when necessary to select on appropriate translation of the segment and combine them to get o correct translation of the sentence.
At the some time, it also creates'some new rules to reflect the selections.
That is, it learns some new knowledge.
Static Interactive Learning (SIL): Whenever the system encounters a sentence out of its processing range,it records down the sentence and its appearance context in e file.
After the text has been translated, it begins to analyze the sentence in detail to get various possible translations for each segment of the sentence and interacts with human beings when necessary to get appropriate translations of the segments and combines them to get a correct translation of the sentence.
At the same time, it also creates some new rules to reflect the selections, thus, to learn new knowledge.
Disconnected Learning (DL): Whenever the system encounters o sentence out of its processing range, it analyzes the sentence in detail to get all the possible translations, and then evaluates these translations according to the preference rules stored in.the IMT-KB to select on appropriate translation and modify the related rules used in the analysis to reflect the selections.
It skips over sentences which the translation con not be determined by the preference rules Instead of interacting with human beings.
5. The translation procedure IMT/EO's tronslatlon procedure is divided into several phases, i.e.,morphology onalysls and dictioncry retrlvlng, SC-grammor anolysls,dlsamblguotlon and transfer, modification of the tronslatlon etc.
The communlcotions between tronslotlon mechanisms and the knowledge bose ore performed by the knowledge base management system IMT-KB, these operations includes getting a se~ of related rules and returning some Information for the modification as well aS augmentotlon of the MT knowledge bose.
5.1. Morphology analysis and dictionary retriving In the IMT/EC, words in most common uses con be retrived by either their base forms or their surface forms, whlle most of the other words can only be retrieved by their base forms.
The tasks of the morphology analysis ore to process the prefix, suffix, and compound words.
Since these processlngs ore completeiv natural language specific, in order for the processing mechanisms to be language independent, we develop a language independent morphology analysis mechanism to opply the language specific morphology rules In the morphology analysis, The morphology analysis rule form is <surface pattern> -> <conditions> I <result> 118 Here, <surface pattern> is the surface form of the word to be analyzed, <conditions> is the oppllcotlon condltlons of.
the rule, <result> Is the definltlon of the word base form analyzed.
For example, (1) (" s)-> (verb -) I (def("), SV) (2) (" s)-> (noun *) I (clef(*), PN) (3)(-1 "2)-> (word -1)(word "2)1 ((def(morpholog v w1), def(morphologv "2)), CaM) Here, *, -1 and *2 are variables Indlcating that it con be bounded to any sub-character string of the word to be analyzed, def(X) is the definition of X in the IMT-KB, SV, PN, cam are surface 'features of the word.
Rule (I) Indlcotes that when the last character of the surface form of a word is 's' and the remained character string * in the word is o verb, then its surface feature is the slngulor verb form (SV) of the verb *.
Thus, It returns the value of (def(*), SV) as result.
Rule (2) indicates that when the lost character of the surface form of a word is 's' and the remained character string * in the word is o noun, then its surface feature is the plural noun form (PN) of the noun *.
Thus, it returns the value of (def(*), PN) as result.
Rule (5) indicates that when the character string of o word comprises a character '-', the left pert ~1 and the right part w2 of '-' ore both words, then it lso compound word of ~I and w2.Thus, it applies morphology rules to analyze the word ~1 and *2, and returns the value of ((f(morphology -1),f(morphology w2)),COM) as result, Suppose that, SX indicates that X is o variable, #X returns the character llst of X, &X returns the lost character of X, >X returns the first part of rule X or the first element of a list, <X returns the remained port of X which (>X" <X o X), f(X,V) returns the first different item palr of X ond Y, lookup(X) looks up the dictionary and returns the deflnltlon of the word X, search(X) returns the morphology rules which leclu-.
des character X, check(X) tests whether two elements of the item pair X is uniflable or nag, null(x) tests whether llst X IS empty, apply(g,x) returns the result of g(X), t(X) tests whether result X needs further onolysls and performs recurslve analysis when necessary.
The algorithm for morphology analysis and diction-erv retrievlnq is as follow.
INITIALIZE $X <#word; SP <search(& SX); $P <$PU search(> $X); $result <( ); for $rule m SP do {MATCH SPAT <= > Srule; $COND <>"< $rule; $RES <<=< $rule; Loop $patr <-f(SPAT, SX); if (null($polr)) goto TEST; if (not(check($pair))) break; SPAT <$PAT~ Spelt; iPAIR .I.
<-. iPAIR l.U ($polr}; gate Loop ; rEST for $CONDI e$COND, do ($PROP <lookup(>e < ($CONDL)); if (not(apply(> $CONDI, SPROP)) brook; } |:~ESUI.T iPROP <-lookup (> ($RES~'$PA);R L)); iresult <-iresult U {($RES~ iPA:\[R L, iPR(IP ) } ; ) if (pull($res~it)) return word else returrl t($resu\].t); El~ll), 3.2.
St--Grammar Anulys:Ls The St-grammar enolysis mechanism of IMT/EC U|)plle~ th( SC--rolos stored ill the iMT-KB to dlsumblgLlate the ~.trueturol embigultles of the input senten-cos end predm;es the structural description for them.
"ihe grammar |lOS some outstending features of the case grommet ond semuntic gr'ommor.
The rule form ls cs follow, <S-STRUCTURE> ~> <S-ENVIRONMENT>I < R=SI'RUCTURE >, <I~ENVIRONMENi> <TRANSFER>.
Itore, <S-.SIIRUCrUI~E> mid <S-ENVIRONMENT> are rule conditions which defines the current strtlctLIr(\]l form end contextual foattlres of the input, <R-.STRUCTURE> und <R-ENVIRONNiENT> ore result strueturul form ~nd corltextuel features of the input, <TRANSFER> ere the trensformotlo~Is related to the rule.
lho structural forms, <S-SI'RUCTURE> end <R-STRUCTURE> ore represented os strings of syntogmos arid words.\]he contextuel envlronments,<S-ENVIRON~ENT> and <R-ENViRONMENT> ore represented os vectors, of which each element corresponds to on inter-sententtal reletion or e specla\] eeoc, their values ere used to resolve the ellipsi.s,dnephore, tense and espocts etc.
it is the principal contextual processing mochenisms in the IMI/EC.
Since the contextual vector is used only os a supplo*~lent to the pure semantic grammar ona\]vsls, espeele\].\].y in the processing of contextual relations, it is riot necessary to analyze the Irlput to the extent the|.
one con get ell the semantic relations of the input.
Thus, the vector processing formalism is completely acceptable.
Two example rules ore as follow, NP VP -> A I S, change(B1,×), INP IVP.
in NP -> A1 I PP, chonge(B2,X), zel INP nuei.
St-grammar onelysis mechanisms receive the results of morphology analysis or previous SO-reduction, send the messages to the IMT-K8 to get releted rules, end apply these rules to,reduce.
the input until o nonterminal symbol S is reduced, thus, to produce the structural description o1' the input.
The SO-grommet analysis algorithm of the system is:.
(I) \]in the entries of' the \[MT-KB dictionary, we stored not only the word meanings and their disembi-guotlon conditions, but oleo SO-phrase end sementlc rules specJflo to the entry word.
When onulyzlng e sentence, the system first retrieves the SC-phrose rules specific te the words appeared irl the sentence, end ~pplim these rules to find a list of possible phrases of the sentence from the context of the words in the senl;eneo.
The phr~se list returned is os follow, X, (i,, J, ) X~(±~,J:) x~(i.,j~). Here, XI, X~., ...,Xm ore phrase syutogma Identif$ers, i}, ~) .....
J.~ arid J~, Jz .....
J~ ere ending positrons of the phrases in the input sentence.
(2) Find a list of expectation pathos from the phrase \[List as follow,.
"'~') X~;(J,~l k,!
X~l(m,4t m) X, (i,J,) vl~), ×~/(l,Jm i X~)(Jm÷l,k ) ~ U"~+I,n#) P(w ~ ) P(w~+ L) .,, p(w~z.
# (Here, P(w) is the word w itself or its property, t is the current onalysls position which initial veluo is ~,I is the expects|lee length defined by the user) end order them by means of the phrase ending post-tlons n=,n~ ..... n~ from lerger to smeller.
These pothes are used as heuristics in the ano\].ysis ef the sentence.
We try one new patti ot one becktrecking.
(3) Send the ano\].yzed component M = V,()...
V~()... ...
V~()... cndIiihe current expectetion path to theIIMT---KB to retrleve the'SC-ruIes'which heed pc|terns contain sub-string of {~,()... ...
v~()... x~(..:) ...
xz()... ~1 Path = or (.
) v~( ) P (w~ ) ...
P (w~.~) and organize these rules in a list according to their preferences from higher" Lo lower.
Then, it tokes one rule from the rule llst at one buckfirecklng and go to (~) to appl V the rule to reduce the input.
If no rule in the llst con be successfully applied to reduce the input, the system gets the next expectation path from (2)end repeet (3).
If all the expectation pethes have been tried end no successful rule has been applied, it returns 1;o the last analysis position to re-analyze the input.
If the current erla-lysis position Is the beginning of the sentence, the system coils the exception processing,lechenism to deal with this un--analyzable sentence.
(l~) Match the rule head pattern with the current form of the input sentence.
If there is a sub-pattern of the current sentence pettern that can match the rule heed, then go to (5) else get the next rule from (3) end tries to re-.match them.
(5) First, odd some newly formed phrases into the phrase list in order For the backtracking of the one lysls, then coll the cese enelys±s mechanism to check the eurreet analysis results und the current form of tile sentence 'to Fill in the rose freme A, B in the rule end the context vector.
The case anelysis algorithm is described In the following paragraph.
(6) Check A end the context vector to see whether their values are unlfleble.
If they are unifieble, then go to (71, else get the next rule from (3) and returns to (4).
(7) Store the backtracking informetion into the temporary stock, substitute the reducing part of the current sentence form with the reduced form, change the current analysis position to the last word oF the newly reduced syntagma,cnd change the related element values o£ the context vector aecording to the element values of B.
If the current position is not the end of o sentence, then go to (2), If the current position is the end of a sentence end the current form of the sentence is net S, ~hon go to (2), If the current position is the end of e sentence end the current form of the sentence is S, then go to (8), (8)Call the semantic processing mechanism to check the result of the nnslysls to see whether ~t violates the English collocetlon rules.
If the result violetes the collocation rules, the system recovers to the status before the last reduction and gets 'the rlext rule from (5) to r'e-onoiyze the input.
Otherwise,there wlll be two cases, a, If the user only needs the most adequate • trensletlon, the system proceeds to analyze the next sentence.
b. If the user needs ell possible trcnslations, the system records down ~he current result end rosevers to the stetus before the Zest reduction end gets 119 the next rule from (5) to re-analyze the input in order to get other onolysls results.
AS we have mentioned before, the case analysis in the SC-analysls is only a complement to the semantic analysis.
It is mainly used to des1 with the context relation and a§pect, tense, modal etc.
Thus, the system only needs to analyze those cases which can be used in those purposes.
It ls much simpler than the case analysis in the case grammar analysis.
The case analysis in the SC-enalysls ls performed by the following algorithm, (1) Get the case expressions defined in the el'emerita of" vector A and B.
The form of the element expressions of A and g ls s~\[i\]:E Here, S~\[I\] indicates the element case Cdentlfler(S#) of the case frame A or g is corresponded to the case identifier sill of the system case frame, l.e.,system context vector.
E is the expression used to get the value of the respected case.
(2) Retrieve the definition of the case identifiers from the system case frame and organize these case identifier into a 1let according to their preferences from higher to lower.
The form is, (S\[il\].subject:EI,S\[12\].obJect:E2 .....
S\[lm\].Em ....
) (5) Evaluate the value of the elements in the case identifier llst, and flll them Into the respected position in the case frame A end B.
There are many cases in the evoluatlon.
a. E ls a constant, returns E, b.
E ls empty, evaluate the case value according the definition of the case identifier, c.
If the case identifier lsa syntagma idetlfler, then finds the vclue of the identifier from the analyzed input according to the heuristics provided by the expression E, d.
If the ease identifier is o sementlc identifier, then call the semantic mechdnlsm to get the value which can be filled into the case identifier from the input according to the heuristics provided by the expression E, e.
For other case identifiers,call thelr respected Subroutines to get the value of the case.
These subroutines are defined by the rule designer.
The case analysis in the SC-analysis con solve the elllpsls, anaphora, and other contextual problems.
5.5. Semantic dlsambiguatlon and transformation The SO-rules define not only the relations for the syntagma reduction, but also contextual vector value changes with respect to the reduction of o sentence, and the rules related transformations.
The transformation operation defined in the SC~rule is in the follewlng forms, IX IX ...
IX Here, IX, IX ....., IX are translations of the syntagmas X, X, ..., X in the rule head.
Their positions indicate the positions of the translations of the syntogmas.
There will also be some indicators In the string which are used to indicate positions of the translations for inserting tense, voice, modal modiflers.These indlcotors are used as the heuristics of the semantic processing.
The transformetlon in the IMT/EC ls relatively slmple.
It travels over the whole anolysls tree from top to down, left to right, transfer every node when the node is £raveled.J'he result of the transformation is the Chinese utterance of the sentence.
Rules with same head patterns may have different case frames A and B,in this case, they may correspond to different transformation operations.
These rules ore defined as two different rules by the rule deslgne'r.
Whfle in the IMT-KB, the system stores them as one rule wlth many candidate right patterns.
Whenever the head pattern is successfully matched, the system sequentially checks these candidates until one of them is satisfied and records down the current successful position so that backtracking mechanism can 120 get the other candidates when necessary.
The tasks of the semantic processing in the IMT/EC ore to check the results of the analysis to see whether they satisfy the syntax or semantic collocation rules defined in the IMT-KB, to produce the suitable modifiers for expressing the tense, volce, aspects and so on In the Chinese.
In some cases,lt also apply the well formed world knowledge deflned in the IMT-KB to eliminate some 11legal expressions and extend the meanings of some ambiguity words.
Slnce the SC-analysls is based on the semantic grammar analysis, most of the syntax and semantic ambiguities are solved in the reduction operations.
Even though the case analysls in SC-analysls ls aimed mainly to resolve the contextual problems, they can also solve some ambiguities among o sentence.
That is, the semantic processing in the IMT/EC ls orlented to speclflc ambiguities and lnter-sententlal case value evaluations.
Though the processtngs are different in different phases of the trons1otlon, they can be categorized as, (1) determining the value of o specific semantic identifier, such as tlme adverbial, place edverblal, anophoro etc.
When o specific semantic identifier is concerned, the semontlc, processlng mechanisms first finds the key word which con match the semantic identifier from the sentence,such as word wlth tlme,plaoe properties, then get the phrase which comprises the key word in the sentence, and return the phrase as the value of the identifier.
Only simple anaphoro phenomena are considered in the IMT/EC.
They are processed in two different ways.
One is to compare the synonyms to flnd the.
anaphorn words, the other Is to flnd the suitable anaphoro content through the position relations, such ca, in some specific context the word 'which' can refer to the noun phrases immedlotel y before it.
(2) checking the collocation of syntogmas.
There ore three possible categories of collocation In the analysls results, <1> X W -> (W => CI) <2> W Y -> (W => C2) <5> X W Y -> (w => C 3) Here, X, Y may be strings of words or syntagmos, W Is a specific word.
The above expressions means that, <1> W appears after string X and functions as speech CI, <2> W appears before string Y and functions as speech C~, <5> W appears between strlng X and Y and functions as speech C~.
The related word definition in the IMT-KB dictionary is as follow, W := C, (E, => MI) (E~ :> M~) c: (E~ => M~) Cm (E~ => M~) Here, C is the speech category, E is the context structure of word W, M Is the meaning of word W.
The semantic processing mechanism retrieves the collocatlon rules specific to words of the sentence from the IMT-KB, and applies these rules to check the analysis result to see whether there is any Violation between the analysis result and collocation rules.
If there ls, returns fell.
(5) cheoklng the distant contextual relatlons.
There are also three possible categories of distant contextual relations appeared in o sentence, X ...
W \[m\] -> (W => C~) W ...
Y \[n\] -> (W => C~) X ...
W ...
Y \[m,n\] -> (W => C~) Here, X, V, W, C have the same meanings as in the (2).
n, m are optional, they defines the relative position between the word W and XIY.
When n, m = 0, they ore the cases described in (2), When n, m is not defined, they indicates any position before/after the word ~V.
These distant contextual relation rules are defined la the It~-I'--Kg In the same way as in (2).
If m and/or u are present, the semantic processing mochenisdl finds m/rl word before/after tile word W in the sentence, and tries to reduce that word and its adjacent words inca X or' Y.
If they can be reduced, end tile word W functioas as the same category as defined in the rule, trlen Successes, e18o eliminates tlm analysis, if .iaud n are not ~efined, then try to find the word before/after tile word W which con be reduced into X or Y together with its adjacent words.
If there ere no such element in tile sentence, then returns f(lil.
(ll)cre,3ting Chinese modifiers to express the tense.
voice, modal arid so on Grid insert these modifiers in tile t r(3Jisloticn according to tile position mark Ip'pearoci iu the rule.
the 9recessing procedure is as follow, a.
GeL ClIO niorks of the tense, voice, modal etc.
b. Coll.
trio' correspelld/ng sabrautines defined by the rule designer to del.orlidtle on appropriate modifi-or 1-'or tile mclrk.
This is bclsod mainly on tile soatexi;llul structure of the analysis result.
C. Ins(~rt tri() modifier in trlo position of tile trunslati~)n marked by the niarker.
For" exalllJilo,if a very is in the '-leg' form and tilere &s I:e time odvorbiol in the i~lput, the tease of tho contoxt are all progressive, then ignores trle time rHark.
IF the predicate ore 'be going to', then translates it as 'dashuang' ignoring trlo time mark.
The world knowledge rules are defined in the same form as ihe semantic rules.
"lhe application of these rules (Jr( to test tile context to find the semantic f'o(~ttlres Of the sltLIotIon end coIdpQre these to the world mo(iel definition dei"i~lc, d if~ the world knowledge rule to \[{el;ormiue the sit<lotion of" the utterance, and thO~l detormido the correch translation or exterlct the mounlllgS Of related words.
Every semuntlc processing nleChOnlsm mentiorled .b<)ve co,~responds to u specific processing subrout.irle.
rtie;~.~ sabroatines are called ill the grammar onelysls Ulid transformation processing to perform the related \[~{911tantic processing.
(1) Is primarily asod in the case qnalysls, (2) and (~) are pr'Imarlly used in checking cbe analysis result and disembiguations in the analv:;Is and tronsfortllaLion,(4) is primarily used ill the tr,msformotlon.
The gr~muner and word trnnsformatlon qlgor$thm is, (1) CHrrent=node <-root of tile enalysls tree, (2))Z'£ the curront-InOdO is o loaf node, go (4), (~) The current--node is not a leaf node, the processin!j are as follow, a.
iI' ~ll the elemerlts in the transformation e~:pression of the node c~re constant, go (5), b.
Ji ~ till the variables le trio transformation expression of the node are substituted by c(~nstants, thee call semantic processing mechanism to create suitable modifiers.
Go (5).
a. if' there are scale unsubstituted variables in the expression of the node.
set these varla-.
bias r~s current-node er)e by one, aed uses the results returned by each subnode to replace the vari(lbles.
(l~) Whet! the current=node Js a leaf node,that is, it is n spec~flc word or arl ldlol~, then retrieves its defintt;lon l=l"Onl the IM'I'-,KB, cell the semantic i}re(:osslu\[I,lecheli I Sill to determine on appropriate moaning far it according to the tree structure.
(5) I|' Lhe eurrent-aode is root node,then returns trio curron; fornl of the transfermatiou expreseion es the translation of the sentence.
Otherwise, returns tile expr'ession to the parent uode,reeovers the parent nod~ rJs curreet node.
Go (2).
~.t, The modification of: the translation The objective of" the automatic modification of the tr'auslGtlo~i iS tO ililprove the roadability of the transl~L:lorl,but tilts socrlflces part of the accuracy.
It is more suitable for the non-sctelltiflc literature tdanslatlon.
The main tasks comprises: a.
Change the order of the phrases and words of the translation, b.
Substitute some words which collocotion is not commonly used in the Chinese utterahce for the synoi nymous words, c.
lnsert some conjunctive words when necessary, d.
E11m~.nate some redundant wards.
The algorithm for these processing is, (I) According to the Chinese oollocotion rules defined in the IMT-KB, changes the words and phrases order of the tranelatlon which are not in accord with the collocat£on conventions in Chinese, such as, Budon ....
Erchia ....
(2) According to the co-occurrence rules of the Chinese words defined in the IMT-KB, check the uses of the Chinese words in the translation.
If they are not in accord with the co-occurrence rules, then replaces these words with the Chinese synonymous words until they ape accord to the rules.
If there is no suitable synonyms.then tries to extend the meaning of some words.
The meaning extending rules are defined in the word entries.
Its form is as follow, <word> :<condition 1> <extension I> <condition 2> <extension 2> <condition n> <extension n> Here, <word> indicates the word appeared in the sentence, <condition> defines the extending conditions, <extension> is the utterances extended.
i£ the word can not be replaced or extended, tilen just returns the source translation.
(5) Check the translation to find the redundant words and eliminates them.
The form of doletiorl rule is, X V X Z -> p (X), p (V) i X V Z such as, 'NP de NP de -> NP NP de'.
Since the modification has no absolute standard and requires a large amount of world knowledge, it is rather dlfflcult to solve this problem in one day.
In the ZMT/EC, we only deal with the most simple eases.
More complex situations can be solved with the application and improvement of the system.
Thus,the system is designed to be easily extended with the application.
if the user needs high quality translation, he may call the post editing subroutine to modify the translation by human beings or with the aid of human beings.
At tile same time,we can also set the learning mechanisms in working status to trace the modification procedure oF human beings and produce some useful rules For the system.
I~. Summary In conclusion, we hove lntroduce~ ~ translation processing procedure 9f the English-Chinese machine translation system IMT/EC, and describe its principal processing algorithms.
Aknowledgement: We would like to thank Hang Xiong, Zharlg Yujie, Ye Yimln, Tong Jioxion, Zong Llyi, Zhong Zife, Chen Z1zong, Chen Zizeng and Fu Wei For their cooperation in th e implementation of IMT/EC, References \[1 \] Axelbiewer, Christian Fenneyrol, Johannes Rltzke, ErWirl itegentrltt(1985), ASCOF-A modular multilevel system for French-German translation, OL, Voi.11, No.
2-5, p'157-'154, 1985.
\[2\] Bernard Vauquois and Christian ~\]oitet,Automated transletion at Grenoble university, CL, Voi.11, No.I, p28-36, 1985.
\[5\] galena Henlsz-Dostert et el., Machine Translation, Mouton publishers, Hague, Paris,New York, 1979.
\[4\] Harry tennant, Natural Language processing, Petrocelli books, New York, 1981.
\[5\] Hiroshl Uchida, Fujltru machine translation system: ATLAS, FGCS, Vol.2, No.2, p95-1~0,1986.
\[6\] Jaime G.
Carbonell and Masaru Tomita, New approaches to Machine Translation, TR-CMU-CS-85-143, Carnegie-Mellon University, 1985.
\[7\] Jonathan Slocum, A survey of machine translation: its hlstory,current status and future perspectives, CL, Vol.
11,No.
1, p1-17, 1985.
\[8\] Kazunori Muraki, VENUS: Two-phrase machine translation system, FGCS, Vol.2, p121-124, 1986.
\[9\] Martin Kay, The MIND system, Natural Language processing, edited by Rustin, Algorithmics press, New York, 1975, p155-189.
\[10\] Makota Nagao, Current Status and future trends in machine translation, FGCS, Vol.
2, No.
2, p77-82, 1986.
\[11\] M.Nogao, J.Tsujil and J.Nakamura, Science and Technology agency's machine translation proJect,FGCS, Vol.2, No.2, p125-14~, 1986.
\[12\] Murlel Vasconcellos and MarJorie Leon, SPANAM and ENGSPAN: machine translation at the PAN American health organization, CL,Vol.11,No.2-5, p122-156,1985.
\[15\] Paul L.Garvin(ed.), Natural Language and the Computer, McGraw-Hill book, New York, London, 1979.
\[14\] Perelra F.
and Warren D., Definite clause grammar for language onalvsls, Artlf~clol Intelllgence, Vol.15,p251-278,198~.
\[15\] Pierre Isabelle and Laurent Bourbeau, TAUMAVIATION:Its technlcal features and some experimental results, CL, Vol.11, No.
1, p18-27, 1985.
\[16\] Richard E.
CulZingford, Word-meaning selection in multiproces~language understanding, IEEE Trans.
on Pattern analysis and m~chlne intelligence, Vol, PAMI-.6, No.4., July 1984,p493-509.
\[17\] R.F.Simmons, Technologies for machine translation, FGCS, Vol.2, No.2, p85-94, 1986.
\[18\] Rod Johnson, Maghi Kinq, end Louis des Tombe, EUROTRA: A multilingual system under development, CL, V01.11, No.2-3, p155-169,1985.
\[19\] Roger Sehank, The condeptuel analysis of natural language, Natural Language processing, edited by Randall Rustln, Algorithmics Press, New York,1975, p291-511.
\[20\] Rozena Hennisz-Dostert, R.Ross Macdonald and Michael Zarechnak, Machine translotion, Mouton Publisher, Hugue, Paris, New York, 1979.
~. \[21\] S.Amano, The Toshiba machine translation system, FGCS, Vol.2, No.2, p121-124~11986.
\[22\] Terry Wlnograd, Language as a Cognltlve(Vol 1) process, Addison-Wesley Publishing Company, California,London, 1985.
\[25\] Vtnfield S.Bennett and Jonathan 61ocum, The LRC machine translation system, CL, Vo1.11, No.2-5, p1¢1-121, 1985.
\[24\] Y.
Wilks, The stanford machine translation project, Natural Language Processing, edited by Randall Rustin, Algorithmics Press, New York, 1973, p245-291.
\[25\] Yoshlhiko Nltta, Problems of machine translation systems-effect of cultural differences on sentence structure, FGCS, Vol.2, No.2, p117-120, 1986 .

