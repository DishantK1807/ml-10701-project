<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>M Becker</author>
<author>M Osborne</author>
</authors>
<title>A two-stage method for active learning of statistical grammars</title>
<date>2005</date>
<booktitle>In Proceedings of IJCAI</booktitle>
<contexts>
<context>anslation). Similar ideas can be exploited, involving a higher degree of expert intervention, as in corrected co-training (Hwa et al., 2003), self-training (McClosky et al., 2006) or active learning (Becker and Osborne, 2005). (C3) ML techniques. Finally, general discriminative ML techniques like Maximum Entropy models or Support Vector Machines can deal with redundant feature information from alternative sources, i.e. i</context>
</contexts>
<marker>Becker, Osborne, 2005</marker>
<rawString>M. Becker and M. Osborne. 2005. A two-stage method for active learning of statistical grammars. In Proceedings of IJCAI 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Blum</author>
<author>T Mitchell</author>
</authors>
<title>Combining Labeled and Unlabeled Data with Co-Training</title>
<date>1998</date>
<booktitle>In Proceedings of the 1998 Conference on Computational Learning Theory</booktitle>
<pages>92--100</pages>
<contexts>
<context>roblem are used to train initial independent learners on a small labelled seed set and iteratively augment their training set with unlabelled data which (some of) the learners label most confidently (Blum and Mitchell, 1998). Parallel data can be divided into such views very naturally, with one view for each language (as Callison-Burch and Osborne (2003) did in statistical machine translation). Similar ideas can be expl</context>
</contexts>
<marker>Blum, Mitchell, 1998</marker>
<rawString>A. Blum and T. Mitchell. 1998. Combining Labeled and Unlabeled Data with Co-Training. In Proceedings of the 1998 Conference on Computational Learning Theory, pages 92–100, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Bouma</author>
<author>J Kuhn</author>
<author>B Schrader</author>
<author>K Spreyer</author>
</authors>
<title>A Framework for multi-source annotation projection</title>
<date>2008</date>
<institution>Ms., University of Potsdam</institution>
<location>Germany</location>
<contexts>
<context>e-source models. In future work, we will apply more sophisticated feature selection methods, in combination with general modular (statistical) heuristics to deal with noisy data. In ongoing research (Bouma et al., 2008), we try to capture the interdependence of isolated argument status decisions explicitly in joint models and integrate our methodology with active learning proper to provide the linguistic researcher</context>
</contexts>
<marker>Bouma, Kuhn, Schrader, Spreyer, 2008</marker>
<rawString>G. Bouma, J. Kuhn, B. Schrader, and K. Spreyer. 2008. A Framework for multi-source annotation projection. Ms., University of Potsdam, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Butt</author>
<author>H Dyvik</author>
<author>T Holloway King</author>
<author>H Masuichi</author>
<author>C Rohrer</author>
</authors>
<title>The parallel grammar project</title>
<date>2002</date>
<booktitle>In Proceedings of COLING-2002 Workshop on Grammar Engineering and Evaluation</booktitle>
<pages>1--7</pages>
<contexts>
<context>h reported in this paper has been supported by the Deutsche Forschungsgemeinschaft (DFG, Sonderforschungsbereich 632, project D4). man, Japanese, as included in the grammars from the ParGram project (Butt et al., 2002)), which can be used as “hubs” in a multi-parallel corpus; (iii) machine learning techniques for combining various information sources; (iv) weakly supervised learning techniques for channeling human</context>
</contexts>
<marker>Butt, Dyvik, King, Masuichi, Rohrer, 2002</marker>
<rawString>M. Butt, H. Dyvik, T. Holloway King, H. Masuichi, and C. Rohrer. 2002. The parallel grammar project. In Proceedings of COLING-2002 Workshop on Grammar Engineering and Evaluation, pages 1–7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Callison-BurchandM Osborne</author>
</authors>
<title>Co-TrainingFor Statistical Machine Translation</title>
<date>2003</date>
<booktitle>In Proceedings of the 6th Annual CLUK Research Colloquium</booktitle>
<marker>Osborne, 2003</marker>
<rawString>C.Callison-BurchandM.Osborne. 2003. Co-TrainingFor Statistical Machine Translation. In Proceedings of the 6th Annual CLUK Research Colloquium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Cohn</author>
<author>M Lapata</author>
</authors>
<title>Machine Translation by Triangulation: Making Effective use of multi-parallel corpora</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the ACL</booktitle>
<pages>728--735</pages>
<location>Prague</location>
<contexts>
<context>ssed in various guises in quite different contexts (C1– C3). (C1) Triangulation. In classical work on machine translation as well in recent work on statistical machine translation (Och and Ney, 2001; Cohn and Lapata, 2007), the idea of “triangulation” (originally due to Martin Kay) is considered a helpful tool for disambiguating translational choices: if some unit in language A can be translated to language B in sever</context>
</contexts>
<marker>Cohn, Lapata, 2007</marker>
<rawString>T. Cohn and M. Lapata. 2007. Machine Translation by Triangulation: Making Effective use of multi-parallel corpora. In Proceedings of the 45th Annual Meeting of the ACL, pages 728–735, Prague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Daum´e</author>
</authors>
<title>Notes on CG and LM-BGFS optimizationoflogisticregression. Unpublishedmanuscript. Paper and software downloadable from www.cs</title>
<date>2004</date>
<pages>utah.edu/∼hal/megam/.</pages>
<marker>Daum´e, 2004</marker>
<rawString>H. Daum´e III. 2004. Notes on CG and LM-BGFS optimizationoflogisticregression. Unpublishedmanuscript. Paper and software downloadable from www.cs. utah.edu/∼hal/megam/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Hoekstra</author>
<author>M Moortgat</author>
<author>B Renmans</author>
<author>M Schouppe</author>
<author>I Schuurman</author>
<author>T van der Wouden</author>
</authors>
<title>Cgn syntactischeannotatie. http://ww2.tst.inl.nl/ images/stories/docs/syn prot.pdf</title>
<date>2003</date>
<marker>Hoekstra, Moortgat, Renmans, Schouppe, Schuurman, van der Wouden, 2003</marker>
<rawString>H. Hoekstra, M. Moortgat, B. Renmans, M. Schouppe, I. Schuurman, and T. van der Wouden. 2003. Cgn syntactischeannotatie. http://ww2.tst.inl.nl/ images/stories/docs/syn prot.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Hwa</author>
<author>M Osborne</author>
<author>A Sarkar</author>
<author>M Steedman</author>
</authors>
<title>Corrected co-training for statistical parsers</title>
<date>2003</date>
<booktitle>In Proceedings of the 20th International Conference on Machien learning</booktitle>
<location>Washington, D.C</location>
<contexts>
<context> language (as Callison-Burch and Osborne (2003) did in statistical machine translation). Similar ideas can be exploited, involving a higher degree of expert intervention, as in corrected co-training (Hwa et al., 2003), self-training (McClosky et al., 2006) or active learning (Becker and Osborne, 2005). (C3) ML techniques. Finally, general discriminative ML techniques like Maximum Entropy models or Support Vector </context>
<context>lpino-parsed sentences (cf. fn. 2) is used as seed data in two weakly supervised bootstrapping experiments (self-training and co-training). We also report on an experiment with corrected co-training (Hwa et al., 2003), an interactivebootstrappingmethodwhichcombinesco-training with ideas from active learning. In the self-training scenario, after training an initial classifier from the seed data, we iteratively add</context>
</contexts>
<marker>Hwa, Osborne, Sarkar, Steedman, 2003</marker>
<rawString>R. Hwa, M. Osborne, A. Sarkar, and M. Steedman. 2003. Corrected co-training for statistical parsers. In Proceedings of the 20th International Conference on Machien learning, Washington, D.C.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Hwa</author>
<author>P Resnik</author>
<author>A Weinberg</author>
<author>C Cabezas</author>
<author>O Kolak</author>
</authors>
<title>Bootstrapping Parsers via Syntactic Projection across Parallel Texts</title>
<date>2005</date>
<journal>Natural Language Engineering</journal>
<volume>11</volume>
<contexts>
<context>ied it to morphological analysis and NP bracketing. Their method of annotation projection has beenadoptedinawiderangeofannotations,includingpartof-speech tagging (Ozdowska, 2006), dependency parsing (Hwa et al., 2005) and role semantic analysis (Pad´o and Lapata (2006) for German, Pad´o and Pitel (2007) for French). However, these approaches differ from the one presented here in that we propose projection from tw</context>
</contexts>
<marker>Hwa, Resnik, Weinberg, Cabezas, Kolak, 2005</marker>
<rawString>R. Hwa, P. Resnik, A. Weinberg, C. Cabezas, and O. Kolak. 2005. Bootstrapping Parsers via Syntactic Projection across Parallel Texts. Natural Language Engineering, 11(3):311–325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Europarl: A Parallel Corpus for Statistical Machine Translation</title>
<date>2005</date>
<booktitle>In Proceedings of the MT</booktitle>
<location>Summit</location>
<contexts>
<context>Section 3.1.), either because alignment links are missing or because of true cross-language divergence. 4. Data and Resources Parallel corpus. For our experiments we use the parallel Europarl corpus (Koehn, 2005). It consists of translations of the proceedings of the European Parliament in 11 languages, each represented by approx. 1 million sentences (30 million words). The alignment on the word level was es</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>P. Koehn. 2005. Europarl: A Parallel Corpus for Statistical Machine Translation. In Proceedings of the MT Summit 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Malouf</author>
<author>G van Noord</author>
</authors>
<title>Wide coverage parsin with stochastic attribute value grammars</title>
<date>2004</date>
<booktitle>In IJCNLP-04 Workshop Beyond Shallow</booktitle>
<marker>Malouf, van Noord, 2004</marker>
<rawString>R. Malouf and G. van Noord. 2004. Wide coverage parsin with stochastic attribute value grammars. In IJCNLP-04 Workshop Beyond Shallow Analyses Formalisms and statistical modeling for deep analyses.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J T Maxwell</author>
<author>R M Kaplan</author>
</authors>
<title>A Method for Disjunctive Constraint Satisfaction</title>
<date>1991</date>
<booktitle>In Masaru Tomita, editor, Current Issues in Parsing Technology</booktitle>
<pages>173--190</pages>
<publisher>Kluwer Academic</publisher>
<location>Boston, MA</location>
<contexts>
<context>r for the target language. Parallel grammars. The grammars we use to parse the German and English portion of the corpus are LFG grammarsfromtheParGramproject(Buttetal.,2002),runinthe XLE environment (Maxwell and Kaplan, 1991). In addition, we use XLE’s built-in Prolog-based extraction engine to extract from the parses the features that we are interested in. We should note that we experience considerable data reduction du</context>
</contexts>
<marker>Maxwell, Kaplan, 1991</marker>
<rawString>J. T. Maxwell and R. M. Kaplan. 1991. A Method for Disjunctive Constraint Satisfaction. In Masaru Tomita, editor, Current Issues in Parsing Technology, pages 173– 190. Kluwer Academic, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak D McClosky</author>
<author>andM Johnson</author>
</authors>
<title>Reranking and self-training for parser adaptation</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the ACL</booktitle>
<pages>337--344</pages>
<marker>McClosky, Johnson, 2006</marker>
<rawString>D.McClosky,E.Charniak,andM.Johnson. 2006. Reranking and self-training for parser adaptation. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the ACL, pages 337–344.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J OchandH Ney</author>
</authors>
<title>StatisticalMulti-SourceTranslation</title>
<date>2001</date>
<booktitle>In MT Summit</booktitle>
<pages>253--258</pages>
<location>Santiago de Compostela, Spain</location>
<contexts>
<context> been discussed in various guises in quite different contexts (C1– C3). (C1) Triangulation. In classical work on machine translation as well in recent work on statistical machine translation (Och and Ney, 2001; Cohn and Lapata, 2007), the idea of “triangulation” (originally due to Martin Kay) is considered a helpful tool for disambiguating translational choices: if some unit in language A can be translated</context>
</contexts>
<marker>Ney, 2001</marker>
<rawString>F.J.OchandH.Ney. 2001. StatisticalMulti-SourceTranslation. In MT Summit 2001, pages 253–258, Santiago de Compostela, Spain, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>A Systematic Comparison of Various Statistical Alignment Models</title>
<date>2003</date>
<journal>Computational Linguistics</journal>
<volume>29</volume>
<contexts>
<context>ations of the proceedings of the European Parliament in 11 languages, each represented by approx. 1 million sentences (30 million words). The alignment on the word level was established using GIZA++ (Och and Ney, 2003), followed by lemmatization and POS tagging for the languages Dutch, German and English with the IMS TreeTagger (Schmid, 1994). We used the word alignment and a list of English main verbs extracted f</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>F. J. Och and H. Ney. 2003. A Systematic Comparison of Various Statistical Alignment Models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Ozdowska</author>
</authors>
<title>Projecting POS tags and syntactic dependencies from English and French to Polish in aligned corpora</title>
<date>2006</date>
<booktitle>In Proceedings of the EACL 2006 Workshop on Cross-Language Knowledge Induction</booktitle>
<pages>53--60</pages>
<location>Trento, Italy</location>
<contexts>
<context>d by Yarowsky et al. (2001), who applied it to morphological analysis and NP bracketing. Their method of annotation projection has beenadoptedinawiderangeofannotations,includingpartof-speech tagging (Ozdowska, 2006), dependency parsing (Hwa et al., 2005) and role semantic analysis (Pad´o and Lapata (2006) for German, Pad´o and Pitel (2007) for French). However, these approaches differ from the one presented her</context>
</contexts>
<marker>Ozdowska, 2006</marker>
<rawString>S. Ozdowska. 2006. Projecting POS tags and syntactic dependencies from English and French to Polish in aligned corpora. In Proceedings of the EACL 2006 Workshop on Cross-Language Knowledge Induction, pages 53–60, Trento, Italy, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pad´o</author>
<author>M Lapata</author>
</authors>
<title>Optimal constituent alignment with edge covers for semantic projection</title>
<date>2006</date>
<booktitle>In Proceedings of COLING/ACL 2006</booktitle>
<location>Sydney, Australia</location>
<marker>Pad´o, Lapata, 2006</marker>
<rawString>S. Pad´o and M. Lapata. 2006. Optimal constituent alignment with edge covers for semantic projection. In Proceedings of COLING/ACL 2006, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pad´o</author>
<author>G Pitel</author>
</authors>
<title>Annotation pr´ecise du franc¸ais en s´emantique de rˆoles par projection cross-linguistique</title>
<date>2007</date>
<booktitle>In Proceedings of TALN-07</booktitle>
<location>Toulouse, France</location>
<marker>Pad´o, Pitel, 2007</marker>
<rawString>S. Pad´o and G. Pitel. 2007. Annotation pr´ecise du franc¸ais en s´emantique de rˆoles par projection cross-linguistique. In Proceedings of TALN-07, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees</title>
<date>1994</date>
<booktitle>In International Conference on New Methods in Language Processing</booktitle>
<pages>44--49</pages>
<location>Manchester, England</location>
<contexts>
<context>ords). The alignment on the word level was established using GIZA++ (Och and Ney, 2003), followed by lemmatization and POS tagging for the languages Dutch, German and English with the IMS TreeTagger (Schmid, 1994). We used the word alignment and a list of English main verbs extracted from the POS-tagged Europarl corpus to determine potential verbal heads in the target language. We thus reduce our reliance on </context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>H. Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. In International Conference on New Methods in Language Processing, pages 44–49, Manchester, England.</rawString>
</citation>
</citationList>
</algorithm>

