Proceedings of the ACL Student Research Workshop, pages 31–36, Ann Arbor, Michigan, June 2005.
c©2005 Association for Computational Linguistics Automatic Discovery of Intentions in Text and its Application to Question Answering Marta Tatu Human Language Technology Research Institute Department of Computer Science University of Texas at Dallas Richardson, TX 75080, USA marta@hlt.utdallas.edu Abstract Semantic relations between text concepts denote the core elements of lexical semantics.
This paper presents a model for the automatic detection of INTENTION semantic relation.
Our approach first identifies the syntactic patterns that encode intentions, then we select syntactic and semantic features for a SVM learning classifier.
In conclusion, we discuss the application of INTENTION relations to Q&A.
1 Introduction
1.1 Problem description Intentions comprise of semantic relationships that express a human’s goal-oriented private states of mind, including intents, objectives, aims, and purposes.
As a relation, it encodes information that might not be explicitly stated in text and its detection might require inferences and human judgment.
The answer to the question What was Putin trying to achieve by increasing military cooperation with North Korea? is found in the sentence Putin is attempting to restore Russia’s influence in the East Asian region.
Extracting the exact answer to restore Russia’s influence in the East Asian region becomes easier if this is recognized as Putin’s intention which matches the question’s expected answer.
In this paper, we describe a method that identifies intentions in domain independent texts.
We employed two machine learning algorithms to create models that locate intentions in a given paragraph using a set of six syntactic and semantic features.
1.2 Motivation
The current state-of-the-art NLP systems cannot extract intentions from open text and, as we saw in the example, their detection benefits Question Answering.
An intention is the answer to general questions like What is the goal of X?, What does X plan to do?, or What does X aim for?
The INTENTION semantic relation is one of the most challenging relations because text fragments may convey unstated intentions.
These are most pervasive in dialogues, communication specific to humans.
For example, in the following conversation, the vendor infers the client’s unstated intention of buying the cups.
Customer: Where do you have the $1 cups?
Salesman: How many do you want?
Intentions are closely related to other semantic relations such as beliefs, motives, desires, or plans.
In the above example, the context tells us that this takes place in a superstore, well-known as a place where people buy things from.
The clerk’s answer emerges from our common beliefs and background knowledge as well as from his desire to help a customer.
Intentions are the framework for plans.
Many philosophers and artificial intelligence researchers studied the intentions as parts of coordinating plans (Bratman, 1987; Pollack, 1990) because people establish plans for future times.
In this paper, we regard intentions as expressions of a particular action that shall take place in the future, in which the speaker is some sort of agent (Anscombe, 1957).
For example, the sentence Mary is going to buy a TV set shows Mary’s intention.
Anscombe (1957) considers intentions as a subclass of predictions, besides commands and 31 prophecies.
John is going to be sick is usually a prophecy, John, go for a walk! is an order, and John plans to take a walk expresses an intention.
1.3 Previous
work Various methodologies have been proposed and used over the years for the task of extracting semantic relations from text.
Purely probabilistic models, empirical methods, or hand-coded constraints were some of the approaches that do not use machine learning algorithms.
Later on, methods that use decision tree, neural networks, memory-based learning, or support vector machines were introduced.
Currently, there is also a increased interest in shallow semantic parsing of open texts and automatic labeling of semantic roles.
Wiebe et al.(2004) focused on the detection of subjective language such as opinions, evaluations, or emotions in text.
Using clues of subjectivity (low-frequency words, collocations), they identify opinion piece texts such as editorials, letters to the editor, or arts and leisure reviews.
There exists an immense literature in philosophy about the different types of intentions and their characteristics.
Bratman (1987) tries to find the relationship between the two distinct phenomena of doing something intentionally and intending to do something.
Numerous philosophical studies discuss how intentions relate to other psychological concepts, such as, beliefs, desires, hopes, or expectations (Audi, 1973; Bratman, 1981; Bratman, 1987).
Intentions are consistent with the person’s beliefs, and, unlike ordinary desires, require consistency (Bratman, 1987).
They can generate reasons for or against future intentions (Bratman, 1981; Bratman, 1987).
As plan elements, intentions require a certain stability.
Their side effects need not be intended, even if they were taken into consideration in the first place1 (Bratman, 1990).
2 Syntax
and Semantics of Intention 2.1 Syntactic patterns Because, in all the cases that we encountered, intentions were conveyed by phrases, we took a closer look at how intentions can be expressed in the written text.
For our investigations, we chose the Sem1Due to space limitations, we couldn’t include detailed examples.
Please see the cited articles for examples.
Cor text collection (Miller et al., 1993), a subset of the Brown corpus manually tagged with WordNet senses (37,176 sentences in 352 newspaper articles).
After manually classifying the first 2,700 sentences from SemCor into sentences that contain or not intentions, only 46 examples were identified.
The syntactic patterns listed in Table 1 cover 95.65% of them.
Because the first pattern comprises more than half of the studied examples, our algorithm focuses on detecting intentions encoded by a0a2a1a4a3 to a0a5a1a7a6. We note that this pattern is ambiguous and may convey other semantics.
For instance, Mary began to play with the dog, He told her to meet you are encoded by our pattern, but do not express intentions.
Pattern Example Frequency a8a10a9a10a11 to a8a12a9a14a13 plan to go for a walk 27 (58.69) NN to VB strivings to give up drink 6 (13.04) VB PP VP He resigned so that he can work 5 (10.87) for the school campaign goal/purpose is to VB his goal is to leave the country 4 (8.69) ADJ to VB eager to end a pitching slump 2 (4.34) Table 1: INTENTION syntactic patterns 2.2 Semantics of intentions From the semantic point of view, an intention may be very specific, it may contain a future time or a location (John intends to meet Mary today), but every intention must specify a future action.
Hence, we propose the following representation for the INTENTION semantic relation: INT(a15 a3a17a16a19a18a20a3a21a16 a15 a6 ) where a15 a3 is the event denoting the intention, a18 a3 denotes the person that has the intention and a15 a6 is the intended action or event.
If the intention is more specific then we will identify instances of other semantic relations2.
a22a24a23a26a25a14a27a29a28 a18a20a3a31a30a33a32 INTa28a34a15 a3a35a16a19a18a20a3a21a16 a15 a6a17a30a33a32a37a36 a15a17a15a21a38a39a28a34a15 a6a35a30 a32a41a40a43a42a45a44a47a46 a28 a18 a6 a30a48a32 a38a49a23a47a50 a42a51a46 a28 a18a53a52a17a30a48a32 THEME a28a34a15 a6 a16a19a18 a6 a30a54a32 TIMEa28a34a15 a6 a16a19a18a53a52a17a30 represents a more specific intention.
The semantics of the INTENTION relation allows the derivation of inference rules which show that INTENTION dominates other semantic relations such as PURPOSE, ENTAIL, or ISA.
For example, if a person a18a24a3 intends to perform action a15 a6 and this action has a purpose a15 a52, then we can say that a18 a3 intends to do a15 a52 3.
Formally, we can express the above relations 2The list of semantic relations that can specialize an INT includes THEME, LOCATION, TEMPORAL, MANNER, INSTRUMENT, SOURCE, MEANS, and FREQUENCY.
Their arguments are a55a57a56, the intention verb, and a corresponding a58a60a59 . 3Similar statements can be made for the ENTAIL and ISA 32 with the following set of implications4: INTa0 a55a2a1a4a3a34a58a5a1a6a3a34a55 a56a8a7a10a9 PURPOSEa0 a55a57a56a11a3 a55a13a12a14a7a16a15 INTa0 a55a13a17a18a3a34a58a5a1a6a3a34a55a11a12a6a7 INTa0 a55 a1 a3a34a58 a1 a3a34a55 a56 a7a10a9 ENTAILa0 a55 a56 a3 a55 a12 a7a19a15 INTa0 a55 a17 a3a34a58 a1 a3 a55 a12 a7 INTa0 a55 a1 a3a34a58 a1 a3a34a55 a56 a7a10a9 IS-Aa0 a55 a56 a3 a55 a12 a7a19a15 INTa0 a55 a17 a3 a58 a1 a3 a55 a12 a7 INTa0 a55a2a1a4a3a34a58a5a1a6a3a34a55 a56a8a7a10a9 PURPOSEa0 a55a13a12a20a3 a55a57a56a6a7a22a21a15 INTa0 a55a13a17a18a3a34a58a5a1a6a3a34a55a11a12a6a7 INTa0 a55 a1 a3a34a58 a1 a3a34a55 a56 a7a10a9 CAUSEa0 a55 a56 a3 a55 a12 a7a22a21a15 INTa0 a55 a17 a3 a58 a1 a3 a55 a12 a7 The first three implications formalize the above inference rules.
If John intends to start his car to go to the park, then John intends to go to the park.
Similarly, if John intends to buy a car, then we can say that he intends to pay for it.
The sentences John intends to go to the park.
He’s starting his car right now express John’s intention to go to the park (a15 a6 ).
The purpose of starting the car (a15 a52 ) is to go to the park.
We cannot say that John intends to start his car.
This is just an intentional action done to achieve his objective.
The fifth rule tries to eliminate the effects (a15 a52 ) of an intention (a15 a6 ) from being considered as intentions or objectives.
If John intends to swim in the pool (a15 a6 ) even if he knows that he is going to catch a cold (a15 a52 ) because the water is too cold, we cannot say that John intends to catch a cold.5 The traditional relational properties (reflexivity, symmetry, or transitivity) do not hold for the INTENTION semantic relation.
3 Learning
Model 3.1 Experimental data We applied the most frequent syntactic pattern that expresses intentions in text (a0a5a1 a3 to a0a5a1 a6 ) on the first 10,000 sentences of the SemCor2.0 collection and we extracted 1,873 sentences.
These sentences contain 115 intentions (manually identified by a graduate student, not the author).
The data consisting of these positives and 258 arbitrarily selected negative examples, was randomly divided into a training set that contains 80% of the examples and a test set with the remaining 20% instances.
The statistics are shown in Table 2.
Intentions Non-Intentions Total Training 92 208 300 Testing 23 50 73 Table 2: Experiments Data Division semantic relations.
4 a55a23a1 and a55a13a17 represent different intentions of the same person.
5A more detailed example can be found in (Bratman, 1990).
3.2 Features
for intention After analyzing our training data, we pinpointed a set of features to help us identify the intentions encoded by the pattern a0 a1 a3 to a0a5a1 a6 . The WordNet senses needed to extract the semantic features were taken from SemCor.
We will use Mary intends to revise the paper to show each feature’s value.
The semantic class of the the a0a5a1 a3 verb’s agent or specializations of it.
Intentions and objectives are specific to humans.
Thus, the semantic class of the a0a5a1 a3 agent bears a high importance.
We used an in-house semantic parser to retrieve the AGENT of the a0 a1 a3 verb.
The feature’s value is its WordNet semantic class.
Mary names a person.
Thus, the semantic class that we are seeking is entity#1.
We chose this semantic generalization because nouns and verbs belong to open part-of-speech classes.
There can be an enormous number of possibilities and any models built using them as feature values will not be able to generalize beyond the training examples.
Therefore, we introduce a bias in our learning framework based on the assumption: noun and verb concepts will semantically behave as the concepts that subsume them in the WordNet structures.
But, by generalizing concepts, we lose some of their semantic properties.
Hence, we specialize the semantic class a24 of a concept a25 by replacing it with its immediate hyponym (a25 ) that subsumes a25 . We can further increase the semantic level by specializing a25 . We note that the number of values is still finite even though we specialized the general concepts.
As the specialization level increases, there will be words a25 that cannot be further specialized (entity#1 cannot be specialized even once).
In such cases, we add a25 to the set of feature values.
The semantic class of the a0a5a1 a3 verb or its specializations.
The intention phrase is subordinated to a verb (a0a5a1 a3 ).
The semantic class of this verb is the system’s second feature.
In our example, a0 a1 a3 (intend#1) semantic class is wish#3.
The semantic class of the a0a2a1a2a6 verb’s agent, if this agent differs from the a0a5a1 a3 verb’s agent; otherwise, a common value (equal) is given.
We identify the AGENT of the a0a5a1 a6 verb.
The specializations of its semantic class will be used if the top noun proves to be too general.
In the sample sentence, the agent of revise is Mary.
We can have a different agent for 33 Semantic Semantic class of the a8a53a9 a11 verb (%) class of no specialization a0a2a1 a3 level of specialization a4a2a5 a6 level of specialization the a8a10a9 a11 ’s Semantic class of the a8a53a9 a13 verb Semantic class of the a8a12a9 a13 verb Semantic class of the a8a12a9 a13 verb agent no spec.
a0a7a1 a3 level a4a7a5 a6 level no spec.
a0a7a1 a3 level a4a7a5 a6 level no spec.
a0a7a1 a3 level a4a2a5 a6 level no spec.
87.67 80.82 87.67 90.41 87.67 87.67 86.30 83.56 84.93 a0a7a1 a3 level 89.04 82.19 87.67 87.67 89.04 87.67 87.67 86.30 84.93 a4a7a5 a6 level 87.67 83.56 87.67 90.41 90.41 89.04 89.04 87.67 86.30 Table 3: Accuracy of models using the a8a10a9a12a11 specialization level for the a0a2a1 a6 agent semantic class the a0a2a1a7a6 verb (Mary intends John to revise the paper).
Let’s assume that Mary is John’s supervisor and she can make him revise the document.
The sentence expresses Mary’s intention of persuading John to revise the paper, but this objective is not encoded by the pattern we considered.
The semantic class of the a0a5a1 a6 verb or its specializations.
The a0a5a1 a6 verb expresses the future action or behavior that the agent intends.
We extract this feature using WordNet hierarchies.
Revise#1 belongs to the act#1 semantic class.
A flag indicating if the a0 a1 a3 verb has an affirmative or a negative form.
We want to differentiate between sentences like John wants to go for a walk and John doesn’t want to go for a walk.
The first sentence expresses John’s intention, while, in the second one, no intention can be identified.
The type of the analyzed sentence.
This feature is primarily concerned with questions.
A question like Where do you plan to go for a walk? indicates the intention of going for a walk, unlike the question Do you plan to go for a walk? which might express an intention if the answer is “yes”.
This feature’s values are the wh-words that begin a question or n/a for the other types of English sentences.
We did not analyze the affirmative versus the negative form of the a0a2a1 a6 verb because it does not affect the objective attribute of the intention.
The sentence John intends not to go for a walk expresses a negative intention.
This sentence is much stronger than John doesn’t intend to go for a walk.
In the former context, John has set a goal for himself, while in the second sentence, the objective does not exist.
4 Experimental
Results 4.1 Impact of specialization The first experiment was performed using the LIBSVM package6 and the WordNet semantic classes.
6http://www.csie.ntu.edu.tw/˜cjlin/libsvm/index.html These features yield an accuracy of 87.67%.
Trying to improve the performance, we specialized the semantic classes.
When the a0 a1 a6 ’s agent semantic class was specialized, the accuracy remained constant.
If we replace the a0a2a1 a6 ’s semantic class with its direct hyponyms, the accuracy drops 5.48%.
But, the specialization of the a0a5a1 a3 agent’s semantic class brings an improvement of 1.37% and the specialization of the a0a2a1 a3 ’s class produces an increase in accuracy of 2.74%.
Given this fluctuation in performance, we performed 81 different experiments which create SVM models using the same training data annotated with more general or more specific feature values.
For each feature, we analyzed the first two semantic specialization levels.
From our experiments, we noticed that the specialization of the a0 a1a33a6 ’s agent semantic class does not influence the performance.
Out of the 27 experiment triplets in which this specialization level changes, in only 4, it influences the result and, in 3 of them, the accuracy increases with the specialization level.
Thus, our third feature is the second specialization level of the a0a5a1 a6 ’s agent class.
Table 3 shows the results obtained when the values of the radial kernel parameters were chosen to optimize the 5-fold-cross-validation on the training data.
The best models are described in Table 4.
Model Level of specialization for the features A semantic class of the a8a53a9 a11 agent, a0a13a1 a3 level of specialization for the a8a10a9 a11 ’s semantic class, and semantic class of the a8a10a9 a13 verb B a4a2a5 a6 semantic level for the a8a53a9a53a11 agent class, a0a7a1 a3 level of the a8a53a9 a11 ’s semantic class, and the semantic class of the a8a10a9 a13 verb C a4a2a5 a6 level of the a8a12a9 a11 agent’s semantic class and a0a7a1 a3 specialization levels for the a8a12a9a53a11 and a8a10a9a14a13 semantic classes Table 4: The best three intention classifiers 4.2 Learning curves We further analyzed our data and models and tried to see how many training examples are needed to reach 90.41% accuracy.
We varied the training data 34 Semantic class of the Semantic class of the Semantic class of the Semantic class of the a8a53a9 a11 verb Sentence a8a10a9 a11 ’s agent a8a10a9 a11 verb a8a10a9 a13 ’s agent a8a10a9 a13 verb form type Model A 2.74 16.44 1.37 0 2.74 4.11 Model B 2.74 15.07 1.37 0 4.11 2.74 Model C 1.37 16.44 4.11 0 4.11 2.74 Table 5: The improvement (%) brought by each feature to the three best SVM models size and validated the new models using our previous test set.
Figure 1 shows the performance variation of three models that use feature sets identical in terms of specialization levels to the ones of the A, B, and C classifiers.
All three models exhibit a similar behavior with respect to the change in the training set size.
Therefore, our features create a stable algorithm.
The highest accuracy models use all 300 training examples.
Thus, we did not reach the saturation point, but, considering the performance curve, this point is not very far.
30 40 50 60 70 80 90 100 50 100 150 200 250 300 SVM model accuracy Number of training examples Model A Model B Model C Figure 1: Testing set is constant 4.3 Feature impact on the SVM models All our previous experiments used the entire set of features.
Now, we investigate the relative contribution of each feature.
We performed experiments that use only five out of the six features.
In Table 5, we list the accuracy increase that is gained by the inclusion of each feature.
The most influential attribute is the a0a5a1 a3 verb’s semantic class or its specializations.
The intention’s description verb does not influence the classification result.
Because intentions consist of a future action and verbs express actions, there are very few verbs, such as dream or snore (involuntary actions) that cannot occupy the a0a2a1 a6 verb’s position.
The syntactic features bring an average increase in accuracy of 3.50%. 4.4 Impact of word sense disambiguation Perfect word sense disambiguation might be a too strong assumption.
In this section, we examine the effects of weaker disambiguation.
Table 6 shows the accuracies of the best three models when each concept is tagged with its first WordNet sense (No WSD) and when the senses are given by an in-house WSD system with an accuracy of 69% computed on the SemCor data (Automatic WSD).
No WSD Automatic WSD Gold WSD Model A 72.60 79.45 90.41 Model B 73.97 79.45 90.41 Model C 72.60 80.82 90.41 Table 6: Best models performance (%) 4.5 C5 results After examining the SVM results, we applied the C5 machine learning algorithm (Quinlan, 2004) to the same training data annotated with the same feature set, in a similar manner.
Again, we specialized the four semantic classes, independently, and tested the decision trees against the testing data.
Table 7 shows their accuracy.
The highest values were obtained for the first level of specialization of the a0a2a1 a3 verb semantic class.
The specialization levels of the other semantic classes do not influence the accuracy of the decision trees.
The most tested attribute is the a0a5a1 a3 verb.
This further substantiates our observation, made during our SVM models analysis, that this feature has the greatest importance in the intention classification process.
Our error analysis of the C5 results indicates that, because of the relatively small numbers of training instances, C5 ignores some of the features and makes wrong decisions.
5 Application
to Question Answering Questions involving intentions cannot be answered only by keyword-based or simple surface-level matching techniques.
Table 8 lists two questions for 35 a0 a11 : What was Putin trying to achieve by increasing military cooperation with North Korea? a0a2a1a4a3 a11 : Putin a5a7a6 a11a9a8 & INT a5a11a10a13a12a15a14a16a6 a11 a14a16a17 a8 & ANS a5a7a17 a8 & MANNER a5a7a17a18a14a19a10 a13a20a8 & increase a5a11a10 a13 a14a16a6 a11 a14a21a6 a13a20a8 & military a5a7a6 a13a19a8 & cooperation a5a11a6 a13a20a8 & with a5a7a6 a13 a14a16a6a23a22 a8 & North Koreaa5a11a6 a22 a8 a24 a11 : Putin is attempting [to restore Russia’s influence in the East Asian region][ INT].
The report said, the possibility remains that Russia could increase military cooperation with North Korea based on their treaty.
a24 a1a4a3 a11 : Putin a5a7a6 a11a9a8 & INT a5a11a10a13a12a15a14a16a6 a11 a14a21a10 a11a25a8 & restore a5a11a10 a11 a14a21a6 a11 a14a16a6 a13a20a8 & Russia a5a7a6a26a22 a8 & ’s a5a7a6a26a22a27a14a16a6 a13a25a8 & influence a5a7a6 a13a25a8 & LOCATION a5a7a6 a13 a14a21a6a29a28 a8 & East a5a7a6a23a28 a8 & Asiana5a7a6a23a28 a8 & regiona5a7a6a23a28 a8 & reporta5a7a6a26a30 a8 & saya5a11a10 a13 a14a16a6a26a30a31a14a32a10a13a22 a8 & possibilitya5a7a6a26a33 a8 & remainsa5a11a10a13a22a29a14a16a6a26a33a31a14a21a10a32a28 a8 & increasea5a11a10a13a28a34a14a16a6a26a22a31a14a21a6a26a35 a8 & militarya5a7a6 a35 a8 & cooperationa5a7a6 a35 a8 & witha5a7a6 a35 a14a16a6a23a36 a8 & North Koreaa5a7a6a26a36 a8 & basea5a11a10 a28 a14a16a6a26a37 a8 & treatya5a11a6a23a37 a8 a0 a13 : From where does al Qaeda intend [to purchase weapons of mass destruction][INT]? a0a2a1a4a3 a13 : alQaeda a5a7a6 a11a32a8 & INT a5a38a10a13a12a39a14a16a6 a11 a14a21a10 a11a9a8 & ANS a5a11a17 a8 & LOCATION a5a38a10 a11 a14a16a17 a8 & purchase a5a11a10 a11 a14a16a6 a11 a14a16a6 a13a25a8 & weapons of mass destruction a5a7a6 a13a19a8 a24 a13 : It is known that Osama bin Laden’s al Qaeda network has tried [to buy ingredients for weapons of mass destruction in Russia][ INT].
a24 a1a4a3 a13 : Osama bin Laden a5a7a6 a11a13a8 & ’s a5a7a6 a11 a14a21a6 a13a20a8 & al Qaeda a5a7a6 a13a9a8 & network a5a7a6a26a22 a8 & IS-A a5a11a6 a13 a14a16a6a23a22 a8 & INT a5a11a10a13a12a26a14a16a6 a13 a14a32a10 a11a13a8 & buy a5a11a10 a11 a14a16a6a23a22a34a14a16a6a23a28 a8 & ingredienta5a11a6 a28 a8 & PURPOSEa5a7a6 a28 a14a16a6 a30 a8 & weapons of mass destructiona5a11a6 a30 a8 & LOCATIONa5a11a10 a11 a14a21a6 a33 a8 & Russiaa5a7a6 a33 a8 Table 8: Question and answer pair examples Semantic class of Semantic class of the a40a42a41 a1 verb the a40a42a41 a1 ’s agent no spec.
a43a31a44a21a45 level a46a29a47a23a48 level no spec.
79.45 87.67 84.93 a43a27a44a32a45 level 68.49 87.67 84.93 a46 a47a23a48 level 79.45 87.67 84.93 Table 7: C5 models accuracy (%) which finding the correct answer primarily depends on the discovery of the INTENTION relation.
The answer type for the question a49 a3 is the INTENTION argument itself.
The question processing module will detect that the answer being sought is Putin’s intention.
The semantic relations module processes a50 a3 ’s text and discovers the INTENTION relation.
The question is searching for the intent of Putin with regards to North Korea and the answer text reveals Putin’s intention to restore Russia’s influence in the area.
Question a49 a6 is searching for a location as its answer type and the correct answer is one which involves al Qaeda intending to purchase weapons of mass destruction.
The candidate answer text (a50 a6 ) reveals the organization’s past intent to buy (synonym with purchase) weapons in Russia.
Because the two intentions have the same agent, future action and theme, the two semantically enhanced logic forms can now be unified and we can pin down the location of the intent (Russia).
6 Conclusions
We proposed a method to detect the INTENT relation encoded by the sentence-level pattern a0a5a1 a3 to a0a5a1 a6 with a 90.41% accuracy.
We plan to investigate the other INTENTION patterns as well as other semantic relations such as MOTIVE, IMPLICATION, or MEANING which, currently, cannot be identified by the state-of-the-art NLP systems.
These relationships need to be analyzed to provide a complete coverage of the underlying semantics of text documents.
We intend to incorporate our INTENTION detection module into a Question Answering system and show its impact.
References Anscombe, G.E.M. 1957.
Intention. Cornell University Press, Ithaca, New York.
Audi, Robert.
1973. Intending.
The Journal of Philosophy, 70(13):387–403.
Bratman, Michael E.
1981. Intention and means-end reasoning.
The Philosophical Review, 90(2):252–265.
Bratman, Michael E.
1987. Intention, Plans, and Practical Reason.
Harvard University Press, Cambridge, Massachusetts.
Bratman, Michael E.
1990. What is intention?
In Intentions in Communication.
MIT Press.
Miller, George A., Claudia Leacock, Randee Tengi, and Ross T.
Bunker. 1993.
A semantic concordance.
In Proceedings of the ARPA Human Language Technology Workshop Miller, George A.
1995. Wordnet: A lexical database.
Communication of the ACM, 38(11):39–41.
Pollack, Martha E.
1990. Plans as complex mental attitudes.
In Intentions in Communication.
MIT Press.
Quinlan, Ross.
2004. Data Mining Tools See5 and C5.0. http://www.rulequest.com/see5-info.html Wiebe, Janyce M., Theresa Wilson, Rebecca F.
Bruce, Matthew Bell, and Melanie Martin.
2004. Learning subjective language.
Computational Linguistics, 30(3):277–308. 36

