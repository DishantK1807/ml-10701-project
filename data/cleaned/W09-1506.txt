Proceedings of the NAACL HLT Workshop on Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 40–41,
Boulder, Colorado, June 2009. c 2009 Association for Computational Linguistics
Scaling up a NLU system from text to dialogue understanding 
 
R. Delmonte, A. Bristot, G. Voltolina 
Department of Language Science 
Università Ca’ Foscari 30123 
VENEZIA 
delmont@unive.it 
 
Vincenzo Pallotta 
Webster University, Geneva 
Switzerland 
palota@webster.ch 
Abstract 
In this paper we wil present work caried out 
to scale up the system for text understanding 
caled GETARUNS, and port it to be used in 
dialogue understanding. We wil present the 
adjustments we made in order to cope with 
transcribed spoken dialogues like those 
produced in the ICSI Berkely project. In a 
final section we present preliminary 
evaluation of the system on non-referential 
pronominals individuation. 
1 Introduction

Very much like other dep linguistic procesing 
systes (se Alen et al.), our system is a generic 
text/dialogue understanding syste that can be 
used in conection with an ontolgy – WordNet 
and/or a repository of comonsense knowledge 
like CONCEPTNET. Word sense disambiguation 
takes place at the level of semantic interpretation 
and is represented in the Discourse Model. 
Computing semantic representations for spoken 
dialogues is a particularly hard task which – when 
compared to writen text procesing requires the 
folowing aditional information to be made 
available: 
adequate treatment of fragments; 
adequate treatent of short turns, in particular 
one-word turns; 
adequate treatment of first person singular and 
plural pronominal expresions; 
adequate treatment of disfluencies, thus including 
cases of turns ade up of just such expresions, or 
cases when they are found inside the uterance; 
adequate treatment of overlaps; 
adequate treatent of speaker identity for 
pronominal coreference; 
In our system, then, every dialogue turn receives 
one polarity label, indicating negativity or 
positivity, and this is computed by loking into a 
dictionary of polarity ites. This is subsequently 
used to decide on argumentative automatic 
clasification. 
The Berkely ICSI dialogues are characterized by 
the ned to argument in a exhaustive maner the 
topics to be debated which are the thee of each 
multiparty dialogue. The mean length of 
uterances/turns in each dialogue we parsed was 
rather long. 
2 The
System GETARUNS 
GETARUNS
1, the system for text understanding 
developed at the University of Venice, is organized 
as a pieline which includes two versions of the 
system: what e cal the Partial and the Dep 
GETARUNS (Delmonte 207;209). The ep 
version is equiped with thre main modules: a 
lower module for parsing, where sentence 
strategies are implemented; a midle module for 
semantic interpretation and discourse model 
construction which is cast into Situation Seantics; 
and a higher module where reasonig and 
generation takes place. 
2.1 The
Algorithm for Overlaps 
Overlaps are an important component of al spoken 
dialogue analysis. In al dialogue transcription, 
overlaps are treated as a separate turn from the one 
in which they ocur, which usualy folows it. On 
the contrary, when computing overlaps e set as 
our first goal that of recovering the temporal order. 
This is done because overlaps ay introduce 
linguistic elments which influence the local 
context. Eventualy, they may detrmine the 
interpretation of the curent uterance. 
                                                 
1
 The system has been tested in STEP competition, and can be 
downloaded at, htp:/project.cgm.unive.it/html/sharedtask/. 
40
For these reasons, they canot be moved to a 
separate turn because they must be seanticaly 
interpretd where they temporaly belong. 
The algorithm we built loks at time stamps, and 
everytime the folowing turn begins at a time 
preceding the nding time of curent turn it enters a 
special recursive procedure. It loks for internal 
interuption in the curent turn and splits the 
uterance where the interuption ocurs. Then it 
parses it split initial portion of curent uterance 
and continues with the overlaping turn. This may 
be reiterated in case another overlap folows which 
again begins before the end of curent uterance. 
Eventualy, it returns to the analysis of the curent 
turn with the remainig portion of curent 
uterance. 
2. The Treatment of Fragments and Short 
Turns 
Fragments and short turns are filtered by a lexical 
lokup procedure that searches for specific 
linguistic elments which are part of a list of 
backchanels, acknoledgements expresions and 
other similar spech acts. In case this procedure has 
suces, no further computation takes place. 
However, this only aplies to uterances shorter 
than 5 words, and should be made up only of such 
special ords. No other linguistic elment should 
be present apart from non-words, that is words 
which are only partialy produced and have ben 
transcribed with a dash at the end. Otherwise we 
proced as folows: 
graceful failure procedures for ungramatical 
sentences, which might be fulfledged uterances 
but semanticaly uniterpretable due to the 
presence of repetitions, false starts and similar 
disfluency phenomena. Or else they may be just 
fragments, i.e. partial or incomplet uterances, 
hence non-interpretable as such; this is done by 
imposing gramatical constraints of 
welformednes in the parser. 
We ipleented a principled treatment of eliptical 
uterances and contribute one specific spech act. 
They may expres agrement/ disagrement, 
acknowledgements, asesents, continuers etc. 
Al these items are computed as being 
complements of abstract verb SAY which is 
introduced in the analysis, and has as subject, the 
name of curent speaker. 
3 The
Experiment 
We set up an experiment in order to test the new 
version of the syste, that is detcting referential 
from nonreferential uses of personal pronouns 
“you”, “we” and “it”. 
In order to take decisions as to whether pronouns 
are to be interpretd as referential or not a 
recursive procedure checks the type of governig 
predicate. Referential pronouns are then pased on 
to the pronominal binding algorithm that loks for 
local antecedents if any. Otherwise, the pronouns 
is labeld as having External coreference in the 
previous discourse stretch. The Anaphora 
Resolution module wil then take care of the 
antecedent and a suitable semantic identifier wil 
be asociated to it. On the contrary, if the pronouns 
are judged to be referentialy empty or generic, no 
binding takes place. Here below is a table 
containig total values for pronouns WE/YOU/IT 
in al the 10 dialogues analysed. 
 
 Referential Generic Total 
WE 186 706 1892 
YOU 1045 742 1787 
IT 1593 108 2601 
 Total 3824 2456 6280 
Table 1. Overal count of pronominal expresions 
Results for the xperiment are as folows 
 
 Recal Precision F-Score 
WE 98.2% 60.59% 74.94% 
YOU 9.3 70.9 82.79 
IT 97.6% 64.2% 7.45% 
Table 2. Results for pronominal expresions 
 
References 
 
Alen, J., M. Dzikovska, M. Manshadi, and M. Swift. 
2007. Dep linguistic procesing for spoken dialogue 
systems. In ACL 2007 Workshop on Dep Linguistic 
Procesing, pp. 49–56. 
Delmonte R. 2007. Computational Linguistic Text 
Procesing – Logical Form, Semantic 
Interpretation, Discourse Relations and Question 
Answering, Nova Science Publishers, New York. 
Delmonte R. 2009. Computational Linguistic Text 
Procesing – Lexicon, Grammar, Parsing and 
Anaphora Resolution, Nova Science Publishers, 
New York. 
 
41

