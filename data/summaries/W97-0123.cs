According to Della Pietra, Della Pietra, and Lafferty (1997) and Berger, Della Pietra, and Della Pietra (1996), the solution can be found as the following px(y \[ z) of the form of the exponential family: p~(y \[ =) = ~ (22) y i where a parameter Ai is introduced for each feature fi.
J96-1002
Collins (1996) proposed a statistical parser which is based on probabilities of dependencies between head-words in the parse tree.
P96-1025
Li and Abe (1996) also studied a method for learning dependencies between case slots and evaluated the discovered dependencies in the syntactic disambiguation task.
C96-1004
For example, in the context of syntactic disambiguation, Black (1993) and Magerman (1995) proposed statistical parsing models based-on decision-tree learning techniques, which incorporated not only syntactic but also lexical/semantic information in the decision-trees.
P93-1005 P95-1037
! ! I I ! As in the case of the models of Black (1993), Magerman (1995), and Collins (1996), this paper proposes a method of utilizing lexical/semantic features for the purpose of applying them to ranking parses in syntactic analysis.
P93-1005 P95-1037 P96-1025
At each step, we select the candidate feature which, when adjoined to the set of active features S, produces the greatest increase in log-likelihood of the training sample: 3 sit is shown in Della Pietra, Della Pietra, and La/ferty (1997) and Berger, Della Pietra~ and Della Pietra (1996) that the model p.
J96-1002
As a model learning method, we adopt the maximum entropy model learning method (Della Pietra, Della Pietra, and Lafferty, 1997; Berger, Della Pietra, and Della Pietra, 1996) and apply it to the task of model learning of subcategorization preference.
J96-1002
As lexical/semantic information, Black (1993) used about 50 semantic categories, while Magerman (1995) used lexical forms of words.
P93-1005 P95-1037
If the three cases in e are dependent on each other as in the generation of e in the formula (6), the generation of e is denoted as below in the case of the independent-frame model: pred : nomu ga : Chum "11.70 : Cbe v : cpz~ ~ e (15) ! i | i i *~'k, I the generation of e is denoted as below: Otherwise, if only the two cases "ga(NOM)" and "wo(ACG) ~ are dependent on each other and Ude(at)" case is independent of those two cases as in the generation of e in the formula (7), the ! ( ----* e (16) ~0 : Obey 3 Maximum Entropy Modeling This section gives a formal description of maximum entropy modeling (Della Pietra, Dena Pietra, and Lafferty, 1997; Berger, Della Pietra, and Della Pietra, 1996).
J96-1002
Della Pietra, Della Pietra, and Lafferty (1997) and Berger, Della Pietra, and Della Pietra (1996) also presented an optimization method of estimating the parameter values ~*i that max~rn~.e the entropy, which is called Improved Iterative Scaling (IIS).
J96-1002
2Details of the method of statistically identifying the dependencies of the cases in verb.noun collocations are ~ven in Utsuro and Matsumoto (1997).
A97-1053
Then, given the empirical distribution i~(v, e~) of the training sample, the set 5(C_ ~') of active features is found according to the feature selection algorithm in section 3.3, and the parameters of subcategorization frames are estimated according to HS Algorithm(Della Pietra, Della Pietra, and Lafferty, 1997; Berger, Della Pietra, and Della Pietra~ 1996).
J96-1002
Resnik (1993) and Li and Abe (1995) studied how to find an optimal abstraction level of an argnment noun in a tree-structured thesaurus.
H93-1054
However, unlike the models of Black (1993), Magerman (1995), and Collins (1996), we put an assumption that syntactic and lexical/semantie features are independent.
P93-1005 P95-1037 P96-1025
