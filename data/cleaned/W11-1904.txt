Proceedings of the 15th Conference on Computational Natural Language Learning:Share Task, pages 17–21,
Portland, Oregon, 23-24 June 2011. c©2011 Association for Computational Linguistics
ETS:An Error TolerableSystemfor CoreferenceResolution
HaoXiong, LinfengSong, FandongMeng, YangLiu , QunLiu andYajuanL¨u
Key Lab. of IntelligentInformationProcessing
Instituteof ComputingTechnology
ChineseAcademyof Sciences
P.O. Box 2704,Beijing100190,China
{xionghao,songlinfeng,mengfandong,yliu,liuqun,lvyajuan}@ict.ac.cn
Abstract
This paper presents our error tolerable sys-
tem for coreference resolution in CoNLL-
2011(Pradhanet al., 2011)sharedtask(closed
track). Different from most previous reported
work, we detect mention candidatesbased on
packed forest instead of single parse tree, and
we use beam search algorithm based on the
Bell Tree to create entities. Experimental re-
sultsshowthatourmethodsachievepromising
resultson the developmentset.
1 Introduction
Over last decades, there has been increasing inter-
est on coreference resolution within NLP commu-
nity. The task of coreference resolution is to iden-
tify expressions in a text that refer to the same dis-
course entity. This year, CoNLL1 holds a shared
task aiming to model unrestricted coreference in
OntoNotes.2 The OntoNotes project has created a
large-scale, accurate corpus for general anaphoric
coreference that covers entities and events not lim-
ited to noun phrases or a limited set of entity types.
AndPradhanetal. (2007)haveeverusedthiscorpus
for similarunrestrictedcoreferencetask.
Our approachto this year’s task could be divided
into two steps: mention identification and creation
of entities. The first stage is conductedon the anal-
ysis of parse trees produced by input data. The of-
ficial data have provided gold and automatic parse
treesforeachsentencesin traininganddevelopment
1http://conll.bbn.com/
2http://www.bbn.com/ontonotes/
set. However, according to statistics, almost 3%
mentions have no correspondingconstituentsin au-
tomaticparsetrees. Sinceonlyautomaticparsetrees
will be provided in the final test set, the effect of
parsing errors are inevitable. To alleviate this issue,
based on given automatic parse trees, we modify a
state-of-the-artparser(CharniakandJohnson,2005)
to generate packed forest, and determine mention
candidates among all constituents from both given
parse tree and packed forest. The packed forest is a
compactrepresentationof all parse trees for a given
sentence. Readers can refer to (Mi et al., 2008) for
detaileddefinitions.
Once the mentions are identified, the left step is
to groupmentionsreferringto sameobjectintosim-
ilar entity. This problem can be viewed as binary
classificationproblem of determiningwhether each
mention pairs corefer. We use a MaximumEntropy
classifierto predictthe possibilitythattwo mentions
refer to the similarentity. And mainlyfollowing the
work of Luo et al. (2004), we use a beam search
algorithm based on Bell Tree to obtain the global
optimalclassification.
As this is the first time we participate competi-
tion of coreference resolution, we mainly concen-
trate on developing fault tolerant capability of our
systemwhileomittingfeatureengineeringandother
helpfultechnologies.
2 MentionDetection
The first step of the coreference resolution tries to
recognize occurrences of mentions in documents.
Note that we recognizementionboundariesonly on
development and test set while generating training
17
Figure 1: Left side is parse tree extracted from develop-
ment set, and right side is a forest. “my daughter” is a
mentionin this discourse,however it has no correspond-
ing constituent in parse tree, but it has a corresponding
constituentNP0 in forest.
instancesusinggoldboundariesprovidedby official
data.
Thefirststageof oursystemconsistsof following
three successive steps:
• Extracting constituents annotated with NP,
NNP,PRP,PRP$ andVBDPOStagsfromsin-
gle parsetree.
• Extracting constituents with the same tags as
the last step from packed forest.
• Extracting Named Entity recognized by given
data.
It is worth mentioning that above three steps will
produce duplicated mentions, we hence collect all
mentions into a list and discard duplicated candi-
dates. Thecontributionofusingpackedforestisthat
itextendsthesearchingspaceofmentioncandidates.
Figure 1 presents an example to explain the advan-
tageofemployingpackedforesttoenhancethemen-
tion detection process. The left side of Figure 1 is
theautomaticparsetreeextractedfromdevelopment
set, in which mention “my daughter” has no corre-
sponding constituent in its parse tree. Under nor-
mal strategy, such mention will not be recognized
and be absent in the clustering stage. However, we
find that mention has its constituentNP0 in packed
forest. According to statistics, when using packed
forest, only 0.5% mentionscould not be recognized
while the traditional method is 3%, that means the
theoreticalupper bound of our system reaches 99%
comparedto baseline’s 97%.
Since the requirement of this year’s task is
to model unrestricted coreference, intuitively, we
should not constraint in recognizing only noun
phrases but also adjective phrase, verb and so on.
However, we find that most mentions appeared in
corpus are noun phrases, and our experimental re-
sultsindicatethatconsideringconstituentsannotated
with above proposedPOS tags achieve the best per-
formance.
3 DeterminingCoreference
Thisstageis to determinewhichmentionsbelongto
the same entity. We train a MaximumEntropy clas-
sifier(Le,2004)to decidewhethertwo mentionsare
coreferent.WeusethemethodproposedbySoon, et
al.’s to generatethe traininginstances,wherea posi-
tive instanceis formedbetweencurrentmentionMj
and its closest precedingantecedentMi, and a neg-
ative instance is created by paring Mj with each of
the interveningmentions,Mi+1, Mi+2,...,Mj−1.
We use the following features to train our classi-
fier.
Features in Soonet al.’s work (Soonet al., 2001)
Lexicalfeatures
IS PREFIX:whetherthe string of one mentionis
prefixof the other;
IS SUFFIX:whetherthe string of one mentionis
suffix of the other;
ACRONYM:whetheronementionistheacronym
of the other;
Distancefeatures
SENT DIST:distancebetweenthesentencescon-
tainingthe two mentions;
MEN DIST: number of mentions between two
mentions;
Grammaticalfeatures
IJ PRONOUN: whether both mentions are pro-
noun;
I NESTED: whether mention i is nested in an-
othermention;
J NESTED: whether mention j is nested in an-
othermention;
Syntaxfeatures
HEAD: whether the heads of two mentions have
the same string;
HEAD POS: whether the heads of two mentions
have the samePOS;
HEA POS PAIRS: pairs of POS of the two men-
tions’heads;
18
Semanticfeatures
WNDIST: distance between two mentions in
WordNet;
I ARG0: whethermentioni hasthe semanticrole
of Arg0;
J ARG0: whethermentionj hasthesemanticrole
of Arg0;
IJ ARGS:whethertwo mentionshave the seman-
tic roles for similarpredicate;
In the submitted results, we use the L-BFGS pa-
rameter estimation algorithm with gaussian prior
smoothing(Chen and Rosenfeld, 1999). We set the
gaussian prior to 2 and train the model in 100 itera-
tions.
3.1 Creationof
Entities
This stage aims to create the mentions detected in
the first stage into entities, according to the predic-
tion of classifier. One simple method is to use a
greedyalgorithm,by comparingeach mentionto its
previous mentions and refer to the one that has the
highest probability. In principle, this algorithm is
too greedy and sometimes results in unreasonable
partition (Ng, 2010). To address this problem, we
follow the literature (Luo et al., 2004) and propose
to use beamsearchto find globaloptimalpartition.
Intuitively, creation of entities can be casted as
partition problem. And the number of partitions
equals the Bell Number (Bell, 1934), which has a
“closed”formulaB(n) = 1e∑∞k=0 knk! . Clearly, this
numberisveryhugewhennislarge,enumerationof
all partitionsis impossible,so we instead designing
a beamsearchalgorithmto find the best partition.
Formally, thetaskistooptimizethefollowingob-
jective,
ˆy = argmax
ϕ∈P
∑
e∈ϕ
Prob(e) (1)
where P is all partitions, Prob(e) is the cost of
entity e. And we can use the following formula to
calculatethe Prob(e),
Prob(e) =
∑
i∈e,j∈e
pos(mi,mj)
+
∑
i∈e,j/∈e
neg(mi,mj)
(2)
where pos(mi,mj) is the score predicted by clas-
sifier that the possibility two mentions mi and mj
group into one entity, and neg(mi,mj) is the score
that two mentionsare not coreferent.
Theoretically, wecandesigna dynamicalgorithm
to obtain the best partition schema. Providing there
are four mentions from A to D, and we have ob-
tained the partitions of A, B and C. To incorporate
D, we should considerassigningD to each entity of
every partition, and generate the partitions of four
mentions. For detailed explanation, the partitions
of three mentions are [A][B][C],[AB][C], [A][BC]
and [ABC], when considering the forth mention D,
we generatethe following partitions:
• [A][B][C][D], [AD][B][C], [A][BD][C],
[A][B][CD]
• [AB][C][D],[ABD][C],[AB][CD]
• [A][BC][D],[AD][BC],[A][BCD]
• [ABC][D],[ABCD]
The score of partition [AD][B][C] can be
calculated by score([A][B][C]) + pos(A,D) +
neg(B,D) + neg(C,D). Since we can computer
pos and neg score between any two mentions in
advance, this problem can be efficiently solved by
dynamic algorithm. However, in practice, enumer-
ating the whole partitions is intractable, we instead
exploitingabeamwithsizek tostorethetopk parti-
tions of currentmentionsize, accordingto the score
the partitionobtain. Due to the scope limitation,we
omitthe detailedalgorithm,readerscanreferto Luo
et al. (2004) for detailed description, since our ap-
proachis almostsimilarto theirs.
4 Experiments
4.1 DataPreparation
The shared task provided data includes information
of lemma, POS, parse tree, word sense, predicate
arguments, named entity and so on. In addition to
thoseinformation,weuseamodifiedinhouseparser
to generatepacked forestforeachsentencein devel-
opmentset,andprunethepacked forestwiththresh-
old p=3 (Huang, 2008). Since the OntoNotes in-
volves multiple genre data, we merge all files and
19
Mention MUC BCUBED CEAFM CEAFE BLANC
baseline 58.97% 44.17% 63.24% 45.08% 37.13% 62.44%
baseline gold 59.18% 44.48% 63.46% 45.37% 37.47% 62.36%
sys forest 59.07% 44.4% 63.39% 45.29% 37.41% 62.41%
sys btree 59.44% 44.66% 63.77% 45.62% 37.82% 62.47%
sys forest btree 59.71% 44.97% 63.95% 45.91% 37.96% 62.52%
Table 1: Experimentalresultson developmentset (F score).
Mention MUC BCUBED CEAFM CEAFE BLANC
sys1 54.5% 39.15% 63.91% 45.32% 37.16% 63.18%
sys2 53.06% 35.55% 59.68% 38.24% 32.03% 50.13%
Table 2: Experimentalresultson developmentset with differenttrainingdivision(F score).
take it as our training corpus. We use the sup-
plied score toolkit 3 to compute MUC, BCUBED,
CEAFM,CEAFEand BLANCmetrics.
4.2 ExperimentalResults
We first implement a baseline system (baseline)
that use single parse tree for mention detection
and greedy algorithm for creation of entities. We
also run the baseline system using gold parse tree,
namely baseline gold. To investigate the contribu-
tion of packed forest, we design a reinforced sys-
tem, namelysys forest. And anothersystem,named
as sys btree, is used to see the contribution of beam
search with beam size k=10. Lastly, we combine
twotechnologiesandobtainsystemsys forest btree.
Table 1 shows the experimentalresults on devel-
opment data. We find that the system using beam
search achieve promising improvement over base-
line. The reason for that has been discussed in last
section. We also find that compared to baseline,
sys forest and baseline gold both achieve improve-
ment in term of some metrics. And we are glad to
find that using forest, the performance of our sys-
tem is approaching the system based on gold parse
tree. But even using the gold parse tree, the im-
provement is slight. 4 One reason is that we used
some lexical and grammar features which are dom-
3http://conll.bbn.com/download/scorer.v4.tar.gz
4Since under task requirement, singleton mentions are fil-
tered out, it is hard to recognizethe contribution of packed for-
esttomentiondetection,whilewemayincorrectlyresolvesome
mentionsintosingletonsthataffectsthescoreofmentiondetec-
tion.
inant during prediction, and another explanation is
that packed forest enlarges the size of mentions but
bringsdifficultyto resolve them.
To investigate the effect of different genres to de-
velop set, we also perform following compared ex-
periments:
• sys1: all training corpus + WSJ development
corpus
• sys2: WSJtrainingcorpus+ WSJdevelopment
corpus
Table 2 indicates that knowledge from other genres
can help coreferenceresolution. Perhaps the reason
is the same as last experiments,where syntax diver-
sity affects the task not very seriously.
5 Conclusion
In this paper, we describe our system for CoNLL-
2011 shared task. We propose to use packed for-
est and beam search to improve the performanceof
coreferenceresolution. Multiple experimentsprove
that such improvementsdo help the task.
6 Acknowledgement
The authors were supported by National Natural
Science Foundation of China, Contracts 90920004.
We would like to thank the anonymous reviewers
for suggestions, and SHUGUANG COMPUTING
PLATFORMfor supportingexperimentalplatform.
20
References
E.T. Bell. 1934. Exponential numbers. The American
MathematicalMonthly, 41(7):411–419.
E. Charniak and M. Johnson. 2005. Coarse-to-fine n-
best parsing and maxent discriminative reranking. In
Proceedings of the 43rd Annual Meeting on Associ-
ation for Computational Linguistics, pages 173–180.
Associationfor ComputationalLinguistics.
StanleyF.ChenandRonaldRosenfeld. 1999. Agaussian
prior for smoothingmaximumentropy models. Tech-
nical report,CMU-CS-99-108.
Liang Huang. 2008. Forest reranking: Discriminative
parsing with non-local features. In Proceedings of
ACL-08: HLT, pages586–594,Columbus,Ohio,June.
Z. Le. 2004. Maximum entropy modeling toolkit for
Pythonand C++.
X. Luo, A. Ittycheriah, H. Jing, N. Kambhatla, and
S. Roukos. 2004. A mention-synchronous corefer-
ence resolution algorithm based on the bell tree. In
Proceedings of the 42nd Annual Meeting on Associa-
tion for ComputationalLinguistics, pages135–es.As-
sociationfor ComputationalLinguistics.
H. Mi, L. Huang,and Q. Liu. 2008. Forestbasedtransla-
tion. InProceedingsofACL-08: HLT, pages192–199.
Citeseer.
Vincent Ng. 2010. Supervised noun phrase coreference
research: The first fifteenyears. In Proceedingsof the
48th Annual Meeting of the Association for Compu-
tationalLinguistics, pages 1396–1411,Uppsala,Swe-
den, July. Associationfor ComputationalLinguistics.
Sameer Pradhan, Lance Ramshaw, Ralph Weischedel,
JessicaMacBride,and LinneaMicciulla. 2007. Unre-
stricted Coreference: Identifying Entities and Events
in OntoNotes. In in Proceedings of the IEEE Inter-
national Conference on Semantic Computing (ICSC),
September17-19.
Sameer Pradhan, Lance Ramshaw, Mitchell Marcus,
MarthaPalmer, Ralph Weischedel,and NianwenXue.
2011. Conll-2011shared task: Modeling unrestricted
coreference in ontonotes. In Proceedings of the Fif-
teenth Conference on Computational Natural Lan-
guage Learning (CoNLL 2011), Portland, Oregon,
June.
W.M. Soon, H.T. Ng, and D.C.Y. Lim. 2001. A ma-
chine learning approach to coreference resolution of
noun phrases. ComputationalLinguistics, 27(4):521–
544.
21

