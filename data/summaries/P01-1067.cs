Following (Brown et al., 1993) and the other literature in TM, this paper only focuses the details of TM.
J93-2003
Researchers at IBM first described such a statistical TM in (Brown et al., 1988).
C88-1016
To make this paper comparable to (Brown et al., 1993), we use English-French notation in this section.
J93-2003
Brown et al.(1993) assumes that there is an invisible NULL word in the input sentence and it generates output words that are distributed into random positions.
J93-2003
Let a183a49a48a50 a69 a188 a50 a51a181a51a181a51a212a188 a50a7a51a24a52 a48a54a53 a185a56a55 be a substring of a183 from the word a188 a50 with length a57 . Note this notation is different from (Brown et al., 1993).
J93-2003
Mathematical details are fully described in (Brown et al., 1993).
J93-2003
Wang (1998) enhanced the IBM models by introducing phrases, and Och et al.(1999) used templates to capture phrasal sequences in a sentence.
W99-0604
Wu (1997) and Alshawi et al.(2000) showed statistical models based on syntactic structure.
J00-1004 J97-3002
IBM Model 5 was sequentially bootstrapped with Model 1, an HMM Model, and Model 3 (Och and Ney, 2000).
P00-1056
Brill’s part-of-speech (POS) tagger (Brill, 1995) and Collins’ parser (Collins, 1999) were used to obtain parse trees for the English side of the corpus.
J95-4004
TMs have been used for statistical machine translation (Berger et al., 1996), word alignment of a translation corpus (Melamed, 2000), multilingual document retrieval (Franz et al., 1999), automatic dictionary construction (Resnik and Melamed, 1997), and data preparation for word sense disambiguation programs (Brown et al., 1991).
A97-1050 J00-2004 P91-1034
