Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 170–173,
Uppsala, Sweden, 15-16 July 2010. c 2010 Association for Computational Linguistics
KX: A flexible system for Keyphrase eXtraction 
 
Emanuele Pianta 
Fondazione Bruno Kessler 
Trento, Italy. 
pianta@fbk.eu 
Sara Tonelli 
Fondazione Bruno Kessler 
Trento, Italy. 
satonelli@fbk.eu 
 
  
 
Abstract 
In this paper we present KX, a system for key-
phrase extraction developed at FBK-IRST, 
which exploits basic linguistic anotation 
combined with simple statistical measures to 
select a list of weighted keywords from a 
document. The system is flexible in that it of-
fers to the user the posibility of seting pa-
rameters such as frequency thresholds for col-
location extraction and indicators for key-
phrase relevance, as wel as it alows for do-
main adaptation exploiting a corpus of docu-
ments in an unsupervised way. KX is also eas-
ily adaptable to new languages in that it re-
quires only a PoS-Tager to derive lexical pat-
terns. In the SemEval task 5 “Automatic Key-
phrase Extraction from Scientific Articles”, 
KX performance achieved satisfactory results 
both in finding reader-asigned keywords and 
in the combined keywords subtask. 
1 Introduction

Keyphrases are expresions, either single words 
or phrases, describing the most important con-
cepts of a document. As such, a list of key-
phrases provides an aproximate but useful char-
acterization of the content of a text and can be 
used in a number of interesting ways both for 
human and automatic procesing. For example, 
keyphrases provide a sort of quick sumary of a 
document. This can be exploited not only in 
automatic sumarization tasks, but also to en-
able quick topic search over a number of docu-
ments indexed acording to their keywords, 
which is more precise and eficient than ful-text 
search. Once the keywords of a document colec-
tion are known, they can also be used to calculate 
semantic similarity betwen documents and to 
cluster the texts acording to such similarity 
(Rica et al, 204). Also, keyword extraction can 
be used as an intermediate step for automatic 
sense extraction (Jones et al, 202). 
For these reasons, the keyphrase extraction 
task proposed at SemEval 2010 raised much at-
tention among NLP researchers, with 20 groups 
participating to the competition. In this frame-
work, we presented the KX system, specificaly 
tuned to identify keyphrases in scientific articles. 
In particular, the chalenge comprised two sub-
tasks: the extraction of reader-asigned and of 
author-asigned keyphrases in scientific articles 
from the ACM digital library. The former are 
asigned to the articles by anotators, who can 
chose only keyphrases that ocur in the docu-
ment, while author-asigned keyphrases are not 
necesarily included in the text. 
2 KX
architecture 
A previous version of the KX system, named 
KXPat (Pianta, 209), was developed to extract 
keyphrases from patent documents in the PatEx-
pert project (ww.patexpert.org). The sys-
tem employed in the SemEval task has aditional 
parameters and has ben tailored to identify key-
phrases in scientific articles. 
With KX, the identification of keyphrases can 
be acomplished with or without the help of a 
reference corpus, from which some statistical 
measures are computed in an unsupervised way. 
We present here the general KX architecture, 
including the corpus-based pre-procesing, even 
if in the SemEval task the information extracted 
from the corpus did not contribute as expected 
(se Section 3). 
KX keyphrase extraction combines linguistic 
and statistical information, similar to (Frantzi et 
al., 200) and is based on 4 steps. The first thre 
steps are caried out at corpus level, whereas the 
fourth one extracts information specific to each 
single document to be procesed. This means that 
the first thre steps require a corpus C, preferably 
sharing the same domain of the document d from 
which the keyphrases should be extracted. The 
fourth step, instead, is focused only on the 
170
document d. The steps can be sumarized as 
folows: 
Step 1: Extract from C the list NG-c of corpus 
n-grams, where an n-gram is any sequence 
of tokens in the text, for instance “the sys-
tem”, “of the”, “specificaly built”. 
Step 2: Select from the list NG-c a sub-list of 
multiword terms MW-c, that is combina-
tions of words expresing a unitary con-
cept, for instance “light beam” or “aces 
control” 
Step 3: For each document in C, recognize 
and mark the multiword terms. Calculate 
the inverse document frequency (IDF) for 
al words and multiword terms in the cor-
pus. 
Step 4: Given a document d from which a set 
of relevant keyphrases should be ex-
tracted, count al words and multiword 
terms and rank them. 
Step 1 is aimed at building a list of al posible n-
grams in C. The maximum length of the selected 
n-grams can be set by the user. For SemEval, 
beside one-token n-grams, we select 2-, 3and 4-
grams. Since n-grams ocuring only a few times 
are very unlikely to be useful for keyphrase 
recognition, they are cut of from the extracted 
list and excluded for further procesing. The fre-
quency threshold can be set acording to the ref-
erence corpus dimensions. For SemEval, we 
fixed the frequency threshold to 4. In this step, a 
black-list was also used in order to exclude n-
grams containing any of the stopwords in the list. 
Such stopwords include for example “every-
thing”, “exemplary”, “preceding”, etc. 
In Step 2, we select as multiword terms those 
n-grams that match certain lexical paterns. To 
this purpose, we first analyze al n-grams with 
the MorphoPro morphological analyzer of the 
TextPro tolsuite (Pianta et al., 206). Then, we 
filter out the n-grams whose analysis does not 
corespond to a predefined set of lexical paterns. 
For example, one of the paterns admited for 4-
grams is the folowing: [N]~[O]~[ASPGLU]~[NU]. 
This means that a 4-gram is a candidate 
multiword term if it is composed by a Noun, fol-
lowed by “of” or “for” (defined as O), folowed 
by either an Adjective, Singular noun, Past parti-
ciple, Gerund, punctuation (L) or Unknown 
word, folowed by either a Noun or Unknown 
word. This is matched for example by the 4-gram 
“subset [S] of [O] parent [S] pers [N]”. 
Both the lexical categories (e.g. S for singular 
noun) and the admisible lexical paterns can be 
defined by the user. 
In Step 3, multiword terms are recognized by 
combining local (document) and global (corpus) 
evidence. To this purpose, we do not exploit as-
sociation measures such as Log-Likelihod, or 
Mutual Information, but a simple frequency 
based criterion. Two thresholds are defined: 
MinCorpus, which coresponds to the minimum 
number of ocurences of an n-gram in a refer-
ence corpus, and MinDoc, i.e. the minimum 
number of ocurences in the curent document. 
KX marks an n-gram in a document as a 
multiword term if it ocurs at least MinCorpus 
times in the corpus or at least MinDoc times in 
the document. The two parameters depend on the 
size of the corpus and the document respectively. 
In SemEval, we found that the best thresholds 
are MinDoc=4 and MinCorpus=8. A similar, fre-
quency-based, strategy is used to solve ambigui-
ties in how sequences of contiguous multiwords 
should be segmented. For instance, given the 
sequence “combined storage capability of sen-
sors” we ned to decide whether we recognize 
“combined storage capability” or “storage capa-
bility of sensors”. To this purpose, we calculate 
the strength of each alternative colocation as 
docFrequency * corpusFrequency, and then 
chose the stronger one. To calculate IDF for 
each word and multiword term, we use the usual 
formula:  log( TotDocs / DocsContaningTerm ). 
In step 4, we take into acount a new docu-
ment d, posibly not included in C, from which 
the keyphrases should be extracted. First we rec-
ognize and mark multiword terms, through the 
same algorithm used in Step 3. Note that KX can 
recognize multiwords also in isolated documents, 
independently of any reference corpus, by acti-
vating only the MinDoc parameter (se above). 
Then, we count the frequency of words and 
multiword terms in d, obtaining a first list of 
keyphrases, ranked acording to frequency. 
Thus, frequency is the baseline ranking parame-
ter, based on the asumption that important con-
cepts are mentioned more frequently than les 
important ones. 
After the creation of a frequency-based list of 
keyphrases, various techniques are used to re-
rank it acording to relevance. In order to find 
the best ranking mechanism for the type of key-
phrases we want to extract, diferent parameters 
can be set: 
• Inverse document frequency (IDF): this 
parameter takes into acount the fact that a 
171
concept that is mentioned in al documents 
is les relevant to our task than a concept 
ocuring in few documents 
• Keyphrase length: number of tokens in a 
keyphrase. Concepts expresed by longer 
phrases are expected to be more specific, 
and thus more relevant. When this pa-
rameter is activated, frequency is multi-
plied by the keyphrase length. 
• Position of first ocurence: important 
concepts are expected to be mentioned be-
fore les relevant ones. If the parameter is 
activated, the frequency score wil be mul-
tiplied by the PosFact factor computed as 
(DistFromEnd / MaxIndex)
pwr2, where 
MaxIndex is the length of the curent 
document and DistFromEnd is MaxIndex 
minus the position of the first keyphrase 
ocurence in the text. 
• Shorter concept subsumption: In the key-
phrase list, two concepts can ocur, such 
that one is a specification of the other. 
Concept subsumption and bosting are 
used to merge or re-rank such couples of 
concepts. If a keyphrase is (stringwise) in-
cluded in a longer keyphrase with a higher 
frequency, the frequency of the shorter 
keyphrase is transfered to the count of the 
longer one. E.g.  “grid service discov-
ery”=6 and “grid service”=4 are re-ranked 
as “grid service discovery”=10 and “grid 
service”=0 
• Longer concept bosting: If a keyphrase 
is included in a longer one with a lower 
frequency, the average score betwen the 
two keyphrase frequency is computed. 
Such score is asigned to the les frequent 
keyphrase and subtracted from the fre-
quency score of the higher ranked one. For 
example, if “grid service discovery”=4 
and “grid service”=6, the average fre-
quency is 5, so that “grid service discov-
ery”=5 and “grid service” = 6–5=1. This 
parameter can be activated alone or to-
gether with another one that modifies the 
criterion for computing the bosting. With 
this second option, the longer keyphrase is 
asigned the frequency of the shorter one. 
For example, if “grid service discovery”=4 
and “grid service”=6, the bosting gives 
“grid service discovery”=6 and “grid serv-
ice”=6. 
After the list of ranked keyphrases is extracted 
for each document, it is finaly post-procesed in 
two steps. The post-procesing phase has ben 
aded specificaly for SemEval, because key-
phrases do not usualy ned to be stemed and 
acronym expansion is relevant only for the spe-
cific genre of scientific articles. For this reason, 
the two proceses are not part of the oficial sys-
tem architecture. 
First, acronyms are replaced by the extended 
form, which is automaticaly extracted from the 
curent document. The algorithm for acronym 
detection scans for parenthetical expresions in 
the text and checks if a preceding text span can 
be considered a suitable corespondence 
(Nguyen and Kan, 207). The algorithm should 
detect cases in which the acronym apears after 
or before the extended form, like in “Imediate 
Predecesors Tracking (IPT)” and “IPT (Ime-
diate Predecesors Tracking)”. If the acronym 
and the extended form apear both in the key-
phrase list, only the extended form is kept and 
the acronym frequency is aded. 
The second step is steming with the (Porter 
Stemer). Then, we check if the list of stemed 
keyphrases contains duplicate entries. If yes, we 
sum the frequencies of the double keyphrases 
and remove one of the two from the list.  
3 Experimental
Setup 
In the SemEval task, 14 training files were 
made available before the test data release. We 
split them into a training/development set of 10 
documents and a test set of 4 documents, in or-
der to find the best parameter combination. Key-
phrase asignment is a subjective task and crite-
ria for keyphrase identification depend on the 
domain and on the goal for which the keyphrases 
are neded. For example in scientific articles 
longer keyphrases are often more informative 
than shorter ones, so the parameters for bosting 
longer concepts are particularly relevant.  
We first tested al parameters in isolation to 
compute the improvement over the frequency-
based baseline. Results are reported in Table 1. 
F1 is computed as the harmonic mean of preci-
sion and recal over the 15 top-ranked key-
phrases after steming. We report the combined 
F1, as computed by the task scorer in order to 
combine reader-asigned and author-asigned 
keyword sets. 
 
Parameter F1 (combined) 
Baseline(MinDoc = 2) 13.63 
Baseline(inDoc = 4) 14.84 
+CorpusColoc(smal) 13.48 
  +CorpusColoc(big) 13.3 
+IDF 17.98 
172
+KeyphraseLength 16.78 
+FirstPosition 16.18 
+ShortConcSubsumption 16.03 
+LongConcBost(version1) 14.38 
+LongConcBost(version2) 13.93 
MinDoc = 4, +FirstPosition,  
+IDF,  +KeyphraseLength,  
+ShortConcSubsumption, 
+LongConcBost(version1) 
 
25.62 
Table 1: Parameter performance over development set 
 
The parameter scoring the highest improvement 
over the baseline is IDF. Also the parameters 
bosting longer keyphrases and those that ocur 
at the begining of the text are efective. Note 
that the LongConcBost parameter achieves bet-
ter results in the first version, which has a higher 
impact on the re-ranking. Surprisingly, using a 
domain corpus to extract information about 
multiword terms, as described in Section 2, steps 
1 3, does not achieve any improvement. This 
means that KX can beter recognize keyphrases 
in single documents without any corpus refer-
ence. Besides, the best seting for MinDoc, the 
minimum number of multiword ocurences in 
the curent document (se Section 2) is 4. We 
tested the CorpusColoc parameter using two 
diferent reference corpora: one contained the 
10 articles of the training set (CorpusColoc 
smal), while the other (CorpusColoc big) in-
cluded both the 10 training articles and the 20 
scientific publications of the NUS Keyphrase 
Corpus (Nguyen and Kan, 207). The perform-
ance is worse using the larger corpus than the 
smaler one, and in both cases it is below the 
baseline obtained without any reference corpus. 
In the botom row of Table 1, the best pa-
rameter combination is reported with the score 
obtained over the development set. The im-
provement over the baseline reaches 1.9 F1. 
4 Evaluation

In the SemEval task, the system was run on the 
test set (10 articles) with the best performing 
parameter combination described in the previous 
section. The results obtained over the 15 top-
ranked keyphrases are reported in Table 2. 
 
Keyphrase type P R F1 
Reader-asigned 20.3 25.3 2.56 
Combined 23.60 24.15 23.87 
Table 2: System performance over test set 
In the competition, the F1 score over reader-
asigned keyphrases was ranked 3
rd
 out of 20 
participants, while the combined measure 
achieved the 7
th
 best result out of 20. 
5 Conclusions

In this work we have described KX, a flexible 
system for keyphrase extraction, which achieved 
promising results in the SemEval task 5. The 
god KX performance is due to its adaptable ar-
chitecture, based on a set of parameters that can 
be tailored to the document type, the prefered 
keyphrase length, etc. The system can also ex-
ploit multiword lists (with frequency) extracted 
from a reference corpus, even if this feature did 
not improve KX performance in this specific 
task. However, this proved to be relevant when 
aplied to keyphrase extraction in the patent do-
main, using a large domain-specific corpus of 
10.00 very long documents (Pianta, 209). 
A limitation of KX in the task was that it ex-
tracts only keyphrases already present in a given 
document, while the author-asigned subtask in 
the SemEval competition included also key-
phrases that do not ocur in the text. Another 
improvement, which is now being implemented, 
is the extraction of the best parameter combina-
tion using machine-learning techniques. 
References  
Jones, S., Lundy, S. and Paynter, G. W. 202. Interac-
tive Document Sumarization Using Automati-
caly Extracted Keyphrases. In Proc. of the 35
th
 
Hawai International Conference on System Sci-
ences. 
Frantzi, K., Ananiadou, S. and Mima, H. 200. 
Automatic recognition of multi-word terms: the C-
value/NC-value method. Journal on Digital Li-
braries. 3 (2), p.15-130. 
Thuy Dung Nguyen and Min-Yen Kan. 207. Key-
phrase Extraction in Scientific Documents. In 
D.H.-L. Goh et al. (eds.): ICADL 207, LNCS 
482, p. 317-326. 
Pianta, E., Girardi, C and Zanoli, R. 206. The 
TextPro tol suite. In Proc. of LREC. 
Pianta, E. 209. Content Distilation from Patent Ma-
terial, FBK Technical Report. 
Rica, F., Tonela, P., Girardi, C and Pianta, E. 204. 
An empirical study on Keyword-based Web Site 
Clustering. In Procedings of the 12
th
 IWPC. 
PorterStemer: 
htp:/tartarus.org/~martin/PorterStem
mer/perl.txt. 
 
173

