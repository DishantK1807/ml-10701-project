As an example, maximum entropy taggers have achieved very good performance (Ratnaparkhi, 1998; Toutanova and Manning, 2000; Lafferty et al., 2001), but almost identical performance has also come from finely tuned HMM models (Brants, 2000; Thede and Harper, 1999).
A00-1031 P99-1023 W00-1308
Johnson (2001) finds that a conditionally trained PCFG marginally outperforms a standard jointly trained PCFG, but that a conditional shiftreduce model performs worse than a joint formulation.
P01-1042
Since the number of senses and skew towards common senses is so varied between SENSEVAL-2 words, we turned to larger data sets to test the effective “break-even” size for WSD data, using the hard and line data from Leacock et al.(1998). Figure 4 shows the accuracy of NB-CL and NB-JL as the amount of training data increases.
J98-1006
Results Johnson (2001) describes two parsing experiments.
P01-1042
Unconstrained CL corresponds exactly to a conditional maximum entropy model (Berger et al., 1996; Lafferty et al., 2001).
J96-1002
Goodman (1996) describes algorithms for parse selection where the criterion being maximized in parse selection is the bracket-based accuracy measure that parses are scored by.
P96-1024
