Structural Disambiguation Based on Reliable 
Estimation of Strength of Association 
Haodong Wu Eduardo dc Paiva Alves 
Teiji Furugori 
Department of Computer Science 
University of Electro-Communications 
1-5-1: Chofugaoka, Chofll, Tokyo 1828585, JAPAN 
{wu, ealve s, furugori }Ophaet on. cs. uec. ac. j p 
Abstract 
This paper proposes a new class-based method 
to estimate the strength of ,association in word 
co-occurrence for the purpose of structural dis
ambiguation. To deal with sparseness of data, 
we use a conceptual dictionary ,'us the source 
for acquiring upper closes of the words related 
in the co-occurrence, and then use t-scores to 
determine a pair of classes to be employed for 
calculating the strength of association. We have 
applied our method to determining dependency 
relations in Japanese and prepositional phrase 
attachments in English. The experimental re
suits show that the method is sound, effective 
and usefifl in resolving structural ambiguities. 
1 Introduction

The strength of association between words pro
vides lexical preferences for ambiguity resolu
tion. It is usuMly estimated fi'om statistics on 
word co-occurrences in large corpora (Hindle 
and Rooth, 1993). A problem with this ap
proach is how to estimate the probability of 
word co-occurrences that are not observed in 
the training corpus. There are two main ap
proaches to estimate the probability: smoothing 
methods (e.g., Church and Gale, 1991; Jelinek 
and Mercer, 1985; Katz, 1987) and clmss-b~ed 
methods (e.g., Brown et al., 1992; Pereira and 
Tishby, 1992; Resnik, 1992; Yarowsky, 1992). 
Smoothing methods estimate the probabil
ity of the unobserved co-occurrences by using 
frequencies of the individual words. For exam
ple, when eat and bread do not co-occur, tile 
probability of (eat, bread) would be estimated 
by using the frequency of (eat) and (bread). 
A problem with this approach is that it pays 
no attention to tile distributional characteris
tics of the individual words in question. Using 
this method, the probability of (eat, bread} and 
(eat, cars) would become the same when bread 
and cars have the same frequency. It is unac
ceptable fl'om the linguistic point of view. 
Cl,~ss-bmsed methods, oll the other hand, es
timate tile probabilities by associating a class 
with each word and collecting statistics on word 
class co-occurrences. For instance, instead of 
calculating tile probability of (eat, bread) di
rectly, these methods associate eat with the 
class \[ingest\] and bread with the class \[food\] 
and collect statistics on the classes \[ingest\] and 
\[food\]. The accuracy of the estimation depends 
on the choice of classes, however. Some class
based methods (e.g., Yarowsky, 1992) associate 
each word with a single class without consider
ing the other words in the co-occurrence. How
ever, a word may need to bc replaced by differ
ent class depending on the co-occurrence. Some 
classes may not have enough occurrences to al
low a reliable estimation, while other classes 
may be too general and include too many words 
not relevant to the estimation. An alternative is 
to obtain various classes ~sociated in a taxon
omy with the words in question and select the 
closes according to a certain criteria. 
There are a number of ways to select the 
classes used in the estimation. Weischedel et al. 
(1993) chose the lowest classes in a taxonomy 
1416 
for which the association for the co-occurrence 
can be estimated. This approach may result in 
unreliable estimates, since sonic of the class co
occurrences used may bc attributed to chance. 
Resnik (1993) selected all pairs of closes corre,~ponding to the head of a prepositional phrase 
and weighted them to hi,us the computation 
of the association in favor of higher-frequency 
co-occurrences which hc considered "more reli
able." Contrary to this ,assumption, high fre
quency co-occurrences arc unreliable when the 
probability thai; the co-occurrence may be at
t.ributcd to chance is high. 
In this paper we propose a clmss-b;used 
method that selects the lowest cbLsses in a tax
onomy for which the co-occurrence confidence 
is above a threshold. We subsequently apply 
the method to solving structural ambiguities 
in Japanese dcpcndcncy structures and English 
prepositional phrase attachments. 
2 Class-based Estimation of 
Strength of Association 
The strength of association (SA) may be 
measured using thc frequencies of word co
occurrences in large corpora. For instance, 
Church and Hanks (1990) calculated SA in 
terms of mutual infornlation between two words 
wl and w2: 
N * f(wl, w2) I(wl,w2) = lo.q2 f(wt)f(w2) 
(1) 
here N is the size of the corpus used in the es
tilnation, f(wl,W2) is the frequency of the co
occurrence, f(wl) and f(w2) that of each word. 
When no co-occurrence is observed, SA may 
be estimated using the frequencies of word 
cl,'~sses that contain the words in question. The 
nmtual information in this case is estimated by: 
N * f(C1, C2) 
I(CI,C2) ~-1o02 f(Cl)f(C2) (2) 
here C1 and C2 are the word classes that respec
tively contain wl and w2, f(C1) and f(C2) the 
nmnbers of occurrences of all the words included 
in the word classes C1 and C2, and f(C1, C2) is 
the number of co-occurrences of the word classes 
C1 and (72. 
Normally, the estimation using word classes 
needs to select classes, from a taxonomy, for 
which co-occurrences arc significant. We. use t
scores for this purpose'. 
For a class co-occurrence (C1,C2), the t~ 
score may be approximated by: 
f(Cl, C2) l f(c1)f(C2) t ' (3) 
x/f(Ct,C2) 
We use the lowest cl~s co-occurrence for 
which the. confidence memsured with t-scores is 
above a threshold 2. Given a co-occurrence con
taining the word w, our method selects a class 
for w in the following way: 
Step 1: Obtain the classes C '1, C 2 ..... C" associ
ated with w in a taxonomy. 
Step 2: Set i to 0. 
Step 3: Set i to i + 1. 
Step 4: Compute t using formula (3). 
Step 5: If t < threshold. 
If i # n goto step 3. 
Otherwise exit. 
Step 6: Select the class C i to replace u,. 
Let us see what this means with at: ex
ample. Suppose we try to estimate SA for 
(produce,,tclcphonc) a. See Table 1. Here f(v), 
f(n) and f(vn) are the frequencies for the verb 
Froduce, classes for the noun telephone, and co
occurrences between the verb and the claases for 
telephone, respectively; and t is the t-score d. 
I The t-score (Church and Mrrcer, 1993) cmnparcs the 
hyl)othesis that a co-occurrence is significant against the 
null hypothesis that tim co-occurrence can t)e attritmted 
to chalJ.Cc. 
2The default tt, rcshohl for t-score is 1.28 which col 
responds to a confidence level of 90%. t-scores are often 
inflated due to certain violations of assumptions. 
3The data was obtained front 68,623 w:rb-noun lmirs 
in EDR Corpus (EDR, 1993). 
4In our theory, we are to use each pair of (C i, cJ), 
where i=1,2,...m, j=l,2,...,n, to calculate strengths of 
lexical associations. But our experiments show that up
pcr classes of a verl) are very unreliablc to bc used to 
measure the strengths. The reason may be that, unlike 
nouns, the wrrbs would not have a "neat" hierarchy or 
that the upper classes of a verl) become too general as 
they contain too many concel)ts un(lcrneath them. Be
cause of this obserwdion, we use, h)r the classes of a 
1417 
verb classes for telephone f(v) f(n) f(vn) t-score 
produce concrete thing 671 18926 100 -4.6 
produce inanimate object 671 5593 69 0.83 
produce implement/tool 671 2138 35 1.91 
produce machine 671 664 19 2.86 
produce connnunication machine 671 83 1 0.25 
produce telephone 671 24 0 
Table 1 Estimation of (produce telephone) 
The lowest cl~s co-occurrence (produce, 
communication machine} h~ a low t-score and 
produces a bad estimation. The most frequent 
co-occurrence (produce, concrete thing) has a 
low t-score also reflecting the fact that it may be 
attributed to chance. The t-scores for (produce, 
machine} and (produce, implement/tool) are 
high and show that these co-occurrences are sig
nificant. Among them, our method selects the 
lowest class co-occurrence for which the t-score 
is above the threshold: (produce, machine). 
3 Disambiguation
Using 
Class-Based Estimation 
We. now apply our method to estimate SA for 
two different types of syntactic constructions 
and use the results in resolving structural am
biguities. 
3.1 Disambiguation
of Dependency 
Relations in Japanese 
Identifying the dependency structure of a 
Japanese sentence is a difficult problem since 
the language allows relatively free word or
ders. A typical dependency relation in 
Japanese appears in the form of modifier
particle-nmdificand triplets. When a modifier is 
followed by a mnnber of possible modificands, 
verb, the verb itself or, when it does not give us a good 
result, only the lowest class of the verb in calculating the 
strength of association (SA). Titus, for an example, the 
verb eat has a sequence of eat -+ ingest -+ put something 
into body -+.... -+ event -~ concept in the (:lass hierarchy, 
but we use only eat and ingest for the verb eat when 
calculating SA for (eat, apple}. 
there arise situations in which syntactic rules 
may be unable to determine the dependency re
lation or the modifier-modificand relation. For 
instance, in 
'~-~ 0 '(vigorous) may modify either :~ 
~#' (middle aged) or ' ~g{~:~ ' ( health care). 
But which one is the modificand of' ~ & ~ 0 ' ? 
We solve the ambiguity comparing the strength 
of association for the two or more possible de
pendency relations. 
Calculation of Strength of Association We. cal
culate the Strength of Association (SA) score 
for modifier particle modi f icand by: 
\[ N ._ I v.., ,,, \] 
SA(my;p,,.,, m,,) = loq2 k, f(Cmyi~,.)f(p,,.tm,:) / 
(4) 
where Cm/i~.,stands for the classes that in
clude the modifier word, P,,~t is the particle fol
lowing the modifier, m,. the content word in tile 
modificand phr,~se, and f the frequency. 
Let us see the process of obtaining SA score 
in an example < ~ -/)~ ~ < ) (literally: profes
sor subject-markerwork). To calculate the 
frequencies for the classes associated with ' ~ 
', we obtain from the Co-occurrence Dictionary 
(COD) s the number of occurrences for (w5~'
SCOD and CD are provided by Japan Electronic Die
tionary Research Institute (EDR, 1993). COD contains 
the frequencies of individual words and of the modifier
1418 
< ), where w can be any modifier. We then 
obtain fi'om the Concept Dictionary (CD) 6 the 
classes that include ' ~' and then stun up all 
the occurrences of words included in the classes. 
The relevant portion of CD for " ~' in ( ~\[~ 
oh ~-~< } is shown in Figure 1. The numbers 
in parenthesis here indicate the summed-up fi'c
quencies. 
We then cMculate the t-score between ' ?)~
ff~ < ' and all the classes that include' ~ '. See 
'Fable 2. 
Classes for the tparticle
modifier 12~ score nmdificand 
),N ~ ¢£tcN~ ~ ~ 7o ~i~ 4.57 ~¢~< 
3,N 5.14 ~< 
{~R~\]-c}I~_?:XN 1.74 ~ < 
#~'e~. f-)k ~ 0.74 /)¢~ < 
Table 2 t-scores for ( ~ re~J < ) 
The t-score for the co-occurrence of the 
modifier and particle-modificand pair, '~' 
and 'h~-t//< ', is higher than the threshold 
when : ~' is replaced with \[~.~U'~'~I~/~XN\]. 
Using (4), the strength of association for the co
occurrence of ( ~ ~0~ ~J < ) is calculated from 
the SA between the class \[~Ij-C~_f.:)kN\] and 
' rS~1I~ < .' 
When the word in question has more than 
one sense, we estimate SA corresponding to each 
sense and choose the one that results in the 
highest SA score. For instance, we estimate SA 
between ' ~ ' and the various senses of :/~ < 
', and choose the highest value: in this case the 
one corresponding to the sense 'to be employed.' 
Determination of Most Strongly Associated 
Structure After calculating SA for each possible 
construction, we choose the construction with 
lfighest SA score ~s the most probable struc
particlc-modificand triplets i,t a corpus that includes 
220,000 parsed Japanese sentences. 
CD provides a hierarchical structure of concepts cor
rcslmnding to all the words in COD. The number of con
cepts in CD is about 400,000. 
ture. See the following example: 
vt~ 2.86 
• • .~f*~¢N~ ~" ~I,,~ ~j< At) x b t~x... 
tee\[ n qa progress work people stress i n nowd lon 
Here, the arrows show possible dependency 
relations, the numbers on the arrows the esti
mated SA, and the thick arrows the dependency 
with highest mutual information that means the 
most probable dependency relation. In the ex
ample, ' ~$f:~?)~ ' modifies ' ~I~ ' and ' ~ < 
' modifies ' A. '. The estimated mutual informa
tion for ( ~'~/~g#h ~, i.~,~'e ) is 2.79 and that for 
( ~ i, A ) is 6.13. Thus, we choosc ' ~,~'C' ' as 
the modificaud for ' ~t$i~gN7)~ ' and ' Z. ' as that 
for '~< ' 
In the example shown in Figure 2, our 
method selects the nmst likely modifier
modificand relation. 
Experiment Disa,nbiguation of dependency re
lations was done using 75 ambiguous con
structions f,'mn Fukumoto (1992). Solving 
the ambiguity in the constructions involves 
choosing among two or nmre modifier-particle
modificand relations. The training data con
sists of all 568,000 nmdifier-partiele-modificand 
triplets in COD. 
Evaluation We evaluatcd the performance of 
our method comparing its results with those of 
other methods using the same test and training 
data. Table 3 shows the various results (suc
cess rates). Here, (1) indicates the pcrfbrmance 
obtained using the principle of Closest Attach
ment (Kimball, 1973); (2) shows the perfor
mance obtained using the lowest observed class 
co-occurrence (Weischedel et al., 1993); (3) is 
the result from the maximum mutual informa
tion over all pairs of clm~ses corresponding to 
the words in the co-occurrence (Resnik, 1993; 
Alves, 1996); and (4) shows the performance of 
our method 7. 
7The precision is for the 1.28 default threshold, The 
precision was 81.2% and 84.1% v, qu:n we set the thrcshohl 
to .84 and .95. In all these cases the coverage was 92,0%. 
1419 
(42) I human or similar 
(3) person 
(39) human 
(3) person defined by race or origin 
(3) Japanese (2) worker 
(5) 
Figure 1 
person defined by role 
(1) person defined by position 
(1) slave (0) professor 
An Extract of CD 
.'~.4 7 
9.19 \[_.....__~ ¢ ~ ~ ~ 
national investigation based cause prompt study expect 
Figure 2 An example of parsing a Japanese sentence 
method precision 
(1) closest attachnlent 70.6% 
(2) lowest classes 81.2% 
(3) maximmn MI 82.6% 
(4) our method 87.0% 
Table 3 Results for determining dependency 
relations 
Closest attachment (1) h,~s a low perfor
mance since it fails to take into consideration 
tile identity of the words involved in the deci
sion. Selecting the lowest classes (2) often pro
duces unreliable estimates and wrong decisions 
due to data sparseness. Selecting the classes 
with highest mutual information (3) results in 
overgeneralization that may lead to incorrect at
tachments. Our method avoids both estimating 
from unreliable classes and overgeneralization 
and results in better estimates and a better per
formance. 
A qualitative analysis of our results shows 
two causes of errors, however. Some errors oc
curred when there were not enough occurrences 
of the particle-modificand pattern to estimate 
any of the strength of mssociation necessary 
for resolving ambiguity. Other errors occun'ed 
when the decision could not be made without 
surrounding context. 
3.2 Prepositional
Phrase Attachment 
in English 
Prepositional phrase (PP) attachment is a 
paradigm c,~se of syntactic ambiguity. The most 
probable attachnlent may be chosen comparing 
the SA between the PP and the various attach
ment elements. Here SA is measured by: 
SA(v-attachlv'p'n'e) = l°g'~ ( N * f(C''p'C''2) C,, 2 ) 
• SA(n-attach.ln,,p, n2) = log.e \ -/-(C~p. C--,,~) ) 
(6) 
where Cw stands for the class that includes 
the word w and f is the frequency in a training 
data containing verb-nounl-preposition-noun2 
constructions. 
Our method selects fl'om a taxonomy the 
cla.sses to be used to calculate the SA score and 
1420 
then chooses the attachment with highest SA 
score ,as the most probable. 
Experiment We performed a PP attachment 
experiment on the data that consists of all 
the 21,046 semantically annotated verb-noun
preposition-noun constructions found in EDR 
English Corpus. We set aside 500 constructions 
for test and used the remaining 20,546 as train
ing data. We first performed the experiment 
using various values for the threshoM. Table 
4 shows the results. The first line here shows 
the default which corresponds to the most likely 
attachment for each preposition. For instance, 
the preposition of is attached to the noun, re
flecting the fact that PP's led by of are nmstly 
attached to nouns in the training data. The 
:confidence' values correspond to a binomial dis
tribution and are given only as a reference s. 
confidence t coverage precision success 
100% 68.0% 68.0% 
50% .00 82% 82.2% 79.4% 
70% .52 75% 87.3% 83.4% 
80% .84 65% 88.6% 84.2% 
85% .95 57% 89.6% 84.8% 
90% 1.28 50% 91.3% 85.6% 
Table 4 Results for PP attachment with 
various thresholds for t-score 
The precision grows with t-scores, while 
coverage decreases. In order to improve cov
erage, when the method cannot find a class 
co-occnrrence for which the t-score is above 
the threshold, we recursively tried to find a 
co-occurrence using the threshold immediately 
smaller (see Table 4). When the method could 
not find co-occurrences with t-score above the 
smallest threshold, the default was used. The 
overall success rates are shown in "success" col
umn in Table 4. 
SAs another way of reducing the sparse data problem, 
we clustered prepositions using the nmthod described in 
\¥u and Furugori (1996). Prepositions like synonylns 
and antonyms are chtstered into groups and replaced by 
a representative ineposition (e.g., till aim pending are 
replaced by until; among.~t, amid and amid,st are replaced 
by among.). 
Evaluation We evaluated the performance of 
our method comparing its results with those of 
other methods with the same test and training 
data. The results are given in Table 5. Here, (5) 
shows the performance of two native speakers 
who were just presented quadruples of four head 
words without surrounding contexts. 
Method Success Rate 
(1)closest Attachment 59.6% 
(2)lowest classes 80.2% 
(3) nlaxinnlnl MI 79.0% 
(4)our nmthod 85.6% 
(5)human (head words only) 87.0% 
Table 5 Comparison with other methods 
The lower bound and the upper bound on 
the performance of our method seem to be 
59.6% scored by the simple heuristic of closest 
attachment (1) and 87.0% by hmnan beings (4). 
Obviously, the success rate of closest attach
ment (1) is low as it Mways attaches a word to 
the noun without considering the words in ques
tion. The unanticipated low success rate of hu
man judges is partly due to the fact that some
times constructions were inherently ambiguous 
so that their choices differed from the annota
tion in the corpus. 
Our method (4) performed better than the 
lowest classes method (2) and nlaximum MI 
method (3). It owes mainly to the fact that 
our method makes the estimation fi'om class co
occurrences that are more reliable. 
4 Concluding
Remarks 
We, proposed a class-based method that selects 
classes to be used to estimate tile strength of as
sociation for word co-occurrences. The classes 
selected by our method can be used to estimate 
various types of strength of association in (lifter
ent applications. The nmthod differs fi'mn other 
clmss-ba,sed methods in that it allows identifica
tion of a reliable and specific class for each co
occurrence in consideration and call deal with 
date sparseness problem more efficiently. It 
1421 
overcame the shortcomings fl'om other meth
ods: overgeneralization and employment of un
reliable class co-occurrences. 
We applied our method to two structural 
disambiguation experiments. In both exper
iments the performance is significantly better 
than those of others. 

References 

\[1\] Alves, E. 1996. "The Selection of the Most 
Probable Dependency Structure in Japanese 
Using Mutual Information." In Proc. of the 
34th ACL, pages 372-374. 

\[2\] Brown, P., Della Pietra, V. and Mercer, 
R. (1992). "Word Sense Disambiguation Us
ing Statistical Methods." Proceeding:s of the 
30th ACL, pages 264-270. 

\[3\] Church, K., and Mercer, R. 1993. "Introduc
tion to the Special Issue on Computational 
Linguistics Using Large Corpora." Compu
tational Linguistics, 19(1): 1-24. 

\[4\] Church, K., and Hanks, P. 1990. "Word As
sociation Norms, Mutual Information and 
Lexicography." Computational Linguistics, 
16(1):22-29. 

\[5\] Church, K., and Gale, W. 1991. "A Com
parison of the Enhanced Good-Turing and 
Deleted Estimation Methods for Estimat
ing Probabilities of English Bigrams." Com
puter Speech and Language, 5:19-54. 

\[6\] Fukumoto, F., Sano, H., Saitoh, Y. and 
Fukumoto J. 1992. "A Framework for De
pendency Grammar Based on the Word's 
Modifiability Level Restricted Dependency 
Grammar." Trans. IPS ,lapan, 33(10):1211
1223 (in ,Japanese). 

\[7\] Hindle, D., and Rooth, M. 1993. "Structural 
Ambiguity and Lexical Relations." Compu
tational Linguistics, 19(1):103-120. 

\[8\] Japan Electronic Dictionary Research Insti
tute, Ltd. 1993. EDR Electronic Dictionary 
Specifications Guide (in Japanese). 

\[9\] Jelinek, F., and Mercer, R. 1985. "Proba
bility Distribution Estimation from Sparse 
Data." IBM TechnicM DiscIosure Bulletin, 
28:2591-2594. 

\[10\] Katz, S. 1987. "Estimation of Probabili
ties from Sparse Data for Language Model 
Cmnponent of a Speech Recognizer." IEEE 
Transactions on Acoustics, Speech and Sig'
hal Processing, ASSP-35(3):400-401. 

\[11\] Kimball, J. 1973. "Seven Principles of 
Surfacc Structure Parsing in Natural Lan
guage." Cognition, 2:15-47. 

\[12\] Pereira, F. and Tishby, N. 1992. "Distribu
tional Similarity, Phr~e Transitions and Hi
erarchical Clustering." In Proc. of the 30th 
ACL, pages 183-19(}. 

\[13\] Resnik, P. 1992. "Wordnet and Distribu
tional Analysis: A Class-Based Approach 
to Lexical Discovery." AAAI Workshop on 
Statistically-based Natural Language Pro
cessing Techniques, pages 56-64. 

\[14\] Resnik, P. 1993. "Selection and Informa
tion: A Class-Based Approach to Lexical 
Relationships." PhD. thesis, University of 
Pennsylvania. 

\[15\] Weischedel, R., Mercer, M., Schwartz, R., 
Ramshaw, L., and Palmucci, J. 1993. "Cop
ing with Ambiguity and Unknown Words 
Through Probabilistic Models." Computa
tional Linguistics, 19(2):359-382. 

\[16\] Wu, H. and Furugori, T. 1996. '% Hy
brid Disambiguation Model for Preposi
tional Phrase Attachnlent." Literary and 
Linguistic Computing. 11(4):187-192. 

\[17\] Yarowsky, D. 1992. "Word Sense Disam
biguation using Statistical Models of Roger's 
Categories Trained on Large Corpora." Pro
ceedings of COLING-92, pages 454-460. 

