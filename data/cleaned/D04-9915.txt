1:229	The Influence of Argument Structure on Semantic Role Assignment Sebastian Pad SALSA Dept. of Computational Linguistics Saarland University Saarbrcken pado@coli.uni-sb.de Gemma Boleda GLiCom Dept. of Translation and Interpreting Pompeu Fabra University Barcelona gemma.boleda@upf.edu Abstract We present a data and error analysis for semantic role labelling.
2:229	In a first experiment, we build a generic statistical model for semantic role assignment in the FrameNet paradigm and show that there is a high variance in performance across frames.
3:229	The main hypothesis of our paper is that this variance is to a large extent a result of differences in the underlying argument structure of the predicates in different frames.
4:229	In a second experiment, we show that frame uniformity, which measures argument structure variation, correlates well with the performance figures, effectively explaining the variance.
5:229	1 Introduction Recent years have witnessed growing interest in corpora with semantic annotation, especially on the semantic role (or argument structure) level.
6:229	A number of projects are working on producing such corpora through manual annotation, among which are FrameNet (Baker et al. , 1998), the Prague Dependency Treebank (Hajicov, 1998), PropBank (Kingsbury et al. , 2002), and SALSA (Erk et al. , 2003).
7:229	For semantic role annotation to be widely useful for NLP, however, robust and accurate methods for automatic semantic role assignment are necessary.
8:229	Starting with Gildea and Jurafsky (2000), a number of studies have developed (almost exclusively statistical) models of this task, e.g. Thompson et al.9:229	(2003) and Fleischman et al.10:229	(2003).
11:229	This year (2004), semantic role labelling served as the shared task at two conferences, CoNLL1 and SENSEVAL2.
12:229	However, almost all studies have concentrated on the technical aspects of the models  identifying informative feature sets and suitable statistical frameworks  with the goal of optimising the performance of the models on the complete dataset.
13:229	The only study we are aware of with a more detailed evaluation is Fleischman et al.14:229	(2003), who nevertheless come to the conclusion that either new features, 1http://www.lsi.upc.es/~conll04st/ 2http://www.clres.com/SensSemRoles.html more data, or more sophisticated models are needed.
15:229	The present study is a first step in pursuing the third alternative, presenting a data and error analysis for semantic role assignment in the FrameNet paradigm.
16:229	We first build two different, generic statistical models for semantic role assignment, which are fairly representative for the span of models investigated in the literature.
17:229	A frame-wise evaluation shows that the models exhibit a large variance in performance across frames.
18:229	Our hypothesis is that this variance is to a large extent caused by differences in the underlying argument structure of the predicates: Frames which are less uniform, i.e. whose predicates have a more heterogeneous mapping between semantic roles and syntactic functions, are more difficult to label automatically.
19:229	In order to put this hypothesis, which is intuitively very plausible, on a a firm empirical footing, we investigate the relationship between frame uniformity and the variance in the data and show that the two variables correlate.
20:229	Since argument structure has been investigated mostly for verbs, we restrict our study to verbal predicates.
21:229	Structure of the paper.
22:229	In Section 2 we give a brief introduction to FrameNet.
23:229	Section 3 outlines the first experiment and discusses the variance in performance across frames.
24:229	In Section 4, we define two measures of frame uniformity based on argument structure, and show in our second experiment (Section 5) that they correlate with the performance figures.
25:229	Finally, Section 6 discusses the implications of our results for semantic role assignment.
26:229	2 FrameNet FrameNet is a lexical resource based on Fillmores Frame Semantics (Fillmore, 1985).
27:229	It is designed as an ontology of frames, representations of prototypical situations.
28:229	Each frame provides a set of predicates (nouns, verbs or adjectives) which can introduce the frame.
29:229	The semantic roles are framespecific, since they are defined as categories of entities or concepts pertaining to the particular situation a predicate evokes.
30:229	The following sentences are examples for the semantic annotation provided in the FrameNet corpus for verbs in the IMPACT frame, which describes a situation in which typically an Impactor makes sudden, forcible contact with the Impactee, or two Impactors both [make] forcible contact3.
31:229	(1) a. [Impactee His car] was struck [Impactor by a third vehicle].
32:229	b. [Impactor The door] slammed [Result shut].
33:229	c. [Impactors Their vehicles] collided [Place at Pond Hill].
34:229	Note that the frame-specificity of semantic roles in FrameNet has important consequences for semantic role assignment, since there is no direct way to generalise across frames.
35:229	Therefore, the learning for automatic assignment of semantic roles has to proceed frame-wise.
36:229	Thus, the data sparseness problem is especially acute, and automatic assignment for frames with no training data is very difficult (see Gildea and Jurafsky (2002)).
37:229	3 Experiment 1: Frame-Wise Evaluation of Semantic Role Assignment In our first experiment, we perform a detailed (frame-wise) evaluation of semantic role assignment to discover general patterns in the data.
38:229	Our aim is not to outperform existing models, but to replicate the workings of existing models so that our findings are representative for the task as it is currently addressed.
39:229	To this end, we (a) use a standard dataset, the FrameNet data, (b) model the task with two different statistical frameworks, and (c) keep our models as generic as possible.
40:229	3.1 Data and experimental setup For this experiment, we use 57758 manually annotated sentences from FrameNet (release 2), corresponding to all the sentences with verbal predicates (2228 lemmata from 196 frames).
41:229	Gildea and Jurafsky (2000) and Fleischman et al.42:229	(2003) used a previous release of the dataset with less annotated instances, but covered all predicates (verbs, nouns and adjectives).
43:229	Data preparation.
44:229	After tagging the data with TnT (Brants, 2000), we parse them using the Collins parsing model 3 (Collins, 1997).
45:229	We consider only 3From the definition of the frame athttp://www.icsi.
46:229	berkeley.edu/~framenet/.
47:229	Examples adapted from the FrameNet data, release 2.
48:229	the most probable parse for each sentence and simplify the resulting parse tree by removing all unary nodes.
49:229	We lemmatise the head of each constituent with TreeTagger (Schmid, 1994).
50:229	Gold standard.
51:229	We transform the FrameNet character-offset annotations for semantic roles into our constituent format by determining the maximal projection for each semantic role, i.e. the set of constituents that exactly covers the extent of the role.
52:229	A constituent is assigned a role iff it is in the maximum projection of a role.
53:229	Classification procedure.
54:229	The instances to be classified are all parse tree constituents.
55:229	Since direct assignment of role labels to instances fails due to the preponderance of unlabelled instances, which make up 86.7% of all instances, we follow Gildea and Jurafsky (2000) in splitting the task into two sequential subtasks: first, argument recognition decides for each instance whether it bears a semantic role or not; then, argument labelling assigns a label to instances recognised as role-bearers.
56:229	For the second step, we train frame-specific classifiers, since the frame-specificity of roles does not allow to easily combine training data from different frames.
57:229	Statistical modelling.
58:229	We perform the classification twice, with two learners from different statistical frameworks, in order to make our results more representative for the different statistical models employed so far for the task.
59:229	The first learner uses the maximum entropy (Maxent) framework, which has been applied e.g. by Fleischman et al.60:229	(2003).
61:229	The model is trained with the estimatesoftware, which implements the LMVM algorithm (Malouf, 2002)4.
62:229	The second learner is an instance of a memory-based learning (MBL) algorithm, the a0 nearest neighbour algorithm.
63:229	We use the implementation provided by TiMBL (Daelemans et al. , 2003) with the recommended parameters, namely a0a2a1a4a3, adopting modified value difference with gain ratio feature weighting as similarity metric.
64:229	3.2 Features In accordance with our goal of keeping our models generic, we use a set of vary (syntactic and lexical) features which more than one study in the literature has found helpful, without optimising the features for the individual learners.
65:229	Constituent features: The first type of feature represents properties of the constituent in question.
66:229	We use the phrase type and head lemma of each constituent; its preposition (if available); its position 4Software available for download at http://wwwrohan.sdsu.edu/ malouf/pubs.html relative to the predicate (left, right or overlapping); the phrase type of its mother constituent; whether it is an argument of the target, according to the parser; and the path between target and constituent as well as its length.
67:229	Sentence level features: The second type of feature describes the context of the current instance.
68:229	The predicate is represented by its lemma, its part of speech, its (heuristic) subcategorisation frame, and its governing verb.
69:229	We also compile a list of all the prepositions in the sentence.
70:229	3.3 Results All results in this section are averages over F scores obtained using 10-fold cross validation.
71:229	For each frame, we perform two evaluations, one in exact match and one in overlap mode.
72:229	In exact match mode, an assignment only counts as a true positive if it coincides exactly with the gold standard, while in overlap mode it suffices that they are not disjoint.
73:229	F scores are then computed in the usual manner.
74:229	Table 1 shows the performance of the different configurations over the complete dataset, and the standard deviation of these results over all frames.
75:229	To illustrate the results for individual frames, Table 2 lists frame-specific performances for five randomly selected frames and how they varied over cross validation runs.
76:229	Maxent MBL Exact Match 53.3 a0 10.8 56.9 a0 10.1 Overlap 70.0 a0 11.0 74.2 a0 10.0 Table 1: Overall F scores and standard deviation across frames for Experiment 1.
77:229	3.4 Analysis and Discussion In terms of overall results, the MBL model outperforms the Maxent model by 3 to 4 points F-score.
78:229	However, all our results lie broadly in the range of existing systems with a similar architecture (i.e. sequential argument identification and labelling): Gildea and Jurafsky (2002) report a1 a1 a3 a3a3a2a5a4, and Fleischman et al.79:229	(2003) a1 a1 a3a7a6a8a2a10a9 for exact match evaluation.
80:229	We assume that our feature formulation is more suitable for the MBL model.
81:229	Also, we do not smooth the Maxent model, while we use the recommended optimised parameters for TiMBL.
82:229	Our most remarkable finding is the high amount of variance presented by the numbers in Table 1.
83:229	Computed across frames, the standard deviation amounts to 10% to 11%, consistently across evaluation measures and statistical frameworks.
84:229	Since these figures are results of a 10-fold cross validation run, it is improbable that the effect is solely Exact match Maxent MBL APPEARANCE 50.5 a0 4.5 60.1 a0 7.3 AVOIDING 47.9 a0 5.0 51.3 a0 6.9 JUDGM._COMM.
85:229	57.0 a0 1.5 57.5 a0 3.4 ROBBERY 38.4 a0 19.1 37.9 a0 16.2 WAKING_UP 60.5 a0 11.4 64.4 a0 11.8 Overlap Maxent MBL APPEARANCE 68.3 a0 4.0 75.0 a0 5.6 AVOIDING 68.6 a0 4.3 72.7 a0 5.9 JUDGM._COMM.
86:229	76.9 a0 1.6 77.6 a0 1.8 ROBBERY 61.2 a0 20.6 55.2 a0 17.6 WAKING_UP 75.1 a0 9.1 77.6 a0 7.8 Total Exact Match 53.3 a0 0.5 56.9 a0 0.4 Total Overlap 70.0 a0 0.4 74.2 a0 0.5 Table 2: F scores and standard deviations over cross validation runs for five random frames (Exp. 1).
87:229	due to chance splits into training and test data.
88:229	This assessment is supported by Table 2, which shows that, while the performance on individual frames can vary largely (especially for small frames like ROBBERY), the average performance on all frames varies less than 0.5% over the cross validation runs.
89:229	The reasons which lead to the across-frames variance warrant investigation, since they may lead to new insights about the nature of the task in question, answering Fleischman et al.s (2003) call for better models.
90:229	Some of the plausible variables which might explain the variance are the number of semantic roles per frame, the amount of training data, and the number of verbs per frame.
91:229	However, we suggest that a fourth variable might have a more decisive influence.
92:229	Seen from a linguistic perspective, semantic role assignment is just an application of linking, i.e. learning the regularities of the relationship between semantic roles and their possible syntactic realisation and applying this knowledge.
93:229	Therefore, our main hypothesis is: The more varied the realisation possibilities of the verbs in a frame, the more difficult it is for the learner to learn the correct linking patterns, and therefore the more error-prone semantic role assignment.
94:229	Even though this claim appears intuitively true, it has never been explicitly made nor empirically tested, and its consequences might be relevant for the design of future models of semantic role assignment.
95:229	As an example, compare the frame IMPACT, as exemplified by the instances in (1), with the frame INGESTION, which contains predicates such as drink, consume or nibble.
96:229	While every sentence in (1) shows a different linking pattern, linking for INGESTION is rather straightforward: the subject is usually the Ingestor, and the direct object is an Ingestible.
97:229	This is reflected in the scores: a1 a1 a3a7a6a8a2a1a0 for IMPACT and a1 a1 a6a2a0 a2a10a9 for INGESTION (exact match scores for the MBL model).
98:229	The most straightforward strategy to test for the different variables would be to perform multiple correlation analyses.
99:229	However, this approach has a serious drawback: The results are hard to interpret when more than one variable is significantly correlated with the data, and this is increasingly probable with higher amounts of data points.
100:229	Instead, we adopt a second strategy, namely to design a new data set in which all variables but one are controlled for and correlation can be tested unequivocally.
101:229	The new experiment is explained in Section 5.
102:229	Section 4 describes the quantitative model of argument structure required for the experiment.
103:229	4 Argument Structure and Frame Uniformity In this section, we define the concepts we require to test our hypothesis quantitatively.
104:229	First, we define argument structure for our data in a corpus-driven way.
105:229	Then, we define the uniformity of a frame according to its variance in argument structure.
106:229	4.1 An Empirical Model of Argument Structure Work in theoretical linguistics since at least Gruber (1965) and Jackendoff (1972) has attempted to account for the regularities in the syntactic realisation of semantic arguments.
107:229	Models for role assignment also rely on these regularities, as can be seen from the kind of features used for this task (see Section 3.2), which are either syntactic or lexical.
108:229	Thus, current models for automatic role labelling rely on the regularities at the syntax-semantics interface.
109:229	Unlike theoretical work, however, they do not explicitly represent these regularities, but extract statistical properties about them from data.
110:229	The model of argument structure we develop in this section retains the central idea of linking theory, namely to model argument structure symbolically, but deviates in two ways from traditional work in order to bridge the gap to statistical approaches: (1), in order to emulate the situation of the learners, we use only the data available from the FrameNet corpus; this excludes e.g. the use of more detailed lexical information about the predicates.
111:229	(2), to be able to characterise not only the possibility, but also the probability of linking patterns, we take frequency information into account.
112:229	Our definition proceeds in three steps.
113:229	First, we define the concept of a pattern, then we define the argument structure of a predicate, and finally the argument structure of a frame.
114:229	Patterns.
115:229	A pattern encodes the argument structure information present in one annotated corpus sentence.
116:229	It is an unordered set of pairs of semantic role and syntactic function, corresponding to all roles occurring in the sentences and their realisations.
117:229	The syntactic functions used in the FrameNet corpus are as follows5: COMP (complement), EXT (subject in a broad sense, which includes controlling subjects), OBJ (object), MOD (modifier), GEN (genitive modifier, as John in Johns hat).
118:229	For example, Sentence (1-a) gives rise to the pattern a3a5a4 Impactee a6 EXTa7a8a6 a4 Impactor a6 COMPa7a10a9 which states that the Impactee is realised as subject and the Impactor as complement.
119:229	Argument Structure for Predicates and Frames.
120:229	For each verb, we collect the set of all patterns in the annotated sentences.
121:229	The argument structure of a verb is then a vector a11a12, whose dimensionality is the number of patterns found for the frame.
122:229	Each cell a12a5a13 is filled with the frequency with which pattern a14 occurs for the predicate, so that the vector mirrors the distribution of the occurrences of the verb over the possible patterns.
123:229	Finally, the set of all vectors for the predicates in a frame is a model for the argument structure of the frame.
124:229	The intuition behind this formalisation is that two verbs which realise their arguments alike will show a similar distribution of patterns, and conversely, if they differ in their linking, these differences will be mirrored in different pattern distributions.
125:229	Example.
126:229	If we only had the three sentences in (1) for the IMPACT corpus, the three occurring patterns would be {(Impactee, EXT), (Impactor, COMP)}, {(Impactor, EXT), (Result, COMP)}, and {(Impactors, EXT), (Place, MOD)}.
127:229	The argument structure of the frame would be a15 a16a18a17a20a19a21 a4 a0 a0 a22a23 a6 a19a21 a0 a4 a0 a22a23 a6 a19a21 a0 a0 a4 a22a23a25a24a18a26 a27 containing the information for the predicates strike, slam and collide, respectively.
128:229	The variation arises from differences in syntactic construction (e.g. passive vs. active), but also, more significantly, from lexical differences: collide accepts a reciprocal plural subject, i.e. an Impactors role, while strike does not.
129:229	This model is very simple, but achieves the 5See Johnson et al.130:229	(2002) for details.
131:229	goal of highlighting the differences and similarities in the mapping between semantics and syntax for different verbs in a frame.
132:229	4.2 Uniformity of Argument Structure At this point, we can define a measure to compute the uniformity of a frame from the frames argument structure, which is defined as a set of integer-valued vectors.
133:229	Similarity metrics developed for vector space models are obvious candidates, but work in this area has concentrated on metrics for comparing two vectors, whereas we may have an arbitrary number of predicates per frame.
134:229	Therefore, we borrow the concept of cost function from clustering, as exemplified by the well known sum-of-squares function used in the k-means algorithm (see e.g. Kaufman and Rousseeuw (1990)), which estimates the cost of a cluster as the sum of squared distances a0 between each vector a11a12 a13 and the cluster centroid a11a1 : 6 a2 a4 a11 a12a4a3 a6 a2 a2 a2 a6 a11 a12a6a5 a7 a1 a5 a7 a13a9a8a10a3 a0 a4 a11 a12a2a13 a6 a11 a1 a7a12a11 Under this view, a good cluster is one with a low cost, and the goal of the clustering algorithm is to minimise the average distance to the centroid.
135:229	However, for our purposes it is more convenient for a good cluster to have a high rating.
136:229	Therefore, we turn the cost function into a quality function.
137:229	By replacing the distance function with a similarity function a13, we say that a good cluster is one with a high average similarity to the centroid: a14 a4 a11 a12 a3 a6 a2 a2 a2 a6 a11 a12 a5 a7 a1 a5 a7 a13a15a8a10a3 a13 a4 a11 a12 a13 a6 a11 a1 a7 a11 If we consider each frame to be a cluster and each predicate to be an object in the cluster, represented by the argument structure vector, the values of a14 can be interpreted as a measure for frame uniformity: Verbs with a similar argument structure will have similar vectors, resulting in high values of a14 for the frame, and vice versa.
138:229	What intuitively validates this formalisation is that frames are clusters of predicates grouped together on semantic grounds, i.e. predicates in a frame share a common set of arguments.
139:229	What a14 checks is whether the mapping from semantics to syntax is also similar.
140:229	6The centroid of a cluster is a point in a16 -dimensional space found by averaging the measurement values along each dimension (Kaufman and Rousseeuw, 1990, p. 112), so that it is the point situated at the center of the cluster.
141:229	In order to obtain an actual measure for frame uniformity, we take two further steps.
142:229	First, we instantiate a13 with the cosine similarity a1a18a17 a13, which has been found to be appropriate for a wide range of linguistic tasks (see e.g. Lee (1999)) and ranges between 0 (least similar) and 1 (identity): a1a18a17 a13 a4 a11 a12a19a3 a6 a11 a12 a11 a7 a1 a20 a5 a13a15a8a10a3 a12a4a3a22a21a13a24a23 a12 a11 a21a13 a25 a20 a5 a13a15a8a10a3 a12 a11 a3a22a21a13 a25 a20 a5 a13a15a8a10a3 a12 a11 a11 a21a13 Second, we normalise the values of a14, which grow in a26 a4a28a27 a7, the number of vectors, to a29 a0a31a30 a4a33a32, to make them interpretable analogously to values of the cosine similarity.
143:229	Since this is possible in two different ways, we obtain two different measures for frame uniformity.
144:229	The first one, which we call normalised quality-based uniformity (a34a19a35 ), simply divides the values by a27 : a34a19a35 a4 a11 a12a4a3 a6 a2 a2 a2 a6 a11 a12a6a5 a7 a1 a4 a27 a5 a7 a13a9a8a10a3 a29 a1a18a17 a13 a4 a11 a12 a13 a6 a11 a1 a7 a32 a11 The second measure, weighted quality-based uniformity (a36a37a34a19a35 ), is a weighted average of the similarities.
145:229	The weights are given by the vector sizes  in our case, the frequency of the predicates: a36a38a34a39a35 a4 a11 a12a4a3 a6 a2 a2 a2 a6 a11 a12a6a5 a7 a1 a4 a20 a5 a40 a8a10a3a10a41 a11 a12 a40 a41 a5 a7 a13a15a8a10a3 a41 a11 a12a2a13 a41 a29 a1a18a17 a13 a4 a11 a12 a13 a6 a11 a1 a7 a32 a11 The weighting lends more importance to wellattested predicates, limiting the amount of noise introduced by infrequent predicates.
146:229	Therefore, our intuition is that a36a37a34a19a35 should be a better measure than a34a19a35 for argument structure uniformity.
147:229	5 Experiment 2: Explaining the Variance With Argument Structure With two measures for the uniformity of argument structure at hand, we now proceed to test our main hypothesis.
148:229	5.1 Data and Experimental Setup As argued in Section 3.4, our aim in this experiment is to control for the most plausible sources of performance variance and isolate the influence of argument structure.
149:229	To meet this condition, we perform both the experiments and the uniformity measure calculation on a controlled subset of the data, with the condition that both the number of verbs and the number of sentences are the same for each frame.
150:229	Following the methodology in Keller and Lapata (2003), we divide the verbs into four frequency bands, frequency being absolute number of annotated sentences: low (5), medium-low (12), medium-high (22), and high (38).
151:229	We set the boundaries between the bands as the quartiles of all the verbs containing at least 5 annotated examples7.
152:229	For each frame, 2 verbs in each frequency band are randomly chosen.
153:229	This reduces our frame sample from 196 to 40.
154:229	We furthermore randomly select a number of sentences for each verb which matches the boundaries between frequency bands, that is, all verbs in each frequency bands are artificially set to have the same number of annotated sentences.
155:229	This method assures that all frames in the experiment have 8 verbs and 154 sentences, so that both the performance figures and the uniformity measures were acquired under equal conditions.
156:229	The models for semantic role assignment were trained in the same way as for Experiment 1 (see Section 3.1), using the same features.
157:229	We also performed 10-fold cross validation as before.
158:229	The uniformity measures a34a19a35 and a36a37a34a19a35 were computed according to the definitions in Section 4.2.
159:229	5.2 Results and Discussion Table 3 shows the overall results and variance across frames for the new dataset.
160:229	Table 4 contains detailed performance results (Columns 1 and 2) and uniformity figures (Columns 3 and 4) for five randomly drawn frames.
161:229	Maxent MBL Exact Match 47.5 a0 11.0 53.4 a0 11.1 Overlap 66.4 a0 11.0 72.4 a0 9.9 Table 3: Overall F scores and standard deviation across frames for Experiment 2.
162:229	The overall results for the new, controlled dataset are 3 to 5 points F-score worse than in Experiment 1, which is a result of the artificial limitation of larger frames to fewer training examples.
163:229	Otherwise, the same tendencies hold: The memory-based learner again performs better than the maximum entropy learner, and overlap evaluation returns higher scores than exact match.
164:229	More relevantly, the data show the same amount of variance across frames as before (between 10 and 11%), even though the most plausible sources of variance are controlled for.
165:229	The variation over cross validation runs is somewhat larger, but still small (2.0%/1.9% for Maxent and 0.9%/0.8% for MBL, respectively).
166:229	We can now test our main hypothesis through an analysis of the correlation between performance and 7We consider 5 to be the (very) minimum number of instances necessary to construct a representative argument structure for a predicate.
167:229	Exact match Maxent MBL a34a19a35 a36a37a34a19a35 BODY_MOVMT.
168:229	51.2 57.5 33.0 39.0 COMMERCE 25.7 41.9 27.4 31.1 MOTION 54.6 58.1 57.2 60.8 PERC._ACTIVE 52.1 51.5 30.0 35.4 REMOVING 59.3 60.1 58.7 64.2 Overlap Maxent MBL a34a19a35 a36a37a34a19a35 BODY_MOVMT.
169:229	56.4 64.8 33.0 39.0 COMMERCE 48.9 66.4 27.4 31.1 MOTION 68.1 71.9 57.2 60.8 PERC._ACTIVE 69.3 69.0 30.0 35.4 REMOVING 76.1 77.2 58.7 64.2 Table 4: F scores and frame uniformities for data from Exp. 2.
170:229	a34a39a35 = normalised uniformity, a36a37a34a19a35 = weighted uniformity (in percentages).
171:229	uniformity figures.
172:229	We log-transformed both variables to guarantee normal distribution and used the standard Pearson product-moment correlation coefficient, testing for positive correlation (higher uniformity  higher performance).
173:229	The results in Table 5 show that all correlation tests are significant, and most are highly significant.
174:229	This constitutes very good empirical support for our hypothesis.
175:229	Exact match Maxent MBL a34a19a35 0.39 (a0 =0.007) 0.33 (a0 =0.04) a36a37a34a19a35 0.45 (a0 =0.002) 0.35 (a0 =0.01) Overlap Maxent MBL a34a19a35 0.54 (a0 <0.001) 0.50 (a0 <0.001) a36a37a34a19a35 0.58 (a0 <0.001) 0.55 (a0 <0.001) Table 5: Pearson coefficients a1 a11 and significance levels for correlating frame performance and frame uniformity for the dataset from Experiment 2.
176:229	We find that a36a38a34a19a35 yields consistently higher correlation measures (and therefore more significant correlations) than a34a19a35, which supports our hypothesis from Section 4 that a36a37a34a19a35 is a better measure for argument structure uniformity.
177:229	Recall that the intuition behind the weighting is to let well-attested predicates (those with higher frequency) have a larger influence upon the measure.
178:229	However, an independent experiment for the adequacy of the measures should be devised to verify this hypothesis.
179:229	A comparison of the evaluation modes shows that frame uniformity correlates more strongly with the overlap evaluation measures than with exact match.
180:229	We presume that this is due to the evaluation figures in exact match mode being somewhat noisier.
181:229	All other things being equal, random errors introduced during the different processing stages (e.g. parsing errors) are more likely to influence the exact match outcome: A processing error which leads to a partially right argument assignment will influence the outcome of the exact match evaluation, but not of the overlap evaluation.
182:229	As for the two statistical frameworks, uniformity is better correlated with the Maxent model than with the MBL model, even though MBL performs better on the evaluation.
183:229	However, this does not mean that the correlation will become weaker for semantic role labelling systems performing at higher levels of accuracy.
184:229	We compared our current models with an earlier version, which had an overall lower performance of about 5 points F-score.
185:229	Using the same data, the correlation coefficients a1 a11 were on average 0.09 points lower, and the p-values were not significant for the Maxent model in exact match mode.
186:229	This indicates that correlations tend to increase for better models.
187:229	Therefore, we attribute the difference between the Maxent and the MBL model to their individual properties, or more specifically to differences in the distribution of the performance figures for the individual frames around the mean.
188:229	While they are more evenly distributed in the MBL model, they present a higher peak with more outliers in the Maxent model, which is also reflected in the slightly higher standard deviation of the Maxent model (cf.
189:229	Tables 1 and 3).
190:229	In short, the Maxent model appears to be more sensitive to differences in the data.
191:229	Nevertheless, both models correlate strongly with each other in both evaluation modes (a1 a11 a1 a0 a2 a6a1a0, a0 <0.001 for exact match, a1 a11 a1 a0 a2a3a2 a9, a0 <0.001 for overlap).
192:229	Thus, they agree to a large extent on which frames are easy or difficult to label.
193:229	Our present results, thus, seem to indicate that the influence of argument structure cannot be solved by simply improving existing systems or choosing other statistical frameworks.
194:229	Instead, there is a systematic relationship between the uniformity of the argument structures of the predicates in the frames and the performance of automatic role assignment.
195:229	6 Conclusion and Outlook In this paper, we have performed an error analysis for semantic role assignment, concentrating on the relationship between argument structure and semantic role assignment.
196:229	To obtain general results, we kept our models as general as possible and verified our results in two different statistical frameworks.
197:229	In our first experiment, we showed that there is considerable variance across frames in the performance of semantic role assignment, and hypothesised that the effect was due to the varying difficulty of the underlying argument structure.
198:229	To test the hypothesis, we defined a measure of frame uniformity which modelled the variability of argument structure.
199:229	In a second experiment, in which we controlled for other plausible sources of variance, we showed a reliable correlation between performance and uniformity figures.
200:229	The underlying reason for the difficulty of semantic role assignment is that FrameNet is essentially an ontological classification.
201:229	While the predicates of one frame share the same semantic arguments, they can vary widely in their linking patterns.
202:229	Without unlimited training data, automatic role assignment has to find and exploit regularities in linking to achieve good results.
203:229	A priori, this can only be done within frames, since roles are frame-specific, and there is no unique right mapping between roles.
204:229	Consequently, as observed by Fleischman et al.205:229	(2003), relatively rare constructions, such as passives, are frequent error sources.
206:229	Because such constructions have to be learnt individually for each frame, data sparseness is a serious issue.
207:229	A similar problem arises for lexical differences in the linking properties of predicates in a frame, as with the collide vs. strike case discussed above.
208:229	Here, the learning has to take into account that the relevant linking properties differ between individual predicates.
209:229	Our results suggest that the variance caused by argument structure will not disappear with better classifiers, but that the problem of inadequate generalisations should be addressed in a principled way.
210:229	There are several possible approaches to do so.
211:229	First, the classic statistical approach: Combining evidence from different frame-specific roles to alleviate data sparseness.
212:229	To this end, Gildea and Jurafsky (2002) developed a mapping from framespecific to syntactic roles, but results did not improve much.
213:229	Baldewein et al.214:229	(2004) experiment with EM-driven generalisation, and obtain also only modest improvements.
215:229	A second approach is to identify other levels, different from frames, at which regularities can be learnt better.
216:229	One possibility is to identify smaller units within frames which have a more uniform structure and which can be learnt more easily.
217:229	Since uniformity is defined in terms of a quality function, clustering would be the natural method to employ for this task.
218:229	However, this method is only viable for frames with a large amount of annotation.
219:229	A more general idea in this spirit is to construct an independent classification of verbs motivated at the argument structure level (transitive, intransitive, unaccusative, etc.), e.g. using data sources like Levins verb classes (Levin, 1993).
220:229	This would allow models to learn class-specific regularities and diathesis alternations more easily.
221:229	However, it is unclear if there is a unique level at which all relevant regularities can be stated.
222:229	A more realistic variant might be to map FrameNet roles to an existing, more syntactically oriented role set, such as PropBank.
223:229	These roles can serve as an intermediate level to capture mapping regularities, and can be translated back to semantically defined FrameNet roles when the mapping has been accomplished.
224:229	A third, different approach to semantic role assignment is presented by Frank (2004), who presents a syntax-semantics interface to extract symbolic frame element projection rules from an LFG-annotated corpus and discusses strategies to generalise over these rules.
225:229	Such an approach is, due to the finer control over the generalisation, not as susceptible to the problem described in this study as purely statistical models.
226:229	However, it has yet to be tested on large-scale semantic role assignment.
227:229	Acknowledgements We are grateful to Katrin Erk, Alexander Koller and three anonymous reviewers for helpful comments on previous versions of the paper.
228:229	We also thank the audiences at the Prospects and Advances in the Syntax/Semantics Interface Workshop in Nancy and the Computational Linguistics Seminar at UPF for their suggestions.
229:229	This work is supported by the Departament dUniversitats, Recerca i Societat de la Informaci (grant 2001FI-00582, Gemma Boleda).

