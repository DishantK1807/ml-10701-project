Long-Distance Dependencies and Applicative Universal Grammar Sel)astian Shaumyan Yale University, U.S.A., e-maih shaumyan@minerva.cis.yale.edu Fr6d~rique Segond Rank Xerox Research Centre, France, e-maih fi~ederique.~egond@xerox.fr Abstract To deal with long-distance dependencies, Applicative Universal Grammar (AUG) proposes a new type of categorial rides, called superposition rules.
We compare the AUG rules with the alternative rules of Steedman's Combinatery Categorial Grammar (CCG) (Steedman, 1987, 1988, 1990; Szabolcsi, 1987; Ades and Steedman, 1982).
In contrast to Steedtmm's rules, the AUG rules are free from inconsistencies in their semantic interpretation, fi'ee from spurious ambiguity.
"lhe superposition rules arc based on the Theory of Type Supetposition, established independently of the problem of long-distance dependencies and having a broad unifying power.
I. Characterization of Applicative Universal Grammar Applicative Universal Grmnmar (AUG) is a linguistic theory that uses the lormalism of catcgorial g~unmar,as a means for representing the structure of language.
AUG has two levElS: 1) lhe study of the grammatical slructurc in itsclt (genotype grammar), ~md 2) the study of the linear representation of the grammatical structure (phenotype grammar).
AUG includes a system of combinators (Curry and Feys, 1958),'rod fi)nnulates semiotic concepts, principles, and laws that dctcnninc tile fimctioning of natur~d languages,as sign systems (for a complete description of AUG, see Shaumyan, 1974, 1977, 1987; Dcsci6s, 1990; Scgond, 1990a; some applications of AI \]G arc discussed in Shaumyan 1989, 1991).
AUG is based on the relation operator-operand, which corresponds to the relation fi~nction-argument in categorial grmnmar.
We prefer the terms operator-operand for reasons similar to those given by llindley and Seldin (1986, pp.
44-45). In AI IG categories are generated rccursively by the type-forming operator O, and are called O-types.
AUG recognizes two primitive types--terms (nouns and noun-phrases) and sentences, denoted by t mid s, respectively.
The rule for generating O-types is: 1) The primitive types t and s are O-types.
2) If x and y m'e O-types, then Oxy is an O-lype.
(1) For the sake of brevity, we use the term type in the sense of the O-type.
Taking t and s as primitives, wc generate the inductive class of types: t, s, Ott, Oss, Ots, Ost, OtOts, OOtsOts, and so on.
In representing the types we u~ the parentheses-free Polish notation, which is more convenient than Curry's nolation with internal parentheses.
The basic rule of combination of phrases is the Rule of Phrase Application, which is defined as follows: Phrase A of type Oxy, called an operator, combines with phrase B of type x, called its operand, to form phrase AB of type y, called its resultant: Oxy A x B y (AB) (2) The applicative tree of (2) has the form: y (AB) Oxy A x B (3) "llm concept of immediate constituents is defined as: If phrase A is ml operator and phm~ B is its operand, then they,are inunediate constituenls of file resultant (AB).
(4) The concept of closeness is defined as: (liven phrases A and B that are immediate constituents of phrase (AB), if A is a complex phrase comprising immcdiate constituents C and D, then the syntactic and semantic connEction between C and D is closer than the syntactic m~d scmanlic connection between A and B.
(5) Under definition (5) various degrees of relative closeness of syntactic and semantic connection between immediate constituents me distinguished depending on the complexity of a phrase.
in phenotype grmnmm" the application operation is constrained by two principles: the Principle of Adjacency of Operators and Their Operands and the Principle of Uniqueness of hmnediate Constituents.
l'rinciple of Adjacency of Operators and Their Operands: An operator and its operand must be adjacent elements of a sequence, so that tile operator either directly precedes or directly follows its oper,-md.
(6) Under file Adjacency l'rinciplc we have two new rules -the notational wuiants of operator application: one for torward combination mid one for backward combination: Oxy A x B y (AB) (7) 853 x A Oxy B y (AB) (8) These rules are called the Linear Precedence Rules'.
An alternative notation for these rules splits the type-forming operator O iuto indexed type-fot~ning operators O r and 0 l which generate types of the form Orxy and Otxy.
The operator of type O~xy has its operand on its right, and file operator of type OtxY has its operand on its left.
So the Linear Precedence Rules may be presented as follows: Orxy A x B y (AB) (9) x A Olxy B y (AB) (10) llere is an exmnple of applying this notation: OrtOtts bought t newspapers t John Ods bought newspapers s John bought newspapers (11) Given file Rule of Phrase Application and Linear Prccedence Rules, we can combine tile two rule formats into one system, as is done with the corresponding rule formats in Generalized Phrase Structure Greanmar (Gazdar et al., 1985: 44-50).
Principle of Uniqueness of immediate Constituents': If phrase A aud phrase B are immediate constituents of phrase C, then neither A uor B can be an immediate constituent of another phrase D.
(12) qb illustrate, consider the sentence: John loves vodka.
Here loves and vodka are the immediate constituents of (loves vodka), enid John.aud (loves vodka) are tile hnmediate constituents of (John (loves vodka)), tinder the alxwe constraint, this analysis precludes analyzing this sentence as: ((John loves) vodka).
In terms of "algebra, the Principle of Uniqueness of hnmediate Constituents con'esponds to non-associativity: AUG is a non-associative system.
To make the AUG notation compact, we introduce recursively defined adjoined symbols (Shaumyan 1987: 199): A type symbol is called adjoined if it is introduced into tile type system by a definition of file form: Z = Oxy where z denotes,'m adjoined type and Oxy denotes a type where x and y are either other,adjoined type symbols, oft, ors.
(13) This type of definition is called definitional reduction.
By this process all adjoined type symbols are defined ill terms of the uithnate definientia t,'rod s.
We can introduce as many adjoined type symbols as we need.
llere are examples of the definitional reduction for adjoined type symbols that will be used below: PI = Ots P2 = Oqh = OtOts P3 = Otpz = OtOtOts d I = OplPl = OOtsOts d2 = OP2 P2 = OOtplOt Pl = OOtOtsOtOts (14) AUG clahns that a typology of word order must be based on a comparison of specific word orders in individual languages with a canonical word order as defined in genotype gr,-anmar.
The canonical word order requires that an operator precedes its adjacent operand.
For ex,'unple, the canonical form of file sentence My older brother bought an interesting book yesterday is: (yesterday ((bought (an (interesting book))) (my (oMer brother)))).
2. Long-Distance Dependencies in CCG Consider, for example, the phrase Apples which Harry eats.
This phrase contains three sets of binary dependences: 1) apples-eats, 2) which-eats, and 3) Harry-eats.
The first two sets consist of discontinuous constituents.
This is ml iastauce of file phenomenon called intersecting dependencies.
Intersecting dependencies arise when one set of discontinuous constituents is intercalated by another set of discontinuous constituents in the surface expression.
To find au adequate formed characterization of discontinuous constituents and intersecting dependencies is one of the cenla~d problems for categorial gr,'umnar, as lbr auy linguistic theory timt is concerned with linear representation of expressions.
This problem induced some linguists to introduce new rules extending the tbnnalism of categori~d gramm~u'.
Sleedman's Combiuatory Categorial Grammar (CCG) proposes file following,-malysis of the phrase Apples which Harty eats (1987:415; presented hcrc in the AUG notation): (apples) which llarty OOtsOtt OOtss Ott eats OtOts Â¢OIII|X)Se backward Ots apply forward (15) In (15), subject type raising (assigning OOtss to Harry) in coujuuction with composition is used to resolve tile difficulty caused by gapping involved ill the extraction of the direct object of the finite verb eats.
Forward and backward composition,are dclined as follows (ill terms of AUG): Under the rule of "compose forward", A of type Oxy and B of type Oyz combine to yield the result (AB) of type Oxz.
Under the rule of "compose backward", A of type Oyz aud B of type Oxy comhinc to yield the result (AB) of type Oxz.
(16) Type rai~ing is defiue(l as,'m operation whereby an oper-,'rod acquires a new type that turus it into,'m operator over its operator.
The general rule of type raising in tile AUG notation is: x -~ OOxyy (17) 854 For exmnple, subject type raising is delined in lerms of AUG as follows: Subject type raising is a proccss by which a subject of type t acquires the type OOtss, which turns it into an opcmtor over the predicate (51 type Ots.
(l 8) As,'mothcr examplc of the ~m;dysis Ihat uses type raising, let us eonsidcr the scntcnce John loves Mary wiMly and Sue madly (Bouma, 1989: 25).
Using typc raising and compositiou, the analysis of this sentence can be presenlcd as follows in |he AI.
IG notation: John loves Mary wiMly and Sue nuMly t P2 t Op2P2 OxOxx t Op2P2 raise object Op2Pl OP2Pl COl I|\[)OSP,..... backward OP2P 1 O1)215 I apply for w,'ml ......
(X)P2Pl ()p2pl apply I~mkward OP2Pl ............. apply backward Pt apply I)ackward s (19) in (19), to resolve the difficulty caused by gapping involved in the coordination operation, object type raisiug is used (assigning OP2Pl to Mary and Sue) ahmg with composition.
l)oes lhe CCG machinery produce adequate syntactic and semaulic represenlations of the stn~cturc of a sentence?
What is the semantic interpretation (51 type raising?
It is ckfimed lhat Ilm nominative case moq)hology in laliguages like 1,atin delermines a noun-phrase argument like Balbus to be something that must combine with a predicate (Steedman, 1990: 22l).
But case endings ~e not reliablc criteria for detc,'mining facts of syntax and selnalllics, lit Russiml and lnally oilier languages thc lIOlllinativc h~Ls no cndings.
Scmantic~dly, predicate + subject is an attributivc conncclion just as adjectival modiJier + subject, lÂ¥cdieate and a((jcctival modificr arc determining members, and sul)jcct is thcir determined member.
Accordingly, wc get tile prolx)rtion: predicate : subject = adjectival modifier : subject (20) This means that if the synlactic categorial system is to confi)rm to the semantic catego,'ial system, predicates must be operators over subjects just as adjee|ives.
Type raising transforming sut)jeets inlo operators over predicates conllicts with the scmmllie categorial system.
Furthermore, if in (19) we have a correct analysis of e(~)rdination, we should bc able to deduce the two interpretations of the scntence John loves Mary wildly and Sue madly: "John loves Mary wildly, aud John loves Sue madly" mid "John loves Mmy wildly, and Sue loves M,-u'y madly".
This is a classic case of mnbiguity with co(n'dina~ tion (we do not know if the second conjunct is subject or object).
Unfortunately CCG fails to distinguish I)ctween thc two interpretations.
The other well-known prot)lem with type raising is spurious ambiguity.
Spurious mnbiguity is multiple mmlyses of one sentence, Idl o1' them related to file s~unc seinautic interpretation.
For instance, just by using subject and ol~icct type raising one obtains four different analyses ti)r a simple sentence: John loves Mary t Otp I t -~ s ()pl s OtPl t --> s Opls OtPl Opzpl ~ > s t ()lPl Op2Pl ~ s (20 These lour a\[mlyses arc associated with just one motoring: ((loves Mary) John).
There m'e other difficulties with type raising.
We see that in (19) (Mary wildly) and (Sue madly) m'e assigned type OP2Pl, which is associated with the accusative luucli(nL It is very dillicult to accept that (Mary wildly) or (Sue madly) are direct objects of low', or that they arc at all colnpatitsle.
The correct analysis is: the adverbs wildly and mad@ me modifiers of the verb love,,'rod the nouns Mary and Sue are direct objects of the verb love.
(Mary wildly) and (Sue madly) arc phantom coustituenls Ihat (1o IIO1 correspoll(l I(1 ~uly synlaetic or SeluaulJc reality.
Type raising corresponds to Ihe coml)inator C.
and composithm correspond to combinator B.
Both m'c powerful tools when properly used.
One of tim conditions of Ilmir l)rope r use is respect for constituency.
A(1G uses these combinators widely when their usc is justified.
The main sin oi' CC(; is that it fails to recognize Ilmt synlaclic al|d semantic connections are non-associative.
CC(; bmls liom linguistics Ilm norm~d non-~tssocialive constituency mmlysis based on the explicit or implicit rccognilion of the hierarchy of relative syntactic m~d semmdic clo~IleSS of cOnlleCliOllS betwecll inunediate conslituents of a sentence.
3. The AUG Theory of Type Superposition An altcrnativc method of parsing gapping consmlcthms is based on Ihc Thcory of Typc Superpositi(m.
"1o explain our new method, wc need to outline this theory briclly.
( ;iron a synlactic unit, a secondary syntaclic type may bc supelposed on its inhercnl, primaxy syntactic tylx: so as to form a new bislralal, syncretic type.
For exmnple, when the suflix -ing is used to change Ihe linite form of Ilm verb to itlslruct into a verbal noun-the so-called gerundinstructing, wc have a ease of the supcrposition of type t on type OtOts.
Thc verNd noun retains thc synlaetie rimelion of Ihe verb to inslruct: it can lake an ot'dcct in the accusative (on instructing him) and an adverb (He suggested our immediately instructing them).
The s~unc is line of Ihe I~nglish or French inlinilives: they behave both like verbs and nouns.
For exmnplc, ill tile Frellch senl~llec Life des livres est divertissant or in the English scntence "lb read books isfim the infinitivcs lake direct objccts likc finite verbs and simultaneously are subjects like nouns.
The suflix -ing (or any olher similar device) we call a 8:;5 superposer, and the finite form of the verb to instruct with respect to the suffix -ing we call the superponend of -ing.
The suffix -ing superposes the syntactic type t on the syntactic type OtOts of the verb to instruct so as to combine them into a new syncretic syntactic type.
We can formalize the notion ofsuperposition,as follows: Let E be an expression of type x, and let E take on type y on type x.
Then E shall be said to belong to type z such that z is stratified into y superposed onto x.
Type z is represented by the formula: <y:x) (22) where the colon C) indicates the stratification of type z into y superposed on x enclosed into angle brackets.
The right part of the formula indicates the primary type of E, and its left part indicates the secondary type of E.
Definition of superposer: An operator R of type Ox<y:x> shall be called a superposer.
(23) Rule of Superposition: Ox<y:x> A x B <y:x> (AB) (24) Type superposition has important consequenccs both for linguistic theory mid computational linguistics, the discussion of which is beyond the scope of the present paper.
We will only focus on the topic of our paper--long-distance dependences.
For the lack of space we must confine ourselves to some examples of our approach that conceru topicalization, relative clauses, and gapping (a detailed presentation of the theory of type superposition is given in Shaumyan and Segond, 1993).
4. Long-Distance Dependencies in AUG We propose a new approach to parsing gapping sentences that allows us to dispense with the concept of type raising.
AUG claims that gapping superposes secondary types on primary types of the adjacent syutactic units of a sentence, thereby establishing new relations betwecn them on top of the old ones preserved in superposition.
Here is the AUG alternative analysis of the phrase in (15): (apples) which Harry eats OxOtt t OtOts SUl)etl)ose dis ~Ots:OtOts> apply backward S apply forward Ott (25) Under the characterization of superposition in the foregoing section, the obligatory absence of the adjacent direct object in apples which Harry eats is a contextual operator superposing type Ots on type OtOts of eats.
Thc superposition yields the same result as the hypothetical application of eats to its absent direct object.
That is, the secondary type of eats is equivalent to the type of the hypothetical combination eats' + direct object.
Then, the application of eats to Harry results in Harry eats of type s.
Following Benveniste's analysis of relative pronouns (1966: 208-224), we consider them operators having variable operands; hence, type OxOtt is assigned to which.
Type superposition is a strictly fonn,-d concept reflecting observable formal processes of language.
There are observable strictly formal criteria for defining superposition.
A derived syntactic unit with a syncretic type is always more complex than the initial one; it consists of two parts: initial syntactic unit + superposer.
So read-ing, where -ing is a superposcr, is more complex than read.
But where are formal markers of superposition in (25)?
The answer is that superposers, as all other language items,,are signs, and a sign is not necessarily a sequence of sounds.
It may be a change of stress, an alternation, a change of word order, a change of grammatical context, etc.
(ShaumymL 1987: 3-5).
In (25) the syntactic configuration of the phrase apples which Harry eats contains observable contextual signs of superposition.
To do justice to this fact we have to use an adequate formalism.
AUG includes two principles to describe superposition: the Principle of Elimination of Empty Constituents and the Principle of Syntactic Assimilation.
Principle of Elimination of Empty Constituents': Given a syntactic group of an operator A of type Oxy and its operand B of type x, either A or B may be empty: 1) if B is empty, empty B serves as a contextual sign superposiug type y on type Oxy of A, so that A is assigned the syncretic type <y:Oxy~; and 2) ifA is empty, empty A serves as a contextual sign superposing type y on type x of B, so that B is assigned the syncretic type <y:x~.
(26) The Principle of the Elimination of Empty Constituents eharactcrizes natural syntactic connectivity.
When in the group operator:operand file empty operand is eliminated, the operator represents the whole group and is assigned the type of the whole group.
Conversely, when in the group operator:operand the empty operator is eliminated, the operand represents the whole group and is assigncd thc type of the whole group.
Lct us turn to the senteuce John loves Mary wildly and Sue madly in (19).
As was said above, this sentence is,'unbiguous: Sue may bc a subject or,an object.
A correct syntactic analysis of this sentence must reflect this semantic ambiguity.
Dcpending on two possible iutcrpretations of this sentence, we discover two different gappings here: "John loves Mary wildly, and \[loves\] Sue madly" and "John loves Mary wildly, and Sue \[loves Mary\] madly".
In the light of the lhiuciple of Elimination of Empty Constituents, AUG proposes the following two mmlyses of the sentence to reflect two different gappings: 856 John loves Mary t P2 t apply -f6rward Pl apply bael~ward wiMly and OPlPl OxOxx Pl Pl llovesl Sue madly t OPlPl superpose Pl -<Pl:t> apply backward Pl â¢ apply OPlP 1 forward apply backward (27) John loves Mary wildly and Sue ltoves Mary\] madly t P2 t OPlPl OxOxx t OplPl -apply superpose Pl f6rw~d Pl ~PI:OPlPl > apply apply bacl~ward bacl~ward Pl S ~apply apply backward OSS f6rward apply backward (28) Principle of Syntactic Assimilation: Given two phrases A and B belonging to types incompatible under the Rule of Phrase Application, one of these phrases can change its type by superposition so that the types of the two phrases become compatible, if tile relation A:B is analogous to some relation X:Y between phrases of compatible types.
(29) Consider the sentence Apples Harry eats.
qtfis sentence is an exmnple of long-distance dependency because the subject intervenes between the direct object and the predicate.
! Iere is tile AUG analysis: Apples Harry eats t t OtOts SUl~rpose Ol,s <Ots:OtOts> apply backward S --superpose Ols <Ots:S~ apply backward s (30) We observe that in (30) Apples is the topic and Harry eats is tile comment.
Since the proportion topic : comment = subject : predicate holds, type Ots is supcrposed on type s of ttarry eats.
The Principle of Syntactic Assimilation is completely general: it concerns both long-distance and immediate dependencies.
Consider the phrase gold watch.
Both words have type t.
Therefore, they belong to incompatible types.
But since the proportion gold : watch = goMen : watch holds, type Ott is superposed on type t of goM.
The phenomenon of superposition must not be coufused with polymorphism.
Polymorphism is a situation when a word is assigned several types, having equal syntactic weight.
For example, an English adverb can be assigned at least three types having equal syntactic weight: OPlPl, Op2P2 or OP.~3, depending whether it modifies an intransitive, transitive or ditransitive verb.
Iiere we have an equality between the types.
But in the above example the noun gold remains a noun even though it modifies another noun.
To describe polymorphism in a compact way, Fr6d6rique Segond has introduced the concept of type variable.
"Ilms, the above and other types that can be assigned to an adverb are coded by the formula Oxx (Segond, 1990a: 131-132).
Other cases of polymorphism are exhibited by the conjunction and, which can combine two sentences, two nouns or any units belonging to identical types; ~md by the relative pronoun which of type OxOtt, mentioned in (25).
Depending on different cases of polymorphism, we introduce various type variables.
5. Conclusion We have compared two "alternative methods of compulalion of long-distance dependencies: the CCG and AUG methods.
Both methods,are consistent with respect to their mathematical machinery.
The essential difference between the two methods is that while AUG with its theory of superposition expands its formalism to reflect file linguistic reality, CCG, by abandoning the normal constituency analysis, gets caught up in its formalism to lapse into linguistic unreality.
CCG analysis produces phantoms, as: (He must) leave.
((He must) love) her.
(31) This startling analysis does not permit us to correctly describe agreement, government and clitization.
These artificial constituent structures are completely divorced from the syntactic and semantic reality.
The CCG's use of type raising iu conjunction with type composition changes the initial natural types assigned to words into artificial types and produces artificial constituents for the convenience of computation.
By contrast, supeq)osition, in conj unction with the Principle of Elhnination of Empty Constituents and the Principle of Syntactic Assimilation, changes natund types into natural types and produces syutactically and semantically appropriate constituents without any sacrifice in the consistency of the mathematical formalism or in the convenience of computation.
In support of their departure from the accepted ealalyses of syntactic constituents the proponents of the CCG refer to psychological studies ou speech recognition claiming that hmnan "recognizer" works "from left to right".(Ades and Stcedman, 1982: 517-518).
~\[kvo problems arise here.
First, although human speech is linear and the words of a sentence are produced from left to right, so to say, that does not mean that the listener analyzes spccch word by word.
It is reasonable to assume that the listener performs the analysis of a sentence first by syntactic blocks and then globally.
There is no conchlsive psychological evidence that tile hearer's recognition of tile sentence sUucture corresponds to the CCG method that disposes with the normal constituency analysis.
Second, psychological phenomena are irrelevant to confirmation or refutation of linguistic theories, because fin857 guistics is completely independent of psychology.
True, linguistic processes involve the psychological processes in the human mind.
But logical and mathematical reasoning also involve psychological processes, llowever, nobody tries to b~se logic or mathematics on psychology.
Linguistics is part of semiotics--the theory of sign systems.
Sign systems, as well as mathematical systems, are in the human mind.
But the laws of semiotics and mathematics are different from the laws of psychology.
One may argue that computational linguistics is different from ordinary linguistics,and therefore any parser will do for computational linguistics as long as it "works".
We believe that good computatiolml linguistics must be good linguistics,'tq well.
Both ordinary and computational linguistics must share common theoretical principles characterizing the nature of human language.
Computatioual linguistics is not second-rate linguistics where anything goes.The real difference between the two types of linguistics is that compuUltional linguistics exp,'mds ordinary linguistics by rules characterizing its interaction with computers rather than distorts it.
Computational linguistics is at the cutting edge of the study of hum,'m lauguage: it must enrich our understauding of all its aspects, rather them fudge the linguistic concepts for the sake of the ease of the implementation.
The irreparable defect of the CCG method is that it produces phantom constituents m~d phautom slructures that prechtde a correct analysis of linguistic processes.
The CCG method is interesting attd important as an experiment in rite application of combiuators in linguistics.
The negative results of this experiment ~u'e important in that they reveal the hazards involved in the use of combinators (for use of combiuators in AUG, see Shaumyan, 1987; Descl6s, 1990; Descl6s et al.1985, 1986).
As an instrument of cognition mathematics has a specific function--to be a tool of deduction.
But deduction is neutral to file value of ideas.
It is like a mill: if you put grain into it, you will get flour; ~utd if you put in chaff, you will get processed chaff.
Mathematical consistency does uot guarantee a correct description of reality.
"Side by side with mathematization of knowledge, mathematization of nonsense also goes on (N~dimov, 1981: 149)".
The use of mathematics as a tool of deduction makes sense only when the initial ideas from which we deduce their consequences have value (on use and abuse of mathematical formalism, see Shaumy,'m 1987: 28-29, 318-321).
In conclusion, we would like to say a few words about Ihe computer implementation of AUG, Fr6d6rique Segond has implemented AUG and its theory of superposition to deal with infinitive clauses and gerunds in French (for a complete description of the parser, see Segond, 1990a).
This parser has been implemented in PLNLP (Program~ ruing Language for Natural Language Processing, described in lleidom, 1972) at the IBM Research Center in l'aris.
The parser uses a machine dictionary of 50,000 ena'ies ~md was tested on more thm~ one hundred different types of sentences, including constructions such as relative clauses, simple cases of coordinatiou, infinitive clauses, and gerunds, among others.
Currently Sebasli~m Shaumyan is working on implementing AUG in functional programming languages (Miranda, I Iaskell).
References Ades, Anthony and Steedman, Mark.
1982. "On tile Order of Words".
Linguistics and Philosophy, 4, pp.
515-578. Benveniste, l~mile.
1966. Probldmes de linguistique gdndrale.
Editions Gallimard.
Bouma, Gosse.
1989. "Efficient Processing of Flexible Categorial Grammar".
In Proceedings of ACL (European Chapter), Manchester, pp.
12-26. Curry, Haskell B.
and Feys, Robert.
1958. Combinatoty Logic.
Vol. 1.
Amsterdam: North-Holland Publishing Company.
Descl6s, Jean-Pierre; Guentch6va, Zlatka; Shaumyan, Sebastian.
1985. Theoretical Aspects of Passivization in the Framework of Applicative Grammar.
Aansterdam & Philadelphia: John Benjamins Publishing Company.
Descl6s, Jean-Pierre; Guentchfva, Zlatka; Shaumyan, Sebastian.
1986. "Reflexive Constructions: 'lbwards a Universal Deftnitiou in the Framework of Applicative Granuuar".
Linguisticae lnvestigationes, 2.
Descl6s, Jean-Pierre.
1990. Languages applicatifs, langues naturelles et cognition.
Paris: Hermes.
Gazdar, Gerald; Klein, Ewan; Pullum, Geoffrey; Sag, Ivan.
1985. Generalized Phrase Structure Grammar.
Cambridge, Massachusetts: lhtrvard University Press.
Iteidorn G.
E. 1972.
Natural Language Inputs to a Simulation Programming System.
Technical report from the Naval Postgraduate School.
llindley, J.
R. and Seldin, J.
P. 1986.
lntpoduction to Combinators and Z-Calculus.
Cambridge: Cambridge University Press.
Nalimov, V.
V. 1981.
hi the Labyrinth of lzJnguage: A Mathematician's Journey.
Philadelphia: ISI Press.
Segond, Fr6d6rique, 1989.
"Grammaire cat6gorielle earichie: uue implementation", hvceedings of the 7th Congress AFCE RFIA, P;u'is, pp.
599-613. Segond, Fr6d~rique.
1990a. Grammaire eatdgorielle du francais, t/tude th(orique et implantation.
Le systkme GraCF (Grammaire Catggorielle Etandu).
Paris: IBM FRANCE.
Segond, Fr~d6rique, 1990b.
"Approches des grammaires cat6gorielles".
Mathdmatique, lnformatique et Sciences Humuines, 110, pp.
47-60. Shaumyan, Sebastian.
1974. Applikativnaja grammatika kak semanticeskaja teorija jazyka.
Moskva: Nauka.
Shaumyan, Sebastian.
1977. Applicative Grammar as a Semantic Theory of Natural Language (translation of Shaumyan, 1974).
Chicago: tJuiversity of Chicago Press.
Shauinyan, Sebastian.
1987. A Semiotic Theory of Language.
Bloomington & Indianapolis: Indiana University Press.
Shaumyan, Sebasti~ul.
1989. "A Semiotic llleory of KnowleAge Representation and Symbolic Computing".
Proceedings of the Fourth International Confetence on Symbolic and Logical CornÂ° puting.
Madison, SD.
Shaumyan, Sebastian.
1991. "Applicative Ilniversal Grammar and Translation".
t'toceedings of the Fifth International Conference on Symbolic aml Logical Computing.
Madison, SD.
Shaumyan, Sebastian and Segond, Fr6d6rique, 1993.
"The Theory of Superposition of Applicative Utfiversal Grammar".
Colloque ~lnformatique & Langues Naturelles~ (LL.N).
'93. Nantes: I.R.I.N.
Steedmau, Mark.
1987. "Combinatory Gr~unmars and Parasitic Gaps".
Natural lxtnguage and Linguistic Theory, 5, pp.
403439.
Steedman, Mark.
1988. "Combinators and Grammars".
In Oehrle R.
T., Bach E., Wheeler D.
(eds.), 1988, Categorial Grammars and Natural Language Structures, Dordrecht: I).
Reidel l'ul~lishiag Company, pp.
207-263. Steedman, Mm'k.
1990. "Gapping as Constituent Coordination".
Linguistics and Philosophy, 13, pp.
207-263. Szabolcsi, Anna.
1987. "On Combinatory Categorial Grammar".
In Proceedings of the Symposium on Logic and language, Debrecen, Budapest: Akademiai Kiado, pp.
151162. 858

