<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>Satanjeev Banerjee</author>
<author>Alon Lavie</author>
</authors>
<title>METEOR: An automatic metric for MT evaluation with improved correlation with human judgement</title>
<date>2005</date>
<booktitle>In Proceedings of Workshop on Intrinsic and Extrinsic Evaluation Measures for MT and/or Summarization at the 43th Annual Meeting of the Association of Computational Linguistics (ACL-2005</booktitle>
<location>Ann Arbor, Michigan</location>
<contexts>
<context> when integrating PSD-augmented context-dependent lexicons into SMT. However, widely used translation quality evaluation metrics such as BLEU (Papineni et al., 2002), NIST (Doddington, 2002), METEOR (Banerjee and Lavie, 2005), etc., aggregate the impact of many different factors. These metrics compare the translation hypothesis with one or more reference translations, but ignore how the translation hypothesis was generat</context>
</contexts>
<marker>Banerjee, Lavie, 2005</marker>
<rawString>Satanjeev Banerjee and Alon Lavie. 2005. METEOR: An automatic metric for MT evaluation with improved correlation with human judgement. In Proceedings of Workshop on Intrinsic and Extrinsic Evaluation Measures for MT and/or Summarization at the 43th Annual Meeting of the Association of Computational Linguistics (ACL-2005), Ann Arbor, Michigan, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Berger</author>
<author>Stephen Della Pietra</author>
<author>Vincent Della Pietra</author>
</authors>
<title>A maximum entropy approach to natural language processing</title>
<date>1996</date>
<journal>Computational Linguistics</journal>
<volume>22</volume>
<contexts>
<context>xt are limited by strictly residing within the IBM translation models There have been a few early attempts at defining context-dependent translation lexicons, but their usefulness in SMT is unclear. (Berger et al., 1996) first used maximum entropy modeling to integrate local context information into IBM translation models, but they do not perform any significant evaluation of the impact on translation quality: only </context>
<context>able context features from noisy decoding hypotheses than from clean input sentences, as it is done in our context-dependent lexicons. (Garcia-Varea et al., 2001) have extended the model proposed by (Berger et al., 1996) to include context features from both input and output language, but the resulting feature set is still insufficiently rich to make much better predictions than the SMT model itself. In addition to </context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>Adam Berger, Stephen Della Pietra, and Vincent Della Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguistics, 22(1):39–68.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Clara Cabezas</author>
<author>Philip Resnik</author>
</authors>
<title>Using WSD techniques for lexical selection in statistical machine translation</title>
<date>2005</date>
<tech>Technical report</tech>
<institution>Institute for Advanced Computer Studies, University of Maryland</institution>
<contexts>
<context>t of the translation lexicon where input phrases are single words. While this makes the WSD task identical to traditional standalone WSD, it does not seem to be an optimal modeling approach for SMT. (Cabezas and Resnik, 2005) used word-based Senseval WSD predictions to augment a SpanishEnglish phrase-based translation system and report small but not statistically significant improvements in BLEU score. (Gim´enez and M`ar</context>
</contexts>
<marker>Cabezas, Resnik, 2005</marker>
<rawString>Clara Cabezas and Philip Resnik. 2005. Using WSD techniques for lexical selection in statistical machine translation. Technical report, Institute for Advanced Computer Studies, University of Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marine Carpuat</author>
<author>Dekai Wu</author>
</authors>
<title>Word sense disambiguation vs. statistical machine translation</title>
<date>2005</date>
<booktitle>In Proceedings of the annual meeting of the association for computational linguistics (ACL-05</booktitle>
<location>Ann Arbor, Michigan</location>
<contexts>
<context>eful in standalone translation disambiguation tasks, using contextrich approaches from WSD methods in standard SMT systems surprisingly did not yield the expected improvements in translation quality (Carpuat and Wu, 2005). In recent work, we have proposed a method for designing a context-dependent lexicon specifically for a given phrase-based SMT model. The baseline SMT lexicon, which uses translation probabilities t</context>
<context>ocused on translation quality Our first attempt at using context-rich approaches from Senseval WSD in standard SMT systems surprisingly did not yield the expected improvements in translation quality (Carpuat and Wu, 2005). Following this disappointing results, several alternatives to strict Senseval-style WSD have been proposed, but all these proposals only evaluated the impact on automatic metrics of translation qua</context>
</contexts>
<marker>Carpuat, Wu, 2005</marker>
<rawString>Marine Carpuat and Dekai Wu. 2005. Word sense disambiguation vs. statistical machine translation. In Proceedings of the annual meeting of the association for computational linguistics (ACL-05), Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marine Carpuat</author>
<author>Dekai Wu</author>
</authors>
<title>How phrase sense disambiguation outperforms word sense disambiguation for statistical machine translation</title>
<date>2007</date>
<booktitle>In Proceedings of the 11th Conference on Theoretical and Methodological Issues in Machine Translation (TMI</booktitle>
<pages>43--52</pages>
<location>Skovde, Sweden</location>
<contexts>
<context>lly significant positive improvements from novel ways of integrating Word Sense Disambiguation (WSD) methods into statistical machine translation ((Chan et al., 2007); (Gim´enez and M`arquez, 2007); (Carpuat and Wu, 2007b)). In particular, as we shall describe, we have introduced a generalized WSD approach called Phrase Sense Disambiguation (PSD) where the key is a reliance on an innovative kind of resource: automati</context>
<context> showed that this approach reliably helps performance on both IWSLT and NIST Chinese-English test sets, yielding consistent gains on all eight of the most commonly used automatic evaluation metrics ((Carpuat and Wu, 2007b) and (Carpuat and Wu, 2007a)). In this paper, we focus on the impact of contextdependent translation lexicons on lexical choice in phrase-based SMT and show that context-dependent lexicons are more </context>
<context>ced PSD models that generalize WSD to phrasal translations and provide a context-dependent probability distribution over the possible translation candidates for a given Chinese phrasal lexicon entry (Carpuat and Wu, 2007b). Our word sense disambiguation subsystem is modeled after the best performing WSD system in the Chinese lexical sample task at Senseval-3 (Carpuat et al., 2004). Note that PSD is task-dependent and</context>
<context>nalysis of the usage of the context-dependent lexicon vs. the conventional lexicon by the phrase-based decoder Pharaoh on the NIST-2004 Chinese to English translation task described in previous work (Carpuat and Wu, 2007b). 3.1. Experiment set-up The conventional SMT phrasal lexicon is learned in a standard fashion. The training data is a newswire corpus of about 2M parallel Chinese-English sentences. Phrasal transla</context>
<context>rmation in the second. Since our focus is not on a specific SMT architecture, we incorporate our lexicons in the widely-used off-the-shelf phrase-based decoder Pharaoh (Koehn, 2004), as described in (Carpuat and Wu, 2007b). Note that Pharaoh uses a log linear model of translation that combines several features in addition to the phrasal translation probabilities from the lexicon: in particular, translation probabilit</context>
</contexts>
<marker>Carpuat, Wu, 2007</marker>
<rawString>Marine Carpuat and Dekai Wu. 2007a. How phrase sense disambiguation outperforms word sense disambiguation for statistical machine translation. In Proceedings of the 11th Conference on Theoretical and Methodological Issues in Machine Translation (TMI 2007), pages 43–52, Skovde, Sweden, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marine Carpuat</author>
<author>Dekai Wu</author>
</authors>
<title>Improving statistical machine translation using word sense disambiguation</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</booktitle>
<pages>61--72</pages>
<location>Prague</location>
<contexts>
<context> segmentation is a key factor explaining the improved translation quality obtained with fully phrasal contextdependent lexicons as opposed to using contextdependent predictions for single words only (Carpuat and Wu, 2007a). 4.2. Context-dependent lexicons encourage the decoder to use more phrase types Context-dependent lexicons help the phrase-based SMT decoder use more phrase types than with a conventional lexicon. </context>
<context>T system. This approach reliably improves performance on both IWSLT and NIST Chinese-English test sets, producing consistent gains on all eight of the most commonly used automated evaluation metrics (Carpuat and Wu, 2007b). In direct contrastive experiments, we showed that it is necessary to use context-dependent translation probabilities for the entire phrasal lexicon in order to obtain those reliable improvements i</context>
<context>stent with previous contrastive studies which showed that using fully phrasal, as opposed to single-word, context-dependent lexicons is crucial to obtain reliable improvements in translation quality (Carpuat and Wu, 2007a). This study therefore suggests that despite the additional complexity of extracting context features, training and applying WSD models, context-dependent phrasal translation lexicons are worth inte</context>
</contexts>
<marker>Carpuat, Wu, 2007</marker>
<rawString>Marine Carpuat and Dekai Wu. 2007b. Improving statistical machine translation using word sense disambiguation. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL 2007), pages 61– 72, Prague, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marine Carpuat</author>
<author>Weifeng Su</author>
<author>Dekai Wu</author>
</authors>
<title>Augmenting ensemble classification for word sense disambiguation with a Kernel PCA model</title>
<date>2004</date>
<booktitle>In Proceedings of Senseval-3, Third International Workshop on Evaluating Word Sense Disambiguation Systems</booktitle>
<publisher>SIGLEX, Association</publisher>
<location>Barcelona</location>
<contexts>
<context>ovides insights that complement previous evaluation results. In Senseval evaluations, we have previously evaluated lexical choice of the underlying WSD models without integration into the SMT system (Carpuat et al., 2004). In translation quality evaluations, we have reported improvements in overall translation quality when integrating PSD-augmented context-dependent lexicons into SMT. However, widely used translation</context>
<context> given Chinese phrasal lexicon entry (Carpuat and Wu, 2007b). Our word sense disambiguation subsystem is modeled after the best performing WSD system in the Chinese lexical sample task at Senseval-3 (Carpuat et al., 2004). Note that PSD is task-dependent and slightly differs from dedicated Senseval-style WSD. a0 The basic unit to disambiguate is any Chinese entry in the phrasal translation lexicon. It can be any sing</context>
</contexts>
<marker>Carpuat, Su, Wu, 2004</marker>
<rawString>Marine Carpuat, Weifeng Su, and Dekai Wu. 2004. Augmenting ensemble classification for word sense disambiguation with a Kernel PCA model. In Proceedings of Senseval-3, Third International Workshop on Evaluating Word Sense Disambiguation Systems, Barcelona, July. SIGLEX, Association for Computational Linguistics. Yee Seng Chan, Hwee Tou Ng, and David Chiang.</rawString>
</citation>
<citation valid="true">
<title>Word sense disambiguation improves statistical machine translation</title>
<date>2007</date>
<booktitle>In 45th Annual Meeting of the Association for Computational Linguistics (ACL-07</booktitle>
<location>Prague</location>
<marker>2007</marker>
<rawString>2007. Word sense disambiguation improves statistical machine translation. In 45th Annual Meeting of the Association for Computational Linguistics (ACL-07), Prague, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Doddington</author>
</authors>
<title>Automatic evaluation of machine translation quality using n-gram cooccurrence statistics</title>
<date>2002</date>
<journal>Ismael Garcia-Varea</journal>
<booktitle>In Proceedings of the Human Language Technology conference (HLT-2002</booktitle>
<location>San Diego, CA</location>
<contexts>
<context>overall translation quality when integrating PSD-augmented context-dependent lexicons into SMT. However, widely used translation quality evaluation metrics such as BLEU (Papineni et al., 2002), NIST (Doddington, 2002), METEOR (Banerjee and Lavie, 2005), etc., aggregate the impact of many different factors. These metrics compare the translation hypothesis with one or more reference translations, but ignore how the</context>
</contexts>
<marker>Doddington, 2002</marker>
<rawString>George Doddington. 2002. Automatic evaluation of machine translation quality using n-gram cooccurrence statistics. In Proceedings of the Human Language Technology conference (HLT-2002), San Diego, CA. Ismael Garcia-Varea and Francisco Casacuberta.</rawString>
</citation>
<citation valid="true">
<title>Maximum entropy modeling: A suitable framework to learn context-dependent lexicon models for statistical machine translation</title>
<date>2005</date>
<booktitle>Machine Learning</booktitle>
<pages>60--135</pages>
<marker>2005</marker>
<rawString>2005. Maximum entropy modeling: A suitable framework to learn context-dependent lexicon models for statistical machine translation. Machine Learning, 60:135–158.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ismael Garcia-Varea</author>
<author>Franz Och</author>
<author>Hermann Ney</author>
<author>Francisco Casacuberta</author>
</authors>
<title>Refined lexicon models for statistical machine translation using a maximum entropy approach</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th annual meeting of the association for computational linguistics (ACL-01</booktitle>
<location>Toulouse, France</location>
<contexts>
<context>extracted from the output language: it is harder to extract reliable context features from noisy decoding hypotheses than from clean input sentences, as it is done in our context-dependent lexicons. (Garcia-Varea et al., 2001) have extended the model proposed by (Berger et al., 1996) to include context features from both input and output language, but the resulting feature set is still insufficiently rich to make much bet</context>
<context>on, and benefit from the much richer Senseval-style feature set. In addition, unlike in the present work, Garcia Varea et al. did not fully integrate their context-dependent models were in decoding. (Garcia-Varea et al., 2001) and (Garcia-Varea et al., 2002) only report improved alignment error rates over IBM models 4 and 5 on the German-English Verbmobil corpus, and omit to evaluate the impact on translation quality. Thi</context>
</contexts>
<marker>Garcia-Varea, Och, Ney, Casacuberta, 2001</marker>
<rawString>Ismael Garcia-Varea, Franz Och, Hermann Ney, and Francisco Casacuberta. 2001. Refined lexicon models for statistical machine translation using a maximum entropy approach. In Proceedings of the 39th annual meeting of the association for computational linguistics (ACL-01), Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ismael Garcia-Varea</author>
<author>Franz Och</author>
<author>Hermann Ney</author>
<author>Francisco Casacuberta</author>
</authors>
<title>Efficient integration of maximum entropy lexicon models within the training of statistical alignment models</title>
<date>2002</date>
<booktitle>In Proceedings of AMTA-2002</booktitle>
<pages>54--63</pages>
<location>Tiburon, California</location>
<contexts>
<context>cher Senseval-style feature set. In addition, unlike in the present work, Garcia Varea et al. did not fully integrate their context-dependent models were in decoding. (Garcia-Varea et al., 2001) and (Garcia-Varea et al., 2002) only report improved alignment error rates over IBM models 4 and 5 on the German-English Verbmobil corpus, and omit to evaluate the impact on translation quality. This is an issue since alignment is</context>
</contexts>
<marker>Garcia-Varea, Och, Ney, Casacuberta, 2002</marker>
<rawString>Ismael Garcia-Varea, Franz Och, Hermann Ney, and Francisco Casacuberta. 2002. Efficient integration of maximum entropy lexicon models within the training of statistical alignment models. In Proceedings of AMTA-2002, pages 54–63, Tiburon, California, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jes´us Gim´enez</author>
<author>Llu´ıs M`arquez</author>
</authors>
<title>Contextaware discriminative phrase selection for statistical machine translation</title>
<date>2007</date>
<booktitle>In Workshop on Statistical Machine Translation</booktitle>
<location>Prague</location>
<marker>Gim´enez, M`arquez, 2007</marker>
<rawString>Jes´us Gim´enez and Llu´ıs M`arquez. 2007. Contextaware discriminative phrase selection for statistical machine translation. In Workshop on Statistical Machine Translation, Prague, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Pharaoh: a beam search decoder for phrase-based statistical machine translation models</title>
<date>2004</date>
<booktitle>In 6th Conference of the Association for Machine Translation in the Americas (AMTA</booktitle>
<location>Washington, DC</location>
<contexts>
<context> 2.3. Integrating context-dependent lexicons in phrase-based SMT architectures It is non-trivial to incorporate a context-dependent lexicon into an existing phrase-based architecture such as Pharaoh (Koehn, 2004), since the decoder is not set up to easily accept multiple translation probabilities that are dynamically computed in context-dependent fashion. For every phrase in a given SMT input sentence, the P</context>
<context>, thus ignoring contextual information in the second. Since our focus is not on a specific SMT architecture, we incorporate our lexicons in the widely-used off-the-shelf phrase-based decoder Pharaoh (Koehn, 2004), as described in (Carpuat and Wu, 2007b). Note that Pharaoh uses a log linear model of translation that combines several features in addition to the phrasal translation probabilities from the lexico</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004. Pharaoh: a beam search decoder for phrase-based statistical machine translation models. In 6th Conference of the Association for Machine Translation in the Americas (AMTA), Washington, DC, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models</title>
<date>2003</date>
<journal>Computational Linguistics</journal>
<volume>29</volume>
<contexts>
<context>f about 2M parallel Chinese-English sentences. Phrasal translation candidates are extracted if they are consistent with the intersection of bidirectional IBM Model 4 alignments, obtained with GIZA++ (Och and Ney, 2003) and augmented to improve recall. Contextindependent phrasal translation probabilities are simply maximum likelihood estimates. The context-dependent phrasal lexicon is learned by training PSD models</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–52. This is the citation to use for GIZA++.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-Jing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</booktitle>
<contexts>
<context>have reported improvements in overall translation quality when integrating PSD-augmented context-dependent lexicons into SMT. However, widely used translation quality evaluation metrics such as BLEU (Papineni et al., 2002), NIST (Doddington, 2002), METEOR (Banerjee and Lavie, 2005), etc., aggregate the impact of many different factors. These metrics compare the translation hypothesis with one or more reference transla</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nivolas Stroppa</author>
<author>Antal van den Bosch</author>
<author>Andy Way</author>
</authors>
<title>Exploiting source similarity for smt using context-informed features</title>
<date>2007</date>
<booktitle>In Proceedings of the 11th Conference on Theoretical and Methodological Issues in Machine Translation (TMI</booktitle>
<location>Skovde, Sweden</location>
<marker>Stroppa, van den Bosch, Way, 2007</marker>
<rawString>Nivolas Stroppa, Antal van den Bosch, and Andy Way. 2007. Exploiting source similarity for smt using context-informed features. In Proceedings of the 11th Conference on Theoretical and Methodological Issues in Machine Translation (TMI 2007), Skovde, Sweden, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
<author>David Chiang</author>
<author>editors</author>
</authors>
<date>2007</date>
<booktitle>NAACLHLT 2007 / AMTA Workshop on Syntax and Structure in Statistical Translation (SSST). Association for Computational Linguistics</booktitle>
<location>Rochester, NY, USA</location>
<marker>Wu, Chiang, editors, 2007</marker>
<rawString>Dekai Wu and David Chiang, editors. 2007. NAACLHLT 2007 / AMTA Workshop on Syntax and Structure in Statistical Translation (SSST). Association for Computational Linguistics, Rochester, NY, USA, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
<author>Pascale Fung</author>
</authors>
<title>Improving Chinese tokenization with linguistic filters on statistical lexical acquisition</title>
<date>1994</date>
<booktitle>In ANLP-94: 4th Conference on Applied Natural Language Processing</booktitle>
<location>Stuttgart</location>
<contexts>
<context>t only a by-product of the full translation process, it does not make sense to define an a-priori gold standard or correct phrasal segmentation for a given sentence independently of the application. (Wu and Fung, 1994) showed that it is hard for human judges to agree on what a correct segmentation is. Instead, since our focus is on the usefulness of the translation lexicons as resources, we analyze how the Chinese</context>
</contexts>
<marker>Wu, Fung, 1994</marker>
<rawString>Dekai Wu and Pascale Fung. 1994. Improving Chinese tokenization with linguistic filters on statistical lexical acquisition. In ANLP-94: 4th Conference on Applied Natural Language Processing, Stuttgart, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora</title>
<date>1997</date>
<journal>Computational Linguistics</journal>
<volume>23</volume>
<marker>Wu, 1997</marker>
<rawString>Dekai Wu. 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. Computational Linguistics, 23(3):377–404.</rawString>
</citation>
</citationList>
</algorithm>

