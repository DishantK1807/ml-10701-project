Some examples for English include the English parser used in tide SPARKLE project \[Briscoe et al., \] \[Carroll et al., 1997b\] \[Carroll et al., 1998b\] and the finder built with a memory-based approach \[Argamon et aI., 1998\].
P98-1010 W98-1114
In an illustration of the time consuming nature of annotating or i'eannotating a large corpus, the SPARKLE project originally did not have time to annotate the English test data for modifier relationships..ks a result, the SPARKLE English parser was originally not evaluated on how well it found modifier relationships \[Carroll et al., 1997b\] \[Carroll et al.: 1998b\].
W98-1114
The system in \[Argamon et al., 1998\] only finds a subset of the surface subjects and objects.
P98-1010
Except for the object precision score of 77% in \[Argamon et al., 1998\], both finders have grammatical relation recall and precision scores in the 80s.
P98-1010
\[Carroll et al., 1998b\] J.
W98-1114
\[Ramshaw and Marcus, 1995\] L.
W95-0107
Our set of relationships is similar to the set used in the SPARKLE project \[Carroll et al., 1997a\] \[Carroll et al., 1998a I.
W98-1114
1994. \[Lai and Huang, 1998\] T.
W98-0512
\[Brill and Resnik, 1994\] E.
C94-2195
The figures given above were the original (1998) results for the system in \[Argamon et al., 1998\], which came from training and testing on data derived from the Penn Treebank corpus \[Marcus et al., 1993\] in which the added null elements (like null subjects) were left in.
J93-2004 P98-1010
Our training and test corpora, for instance, are lessthan-gargantuan compared to such collections as the Penn Treebank \[Marcus et al., 1993\].
J93-2004
The attachment estimation uses a procedure described in \[Yeh and Vilain, 1998\] when multiple left attachment possibilities exist and four simple rules when no or only one left attachment possibility exists.
P98-2234
chunks \[Abney, 1996\], or base NPs \[Ramshaw and Marcus, 1995\].
W95-0107
There has been some work at making additions to extract grammatical relationships from a dependency tree structure \[BrSker, 1998, Lai and Huang, 1998\] so that one first produces a surface structure dependency tree with a syntactic parse and then extracts grammatical relationships from that tree.
W98-0512
The results we have presented here are given solely for this harder part, which may explain why at roughly 70 points of f-score, they are lower than those reported for current state-of-the-art parsers (e.g., Collins \[Collins, 1997\]).
P97-1003
\[Carroll et al., 1998a\] J.
W98-1114
\[Collins, 1997\] M.
P97-1003
The Processing Model Our system uses transformation-based error-driven learning to automatically learn rules from training examples \[Brill and Resnik, 1994\].
C94-2195
Like other Brill transformation rule systems \[Brill and Resnik, 1994\], our system can take in the output of another system and try to improve on it.
C94-2195
\[Palmer, 1997\] D.
P97-1041
\[Marcus et al., 1993\] M.
J93-2004
\[Argamon et hi., 1998\]S.
P98-1010
Pennsylvania. \[Yeh and Vilain, 1998\] A.
P98-2234
