Proceedings of the NAACL HLT 2010 Workshop on Computational Linguistics and Writing, pages 51–55,
Los Angeles, California, June 2010. c©2010 Association for Computational Linguistics
Questions Worth Asking: Intersections betwen Writing Research and 
Computational Linguistics 
Ane Ruggles Gere and Laura Aul 
University of Michigan 
An Arbor, MI 48104, USA 
 
 
 
 
 
 
Abstract 
Rather than explain research that has al-
ready ben caried out, this paper describes 
a specific context of writing instruction and 
poses questions about how research on 
writing and computational linguistics might 
be brought together to adres thre press-
ing isues: the validity of Directed Self-
Placement; the relationship betwen confi-
dence and competence in student writing; 
and strategies to help English Language 
Learners, especialy those in the category 
of Generation 1.5, improve their writing. 
1 Introduction

In this paper we would like to explore questions 
that hover at the intersection of writing research 
and computational linguistics.  First, however, 
we would like to explain the context of our work 
since we believe that context is a shaping force 
in any research on writing.  The site where we 
work is the Sweetland Center for Writing at the 
University of Michigan, and this Center is re-
sponsible for the placement of some 400 first-
year students in several different coleges in-
cluding LSA, Nursing, Kinesiology, Art and 
Design, and Music.  
  The majority of students who enrol at this 
university have performed well on tests and in 
high schol.  Only approximately 5% have a 
high schol GPA under 3.3 or a SAT verbal 
below 530. The university also enrols a signifi-
cant (approximately 5%) number of international 
students who are English Language Learners, 
along with an unknown number of Generation 
1.5 students who are also learning to manage 
various aspects of academic English but who are 
very difficult to identify because they do not 
have the clear markers of international students. 
The Center is also responsible for oversight of 
all courses that meet the First Year Writing Re-
quirement and the Uper Level riting Re-
quirement.    
First-year students enrol in either a develop-
mental course, Writing 10, or one of the seven 
different courses that satisfy the First Year Writ-
ing Requirement (FYW).  For nearly a decade 
students decided between the two, in concert 
with their advisors, by participating in a form of 
Directed Self-Placement (DSP).  
DSP, which came into use in the United 
States during the final years of the 20th century, 
puts into student hands the decision about 
placement in writing courses.  DSP was first 
implemented at coleges small enough to pro-
vide significant amounts of one-on-one time 
between students and advisors and/or writing 
instructors.  DSP has taken various forms, de-
pending upon the local context, but it always 
asks students to assess their own abilities as 
writers.  
In the version of DSP first implemented at our 
university, students answered seven questions 
about their reading habits and their writing prac-
tices, along with their grades and test scores. 
The questions used from 200 to 205 gave 
more attention to mastery, as in “I have learned 
the correct forms of standard writen English and 
make few mistakes in sentence construction, 
51
punctuation, and usage,” while the survey used 
from 206 to 208 focused more on comfort or 
confidence, as in “I am comfortable using stan-
dard writen English, including the correct forms 
of grammar, punctuation, and sentence construc-
tion.”  
   Significantly, the number of students who 
received a recommendation for Writing Practi-
cum droped dramatically—from approximately 
100 to approximately 20when the second 
form of the survey was introduced.  The deci-
sions about enrolment, of course, remained in 
the hands of students, and it is worth noting that 
the percentage of students who folowed the 
recommendation generated by the survey in-
creased from 15% to 35%. 
2 Questions
of Validity 
Analysis of the DSP process that had been in 
place from 200 to 208 (under both sets of 
questions) showed that it had litle validity (Gere 
et al., forthcoming).  It lacked substantive valid-
ity because of the time gap between completion 
of the survey and course selection; it lacked 
structural validity because the survey questions 
bore litle relation to the construct of writing 
central in the FYW courses; it lacked validity of 
generalizability because only a small percentage 
of students folowed the recommendation gener-
ated by the DSP survey; it lacked external valid-
ity because there was a low correlation between 
students’ scores on other measures and on the 
DSP survey; and it lacked consequential validity 
because  the construct of writing operating in the 
Writing 10 course bore litle relation to that 
emphasized in the DSP survey.  This analysis, 
combined with the fact that students’ perception 
of the importance of writing was influenced by 
the contrast between answering seven multiple 
choice questions and completing substantive 
tests in math, chemistry and foreign languages, 
led to a reconfiguring of the DSP process to 
include writing an essay and answering ques-
tions about that process as well as about literacy 
practices more generally. 
    Begining in the fall of 209, entering first-
year students at our university write an evi-
dence-based argument in response to a 350 
word publication.  Esays of entering students 
are submited electronically and are delivered to 
individual instructors of students’ first writing 
class so that they become incorporated into in-
struction.  The Writing 10 course has been 
redesigned so that it is aligned with the construct 
of writing in the DSP process and in the FYW 
course.  
In other words, we now have a large and 
growing corpus of student writing, and it would 
be helpful to think through how we might make 
best use of it, with regard to questions of validity 
as well as other isues.  The DSP essay corpus 
currently includes over 350 student essays 
comprising over three milion words, and by the 
end of August 2010, these numbers wil double 
as a new cohort of students enters the Univer-
sity. Al the texts in the initial corpus were writ-
ten by incoming first-year students in response 
to a prompt for an evidence-based argument 
about a Malcom Gladwell essay that discuses 
the difficulty of predicting which candidates wil 
become god teachers—or quarterbacks or fi-
nancial advisors.   Instructions included a rec-
ommendation to consider these features:  focus 
or development around a clear central thesis or 
argument; structure or organization that elabo-
rates on and suports the central argument; and 
evidence or well-chosen examples from the text 
to suport claims. 
In addition to this corpus, we have the poten-
tial to create a smaller corpus of student writing 
produced in first writing classes, both Writing 
10 and courses that satisfy the First Year rit-
ing Requirement, as well as personal narratives 
writen as part of each student’s admision port-
folio.  In coming years, we could also colect 
samples of writing acros the entire undergradu-
ate experience of a subset of students.  One of 
the questions we would like to discus, then, 
centers on what decisions we should make about 
structuring additional corpora so as to take best 
advantage of the texts and materials available to 
us. 
  One clear direction for our work is to con-
tinue the investigation of validity to determine 
the extent to which the modifications in the DSP 
process and in Writing 10 enhance the validity 
of the placement process now in place.  In par-
ticular, it would be useful to learn more about 
the consequential validity of the DSP process 
since its main result or consequence is enroll-
ment in either Writing 10 or a course that meets 
52
the First Year Writing Requirement.   Among 
the posible questions to investigate are these: 
 
• How can we best use the existing corpus 
and additional ones we might create to de-
termine the extent to which the writing of 
students who elect Writing 10 differs 
from that of students who chose to enrol 
immediately in courses that meet the FYW 
requirement?  
• How might we best create subgroups (and 
subcorpora) to understand how writers in 
each subgroup articulate arguments and 
use evidence?  
 
The evidence-based argument is central in 
both contexts of first writing courses, and the 
construct of writing that operates in the DSP and 
in Writing 10 includes features of formal, pur-
poseful, coherent, complex, audience-aware, and 
evidence-based writing.  A variety of rhetorical 
choices in academic writing help writers achieve 
these features; for example, we know from the 
work of Hyland (205) that effective writers use 
textual signals to pul readers along their line of 
argument, so one approach in our research 
would be to compare the writing of students who 
elect Writing 10 and those who do not in terms 
of their use of textual signs that make the terms 
of their arguments clear.  
Given student data and surveys we have ac-
cess to, we also have the capacity to create sub-
corpora based on student grades and scores, 
English nativeness, student high schol types, or 
students’ reported attributes such as confidence 
or writing experience. Understanding how writ-
ers in various subgroups construct arguments 
wil help answer key questions about the validity 
of the current form of DSP, and we welcome 
discusion of how quantitative linguistics can 
aid in that process. 
3 Questions
of Confidence 
Another set of questions emerges from analysis 
of students’ responses to the DSP survey.  This 
examination showed that there were a few “trig-
ger” questions that influenced students’ choices 
about which writing course to take.  That is, 
certain questions were the ones that propelled 
the greatest number of students to take or not 
take Writing 10. Most prominent among these 
were the questions dealing with the isue of 
confidence, as in “I am confident about my abil-
ity to comprehend unfamiliar texts.”   
    In a subsequent survey of students who had 
already enroled in either Writing 10 or a 
course that meets the FY requirement, the 
isue of confidence became even more promi-
nent.  When asked to rank the importance of 
various factors in their self-placement in a writ-
ing course, “confidence in my own writing abil-
ity” was the number one factor for the great 
majority of students.  
   The next most important factor, input from 
an academic advisor, received less than half as 
many “most important” responses. This finding 
is significant in at least two ways, and it also 
raises questions that can call upon the resources 
of computational linguistics.  One dimension of 
the significance of the confidence isue is that 
confidence is central to the theory underlying 
Directed Self-Placement. The literature on DSP 
positions confidence as the goal of a develop-
mental course and a desired result of a FYW 
course is that students wil develop “writing 
confidence.”  Indeed some scholars have sug-
gested that DSP may be more a measure of con-
fidence than of writing ability (Reynolds, 203). 
The importance of confidence is magnified by 
the fact that confidence is frequently equated 
with competence in writing; it is also credited 
with driving out apprehension about writing, and 
with enhancing the authorial identity of students.   
  Another significant dimension of confi-
dence, however, troubles its relationship to DSP 
and to writing more generally because empirical 
studies show that confidence in writing does not 
have a fixed or stable meaning. The person who 
expresses considerable confidence in writing 
essays may experience and express a lack of 
confidence about writing in another genre or 
form such as a grant proposal or lab report. The 
student who is a confident writer in high schol 
may have a significant los of confidence when 
faced with the writing tasks of colege or the 
workplace.  Writers who express confidence 
may or may not be able to produce writing that 
is recognized by others as “god.”  And those 
confident writers who are recognized for “god” 
53
writing in one context may not be so recognized 
in other contests.  
Confidence, which is closely allied with self-
efficacy, is task specific, and this complicates 
the meaning of writing confidence.  Given the 
importance and instability of confidence in rela-
tion to writing and to DSP specifically, it wil be 
useful to learn more about how confidence is 
manifested in student writing.  Because the re-
search on the relationship between confidence 
and competence in writing is mixed, it wil be 
important to explore this relationship more 
closely.  The corpus of student writing along 
with information about the questions to which 
students respond, particularly those focused on 
confidence, allows us to compare patterns in 
subcorpora of writing done by students who self-
identify as confident academic writers versus 
those who do not. These resources provide use-
ful data for begining to address a number of 
questions that emerge from the isue of confi-
dence in DSP, and in writing more generally. 
One way to understand more about the nature 
and function of confidence is to consider its 
relationship to competence in writing. Our pre-
liminary investigation of the relationship be-
tween student confidence and competence has 
focused on features that research shows to corre-
late with highly ranked writing.  Two features 
emerge directly from the genre of writing re-
quired by the DSP prompt. One is organization, 
and we can learn something about this from 
analyzing the corpus for discourse markers such 
as transition words, since such markers correlate 
highly with effective argumentative writing 
(Xing et al., 208).  Another is reference to the 
reading material because research (Wodward-
Kron, 203) shows the importance of interacting 
with multiple voices to make effective argu-
ments, and examples from the text are one of the 
features mentioned in the DSP prompt.  
In addition, there are features that correlate 
with effective writing more generally.  One of 
these is text length because research shows that 
students who produce more words typically 
receive higher scores, particularly on timed writ-
ing tests (Friedlander, 190).  Another is 
type/token ratios because research shows that 
students who use a greater variety of words are 
typically identified as better writers (Engber, 
193).  
 We believe that analyzing the entire corpus 
as well as subgroups identified by levels of self-
proclaimed confidence for features like transi-
tion words and references to the reading material 
as well as text length and type-token ratios wil 
provide some insight into the relationship be-
tween confidence and competence in writing. 
At the same time, however, we welcome discus-
sion on how we might nuance this investigation 
further by calling upon other resources of com-
putational linguistics. 
 
4 Questions
of Language Learning 
As mentioned earlier, one of the subgroups 
within the larger university population is English 
Language Learners.  Briefly, international stu-
dents at our university who score below a fixed 
threshold on the TESOL are required to take a 
second test, the AE, in addition to participating 
in the DSP process.  The survey questions to 
which they respond are slightly different from 
those answered by native speakers, and the essay 
they read includes gloses to explain culturally 
specific terms.  This combination of accomo-
dations and measures is relatively effective in 
identifying students who need special interven-
tion in order to write well in English.  
   But, as current research shows, there is an-
other population of English Language Learners 
that is much less visible than the typical interna-
tional students—the population typically known 
as Generation 1.5.  These students are much 
more fuly assimilated into US culture, usually 
because they have lived in this country for an 
extended period and have attended US schols.  
However, their writing frequently manifests 
many of the same difficulties as the more easily 
identified English Language Learners.  One of 
the chief instructional challenges posed by Gen-
eration 1.5 students is that they are not easy to 
identify, and their instructional needs are not 
clearly defined. Analysis of the DSP process at 
our university shows that Generation 1.5 stu-
dents regularly fly under the radar of self-
placement and find themselves strugling in 
writing classes. Anecdotal reports from instruc-
tors point to these students’ difficulties, but we 
have no systematic way of identifying and help-
ing them.  This population, like that of EL 
54
students, is currently growing each year, and it is 
becoming increasingly important to address its 
needs. 
   It is clear, however, that positioning English 
language learners and, especially, Generation 
1.5 as deficient is not constructive.  EL and 
Generation 1.5 students are often constructed in 
highly positive terms such as hard-working and 
determined in high schol and then positioned 
negatively as resistant and unmotivated when 
they enter colege writing classes.  The first 
chalenge is to develop better ways of identify-
ing Generation 1.5 students early in their univer-
sity work so that they are not left to flounder, as 
they so often do, when they move into uper 
division courses.  The double challenge of ac-
quiring academic literacy while simultaneously 
acquiring proficiency in the English language 
frequently, as Short and Fitzsimmons (207) 
show, becomes overwhelming to students who 
have many competencies and are highly moti-
vated.  The colege writing class offers a space 
for equiping students who are learning English 
at the same time that they are leaning about col-
lege writing.  In order for this to happen, how-
ever, we need to learn more about the specific 
nature of challenges faced by these students. 
Research by Wu (207) shows that ability to 
adjust dialogic space is often difficult for L2 
writers, and Hyland and Milton (197) demon-
strate that L2 writers frequently take a more 
authoritative and less nuanced stance, while 
more highly valued writing typically expresses 
more epistemic uncertainty.   
As a first step, we wil create a sub corpus of 
identified English Language Learners and use 
the rhetorical and interactive features of compe-
tence (organization, reference to reading, text 
length, lexical variety, and transition words) 
identified above to determine the extent to which 
these features identify levels of writing compe-
tence for this population. If we can isolate fea-
tures that are characteristic of this population of 
English Language Learners, then we can attempt 
to apply the same features to the entire corpus in 
order to begin the process of identifying Genera-
tion 1.5 students.  
We are less certain about how to use compu-
tational linguistics most effectively to identify 
ability to adjust dialogic space and take a more 
nuanced stance in writing.   Nor, of course, are 
we certain that these features wil be the most 
productive in helping us to identify Generation 
1.5 students.  Accordingly, we wil welcome 
discusion of additional ways to use computa-
tional linguistics to identify Generation 1.5 stu-
dents. 
5 Conclusion

We have done some preliminary thinking and 
begun investigations of questions about validity, 
confidence and English Language Learners, and 
we welcome the oportunity to explore ways of 
uniting research in writing and in computational 
linguistics to further our investigation. 
 
References 
C. Engber. 195. The relationship of lexical profi-
ciency to the quality of ESL compositions. Journal 
of Second Language Writing 4(2):139–155. 
A. Friedlander. 190. Composing in English: Effects 
of a first language on writing in English as a sec-
ond language In Barbara Krol (Ed.) Second Lan-
guage Writing: Research Insights for the Class-
rom, New York: Cambridge UP. 
A. R. Gere, L. Aul, T. Gren and A. Porter. (forth-
coming). Asesing the validity of directed self-
placement at a large university. Assesing Writing. 
K. Hyland. 205. Representing readers in writing: 
Student and expert practices. Linguistics and Edu-
cation  16, 363–377. 
K. Hyland, and J. Milton. 197. Qualifications and 
certainty in L1 and L2 students writing. Journal of 
Second Language Writing 6(2):183–205. 
E. J. Reynolds. 203. The role of self-eficacy in 
writing and directed self-placement.  In Daniel 
Royer and Roger Giles (Eds.) Directed Self-
Placement: Principles and Practices. Creskil, 
NJ: Hampton Pres, 73–104. 
R. Wodward-Kron. 203. Critical analysis and the 
journal article review asignment Journal of Eng-
lish for Academic Purposes, 6, 254–271. 
M. Xing, J. Wang and K. Spencer. 208. Raising 
Students’ Awarenes of cros-cultural contrastive 
rhetoric in English writing via an E-learning 
course. Language Learning & Technology 
12(2):71–93. 
55

