<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>W J Sui</author>
<author>Z F Ji</author>
<author>L N</author>
</authors>
<title>A Study on Term Extraction Based on Classified Corpora</title>
<date>2006</date>
<marker>Sui, Ji, N, 2006</marker>
<rawString>Chen, Y.R., Lu, Q., Li. W.J., Sui, Z.F., Ji, L.N. (2006). A Study on Term Extraction Based on Classified Corpora.</rawString>
</citation>
<citation valid="true">
<date>2006</date>
<booktitle>In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC2006</booktitle>
<location>Italy</location>
<marker>2006</marker>
<rawString>In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC2006), Italy, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L F Chien</author>
</authors>
<title>Pat-tree-based adaptive keyphrase extraction for intelligent Chinese information retrieval</title>
<date>1999</date>
<journal>Information Processing and Management</journal>
<volume>35</volume>
<pages>501--521</pages>
<contexts>
<context>asure which estimates the strength by the dependency of the candidate on its context using measures such as the left/right entropy (Sornlertlamvanich et al., 2000), the left/right context dependency (Chien, 1999), and accessor variety criteria (Feng et al., 2004). Most previous studies use one or both of them for unithood calculation. The UnitRate algorithm proposed in (Chen et al., 2006) integrates occurren</context>
</contexts>
<marker>Chien, 1999</marker>
<rawString>Chien, L.F. (1999). Pat-tree-based adaptive keyphrase extraction for intelligent Chinese information retrieval. Information Processing and Management, 35, pp.501--521.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Frank</author>
<author>G W Paynter</author>
<author>I H Witten</author>
<author>C Gutwin</author>
<author>C G Nevill-Manning</author>
</authors>
<title>Nevill-Manning. Domain-specific keyphrase Extraction</title>
<date>1999</date>
<booktitle>In Proceedings of 16th International Joint Conference on Artificial Intelligence IJCAI-99</booktitle>
<pages>668--673</pages>
<contexts>
<context>hm, TCE_SEF&amp;CV with the best performance (Ji and Lu, 2007), is used as a reference algorithm. Another popular algorithm which is integrated without division of steps, TF-IDF (Salton and McGill, 1983; Frank et al., 1999) is used as a reference method for term extraction. All the proposed algorithms and the reference algorithms need to run a term verification algorithm. For fairness, the term verification algorithm T</context>
</contexts>
<marker>Frank, Paynter, Witten, Gutwin, Nevill-Manning, 1999</marker>
<rawString>Frank, E., Paynter, G.W., Witten, I.H., Gutwin, C., Nevill-Manning, C.G. (1999). Nevill-Manning. Domain-specific keyphrase Extraction. In Proceedings of 16th International Joint Conference on Artificial Intelligence IJCAI-99, pp. 668--673.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H D Feng</author>
<author>K Chen</author>
<author>X T Deng</author>
<author>W M Zheng</author>
</authors>
<title>Accessor variety criteria for Chinese word extraction</title>
<date>2004</date>
<journal>Computational Linguistics</journal>
<volume>30</volume>
<pages>75--93</pages>
<contexts>
<context>endency of the candidate on its context using measures such as the left/right entropy (Sornlertlamvanich et al., 2000), the left/right context dependency (Chien, 1999), and accessor variety criteria (Feng et al., 2004). Most previous studies use one or both of them for unithood calculation. The UnitRate algorithm proposed in (Chen et al., 2006) integrates occurrence probability and marginal variety probability of </context>
</contexts>
<marker>Feng, Chen, Deng, Zheng, 2004</marker>
<rawString>Feng, H.D., Chen, K., Deng, X.T., Zheng, W.M. (2004). Accessor variety criteria for Chinese word extraction. Computational Linguistics. 30(1), pp.75--93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Frantzi</author>
<author>S Ananiadou</author>
<author>H Mima</author>
</authors>
<title>Automatic recognition of multi-word terms</title>
<date>2000</date>
<journal>International Journal of Digital Libraries</journal>
<volume>3</volume>
<pages>117--132</pages>
<contexts>
<context>ty and marginal variety probability of the candidates and all its components. The TCE_SEF&amp;CV algorithm presented in (Ji and Lu, 2007) applies the significance estimation function and C-value measure (Frantzi et al., 2000) to estimate the internal and external strength for unithood calculation. However, these algorithms do not perform well for low frequency terms and long terms because of data sparseness. They also ap</context>
</contexts>
<marker>Frantzi, Ananiadou, Mima, 2000</marker>
<rawString>Frantzi, K., Ananiadou, S., Mima, H. (2000) Automatic recognition of multi-word terms. International Journal of Digital Libraries, 3(2), pp.117--132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C R Huang</author>
<author>P Simon</author>
<author>S K Hsieh</author>
<author>L Pr´evot</author>
</authors>
<title>Rethinking Chinese Word Segmentation: Tokenization, Character Classification, or Wordbreak Identification</title>
<date>2007</date>
<marker>Huang, Simon, Hsieh, Pr´evot, 2007</marker>
<rawString>Huang, C.R., Simon, P., Hsieh, S.K., Pr´evot, L. (2007). Rethinking Chinese Word Segmentation: Tokenization, Character Classification, or Wordbreak Identification.</rawString>
</citation>
<citation valid="false">
<booktitle>In Proceedings of the ACL 2007 Demo and Poster Sessions</booktitle>
<pages>69--72</pages>
<marker></marker>
<rawString>In Proceedings of the ACL 2007 Demo and Poster Sessions, pp. 69–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L N Ji</author>
<author>Q Lu</author>
</authors>
<title>Chinese Term Extraction Using Window-Based Contextual Information. CICLing 2007, LNCS 4394</title>
<date>2007</date>
<pages>62--74</pages>
<contexts>
<context>association (e.g. Schone and Jurafsky, 2001) and context dependency (e.g. Sornlertlamvanich et al., 2000). These techniques are also used in Chinese term candidate extraction (e.g. Chen et al., 2006; Ji and Lu, 2007). All the current techniques focus on domain dependent terms and use a weighted approach to consider various features to identify term boundaries. However, only one or two features are useful in a pa</context>
<context> UnitRate algorithm proposed in (Chen et al., 2006) integrates occurrence probability and marginal variety probability of the candidates and all its components. The TCE_SEF&amp;CV algorithm presented in (Ji and Lu, 2007) applies the significance estimation function and C-value measure (Frantzi et al., 2000) to estimate the internal and external strength for unithood calculation. However, these algorithms do not perf</context>
<context>List IT and DList Legal in the subsequent evaluations. 4.3 Evaluation on Term Extraction For comparison, a statistical based term candidate extraction algorithm, TCE_SEF&amp;CV with the best performance (Ji and Lu, 2007), is used as a reference algorithm. Another popular algorithm which is integrated without division of steps, TF-IDF (Salton and McGill, 1983; Frank et al., 1999) is used as a reference method for ter</context>
</contexts>
<marker>Ji, Lu, 2007</marker>
<rawString>Ji, L.N., Lu, Q. (2007). Chinese Term Extraction Using Window-Based Contextual Information. CICLing 2007, LNCS 4394, pp. 62--74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Kageura</author>
<author>B Umino</author>
</authors>
<title>Methods of automatic term recognition: a review</title>
<date>1996</date>
<journal>Term</journal>
<volume>3</volume>
<pages>259--289</pages>
<contexts>
<context>most fundamental knowledge of a domain. Term extraction involves two steps. The first step extracts candidates by unithood calculation and the second step verifies them as terms measured by termhood (Kageura and Umino, 1996). Unithood measures the strength which qualifies a string as a valid term. Termhood measures the degree at which a term represents some domain specific concept. This study focuses on unithood measure</context>
</contexts>
<marker>Kageura, Umino, 1996</marker>
<rawString>Kageura, K., Umino, B. (1996). Methods of automatic term recognition: a review. Term, 3(2), pp. 259--289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kleinberg</author>
</authors>
<title>Authoritative sources in a hyperlinked environment</title>
<date>1997</date>
<booktitle>In Proceedings of the 9th ACM-SIAM Symposium on Discrete Algorithms</booktitle>
<pages>668--677</pages>
<marker>Kleinberg, 1997</marker>
<rawString>Kleinberg, J. (1997). Authoritative sources in a hyperlinked environment. In Proceedings of the 9th ACM-SIAM Symposium on Discrete Algorithms, pp. 668--677.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S F Luo</author>
<author>M S Sun</author>
</authors>
<title>Two-Character Chinese Word Extraction Based on Hybrid of Internal and Contextual Measures</title>
<date>2003</date>
<booktitle>In Proceedings of the Second SIGHAN Workshop on Chinese Language Processing</booktitle>
<pages>24--30</pages>
<contexts>
<context>ribes the methodology and the algorithms. Section 4 presents the experiments and evaluations. Section 5 is the conclusion. 2. Related work In general, there are two kinds of statistic-based measures (Luo and Sun, 2003) for estimating the unithood of a term candidates. The first kind is the internal measure which estimates the strength by the internal associative measures between constituents of the candidate chara</context>
</contexts>
<marker>Luo, Sun, 2003</marker>
<rawString>Luo, S.F., Sun, M.S. (2003). Two-Character Chinese Word Extraction Based on Hybrid of Internal and Contextual Measures. In Proceedings of the Second SIGHAN Workshop on Chinese Language Processing, July, 2003, pp. 24--30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Salton</author>
<author>M J McGill</author>
</authors>
<title>Introduction to Modern Information Retrieval</title>
<date>1983</date>
<publisher>McGraw-Hill</publisher>
<contexts>
<context>didate extraction algorithm, TCE_SEF&amp;CV with the best performance (Ji and Lu, 2007), is used as a reference algorithm. Another popular algorithm which is integrated without division of steps, TF-IDF (Salton and McGill, 1983; Frank et al., 1999) is used as a reference method for term extraction. All the proposed algorithms and the reference algorithms need to run a term verification algorithm. For fairness, the term veri</context>
</contexts>
<marker>Salton, McGill, 1983</marker>
<rawString>Salton, G., McGill, M.J. (1983). Introduction to Modern Information Retrieval. McGraw-Hill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Schone</author>
<author>D Jurafsky</author>
</authors>
<title>Is knowledge-free induction of multiword unit dictionary headwords a solved problem</title>
<date>2001</date>
<booktitle>In Proceedings of the 6th Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<pages>100--108</pages>
<contexts>
<context>his study focuses on unithood measures for term candidate extraction only. Existing techniques extract term candidates using two kinds of statistic based measures including internal association (e.g. Schone and Jurafsky, 2001) and context dependency (e.g. Sornlertlamvanich et al., 2000). These techniques are also used in Chinese term candidate extraction (e.g. Chen et al., 2006; Ji and Lu, 2007). All the current technique</context>
<context>ccurrence probability of the whole unit and its component elements are mainly used in these algorithms. Nine widely adopted internal measures, such as frequency and mutual information, are listed in (Schone and Jurafsky, 2001). The second kind is the contextual measure which estimates the strength by the dependency of the candidate on its context using measures such as the left/right entropy (Sornlertlamvanich et al., 200</context>
</contexts>
<marker>Schone, Jurafsky, 2001</marker>
<rawString>Schone, P., Jurafsky, D. (2001). Is knowledge-free induction of multiword unit dictionary headwords a solved problem? In Proceedings of the 6th Conference on Empirical Methods in Natural Language Processing (EMNLP 2001), pp. 100--108.</rawString>
</citation>
<citation valid="false">
<authors>
<author>V Sornlertlamvanich</author>
<author>T Potipiti</author>
<author>T Charoenporn</author>
</authors>
<marker>Sornlertlamvanich, Potipiti, Charoenporn, </marker>
<rawString>Sornlertlamvanich, V., Potipiti, T., Charoenporn, T.</rawString>
</citation>
</citationList>
</algorithm>

