2 Example-based metonymy recognition As I have argued, Nissim and Markert’s (2003) approach to metonymy recognition is quite complex.
P03-1008
Clearly, the classifier did not benefit from WordNet information as Nissim and Markert’s (2003) did from Lin’s (1998) thesaurus.
P03-1008
TiMBL: my TiMBL results N&M: Nissim and Markert’s (2003) results simple learning phase, TiMBL is able to replicate the results from Nissim and Markert (2003; 2005).
P03-1008
This statistical dependency between the reading of a word and its grammatical and semantic context was investigated by Markert and Nissim (2002a) and Nissim and Markert (2003; 2005).
P03-1008 W02-1027
To this goal, Markert and Nissim extracted from the BNC a corpus of possibly metonymical words from two categories: country names (Markert and Nissim, 2002b) and organization names (Nissim and Markert, 2005).
W02-1027
Therefore Nissim and Markert (2003) developed an algorithm that also relied on semantic information, and tested it on the mixed country data.
P03-1008
Nissim and Markert (2003) showed that a combination of semantic and grammatical information gave the most promising results (87%).
P03-1008
It has previously been applied to NLP tasks such as parsing (Hwa, 2002; Osborne and Baldridge, 2004) and Word Sense Disambiguation (Fujii et al., 1998).
J04-3001 J98-4002 N04-1012
However, Nissim and Markert’s (2003) approach has two major disadvantages.
P03-1008
The experiments for the location data were similar to Nissim and Markert’s (2003), and took the following features into account: • the grammatical function of the word (subj, obj, iobj, pp, gen, premod, passive subj, other); • its head; • the presence of a second head; • the second head (if present).
P03-1008
By contrast, since all words of the same semantic class may undergo the same metonymical shifts, metonymy recognition systems can be built for an entire semantic class instead of one particular word (Markert and Nissim, 2002a).
W02-1027
In this respect, it is important to stress that the results for the country data were reached without any semantic information, whereas Nissim and Markert’s (2003) algorithm used Dekang Lin’s (1998) clusters of semantically similar words in order to deal with data sparseness.
P03-1008
Note, moreover, that these results were reached with grammatical information only, whereas Nissim and Markert’s (2003) algorithm relied on semantics as well.
P03-1008
with grammatical information only In order to see if Memory-Based Learning is able to replicate Nissim and Markert’s (2003; 2005) results, I used their corpora for a number of experiments.
P03-1008
The second disadvantage of Nissim and Markert’s (2003) algorithms is their supervised nature.
P03-1008
