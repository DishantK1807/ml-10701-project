<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>Michaela Atterer</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>The effect of corpus size in combining supervised and unsupervised trainin g for disambiguation</title>
<date>2006</date>
<booktitle>In ACL Poster Proceedings</booktitle>
<location>Sydney, Australia</location>
<marker>Atterer, Sch¨utze, 2006</marker>
<rawString>Michaela Atterer and Hinrich Sch¨utze. (2006a). The effect of corpus size in combining supervised and unsupervised trainin g for disambiguation. In ACL Poster Proceedings, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michaela Atterer</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>A latticebased framework for enhancing statistical parsers with information from unlabeled corpora</title>
<date>2006</date>
<booktitle>In Proceedings of CoNLL</booktitle>
<location>New York, USA</location>
<marker>Atterer, Sch¨utze, 2006</marker>
<rawString>Michaela Atterer and Hinrich Sch¨utze. (2006b). A latticebased framework for enhancing statistical parsers with information from unlabeled corpora. In Proceedings of CoNLL, New York, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew W Bilotti</author>
<author>Paul Ogilvie</author>
<author>Jamie Callan</author>
<author>Eric Nyberg</author>
</authors>
<title>Structured retrieval for question answering</title>
<date>2007</date>
<booktitle>In SIGIR</booktitle>
<pages>351--358</pages>
<contexts>
<context>yntactic constructions. It is thus more complex than the relatively simple indexing procedure we present here, and has more overhead for the simpler queries we discuss in this paper. The approach by (Bilotti et al., 2007) is most similar to the work we present here. The authors index a semantically parsed corpus and show that structured retrieval using this index can improve a Question Answering system. However, thei</context>
</contexts>
<marker>Bilotti, Ogilvie, Callan, Nyberg, 2007</marker>
<rawString>Matthew W. Bilotti, Paul Ogilvie, Jamie Callan, and Eric Nyberg. (2007). Structured retrieval for question answering. In SIGIR, pp. 351–358.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Kilgarriff</author>
</authors>
<title>Googleology is bad science</title>
<date>2007</date>
<journal>Computational Linguistics</journal>
<volume>33</volume>
<pages>147--151</pages>
<contexts>
<context> that do not have a fixed word order. Post-processing of search engine results can become a problem for computational efficiency, for example if used in real-time applications like dialogue-systems. (Kilgarriff, 2007) argues against the use of search engines for computational linguistic research using similar arguments. In this paper, we propose an inverted index over grammatical dependencies as an alternative to</context>
<context> engine, we would need a timeconsuming online post-processing of our search results. 3. Greater reliability of the frequency counts. As is well known counts returned by search engines are unreliable (Kilgarriff, 2007) and we have to cope with limitations such as an upper limit on the number of queries a single machine is allowed to issue per day etc. The remainder of this paper is organized as follows: Section 2 </context>
<context>al alternative to using the web for researchers in linguistics and computational linguistics. Alternative tools for searching for grammatical relations and structure in corpora are the sketch engine (Kilgarriff, 2007) and the linguist’s search engine (Resnik and Elkiss, 2003). The sketch engine supports searching corpora for the grammatical behavior of words. It is possible to list a word’s objects together with </context>
</contexts>
<marker>Kilgarriff, 2007</marker>
<rawString>Adam Kilgarriff. (2007). Googleology is bad science. Computational Linguistics, 33(1), pp. 147–151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
<author>Frank Keller</author>
</authors>
<title>The web as a baseline: Evaluating the performance of unsupervised web-based models for a range of nlp tasks</title>
<date>2004</date>
<booktitle>In HLTNAACL</booktitle>
<pages>121--128</pages>
<contexts>
<context>ics retrieved from the world wide web have become a widely-used resource in a variety of NLP tasks, such as candidate selection for machine translation (Lapata and Keller, 2005), spelling correction (Lapata and Keller, 2004), and resolving attachment ambiguities (Volk, 2001). Sometimes, as in (Volk, 2001), raw word counts are found to be insufficient, because further linguistic information of some sort is paramount to i</context>
</contexts>
<marker>Lapata, Keller, 2004</marker>
<rawString>Mirella Lapata and Frank Keller. (2004). The web as a baseline: Evaluating the performance of unsupervised web-based models for a range of nlp tasks. In HLTNAACL, pp. 121–128.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
<author>Frank Keller</author>
</authors>
<title>Web-based models for natural language processing</title>
<date>2005</date>
<journal>ACM Transactions on Speech and Language Processing</journal>
<pages>2--1</pages>
<contexts>
<context> structures. 1. Introduction Word count statistics retrieved from the world wide web have become a widely-used resource in a variety of NLP tasks, such as candidate selection for machine translation (Lapata and Keller, 2005), spelling correction (Lapata and Keller, 2004), and resolving attachment ambiguities (Volk, 2001). Sometimes, as in (Volk, 2001), raw word counts are found to be insufficient, because further lingui</context>
</contexts>
<marker>Lapata, Keller, 2005</marker>
<rawString>Mirella Lapata and Frank Keller. (2005). Web-based models for natural language processing. ACM Transactions on Speech and Language Processing, 2,pp. 1–31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David D Lewis</author>
<author>Yiming Yang</author>
<author>Tony G Rose</author>
<author>Fan Li</author>
</authors>
<title>RCV1: A new benchmark collection for text categorization research</title>
<date>2004</date>
<journal>The Journal of Machine Learning Research</journal>
<volume>5</volume>
<pages>361--397</pages>
<contexts>
<context>Section 6 discusses the limitations of the approach, and Section 7 concludes. 2. Resources for Building a Dependency Index 2.1. Corpus As a corpus we used 80,000,000 words of the Reuters RCV1 corpus (Lewis et al., 2004). It contains newswire text, and about 3,820,057 relations like obj(ect) and subj(ect). The triple “dog obj chase” or “cat subj chase” are examples of the relations obj and sub. The last two weeks of</context>
</contexts>
<marker>Lewis, Yang, Rose, Li, 2004</marker>
<rawString>David D. Lewis, Yiming Yang, Tony G. Rose, and Fan Li. (2004). RCV1: A new benchmark collection for text categorization research. The Journal of Machine Learning Research, 5, pp. 361–397.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Dependency-based evaluation of MINIPAR</title>
<date>1998</date>
<booktitle>In Workshop on the Evaluation of Parsing Systems</booktitle>
<location>Granada, Spain. Lucene</location>
<note>http://lucene.apache.org</note>
<contexts>
<context>two weeks of the Reuters corpus were set apart for future experiments. 2.2. Retrieving Dependencies – Minipar To be able to index over grammatical dependencies, we annotated the corpus using Minipar (Lin, 1998). Minipar is a free partial dependency parser that outputs a dependency structure as shown in Figure 1. ( E0 (() fin C * ) 1 (The The Det 2 det (gov cat)) 2 (cat cat N 3 s (gov chase)) 3 (chases chas</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. (1998). Dependency-based evaluation of MINIPAR. In Workshop on the Evaluation of Parsing Systems, Granada, Spain. Lucene. (2006). http://lucene.apache.org.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Miyao</author>
</authors>
<title>Tomoko Ohta, Katsuya Masuda, Yoshimasa Tsuruoka, Kazuhiro Yoshida, Takashi Ninomiya, and Jun’ichi Tsujii</title>
<date>2006</date>
<booktitle>In Proceedings of COLING-ACL 200</booktitle>
<location>Sydney, Australia</location>
<marker>Miyao, 2006</marker>
<rawString>Yusuke Miyao, Tomoko Ohta, Katsuya Masuda, Yoshimasa Tsuruoka, Kazuhiro Yoshida, Takashi Ninomiya, and Jun’ichi Tsujii. (2006). Semantic retrieval for the accurate identification of relational concepts in massive textbases. In Proceedings of COLING-ACL 200, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomoko Ohta</author>
</authors>
<title>Yusuke Miyao, Takashi Ninomiya, Yoshimasa Tsuruoka, Akane Yakushiji, Katsuya Masuda, Jumpei Takeuchi, Kazuhiro Yoshida, Tadayoshi Hara, Jin-Dong Kim, Yuka Tateisi, and Jun’ichi Tsujii</title>
<date>2006</date>
<marker>Ohta, 2006</marker>
<rawString>Tomoko Ohta, Yusuke Miyao, Takashi Ninomiya, Yoshimasa Tsuruoka, Akane Yakushiji, Katsuya Masuda, Jumpei Takeuchi, Kazuhiro Yoshida, Tadayoshi Hara, Jin-Dong Kim, Yuka Tateisi, and Jun’ichi Tsujii. (2006). An intelligent search engine and GUI-based efficient MEDLINE search tool based on deep syntactic parsing.</rawString>
</citation>
<citation valid="false">
<booktitle>In Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions</booktitle>
<location>Sydney, Australia</location>
<marker></marker>
<rawString>In Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
<author>Aaron Elkiss</author>
</authors>
<title>The linguist’s search engine: Getting started guide</title>
<date>2003</date>
<tech>Technical Report LAMP-TR-108/CS-TR-4541/UMIACS-TR2003-109</tech>
<institution>University of Maryland, College Park</institution>
<contexts>
<context>inguistics and computational linguistics. Alternative tools for searching for grammatical relations and structure in corpora are the sketch engine (Kilgarriff, 2007) and the linguist’s search engine (Resnik and Elkiss, 2003). The sketch engine supports searching corpora for the grammatical behavior of words. It is possible to list a word’s objects together with frequencies, to search for words that behave similarly, and</context>
<context>ow concordances. However, it is not possible to easily search for complex dependency structures and to do a combined search on grammatical structure and surface strings. The linguist’s search engine (Resnik and Elkiss, 2003) supports searching for arbitrary syntactic structures. Its main purpose is to help the “ordinary working linguist without considerable computer skills” to find examples of certain syntactic construc</context>
</contexts>
<marker>Resnik, Elkiss, 2003</marker>
<rawString>Philip Resnik and Aaron Elkiss. (2003). The linguist’s search engine: Getting started guide. Technical Report LAMP-TR-108/CS-TR-4541/UMIACS-TR2003-109, University of Maryland, College Park.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Volk</author>
</authors>
<title>Exploiting the WWW as a corpus to resolve PP attachment ambiguities</title>
<date>2001</date>
<booktitle>In Proceedings of Corpus Linguistics</booktitle>
<contexts>
<context>resource in a variety of NLP tasks, such as candidate selection for machine translation (Lapata and Keller, 2005), spelling correction (Lapata and Keller, 2004), and resolving attachment ambiguities (Volk, 2001). Sometimes, as in (Volk, 2001), raw word counts are found to be insufficient, because further linguistic information of some sort is paramount to increase performance. In the case of PP-attachment f</context>
</contexts>
<marker>Volk, 2001</marker>
<rawString>Martin Volk. (2001). Exploiting the WWW as a corpus to resolve PP attachment ambiguities. In Proceedings of Corpus Linguistics 2001. Ian H. Witten, Alistair Moffat, and Timothy C. Bell.</rawString>
</citation>
</citationList>
</algorithm>

