gual parsing (Burkett et al., 2010), part-of-speech
N10-1015
tences sampled from the web (Papineni et al., 2002).
P02-1040
2006; Haghighi et al., 2009; DeNero and Klein,
P09-1104
Daniel Marcu and William Wong. 2002. A phrase-based,
W02-1018
Kuzman Ganchev, Joao Grac¸a, and Ben Taskar. 2008.
P08-1112
translation systems (Ayan and Dorr, 2006). Let
P06-1002
David A. Smith and Jason Eisner. 2009. Parser adapta-
D09-1086
(Ayan and Dorr, 2006). We trained the model on a
P06-1002
Necip Fazil Ayan and Bonnie J. Dorr. 2006. Going be-
P06-1002
models (He, 2007), extended conditioning contexts
W07-0711
(Haghighi et al., 2009; DeNero and Klein, 2010).
P09-1104 P10-1147
Xiaodong He. 2007. Using word-dependent transition
W07-0711
(Brown et al., 1993) or the HMM-based alignment
J93-2003
John DeNero and Dan Klein. 2010. Discriminative mod-
P10-1147
Yonggang Deng and Bowen Zhou. 2009. Optimizing
P09-2058
and Wong, 2002; DeNero et al., 2008), unsuper-
D08-1033 P08-2007
Dipanjan Das and Slav Petrov. 2011. Unsupervised part-
P11-1061
(Brunning et al., 2009), and external information
N09-1013
Franz Josef Och and Hermann Ney. 2004. The align-
J04-4002
David Burkett, John Blitzer, and Dan Klein. 2010.
N10-1015
Percy Liang, Ben Taskar, and Dan Klein. 2006. Align-
N06-1014
final heuristic (Koehn et al., 2003), produce align-
N03-1017
John DeNero and Dan Klein. 2008. The complexity of
D08-1033 P08-2007
tation maximization algorithm (Liang et al., 2006).
N06-1014
learning (Liang et al., 2006). This approach to
N06-1014
models (Brown et al., 1993). Both IBM Model 1
J93-2003
a combination technique (Deng and Zhou, 2009).
P09-2058
Joao Grac¸a, Kuzman Ganchev, and Ben Taskar. 2008.
P08-1112
(Shindo et al., 2010).
P10-2025
(Blunsom et al., 2009), and supervised ITG models
P09-1088
model projection (Smith and Eisner, 2009; Das and
D09-1086
model (Vogel et al., 1996).
C96-2141
