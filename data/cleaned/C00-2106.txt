Parsing Schemata for Grammars with Variable Number and Order of Constituents Karl-Michael Schneider Departinent of General Linguistics University of Passau Imlstr.
40, 94032 Passau, Germany schneide(@l)hil.uni-t)assau.de Abstract We define state transition grammars (STG) as an intermediate tbrmalism between grammars and parsing algorithms which is intended to separate the description of a parsing strategy from the grammar tbrmalism.
This allows to define more general parsing algorithms for larger classes of grammars, including gramnmrs where the nunfl)er and order of subconstituents detined by a production may not be tlxed.
Various grammar formalisms are characterized in terms of prol)erties of STG's.
We define an Earley parsing schema tbr S'rC's and characterize the wflid l)arse items.
We also discuss the usability of STG's tbr head-(:orner parsing and direct 1)arsing of sets of tree constraints.
1 Introduction
This t)aper addresses the qllestion of how l;o define (talmlar) parsing algorithms on a greater level of al)straction, in order to apply them to larger (:lasses of grammars (as compared to parsing algorithms tbr context-Dee gramlllars).
SllCtl an abstraction is useflll beCallSe it; allows to study l)rot)erties of parsing algorithms, and to compare different parsing algorithms, independently of tile prot)erties of an mtderlying grammar formalism.
While previous atteml)ts to define more general parsers have only aimed at expanding the domain of the nontenninal symbols of a grammar (Pereira and Warren, 1983), this paper aims at a generalization of parsing in a difl'erent dimension, namely to include grammars with a flexible constituent sI;ructure, i.e., where tile sequence of subconstituents specified by a grammar production is not fixed.
We consider two grammar tbrmalisms: Extended context-ii'ee grammars (ECFG) and ID/LP granllllars.
ECFG's (sometimes called r(~.q'ular righ, t part grammars) are a generalization of context-free grammars (CFG) in which a grammar production specifies a regular set of sequences of subconstituents of its left-haM side instead of a fixed sequence of subconstituents.
The righthand side of a production can 1)e represented as a regular set, or a regular expression, or a finite automaton, which are all equivalent concepts (Hopcroft and Ulhnan, 1979).
ECFG's are often used by linguistic and programming language grammar writers to represent a (possibly infinite) set of context-free productions as a single production rule (Kaplan and Bresnan, 1982; Woods, 1973).
Parsing of ECFG's has been studied t br example ill Purdom, Jr.
and Brown (1981)and l;~','r,nakers (1989).
'rab,ll~r parsing teclmiques tbr CFG's can be generalized 1;o ECFG's in a natural way by using the con> putations of the tinite automata in the grammar productions to guide the recognition of new subconstituents.
ID/LP grammars are a variant of CFG's that were introduced into linguistic tbrmalisms to encode word order generalizations (Gazdar et al., 1985).
Her(',, the number of snbconstituents of the left-hand side of a production is fixed, but their order can w~ry.
ID rules (immediate dominance rules) speci(y the subconstituents of a constituent but leave their order unspeeitied.
The adnfissible order|rigs of subeonstituents are specified separate, ly by a set of LP constraints (linear precedence constraints).
A simple approach to ID/LP parsing (called indirect parsing) is to tully expand a grammar into a CFG, but this increases the nmnber of productions significantly.
Therefore, direct; parsing algorithms for ID/LP grammars were proposed (Shieber, 1984).
It is also possible to encode an ID/LP grammar as an ECFG by interleaving the ID rules with LP checking with733 out increasing the number of productions.
However, tbr unification ID/LP grammars, expansion into a CFG or encoding as an ECFG is ruled out because the information contained in the ID rules is only partial and has to be instantiated, which can result in an infinite number of productions.
Moreover, Seiffert (1991) has observed that, during the recognition of subconstituents, a subconstituent recognized in one step can instantiate t~atures on another subconstituent recognized in a previous step.
Theretbre, all recognized subconstituents must remain accessible fbr LP checking (Morawietz, 1995).
We define an intermediate tbrmalism between grammars and parsers (called state transition 9rammars, STG) in which different grammar fbrmalisms, including CFG's, ECFG's, and ID/LP grammars can be tel)resented.
Moreover, admissible sequences of subconstituents are defined in a way that allows a parser to access subconstituents that were recognized in previous parsing steps.
Next, we describe an Earley algorithm tbr STG's, using the parsing schemata ibrmalism of Sikkel (1993).
This gives us a very high level description of Earley's algorithm, in which the definition of parsing steps is separated from the properties of the grammar tbrmalism.
An Earley algorithm for a grammar may be obtained tiom this description by representing the grammar as an STG.
The paper is organized as tbllows.
In Section 2, we define STG's and give a characterization of various grammar tbrmalisms in terms of properties of STG's.
In Section 3 we present an Earley parsing schema for STG's and give a characterization of the wflid parse items.
In Section 4, we introduce a variant; of STG's tbr headcorner parsing.
In Section 5, we discuss the usability of STG's to define parsers for grammars that define constituent structures by means of local tree constraints, i.e., formulae of a (restricted) logical language.
Section 6 presents final conclusions.
2 State
Transition Grammars Wc denote nonterminal symbols with A, B, terminal symbols with a, terminal and nonterminal symbols with X, states with F, strings of symbols with/3, % and the empty string with c.
An STG is defined as tbllows: Definition 1 (ST(\]).
Art STG G is a tuple ( N, E, A~, AJ l;', He, P, S) where • N is a finite set of nonterminal symbols, • E is a finite set of terminal symbols, • A/I is a finite set of states,,, A.4\];, c_.A4 is a set of final states,,, Ha c (.A4 x V) 2 is a binary relation of the form (r,/3) ~-a (F',/3X), where V = NUE, • P C_ N × AJ \ .A41,~ is a set of productions written as A -+ F, and • S E N is a start symbol.
Note thai; we do not allow final states in the right-hand side of a production.
A pair (F,/3) is called a configuration.
If F is a fnal state then (P,/3) is called a final configuration.
The reflexive and transitive closure of \[-c, is denoted with H~.
The state projection of Hc is the binary relation (Ho) = {(r, r')l /3x: (p,/3) (p',/3x)}.
Ha is called context:free iff a transition from (P,/3) does not del)end on fl, tbrmally: for all /3, fl', r, r', x: (r,/3) Ha (r', fiX) iff (r,/3') He; (F',/3'X).
The set of terminal states of G is the set w(C) = {PlVP' : (1 ~, P') ~ ~(Ha)}.
The language defined by a state P is the set of strings in the final configurations reachable t'rom (r, e): L(r) = {/313 r' My: (r, (r',/3)}.
Note that if A --> F is a production then e L(P) (i.e., there are no ~-productions).
The derivation relation is defined by 7A5 ==> 7fl5 itf for some production A ~ P: /3 C L(P).
The language defined by G is the set of strings in E* that are derivable fi'om the start symbol.
We denote a CFG as a tuple (N,E,P,S) where N, E, S are as betbre and P C_ N x V + is a finite set of productions A -+/~.
We assume that there are no e-productions.
An ECFO can be represented as an extension of a CFO with productions of the tbrm A -+ A, where .A = (V, Q, qo, 5, Of) is a nondeterministic finite automaton (NFA) without e-transitions, 734 54 ECFG Q D/LP {MI A+M'cP: MC_M'} {c} Qf F = XF' (r, X, r') ~ r = r'u {x},/~x < LP Tnble 1: Encoding of grmnmars in STG's.
with input alphalmt V, state set Q, initial state q0, final (or accepting) states Q f, m~(t tr~msition relation 5 C_ Q x V x Q (Iopcroft and Ullman, 1979).
A accepts ~ string fl ill tbr some final st;;~l;e q C Q f, (qo,/'-\], q) ~ 5".
Furl;hermore, we assume that q0 ~ Q f, i.e., ..4 does nol; ac(:ept the emi)l;y word.
We can assmne wit;hour loss of generalizal;ion thai, the mfl;omal;a in the right-lmnd sides of a grammar are nll disjoint.
Then we cml rel)resent ml ECFG as a tul)le (N, E, Q, Q f, 5,1 ), S) where N, E, Q, Q f, 5, S m'e as befbre and P C N x (2 is ~t finite set of productions A -> q0 (q0 is ml initial st~te.).
For rely production p = A ~ q0 let A p = (17, Q, q0, (t, Oj).
l)e the NFA with initiM state q0.
The, deriwd;ion relation is detined by 7A5 ~ 7/35 itf fbr some 1)roduction p = A ---> q0, A p accet)ts fl.
An ID/LP grnmm~tr is represented as a l;upie (N~ E, \], LP, S) whoa'e.
N, E, S are as before nnd P is a finite set of productions (ID rules) A --+ M, where.
A C N ;uid ~4 is ~ multiset over V, and LP is a set ()f line~r l)re(:edence constraints.
We are not concerned with de.tails of the LP constra.ints here.
We write fl ~ LP to denote that the sl;ring fi s~d;isties all the constraints in l,P.
The derivation r(;l~|;ion is defined by 7A5 ~ 7\[3d i1\[ fl = X~...X~ and a > {X~,...,Xk} ~ 1" mM fl ~ LI'.
CFG's, ECFG's and ID/LP grmnlnars (:;m t)e chara(:l;erized by al)t)rol)ri~te restrictions on the transition relation and the fired st;~l;es of an STG: ~ • CFG: \]-o is context-free and deterministic, cy(t-6,) is acyelic, 2~4F = T(G).
• ECFG: t-a is context-free.
• ID/LP: or(t-(;) is aeyclic: J~41,' = T(G), for all F: iffl, 7 C L(F) then 7 is ~t permutal,iolt These conditions define normal-forms of STG's; that is, for STG's that do not, satist~y the conditions for some type there can nevertheless lm strongly equivalent grammars of that; t;ype.
These STG's are regarded as degenerate mM are not fllrther considered.
of ft.
For instance, if G is an STG that satisfies the conditions tbr CFG's, then a CFG G / can be constructed as follows: l,br every production A -~ q0 in G, let A -~ fl be a production in G' whe.re L(qo) = {/3}.
Then the deriw~tion relations of G mid G' coincide.
Similarly tbr the other grammar tyl)es.
Conversely, if ~t grammar is of a given type, l;hen it (:ml be rel)resented as ml STG satist~ying the conditions tbr that type, by spe(:it~ying the states and transition relation, as shown in Table 1 (tO denotes nmltiset lnlion).
3 Earley
Parsing Parsing schemat~ were proposed by Sikkel (1.993) as a framework for the specific~tion 0rod comparison) of tabular parsing algorithms.
Parsing schemata provide n well-detined level of abstra(:l;ion by al)stra(:ting fi'om (:ontrol structures (i.e., or(lering of operations) and (later structures.
A parsing schem;t cmJ \])e implemented as n tabulm: parsing ;flgorithm in ~ em~onical w;~y (Sikkel, 1998).
A \])re:sing schema for n gr;tllllll;~r cla,ss is & function that assigns ('.~mh grmnmar and each input string a deduction system, called a parsing sy.ste.m.
A parsing schema is usmdly defined by pre.senting a parsing system.
A parsing system consists of ~ finite set Z of pars(; items, a finite set "H of hyt)otheses, whi(:h ell(:()(\](; the input string, mxd ~ finite set 29 of deduction stel)s of the fbrm x~,...,x, ta: where xi C 2; U ~ and x E Z.
The hypotheses can be represented as deduction steps with empty prenfises, so we can assume that, all xi m'e it;eros, and represent a parsing system as a pair (Z, 29).
Correctness of a l)~rsing system is defined with respect to some item senmntics.
Every item denotes a particub~r deriw~tion of some substring of the input string.
A parsing syste.m is correct if an item is deducible precisely if it denotes an admissible deriw~tion.
Items that denote admissible derivations are called coffee/,.
735 Z={\[A~/3.F,i,j\]IAEN, flEV*, £EM, 1/31 <.,, O<i<j<n} D Init =S--~ P E P \[S ~ .r, 0,0\] Dpredi~t = \[A --+ ft.
P, i, j\] T)Comp I =_ \[B --+ .P0,j,j\] \[A + fl.P,i,j\] \[A -+ \[3aj+l.
F', i, j + 1\] r': (r,/3) No (r',/~B), B -~ ro e p (r,/5) \[-G (r',/3aj+l) \[A ~ /3.r,i,j\] \[B ~,>r:, j, k\] \[A -+ fiB.
£', i, t~\] r: E M,, (r,/3) >a (r',/3~) Figure 1: The Earley parsing schema for an STG G and input string w = al ...
an. STG's constitute a level of abstraction between grammars and parsing schemata because they can be used to encode various classes of grammars, whereas the mechanism for recognizing admissible sequences of subconstituents by a parsing algorithm is built into the grammar.
Thereibre, STG's allow to define the parsing steps separately fiom the mechanism in a grmnmar that specifies admissible sequences of subconstituents.
A generalization of Earley's algorithm ibr CFG's (Earley, 1970) to STG's is described by the parsing schema shown in Fig.
1. An item \[A -~/3.P, i, j\] denotes an A-constituent that is partially recognized fi'om position i through j in tile input string, where/3 is the sequence of recognized subconstituents of A, and a sequence of transitions that recognizes ~ can lead to state F.
Note that the length of/5 can be restricted to the length of the int)ut string because there are no g-productions.
In order to give a precise definition of the semantics of the items, we define a derivation relation which is capable of describing the partial recognition of constituents.
This relation is defined on pairs (7, A) where 7 E V* and A is a finite sequence of states (a pair (% A) could be called a super configuration).
7 represents the fi'ont (or yield) of a partial derivation, while A contains one state for every partially recognized constituent.
Definition 2.
The Earley derivation relation is defined by th, e clauses: • (TA, A) ~ (7/5, FA) iff 3A --+ P' E P: (r', e) e5 (r,/3).
• (TAa, A) p (7/3a, A) /ff 7Aa ~ 798.
The first clause describes the I)artial recognition of an A-constituent, where/3 is the recognized part and tile state P is reached when /3 is recognized.
The second clause describes ~he complete recognition of an A-constituent; in this case, the final state is discarded.
Each step ill the derivation of a super configuration (% A) corresponds to a sequence of deduction steps in the parsing schema.
As a consequence of the second clause we have that w E L(G) iff (S, c) ~* (w, c).
Note that ~-, is too weak to de-scribe the recognition of the next subconstituent of a partially recognized constituent, but it is sufficient to define the semantics of the items in Fig.
1. The fbllowing theorem is a generalization of the definition of the semantics of Earley items for CFG's (Sikkel, 1993) (al... an is the input string): Theorem 1 (Correctness).
F* \[A --+/3.F, i,j\] iff the conditions are satisfied: • for some A, (S, c) \]'--,* (al... aiA, A).
• (A, e) b" (/3, F).
• /3 ::==>* ai+ 1 . ..
aj. The first and third condition are sometimes called top-down and bottom-up condition, respectively.
The second condition refers to the partial recognition of the A-constituent.
736 \[~ -~.
~,, 0, 0\] (re, ~) >* (r,, ~), (E, ~) \[~ (~, q~) IT -~ .q3,0,0\] (m~) ~ (T,<~), (T,~) p (~, ¢~) (m ~) ~ (T, ~) \[F -+ .q,~, 0, 0\] (E,E) t..,(T,q,jI--,(F, q4q2), (F,~) ~ (E, qs) (Z, ~) \[(T, q2) b (F, ~t2) (z, ~) > (T, ~) b (F, <s4) (z, ~) b (m, ~) b (F, ~) \[F --> a.qu, 0, 1\] (E,e) b(T,q,jb(F,q,lq,2), (F,e)~,,(a, qo) (m ~) b (T, w) b (r, w) (m ~) P (T, ~) b (r, q4) (E, ~) b (T, ~) b (F, ~) \[T -+ S~.~s4,O,q (E,~)b(T, q2), (T,~)p(S<,s4), F~*a (E, ~) b (T, ~) \[\]'~ --+ a.
q6, 2, 3\] (E,m) b(T, q2) b(17*F, qaq2) b(a*F, q4q2), (/P, ¢) b (a, q6) (m ~) b (T, q~) b (~ * s< v',) b (o,.
F, w) (z, ~) \[~ (T, ~) \[~ (F • F, q4) \[~ (o,.
~, w) (m ~) I--.
(T, ~) I--' (F • sV, ~) t-' (<, * S< ~) \[E--+T*T.q,2,0,3\] (E,g) V*(E,e), (E,g)~,,(T*T, q2), T*T==>*a*a ~ihble 2: Valid parse items and derbable super configurations for a * a.
Example 1.
Consider the following STG: G = ({z, T, r}, to,, +, .}, {m,..., <~6}, {q~, q4, q~}, FG, P, E), P = {E --> q~, T --> qa, F -+ q,~} with the following transitions (for all fi): (m, l~) i-(~ (<s~, I~T), (,s~, i~) i-c~ (m, i~+), (qa, i3) t-c (q4,/~S~), (<S4, h ~) i-c; (<S:~, iJ*), (q,~, f~) i-c (<so,/Ja).
Table 2 shows soule valid parse items fbr the recognition of the string a * a, together with the conditions according to Theorem 1.
4 Bidirectional
Parsing STG's describe the recognition of admissible sequences of subconstituents in unidirectional parsing algorithms, like Earley's algorithm.
Bidirectional parsing strategies, e.g., head-conic< strategies, start the recognition of a sequence of subconstituents at sonic position in the middle of the sequence and proceed to both sides.
We can define appropriate STG's for 1)idirectional parsing strategies as follows.
Definition 3.
A h, eaded, bidirectional STG G is like an STG excq~t that P is a finite set of productions of the form A --+ (P,X, A), 'where A c N and X E V and F, A c .M.
The two states in a production accOullt for the bidirectional expansion of a constituent.
The derivation relation for a headed, bidirectional STG is defined by 7A6 ~ 7fllXfl"6 if\[ for some production A -+ (P, X, A): (fit)-* c L(P) and fi' C L(A) ((S) -1 denotes the inversion of fit).
Note that P defines the left part of an adnfissible sequence Doul right to left,.
A t)ottom-up head-conmr parsing schema uses items of the tbrm \[A -+ F.
fl. A, i, j\] (Schneider, 2000).
The semantics of these items is given by the tbllowing clauses: • tbr some production A ~ (P0, X, A0), some fll,fl,.: fl = flZXflr and (P0,e) t-G (r, (/~)-~) dud (A0,~)~o (a,,/~").,, /3 ~* ai+l.., aj.
5 Local
Tree Constraints In this section we discuss the usability of STG's for the design of direct parsing algorithms for grammars that use a set of well-fonnedness conditions, or constraints, expressed in a logical language, to define the admissible syntactic structures (i.e., trees), in contrast to grammars that are based on a derivation mechanism 737 (i.e., production rules).
Declarative characterizations of syntactic structures provide a nlealiS to tbrmalize grammatical frameworks, and thus to compare theories expressed in different formalisms.
There are also applications in theoretical explorations of the complexity of linguistic theories, based on results which relate language classes to definability of structures in certain logical languages (Rogers, 2000).
From a model-theoretic point of view, such a grammar is an axiomatization of a class of structures, and a well-formed syntactic structure is a model of the grammar (Blackt)urn et al., 1993).
The connection between models and strings is established via a yield function, which assigns each syntactic structure a string of terminal symbols.
The parsing problem can then be stated as the problem: Given a string w and a grammar G, find the models .A4 with A.4 ~ G and yieId(./V4) = w.
In many cases, there are eft~ctive methods to translate logical fornmlae into equivalent tree automata (Rogers, 2000) or rule-based grammars (Pahn, 1997).
Thus, a possible way to approach the parsing problem is to translate a set of tree constraints into a grammar and use standard parsing methods.
However, depending on the expressive power of the logical language, the complexity of the translation often limits this approach in practice.
In this section, we consider the possibility to apply tabular parsing methods directly to grammars that consist of sets of tree constraints.
The idea is to interleave the translation of tbrmulae into production rules with the recognition of subconstituents.
It should be noted that this approach suffers from the same complexity limitations as the pure translation.
In Schneider (1999), we used a fragment of a propositional bimodal language to express local constraints on syntactic structures.
The two modal operators ($} and (-~) refer to the leftmost child and the right sibling, respectively, of a node in a tree.
Furthermore, the nesting of ($) is limited to depth one.
A so-called modal grammar consists of a formula that represents the conjunction of a set of constraints that must be satisfied at every node of a tree.
In addition, a second formula represents a condition tbr the root of a tree.
In Schneider (1999), we have also shown how an extension of a standard nlethod tbr automatic proof search in modal logic (socalled analytic labelled tableauz) in conjmmtion with dynamic progrmnming techniques can be employed to parse input strings according to a modal grammar.
Basically, a labelled tableau procedure is used to construct a labelled tableau, i.e., a tree labelled with tbrmnlae, by breaking tbrmulae up into subtbrmulae; this tableau may then be used to construct a model tbr the original formula.
The extended tableau procedure constructs an infinite tableau that allows to obtain all admissible trees (i.e., models of the grammar).
The approach can be described as tbllows: An STG is defined by using certain formulae that appear on the tableau as states, and by defining the transition relation in terms of the tableau rules (i.e., the operations that are used to construct a tableau).
The states are formulae of the form x A A<,>o A AI.
\]o' A A A\[q ' where X is a propositional variable and \[$\], \[-->\] are the dnal operators to (.\[), (~).
X is used as a node \]abe\] in a tree model.
The transition relation can be regarded as a silnnlation of the application of tableau rules to fbrmulae, and a tabular parser tbr this STG can be viewed as a tabulation of the (infinite) tal)leau construction.
In particular, it should be noted that this construction makes no reference to any particular parsing strategy.
6 Conclusion
We have defined state transition grammars (STG) as an intermediate formalism between grammars and parsing algorithnls.
They complement the parsing schemata formalism of Sikkel (1993).
A parsing schema abstracts from unimportant algorithmic details and thus, like STG's, represents a well-defined level of abstraction between grammars and parsers.
STG's add another abstraction to parsing schemata, namely on the grammar side.
Therefore, we argued, a t)arsing schenla defined over a STG represents a very high level description of a tabular parsing algorithm that can be applied to various gralnlnar tbrmalisms.
In this paper we concentrated on grammar formalisms with a flexible constituent structure, i.e., where the 738 mmfl)er and order of subconstituents st)e(:ified by a grammar i)roduction may not \[)e fixed.
In particular, we have discussed extended contextfree grammars (ECFG), II)/LP grammars, and grammars in which admissible trees are delined by means of local tree ('onstraints cxI)resscd in a simple logical language.

