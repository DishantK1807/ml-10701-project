MERGING THE ART OF REPRESENTING DIFFERENT LEVELS OY SENTENCE STRUCTURE IN A SINGLE ANALYSIS TREE.
Frank VanEynde Departement Linguistlek, Blljde Inkomststraat, 21 B 3000 Leuven, Belgium !~ An unproblematic example The first example illustrates the merging of a part of speech analysis with a functional analysis, ltl t Part of speech analysis and the on line principle A part of speech analysis consists in the assignment of category labels to lexicai units.
By adding parsing rules to the categorial analysis one could also carry out the next step of@rouping those lexical units into larger synta~atic units, The principle governing the part of speech analysis is the on llne principle:, syntagmatic units are analysed from the left to the right without changing the word order~ • Example: (I) Harry promised me a new car (' ") Is ~ H~,y~ Cv Pr°misedJ/~o =eli ~T a\] \[A new\] C.
car? \] lt2t Functional analEsie and the dependency principle functional analysis consists in the assignment of function labels to synta~natlc units.
The principle governing the functional analysis is the dependency principle: every syntaEmatic unit (~ sentence) 95 contains one and only one lexical unit functioning as its he ad • Example: ( I" ) SUJ G0V I0 DO GOVI promised J | I Harry me a GOV car I new The sister nodes of each GOV-node are either terminal nodes, in which case there is no function label specified• cf.
the node of the indefinite article.
or non-terminal nodes, in which case the function label takes one of the following values: SUJ, DO, IO, ~F (= modifier),...
The function labels specify the kind of relation holding between the head and its dependents• Por instance, "Harry" is the subject of "promised", "new" is a modifier of "oar", etc.
1,3, A synthetic representation Assumption: the part of speech analysis and the functional analysis can be represented in the same tree, since the on llne principle and the dependency principle are compatible.
. Example: (I) I I 1 i,.ovJ I C a.l~" Harry me a l new 96 2 t A problematic example: the result clause I'll be co~ erned with the external structure of the result clause only, not with its internal structure; the result clause will, consequently, be treated as an unanalyeed synt~gmatic unit.
2,1, A part of speech anal2sis of the result clause Example: (2) He left so early on Tuesday that we missed him (2°) \[4RO heJ IV left'lAdy so~ \[Adv early~ \[p on~ 4 uesdaY3 rs that we ssed We could add some further structure to this bracketing by subsuming the adjacent adverbs under one node: ~\[Adv so~ lAdy early33 We can, however, not incorporate the "that"-clause into this eyntagmatic unit, since the prepositional phrase "on Tuesday" intervenes between both parts.
2,2~ A functional anal2sis of the result clause The ~rucial question concerning the functional analysis of a sentence llke (2) is: which constituent governs the "that"-clause?
In other words, where do ~e have to attach the S-node of the result clause?
Pot reasons (to be given in the full version of this paper) we propose the following dependence structure for (2): (2") SUJ GOV MP GOV left ~IP GOV on Tuesday l /'~L he GOV J N~ early so that we missed him 972.3.
A synthetic representation 2.3.1.
Unfortunately, the part of speech analysis and the functional analysis do not match (cf.
the disturbance of the word order in (2").
A marging of the labeled bracketing with the dependency structure would give the following result: (II) r~,-~\] @Ro~,~ EA,GOVJ on Tuesday tiat.., him he ~A,GOg \[-,MFJ early l so The lowest MF-node dominates no lexlcal material, and has, consequently, no category label.
The righmost S-node, on the other hand, has no functional label, since it does not bear any dependency relation to the verb.
Important to note is the fact that both deficient nodes are complementary, and that they in fact refer to each other.
In order to make thls relation explicit, I propose to add an index (an arbitrary integer) to both nodes: (II),..
~-,MPJ1 ...~S,-~i Thanks to this coindexlng device we are able to merge two levels of sentence structure, although they do not seem to be compatible at first sight.
2.3.2. The computation of (II) can be performed in a straightforward way: ...
so ...
A,®V so-J "JJ'''J 2.
If there is a that-clause in S', then give it a ~S,-Ji-node, and attach it immediately under the S"-node.
If there is no such clause, then delete the L-,MPJi-node.
98 Comparison with a transformational treatment.
2.3.3. Similar analyses can.
be given for all kinds of comparison clauses.
~t A third example: deep and surface sub teots ~tl~ On the notion "surface sub,~ect" 3.2.
On the notion "deep subject" 3.3.
A synthetic representation In a sentence like (3) it seems that Steve likes her it could be argued that the surface subject and the deep subject do not coincide.
Making use of some new notations (to be explained in the full version of this paper) and of the device already known from section 2.3.1.
I propose the following analysis tree for (3): (III) \[S,-,-3 1 ! i .-...'-"'. that likes her ~PRO, GOV\] seems Steve Merging is a technique of representing different levels of syntactic (and semantic) structure in one analysis tree.
In order to make merging work one has to make sure that: 1.
each level of analysis is properly defined, i.e. that there exists a list of possible values for the labels that there is an algorithm for assigning those values in each particular case that there is a unifying principle at each level (for instance, the dependency principle at the level of functional analysis).
2. The relations between the different levels are properly defined.
In order to ~-,~rant the latter I have pleaded for 99 adding referenoe indices to the nodes, thus introducing a new formal device in the ~ra~mar a third dimension in the an~ysis tree.
Some merits of the merging technique in a progrsm .for automatic translation.
100 -

