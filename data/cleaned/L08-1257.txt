<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>T Brants</author>
</authors>
<title>Tnt a statistical part-of-speech tagger</title>
<date>2000</date>
<booktitle>Proceedings of the Sixth Applied Natural Language Processing</booktitle>
<contexts>
<context>(1,2)(2,0) 112 11% Most freq. patterns 617 60.4% Table 2: Reordering patterns for Es2En reference alignment of 500 sentences English POS-tagging was carried out using the freely available TNT tagger (Brants, 2000) and lemmatization using wnmorph included in WordNet package (Miller et al., 1991). In Spanish, we used the FreeLing (Carreras et al., 2004) analysis tool which generates the POS-tagging and the lemm</context>
</contexts>
<marker>Brants, 2000</marker>
<rawString>T. Brants. 2000. Tnt a statistical part-of-speech tagger. Proceedings of the Sixth Applied Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Carreras</author>
<author>I Chao</author>
<author>L Padr´o</author>
<author>M Padr´o</author>
</authors>
<title>Freeling: An open-source suite of language analyzers</title>
<date>2004</date>
<booktitle>In 4th Int. Conf. on Language Resources and Evaluation, LREC’06</booktitle>
<location>Lisboa, Portugal</location>
<marker>Carreras, Chao, Padr´o, Padr´o, 2004</marker>
<rawString>X. Carreras, I. Chao, L. Padr´o, and M. Padr´o. 2004. Freeling: An open-source suite of language analyzers. In 4th Int. Conf. on Language Resources and Evaluation, LREC’06, Lisboa, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Crego</author>
<author>J Mari˜no</author>
<author>A Gispert</author>
</authors>
<title>Reordered search and tuple unfolding for ngram-based smt. MT Summit X</title>
<date>2005</date>
<marker>Crego, Mari˜no, Gispert, 2005</marker>
<rawString>J. M. Crego, J. Mari˜no, and A. Gispert. 2005. Reordered search and tuple unfolding for ngram-based smt. MT Summit X.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A de Gispert</author>
<author>J Mari˜no</author>
</authors>
<title>Experiments in word-ordering and morphological preprocessing for transducer-based statistical machine translation</title>
<date>2003</date>
<booktitle>In IEEE Automatic Speech Recognition and Understanding Workhsop, ASRU’03</booktitle>
<pages>634--639</pages>
<publisher>St. Thomas, USA</publisher>
<marker>de Gispert, Mari˜no, 2003</marker>
<rawString>A. de Gispert and J. Mari˜no. 2003. Experiments in word-ordering and morphological preprocessing for transducer-based statistical machine translation. In IEEE Automatic Speech Recognition and Understanding Workhsop, ASRU’03, pages 634–639, St. Thomas, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A de Gispert</author>
</authors>
<title>Phrase linguistic classification for improving statistical machine translation</title>
<date>2005</date>
<booktitle>In ACL 2005 Students Workshop</booktitle>
<location>Ann Arbor, USA</location>
<marker>de Gispert, 2005</marker>
<rawString>A. de Gispert. 2005. Phrase linguistic classification for improving statistical machine translation. In ACL 2005 Students Workshop, Ann Arbor, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kanthak</author>
<author>D Vilar</author>
<author>E Matusov</author>
<author>R Zens</author>
<author>H Ney</author>
</authors>
<title>Novel reordering approaches in phrase-based statistical machine translation</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Building and Using Parallel Texts: DataDriven Machine Translation and Beyond</booktitle>
<pages>167--174</pages>
<location>Ann Arbor, MI</location>
<contexts>
<context>y using GIZA++ (Och and Ney, 2003). Generally, this alignment contains a certain amount of errors which deteriorates the translation quality. One way of improving this alignment is by monotonization (Kanthak et al., 2005), i.e. reordering the words in the source sentence following the order of the words in the target sentence. For instance in a Spanish to English translation, the original sentence El discurso pol´ıti</context>
</contexts>
<marker>Kanthak, Vilar, Matusov, Zens, Ney, 2005</marker>
<rawString>S. Kanthak, D. Vilar, E. Matusov, R. Zens, and H. Ney. 2005. Novel reordering approaches in phrase-based statistical machine translation. In Proceedings of the ACL Workshop on Building and Using Parallel Texts: DataDriven Machine Translation and Beyond, pages 167– 174, Ann Arbor, MI, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>F J Och</author>
<author>D Marcu</author>
</authors>
<title>Statistical phrasebased translation</title>
<date>2003</date>
<booktitle>In Proc. of the Human Language Technology Conference, HLT-NAACL’2003</booktitle>
<pages>48--54</pages>
<location>Edmonton, Canada</location>
<contexts>
<context> the phrase. We limit the maximum size of any given phrase to 7. The huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (Koehn et al., 2003) as the probability of reappearance of larger phrases decreases. Given the collected phrase pairs, we estimate the phrase translation probability distribution by relative frequency in both directions</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>P. Koehn, F.J. Och, and D. Marcu. 2003. Statistical phrasebased translation. In Proc. of the Human Language Technology Conference, HLT-NAACL’2003, pages 48– 54, Edmonton, Canada, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Lambert</author>
<author>A de Gispert</author>
<author>R Banchs</author>
<author>J Mari˜no</author>
</authors>
<title>Guidelines for word alignment and manual alignment</title>
<date>2006</date>
<journal>Language Resources and Evaluation</journal>
<volume>39</volume>
<marker>Lambert, de Gispert, Banchs, Mari˜no, 2006</marker>
<rawString>P. Lambert, A. de Gispert, R. Banchs, and J. Mari˜no. 2006. Guidelines for word alignment and manual alignment. Language Resources and Evaluation, 39(4):267–285. J.B. Mari˜no, R.E. Banchs, J.M. Crego, A. de Gispert, P. Lambert, J.A.R. Fonollosa, and M.R. Costa-juss`a.</rawString>
</citation>
<citation valid="true">
<title>N-gram based machine translation</title>
<date>2006</date>
<journal>Computational Linguistics</journal>
<volume>32</volume>
<marker>2006</marker>
<rawString>2006. N-gram based machine translation. Computational Linguistics, 32(4):527–549, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
<author>R Beckwith</author>
<author>C Fellbaum</author>
<author>D Gross</author>
<author>K Miller</author>
<author>R Tengi</author>
</authors>
<title>Five papers on WordNet</title>
<date>1991</date>
<journal>Special Issue of International Journal of Lexicography</journal>
<volume>3</volume>
<contexts>
<context>ns for Es2En reference alignment of 500 sentences English POS-tagging was carried out using the freely available TNT tagger (Brants, 2000) and lemmatization using wnmorph included in WordNet package (Miller et al., 1991). In Spanish, we used the FreeLing (Carreras et al., 2004) analysis tool which generates the POS-tagging and the lemma for each input word. Table 1, presents some basic statistics of training, develo</context>
</contexts>
<marker>Miller, Beckwith, Fellbaum, Gross, Miller, Tengi, 1991</marker>
<rawString>G.A. Miller, R. Beckwith, C. Fellbaum, D. Gross, K. Miller, and R. Tengi. 1991. Five papers on WordNet. Special Issue of International Journal of Lexicography, 3(4):235–312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Nelder</author>
<author>R Mead</author>
</authors>
<title>A simplex method for function minimization</title>
<date>1965</date>
<journal>The Computer Journal</journal>
<volume>7</volume>
<pages>313</pages>
<contexts>
<context>ase and it is only used for the phrasebased system. All these feature functions are combined in the decoder. The different weights are optimized on the development set applying the Simplex algorithm (Nelder and Mead, 1965). 4. Evaluation framework 4.1. Corpus statistics Experiments have been carried out using the EPPS database (Spanish-English). The EPPS data set corresponds to the parliamentary session transcriptions</context>
</contexts>
<marker>Nelder, Mead, 1965</marker>
<rawString>J.A. Nelder and R. Mead. 1965. A simplex method for function minimization. The Computer Journal, 7:308– 313.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Nießen</author>
<author>H Ney</author>
</authors>
<title>Statistical machine translation with scarce resources using morpho-syntactic information</title>
<date>2004</date>
<journal>Computational Linguistics</journal>
<volume>30</volume>
<contexts>
<context>ot require extra information that is not employed in an standard SMT system. But it is interesting to benefit from morphological information, if available, in SMT as have been shown in other studies (Nießen and Ney, 2004; de Gispert, 2005). 3. Baseline systems Two baseline systems are proposed to test our approach. The main difference between the two systems is the translation model, which constitutes the actual core</context>
</contexts>
<marker>Nießen, Ney, 2004</marker>
<rawString>S. Nießen and H. Ney. 2004. Statistical machine translation with scarce resources using morpho-syntactic information. Computational Linguistics, 30(2):181–204, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models</title>
<date>2003</date>
<journal>Computational Linguistics</journal>
<volume>29</volume>
<contexts>
<context>tems are trained by using a bilingual corpus composed of bilingual sentences. Each bilingual sentence is composed of a source and target sentence, and we align them at the word level by using GIZA++ (Och and Ney, 2003). Generally, this alignment contains a certain amount of errors which deteriorates the translation quality. One way of improving this alignment is by monotonization (Kanthak et al., 2005), i.e. reord</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>F. J. Och and H. Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Popovic</author>
<author>H Ney</author>
</authors>
<title>Pos-based word reorderings for statistical machine translation</title>
<date>2006</date>
<booktitle>In 5th International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>1278--1283</pages>
<location>Genoa</location>
<contexts>
<context>entence El discurso pol´ıtico fue largo would be modified as El pol´ıtico discurso fue largo. And it would monotonize the alignment: El#The pol´ıtico#political discurso#speech fue#was largo#long. In (Popovic and Ney, 2006), they perform rules based on Part of Speech (POS) tags and reorder pairs of words both in the training and test sentences. Similarly, we propose one type of monotonization: pairs of consecutive bloc</context>
</contexts>
<marker>Popovic, Ney, 2006</marker>
<rawString>M. Popovic and H. Ney. 2006. Pos-based word reorderings for statistical machine translation. In 5th International Conference on Language Resources and Evaluation (LREC), pages 1278–1283, Genoa, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
</authors>
<title>Srilm an extensible language modeling toolkit</title>
<date>2002</date>
<booktitle>In Proc. of the 7th Int. Conf. on Spoken Language Processing, ICSLP’02</booktitle>
<pages>901--904</pages>
<location>Denver, USA</location>
<contexts>
<context>am probabilities. As default language model, a standard word-based 5-gram language model is generated with smoothing Kneser-Ney and interpolation of higher and lower order ngrams with the SRILM tool (Stolcke, 2002). • The forward and backwards lexicon models provide lexicon translation probabilities for each phrase/tuple based on the word IBM model 1 probabilities. For computing the forward lexicon model, IBM </context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>A. Stolcke. 2002. Srilm an extensible language modeling toolkit. In Proc. of the 7th Int. Conf. on Spoken Language Processing, ICSLP’02, pages 901–904, Denver, USA, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Tillmann</author>
<author>T Zhang</author>
</authors>
<title>A localized prediction model for statistical machine translation</title>
<date>2005</date>
<booktitle>In ACL</booktitle>
<contexts>
<context>r approach learns the blocks which swap instead of following a pre-defined set of rules. Figure 1 shows an example of this type of pairs. The reordering based in blocks covers most cases as shown in (Tillmann and Zhang, 2005). 2.2. Reordering process Our purpose is to model the effect of local block reordering to: (1) monotonize the source training corpus; and (2) generalize this monotonization in the test stage to perfo</context>
</contexts>
<marker>Tillmann, Zhang, 2005</marker>
<rawString>C. Tillmann and T. Zhang. 2005. A localized prediction model for statistical machine translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Zens</author>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Improvements in phrase-based statistical machine translation</title>
<date>2004</date>
<booktitle>In Proc</booktitle>
<contexts>
<context>s over the initial wordbased translation. At the end of the last decade the use of context in the translation model (phrase-based approach) represented a clear improvement in the translation quality (Zens et al., 2004). In parallel to the phrase-based approach, the use of a language model of bilingual units gives comparable results to the phrase-based approach (Mari˜no et al., 2006). In both systems, the introduct</context>
<context>f phrase-based translation is to segment the given source sentence into units (here called phrases), then translate each phrase and finally compose the target sentence from these phrase translations (Zens et al., 2004). Given a sentence pair and a corresponding word alignment, a phrase (or bilingual phrase) is any pair of m source words and n target words that satisfies two basic constraints: 1. Words are consecut</context>
</contexts>
<marker>Zens, Och, Ney, 2004</marker>
<rawString>R. Zens, F.J. Och, and H. Ney. 2004. Improvements in phrase-based statistical machine translation. In Proc.</rawString>
</citation>
</citationList>
</algorithm>

