Proceedings of the 2010 Workshop on Companionable Dialogue Systems, ACL 2010, pages 43–48,
Uppsala, Sweden, 15 July 2010. c©2010 Association for Computational Linguistics
VCA: An Experiment With A Multiparty Virtual Chat Agent 
Samira Shaikh
1, Tomek Strzalkowski
1, 2, Sarah Taylor
3, Nick Web
1
 
1
ILS Institute, University at Albany, State University of New York 
2
Institute of Computer Science, Polish Academy of Sciences 
3
Advancded Technology Office, Lockhed Martin IS&GS 
E-mail: ss578726@albany.edu, tomek@albany.edu 
 
 
Abstract 
The purpose of this research was to advance 
the understanding of the behavior of small 
groups in online chat rooms. The research was 
conducted using Internet chat data colected 
through planned exercises with recruited par-
ticipants. Analysis of the collected data led to 
construction of preliminary models of social 
behavior in online discourse. Some of these 
models, e.g., how to efectively change the 
topic of conversation, were subsequently im-
plemented into an automated Virtual Chat 
Agent (VCA) prototype. VCA has ben dem-
onstrated to perform efectively and convinc-
ingly in Internet conversation in multiparty 
chat environments. 
1 Introduction

Internet chat rooms provide a ready means of 
comunication for people of most age groups 
these days. More often than not, these virtual 
chat roms have multiple participants conversing 
on a wide variety of topics, using a highly infor-
mal and fre-form text dialect. An increasing use 
of virtual chat rooms by a variety of demograph-
ics such as small children and impresionable 
youth leads to the risk of exploitation by deceit-
ful individuals or organizations. Such risks might 
be reduced by presence of virtual chat agents that 
could keep conversations from progresing into 
certain topics by changing the topic of conversa-
tion.  
Our aim was to study the behavior of smal 
groups of online chat participants and derive 
models of social phenomena that ocur fre-
quently in a virtual chat environment. We used 
the MPC chat corpus (Shaikh et al., 2010), which 
is 20 hours of multi-party chat data collected 
through a series of carefully designed online chat 
sessions. Chat data colected from public chat 
rooms, while easily available, presents signifi-
cant concerns regarding its adaptability for our 
research use. Publicly available chat data is com-
pletely anonymous, has a high level of noise and 
lack of focus, in adition to engendering user 
privacy isues for its use in modeling tasks. The 
MPC corpus was used in (1) understanding how 
certain social behaviors are reflected in language 
and (2) building an automated chat agent that 
could effectively achieve certain (initially lim-
ited) social objectives in the chat-room. A brief 
description of the MPC corpus and its relevant 
characteristics is given in Section 3 of this paper. 
One specific phenomenon of social behavior 
we wanted to model was an efective change of 
conversation topic, when a participant or a group 
of participants deliberately (if perhaps only tem-
porarily) shift the discussion to a diferent, pos-
sibly related topic. Both sucess and failure of 
these actions was of interest because the outcome 
depended upon the choice of utterance, the per-
sons to whom it was adressed, their reaction, 
and the time when it was produced. Our analysis 
of the corpus for such phenomena led to the use 
of an annotation scheme that alows us to anno-
tate for topic and focus change in conversation. 
We describe the anotation scheme used in Sec-
tion 4.  
We constructed an autonomous virtual chat 
agent (VCA) that could achieve initially limited 
social goals in a chat rom with human partici-
pants. We used a novel approach of exploiting 
the topic of conversation underway to search the 
web and find related topics that could be inserted 
in the conversation to change its flow. We tested 
the first prototype with the capability to oportu-
nisticaly change to topic of conversation using a 
combination of linguistic, dialogic, and topic 
reference devices, which we observed efectively 
deployed by the most influential chat participants 
in the MPC corpus.  The VCA design, architec-
ture and mode of operation are described in de-
tail in Section 5 of this paper. 
2 Related
Work 
Automated dialogue agents such as the early 
ELIZA (Weizenbaum, 196) and PARY 
43
(Colby, 1974) could conduct a one-on-one “con-
versation” with a human using rules and patern-
matching algorithms. More recently, the addition 
of heuristic patern matching in A.L.I.C.E 
(Walace, 208) led to development of chat bots 
using AIML
1
 and its variations, such as Project 
CyN
2
. Most of the work on conversational agents 
was limited to one-on-one situations, where a 
single agent converses with a human user, 
whether to perform a transaction (such as bok-
ing a flight or banking transactions) (Hardy et al., 
2006) or for companionship (e.g., browsing of 
family photographs) (Wilks, 201). Many of 
these systems were inspired by the challenge of 
the Turing Test or its more limited variants such 
as Loebner Prize. 
  Research in the field of developing a multi-user 
chat-room agent has been limited. This is some-
what surprising because a multi-user seting 
makes the agent’s task of maintaining conversa-
tion far les onerous than in one-on-one situa-
tions. In a chat-room, with many users engaged 
in conversations, it is much easier for an agent to 
pas as just another user. Indeed, a skilfully de-
signed agent may be able to influence an ongoing 
conversation. 
3 MPC
Chat Corpus 
The MPC chat corpus is a colection of 20 hours 
of chat sesions with multiple participants (on 
average 4), conversing for about 90 minutes in a 
secure online chat rom. The topics of conversa-
tion vary from fre-flowing chat in the initial 
colection phase to allow participants to build 
comfortable a rapport with each other, to specific 
task-oriented dialogues in the later phase; such 
as chosing the right candidate for a job inter-
view from a list of given resumes. This corpus is 
suitable for our research purposes since the chat 
sessions were designed around enabling the so-
cial phenomena we were interested in modeling. 
4 Anotation
Scheme 
We wished to anotate the dat we colected to 
derive models from language use for social phe-
nomena. These represent complex pragmatic 
concepts that are dificult to annotate directly, let 
alone detect automatically. Our approach was to 
build a multi-level anotation scheme.  
In this paper we briefly outline our anotation 
scheme that consists of thre layers: comunica-
                                                
1
 http://ww.alicebot.org/aiml.html 
2 
http:/ww.daxtron.com/123start.htm?Cyn
 
tive links, dialogue acts, and topic/focus changes. 
A more detailed description of the anotation 
scheme wil be presented in a future publication. 
4.1 Comunicative
Links 
Annotators are asked to mark each uterance in 
one of thre categories – uterance is adresed 
to a participant or a set of participants, it is in 
response to a specific prior uterance by another 
participant or it is a continuation of the partici-
pant’s own prior utterance. By an utterance, we 
mean the set of words in a single turn by a par-
ticipant. In multi-party chat, participants do not 
generaly add addresing information in their 
utterances and it is often ambiguos to whom 
they are speaking. Comunicative link anota-
tion allows us to acurately map who is speaking 
to whom in the conversation, which is required 
for tracking social phenomena acros partici-
pants. 
4.2 Dialogue
Acts 
At this anotation level, we developed a hierar-
chy of 20 dialogue acts, based losely on 
DAMSL (Allen & Core, 197) and SWBD-
DAMSL (Jurafsky et al., 197), but greatly re-
duced and more tuned to dialogue pragmatics. 
For example, the uterance “It is cold here today” 
may function as a Response-Answer when given 
in response to a question about the weather, and 
would act as an Assertion-Opinion if it is evalu-
ated alone. The dialogue acts, thus augmented, 
become an important feature in modeling partici-
pant behavior for our research purpose. A de-
tailed description of the tags is beyond the scope 
of this paper. 
4.3 Topic
and Focus boundaries 
The flow of discusion in chat shifts quite rapidly 
from one topic to another. Furthermore, within 
each topic (e.g., music bands) the focus of conver-
sation (e.g., dc for cutie) moves just as rapidly. We 
distinguish betwen topic and focus to acom-
modate both broader thematic shifts and more 
narow aspect changes of the topic being dis-
cused. For example, participants might discus 
the topic of healthcare reform, by focusing on 
President Obama, and then switch the focus to some 
particulars of the reform, such as the “public op-
tion”. Similarly, topics may shift while the focus 
remains the same (e.g., moving on to Obama’s 
economic policies), although such changes are 
les comon. Annotators typicaly marked the 
first mention of a substantive noun phrase as a 
topic or focus introduction. 
44
The efect of topic change is aparent when a 
subsequent uterance by another participant is 
about the same topic. This is a sucessful atempt 
at changing the topic. Shown in Figure 1 is an 
example of topic shift annotated in our data col-
lection. 
 
 
Figure 1. A topic change in dialogue, with thre 
participants (A, KA and KN) 
 
We found this model of topic change fairly con-
sistently exhibited, where the participants would 
ask an open question, in order to get other par-
ticipants to respond to them, thereby changing 
the course of conversation. We collected all ut-
terances marked topic shifts and focus shifts and 
created a set of templates from them.  Thes 
templates served as a model for the VCA to util-
ize when creating a response. 
Another model of behavior that we found as a 
consequence of topic change is topic sustain. 
This is an instance where the uterance is marked 
to be on the same topic as the one curently being 
discussed, for example, utterance 5 in Figure 1. 
These may be in the form of ofering suport or 
agreement with a previous uterance or asking a 
question about a new in-topic aspect. 
We gave our anotators a fair amount of lev-
erage on how to label the topics and how to rec-
ognize the focus. Our primary interest was in an 
accurate detection of topic/focus boundaries and 
shifts. Of the 14 sessions we selected from the 
MPC corpus, we selected 10 for anotation, with 
at least 3 annotators for each sesion. In Table 1 
some of the overal statistics computed from this 
set are shown. We computed inter-annotator 
agreement on all three levels of our annotation, 
i.e. Comunication Links, Dialogue Acts and 
Topic/Focus Shifts. Topic and Focus shifts had 
the highest inter-annotator agreement scores on 
diferent measures such as Krippendorf’s Alpha 
(Kripendorf, 1980) and Flies’ Kapa (Flies, 
1971). In Figure 2, we show inter-annotator 
agreement measures on Topic/Focus shift anno-
tation for four of the anotated sesions. Krip-
pendorf’s Alpha and Fleis’ Kappa measures 
show inter-annotator agreement on topic shift 
alone, and Conflated Kripendorf’s Alpha 
measures show the agrement when topic and 
focus are conflated as one category. With such 
high degre of agrement, we can reliably derive 
models of topic shift behavior from our ano-
tated data. 
 
Total Number of Sesions Anotated 10 
Number of anotators per file 3 
Total Uterances Anotated 4640 
Average number of uterances per ses-
sion 
~520 
Total topics identified per sesion 174 
Total topic shifts identified per ses-
sion 
344 
Table 1. Selected statistics from anotated 
data set 
 
 
Figure 2. Inter-annotator agreement measures for 
Topic/Focus shifts 
5 VCA
Design 
A virtual chat agent is an automated program 
with the ability to respond to uterances in chat. 
Our VCA is distinctive in its ability to participate 
in multi-party chat and manage to ster the flow 
of conversation to a new topic. We exploit the 
dialogue mechanism underlying HITIQA (Smal 
et al. 209) to drive the dialogue in VCA.  
The topic as defined by the information con-
tained in the participant’s utterance is used to 
mine outside data sources (e.g., a corpus, the 
web) in order to locate and learn aditional in-
formation about that topic. The objective is to 
identify some of the salient concepts that apear 
0	  
0.2	  
0.4	  
0.6	  
0.8	  
1	  
Krippendorff	  
's	  Alpha	  
Con9lated	  
Krippendorff	  
's	  Alpha	  
Fleiss	  '	  Kappa	  
AA 1: did anyone watch the morning talk 
shows today (MTP, for example)? 
KA 2: nope! 
AA 3: I mised them – I was hoping 
someone else had. 
AA 4: My kids tel me the band you’re 
going to hear (dc for cutie) is great. 
(TOPIC: music bands, FOCUS: dc for cutie) 
KA 5: oh cool! Their lyrics are nice, I 
think. 
(TOPIC: music bands, FOCUS: dc for cutie) 
KA 6. what kind of music do you guys 
listen to? 
(TOPIC: music, FOCUS: none) 
KN 7: I don’t realy have a favorite 
genre….you on youtube right now? 
(TOPIC: music, FOCUS: youtube) 
 
45
associated with the topic, but are not directly 
mentioned in the uterance. Such asociations 
may be postulated because aditional concepts 
are repeatedly found near the concepts men-
tioned in the utterance.  
An ilustrative example found in our anotated 
corpus is the uterance, “Lars Ulrich might have a 
thing or two to say about technology.” Here, the topic 
of conversation prior to this utterance was “tech-
nology” and it was changed to “music” after this 
utterance. Here, “Lars Ulrich” is the bridge that 
conects the two concepts “technology” and “mu-
sic” together. 
5.1 VCA
rchitecture 
The VCA is composed of the folowing modules 
that interact as shown in Figure 3.  
 
5.1.1 Chat
Analyzer 
Every uterance in chat is first analyzed by the 
Chat Analyzer component. This proces removes 
stop words, emoticons and punctuation, as wel 
as any participant nicknames from the uterance. 
We postulate that the remaining content bearing 
words in the uterance represent the topic of that 
utterance. We cal this analyzed utterance our 
chat “query” which is sent in parallel to the 
Document Retrieval and NL Procesing compo-
nent. 
 
5.1.2 Document
Retrieval 
The document retrieval proces retrieves docu-
ments from either the web or a test document 
corpus. We use Gogle AJAX api for our web 
retrieval proces and InQuery (Calan et al., 
1992) retrieval engine for our ofline mode of 
operation to retriev documents from the test 
corpus. The test document corpus was collected 
by mining the web for al utterances in our data 
colection, creating a stable document set for ex-
perimental purposes. Currently, the document 
corpus contains about 1Gb of text data. 
 
5.1.3 Clustering

We cluster the paragraphs in documents retrieved 
using clustering method in Hardy et al. (Hardy et 
al., 209) This process groups the paragraphs 
containing salient entities into sets of closely as-
sociated concepts. From each cluster, we chose 
the most representative paragraph, usualy caled 
the “sed” paragraph for further NL procesing. 
Each sed paragraph and the chat query undergo 
the same further NL procesing sequence.   
 
5.1.4 Natural
Language Procesing 
We proces each chat query by performing 
steming, part-of-spech taging and named-
entity recognition on it. Each seed paragraph is 
also run through same three natural language 
procesing tasks. We are using Stanford POS 
tager for our part-of-spech taging. For named 
entity recognition, we have the ability to chose 
betwen BN’s IdentiFinder and AerText™ 
(Taylor, 204). 
 
5.1.5 Framing

We build frames from the entities and atributes 
found in both the chat query and the paragraphs. 
This work extends the concept of framing devel-
oped for HITIQA (Smal et al, 2009) and COL-
LANE (Strzalkowski, 209). Framing provides 
an informative handle on text, which can be ex-
ploited to compare the underlying textual repre-
sentations, as we explain in the next section. 
 
5.1.6 Scoring
and Frame Matching 
Using the information in the frames built in the 
previous step; we compare the chat query frame 
Figure 3. VCA Architecture 
46
built from the chat query, to the frames created 
from the paragraphs, called paragraph frames. 
We asign a score for each paragraph frame 
based on how many atributes and their corre-
sponding values match; in the curent version of 
VCA a very basic aproach to counting how 
many atribute-value pairs match is taken. Of al 
the paragraph frames we select the highest scor-
ing frames and select the attribute-value pairs 
that are not part of the chat query frame. For ex-
ample, as shown in Figure 4a below, the chat 
utterance “Aruba might be nice!” created the fol-
lowing chat query frame. 
 
 
a. Example chat query frame 
 
 
b. Frame Matching, Scoring and Template 
Selection 
 
Figure 4. From frames to VCA responses 
 
Corespondingly, we select al PLACE type en-
tities from the highest-ranking paragraph frames. 
These are shown in Figure 4b as Aruba Entiy 
list.  The entities “NASCAR”, “Women Seking Men” 
and “Mateo” are not of entity type – PLACE, we 
assign them a score of 0. The score is the fre-
quency of occurrence of that entity in the para-
graph; in this example it is found to be 1. Asign-
ing scores by frequency of ocurence ensures 
that the most comonly ocuring concept 
around the one that is being discused in the chat 
query utterance wil be used to respond with. 
 
5.1.7 Template
Selection 
Once we have chosen the entity to respond with, 
we select a template from the set of templates for 
that entity. These are templates that are created 
based on the models created from topic change 
utterances annotated in our data set. For a select 
group of entities, which are quite frequently en-
countered in our data collection such as PLACE, 
PERSON, ORGANIZATION etc., we have a set of 
templates specific to that entity type. We also 
have several generic templates that may be used 
if the entity type does not match the ones that we 
have selected. For example, a PLACE specifc 
template is “Have you ever ben to _?” and a PER-
SON specific template is “You heard about _?”. Not 
all templates are formulated as questions. An-
other example of a generic template is “__rules!”. 
6 Example
of VCA Interaction 
Figure 5 represnts an example of the VCA in 
action in a simulated environment; the VCA is 
the participant “rene”. We can se how the con-
versation changes from “gun laws” to “hunting” 
after renee’s uterance at 1:48 AM. 
 
 
 
Figure 5. Topic change example 
7 Evaluation

We ran two tests of this initial VCA prototype 
in a public chat-room. VCA was inserted into a 
public chat-room with multiple participants on 
two separate ocasions. The general topic of dis-
cusion during both instances was “anime”. We 
have developed an evaluation protcol in order 
to test the efectivenes of the VCA prototype in 
a realistic setting. The initial metric of VCA ef-
fectivenes is the rate of involvement measured 
in the number of utterances generated by the 
VCA during the test period. These utterances are 
subsequently judged for apropriateness using 
the metric developed for the Companions Project 
(Web, 2010). The actual appropriateness anno-
tation scheme can be quite involved, but for this 
simple test we reduced the coding to only binary 
assessment, so that the VCA uterances were an-
notated as either appropriate or inappropriate, 
given the content of the utterance and the flow of 
dialogue thus far. Using this coarse grain evalua-
tion on a live chat segment we noted that the 
VCA made 9 apropriate uterances and 7 inap-
[POS] 
NNP, Aruba 
JJ, nice 
[ENT] PLACE 
 
Aruba Entity List: 
VALUE = NASCAR and TYPE = ORGANIZATION 
and SCORE = 0 
VALUE = Dalas and TYPE = PLACE and SCORE = 
1 
VALUE = Mateo and TYPE = PERSON and SCORE 
= 0 
 
VCA: How about Dalas? 
47
propriate utterances, which gives the appropri-
ateness score of 56%. While some of VCA uter-
ances seem inappropriate (i.e., not related to the 
conversation topic), we noted also that other 
posters generaly tolerated these inappropriate 
utterances that occurred early in the dialogue. 
Moreover, these early inapropriate uterances 
did generate appropriate responses from the hu-
man users. This “positive” dynamic changed 
gradualy as the dialogue progresed, when the 
participants began to ignore VCA’s utterances. 
While this coarse grained evaluation is useful, 
our plan is to conduct evaluation experiments by 
recruiting subjects for chat sesions and inserting 
the VCA in the discusion. We will measure the 
impact of the VCA in the chat session by having 
participants fil out post-session questionaires, 
which can elicit their responses regarding (a) if 
they detect presence of a VCA at any time during 
the dialogue; (b) who was the VCA; (c) who 
changed the topic of conversation most often; 
and so on. Another metric of interest is the level 
of engagement of the VCA, which can be meas-
ured by the number of direct responses to an ut-
terance by the VCA. We are developing the 
evaluation process, and report on the results in a 
separate publication. 
References 
Allen, J. M. Core. (1997). Draft of DAMSL: Dialog 
Act arkup in Several Layers. 
http:/ww.cs.rochester.edu/research/cisd/resource
s/damsl/ 
Calan, J. P., W. B. Croft, and S. M. Harding. 192. 
The INQUERY Retrieval System, in Procedings of 
the 3rd International Conference on Database and 
Expert Systems. 
 Colby, K.M, Hilf, F.D, and S. Weber. 1972. Turing-
like indistinguishability tests for the validation of a 
computer simulation of paranoid processes. In: Ar-
tificial Intelligence , Vol. 3, p. 19-221. 
Fleis, Joseph L. 1971. Measuring nominal scale 
agreement among many raters. Psychological Bul-
letin, 74(5):378{382. 
Hardy, Hilda, Nobuyuki Shimizu, Tomek Strzalk-
owski, Ting Liu, Bowden Wise and Xinyang 
Zhang. 202. Cros-document summarization by 
concept classification. In Procedings of ACM 
SIGIR '02 Conference, pages 121-128, Tampere, 
Finland. 
Hardy, H., A Bierman, R. Bryce Inouye, A. 
McKenzie, T. Strzalkowski, C. Ursu, N. Web and 
M. Wu. 206. The AMITIES System: Data-Driven 
Techniques for Automated Dialogue. In 
Spech Comunication 48 (3-4), pages 354-
373. Elsevier. 
Jurafsky, Dan, Elizabeth Shriberg, and Debra Biasca. 
(1997). Switchboard SWBD-DAMSL Shalow-
Discourse-Function Anotation Coders Manual. 
http:/stripe.colorado.edu/~jurafsky/manual.august
1.html 
Kripendorf, Klaus. 1980. Content Analysis, an In-
troduction to its Methodology. Sage Publications, 
Thousand Oaks, CA. 
Samira S., Tomek Strzalkowski, Sarh Taylor and 
Jonathan Smith (209) Comparing an Integrated 
QA system performance A Preliminary Model. 
Procedings of PACLING Conference, Saporo, 
Japan. 
Shaikh, S., Strzalkowski, T., Broadwel, A., Stromer-
Galey, J., Taylor, Sarah and Web, N. 2010. Pro-
ceedings of LREC onference, Malta. 
Sharon Smal and Tomek Strzalkowski. 2009. 
HITIQA: High-Quality Inteligence through Inter-
active Question Answering. Journal of Natural 
Language Enginering, Vol. 15 (1), p. 31—54. 
Cambridge. 
Tomek Strzalkowski, Sarah Taylor, Samira Shaikh, 
Ben-Ami Lipetz, Hilda Hardy, Nick Web, Tony 
Creswell, Min Wu, Yu Zhan, Ting Liu, and Song 
Chen. 209. COLANE: An experiment in com-
puter-mediated tacit colaboration. In Aspects of 
Natural Language Procesing (M. Marciniak and 
A. Mykowiecka, editors). Springer. 
Taylor, Sarah M. 204. "Information Extraction 
Tools: Deciphering Human Language." IT Profes-
sional. Vol. 06, no. 6, pages: 28-34. Novem-
ber/December, 2004. Online. 
http:/ieexplore.ieee.org/iel5/6294/30282/0139087
0.pdf?tp=&arnumber=1390870&isnumber=30282 
Walace, R. 208. The Anatomy of A.L.I.C.E. In 
Parsing the Turing Test. (Robert Epstein, 
Gary Roberts and Grace Beber, editors). Springer. 
Web, N., D. Benyon, P. Hansen and O. Mival. 2010. 
Evaluating Human-Machine Conversation for Ap-
propriatenes. In Procedings of the 7th Interna-
tional Conference on Language Resources and 
Evaluation (LREC2010), Valletta, Malta. 
Weizenbaum, Joseph. January 196. "ELIZA — A 
Computer Program For the Study of Natural Lan-
guage Communication Betwen Man And Ma-
chine", Comunications of the ACM 9 (1): 36–45. 
Wilks, Y. 2010. Artificial Companions. In: Y.Wilks 
(ed.) Close Engagement with Companions: scien-
tific, economic, psychological and philosophical 
perspectives. John Benjamins: Amsterdam. 
48

