Individual Model[Chen, et al.1998][Sun, et al.1994][Zheng, et al.2000] consists of several submodels, each of them deals with a kind of entities.
M98-1017
The escape probability[Black, et al.1998] was adopted to smooth the statistical model shown as (15).
M98-1014
The Word Model employs word features for NER, which is introduced by [Sun, et al.2002]. The POS Model employs POS features for NER.
C02-1012
Recently, approaches for NER are a shift away from handcrafted rules[Grishman, et al.1995] [Krupka, et al.1998][Black et al.1998] towards machine learning algorithms, i.e. unsupervised model like DL-CoTrain, CoBoost[Collins, 1999, 2002], supervised learning like Error-driven [Aberdeen, et al.1995], Decision Tree [Sekine, et al.1998], HMM[Bikel, et al.1997] and Maximum Entropy[Borthwick, et al.1999][Mikheev, et al.1998].
A97-1029 M95-1001 M95-1012 M98-1014 M98-1015 M98-1021 P02-1062 W98-1120 W99-0613
For example, the recognition of PN may be statistical-based model, while LN and ON may be rulebased model like [Chen, et al.1998]. Integrated Model[Sun, et al.2002] [Zhang, et al.2003][Yu, et al.1998][Chua, et al.2002] deals with all kinds of entities in a unified statistical framework.
C02-1012 M98-1016 M98-1017
Inspired by the algorithms of identifying BaseNP and Chunk[Xun, et al.2000], we propose a hybrid NER model which emphasizes on combining coarse particle features (POS Model) with fine particle features (Word Model).
P00-1015
