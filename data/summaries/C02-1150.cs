However, in the context of factual questions that are of interest to us here, conceptual categories do not seem to be helpful; instead, our goal is to semantically classify questions, as in earlier work on TREC (Singhal et al., 2000; Hovy et al., 2001; Harabagiu et al., 2001; Ittycheriah et al., 2001).
H01-1069
The question classifier makes use of a sequence of two simple classifiers (Even-Zohar and Roth, 2001), each utilizing the Winnow algorithm within SNoW.
W01-0502
alized that locating an answer accurately hinges on first filtering out a wide range of candidates (Hovy et al., 2001; Ittycheriah et al., 2001) based on some categorization of answer types.
H01-1069
Chunks are extracted using a previously learned classifier (Punyakanok and Roth, 2001; Li and Roth, 2001).
W01-0706
Open-domain question answering (Lehnert, 1986; Harabagiu et al., 2001; Light et al., 2001) and story comprehension (Hirschman et al., 1999) have become important directions in natural language processing.
P99-1042 W01-0706
Pos tags are extracted using a SNoW-based pos tagger (Even-Zohar and Roth, 2001).
W01-0502
This work develops a machine learning approach to question classification (QC) (Harabagiu et al., 2001; Hermjakob, 2001).
W01-1203
Data are collected from four sources: 4,500 English questions published by USC (Hovy et al., 2001), about 500 manually constructed questions for a few rare classes, 894 TREC 8 and TREC 9 questions, and also 500 questions from TREC 10 which serves as our test set 3 . These questions were manually labeled according to our question hierarchy.
H01-1069
