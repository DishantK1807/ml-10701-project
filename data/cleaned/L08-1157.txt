<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<title>The MILE corpus for less commonly taught languages. In HLT-NAACL</title>
<date>2006</date>
<location>New York, New York</location>
<marker>2006</marker>
<rawString>2006. The MILE corpus for less commonly taught languages. In HLT-NAACL, New York, New York, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Black</author>
<author>Kevin Lenzo</author>
</authors>
<title>Optimal data selection for unit selection synthesis</title>
<date>2001</date>
<booktitle>In ISCA, 4th Speech Synthesis Workshop</booktitle>
<location>Scotland</location>
<contexts>
<context>quire next. 1. Introduction In recent years, Data Selection has become a common issue in many areas of language technologies including speech recognition (Zhang and Rudnicky, 2006), speech synthesis (Black and Lenzo, 2001), and machine translation (Probst and Lavie, 2004). The benefits of data selection become evident at two stages. First, in gathering language data from humans, the development cost of language techno</context>
</contexts>
<marker>Black, Lenzo, 2001</marker>
<rawString>Alan Black and Kevin Lenzo. 2001. Optimal data selection for unit selection synthesis. In ISCA, 4th Speech Synthesis Workshop, Scotland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaime Carbonell</author>
<author>Kathrina Probst</author>
<author>Erik Peterson</author>
<author>Christian Monson</author>
<author>Alon Lavie</author>
<author>Ralf Brown</author>
<author>Lori Levin</author>
</authors>
<title>Automatic rule learning for resource limited MT</title>
<date>2002</date>
<booktitle>In Association for Machine Translation in the Americas (AMTA</booktitle>
<contexts>
<context> above. This corpus can then be used for learning correspondences between semantic structures in the two languages. In the case of AVENUE, this involves the automatic extraction of MT transfer rules (Carbonell et al., 2002). Though we typically only elicit around 4,000 sentences, we hypothesize that we can make this small amount of data more valuable by using active learning to select the sentences from which the most </context>
</contexts>
<marker>Carbonell, Probst, Peterson, Monson, Lavie, Brown, Levin, 2002</marker>
<rawString>Jaime Carbonell, Kathrina Probst, Erik Peterson, Christian Monson, Alon Lavie, Ralf Brown, and Lori Levin. 2002. Automatic rule learning for resource limited MT. In Association for Machine Translation in the Americas (AMTA), October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
<author>Lyle Campbell</author>
</authors>
<title>A Bayesian model for discovering typological implications</title>
<date>2007</date>
<booktitle>In Conference of the Association for Computational Linguistics (ACL</booktitle>
<location>Prague, Czech Republic</location>
<marker>Daum´e, Campbell, 2007</marker>
<rawString>Hal Daum´e and Lyle Campbell. 2007. A Bayesian model for discovering typological implications. In Conference of the Association for Computational Linguistics (ACL), Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Greenberg</author>
</authors>
<title>Universals of Languages</title>
<date>1963</date>
<publisher>MIT Press</publisher>
<location>Cambridge</location>
<contexts>
<context>iscovered so far (the current state). The Corpus Navigator returns as output a recommentation for the most useful piece of information to ask next. At this stage, Greenbergian Typological Universals (Greenberg, 1963) can be used to augment the knowledge in our current state. For example, if a language does not distinguish singular nouns from plural nouns, then we know the language will not grammaticalize dual nu</context>
</contexts>
<marker>Greenberg, 1963</marker>
<rawString>Joseph Greenberg. 1963. Universals of Languages. MIT Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Haspelmath</author>
<author>Matthew Dryer</author>
<author>David Gil</author>
<author>Bernard Comrie</author>
</authors>
<title>The World Atlas of Language Structures</title>
<date>2005</date>
<publisher>Oxford University Press</publisher>
<location>Oxford</location>
<contexts>
<context>nk that because some kind of reference grammar exists for almost every language, feature detection might be unnecessary. However, in the database of the The World Atlas of Language Structures (WALS) (Haspelmath et al., 2005), a compendium of the types of features we are trying to automatically detect, over 84% of the cells are blank. Haspelmath (Haspelmath, 2008; Haspelmath, 2007) notes that the data required to fill in</context>
</contexts>
<marker>Haspelmath, Dryer, Gil, Comrie, 2005</marker>
<rawString>Martin Haspelmath, Matthew Dryer, David Gil, and Bernard Comrie. 2005. The World Atlas of Language Structures. Oxford University Press, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Haspelmath</author>
</authors>
<date>2007</date>
<note>personal communication</note>
<contexts>
<context>as of Language Structures (WALS) (Haspelmath et al., 2005), a compendium of the types of features we are trying to automatically detect, over 84% of the cells are blank. Haspelmath (Haspelmath, 2008; Haspelmath, 2007) notes that the data required to fill in most of these cells is not easily obtainable. Furthermore, reference grammars report on which features are grammaticalized, but many non-grammaticalized featu</context>
</contexts>
<marker>Haspelmath, 2007</marker>
<rawString>Martin Haspelmath. 2007. personal communication.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Haspelmath</author>
</authors>
<title>The typological database of the World Atlas of Language Structures</title>
<date>2008</date>
<booktitle>In Martin Everaert and Simon Musgrave, editors, Typological databases. Mouton de Gruyter</booktitle>
<location>Berlin</location>
<contexts>
<context> the The World Atlas of Language Structures (WALS) (Haspelmath et al., 2005), a compendium of the types of features we are trying to automatically detect, over 84% of the cells are blank. Haspelmath (Haspelmath, 2008; Haspelmath, 2007) notes that the data required to fill in most of these cells is not easily obtainable. Furthermore, reference grammars report on which features are grammaticalized, but many non-gra</context>
</contexts>
<marker>Haspelmath, 2008</marker>
<rawString>Martin Haspelmath. 2008. The typological database of the World Atlas of Language Structures. In Martin Everaert and Simon Musgrave, editors, Typological databases. Mouton de Gruyter, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald Kaplan</author>
</authors>
<title>The formal architecture of lexical functional grammar</title>
<date>1995</date>
<booktitle>Formal Issues in Lexical Functional Grammar</booktitle>
<editor>In Mary Dalrymple, Ronald Kaplan, J. Maxwell, and A. Zaenen, editors</editor>
<publisher>CSLI Publications</publisher>
<contexts>
<context>ed with phrase structure trees and feature structures similar to the tectogrammatical layer in the Prague Treebank (Petr Sgall, 2004). These sentences are annotated with a head mapping and a mapping (Kaplan, 1995), which links nodes of the phrase structure tree to nodes of the feature structure, thereby providing a mapping from words to the features that they express (Figure 1). The corpus is organized into m</context>
</contexts>
<marker>Kaplan, 1995</marker>
<rawString>Ronald Kaplan. 1995. The formal architecture of lexical functional grammar. In Mary Dalrymple, Ronald Kaplan, J. Maxwell, and A. Zaenen, editors, Formal Issues in Lexical Functional Grammar. CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lori Levin</author>
<author>Jeff Good</author>
<author>Alison Alvarez</author>
<author>Robert Frederking</author>
</authors>
<title>Parallel reverse treebanks for the discovery of morpho-syntactic markings</title>
<date>2006</date>
<booktitle>In Proceedings of Treebanks and Linguistic Theory</booktitle>
<location>Prague</location>
<contexts>
<context>should be Yes. The Linguistic Data Consortium now provides Language Packs for Less Commonly Taught Languages (LCTL) for Thai, Bengali, Urdu, each including 3100 sentences from our elicitation corpus (Levin et al., 2006). After alignments have been obtained for these corpora, they will serve as a primary area of application for feature detection. 3. Implementation We represent the mapping between example sentences a</context>
</contexts>
<marker>Levin, Good, Alvarez, Frederking, 2006</marker>
<rawString>Lori Levin, Jeff Good, Alison Alvarez, and Robert Frederking. 2006. Parallel reverse treebanks for the discovery of morpho-syntactic markings. In Proceedings of Treebanks and Linguistic Theory, Prague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eva Hajicov´a Petr Sgall</author>
<author>Jarmila Panevov´a</author>
</authors>
<date>2004</date>
<marker>Sgall, Panevov´a, 2004</marker>
<rawString>Eva Hajicov´a Petr Sgall, Jarmila Panevov´a. 2004.</rawString>
</citation>
<citation valid="true">
<title>Deep syntactic annotation: Tectogrammatical representation and beyond</title>
<booktitle>In HLT-NAACL 2004 Workshop: Frontiers in Corpus Annotation, Association for Computational Linguistics</booktitle>
<location>Boston</location>
<marker></marker>
<rawString>Deep syntactic annotation: Tectogrammatical representation and beyond. In HLT-NAACL 2004 Workshop: Frontiers in Corpus Annotation, Association for Computational Linguistics, Boston.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katharina Probst</author>
<author>Alon Lavie</author>
</authors>
<title>A structurally diverse minimal corpus for eliciting structural mappings between languages</title>
<date>2004</date>
<booktitle>In Proceedings of the 6th Conference of the Association for Machine Translation in the Americas (AMTA-2004</booktitle>
<location>Washington, DC</location>
<contexts>
<context> Selection has become a common issue in many areas of language technologies including speech recognition (Zhang and Rudnicky, 2006), speech synthesis (Black and Lenzo, 2001), and machine translation (Probst and Lavie, 2004). The benefits of data selection become evident at two stages. First, in gathering language data from humans, the development cost of language technologies is typically increased greatly. Second, in </context>
</contexts>
<marker>Probst, Lavie, 2004</marker>
<rawString>Katharina Probst and Alon Lavie. 2004. A structurally diverse minimal corpus for eliciting structural mappings between languages. In Proceedings of the 6th Conference of the Association for Machine Translation in the Americas (AMTA-2004), Washington, DC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katharina Probst</author>
<author>Lori Levin</author>
</authors>
<title>Challenges in automated elicitation of a controlled bilingual corpus</title>
<date>2002</date>
<booktitle>In Proceedings of the 9th International Conference on Theoretical and Methodological Issues in Machine Translation (TMI-02</booktitle>
<contexts>
<context>000 sentences, we hypothesize that we can make this small amount of data more valuable by using active learning to select the sentences from which the most effective translation rules can be learned (Probst and Levin, 2002). Note that not all language features that we might want to elicit manifest themselves in English. In these cases, we provide the bilingual person with a context field to elicit the proper meaning. F</context>
</contexts>
<marker>Probst, Levin, 2002</marker>
<rawString>Katharina Probst and Lori Levin. 2002. Challenges in automated elicitation of a controlled bilingual corpus. In Proceedings of the 9th International Conference on Theoretical and Methodological Issues in Machine Translation (TMI-02).</rawString>
</citation>
</citationList>
</algorithm>

