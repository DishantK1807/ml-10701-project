<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>M Baroni</author>
<author>S Bernardini</author>
</authors>
<title>BootCaT: Bootstrapping corpora and terms from the web</title>
<date>2004</date>
<contexts>
<context>ome aware that the Internet is an invaluable source of data. Programs that simply download massive collections of documents are now common, but the result is usually a highly noisy corpus. “Bootcat” (Baroni &amp; Bernardini, 2004) is a better choice because it accepts a set of seed words as input. In our particular case, however, we are interested in going further. Since our aim is the study of technical terminology, therefor</context>
</contexts>
<marker>Baroni, Bernardini, 2004</marker>
<rawString>Baroni, M. &amp; Bernardini, S. (2004). BootCaT: Bootstrapping corpora and terms from the web.</rawString>
</citation>
<citation valid="false">
<booktitle>Proceedings of LREC 2004</booktitle>
<pages>13131316</pages>
<location>Lisbon: ELDA</location>
<marker></marker>
<rawString>Proceedings of LREC 2004, Lisbon: ELDA. pp. 13131316.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Banerjee</author>
<author>T Pedersen</author>
</authors>
<title>The Design, Implementation, and Use of the Ngram Statistics Package</title>
<date>2003</date>
<booktitle>In Proceedings of the Fourth International Conference on Intelligent Text Processing and Computational Linguistics</booktitle>
<location>Mexico City</location>
<contexts>
<context> the experiments. Sense #1 Sense #2 3 Second Module: Exploration of the Corpus with Statistical Techniques. Some of the most well known tools to measure statistical association between words are NSP (Banerjee &amp; Pedersen, 2003) for sorting n-grmas; UCS (Evert, 2004) for collocation extraction; the Sketch Engine (Kilgarriff, 2004) for different uses including the comparison of words by their profile of cooccurrence and T-LA</context>
</contexts>
<marker>Banerjee, Pedersen, 2003</marker>
<rawString>Banerjee, S. &amp; Pedersen, T. (2003). The Design, Implementation, and Use of the Ngram Statistics Package. In Proceedings of the Fourth International Conference on Intelligent Text Processing and Computational Linguistics, February 17-21, 2003, Mexico City.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
<author>P Hanks</author>
</authors>
<title>Word Association Norms</title>
<date>1991</date>
<journal>Mutual Information and Lexicography, Computational Linguistics</journal>
<volume>16</volume>
<pages>22--29</pages>
<marker>Church, Hanks, 1991</marker>
<rawString>Church, K., &amp; Hanks, P. (1991). Word Association Norms, Mutual Information and Lexicography, Computational Linguistics, Vol 16:1, pp. 22-29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Daille</author>
</authors>
<title>Approche mixte pour l'extraction automatique de terminologie: statistiques lexicales et filtres linguistiques. Thèse de Doctorat en Informatique Fondamentale. Université</title>
<date>1994</date>
<location>Paris</location>
<contexts>
<context>the probability of coccurrence of lexical items x and y while P(x) and P(y) represent the probability of their independent occurrence. Cubic Mutual Information: This latter measure (first reported in Daille, 1994) is similar to the previous one but with the numerator raised to the power of 3. While the previous has the tendency to highlight the most rare words, this other one makes up for that tendency. These</context>
</contexts>
<marker>Daille, 1994</marker>
<rawString>Daille, B. (1994). Approche mixte pour l'extraction automatique de terminologie: statistiques lexicales et filtres linguistiques. Thèse de Doctorat en Informatique Fondamentale. Université Paris 7. 1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Evert</author>
</authors>
<title>The Statistics of Word Coocurrences; PhD Thesis; IMS</title>
<date>2004</date>
<institution>University of Stuttgart</institution>
<contexts>
<context>Exploration of the Corpus with Statistical Techniques. Some of the most well known tools to measure statistical association between words are NSP (Banerjee &amp; Pedersen, 2003) for sorting n-grmas; UCS (Evert, 2004) for collocation extraction; the Sketch Engine (Kilgarriff, 2004) for different uses including the comparison of words by their profile of cooccurrence and T-LAB (Lancia, 2007) with utilities such as</context>
</contexts>
<marker>Evert, 2004</marker>
<rawString>Evert, S. (2004). The Statistics of Word Coocurrences; PhD Thesis; IMS; University of Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Herdan</author>
</authors>
<title>Quantitative Linguistics</title>
<date>1964</date>
<location>Washington, Butterworths</location>
<marker>Herdan, 1964</marker>
<rawString>Herdan, G. (1964). Quantitative Linguistics. Washington, Butterworths.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Juilland</author>
<author>E Chang-Rodríguez</author>
</authors>
<title>Frequency Dictionary of Spanish Words. The Hague</title>
<date>1964</date>
<publisher>Mouton</publisher>
<contexts>
<context>s for the sorting of terms on the basis of their distribution in a collection of documents, for instance IDF (Sparck Jones, 1972), among other measures of dispersion such as the Juilland coefficient (Juilland &amp; Chang-Rodríguez, 1964) and an original coefficient of this program that has proved to be effective in our preliminary evaluation. Considering tfi,j as the frequency of term i in document j; dfi as the number of documents </context>
</contexts>
<marker>Juilland, Chang-Rodríguez, 1964</marker>
<rawString>Juilland, A. &amp; Chang-Rodríguez, E. (1964). Frequency Dictionary of Spanish Words. The Hague: Mouton.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kilgarriff</author>
</authors>
<title>The Sketch Engine</title>
<date>2004</date>
<booktitle>In Proceedings of Euralex</booktitle>
<pages>105--116</pages>
<contexts>
<context>of the most well known tools to measure statistical association between words are NSP (Banerjee &amp; Pedersen, 2003) for sorting n-grmas; UCS (Evert, 2004) for collocation extraction; the Sketch Engine (Kilgarriff, 2004) for different uses including the comparison of words by their profile of cooccurrence and T-LAB (Lancia, 2007) with utilities such as co-occurrence analysis and document or word clustering. However,</context>
</contexts>
<marker>Kilgarriff, 2004</marker>
<rawString>Kilgarriff, A. (2004). The Sketch Engine. In Proceedings of Euralex, pp. 105–116.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Lancia</author>
</authors>
<title>Word Co-occurrence and Similarity</title>
<date>2007</date>
<booktitle>Mind as Infinite Dimensionality</booktitle>
<editor>in Meaning. In Salvatore S., Valsiner J. (eds</editor>
<contexts>
<context>or sorting n-grmas; UCS (Evert, 2004) for collocation extraction; the Sketch Engine (Kilgarriff, 2004) for different uses including the comparison of words by their profile of cooccurrence and T-LAB (Lancia, 2007) with utilities such as co-occurrence analysis and document or word clustering. However, none of the above mentioned covers completely the range of functionalities our suite does. For an overall intr</context>
</contexts>
<marker>Lancia, 2007</marker>
<rawString>Lancia F. (2007). Word Co-occurrence and Similarity in Meaning. In Salvatore S., Valsiner J. (eds.), Mind as Infinite Dimensionality, Roma, Ed. Carlo Amore (forthcoming, 2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Manning</author>
<author>H Schütze</author>
</authors>
<title>Foundations of Statistical Natural Language Processing</title>
<date>1999</date>
<publisher>MIT Press</publisher>
<marker>Manning, Schütze, 1999</marker>
<rawString>Manning, C. &amp; Schütze, H. (1999). Foundations of Statistical Natural Language Processing. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sparck Jones</author>
<author>K</author>
</authors>
<title>A statistical interpretation of term specificity and its application in retrieval</title>
<date>1972</date>
<journal>Journal of Documentation</journal>
<volume>28</volume>
<pages>11--21</pages>
<marker>Jones, K, 1972</marker>
<rawString>Sparck Jones, K. (1972). A statistical interpretation of term specificity and its application in retrieval. Journal of Documentation, 28 (1), pp. 11-21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Quasthoff</author>
<author>M Richter</author>
<author>C Biemann</author>
</authors>
<date>2006</date>
<contexts>
<context>.1. Automatic Language Recognition. This process is accomplished by vector comparison with models of nine languages that the program has incorporated from corpora of general language (downloaded from Quasthoff et al, 2006). It is a particular instance of document categorization. Each language is represented as a vector of its function words (the 100 more frequent words in those corpora) and each document is assigned t</context>
</contexts>
<marker>Quasthoff, Richter, Biemann, 2006</marker>
<rawString>Quasthoff, U., M. Richter, and C. Biemann (2006).</rawString>
</citation>
</citationList>
</algorithm>

