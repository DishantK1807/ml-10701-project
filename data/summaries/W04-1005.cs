Tokens are an obvious and unambiguous baseline for lexical agreement, one used by such summary evaluation systems as ROUGE (Lin and Hovy, 2003).
N03-1020
Research Previous research addressing summary vocabulary is limited, and most has been undertaken in connection with another issue: either with the problem of evaluating summary quality (Mani, 2001; Lin and Hovy, 2002) or to assess sentence element suitability for use in a summary (Jing and McKeown, 1999).
W02-0406
We judge them to be weakly syntactically motivated2 and only roughly analogous to the factoids identified by van Halteren and Teufel (2003) in the sense that they also express semantic constructs.
W03-0508
Mani (2001) reports that “previous studies, most of which have focused on extracts, have shown evidence of low agreement among humans as to which sentences are good summary sentences.” Lin and Hovy’s (2002) discovery of low interrater agreement in single (~40%) and multiple (~29%) summary evaluation may also pertain to our findings.
W02-0406
Attempting to answer that question, van Halteren and Teufel (2003) conclude that 30 to 40 manual summaries should be sufficient to establish a stable consensus model summary.
W03-0508
