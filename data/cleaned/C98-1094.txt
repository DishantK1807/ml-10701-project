Improving Automatic Indexing through Concept Combination 
and Term Enrichment 
Christian Jacquemin* 
LIMSI-CNRS 
BP 133, F-91403 ORSAY Cedex, FRANCE 
j acqueminOlims ±. fr 
Abstract 
Although indexes may overlap, the output of 
an automatic indexer is generally presented as 
a flat and unstructured list of terms. Our pur
pose is to exploit term overlap and embed
ding so as to yield a substantial qualitative 
and quantitative improvement in automatic in
dexing through concept combination. The in
crease in the volume of indexing is 10.5% for 
free indexing and 52.3% for controlled indexing. 
The resulting structure of the indexed corpus is 
a partial conceptual analysis. 
1 Overview

The method, proposed here for improving an
tomatic indexing, builds partial syntactic stru
ctures by combining overlapping indexes. It is 
complemented by a method for term acquisition 
which is described in (Jacquemin, 1996). The 
text, thus structured, is reindexed; new indexes 
are produced and new candidates are discove
red. 
Most NLP approaches to automatic indexing 
concern flee indexing and rely on large-scale 
shallow parsers with a particular concern for 
dependency relations (Strzalkowski, 1996). For 
the purpose of controlled indexing, we exploit 
the output of a NLP-based indexer and the stru
ctural relations between terms and variants in 
order to (1) enhance the coverage of the in
dexes, (2) incrementally build an a posteriori 
conceptual analysis of the document, and, (3) 
interweave controlled indexing, free indexing, 
and thesaurus acquisition. These 3 goals are 
achieved by CONPARS (CONceptual PARSer), 
presented in this paper and illustrated by Fi
gure 1. CONPARS is based on the output of 
* We thank INIST-CNRS for providing us with thesauri 
and corpora in the agricultural domain and AFIRST for 
supporting this research through the SKETCHI project. 
a part-of-speech tagger for French described in 
(Tzoukermann and Radev, 1997) and FASTR, 
a controlled indexer (Jacquemin et al., 1997). 
All the experiments reported in this paper are 
performed on data in the agricultural domain: 
\[AGRIC\] a 1.18-million word corpus, \[AGRO
VOC\] a 10,570-term controlled vocabulary, and 
\[AGR-CAND\] a 15,875-term list acquired by 
ACABIT (Daille, 1997) from \[AGRIC\]. 
LbP ech 
No 
Augmented indexing 
Figure 1: Overall Architecture of CONPAR$ 
2 Basic
Controlled Indexing 
The preprocessing of the corpus by tlle tag
ger yields a morphologically analyzed text, 
with unambiguous syntactic categories. Then, 
the tagged corpus is automatically indexed by 
FASTR which retrieves occurrences of nmlti
word terms or variants (see Table 1). 
595 
Table 1: Indexing of a Sample Sentence 
La variation mensuelle de la respiration du sol et 
ses rapports avec l'humiditd et la tempdrature du 
sol ont dtd analysdes dans le sol superficiel d'une 
/or~t tropicale. (The monthly variation of the respi
ration of the soil and its connections with the mois
ture and the temperature of the soil have been ana
lyzed in the surface soil of a tropical forest.) 
il 007019 Respiration du sol Occurrence 
respiration du sol (respiration of the soil) 
i2 002904 Sol de \]or~t Embedding2 
so__ll superficiel d'une for~t (surf. soil of a forest) 
i3 012670 Humiditd du sol Coordination1 
humiditd et la tempdrature du sol 
(moisture and the temperature of the soil) 
i4 007034 Tempdrature du sol Occurrence 
tempdrature du sol (temperature of the soil) 
i5 007035 Analyse de sol VerbTransfl 
analysdes dans le sol (analyzed in the soil) 
i6 007809 For~t tropicale Occurrence 
for~t tropicale (tropical forest) 
Each variant is obtained by generating term 
variations through local transformations com
posed of an input lexico-syntactic structure 
and a corresponding output transformed struc
ture. Thus, VerbTransfl is a verbalization which 
transforms a Noun-Preposition-Noun term into 
a verb phrase represented by the variation pat
tern V4 (Adv ? (Prep ? Art I Prep) A ?) N3:1 
VerbTransfl( N1 Prep2 N3 ) (1) 
= V4 (Adv'* (Prep'* Art I Prep) A ?) N3 
{MorphFamily(N1) = MorphFamily(V4)} 
The constraint following the output structure 
states that V4 belongs to the same morphologi
cal family as N1, the head noun of the term. 
VerbTransfl recognizes analysdes\[v\] dans\[prep\] 
le\[Art\] sol\[N\] (analyzed in the soil) as a variant 
of analyse\[N\] de\[prepl sol\[N\] (soil analysis). 
Six families of term variations are accounted 
for by our implementation for French: coordina
tion, compounding/decompounding, term em
bedding, verbalization (of nouns or adjectives), 
nominalization (of nouns, adjectives, or verbs), 
and adjectivization (of nouns, adjectives, or 
verbs). Each index in Table 1 corresponds to 
1The following abbreviations are used for the catego
ries: V = verb, N = noun, Art = article, Adv = adverb, 
Conj conjunction, Prep = preposition, Punc -punc
tuation. 
a unique term; it is referenced by its identifier, 
its string, and a unique variation of one of the 
aforementioned types (or a plain occurrence). 
3 Conceptual
Phrase Building 
The indexes extracted at the preceding step are 
text chunks which generally build up a correct 
syntactic structure: verb phrases for verbaliza
tions and, otherwise, noun phrases. When over
lapping, these indexes can be combined and re
placed by their head words so as to condense 
and structure the documents. This process is 
the reverse operation of the noun phrase decom
position described in (Habert et al., 1996). 
The purpose of automatic indexing entails the 
following characteristics of indexes: 
• frequently, indexes overlap or are embed
ded one in another (with \[AGR-CAND\], 
35% of the indexes overlap with another 
one and 37% of the indexes are embed
ded in another one; with \[AGROVOC\], the 
rates are respectively 13% and 5%), 
• generally, indexes cover only a small fra
ction of the parsed sentence (with \[AGR
CAND\], the indexes cover, on average, 15% 
of the surface; with \[AGROVOC\], the ave
rage coverage is 3%), 
• generally, indexes do not correspond to 
maximal structures and only include part 
of the arguments of their head word. 
Because of these characteristics, the construc
tion of a syntactic structure from indexes is like 
solving a puzzle with only part of the clues, and 
with a certain overlap between these clues. 
Text Structuring 
The construction of the structure consists of the 
following 3 steps: 
Step 1. The syntactic head of terms is deter
mined by a simple noun phrase grammar of the 
language under study. For Prench, the following 
regular expression covers 98% of the term struc
tures in the database \[AGROVOC\] (Mod is any 
adjectival modifier and the syntactic head is the 
noun in bold face): 
Mod* N N ? (Mod \[ (Prep Art': Mod* N N ? Mod*))* 
The second source of knowledge about synta
ctic heads is embodied in transformations. For 
596 
instance, the syntactic head of the verbalization 
in (1) is the verb in bold typeface. 
Step 2. A partial relation between the indexes 
of a sentence is now defined in order to rank 
in priority the indexes that should be grouped 
first into structures (the most deeply embedded 
ones). This definition relies on the relative spa
tial positions of two indexes i and j and their 
syntactic heads H(i) and g(j): 
Definition 3.1 (Index priority) Let i and j 
be two indexes in the same sentcnce. The rela
tive priority ranking of i and j is: 
i~ j ¢~ (i = j) V (H(i) = H(j) A i C j) 
V (II(i) CH(j) AH(i) ej A H(j) ~(i) 
This relation is obviously reflexive, it is nei
ther transitive nor antisymmetric. It can, howe
ver, bc shown that this relation is not cyclic for 
3 elements: iTij A jTik ~ -~(kTii). (This 
property is not demonstrated here, due to the 
lack of space.) 
The linguistic motivations of Definition 3.1 
are linked to the composite structure built at 
Step 3 according to the relative priorities stated 
by %. We now examine, in turn, the 4 cases of 
term overlap: 
1. Head embedding: 2 indexes i and j, with 
a common head word and such that i is 
embedded into j, build a 2-level structure: 
H(i) H(i) //~ 
H(i) 
This structuring is illustrated by nappe 
d'eau (sheet of water) which combines 
with nappe d'eau souterraine (underground 
sheet of water) and produces the 2-level 
structure \[\[nappe d' eau\] souterraine\] (\[un
derground \[_sheet of water\]\]). (Head words 
are underlined.) In this case, i has a higher 
priority than j; it corresponds to (H(i) = 
H(j) A i C j) in Definition 3.1. 
2. Argument embedding: 2 indexes i and j, 
with different head words and such that the 
head word of i belongs to j and the head 
word of j does not belong to i, combine as 
follows: 
H(j) n(j) H(i) 
H(i) 
This structuring is illustrated by nappe 
d'eau which combines with eau soutcr
raine (underground water) and produces 
the structure \[nappe d~eau souterraine\]\] 
(\[.sheet of \[underground waterJ\]), tlere, i 
has a higher priority than j; it corresponds 
to (H(i) ¢ H(j) A H(i) C j A H(j) ¢i) 
in Definition 3.1. 
3. Head overlap: 2 indexes i and j, with 
a common head word and such that i 
and j partially overlap, are also combi
ned at Step 3 by making j a substructure 
of i. This combination is, however, non
deterministic since no priority ordering is 
defined between these 2 indexes. There
fore, it does not correspond to a condition 
in Definition 3.1. ~,,N+ ~ N.D.~ 
i H(i) H(i) 
H(i) 
In out experiments, this structure COl
responds to only one situation: a head 
word with preand post-modifiers such 
as importante aetivitd (intense activity) 
and aetivivtd de ddgradation mdtaboliquc 
(activity of metabolic degradation). 
With \[AGR-CAND\], this configuration 
is encountered only 27 times (.1% of 
the index overlaps) because premodifiers 
rarely build correct term occurrences in 
French. Premodifiers generally correspond 
to occasional characteristics such as size, 
height, rank, etc. 
4. The remaining case of overlapping indexes 
with different head words and reciprocal in
clusions of head words is never encounte
red. Its presence would undeniably denote 
a flaw in the calculus of head words. 
Step 3. A bottom-up structure of the sentences 
is incrementally built by replacing indexes by 
trees. The indexes which are highest ranked by 
597 
the Step 2 are processed first according to the 
following bottom-up algorithm: 
1. build a depth-1 tree whose daughter nodes 
are all the words in the current sentence 
and whose head node is S, 
2. for all the indexes i in the current sentence, 
selected by decreasing order of priority, 
(a) mark all the the depth-1 nodes which 
are a lexical leaf of i or which are the 
head node of a tree with at least one 
leaf in i, 
(b) replace all the marked nodes by a 
unique tree whose head features are 
the features of H(i), and whose depth
1 leaves are all the marked nodes. 
When considering the sentence given in 
Table 1, the ordering of the indexes after Step 2 
is the following: i 2 > i5, i6 > iz, and i4 > i3. 
(They all result from the argument embedding 
relation.) The algorithm yields the following 
structure of the sample sentence: 
..~.la respiratio/z et ses rapports avec l'humiditd ont dtd analvsdes 
re.~7~iration du sol humiditd et la tempdrature analysdes dans le sol 
tempdrature du sol sol superficiel d'une fordt 
for~t tropicale 
Text Condensation 
The text structure resulting from this algorithm 
condenses the text and brings closer words that 
would otherwise remain separated by a large 
number of arguments or modifiers. Because of 
this condensation, a reindexing of the structu
red text yields new indexes which are not ex
tracted at the first step. 
Let us illustrate the gains from reindexing 
on a sample utterance: l'dvolution au cours du 
temps du sol et des rendements (temporal evo
lution of soils and productivity). At the first 
step of indexing, dvolution au eours du temps 
(lit. evolution over time) is recognized as a va
riant of gvolution dans le temps (lit. evolution 
with time). At the second step of indexing, the 
daughter nodes of the top-most tree build the 
condensed text: l'dvolution du sol et des rende
ments (evolution of soils and productivity): 
1st step S 
2nd step 
l'dvolution au cours du temps du sol el des rendements 
l'ivolution du sol et des rendements 
l' gvolution au cours du temps 
This condensed text allows for another index ex
traction: dvolution du sol et des rendements, a 
Coordination variant of dvolution du rendement 
(evolution of productivity). This index was not 
visible at the first step because of the additional 
modifier au cours du temps (temporal). (Reite
rated indexing is preferable to too unconstrai
ned transformations which burden the system 
with spurious indexes.) 
Both processes--text structuring, presented 
here, and term acquisition, described in (Jac
quemin, 1996)--reinforce each other. On the 
one hand, acquisition of new terms increases the 
volume of indexes and thereby improves text 
structuring by decreasing the non-conceptual 
surface of the text. On the other hand, text 
condensation triggers the extraction of new in
dexes, and thereby furnishes new possibilities 
for the acquisition of terms. 
4 Evaluation

Qualitative evaluation: The volume of in
dexing is characterized by the surface of the 
text occupied by terms or their combinations-
we call it the conceptual surface. Figure 2 
shows the distribution of the sentences in re
lation to their conceptual surface. For instance, 
in 8,449 sentences among the 62,460 sentences 
of \[AGRIC\], the indexes occupy from 20 to 30% 
of the surface (3rd column). 
This figure indicates that the structures built 
from free indexing are significantly richer than 
those obtained from controlled indexing. The 
number of sentences is a decreasing exponem 
tial function of their conceptual surface (a linear 
function with a log scale on the y axis). 
Figure 3 illustrates how the successive steps 
of the algorithm contribute to the final size of 
the incremental indexing. For each mode of 
598 
10.~ : ...... 
-~ i0 4 
g~ 10 3 
~ 102 
~ 101 
~ i0 o 
0 
Free indexing 
10 20 30 40 50 60 70 80 90 100 
% of conceptual suface 
Figure 2: Conceptual Surface of Sentences 
Table 2: Increase in the volume of indexing 
Acquisition Condensation Total 
Controlled 49.3% 3.0% 52.3% 
Free 5.8% 4.7% 10.5% 
indexing two curves are plotted: the phrases 
resulting from initial indexing and from rein
dexing due to text condensation (circles) and 
the phrases due to term acquisition (asterisks). 
For instance, at step3, free indexing yields 309 
indexes and reindexing 645. The corresponding 
percentages are reported in Table 2. 
The indexing with the poorest initial volume 
(controlled indexing) is the one that benefits 
best fi'om term acquisition. Thus, concept com
bination and term enrichment tend to compen
sate the deficiencies of the initial term list by 
extracting more knowledge from the corpus. 
I0 ~, ~ Free indexing 
"~ ~ ~ ~ Free acquisition 
104~ \.. ~ , ........ Controlled indexing 
103"L ~*"'" ........ Controlled acquisition 
i o ........ 10 2 ~...... o ..... . " '"" G, '"~''" ~c~ 10 I 
I0 2 3 4 5 6 7 8 
# step 
Figure 3: Step-by-step Number of Phrases 
Qualitative evaluation: Table 3 indicates the 
number of overlapping indexes in relation to 
their type. It provides, for each type, the rate of 
success of the structuring algorithm. This eva
Table 3: Incremental Structure Building 
Head Argument Total 
embedding embedding 
Distribution 27.0% 73.0% 100% 
# correct 128 346 474 
Precision 79.0% 91.1% 87.5% 
luation results from a human scanning of 5,t2 
randomly chosen structures. 
5 Conclusion

This study h~ presented CONPARS, a tool 
for enhancing the output of an automatic in
dexer through index combination and term en
richment. Ongoing work intends to improve the 
interaction of indexing and acquisition through 
self-indexing of automatically acquired terms. 

References 

Beatrice Daille. 1997, Study and implementa
tion of combined techniques tbr automatic ex
traction of terminology. In J. L. Klavans and 
P. Resnik, ed., The Balancing Act: Combi
ning Symbolic and Statistical Approaches to 
Language, p. 49-66. MIT Press, Cambridge. 

Benoit Habert, Elie Nanlleau, and Adeline Na
zarenko. 1996. Symbolic word clustering for 
medium size corpora. In Proceedings of CO
LING'96, p. 490-495, Copenhagen. 

Christian Jacquemin, Judith L. Klavans, and 
Evelyne Tzoukermann. 1997. Expansion of 
multi-word terms tbr indexing and retriewtl 
using morphology and syntax, In Proceedings 
of ACL-EACL '97, p. 24-31. 

Christian Jacquemin. 1996. A symbolic and 
surgical acquisition of terms through varia
tion. In S. Wermter, E. Riloff, and G. Sche
ler, ed., Connectionist, Statistical and Symbo
lic Approaches to Learning for NLP, p. 425
438. Springer, Heidelberg. 

Tomek Strzalkowski. 1996. Natural language 
information retrieval. Information Processing 
Management, 31(3):397 417. 

Evelyne Tzoukermann and Dragomir R. R,adev. 
1997. Use of weighted finite state transducers 
in part of speech tagging, in A. Kornai, ed., 
Extended Finite State Models of Language. 
Cambridge University Press. 

