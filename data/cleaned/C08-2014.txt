Coling 2008: Companion volume – Posters and Demonstrations, pages 55–58
Manchester, August 2008
Multilingual alignments by monolingual string differences
Adrien Lardilleux and Yves Lepage
GREYC, University of Caen Basse-Normandie,
BP 5186, Caen Cedex, France
Firstname.Lastname@info.unicaen.fr
Abstract
We propose a method to obtain subsenten-
tial alignments from several languages si-
multaneously. The method handles sev-
erallanguagesatonce, andavoidsthecom-
plexity explosion due to the usual pair-by-
pair processing. It can be used for differ-
ent units (characters, morphemes, words,
chunks). An evaluation of word align-
ments with a trilingual machine translation
corpus has been conducted. A comparison
of the results with those obtained by state
of the art alignment software is reported.
1 Introduction
Several tools are available nowadays for alignment
of pairs of languages. Among them, the bilingual
word aligner GIZA++ (Och and Ney, 2003) can
perform high quality alignments based on words
statistics and is considered the most efficient tool.
Three main criticisms may be addressed to this
kind of tool.
Firstly, as denoted by Moore (2005), one needs
to tune numerous parameters in order to opti-
mize the results for a particular alignment task,
which can be very time consuming. This is all
the more important when multilingual alignment is
concerned, since every language pair will require
its own set of parameter values.
Secondly, the best methods available nowadays
can only work on language pairs, which results in
a complexity explosion when multilingual align-
ments are needed. Simard (1999) showed how to
adapt a bilingual method to align more than two
c©2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
versions of a text at the sentence level, but lan-
guages have to be processed by pairs to identify
which ones are the most similar.
Thirdly, these approaches are also designed to
align specific units of texts (almost always words).
The same method cannot be applied indifferently
on different units. Languages which do not sep-
arate words by spaces require to be first seg-
mented into words, while a character-based ap-
proach could be a worthy alternative.
To deal with all these issues, we propose a
method which is primarily intended to align many
languages simultaneously from sentence-aligned
parallel corpora, whatever the segmentation unit.
2 Alignment
by string differences
2.1 String
differences
In order to introduce the operation we use,
let us start with a well-known similar tech-
nique, the Longest Common Subsequence (LCS)
(Hirschberg, 1975). Given two strings A and B,
it is always possible to find their longest subse-
quence. Such a subsequence is a sequence of non
necessarily contiguous characters.
For instance, assume we have the follow-
ing short English sentences (space characters are
marked by an underscore and have the same status
as any other character):
A = I would like a donut, please.
B = Regular size, please.
In this case, the LCS for A and B would be:1
LCS(A,B) = ul ie, please.
which is 14 characters long. It is then possible to
form their string difference:
1For purpose of simplicity, we do not mention that the
LCS operation, as well as the difference operation, may de-
liver a plurality of strings.
55
AcircleminusB = I wodlk a donut
BcircleminusA = Regarsz
where we define AcircleminusB = A−LCS(A,B).
Because several isolated characters are dis-
carded, this results in a malformed string that is
of limited interest. To avoid misinformed strings,
we rather resort to Longest Common Substrings
(LCSubstr), that are contiguous.
On the previous example, the LCSubstr is:
LCSubstr(A,B) = , please.
which is 9 characters long and by far more mean-
ingful. By removing this substring from A and B,
we obtain:2
AcircleminusB = I would like a donut
BcircleminusA = Regular size
2.2 A
monolingual operation for multilingual
alignment
String differences are monolingual. They serve as
a starting point to compute alignments. It suffices
to apply them in parallel on the source text and all
aligned target texts.
Let us consider anew the previous English
sentences and their translations into Japanese
(“A stands for “A’s translation”):
“A = uni30C9uni30FCuni30CAuni30C4uni3092uni4E0Buni3055uni3044uni3002
/dˆonatu wo kudasai./
“B = uni666Euni901Auni30B5uni30A4uni30BAuni3092uni4E0Buni3055uni3044uni3002
/hutuu saizu wo kudasai./
LCSubstr(“A,“B) = uni3092uni4E0Buni3055uni3044uni3002
“Acircleminus“B = uni30C9uni30FCuni30CAuni30C4
“Bcircleminus“A = uni666Euni901Auni30B5uni30A4uni30BA
By performing simultaneously the difference be-
tweenAandB andbetween“Aand“B,theiraligned
translations, we obtain:, please. ↔ uni3092uni4E0Buni3055uni3044uni3002
I would like a donut ↔ uni30C9uni30FCuni30CAuni30C4
Regular size ↔ uni666Euni901Auni30B5uni30A4uni30BA
The method assumes that the three strings com-
puted in the source language are translations of
their corresponding strings in the target language
That is:
¤NULLCSubstr(A,B) = LCSubstr(“A,“B)
◊NULAcircleminusB = “Acircleminus“B
◊NULBcircleminusA = “Bcircleminus“A
2Idem. Experiments show that they are not as numerous
as for LCS. For the sake of simplicity, we shall assume that
LCSubstr’s are unique.
2.3 Iterative
application
Assume we want to extract the translation equiva-
lent of “Chicago” in Japanese from the following
pairs of sentences:
A0 = Is this a train for Chicago?
“A0 = uni3053uni306Euni5217uni8ECAuni306Funi30B7uni30ABuni30B4uni884Cuni304Duni3067uni3059uni304Buni3002
/kono ressya ha sikago yuki desu ka./
B = Is this price correct?
“B = uni3053uni306Euni5024uni6BB5uni3067uni6B63uni3057uni3044uni3067uni3059uni304Buni3002
/kono nedan de tadasii desu ka./
C = What track does the train for Boston start from?
“C = uni30DCuni30B9uni30C8uni30F3uni884Cuni304Duni306Euni5217uni8ECAuni306Funi4F55uni756Auni304Buni3089uni51FAuni307Euni3059uni304Buni3002
/bosuton yuki no ressya ha nani ban kara syutu masu ka./
A direct application of the method described
above does not ensure that “Chicago” will corre-
spond to a string difference. A way to solve the
problem is to apply the method iteratively. String
differences are applied on the sentence where
“Chicago” appears (i.e., A), in order to gradually
cut it down to “Chicago” only. By applying the
same process in parallel on all target sentences,
strings are expected to reduce to the translation of
“Chicago”aswell. Also, weaddtheconstraintthat
the string to be aligned must not be altered during
the iterative process, i.e., it should not be included
in any LCSubstr.
Thus, starting with A0 containing “Chicago”,
we perform at each step:
An+1 = An circleminusSn
“An+1 = “An circleminus”Sn
where Sn is the first sentence S in the list
of all source sentences sorted by the length of
LCSubstr(An,S). In other words, amongst the
available English sentences S, select the one that
shares the longest substring with An, and remove
this substring from An. The corresponding differ-
ences are applied in the target languages simulta-
neously.
Table 1 gives the details of an execution of the
iterative process. On a large amount of data, the
method may yield a plurality results; each of them
may be obtained a certain number of times. We
shall judge the quality of alignments based on
these frequencies.
2.4 Best
alignments selection
In practice, it is not possible to perform all the dif-
ferences between sentences that would lead to the
alignment of a particular string. This complexity
explosion, where most of the LCSubstr’s would be
very short, would result in non reliable alignments.
56
n An Sn LCSubstr(An,Sn) hatwideAn LCSubstr(hatwideAn,hatwiderSn)
0 Is
this a train for Chicago? C train for uni3053uni306Euni5217uni8ECAuni306Funi30B7uni30ABuni30B4uni884Cuni304Duni3067uni3059uni304Buni3002 uni306Euni5217uni8ECAuni306F
1 Is
this aChicago? B Is this uni3053uni30B7uni30ABuni30B4uni884Cuni304Duni3067uni3059uni304Buni3002 uni3067uni3059uni304Buni3002
2 aChicago? B ? uni3053uni30B7uni30ABuni30B4uni884Cuni304D uni3053
3 aChicago C a uni30B7uni30ABuni30B4uni884Cuni304D uni884Cuni304D
4 Chicago
uni30B7uni30B7uni30ABuni30ABuni30ABuni30B4uni30B4
Table 1: Details of the steps necessary to extract one alignment for “Chicago” in Japanese. “Chicago”
maynotbemodifiedduringtheiterativeprocessandisnotusedtocomputetheLCSubstr’s. Theresulting
alignment is “A4 =uni30B7uni30ABuni30B4/sikago/, which is correct.
We cut down the complexity by examining only
the c first longest LCSubstr’s longer than a prede-
finedthreshold. Thethresholdwassettohalfofthe
longestLCSubstr. Differentvaluesofcweretested
forintheexperimentsreportedinSection3.3. This
parameter is used in the source language only.
Well-formedness of strings is also tested by
checking the presence of all their n-sequences of
characters in the initial data. This is performed in
the target languages.
Eventually, each alignment is scored by its fre-
quency divided by the number of sentences that
were required to obtain it. The reason for doing
so is that, in practice, the less sentences required,
the longer and the safer the LCSubstr’s used.
3 Evaluation
3.1 Data
used
We used the English, Japanese and Arabic train-
ing parts of the IWSLT 2007 machine transla-
tion campaign corpus (Fordyce, 2007) to conduct
our experiments. It is made of nearly 20,000
triples of aligned sentences from the BTEC corpus
(Takezawa et al., 2002).
3.2 Result
samples
Asmentionedearlier, oneadvantageofourmethod
is that it can align any string of text, providing the
data is sufficient. Table 2 shows a sample of align-
ments obtained using English as the source lan-
guage. The strings requested to be aligned can be
anything, from one character (see the first lines of
the table) to entire sentences (see last line). Most
alignments, if not perfect, differ from the expected
meaning by slight differences only, even in Arabic.
3.3 Comparison
against GIZA++
We compared our system to the state of the art
device, GIZA++, in the particular case of bilin-
gual word alignments on two pairs of languages:
English to Arabic and English to Japanese. Our
systemalignedthethreelanguagessimultaneously,
using English words as input. For each target lan-
guage, the target unit with the best score (see Sec-
tion 2.4) was kept. Different values of c were
tested.
GIZA++ was used to compute IBM model 4.
The default set of parameter values, which typi-
cally produces good results, was used. For each
source word, the most probable pair of words
(source, target) was kept. Note that the output of
IBM model 4 produces word to word alignments,
while there is no guaranty that our system would
output a single target word as the unit of process-
ing is the character.
For an objective assessment, we resort to
two bilingual dictionaries: English-Japanese, and
English-Arabic.3 AsforEnglish-Japanese,thebest
results were obtained for c = 40, and are as good
as those of GIZA++ (628 alignments found in the
reference dictionary vs. 629, see Table 3). As for
English-Arabic, the best results were obtained for
c = 20, but only 37% of GIZA++’s results could
be achieved (63 alignments found in the reference
dictionary vs. 170).
Those alignments output by the two systems
that do not belong to the reference dictionaries are
not necessarily erroneous, since we relied on exact
matching. Specifically, for our method, one extra
characteronlymayberesponsibleforanalignment
to be considered wrong.
3We used an English-Arabic dictionary from sdict
(87,000 entries): http://sdict.com and the
EDICT English-Japanese dictionary (115,000 entries):
http://www.csse.monash.edu.au/∼jwb/j e-
dict.html. The Arabic part of the English-Arabic
dictionary being lemmatized, we had to preprocess the
Arabic part of our corpus so that it be lemmatized too (Debili
and Achour, 1998).
57
English Arabic Japanese
. char2e /./ ‘.’ uni3002 /./ ‘.’
? char3f /?/ ‘?’ uni304Buni3002 /ka ./ ‘?’
Wh char09chare1char4bchar0achar0dchar40 /arrowhookrightayn/ ‘where’ uni4F55 /nani/, /nan/ ‘what’, ‘wh...’
here char41char09char4achareb /hn¯a/ ‘here’ uni3053uni3053 /koko/ ‘here’
I ’d like char59char4bchar0achar50char0dchar40 /arrowhookrightaryd/ ‘I’d like’ uni4E0Buni3055uni3044 /kudasai/ ‘please’
Thank you char40char51charba char11char83 /ˇskr¯a/ ‘thank you’ uni3042uni308Auni304Cuni3068uni3046 /arigatou/ ‘thank you’
Ice chard5chare7char27char0achar51charbb char81char1dchar0achar0echar40 /arrowhookright¯ays krym/ ‘ice cream’ uni6C37uni3092 /koori wo/ ‘ice’
I have to get
char10chare9charabchar41char83 charc8char40 charc9char4achar2e char10charaecharcachar92char4achar0acharcacharab
/arrowhookleftlys.lqbl ¯al s¯aarrowhooklefth/
* malformed string *
uni5165uni624Buni3057uni306Auni3051uni308Cuni3070uni306Auni308Auni307Euni305Buni3093
/nyuusyu si nakerebanarimasen/
‘I have to get’
At seven o’clock
char10chare9charaachar4bchar2echar41char83 charc8char40 char10chare9charabchar41char83 charc8char40 charfachar0achar09charaf
/fy ¯al s¯aarrowhooklefth ¯al s¯abarrowhooklefth/
‘at seven o’clock’
uni4E03uni6642uni306B
/sitizi ni/
‘at seven o’clock’
Table2: AsampleofalignmentsobtainedusingEnglishasthesourcelanguage. TheArabicandJapanese
strings were generated in parallel by aligning the three languages at once. Parameter c was set to 20 in
this experiment.
Our system
GIZA++ c = 1 c = 10 c = 20 c = 30 c = 40 c = 50
English-Japanese 629 / 4,268 369 / 1,569 573 / 2,629 603 / 3,038 598 / 3,165 628 / 3,219 615 / 3,248
English-Arabic 170 / 1,569 36 / 540 57 / 863 63 / 982 57 / 1,017 51 / 1,025 51 / 1,029
Table 3: Comparison of our system against GIZA++. Each cell gives the number of alignments found in
the reference dictionary over the number of alignments obtained.
4 Conclusion
We introduced a simple method to obtain subsen-
tential alignments from several languages simul-
taneously. Its focus is on contexts rather than on
units to be aligned. It avoids the complexity ex-
plosion due to the usual pair-by-pair processing
by relying on the simultaneous application of a
monolingual operation. The method comes close
to GIZA++’s results in some word alignment task,
while being by far much simpler.
References
Debili, Fathi and Hadhemi Achour. 1998. Voyellation
automatique de l’arabe. In Proceedings of the Work-
shop on Computational Approaches to Semitic Lan-
guages (COLING-ACL’98), pages 42–49, Montreal,
Quebec, Canada, August.
Fordyce, Cameron Shaw. 2007. Overview of the
IWSLT 2007 evaluation campaign. In Proceed-
ings of the 4th International Workshop on Spoken
Language Translation (IWSLT 2007), pages 1–12,
Trento, Italy, October.
Hirschberg, Dan. 1975. A linear space algorithm for
computing maximal common subsequences. Com-
munications of the ACM, 18:341–353, June.
Moore, Robert. 2005. A discriminative framework for
bilingual word alignment. In Proceedings of Human
Language Technology Conference and Conference
onEmpiricalMethodsinNaturalLanguageProcess-
ing, pages 81–88, Vancouver, British Columbia, Oc-
tober.
Och, Franz Josef and Hermann Ney. 2003. A system-
aticcomparisonofvariousstatisticalalignmentmod-
els. Computational Linguistics, 29:19–51, March.
Simard, Michel. 1999. Text-translation alignment:
Three languages are better than two. In Proceed-
ings of the Joint SIGDAT Conference of Empirical
Methods in Natural Language Processing and Very
Large Corpora (EMNLP/VLC), College Park, Mary-
land, USA.
Takezawa, Toshiyuki, Eiichiro Sumita, Fumiaki Sug-
aya, Hirofumi Yamamoto, and Seiichi Yamamoto.
2002. Toward a broad-coverage bilingual corpus
for speech translation of travel conversation in the
real world. In Proceedings of the third International
Conference on Language Resources and Evaluation
(LREC 2002), pages 147–152, Las Palmas de Gran
Canaria, Spain.
58

