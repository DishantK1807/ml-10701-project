Separating Surface Order and Syntactic Relations 
in a Dependency Grammar 
Norbert BrSker 
Universit/it Stuttgart 
Azenbergstr. 12 
D-70174 Stuttgart 
NOBI (@ IMS. UNI-STUTTGART. DE 
Abstract 
This paper proposes decoupling the dependency 
tree fl'om word order, such that surface ordering 
is not determined by traversing the dependency 
tree. We develop the notion of a word order do
main structure, which is linked but structurally 
dissimilar to the syntactic dependency tree. The 
proposal results in a lexicalized, declarative, and 
formally precise description of word order; fea
tures which lack previous proposals for depen
dency grammars. Contrary to other lexicalized 
approaches to word order, our proposal does not 
require lexical ambiguities for ordering alterna
tives. 
1 Introduction

Recently, the concept of valency has gained con
siderable attention. Not only do all linguis
tic theories refer to some reformulation of the 
traditional notion of valency (in the form of 0
grid, subcategorization list, argument list, or ex
tended domain of locality); there is a growing 
number of parsers based on binary relations be
tween words (Eisner, 1997; Maruyama, 1990). 
Given this interest in the valency concept, 
and the fact that word order is one of the 
main difference between phrase-structure based 
approaches (henceforth PSG) and dependency 
grammar (DG), it is valid to ask whether DG 
can capture word order phenomena without re
course to phrasal nodes, traces, slashed cate
gories, etc. A very early result on the weak 
generative equivalence of context-free grammars 
and DGs suggested that DGs are incapable of 
describing surface word order (Gaifman, 1965). 
This result has recently been critizised to apply 
only to impoverished DGs which do not properly 
represent formally the expressivity of contempo
rary DG variants (Neuhaus &; BrSker, 1997). 
Our position will be that dependency re
lations are motivated semantically (Tesni~re, 
1959), and need not be projective (i.e., may 
cross if projected onto the surface ordering). We 
argue for so-called word order domains, consist
ing of partially ordered sets of words and associ
ated with nodes in the dependency tree. These 
order domains constitute a tree defined by set in
clusion, and surface word order is determined by 
traversing this tree. A syntactic analysis there
for consists of two linked, but dissimilar trees. 
Sec. 2 will briefly review approaches to word 
order in DG. In Sec. 3, word order domains will 
be defined, and Sec. 4 introduces a modal logic 
to describe dependency structures. Sec. 5 ap
plies our approach to the German clause and 
Sec. 6 relates it to some PSG approaches. 
2 Word
Order in DG 
A very brief characterization of DO is that 
it recognizes only lexical, not phrasal nodes, 
which are linked by directed, typed, binary rela
tions to form a dependency tree (TesniOre, 1959; 
Hudson, 1993). The following overview of DG 
flavors shows that various mechanisms (global 
rules, general graphs, procedural means) are 
generally employed to lift the limitation of pro
jectivity and discusses some shortcomings of 
these proposals. 
Functional Generative Description (Sgall 
et al., 1986) assumes a language-independent 
underlying order, which is represented as a pro
jective dependency tree. This abstract represen
tation of the sentence is mapped via ordering 
rules to the concrete surface realization. Re
cently, Kruijff (1997) has given a categorial
style formulation of these ordering rules. He 
assumes associative categorial operators, per
muting the arguments to yield the surface or
dering. One difference to our proposal is that 
174 
we argue for a repro.sentational account of word 
order (based on valid structures representing 
word order), eschewing the non-determinism in
troduced by unary operators; the second differ
ence is the avoidance of an underlying structure, 
which stratifies the theory and makes incremen
tal processing difficult. 
Meaning-Text Theory (Melc'hk, 1988) as
sumes seven .strata of representation. The rules 
mapping from the unordered dependency trees 
of surface-syntactic i'el)resentations onto the all
notated lexeme sequen(:es of deet)-nmrl)hoh@eal 
representations include global ordering rules 
which allow disesmtinuities. These rules have 
not yet, been formally specitied (Melc'hk & 
Pertsov, 19871). 187f). 
Word Grammar (WG, ttudson (1990))is 
based on geueral graphs instead of trees. Tile 
ordering of two linked words is specified together 
with their dependency relation, its ill the t)rot)o 
sition "object of verb follows it". Extra(:
lion of, e.g,, objects is analyzed 1)3' establish
lug an additional del)en(lency (:ailed visitor 
l)etween the wu'b and tim extractee, which re
(luires the reverse or(ler, as ill "visitor of 
verb precedes it". This results in inconsis
tencies, since an exti'acted object must follow 
tile verb (being its object) and at the same tinle 
precede it (being its visitor). The al)proach 
(:onlproufises tile semantic nlotiw~tion of depen
dencies by adding p,arely order-induced depen
dencies. WG is similar to our proposal in that it 
also distinguishes a t)ropositional nw, ta language 
de.scribing the graph-based analysis structures. 
Dependency Unification Grammar 
(DUG, Hellwig (1986)) defines a tree-like 
data structure for the representation of syntac
tic analyses. Using mortfllosyntactic ligatures 
with special interpretations, a word defines 
abstract positions into whicll modifiers are 
mapped. Partial orderings and even discon
tinuities (:all thus be described by allowing a 
nlodifier to occupy a position defined by some 
transitive head. The approach requires that the 
parser interpretes several features specially, and 
it cannot restrict the s(:ope of discontinuities. 
Slot Grammar (McCord, 1990) employs a 
number of rule types, sOille of which are ex
clusively con(:erned with precedence. So-called 
head/slot and slot/slot ordering rules des(:rilm 
the Inecedence in projective trees, referring to 
arbitrm'y predicates over head and modifiers. 
Extractions (i.e., discontinuities) are merely 
handled by a mechanism built into the parser. 
3 Word
Order Domains 
Summarizing the previous discussion, we require 
the following of a word order description for DO: ,, not to colnpromise the semantic motivation 
of dependencies, 
• to be able to restrict discontinuities to cer
tain constructions and delimit their scope, 
• to be lexicalized without requiring lexical 
ambiguities for the representation of order
ing alternatives, 
• to be declarative (i.e., independent of an 
analysis procedure), and 
• to be formally l)recise and consistent. 
The subsequent definition of an order domain 
structure and its linking to the delmndeney tree 
satisif:y these requirements. 
3.1 The
Order Domain Structure 
A word order domain is a set of words, general
izing the notion of positions in DUG. The cardi
nality of an order domain may be restricted to 
at most one elenlent, at least one element, or 
1)y (:onjun(:tion to exactly one element. Each 
word is associated with a se(tuence of order do
mains, one of wlfieh must contain the word itself, 
and each of these donmins may require that its 
elements have certain features. Order domains 
can be partially ordered based on set inclusion: 
If an order domain d contains word w (which 
is not associated with d), ew'.ry word w' con
tained in a domain d' associated with w is also 
contained in d; therefor, d' C d for each d' asso
ciated with w. This partial ordering induces a 
tree on order (tomains, which we call the order 
domain structure. 
Take the example of German "Den Mann/tat 
der Junge gesehen" ("the manAGe has the 
boyNoM seen"). Its dependency tree is shown 
in Fig.l, with word order domains indicated 
by dashed circles. The finite verb, "hat", de
fines a sequence of domains, <dl, d2, da), which 
roughly correspond to the topological fields ill 
the German nlain clmlse. Tile nouns "Mann" 
175 
.-, ,-&-t-........ 7 ,' dl ',{ ~ vpart "''. ' ' , ,, subj'~.~_~.', \[d3; ,' , '. '. der Junge.' '. gesohen) ,, , , d¢.-~_._~u 6 , '' , '. den Mann , -. ~ ' 
Figure 1: Dependency Tree and Order Domains 
for "Den Mann hat der Junge gesehen" 
dl d2 
d,4 hat d 5 46 , 
Mann Junge gesehen 
d3 
Figure 2: Order Domain Structure for "Den 
Mann hat der Junge geschen" 
and "Junge" and the participle "gesehcn" each 
define one order domain (d4,ds,d6, resp.). Set 
inclusion gives rise to the domain structure in 
Fig.2, where the individual words are attached 
by clashed lines to their including domains (dl 
and d4 collapse, being identical). 1 
3.2 Surface
Ordering 
How is the sm'face order derived fl'om an or
der domain structure? First of all, the ordering 
of domains is inherited by their respective ele
ments, i.e., "Mann" precedes (any element of) 
d2, "hat" follows (any element of) dl, etc. 
Ordering within a domain, e.g., of "hat" and 
d6, or d5 and d6, is based on precedence pred
icates (adapting the precedence predicates of 
WG). There are two different types, one order
ing a word w.r.t, any other element of the do
main it is associated with (e.g., "hat" w.r.t, d6), 
and another ordering two modifiers, referring to 
the dependency relations they occupy (ds and 
d6, referring to subj and vpart). A verb like 
"hat" introduces two precedence predicates, re
quiring other words to follow itself and the par
ticiple to follow subject and object, resp.: 2 
"hat"~ (<. A (vpart) >{subj,obj}) 
1Note that in this case, we have not a single rooted 
tree, but rather an ordered sequence of trees (by virtue 
of ordering dl, d2, and d3) ms domain structure. In gen
eral, we assume the sentence period to govern the finite 
verb and to introduce a single domain for the complete 
sentence. 
2For details of the notation, please refer to Sec. 4. 
Informally, the first conjunct is satisfied by 
any domain in which no word precedes "hat", 
and the second conjunct is satisfied by any do
main in which no subject or object follows a 
participle. The domain structure in Fig.2 satis
fies these restrictions since nothing follows the 
participle, and because "den Mann" is not an el
ement old2, which contains "hat". This is an im
portant interaction of order domains and prece
dence predicates: Order domains define scopes 
for precedence predicates. In this way, we take 
into account that dependency trees are flatter 
than PS-based ones a and avoid the formal in
consistencies noted above for WC. 
3.3 Linking
Domain Structure and 
Dependency Tree 
Order domains easily extend to discontinuous 
dependencies. Consider the non-projective tree 
in Fig.1. Assuming that the finite verb gov
erns the t)articiple, no projective dependency 
between the object "den Mann" and the partici
ple "gesehen" can be established. We allow non
projectivity by loosening the linking between de
pendency tree and domain structure: A modi
tier (e.g., "Mann") may not only be inserted into 
a domain associated with its direct head ("gese
hen"), but also into a domain of a transitive head 
("hat"), which we will call the positional head. 
The possibility of inserting a word into a do
main of some transitive head raises the ques~ 
tions of how to require contiguity (as needed 
in most cases), and how to limit the distance 
between the governor and the modifier in the 
case of discontinuity. From a descriptive view
point, the syntactic construction is often cited to 
determine the possibility and scope of disconti
nuities (Bhatt, 1990; Matthcws, 1981). In PS
based accounts, the construction is represented 
by phrasal categories, and extraction is lira
ited by bounding nodes (e:g., Haegeman (1994), 
Becker et al. (1991)). In dependency-based ac
counts, the construction is represented by the 
dependency relation, which is typed or labelled 
to indicate constructional distinctions which are 
configurationally defined in PSG. Given this cor
respondence, it is natural to employ dependen
cies in the description of discontiImities as fol
aNote that each phrasal level in PS-based trees defines 
a scoi)c for linear precedence rules, which only apply to 
sister nodes. 
176 
lows: For each modifi(:r of a certain head, a set 
(>f dependency types is defined wfiieh may link 
tim direct head and the positional head of the 
modifier ("gesehen" and "hat", resp.). If this set 
is; empty, both he.ads are identical and a con
tiguous attachment restflts. The inll)Ossil)ility of 
extra(:tion from, e.g., a finite verb phrase may 
follow fi'Olll the fact that the dcI)endency embed
ding finite verbs, propo, may not appear on any 
path between a direct and a positional head. 4 
4 The
Description Language 
This section sketches a logical language describ
ing the det)enden(:y structure. It is based (m 
modal logic and owes much to work of Blacklmrn 
(1994). As he argues, standard Kripke models 
can 1o(,. regarded as directed graphs with node 
annotations. We will use this interpr('tation to 
represent detmndeney strllctm'es. Dep(uMen(:ies 
and the mat)i)ing from (tel)endency trec to order 
domain structure are described by nlodal opera
tots, while simple properties such as word (:lass, 
features, and cardinality of order domains are 
des(:ril)ed })y modal In'Oi)t>sitions. 
4.1 Model
Structures 
In the following, we assume a set of words, W, 
ordered 1)y a precede.nee relation, -<, a set of 
dependency tyl)eS, 20, a set (>f atomic feature 
values A, and a set of word classes, C. We 
define a family of dependen(:y re.lalions R.d C 
\]42 x 142, d eft "D and for (:()nveni(ulee al)l>reviate 
the union Ud~> Rd as 1~9. 
Def: A det)endency tree is a tv, plc 
(W, Wr,/~.~o, VA, Vc>, where .l~n forms a tree over 
\]42 rooted in "wr, VA : 142 ~ 2 .4 maps words to 
• ~ets offeat'urc.s, and Vc : I/V ~ C maps words to 
wor'd cla,~aes. 
Deft An order domain (over W) rn is a ~set of 
words from W ,where V~IJI,'W2,'W 3 C W: (W 1 -< 
'w2 -< wa A 'Wl ~ m A 'wa ~ ?n.) =)> w2 C m. 
De:f: An order domain structure (over W) 3.4 
is a .set oJ" order domains where Vm, m' ~ .Ad : 
mr~m' = (~ V m c m' V m' c m. 
4Oil, review \])ointed out that some. verbs may allow 
extractions, i.e., that this restriction is lexical, not uni
versal. This fact can easily 1)e accomodated because tit(, 
possil)ility of discontimlity (and the dependency tyl)es 
across whi(:h the modifier may be extracted) is described 
in the lexical entry of the verb. In fact, a universal re
strictiol~ could not (!Veil l)(} st,~tted })QC~tltS(} the treatment 
is completely lexicalized. 
Deft A dependency structure T is a 
tv, ple (g, w,, R>, VA~ Ve , 3.4, VM > where 
042, w,., R.D, VA, Vc> is a dependency tree, M 
is a, order domain ,str,tct'ure over W, and 
Vz4 : I/V ~÷ 3.4 '~ maps words to order" domain 
sequences. 
Additionally, we require for a dependency 
str~mture four more conditions: (1) Each word w 
is contained in exactly one of the domains fi'om 
VM(w), (2) all domains ill V~ (w) are pairwise 
disjoint, (3) each word (except w,.)is contained 
in at least two domains, one of which is associ
ated with a (transitive) head, and (4) the (par
tial) orde.ring of domains (as described by I/'M) 
is (:onsistent with the precedence of the words 
contained in the donlains (see (BrSker, 1997) for 
more details). 
4.2 The
Language /2-1) 
Fig.3 defines the logical language L;r~ used to 
describe dependency structures. Although they 
haw~ been presented difl'erently, they can eas
ily be rewritten as (multimodal) Kripke models: 
q'h(: dell,lid,hey relal;ion H,d is l'epresenl;e(t as 
modality (d) and tile Inapping fl'oln a word to 
its ith order domain as modality 0~4.5 All other 
formulae denote properties of nodes, and tail be 
formulated as unary predicates nlost evident 
for word (:lass and feature assigmnent. For the 
I)recedence predicates <, and <a, there are ii> 
verses >, and >a. For presentation, the relation 
places C W x 142 has be.en inlroduced, which 
holds between two words iff the first argument 
is the positional h(:ad of the second argument. 
A more elaborate definition of dependency 
structures and L;~ defines two more dimensions, 
a feature graph mapped off' the dependency tree 
much like the proposal of Blackburn (1994), and 
a conceptual representation based on termino~ 
logical logic, linking content words with refer
(;nee objects and dependencies with conceptual 
roles. 
5 The
German Clause 
"IYaditionally, the German main clause is de
scribed using three topological fields; the ini
tim and middle fields are separated by the fi
nite (auxiliary) verb, and the middle and the 
SThe modality D~4 can be viewed as an abbreviation 
of <>~ Kl>a , composed of a Inapping fi'mn a word to its ith 
order domain and fi'om that domain to all its ehmmnts. 
177 
Syntax (valid formulae) 
c6 £v, VcEC T, 
aE £~),Va6A T, 
(d)¢ E £v, Vd e ~9,¢ E z:;v T, 
<. E £v, T, 
<~ E £v, V5 C iD T, 
?a E £~, V6 C /9 T, 
o~4single E £v, Vi E ~V 
o~filled E £z~, Vi E ~V 
E\]~a E £v, ViEW, aeA 
¢ A ~ E £7), Vq~,t/) E £/9 
~0 E £v, V¢ E £v 
Semantics (satisfaction relation) 
w~c w~a 
w ~ (d> ¢ 
w I= ta 
:~, c = Vc(w) 
:** a c V.4(w) 
:~=~ 3w' C W : wRdw' A T,w' ~ ¢ 
:** 3m c M :(V~(w) = (... m...> 
AW' C ,,,: (,,, = ~' v w ~ w')) 
:¢~ -,3w', w", w"' 6 W : places(w', w) 
Aplaces(w', w") A w'"H,~w A w'" -< w 
:¢:~ 3w',w" E I/V : wRz~wA 
places(w", w) A w"Rjw' o 
w'E ~}i (V34 (w))A ~ 
w' -~w" : (w"Rvw'A~ < 1 
~," e ~(~%(w))) J 
• /(v~(,,)) I> 1 
:~ Vw' e ~I,~(V,~ (w)) :r, w' p a 
:~T,w DOandT, w ~b 
:¢* not T,w~¢ 
T, w ~ o~4single :<0 
T, w ~ @~4filled :¢~ 
T,w ~ ~ba 
T,w D O Av) 
T, w p -~¢ 
Figure 3: Syntax and Semantics of £v Formulae 
Vfin ~ o~(single A filled) A ~initial \[I\] 
A O L (middle A norel) \[2\] 
A o~single A ~ (final A norel) \[3\] 
A V2 ~=~ (middleA <. ADLnorel ) \[4\] 
A VEnd ¢$ (middleA >,) \[5\] 
AVI <=~ (initial A norel) \[6\] 
Figure 4: Domain Description of finite verbs 
"hat" A Vfin \[7\] 
A <subj} ("Junge" A ~0) \[8\] 
A(vpart> ("gesehen" A 1"0 \[9\] 
A-~final A >{subj,obj} \[10\] 
A (obj} ("Mann" A ?{vpart})) \[11\] 
Figure 5: Hierachicat Structure 
final fields by infinite verb parts such as sepa
rable prefixes or participles. We will generalize 
this field structure to verb-initial and verb-final 
clauses as well, without going into the linguistic 
motivation due to space limits. 
The formula in Fig.4 states that all finite 
verbs (word class Vfin C C) define three order 
domains, of which the first requires exactly one 
element with the feature init ial \[1\], the second 
allows an unspecified nmnber of elements with 
features middle and norel 12\], and the third al
lows at most one element with featm'es final 
and norel I3\]. The features initial, middle, 
and final E A serve to restrict placement of 
certain phrases in specific fields; e.g., no reflex
ive pronouns can appear in the final field. The 
norel 6 .4 featm'e controls placement of a rela
tive NP or PP, which may appear in the initial 
field only in verb-final clauses. The order types 
are defined as follows: In a verb-second clause 
(feature V2), the verb is placed at the beginning 
(<.) of the middle field (middle), and the el
ement of the initial field cannot be a relative 
phrase (@~4norel in \[41). In a verb-final clause 
(VEnd), the verb is placed at the end (>,) of" the 
middle field, with no restrictions for the initial 
field (relative clauses and non-relative verb-final 
clauses are subordinated to the noun and con
junction, resp.) \[5\]. in a verb-initial clause (Vl), 
the verb occupies the initial field \[6\]. 
The fornmla in Fig.5 encodes the hierarchical 
structure from Fig. 1 and contains lexical restric
tions on placement and extraction (the surface is 
used to identify the word). Given this, the order 
type of"h, at" is determined as follows: The par.
ticiple may not be extraposed (-ffinal in \[101; 
a restriction from the lexical entry of "hat"), it 
S must follow "hat" in d2. 2hu,, the verb can
not be of order type VEnd, which would require 
it to be the last element in its domain (>, in 
\[51). "Mann" is not adjacent to "gesehen", but 
may be extracted across the dependency vpart 
(?{vpart} in 111\]), allowing its insertion into 
a domain defined by "hat". It cannot precede 
"hat" in d2, because "hat" must either begin d2 
(clue to <, in \[4\]) or itself go into d~. But d~ al
lows only one phrase (single), leaving only the 
domain structure from Fig.2, and thus the order 
type V2 for "hat". 
178 
6 Comparison
to PSG Approaches 
One feature of word order domains is that they 
factor ordering alternatives fl'om the syntactic 
tree, much like feature annotations do for mor
phological alt(,rnatives. Other lexicalized gram
mars collapse syntactic and ordering informa
tion an(t are fbI'ced to represent ordering alterna
tives by lexical ambiguity, most notable L-TAG 
(Schabes et al., 1988) and some versions of CG 
(Hepple, 1994). This is not necessary in our 
approach, which drastically reduces the search 
space for parsing. 
This property is shared by the proposal of 
Reape (19931) to associate ItPSG signs with se
(luelices of const;itueilts, also called word or
d(;r dolnains. Surface ordering is determined 
by the s('quen(:c of constituents associated with 
the root node. The order domain of a mother 
node is the sequence :nlion of the. order domains 
of the. daughter nodes, which means that the 
relative ord(~r of elements in an order domain 
is retained, but material flom several domains 
may be iilterleaved, resulting in discontinuities. 
Whether an order domain allows interleaving 
with other domains is a parameter of the con,~;tituent. This approach is v(::'y similar to ours 
in that order (hmiains separate word order fi'om 
the syntactic tree, but; there is one important 
diff(:ren(:e: Word order domains in HPSC (lo not 
completely free the hierarchical structure fl'oin 
ordering considerations, because discontin, fity is 
specified per phrase,, not per modifier. For ex
anlple, two projections are required for an NP, 
the lower one for the continuous material (de-
terminer, adjective, noun, genitival and prepo
sitional attributes) and the higher one for the 
possibly discontinuous relative elaus(,,. This de,
pem\]ence of hierm'chic~fi structure on ordering is 
absent fl'om our prot)osal. 
We may also compare our al)proach with the 
l)rojection architecture of LFG (Kaplan & Bres
nan, 1982; Kaplan, 1995). Th(;re is a close sim
ilarit, y of the LFG projections (c-structure and 
f-structure) to the dimensions used here (order 
domain structure and dependency tree, respec
tively). C-structure and order doinains repre
se:rl; surface ordering, whereas fstructure and 
delmndency tree show the subcategorization or 
yah;nee requirements. What is more, these pro
jections or dimensions are linked in both ae
~:ounts l)y an eh~unent-wise mapt)ing. The (lit
ferenee between tile two architectures lies ill tile 
linkage of the projections or dimensions: LFG 
maps f-structure off c-structure. In contrast, 
the dependency relation is taken to be prilni
tive here, and ordering restrictions are taken to 
be indicators or consequences of dependency re
lations (see also Br6ker (1998b, 1998a)). 
7 Conclusion

We have presented an approach to word or
der %r DG which combines traditional notions 
(semantically motivated dependencies, topolog
ical fields) with contemporary techniques (log
ical description language, model-theoretic se
mantics). Word order domains are sets of par
tially ordered words associated with words. A 
word is contained in an order domain of its head, 
or may float into an order domain of a transi
tive head, resulting in a discontinuous depen
dency tree while retaining a projective order 
domain structure. Restrictions on the floating 
are expressed in a lexicalized fashion in terms of 
dependency relations. An important benefit is 
that the proposal is lexicalized without reverting 
to lexical ambiguity to represent order variation, 
thus 1)rofiting even more from the efficiency con
siderations discussed by Schabes et 31. (1988). 
It is not yet (:lear what the generatiw; capac
ity of such lexicalized discontilmous \])Gs is, but 
at least some index languages (such as a'~b~c '~) 
can be characterized. Neuhaus & Br6ker (1997) 
have shown that recognition and parsing of such 
grammars is ArT'-complete. A parser operating 
()n the model structures is described in (Hahn 
et al., 1997). 

References 

Beck(r, T., A. Joshi & O. Rainbow (1991). Longl)istance s(:ralnbling and tree-adjoining grammar. in Prec. 5th Co@ of the European (\]haptcr of the ACL, pp. 21 -26. 

Bhatt, C. (1990). Dic syntaktische Struktur dcr Nominalphrase im De~ttschcn. Studien zur deutschen Grammatik 38. Tiibingen: Nan'. Blackburn, P. (1994). Structures, Languages and Translations: The Structural Approach to Feature Logic. In 
C. Rupp, M. Rosner ~ R. Johnson (Eds.), Constraints, Language and Computation, Pt). 1 27. I,ondon: Academic Press. 

Br6ker, N. (1997). Eine Dcpendenzgrammatik z?tr Kopplung heat(regent( Wissenssystemc auf modallogischcr Basis. Dissertation, l)eutsches Seminar, Uniwu'sit/it Freilmrg. 179 

Br5ker, N. (1998a). How to define a context-free backbone for DGs: An experiment in grammar conversion. In Proe. of the COLINGACL '98 workshop "Processing of Dependency-based Grammars". Montreal/CAN, Aug 15, 1998. 

BrSker, N. (1998b). A Projection Architecture for Dependency Grammar and How it Compares to LFG. In Proc. 1998 Int'l Lcxical-Functional Grammar Conference. (accepted as alternate paper) Brisbane/AUS: Jun 30-Jul 2, 1998. 

Eisner, J. (1997). Bilexical Grammars and a Cubic-Time Probabilistic Parser. In Proc. of Int'l Workshop on Parsing Technologies, pp. 54-65. Boston/MA: MIT. 

Gaifman, H. (1965). Dependency Systems and Phrase Structure Systems. Information and Control, 8:304-337. 

Haegeman, L. (1994). Intwduction to Government and Binding. Oxford/UK: Basil Blackwell. 

Hahn, U., P. Neuhaus ~5 N. BrSker (1997). Message-Passing Protocols for Real-World Parsing An Object-Oriented Model and its Preliminary Evaluation. In Proc. Int'l Workshop on Parsing Technology, pp. 101--112. Boston/MA: MIT, Sep 17-21, 1997. 

Hellwig, P. (1986). Dependency Unification Grammar. In Proc. 11th Int'l Co~¢ on Computational Linguistics, pp. 195-198. 

Hepple, M. (1994). Discontinuity and the Lambek Calculus. In Proc. 15th Int'l Conf. on Computational Linguistics, pp. 1235-1239. Kyoto/JP. 

Hudson, R. (1990). English Word Grammar. Oxford/UK: Basil Blackwell. 

Hudson, R. (1993). Recent developments in dependency theory. In J. Jacobs, A. v. Stechow, W. Sternefeld &: T. Vennemann (Eds.), Syntax. Ein internationales Handbuch zeitgenSssisciter Forschung, pp. 329-338. Berlin: Walter de Gruyter. 

Kaplan, R. (1995). The formal architecture of Lexical-Functional Grammar. In M. Dalrymple, R. Kaplan, J. I. Maxwell ~ A. Zaenen (Eds.), Formal Issues in Lexical-Funetional Grammar, pp. 7-27. Stanford University. 

Kaplan, R. ~ J. Bresnan (1982). Lexical-Functional Grammar: A Formal System for Grammatical Representation. In J. Bresnan 8z R. Kaplan (Eds.), The Mental Representation of Grammatical Relations, pp. 173 281. Cambridge, MA: MIT Press. 

Kruijff, G.-J. v. (1997). A Basic Dependency-Based Logical Grammar. Draft Manuscript. Prague: Charles University. 

Maruyama, H. (1990). Structural Disambiguation with Constraint Propagation. In Proc. 28th Annual Meeting of the ACL, pp. 31 38. Pittsburgh/PA. 

Matthews, P. (1981). Syntax. Cambridge Text-books in Linguistics, Cambridge/UK: Cambridge Univ. Press. McCord, M. (1990). Slot Grammar: A System for Simpler Construction of Practical Natural Language Grammars. In R. Studer (Ed.), Natura Language and Logic, pp. 118-145. Berlin, Heidelberg: Springer. 

Melc'hk, I. (1988). Dependency Syntax: Theory and Practice. Albany/NY: State Univ. Press of New York. 

Melc'hk, I. ~z N. Pertsov (1987). Surface Syntax of English: A Formal Model within the MTT Framework. Philadelphia/PA: John Benjamins. 

Neuhaus, P. ~ N. Br6ker (1997). The Complexity of Recognition of Linguistically Adequate Dependency Grammars. In Proe. 35th Annual Meeting of the A CL and 8th Conf. of the EA CL, pp. 337-343. Madrid, July 7-12, 1997. 

Reape, M. (1993). A Formal Theory of Word Order: A Case Study in West Germanic. Doctoral Dissertation. Univ. of Edinburg. 

Schabes, Y., A. Abeille ~ A. Joshi (1988). Parsing Strategies with 'Lexicalized' Grammars: Application to TAGs. In Proc. 12th Int'l Co~¢ on Computational Linguistics, pp. 578-583. 

Sgall, P., E. Hajicova 8z J. Panevova (1986). The Meaning of the Sentence in its Semantic and Pragmatic Aspects. Dordrecht/NL: D.Reidel. 

TesniOre, L. (1959). Elemdnts de syntaxe strueturale. Paris: Klincksiek. 180 

