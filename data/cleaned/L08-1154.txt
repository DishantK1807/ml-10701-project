<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>Michaela Atterer</author>
<author>Hinrich Schutze</author>
</authors>
<title>The effect of corpus size in combining supervised and unsupervised training for disambiguation</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions</booktitle>
<pages>25--32</pages>
<location>Sydney, Australia</location>
<contexts>
<context> and Grishman, 2006) show that enlarging the size of training data doesn’t always yield the best results, and they stress the need of carefully selecting appropriate data to bootstrap a name tagger; (Atterer and Schutze, 2006), in a study about disambiguating prepositional phrase and relative clause attachment, also argue that the size of the unannotated corpus had little effect on the performance not only due to the nois</context>
</contexts>
<marker>Atterer, Schutze, 2006</marker>
<rawString>Michaela Atterer and Hinrich Schutze. 2006. The effect of corpus size in combining supervised and unsupervised training for disambiguation. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 25–32, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Harald Baayen</author>
</authors>
<title>Word Frequency Distributions</title>
<date>2001</date>
<volume>18</volume>
<publisher>Technology. Springer</publisher>
<contexts>
<context>ogeneity of each corpus: for instance, if the similarity between the two corpora is small but their homogeneity is high, then one may conclude the two corpora belong to different language varieties. (Baayen, 2001) also advocates a similar position stating that to understand the importance of an intertextual difference one should account for the intratextual variability of the text characteristic being analyze</context>
</contexts>
<marker>Baayen, 2001</marker>
<rawString>R. Harald Baayen. 2001. Word Frequency Distributions, volume 18 of Text, Speech and Language Technology. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nuno Cardoso</author>
<author>Diana Santos</author>
</authors>
<title>Directivas para a identificac¸˜ao e classificac¸˜ao semˆantica na colecc¸˜ao dourada do harem</title>
<date>2007</date>
<editor>In Diana Santos and Nuno Cardoso, editors, HAREM, a</editor>
<publisher>Linguateca</publisher>
<contexts>
<context>zing the task our name tagger was developed for, and the data used in our experiments. 3.1. Task definition The first evaluation for named entity recognition in Portuguese, HAREM, took place in 2004 (Cardoso and Santos, 2007). We adopted the HAREM NE annotation scheme, but simplified the classification task to approximate the MUC named entity task (Grishman and Sundheim, 1995): (i) we are only interested in proper names </context>
</contexts>
<marker>Cardoso, Santos, 2007</marker>
<rawString>Nuno Cardoso and Diana Santos. 2007. Directivas para a identificac¸˜ao e classificac¸˜ao semˆantica na colecc¸˜ao dourada do harem. In Diana Santos and Nuno Cardoso, editors, HAREM, a primeira avaliac¸˜ao conjunta de sistemas de reconhecimento de entidades mencionadas para portuguˆes: Documentac¸˜ao e actas do encontro. Linguateca.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
<author>Robert L Mercer</author>
</authors>
<title>Introduction to the special issue on computational linguistics using large corpora. Computational Linguistics</title>
<date>1993</date>
<pages>24</pages>
<contexts>
<context>orpora to automatically update gazetteers and (Fairon and Courtois, 2000) use online newspapers to enlarge dictionaries of common words. This option follows the suggestion “more data is better data” (Church and Mercer, 1993), focusing on the idea of collecting more data, which indeed enlarge the previous resources, but without a concern for selecting relevant data that would increase even more the resources or would pro</context>
</contexts>
<marker>Church, Mercer, 1993</marker>
<rawString>Kenneth W Church and Robert L Mercer. 1993. Introduction to the special issue on computational linguistics using large corpora. Computational Linguistics, 19(1):1– 24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Ward Church</author>
</authors>
<title>One term or two</title>
<date>1995</date>
<booktitle>In SIGIR ’95: Proceedings of the 18th annual international ACM SIGIR conference on Research and development in information retrieval</booktitle>
<pages>310--318</pages>
<publisher>ACM Press</publisher>
<location>New York, NY, USA</location>
<contexts>
<context>ered words to the latter. In this way, they were aiming at obtaining closer training and test samples, avoiding temporal bias (they had observed measurable differences over the period of one month). (Church, 1995) studied the correlation between word variants (singular/plural, adjective/adverb, lower case/upper case) by comparing the correlation estimates obtained in one year of the Associated Press corpus wi</context>
</contexts>
<marker>Church, 1995</marker>
<rawString>Kenneth Ward Church. 1995. One term or two? In SIGIR ’95: Proceedings of the 18th annual international ACM SIGIR conference on Research and development in information retrieval, pages 310–318, New York, NY, USA. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Yoram Singer</author>
</authors>
<title>Unsupervised models for named entity classification</title>
<date>1999</date>
<booktitle>In Proceedings of the Joint SIGDAT Conference on EMNLP</booktitle>
<contexts>
<context>ction we describe the system we implemented and its performance on each time frame. 5.1. Tagger description We adopted and modified the semi-supervised name tagger based on DL-cotraining proposed by (Collins and Singer, 1999) for two main reasons: 1. It is a simple semi-supervised method, requiring just a few labeled seeds; 2. It performs well when compared to supervised methods. Given that we have limited manually annot</context>
<context>ore analyzing the performance over time, by training and testing the system within different time frames, we evaluated our system in order to understand how well it performed within each time frame. (Collins and Singer, 1999) evaluated their tagger by measuring accuracy and clean accuracy1 on a sub-set of 1000 examples they manually labeled, and randomly selected from the 90000 examples they had identified, obtaining 83.</context>
</contexts>
<marker>Collins, Singer, 1999</marker>
<rawString>Michael Collins and Yoram Singer. 1999. Unsupervised models for named entity classification. In Proceedings of the Joint SIGDAT Conference on EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C´edrick Fairon</author>
<author>Blandine Courtois</author>
</authors>
<title>Les corpus dynamiques et glossanet. extension de la couverture lexicale des dictionnaires ´Electroniques anglais</title>
<date>2000</date>
<booktitle>In Actes des 5es Journ´ees Internationales d’Analyse Statistique des Donn´ees Textuelles (JADT 2000</booktitle>
<location>Lausanne</location>
<contexts>
<context>ion in an indirect way by recognizing that linguistic resources are never complete. For instance, (Stevenson and Gaizauskas, 2000) explore NE annotated corpora to automatically update gazetteers and (Fairon and Courtois, 2000) use online newspapers to enlarge dictionaries of common words. This option follows the suggestion “more data is better data” (Church and Mercer, 1993), focusing on the idea of collecting more data, </context>
</contexts>
<marker>Fairon, Courtois, 2000</marker>
<rawString>C´edrick Fairon and Blandine Courtois. 2000. Les corpus dynamiques et glossanet. extension de la couverture lexicale des dictionnaires ´Electroniques anglais. In Actes des 5es Journ´ees Internationales d’Analyse Statistique des Donn´ees Textuelles (JADT 2000), Lausanne.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Gale</author>
<author>Kenneth W Church</author>
</authors>
<title>What’s wrong with adding one</title>
<date>1994</date>
<booktitle>Corpus-Based Research into Languge: In honour of Jan Aarts</booktitle>
<pages>189--200</pages>
<editor>In N. Oostdijk and P. de Haan, editors</editor>
<location>Rodolpi, Amsterdam</location>
<contexts>
<context>tated corpus, but also because the corpora were from distinct sources and time periods. The idea of having similar temporal data for training and testing NLP systems is also shared by other authors. (Gale and Church, 1994) when comparing different probability estimators for English bigrams, split a one year corpus into training and test by assigning each bigram starting at an even-numbered word to the former, and thos</context>
</contexts>
<marker>Gale, Church, 1994</marker>
<rawString>William A. Gale and Kenneth W. Church. 1994. What’s wrong with adding one? In N. Oostdijk and P. de Haan, editors, Corpus-Based Research into Languge: In honour of Jan Aarts, pages 189–200. Rodolpi, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Grishman</author>
<author>Beth Sundheim</author>
</authors>
<title>Design of the MUC-6 Evaluation</title>
<date>1995</date>
<booktitle>In Sixth Message Understanding Conference (MUC-6): Proceedings of a Conference held in Columbia</booktitle>
<publisher>Morgan Kaufmann</publisher>
<location>Maryland</location>
<contexts>
<context>nition in Portuguese, HAREM, took place in 2004 (Cardoso and Santos, 2007). We adopted the HAREM NE annotation scheme, but simplified the classification task to approximate the MUC named entity task (Grishman and Sundheim, 1995): (i) we are only interested in proper names of people, organizations and locations; (ii) assignment of type and morphological attributes is not considered; (iii) the classification gives preference </context>
</contexts>
<marker>Grishman, Sundheim, 1995</marker>
<rawString>Ralph Grishman and Beth Sundheim. 1995. Design of the MUC-6 Evaluation. In Sixth Message Understanding Conference (MUC-6): Proceedings of a Conference held in Columbia, Maryland, November 6-8, 1995, Los Altos, Ca. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
</authors>
<title>Data selection in semi-supervised learning for name tagging</title>
<date>2006</date>
<booktitle>In Proceedings of the Workshop on Information Extraction Beyond The Document</booktitle>
<pages>48--55</pages>
<location>Sydney, Australia</location>
<contexts>
<context>ld increase even more the resources or would produce tailored resources for analysing a specific corpus. Some authors, however, show that simply adding more data in the training stage is not enough: (Ji and Grishman, 2006) show that enlarging the size of training data doesn’t always yield the best results, and they stress the need of carefully selecting appropriate data to bootstrap a name tagger; (Atterer and Schutze</context>
</contexts>
<marker>Ji, Grishman, 2006</marker>
<rawString>Heng Ji and Ralph Grishman. 2006. Data selection in semi-supervised learning for name tagging. In Proceedings of the Workshop on Information Extraction Beyond The Document, pages 48–55, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janne Bondi Johannessen</author>
<author>Kristin Hagen</author>
</authors>
<title>Asne Haaland, Andra Bjork Jansdottir, Anders Naklestad, Dimitris Kokkinakis, Paul Meurer, Eckhard Bick, and Dorte Haltrup</title>
<date>2004</date>
<marker>Johannessen, Hagen, 2004</marker>
<rawString>Janne Bondi Johannessen, Kristin Hagen, Asne Haaland, Andra Bjork Jansdottir, Anders Naklestad, Dimitris Kokkinakis, Paul Meurer, Eckhard Bick, and Dorte Haltrup. 2004. Named entity recognition for the mainland scandinavian languages. Literary and Linguistic Computing, 20(1):91–102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Kilgarriff</author>
</authors>
<title>Comparing corpora</title>
<date>2001</date>
<journal>International Journal of Corpus Linguistics</journal>
<volume>1</volume>
<contexts>
<context>escribing the corpus similarity approach and then the name list overlap metrics. 4.1. Corpus homogeneity/similarity In order to measure corpus similarity over time, we adopted the method proposed by (Kilgarriff, 2001) to compare language varieties. Given two corpora A and B with the same number of words, the author measures the similarity between A and B, similarity(A,B), by applying the following algorithm: • Sp</context>
</contexts>
<marker>Kilgarriff, 2001</marker>
<rawString>Adam Kilgarriff. 2001. Comparing corpora. International Journal of Corpus Linguistics, 1(6):1–37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Nadeau</author>
<author>Sekine</author>
<author>Satoshi</author>
</authors>
<title>A survey of named entity recognition and classification</title>
<date>2007</date>
<journal>Linguisticae Investigationes</journal>
<volume>30</volume>
<contexts>
<context>arity and names shared correlate with the tagger F-measure. These results show that named entity recognition systems may become obsolete in a short period of time. 1. Introduction A recent survey by (Nadeau et al., 2007), covering the last 15 years of research in named entity recognition (NER), shows that the field has been growing significantly, in terms of the number of languages processed, textual genres and doma</context>
</contexts>
<marker>Nadeau, Sekine, Satoshi, 2007</marker>
<rawString>Nadeau, David, Sekine, and Satoshi. 2007. A survey of named entity recognition and classification. Linguisticae Investigationes, 30(1):3–26, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paulo Rocha</author>
<author>Diana Santos</author>
</authors>
<title>Cetemp´ublico: Um corpus de grandes dimens˜oes de linguagem jornal´ıstica portuguesa</title>
<date>2000</date>
<booktitle>In Maria das Grac¸as Volpe Nunes, editor, Actas do V Encontro para o processamento computacional da l´ıngua portuguesa escrita e falada PROPOR 2000</booktitle>
<pages>131--140</pages>
<location>Atibaia, S˜ao Paulo, Brasil</location>
<contexts>
<context> For a thorough comparison between MUC and HAREM tasks cf. (Seco, 2007). 3.2. Data description We conducted the experiments on samples of the Politics articles of the Portuguese corpus CETEMP´ublico (Rocha and Santos, 2000). The corpus has 180 million words and spans 8 years, from 1991 to 1998, divided into semesters. The original newspaper articles were fragmented by the corpus builders into extracts (typically 2 para</context>
</contexts>
<marker>Rocha, Santos, 2000</marker>
<rawString>Paulo Rocha and Diana Santos. 2000. Cetemp´ublico: Um corpus de grandes dimens˜oes de linguagem jornal´ıstica portuguesa. In Maria das Grac¸as Volpe Nunes, editor, Actas do V Encontro para o processamento computacional da l´ıngua portuguesa escrita e falada PROPOR 2000, pages 131–140, Atibaia, S˜ao Paulo, Brasil.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana Santos</author>
<author>Nuno Cardoso</author>
<author>Nuno Seco</author>
</authors>
<title>Avaliac¸˜ao no harem: M´etodos e medidas</title>
<date>2007</date>
<editor>In Diana Santos and Nuno Cardoso, editors, HAREM, a</editor>
<publisher>Linguateca</publisher>
<contexts>
<context>take into account examples that were incorrectly identified, i.e., which do not belong to one of the categories people, organization or location 2We used the scoring programs of the HAREM evaluation (Santos et al., 2007). 0 1 2 3 4 5 6 7 0.79 0.80 0.81 0.82 0.83 0.84 0.85 Time gap (year) F−measure (%) (a) F-measure for (Sk=91...98, Uk=91...98, Tj=91...98) 0 1 2 3 4 5 6 7 1 2 3 4 5 6 Time gap (year) Dissimilarity (= </context>
</contexts>
<marker>Santos, Cardoso, Seco, 2007</marker>
<rawString>Diana Santos, Nuno Cardoso, and Nuno Seco. 2007. Avaliac¸˜ao no harem: M´etodos e medidas. In Diana Santos and Nuno Cardoso, editors, HAREM, a primeira avaliac¸˜ao conjunta de sistemas de reconhecimento de entidades mencionadas para portuguˆes: Documentac¸˜ao e actas do encontro. Linguateca.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nuno Seco</author>
</authors>
<title>MUC vs HAREM: a contrastive perspective</title>
<date>2007</date>
<editor>In Diana Santos and Nuno Cardoso, editors, HAREM, a</editor>
<publisher>Linguateca</publisher>
<contexts>
<context>ed in Europe Portugal voted against the proposal In HAREM, these references should be classified as location and organization, respectively. For a thorough comparison between MUC and HAREM tasks cf. (Seco, 2007). 3.2. Data description We conducted the experiments on samples of the Politics articles of the Portuguese corpus CETEMP´ublico (Rocha and Santos, 2000). The corpus has 180 million words and spans 8 </context>
</contexts>
<marker>Seco, 2007</marker>
<rawString>Nuno Seco. 2007. MUC vs HAREM: a contrastive perspective. In Diana Santos and Nuno Cardoso, editors, HAREM, a primeira avaliac¸˜ao conjunta de sistemas de reconhecimento de entidades mencionadas para portuguˆes: Documentac¸˜ao e actas do encontro. Linguateca.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Max Silberztein</author>
</authors>
<title>Nooj: A cooperative, objectoriented architecture for nlp</title>
<date>2004</date>
<booktitle>In INTEX pour la Linguistique et le traitement automatique des langues, Cahiers de la MSH Ledoux. Presses Universitaires de FrancheComt´e</booktitle>
<contexts>
<context>the same sequence of operations as for the training set: POS tagging, parsing, NE identification, and NE feature extraction. In our implementation, we modified the identification stage. We used NooJ (Silberztein, 2004) to do local parsing and extract the NEs occurring in the following contexts: head of noun phrase, complement of noun phrase, left or right context of a verb, coordination, and age context; in the cl</context>
</contexts>
<marker>Silberztein, 2004</marker>
<rawString>Max Silberztein. 2004. Nooj: A cooperative, objectoriented architecture for nlp. In INTEX pour la Linguistique et le traitement automatique des langues, Cahiers de la MSH Ledoux. Presses Universitaires de FrancheComt´e.</rawString>
</citation>
</citationList>
</algorithm>

