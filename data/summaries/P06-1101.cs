Additionally, a wide variety of relationship-specific classifiers have been proposed, including pattern-based classifiers for hyponyms (Hearst, 1992), meronyms (Girju, 2003), synonyms (Lin et al., 2003), a variety of verb relations (Chklovski and Pantel, 2004), and general purpose analogy relations (Turney et al., 2003).
C92-2082 W04-3205
For the direct measure of fine-grained precision, we simply ask for each link H(X,Y) added by the system, is X a Y ? In addition to the fine-grained precision, we give a coarse-grained evaluation, inspired by the idea of supersense-tagging in (Ciaramita and Johnson, 2003).
W03-1022
Many algorithms with the potential for automatically extending lexical resources have been proposed, including work in lexical acquisition (Riloff and Shepherd, 1997; Roark and Charniak, 1998) and in discovering instances, named entities, and alternate glosses (Etzioni et al., 2005; Pasc¸a, 2005).
P98-2182 W97-0313
This evaluation task 806 1 Tops 8 communication 15 object 22 relation 2 act 9 event 16 person 23 shape 3 animal 10 feeling 17 phenomenon 24 state 4 artifact 11 food 18 plant 25 substance 5 attribute 12 group 19 possession 26 time 6 body 13 location 20 process 7 cognition 14 motive 21 quantity Table 1: The 26 WordNet supersenses is similar to a fine-grained Named Entity Recognition (Fleischman and Hovy, 2002) task with 26 categories; for example, if our algorithm mistakenly inserts a novel non-capital city under the hyponym state capital, it will inherit the correct supersense location.
C02-1130
Our classifier for (m,n)-cousins is derived from the algorithm and corpus given in (Ravichandran et al., 2005).
P05-1077
In our experiments we set λ = 0.95. 3.2 (m,n)-cousin Classification The classifier for learning coordinate terms relies on the notion of distributional similarity, i.e., the idea that two words with similar meanings will be used in similar contexts (Hindle, 1990).
P90-1034
