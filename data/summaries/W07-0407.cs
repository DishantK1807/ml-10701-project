large margin training For parameter optimization, we have used an online large margin algorithm called MIRA (McDonald et al., 2005) (Crammer and Singer, 2003).
H05-1066
In the past, popular approaches for doing word alignment have largely been generative (Och and Ney, 2003; Vogel et al., 1996).
C96-2141 J03-1002
(Blunsom and Cohn, 2006) do word alignment by combining features using conditional random fields.
P06-1009
(Taskar et al., 2005) cast the problem of alignment as a maximum weight bipartite matching problem, where nodes correspond to the words in the two sentences.
H05-1010
LLR and CLP are the word association statistics used in Mooreâ€™s work (Moore, 2005).
H05-1011
Figure 1: An example of an alignment between an English and a Hindi sentence To learn the weights associated with the parameters used in our model, we have used a learning framework called MIRA (The Margin Infused Relaxed Algorithm) (McDonald et al., 2005; Crammer and Singer, 2003).
H05-1066
(Fraser and Marcu, 2006) have proposed an algorithm for doing word alignment which applies a discriminative step at every iteration of the traditional Expectation-Maximization algorithm used in IBM models.
P06-1097
As the recall of the alignment links of the intersection is very low for this dataset, further refinements of the alignments as suggested by (Och and Ney, 2003) were not performed.
J03-1002
Moore. 2005.
H05-1011
(Lacoste-Julien et al., 2006) extend the above approach to include features for fertility and first-order correlation between alignment links of consecutive words in the source sentence.
N06-1015
A variation of this feature was used by (Moore, 2005) in his paper.
H05-1011
Dice Coefficient of the source word and the target word (Taskar et al., 2005).
H05-1010
(Moore, 2005) has proposed an approach which does not impose any restrictions on the form of model features.
H05-1011
