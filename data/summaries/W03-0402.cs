We use the same data set as described in (Collins, 2000; Collins and Duffy, 2002).
P02-1034
In (Collins and Duffy, 2002), the Voted Perceptron algorithm was used to in parse reranking.
P02-1034
The experimental result is shown in Table 2 The results of our SVM system match the results of the Voted Perceptron algorithm in (Collins and Duffy, 2002), although only 5 slices, amounting to less than one fourth of the whole training dataset, have been used.
P02-1034
In (Collins and Duffy, 2002), for each offending parse, the parameter vector updating function is in the form of w = w + h(xi1) − h(xij), where w is the parameter vector and h returns the feature vector of a parse.
P02-1034
In (Kudo and Matsumoto, 2001), SVMs have been employed in the NP chunking task, a typical labeling problem.
N01-1025
CH00 = (Charniak, 2000).
A00-2018
Our next experiment is on the tree kernel as it is used in (Collins and Duffy, 2002).
P02-1034
In (Collins and Duffy, 2002), the tree kernel Tr is used to count the total number of common sub-trees of two parse trees.
P02-1034
In (Collins and Duffy, 2002), the use of Voted Perceptron (VP) (Freund and Schapire, 1999) for the parse reranking problem has been described.
P02-1034
In recent years, reranking techniques have been successfully applied to the so-called history-based models (Black et al., 1993), especially to parsing (Collins, 2000; Collins and Duffy, 2002).
P02-1034 P93-1005
CD02 = (Collins and Duffy, 2002) ≤100 Words (2416 sentences) Model LR LP CBs CO99 88.1% 88.3% 1.06 CD02 88.6% 88.9% 0.99 SVM(tree) 88.7% 88.8% 0.99 trol the weight of log-likelihood given by the parser.
P02-1034
The performance of our system matches the results of (Charniak, 2000), but is a little lower than the results of the Boosting system in (Collins, 2000), except that the percentage of sentences with no crossing brackets is 1% higher than that of (Collins, 2000).
A00-2018
