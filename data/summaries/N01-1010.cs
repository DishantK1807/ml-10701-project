We report results of comparing our lexicon with the WordNet cousins as well as the inter-annotator disagreement observed between two semantically annotated corpora: WordNet Semcor (Landes et al., 1998) and DSO (Ng and Lee, 1996).
P96-1006
6 Evaluation: Inter-annotator Disagreement To test if the sense partitions in our lexicon constitute an appropriate (or useful) level of granularity, we applied it to the inter-annotator disagreement observed in two semantically annotated corpora: WordNet Semcor (Landes et al., 1998) and DSO (Ng and Lee, 1996).
P96-1006
For instance, the number of sentences in the intersected corpus reported in (Ng et al., 1999) is 30,315.
W99-0502
In this section, we give a brief summary of this tree-cut technique using examples from (Li and Abe, 1998)'s original work.
J98-2002
We speculate the discrepancy might be from the version of WordNet senses used in DSO, whichwas slightly dierent from the standard delivery version (as noted in (Ng et al., 1999)).
W99-0502
It was originally proposed in (Li and Abe, 1998), and then adopted in our previous method for automatically extracting systematic polysemy(Tomuro, 2000).
J98-2002 W00-0104
This issue emerged as a prominent problem after previous studies and exercises in Word Sense Disambiguation (WSD) reported that, when ne-grained sense de nitions such as those in WordNet (Miller, 1990) were used, entries became very similar and indistinguishable to human annotators, thereby causing disagreementon correct tags (Kilgarri, 1998b;; Veronis, 1998;; Ng et al., 1999).
W99-0502
The results are quite promising: our extraction method discovered 89% of the WordNet cousins, and the sense partitions in our lexicon yielded better  values (Carletta, 1996) than arbitrary sense groupings on the agreement data.
J96-2004
As a note, our lexicon is similar to CORELEX (Buitelaar, 1998) (or CORELEX-II presented in (Buitelaar, 2000)), in that both lexicons share the same motivation.
W00-0103
low agreement ratio is also re ected in a measure called the  statistic (Carletta, 1996;; Bruce and Wiebe, 1998;; Ng et al., 1999).
J96-2004 P99-1032 W99-0502
Then we measured the possible increase in  by our lexicon by taking the dierence between the paired  values for all words (i.e.,  w by our sense partition  w by random partition, for a word w), and performed a signi cance 12 (Ng et al.1999)'s result is slightly higher:  = :317.
W99-0502
The agreementbetween those corpora is previously studied in (Ng et al., 1999).
W99-0502
MDL Principle To select the best tree-cut model, (Li and Abe, 1998) uses the Minimal Description Length (MDL).
J98-2002
In our previous work (Tomuro, 2000), we applied this method to a small subset of WordNet nouns and showed potential applicability.
W00-0104
justi cation and detailed explanation of these formulas, see (Li and Abe, 1998).
J98-2002
The lexicon is derived by a fully automatic extraction method which utilizes a clustering technique called tree-cut (Li and Abe, 1998).
J98-2002
11 (Ng et al., 1999) reports a higher agreement of 57%.
W99-0502
More recently, (Gonzalo et al., 2000)alsodiscussespotential usefulnessof systematic polysemy for clustering word senses for IR.
W00-0802
Normally,   :8 is considered a good agreement (Carletta, 1996).
J96-2004
In (Li and Abe, 1998), the tree-cut technique was applied to the problem of acquiring general3 A leaf node is also a cluster whose cardinalityis1.
J98-2002
you 10 Note that the numbers reported in (Ng et al., 1999) are slightly more than the ones reported in this paper.
W99-0502
To searchthebest tree-cut for atree(i.e., the model which requires the minimum total description length), a greedy algorithm called Find-MDL described in (Li and Abe, 1998) is used to speed up the search.
J98-2002
Systematic Polysemy Using the tree-cut technique described above, our previous work (Tomuro, 2000) extracted systematic polysemyfromWordNet.
W00-0104
