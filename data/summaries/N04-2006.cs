Heine. 1998.
P98-1085
(Heine, 1998) takes a Japanese NP as input, and classifies it as either definite or indefinite.
P98-1085
Our baseline accuracy rate on DROP0, 80.1%, is close to the corresponding rate (80.8% for the “head+its partof-speech”feature) reported in (Minnen et al., 2000).
W00-0708
Accuracy Rate DROP0 DROP30 DROP70 TRAINGEN 87.7% 82.5% 76.4% TRAINGENa34a36a35a38a37a39a37 a32 a37 82.4% 79.5% 75.8% TRAINGENa27a29a28a31a30a33a32 80.1% 78.6% 76.9% Table 1: Accuracy rate in article generation a0 TRAINGEN a34a36a35a38a37a40a37 a32 a37 : This set uses the subset of our features that were also used in (Minnen et al., 2000).
W00-0708
Our best result, 87.7%, is an improvement over both (Minnen et al., 2000) and (Knight and Chander, 1994).
W00-0708
In fact, these features dominated the 10 heaviest weights in our training; they were not used in (Minnen et al., 2000).
W00-0708
These features were also used in (Knight and Chander, 1994) but not in (Minnen et al., 2000).
W00-0708
(Minnen et al., 2000) applies a memory-based learning approach to choose between a/an, the and null.
W00-0708
Our motivation for using the text of the Penn Treebank is to facilitate comparison between our article generation results and those reported in (Knight and Chander, 1994) and (Minnen et al., 2000), both of which read context features directly from the Penn Treebank.
W00-0708
