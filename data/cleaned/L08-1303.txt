<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>H M¨ogele</author>
<author>M Kaiser</author>
<author>F Schiel</author>
</authors>
<title>SmartWeb UMTS Speech Data Collection: The SmartWeb Handheld Corpus</title>
<date>2006</date>
<booktitle>Proc. of the LREC 2006</booktitle>
<location>Genova, Italy</location>
<marker>M¨ogele, Kaiser, Schiel, 2006</marker>
<rawString>H. M¨ogele, M. Kaiser, F. Schiel. 2006. SmartWeb UMTS Speech Data Collection: The SmartWeb Handheld Corpus. Proc. of the LREC 2006, Genova, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kaiser</author>
<author>H M¨ogele</author>
<author>F Schiel</author>
</authors>
<title>Bikers Accessing the Web: The SmartWeb Motorbike Corpus</title>
<date>2006</date>
<booktitle>Proc. of the LREC 2006</booktitle>
<location>Genova, Italy</location>
<marker>Kaiser, M¨ogele, Schiel, 2006</marker>
<rawString>M. Kaiser, H. M¨ogele, F. Schiel. 2006. Bikers Accessing the Web: The SmartWeb Motorbike Corpus. Proc. of the LREC 2006, Genova, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K J¨ansch Draxler</author>
</authors>
<title>SpeechRecorder – a Universal Platform Independent Multi-Channel Audio Recording Software</title>
<date>2004</date>
<booktitle>Proc. of the IV. International Conference on Language Resources and Evaluation</booktitle>
<location>Lisbon, Portugal</location>
<marker>Draxler, 2004</marker>
<rawString>Chr. Draxler, K. J¨ansch. 2004. SpeechRecorder – a Universal Platform Independent Multi-Channel Audio Recording Software. Proc. of the IV. International Conference on Language Resources and Evaluation, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kaiser Hacker</author>
<author>H M¨ogele</author>
<author>E N¨oth</author>
</authors>
<title>Taking into Account the User’s Focus of Attention with the Help of Audio-Visual Information: Towards less Artificial Human-Machine-Communication</title>
<date>2007</date>
<marker>Hacker, M¨ogele, N¨oth, 2007</marker>
<rawString>A. Batliner, Chr. Hacker, M. Kaiser, H. M¨ogele, E. N¨oth. 2007. Taking into Account the User’s Focus of Attention with the Help of Audio-Visual Information: Towards less Artificial Human-Machine-Communication.</rawString>
</citation>
<citation valid="true">
<authors>
<author>In Krahmer</author>
</authors>
<title>Emiel; Swerts, Marc; Vroomen, Jean (Eds</title>
<date>2007</date>
<booktitle>AVSP 2007 (International Conference on AuditoryVisual Speech Processing</booktitle>
<pages>51--56</pages>
<marker>Krahmer, 2007</marker>
<rawString>In: Krahmer, Emiel; Swerts, Marc; Vroomen, Jean (Eds.) AVSP 2007 (International Conference on AuditoryVisual Speech Processing 2007, 51-56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Batliner Hacker</author>
<author>E N¨oth</author>
</authors>
<title>Are You Looking at Me, are You Talking with Me – Multimodal Classification of the Focus of Attention. In</title>
<date>2006</date>
<booktitle>Text, Speech and Dialogue. 9th International Conference, TSD 2006</booktitle>
<pages>581--588</pages>
<location>Brno, Czech Republic, Springer Berlin Heidelberg</location>
<marker>Hacker, N¨oth, 2006</marker>
<rawString>Chr. Hacker, A. Batliner, E. N¨oth. 2006. Are You Looking at Me, are You Talking with Me – Multimodal Classification of the Focus of Attention. In: Sojka, P.; Kopecek, I.; Pala, K. (Eds.) Text, Speech and Dialogue. 9th International Conference, TSD 2006, Brno, Czech Republic, Springer Berlin Heidelberg, 581-588.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Schiel</author>
<author>S Burger</author>
<author>A Geumann</author>
<author>K Weilhammer</author>
</authors>
<title>The Partitur Formatat BAS</title>
<date>1998</date>
<booktitle>Proc. of the 1st Int. Conf</booktitle>
<contexts>
<context>uld be processed as valid queries adressing the system, while the third input as well as the second part of the forth would be ignored. Transcripts are also provided in the BAS Partitur Format (BPF) (Schiel et al., 1998) as well as an ATLAS compatible Annotation Graph (Bird et al., 2000). 6. Meta Data Extensive speaker information is stored in XML formatted speaker protocols for each recorded user: sex, age, handedn</context>
</contexts>
<marker>Schiel, Burger, Geumann, Weilhammer, 1998</marker>
<rawString>F. Schiel, S. Burger, A. Geumann, K. Weilhammer. 1998. The Partitur Formatat BAS. Proc. of the 1st Int. Conf.</rawString>
</citation>
<citation valid="true">
<date>1998</date>
<booktitle>on Language Resources and Evaluation</booktitle>
<pages>12951301</pages>
<location>Granada, Spain</location>
<marker>1998</marker>
<rawString>on Language Resources and Evaluation 1998, pp. 12951301, Granada, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Oppermann</author>
<author>F Schiel</author>
<author>S Steininger</author>
<author>N Beringer</author>
</authors>
<title>Off-Talk A Problem for Human-Machine-Interaction</title>
<date>2001</date>
<contexts>
<context> Finally, the percentage of other OffTalk (muttering to himself etc.) is with 3.1% of the OffTalk very low, probably caused by the (possibly embarrassing) presence of the companion. In other studies (Oppermann et al., 2001) where no third party was present this percentage was significantly higher. Table 2 summarizes all data types provided for each recording session. 8. Availability The SVC corpus will be made availabl</context>
</contexts>
<marker>Oppermann, Schiel, Steininger, Beringer, 2001</marker>
<rawString>D. Oppermann, F. Schiel, S. Steininger, N. Beringer. 2001. Off-Talk A Problem for Human-Machine-Interaction.</rawString>
</citation>
<citation valid="true">
<date>2001</date>
<booktitle>Proc. of the EUROSPEECH</booktitle>
<location>Scandinavia, Aalborg, Danmark</location>
<marker>2001</marker>
<rawString>Proc. of the EUROSPEECH 2001, Scandinavia, Aalborg, Danmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Day Bird</author>
<author>J Garofolo</author>
<author>J Henderson</author>
<author>Chr Laprun</author>
<author>M Libermann</author>
</authors>
<title>ATLAS: A flexible and extensible architecture for linguistic annotation</title>
<date>2000</date>
<booktitle>Proceedings of LREC</booktitle>
<contexts>
<context>d input as well as the second part of the forth would be ignored. Transcripts are also provided in the BAS Partitur Format (BPF) (Schiel et al., 1998) as well as an ATLAS compatible Annotation Graph (Bird et al., 2000). 6. Meta Data Extensive speaker information is stored in XML formatted speaker protocols for each recorded user: sex, age, handedness, profession, mother tongue, mother tongue of both parents, exper</context>
</contexts>
<marker>Bird, Garofolo, Henderson, Laprun, Libermann, 2000</marker>
<rawString>St. Bird, D. Day, J. Garofolo, J. Henderson, Chr. Laprun, M. Libermann. 2000. ATLAS: A flexible and extensible architecture for linguistic annotation. Proceedings of LREC 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wahlster</author>
</authors>
<title>Smartweb: Mobile applications of the semantic web</title>
<date>2004</date>
<note>http://smartweb.dfki.de/ Vortraege/SmartWeb-WahlsterKI-2004-LNAI.pdf</note>
<contexts>
<context>orpus of human — machine interactions. The aim of the SmartWeb project is to enable the user to access semantic Web services via mobile UMTS handheld devices by means of a multi-modal user interface (Wahlster, 2004). The SmartWeb speech data collection is carried out by the BAS (Bavarian Archive for Speech Signals) at the Phonetic Institute (IPS) of Munich University. In the course of this data collection three</context>
</contexts>
<marker>Wahlster, 2004</marker>
<rawString>W. Wahlster. 2004. Smartweb: Mobile applications of the semantic web. http://smartweb.dfki.de/ Vortraege/SmartWeb-WahlsterKI-2004-LNAI.pdf.</rawString>
</citation>
</citationList>
</algorithm>

