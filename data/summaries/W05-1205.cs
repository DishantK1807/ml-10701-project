Moreover, for reasons discussed by Wu (1997), ITGs possess an interesting intrinsic combinatorial property of permitting roughly up to four arguments of any frame to be transposed freely, but not more.
J97-3002
The Inversion Transduction Grammar or ITG formalism, which historically was developed in the context of translation and alignment, hypothesizes strong expressiveness restrictions that constrain paraphrases to vary word order only in certain allowable nested permutations of arguments (Wu, 1997).
J97-3002
In Bracketing ITGs, the grammar uses only a single, undifferentiated non-terminal (Wu, 1995).
P95-1033
With regard to translation rather than alignment accuracy, Zens et al.(2004) show that decoding under ITG constraints yields significantly lower word error rates and BLEU scores than the IBM constraints.
C04-1030
Wu (1997) also showed that ITGs can be equivalently be defined in two other ways.
J97-3002
In particular, for this study we employ the MSR Paraphrase Corpus (Quirk et al., 2004).
W04-3219
Zhang and Gildea (2004) find that unsupervised alignment using Bracketing ITGs produces significantly lower Chinese-English alignment error rates than a syntactically supervised tree-to-string model (Yamada and Knight, 2001).
C04-1060 P01-1067
c©2005 Association for Computational Linguistics Recognizing Paraphrases and Textual Entailment using Inversion Transduction Grammars Dekai Wu1 Human Language Technology Center HKUST Department of Computer Science University of Science and Technology, Clear Water Bay, Hong Kong dekai@cs.ust.hk Abstract We present first results using paraphrase as well as textual entailment data to test the language universal constraint posited by Wu’s (1995, 1997) Inversion Transduction Grammar (ITG) hypothesis.
J97-3002 P95-1033
The result in Wu (1997) implies that for the special case of Bracketing ITGs, the time complexity of the algorithm is ΘparenleftbigT3V 3parenrightbig where T and V are the lengths of the two sentences.
J97-3002
For example, Zens and Ney (2003) show that ITG constraints yield significantly better alignment coverage than the constraints used in IBM statistical machine translation models on both German-English (Verbmobil corpus) and French-English (Canadian Hansards corpus).
P03-1019
