<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>A Bigbee</author>
<author>D Loehr</author>
<author>L Harper</author>
</authors>
<title>Emerging Requirements for Multi-Modal Annotation and Analysis Tools. In</title>
<date>2001</date>
<booktitle>Proceedings of the 7th European Conference on Speech Communication and Technology (Eurospeech</booktitle>
<contexts>
<context>ng, facial expression coding, encoding location-based semantic data for information retrieval etc. A number of tools similar to ANVIL have been developed in recent years 3 (cf. Rohlfing et al., 2006; Bigbee et al., 2001) and most of these tools share two key properties: (1) coding is performed along a horizontal timeline, i.e. time intervals are represented as horizontal bars and time points are points on this line,</context>
</contexts>
<marker>Bigbee, Loehr, Harper, 2001</marker>
<rawString>Bigbee, A., Loehr, D., and Harper, L. (2001) Emerging Requirements for Multi-Modal Annotation and Analysis Tools. In: Proceedings of the 7th European Conference on Speech Communication and Technology (Eurospeech).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kipp</author>
<author>M und Albrecht Neff</author>
<author>I</author>
</authors>
<title>An Annotation Scheme for Conversational Gestures: How to economically capture timing and form. In: Multimodal Corpora for Modelling Human Multimodal Behavior, Special issue of the International Journal of Language Resources and Evaluation</title>
<date>2008</date>
<publisher>Springer</publisher>
<contexts>
<context>y spatiotemporal coding. Currently, the ANVIL tool allows the coding of timestamped points with optional linear interpolation between points. This feature has already been used coding human gestures (Kipp et al., 2008) and has potential for many other research areas, e.g. semantic coding for video-based information retrieval. Extending this feature to other shapes and interpolation types will be the subject of fut</context>
</contexts>
<marker>Kipp, Neff, I, 2008</marker>
<rawString>Kipp, M., Neff, M. und Albrecht, I. (2008). An Annotation Scheme for Conversational Gestures: How to economically capture timing and form. In: Multimodal Corpora for Modelling Human Multimodal Behavior, Special issue of the International Journal of Language Resources and Evaluation. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kipp</author>
</authors>
<title>Gesture Generation by Imitation From Human Behavior to Computer Character Animation. Boca</title>
<date>2004</date>
<location>Raton, Florida: Dissertation.com</location>
<contexts>
<context>design decisions and the relation to the MPEG-7 standard and tools. 1. Introduction ANVIL 1 is a free video annotation research tool for adding structured human annotations to digital video material (Kipp, 2004). Relevant research areas where ANVIL is in active use include psychology, psycholinguistics, embodied conversational agents, human-computer interaction, computer vision, computer animation, anthropo</context>
</contexts>
<marker>Kipp, 2004</marker>
<rawString>Kipp, M. (2004). Gesture Generation by Imitation From Human Behavior to Computer Character Animation. Boca Raton, Florida: Dissertation.com.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kipp</author>
</authors>
<title>Anvil A Generic Annotation Tool for Multimodal Dialogue. In</title>
<date>2001</date>
<booktitle>Proceedings of the 7th European Conference on Speech Communication and Technology (Eurospeech</booktitle>
<pages>1367--1370</pages>
<contexts>
<context>oftware.de 2 Java Media Framework, http://java.sun.com/jmf 3 See also http://www.ldc.upenn.edu/annotation/gesture simple string, although ANVIL allows more complex structures to hold the information (Kipp, 2001). It is important to be aware of the time-based nature of these tools in order to see how nontemporal data can be included in an elegant way. For instance, in (Martin &amp; Kipp, 2002) we introduced nont</context>
</contexts>
<marker>Kipp, 2001</marker>
<rawString>Kipp, M. (2001). Anvil A Generic Annotation Tool for Multimodal Dialogue. In: Proceedings of the 7th European Conference on Speech Communication and Technology (Eurospeech), pp. 1367-1370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J C Martin</author>
<author>M Kipp</author>
</authors>
<title>Annotating and Measuring Multimodal Behaviour Tycoon Metrics in the Anvil Tool. In</title>
<date>2002</date>
<booktitle>Proceedings of the Third International Conference on Language Resources and Evaluation (LREC</booktitle>
<contexts>
<context>res to hold the information (Kipp, 2001). It is important to be aware of the time-based nature of these tools in order to see how nontemporal data can be included in an elegant way. For instance, in (Martin &amp; Kipp, 2002) we introduced nontemporal elements that refer to the video as a whole (instead of belonging to a certain time interval) and can thus encode persistent objects that occur in the video all the time or</context>
</contexts>
<marker>Martin, Kipp, 2002</marker>
<rawString>Martin, J.C., Kipp, M. (2002). Annotating and Measuring Multimodal Behaviour Tycoon Metrics in the Anvil Tool. In: Proceedings of the Third International Conference on Language Resources and Evaluation (LREC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Martinez</author>
<author>R Koenen</author>
<author>F Rereira</author>
</authors>
<title>MPEG-7: the generic multimedia content description standard, part 1. In</title>
<date>2002</date>
<journal>IEEE Multimedia</journal>
<volume>9</volume>
<pages>78--87</pages>
<contexts>
<context> interest in marking-up multimedia data with “semantic” data on various levels of sophistication, from simple labels to ontological entities. This common interest culminated in the MPEG-7 5 standard (Martinez et al., 2002) for multimedia content description and a number of tools that support it. 4 see http://www.dfki.de/nite under “Anvil tools”. 5 http://www.chiariglione.org/MPEG/technologies/mp07mds/index.htm Figure </context>
</contexts>
<marker>Martinez, Koenen, Rereira, 2002</marker>
<rawString>Martinez, J.M., Koenen, R., Rereira, F. (2002). MPEG-7: the generic multimedia content description standard, part 1. In: IEEE Multimedia 9 (2), pp. 78-87.</rawString>
</citation>
</citationList>
</algorithm>

