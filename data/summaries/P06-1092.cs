According to this method, the word segmenter divides a sentence DC into a word sequence with the highest probability CMDB BP argmax DBBPDC C5 DBBND2 B4DBB5BM Nagata (1994) reported an accuracy of about 97% on a test corpus in the same domain using a learning corpus of 10,945 sentences in Japanese.
C94-1032
In the method using an unknown word model, first the generation probability of an unknown word is modeled by a character D2-gram, and then an NLP system, such as a morphological analyzer, searches for the best solution considering the possibility that all subsequences might be unknown words (Nagata, 1994; Bazzi and Glass, 2000).
C94-1032
Nagata (1996) proposed a method calculating word candidates with their uni-gram frequencies using a forwardbackward algorithm.
W96-0205
The noisy channel model approach is being successfully applied to various natural language processing (NLP) tasks, such as speech recognition (Jelinek, 1985), spelling correction (Kernighan et al., 1990), machine translation (Brown et al., 1990), etc.
J90-2002
It is now easy to gather machine-readable sentences in various domains because of the ease of publication and access via the Web (Kilgarriff and Grefenstette, 2003).
J03-3001
Thus, when DB CX is outside of the vocabulary CF, C8B4DB CX CYDB CXA0BD CXA0D2B7BD B5BPC5 DCBND2 B4DB CX B5C8B4CDCFCYDB CXA0BD CXA0D2B7BD B5BM 3.2 Automatic Word Segmentation Nagata (1994) proposed a stochastic word segmenter based on a word D2-gram model to solve the word segmentation problem.
C94-1032
