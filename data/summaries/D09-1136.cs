and test data.5 Charniak (2000)’s parser, trained
A00-2018
Liang Huang, Kevin Knight, and Aravind Joshi. 2006.
W06-3601
(2007) and May and Knight (2007) have noted,
D07-1038
(Koehn et al., 2003). Table 1 shows that big
N03-1017
2006; Huang et al., 2006), corresponds to the
W06-3601
2002). Huang et al. (2006) used character-based
W06-3601
DeNeroetal., 2008). Becausesuchapproachesdi-
D08-1033
2006; Huang et al., 2006). The word alignment
W06-3601
to favor syntax-friendly alignments. Fossum et al.(2008) start from the GIZA++ alignment and in-
W08-0306
John DeNero and Dan Klein. 2007. Tailoring word
P07-1003
ing (Galley et al., 2006; May and Knight, 2007),
D07-1038 P06-1121
Philipp Koehn. 2004. Statistical significance tests for
W04-3250
as GHKM (Galley et al., 2004) and is widely used
N04-1035
the TTS transducer (Liu et al., 2006; Huang et
P06-1077
ero (Chiang, 2007). The stumbling block pre-
J07-2003
trees (Liu et al., 2006; Huang et al., 2006; Gal-
P06-1077 W06-3601
ments. DeNero and Klein (2007) use a syntax-
P07-1003
Jonathan Graehl and Kevin Knight. 2004. Training
N04-1014
Yang Liu, Qun Liu, and Shouxun Lin. 2006. Tree-
P06-1077
in SSMT systems (Galley et al., 2006; Liu et al.,
P06-1121
using Charniak (2000)’s parser.
A00-2018
agonal growing heuristic (Koehn et al., 2003). We
N03-1017
the LHS (ROOTN) (Galley et al., 2006), corre-
P06-1121
David Chiang. 2007. Hierarchical phrase-based trans-
J07-2003
GHKM (Galley et al., 2004) is used to generate
N04-1035
ley et al., 2006; May and Knight, 2007), as op-
D07-1038
set (Koehn, 2004).
W04-3250
Carlo (MCMC) (DeNero et al., 2008), and Vari-
D08-1033
Galley et al. (2006) recompose the TTS tem-
P06-1121
process, similar to Goldwater et al. (2006). We
P06-1085
Eugene Charniak. 2000. A maximum-entropy-
A00-2018
inative model. May and Knight (2007) factorize
D07-1038
LHSN, as shown by Galley et al. (2006), cannot
P06-1121
J. May and K. Knight. 2007. Syntactic re-alignment
D07-1038
the IBM series models (Brown et al., 1993) or
J93-2003
