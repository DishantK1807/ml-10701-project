AGlobalJointModelforSemantic
RoleLabeling
KristinaToutanova
∗
MicrosoftResearch
AriaHaghighi
∗∗
UniversityofCaliforniaBerkeley
ChristopherD.Manning
†
StanfordUniversity
We present a model for semantic role labeling that effectively captures the linguistic intuition
that a semantic argument frame is a joint structure, with strong dependencies among the
arguments. We show how to incorporate these strong dependencies in a statistical joint model
with a rich set of features over multiple argument phrases. The proposed model substantially
outperforms a similar state-of-the-art local model that does not include dependencies among
differentarguments.
We evaluate the gains from incorporating this joint information on the Propbank corpus,
when using correct syntactic parse trees as input, and when using automatically derived parse
trees.Thegainsamountto24.1%errorreductiononallargumentsand36.8%oncorearguments
for gold-standard parse trees on Propbank. For automatic parse trees, the error reductions are
8.3%and 10.3%on all and core arguments, respectively. We also present results on the CoNLL
2005 shared task data set. Additionally, we explore considering multiple syntactic analyses to
copewithparsernoise and uncertainty.
1.Introduction
Since the release of the FrameNet (Baker, Fillmore, and Lowe 1998) and Propbank
(Palmer,Gildea,andKingsbury2005)corpora,therehasbeenalargeamountofwork
onstatisticalmodelsforsemanticrolelabeling.Mostofthisworkreliesheavilyonlocal
classiﬁers:onesthatdecidethesemanticroleofeachphraseindependentlyoftheroles
ofotherphrases.
However, linguistic theory tells us that a core argument frame is a joint struc-
ture, with strong dependencies between arguments. For instance, in the sentence
∗ OneMicrosoftWay,Redmond,WA98052,USA.E-mail:kristout@microsoft.com.
∗∗ DepartmentofElectricalEngineeringandComputerSciences,SodaHall,Berkeley,CA94720,USA.
E-mail:aria42@cs.berkeley.edu.
† DepartmentofComputerScience,GatesBuilding1A,353SerraMall,StanfordCA94305,USA.E-mail:
manning@cs.stanford.edu.
Submissionreceived:15July2006;Revisedsubmissionreceived:1May2007;Acceptedforpublication:
19June2007.
©2008AssociationforComputationalLinguistics
ComputationalLinguistics Volume34,Number2
[Final-hour trading]
THEME
accelerated[to 108.1 million shares]
TARGET
[yesterday]
ARGM-TMP,the
ﬁrstargumentisthesubjectnounphraseﬁnal-hour tradingoftheactiveverbaccelerated.
Ifwedidnotconsidertherestofthesentence,itwouldlookmorelikeanAGENTargu-
ment,butwhenwerealizethatthereisnoothergoodcandidateforaTHEMEargument,
becauseto108.1millionsharesmustbeaTARGETandyesterdayismostlikelyARGM-TMP,
wecancorrectlylabelitTHEME.
Eventhoughpreviousworkhasmodeledsomecorrelationsbetweenthelabelsof
parsetreenodes(seeSection2),manyimportantphenomenahavenotbeenmodeled.
Thekeypropertiesneededtomodelthisjointstructureare:(1)noﬁniteMarkovhorizon
assumptionfordependenciesamongnodelabels,(2)featureslookingatthelabelsof
multipleargumentnodesandinternalfeaturesofthesenodes,and(3)astatisticalmodel
capableofincorporatingtheselong-distancedependenciesandgeneralizingwell.We
showhowtobuildajointmodelofargumentframes,incorporatingnovelfeaturesinto
adiscriminativelog-linearmodel.Thissystemachievesanerrorreductionof24.1%
onALLargumentsand36.8%on COREargumentsoverastate-of-the-artindependent
classiﬁerforgold-standardparsetreesonPropbank.
Ifweconsiderthelinguisticbasisforjointmodelingofaverb’sarguments(includ-
ingmodiﬁers),thereareatleastthreetypesofinformationtobecaptured.Themost
basicistolimitoccurrencesofeachkindofargument.Forinstance,thereisusually
atmostoneargumentofaverbthatisanARG0(agent),andalthoughsomemodiﬁer
rolessuchasARGM-TMPcanfairlyeasilyberepeated,otherssuchasARGM-MNRalso
generallyoccuratmostonce.
1
Theremainingtwotypesofinformationapplymainlyto
corearguments(thestronglyselectedargumentsofaverb:ARG0–ARG5inPropbank),
whichinmostlinguistictheoriesaremodeledasbelongingtogetherinanargument
frame(setofarguments).Theinformationisonlymarginallyusefulforadjuncts(the
ARGMargumentsofPropbank),whichareusuallytreatedasindependentrealizational
choicesnotincludedintheargumentframeofaverb.
Firstly,manyverbstakeanumberofdifferentargumentframes.Previouswork
hasshownthatthesearestronglycorrelatedwiththewordsenseoftheverb(Roland
and Jurafsky 2002). If verbs were disambiguated for sense, the semantic roles of
phrases would be closer to independent given the sense of the verb. However, be-
cause in almost all semantic role labeling work (including ours), the word sense is
unknownandthemodelconditionsonlyonthelemma,thereismuchjointinforma-
tion between arguments when conditioning only on the verb lemma. For example,
compare:
(1) Britain’sHouseofCommonspassedalawonsteroiduse.
(2) Themanpassedthechurchonhiswaytothefactory.
IntheﬁrstcasethenounphraseafterpassedisanARG1,whereasinthesecondcaseitisa
ARGM-LOC,withthechoicegovernedbythesenseoftheverbpass.Secondly,evenwith
samesenseofaverb,differentpatternsofargumentrealizationleadtojointinformation
betweenarguments.Consider:
(3) Thedaythattheogrecookedthechildrenisstillremembered.
1 ThePropbanksemanticrolenameswhichweuseherearedeﬁnedinSection3.
162
Toutanova,Haghighi,andManning AGlobalJointModelforSRL
(4) Themealthattheogrecookedthechildrenisstillremembered.
Despitebothexampleshavinganidenticalsurfacesyntax,knowingthattheARG1of
cookisexpressedbytheinitialnounmealinthesecondexamplegivesevidencethatthe
childrenistheARG2(beneﬁciary),nottheARG1inthiscase.
Letusthinkofagraphicalmodeloverasetof m variables,oneforeachnodein
theparsetree t,representingthelabelsofthenodesandthedependenciesbetween
them.Inorderforamodeloverthesevariablestocapture,forexample,thestatistical
tendencyofsomesemanticrolestooccuratmostonce(e.g.,thatthereisusuallyatmost
oneconstituentlabeled AGENT),theremustbeadependencylinkbetweenanytwo
variables.ToestimatetheprobabilitythatacertainnodegetstheroleAGENT,weneed
toknowifanyoftheothernodeswerelabeledwiththisrole.
Weproposesuchamodel,withaveryrichgraphicalmodelstructure,whichis
globally conditioned on the observation (the parse tree).
2
Such a model is formally
aConditionalRandomField(CRF)(Lafferty,McCallum,andPereira2001).However,
notethatinpracticethistermhaspreviouslybeenusedalmostexclusivelytodescribe
therestrictedcaseoflinearchainConditionalMarkovRandomFields(sequencemod-
els)(Lafferty,McCallum,andPereira2001;ShaandPereira2003),oratleastmodels
thathavestrongMarkovproperties,whichallowefﬁcientdynamicprogrammingal-
gorithms(CohnandBlunsom2005).Instead,weconsideradenselyconnectedCRF
structure,withnoMarkovproperties,anduseapproximateinferencebyre-rankingthe
n-bestsolutionsofasimplermodelwithstrongerindependenceassumptions(forwhich
exactinferenceispossible).
Sucharichgraphicalmodelcanrepresentmanydependenciesbuttherearetwo
dangers—oneisthatthecomputationalcomplexityoftrainingthemodelandsearch-
ing for the most likely labeling given the tree can be prohibitive, and the other is
that if too many dependencies are encoded, the model will over-ﬁt the training
data and will not generalize well. We propose a model which circumvents these
two dangers and achieves signiﬁcant performance gains over a similar local model
thatdoesnotaddanydependencyarcsamongtherandomvariables.Totacklethe
efﬁciency problem, we adopt dynamic programming and re-ranking algorithms. To
avoidoverﬁttingweencodeonlyasmallsetoflinguisticallymotivateddependencies
infeaturesoversetsoftherandomvariables.Ourre-rankingapproach,liketheap-
proachtoparsere-rankingofCollins(2000),employsasimplermodel—alocalsemantic
rolelabelingalgorithm—asaﬁrstpasstogenerateasetof n likelycompleteassign-
mentsoflabelstoallparsetreenodes.Thejointmodelisrestrictedtothesenassign-
mentsanddoesnothavetosearchtheexponentiallylargespaceofallpossiblejoint
labelings.
2.RelatedWork
There has been a substantial amount of work on automatic semantic role labeling,
starting with the statistical model of Gildea and Jurafsky (2002). Researchers have
workedondeﬁningnewusefulfeatures,anddifferentsystemarchitecturesandmodels.
Herewereviewtheworkmostcloselyrelatedtoours,concentratingonmethodsfor
incorporatingjointinformationandforincreasingrobustnesstoparsererror.
2 Thatis,itdeﬁnesaconditionaldistributionoflabelsofallnodesgiventheparsetree.
163
ComputationalLinguistics Volume34,Number2
2.1MethodsforIncorporatingJointInformation
GildeaandJurafsky(2002)proposeamethodtomodelglobaldependenciesbyinclud-
ingaprobabilitydistributionovermulti-setsofsemanticrolelabelsgivenapredicate.
Inthiswaythemodelcanconsidertheassignmentofallnodesintheparsetreeand
evaluatewhetherthesetofrealizedsemanticrolesislikely.Ifanecessaryroleismissing
orifanunusualsetofargumentsisassignedbythelocalmodel,thisadditionalfactor
cancorrectsomeofthemistakes.Thedistributionoverlabelmulti-setsisestimated
usinginterpolationofarelativefrequencyandaback-offdistribution.Theback-off
distributionassumeseachargumentlabelispresentorabsentindependentlyofthe
otherlabels,namely,itassumesaBernoulliNaiveBayesmodel.
Themostlikelyassignmentoflabelsaccordingtosuchajointmodelisfoundap-
proximatelyusingre-scoringofthetopk =10assignmentsaccordingtoalocalmodel,
whichdoesnotincludedependenciesamongarguments.Usingthismodelimproves
theperformanceofthesysteminF-measurefrom59.2to62.85.Thisshowsthatadding
globalinformationimprovestheperformanceofarolelabelingsystemconsiderably.
However,thetypeofglobalinformationinthismodelislimitedtolabelmulti-sets.
Wewillshowthatmuchlargergainsarepossiblefromjointmodeling,addingricher
sourcesofjointinformationusingamoreﬂexiblestatisticalmodel.
ThemodelofPradhan,Hacioglu,etal.(2004,2005)isastate-of-the-artmodel,based
onSupportVectorMachines, andincorporating alargesetofstructural andlexical
features.Attheheartofthemodelliesalocalclassiﬁer,whichlabelseachparsetree
nodewithoneofthepossibleargumentlabelsorNONE.Jointinformationisintegrated
intothemodelintwoways:
Dynamicclasscontext:Usingthelabelsofthetwonodestotheleftasfeaturesfor
classifyingthecurrentnode.ThisissimilartotheConditionalMarkovModels(CMM)
often used in information extraction (McCallum, Freitag, and Pereira 2000). Notice
thatheretheprevioustwonodesclassiﬁedarenotingeneraltheprevioustwonodes
assignednon-NONElabels.Ifalinearorderonallnodesisimposed,thentheprevious
twonodesclassiﬁedmostlikelybearthelabelNONE.
Languagemodellatticere-scoring:Re-scoringofanN-bestlatticewithatrigram
languagemodeloversemanticrolelabelsequences.Thetargetpredicateisalsopartof
thesequence.
Thesewaysofincorporatingjointinformationresultedinsmallgainsoverabase-
linesystemusingonlythefeaturesofGildeaandJurafsky(2002).Theperformance
gainduetojointinformationoverasystemusingallfeatureswasnotreported.The
jointinformationcapturedbythismodelislimitedbythen-gramMarkovassumption
of the language model over labels. In our work, we improve the modeling of joint
dependenciesbylookingatlonger-distancecontext,bydeﬁningricherfeaturesover
the sequence of labels and input features, and by estimating the model parameters
discriminatively.
Asystemwhichcanintegratelonger-distancedependenciesisthatofPunyakanok
etal.(2004)andPunyakanok,Roth,andYih(2005).Theideaistobuildasemanticrole
labelingsystemthatisbasedonlocalclassiﬁersbutalsousesaglobalcomponentthat
ensures that several linguistically motivated global constraints on argument frames
aresatisﬁed.Theconstraintsarecategoricalandspeciﬁedbyhand.Forexample,one
global constraint is that the argument phrases cannot overlap—that is, if a node is
labeledwithanon-NONElabel,allofitsdescendantshavetobelabeled NONE.The
proposed framework is integer linear programming (ILP), which makes it possible
toﬁndthemostlikelyassignmentoflabelstoallnodesoftheparsetreesubjectto
164
Toutanova,Haghighi,andManning AGlobalJointModelforSRL
speciﬁedconstraints.SolvingtheILPproblemisNP-hardbutitisveryfastinpractice
(Punyakanok et al. 2004). The authors report substantial gains in performance due
to these global consistency constraints. This method was applied to improve the
performancebothofasystembasedonlabelingsyntacticchunksandonebasedon
labelingparsetreenodes.Ourworkdiffersfromthatworkinthatourconstraintsare
notcategorical(eithersatisﬁedornot),butareratherstatisticalpreferences,andthat
theyarelearnedautomaticallybasedonfeaturesspeciﬁedbytheknowledgeengineer.
Ontheotherhand,wesolvethesearch/estimationproblemthroughre-rankingand
n-bestsearchonlyapproximately,notexactly.
Sofarwehavemainlydiscussedsystemswhichlabelnodesinaparsetree.Many
systemsthatonlyuseshallowsyntacticinformationhavealsobeenpresented(Hacioglu
2004;Punyakanoketal.2004);usingfullsyntacticparseinformationwasnotallowedin
theCoNLL2004sharedtaskonSemanticRoleLabelinganddescriptionofsuchsystems
canbefoundin(CarrerasandM`arquez2004).Mostsystemswhichuseonlyshallow
syntacticinformationrepresenttheinputsentenceasasequenceoftokens(wordsor
phrases),whichtheylabelwithaBIOtaggingrepresentation(beginning,inside,and
outsideargumentlabels)(Hacioglu2004).Limitedjointinformationisusedbysuchsys-
tems,providedasaﬁxedsizecontextoftagsonprevioustokens;forexample,alength
ﬁvewindowisusedinthechunk-basedsystemin(Pradhan,Haciogluetal.2005).
AmethodthatmodelsjointinformationinadifferentwaywasproposedbyCohn
andBlunsom(2005).Itusesatree-structuredCRF,wherethestatisticaldependency
structureisexactlydeﬁnedbytheedgesinthesyntacticparsetree.Theonlydepen-
dencies captured are between the label of a node and the label of each of its chil-
dren.However, thearguments ofapredicate canbearbitrarily farfromeachother
inthesyntacticparsetreeandthereforeatree-CRFmodelislimitedinitsabilityto
modeldependenciesamongdifferentarguments.Forinstance,thedependencybetween
the meal and the children forthesentenceinexample(4)willnotbecapturedbecause
thesephrasesarenotinthesamelocaltreeaccordingtoPennTreebanksyntax.
2.2IncreasingRobustnesstoParserError
There have been multiple approaches to reducing the sensitivity of semantic role
labelingsystemstosyntacticparsererror.Promisingapproacheshavebeentoconsider
multiple syntactic analyses—the top k parses from a single or multiple full parsers
(Punyakanok,Roth,andYih2005),orashallowparseandafullparse(M`arquezetal.
2005; Pradhan et al. 2005), or several types of full syntactic parses (Pradhan, Ward
etal.2005).Suchtechniquesareimportantforachievinggoodperformance:Thetop
foursystemsintheCoNLL2005sharedtaskcompetitionallusedmultiplesyntactic
analyses(CarrerasandM`arquez2005).
Thesepreviousmethodsdevelopspecialcomponentstocombinethelabelingdeci-
sionsobtainedusingdifferentsyntacticannotation.ThemethodofPunyakanok,Roth,
andYih(2005)usesILPtoderiveaconsistentsetofarguments,eachofwhichcould
be derived using a different parse tree. Pradhan, Ward et al. (2005) use stacking to
trainaclassiﬁerwhichcombinesdecisionsbasedondifferentannotations,andM`arquez
etal.(2005)usespecial-purposeﬁlteringandinferencestageswhichcombinearguments
proposedbysystemsusingshallowandfullanalyses.
Ourapproachtoincreasingrobustnessusesthetop k parsesfromasingleparser
andisasimplegeneralmethodtofactorintheuncertaintyoftheparserbyapply-
165
ComputationalLinguistics Volume34,Number2
ingBayesianinference.ItismostcloselyrelatedtothemethoddescribedinFinkel,
Manning,andNg(2006)andcanbeseenasanapproximationofthatmethod.
Wedescribeoursystemindetailbyﬁrstintroducingsimplerlocalsemanticrole
labelingmodelsinSection4,andlaterbuildingonthemtodeﬁnejointmodelsinSec-
tion5.Beforewestartpresentingmodels,wedescribethedataandevaluationmeasures
usedinSection3.ReaderscanskipthenextsectionandcontinueontoSection4ifthey
arenotinterestedinthedetailsoftheevaluation.
3.DataandEvaluationMeasures
3.1Data
FormostofourexperimentsweusedtheFebruary2004releaseofPropbank.Wealso
reportresultsontheCoNLL2005sharedtaskdata(PropbankI)inSection6.2.For
thelatter, weusedthe standard CoNLLevaluation measures, andwe referreaders
to the description of that task for details of the evaluation (Carreras and M`arquez
2005).Inthissectionwedescribethedataandevaluationmeasuresweusedforthe
February2004data.WeuseourownsetofmeasuresontheFebruary2004datafor
threereasons.Firstly,wewishtopresentarichersetofmeasures,whichcanbetter
illustratetheperformanceofthesystemoncoreargumentsasagainstadjunctsand
theperformanceonidentifyingversusclassifyingarguments.Secondly,wetechnically
could not use the CoNLL measure on the February 2004 data, because this earlier
datawasnotavailableinaformatwhichspeciﬁeswhichargumentsshouldhavethe
additionalR-ARGXlabelsusedintheCoNLLevaluation.
3
Finally,thesemeasuresare
betterforcomparisonwithearlypapers,becausemostresearchbefore2005didnot
distinguishreferringarguments.Wedescribeourargument-basedmeasuresindetail
hereincaseresearchersareinterestedinreplicatingourresultsfortheFebruary2004
data.
FortheFebruary2004data,weusedthestandardsplitintotraining,development,
andtestsets—theannotationsfromsections02–21formedthetrainingset,section24the
development,andsection23thetestset.Thesetofargumentlabelsconsideredisthe
setofcoreargumentlabels(ARG0throughARG5)plusthemodiﬁerlabels(seeFigure1).
Thetrainingsetcontained85,392propositions,thetestset4,615,andthedevelopment
set2,626.
Weevaluatesemanticrolelabelingmodelsongold-standardparsetreesandparse
trees produced by Charniak’s automatic parser (Charniak 2000). For gold-standard
parsetrees,wepreprocessthetreestodiscardemptyconstituentsandstripfunctional
tags.Usingthetraceinformationprovidedbyemptyconstituentsisveryusefulfor
improving performance (Palmer, Gildea, and Kingsbury 2005; Pradhan, Ward et al.2005),butwehavenotusedthisinformationsothatwecancompareourresultsto
previousworkandsinceautomaticsystemsthatrecoveritarenotwidelyavailable.
3.2EvaluationMeasures
Since2004,therehasbeenaprecise,standardevaluationmeasureforsemanticrolela-
beling,formulatedbytheorganizersoftheCoNLLsharedtasks(CarrerasandM`arquez
3 Currently,ascriptwhichcanconvertoriginalPropbankannotationstoCoNLLformatisavailableaspart
oftheCoNLLsoftwaredistribution.
166
Toutanova,Haghighi,andManning AGlobalJointModelforSRL
Figure1
LabelsofmodifyingargumentsoccurringinPropbank.
2004,2005).Anevaluationscriptisalsodistributedaspartoftheprovidedsoftwarefor
thesharedtaskandcanbeusedtoevaluatesystemsonPropbankIdata.
Forpaperspublishedbetween2000and2005,thereareseveraldetailsoftheeval-
uation measures for semantic role labeling that make it difﬁcult to compare results
obtainedbydifferentresearchers,becauseresearchersusetheirownimplementations
ofevaluationmeasures,withoutmakingalltheexactdetailsclearintheirpapers.The
ﬁrstissueistheexistenceofargumentsconsistingofmultipleconstituents.Inthiscase
itisnotclearwhetherpartialcreditistobegivenforguessingonlysomeofthecon-
stituentscomprisingtheargumentcorrectly.Thesecondissueiswhetherthebracketing
ofconstituentsshouldberequiredtoberecoveredcorrectly,inotherwords,whether
pairsoflabelings,suchas[the]
ARG0
[man]
ARG0
and[the man]
ARG0
aretobeconsideredthe
sameornot.Iftheyareconsideredthesame,therearemultiplelabelingsofnodesin
aparsetreethatareequivalent.Thethirdissueisthatwhenusingautomaticparsers,
someoftheconstituentsthatareﬁllersofsemanticrolesarenotrecoveredbytheparser.
Inthiscaseitisnotclearhowvariousresearchgroupshavescoredtheirsystems(using
headwordmatch,ignoringtheseargumentsaltogether,orusingexactmatch).Ifwe
varythechoicetakenforthesethreeissues,wecancomeupwithmany(atleasteight)
differentevaluationmeasures,andthesedetailsareimportant,becausedifferentchoices
canleadtoratherlargedifferencesinreportedperformance.
HerewedescribeindetailourevaluationmeasuresfortheresultsontheFebruary
2004datareportedinthisarticle.ThemeasuresaresimilartotheCoNLLevaluation
measure,butreportarichersetofstatistics;theexactdifferencesarediscussedatthe
endofthissection.
For both gold-standard and automatic parses we use one evaluation measure,
whichwecallargument-basedevaluation.Todescribetheevaluationmeasure,wewill
useasanexamplethecorrectandguessedsemanticrolelabelingsshowninFigures2(a)
and2(b).BothareshownaslabelingsonparsetreenodeswithlabelsoftheformARGX
andC-ARGX.ThelabelC-ARGXisusedtorepresentmulti-constituentarguments.Acon-
stituentlabeledC-ARGXisassumedtobeacontinuationoftheclosestconstituenttothe
leftlabeledARGX.Oursemanticrolelabelingsystemproduceslabelingsofthisformand
thegoldstandardPropbankannotationsareconvertedtothisformaswell.
4
Theevalua-
tioniscarriedoutindividuallyforeachpredicateanditsassociatedargumentframe.Ifa
sentencecontainsseveralclauses,theseveralargumentframesareevaluatedseparately.
4 Thisrepresentationisnotpowerfulenoughtorepresentallvalidlabelingsofmulti-constituent
arguments,becauseitcannotrepresentthecasewhereanewargumentwithlabelARGXstartsbefore
apreviousmulti-constituentargumentwiththesamelabelARGXhasﬁnished.Thiscase,however,is
veryrare.
167
ComputationalLinguistics Volume34,Number2
Ourargument-basedmeasuresdonotrequireexactbracketing(ifthesetofwords
constitutinganargumentiscorrect,thereisnoneedtoknowhowthissetisbroken
into constituents) and do not give partial credit for labeling correctly only some of
severalconstituentsinamulti-constituentargument.TheyareillustratedinFigure2.
Forthesemeasures,asemanticrolelabelingofasentenceisviewedasalabelingonsets
ofwords.Thesesetscanencompassseveralnon-contiguousspans.Figure2(c)givesthe
representationofthecorrectandguessedlabelingsshowninFigures2(a)and2(b),inthe
ﬁrstandsecondrowsofthetable,respectively.Toconvertalabelingonparsetreenodes
tothisform,wecreatealabeledsetforeachpossiblymulti-constituentargument.All
remainingsetsofwordsareimplicitlylabeledwithNONE.Wecanseethat,inthisway,
exactbracketingisnotnecessaryandalsonopartialcreditisgivenwhenonlysomeof
severalconstituentsinamulti-constituentargumentarelabeledcorrectly.
Wewillrefertowordsetsas“spans.”Tocomputethemeasures,wearecomparing
aguessedsetoflabeledspanstoacorrectsetoflabeledspans.Webrieﬂydeﬁnethe
variousmeasuresofcomparisonusedherein,usingtheexampleguessedandcorrect
Figure2
Argument-basedscoringmeasuresfortheguessedlabeling.
168
Toutanova,Haghighi,andManning AGlobalJointModelforSRL
labelingsshowninFigure2(c).Allspansnotlistedexplicitlyareassumedtohavelabel
NONE.ThescoringmeasuresareillustratedinFigure2(d).
Theﬁgureshowsperformancemeasures—F-Measure(F1)andWholeFrameAccu-
racy(Acc.)—acrossninedifferentconditions.Whenthesetsoflabeledspansarecom-
pareddirectly,weobtainthecompletetaskmeasures,correspondingtotheID&CLSrow
andALLcolumninFigure2(d).Wealsodeﬁneseveralothermeasurestounderstandthe
performanceofthesystemondifferenttypesoflabels.Wemeasuretheperformanceon
identiﬁcation(ID),classiﬁcation(CLS),andthecompletetask(ID&CLS),whenconsider-
ingonlythecorearguments(CORE),allargumentsbutwithasingleARGMlabelforthe
modiﬁerarguments(COARSEARGM),andallarguments(ALL).Thisdeﬁnesninesub-tasks,
whichwenowdescribe.Foreachofthem,wecomputetheWholeFrameAccuracyand
F-Measureasfollows:
WholeFrameAccuracy(Acc.).Thisisthepercentageofpropositionsforwhich
thereisanexactmatchbetweentheproposedandcorrectlabelings.Forexample,the
wholeframeaccuracyforID&CLSandALLis0,becausethecorrectandguessedsets
oflabeledspansshowninFigure2(c)donotmatchexactly.Intheﬁgures,“Acc.”is
alwaysanabbreviationforthiswholeframeaccuracy.Eventhoughthismeasurehas
notbeenusedextensivelyinpreviouswork,weﬁnditusefultotrack.Mostimportantly,
potentialapplicationsofrolelabelingmayrequirecorrectlabelingofall(oratleastthe
core)argumentsinasentenceinordertobeeffective,andpartiallycorrectlabelingsmay
notbeveryuseful.Moreover,ajointmodelforsemanticrolelabelingoptimizesWhole
FrameAccuracymoredirectlythanalocalmodeldoes.
F-Measure(F
1
).BecausetheremaybeconfusionaboutwhatwemeanbyF-Measure
inthismulti-classsetting,wedeﬁneithere.F-Measureisdeﬁnedastheharmonicmean
ofprecisionandrecall:f=
2×p×r
p+r
;p=
true positive
true positive+false positive
;r=
true positive
true positve+false negative
.
This formula uses the number of true positive, false positive, and false nega-
tivespansinagivenguessedlabeling.Truepositiveisthenumberofspanswhosecorrect
labelisoneofthecoreormodiﬁerargumentlabels(notNONE)andwhoseguessedlabel
isthesameasthecorrectlabel. False positive isthenumberofspanswhoseguessed
labelisnon-NONEandwhosecorrectlabelisdifferentfromtheguessedlabel(possibly
NONE).Falsenegativeisthenumberofspanswhosecorrectlabelisnon-NONEandwhose
guessedlabelisnotthesameasthecorrectone(possiblyNONE).Intheﬁguresinthis
paperweshowF-Measuremultipliedby100sothatitisinthesamerangeasWhole
FrameAccuracy.
Core Argument Measures (CORE). These measures score the system on core
argumentsonly,withoutregardtomodiﬁerarguments.Theycanbeobtainedbyﬁrst
mappingallnon-coreargumentlabelsintheguessedandcorrectlabelingstoNONE.
CoarseModiﬁerArgumentMeasures(COARSEARGM).Sometimesitissufﬁcientto
knowagivenspanhasamodiﬁerrole,withoutknowledgeofthespeciﬁcrolelabel.In
addition,decidingexactmodiﬁerargumentlabelswasoneofthedecisionswithhighest
disagreement among annotators (Palmer, Gildea, and Kingsbury 2005). To estimate
performance under this setting, we relabel all ARGM-X arguments to ARGM in the
proposedandcorrectlabeling.SuchaperformancemeasurewasalsousedbyXueand
Palmer(2004).Notethatthesemeasuresdonotexcludethecoreargumentsbutinstead
considerthecoreplusacoarseversionofthemodiﬁerarguments.ThusforCOARSEARGM
169
ComputationalLinguistics Volume34,Number2
ALL wecount{0}asatruepositivespan,{1,2},{3,4},and{7,8,9}asfalsepositive,
and{1,2,3,4}and{7,8,9}asfalsenegative.
IdentiﬁcationMeasures(ID).ThesemeasurehowwellwedoontheARGvs.NONE
distinction.Forthepurposesofthisevaluation,allspanslabeledwithanon-NONElabel
areconsideredtohavethegenericlabel ARG.Forexample,tocompute COREID,we
comparethefollowingsetsoflabeledspans:
Correct:{0}-ARG,{7,8,9}-ARG
Guessed:{0}-ARG,{7,8,9}-ARG
TheF-Measureis1.0andtheWholeFrameAccuracyis100%.
ClassiﬁcationMeasures(CLS).Theseareperformanceonargumentspanswhich
werealsoguessedtobeargumentspans(butpossiblytheexactlabelwaswrong).In
otherwords,thesemeasuresignoretheARGvs.NONEconfusions.Theyignoreallspans,
whichwereincorrectlylabeled NONE,orincorrectlylabeledwithanargumentlabel,
whenthecorrectlabelwasNONE.Thisisdifferentfrom“classiﬁcationaccuracy”used
inpreviousworktomeantheaccuracyofthesysteminclassifyingspanswhenthe
correctsetofargumentspansisgiven.TocomputeCLSmeasures,weremoveallspans
fromS
guessed
andS
correct
thatdonotoccurinbothsets,andcomparetheresultingsets.
Forexample,tocomputetheALLCLSmeasures,weneedtocomparethefollowingsets
oflabeledspans:
Correct:{0}-ARG0,{7,8,9}-ARG2
Guessed:{0}-ARG0,{7,8,9}-ARG3
Therestofthespanswereremovedfrombothsetsbecausetheywerelabeled NONE
accordingtooneofthelabelingsandnon-NONEaccordingtotheother.TheF-Measure
is.50andtheWholeFrameAccuracyis0%.
As we mentioned before, we label and evaluate the semantic frame of every
predicate in the sentence separately. It is possible for a sentence to contain several
propositions—annotationsofpredicatesoccurringinthesentence.Forexample,inthe
sentenceThespacecraftfacesasix-yearjourneytoexploreJupiter,therearetwopropositions,
fortheverbsfacesandexplore.Theseare:
[Thespacecraft]
ARG0
[faces]
PRED
[asix-yearjourneytoexplore Jupiter]
ARG1
.
[Thespacecraft]
ARG0
facesa six-yearjourneyto[explore]
PRED
[Jupiter]
ARG1
.
Ourevaluationmeasurescomparetheguessedandcorrectsetoflabeledspansforeach
proposition.
3.3RelationtotheCoNLLEvaluationMeasure
TheCoNLLevaluationmeasure(CarrerasandM`arquez2004,2005)isalmostthesame
asourargument-basedmeasure.TheonlydifferenceisthattheCoNLLmeasureintro-
ducesanadditionallabeltypeforarguments,oftheformR-ARGX,usedforreferringex-
170
Toutanova,Haghighi,andManning AGlobalJointModelforSRL
pressions.ThePropbankdistributioncontainsaspeciﬁcationofwhichmulti-constituent
arguments are in a coreference chain. The CoNLL evaluation script considers these
multi-constituent arguments as several separate arguments having different labels,
whereoneargumenthasanARGXlabelandtheothershaveR-ARGXlabels.Thedecision
ofwhichconstituentsweretobelabeledwithreferringlabelswasmadeusingasetof
rulesexpressedwithregularexpressions.
5
AscriptthatconvertsPropbankannotations
toCoNLLformatisavailableaspartofthesharedtasksoftware.
For example, in the following sentence, the CoNLL speciﬁcation annotates the
argumentsofbeganasfollows:
[The deregulation]
ARG1
of railroads[that]
R-ARG1
[began]
PRED
enabledshipperstobargain
fortransportation.
Incontrast,wetreatallmulti-constituentargumentsinthesameway,anddonot
distinguish coreferential versus non-coreferential split arguments. According to our
argument-basedevaluation,theannotationoftheargumentsoftheverbbeganis:
[The deregulation]
ARG1
of railroads[that]
C-ARG1
[began]
PRED
enabledshipperstobargain
fortransportation.
ThedifferencebetweenourargumentbasedmeasureandtheCoNLLevaluation
measureissuchthatwecannotsaythatthevalueofoneisalwayshigherthanthevalue
oftheother.Eithermeasurecouldbehigherdependingonthekindsoferrorsmade.
For example, if the guessed labeling is: [The deregulation]
ARG0
of railroads [that]
R-ARG1
[began]
PRED
enabled shippers to bargain for transportation, the CoNLL script would
counttheargument that ascorrectandreportprecisionandrecallof.5,whereasour
argument-basedmeasurewouldnotcountanyargumentcorrectandreportprecision
andrecallof0.Ontheotherhand,iftheguessedlabelingis[The deregulation]
ARG1
of
railroads[that]
C-ARG1
[began]
PRED
enabled shippers to bargain for transportation,theCoNLL
measurewouldreportaprecisionandrecallof0,whereasourargument-basedmeasure
wouldreportprecisionandrecallof1.Iftheguessedlabelingis[The deregulation]
ARG1
of railroads [that]
R-ARG1
[began]
PRED
enabled shippers to bargain for transportation,both
measureswouldreportprecisionandrecallof1.(Forourargument-basedmeasure
itdoesnotmakesensetopropose R-ARGXlabelsandweassumesuchlabelswould
beconvertedtoC-ARGXlabelsiftheyareafterthephrasetheyreferto.)Nevertheless,
overallweexpectthetwomeasurestoyieldverysimilarresults.
4.LocalClassiﬁers
Aclassiﬁerislocalifitassignsaprobability(orscore)tothelabelofanindividualparse
treenoden
i
independentlyofthelabelsofothernodes.
Indeﬁningourmodels,weusethestandardseparationofthetaskofsemanticrole
labelingintoidentiﬁcationandclassiﬁcationphases.Formally,letLdenoteamapping
ofthenodesinatreettoalabelsetofsemanticroles(includingNONE)withrespectto
apredicatev.LetId(L)bethemappingwhichcollapsesL’snon-NONEvaluesintoARG.
5 Theregularexpressionslookforphrasescontainingpronounswithpart-of-speechtagsWDT,WRB,WP,
orWP$(XavierCarreras,personalcommunication).
171
ComputationalLinguistics Volume34,Number2
Then,liketheGildeaandJurafsky(2002)system,wedecomposetheprobabilityofa
labelingLintoprobabilitiesaccordingtoanidentiﬁcationmodelP
ID
andaclassiﬁcation
modelP
CLS
.
P
SRL
(L|t,v)=P
ID
(Id(L)|t,v)P
CLS
(L|t,v,Id(L)) (1)
This decomposition does not encode any independence assumptions, but is a use-
fulwayofthinkingabouttheproblem.Ourlocalmodelsforsemanticrolelabeling
usethisdecomposition.Weusethesamefeaturesforlocalidentiﬁcationandclassi-
ﬁcationmodels,butusethedecompositionforefﬁciencyoftraining.Theidentiﬁca-
tion models are trained toclassify each node ina parse tree as ARG or NONE,and
theclassiﬁcationmodelsaretrainedtolabeleachargumentnodeinthetrainingset
with its speciﬁc label. In this way the training set for the classiﬁcation models is
smaller.Notethatwedonotdoanyhardpruningattheidentiﬁcationstageintesting
andcanﬁndtheexactlabelingofthecompleteparsetree,whichisthemaximizerof
Equation(1).
Weuselog-linearmodelsformulti-classclassiﬁcationforthelocalmodels.Because
theyproduceprobabilitydistributions,identiﬁcationandclassiﬁcationmodelscanbe
chainedinaprincipledway,asinEquation(1).Thebaselinefeaturesweusedforthe
localidentiﬁcationandclassiﬁcationmodelsareoutlinedinFigure3.Thesefeaturesare
asubsetofthefeaturesusedinpreviouswork.Thestandardfeaturesatthetopofthe
ﬁgureweredeﬁnedbyGildeaandJurafsky(2002),andtherestareotherusefullexical
andstructuralfeaturesidentiﬁedinmorerecentwork(Surdeanuetal.2003;Pradhan
etal.2004;XueandPalmer2004).Wealsoincorporatedseveralnovelfeatureswhich
wedescribenext.
Figure3
Baselinefeatures.
172
Toutanova,Haghighi,andManning AGlobalJointModelforSRL
Figure4
Exampleofdisplacedarguments.
4.1AdditionalFeaturesforDisplacedConstituents
Wefoundthatalargesourceoferrorsfor ARG0and ARG1stemmedfromcasessuch
asthoseillustratedinFigure4,whereargumentsweredislocatedbyraisingorcontrol
verbs.Here,thepredicate, expected,doesnothaveasubjectinthetypicalposition—
indicatedbytheemptyNP—becausetheauxiliaryishasraisedthesubjecttoitscurrent
position.Inordertocapturethisclassofexamples,weuseabinaryfeature,MISSING
SUBJECT,indicatingwhetherthepredicateis“missing”itssubject,andusethisfeature
inconjunctionwiththePATHfeature,sothatwelearntypicalpathstoraisedsubjects
conditionedontheabsenceofthesubjectinitstypicalposition.
6
IntheparticularcaseofFigure4,thereisanotherinstanceofanargumentbeing
quitefarfromitspredicate.Thepredicate widen sharesthephrase the trade gap with
expectasanARG1argument.However,asexpectisaraisingverb,widen’ssubjectisnot
initstypicalpositioneither,andweshouldexpecttoﬁnditinthesamepositionas
expected’ssubject.Thisindicatesitmaybeusefultousethepathrelativeto expected
to ﬁnd arguments for widen. In general, to identify certain arguments of predicates
embeddedinauxiliaryandinﬁnitivalVPsweexpectittobehelpfultotakethepath
fromthemaximumextendedprojectionofthepredicate—thehighestVPinthechain
ofVPsdominatingthepredicate.Weintroduceanewpathfeature,PROJECTEDPATH,
whichtakesthepathfromthemaximalextendedprojectiontoanargumentnode.This
featureappliesonlywhentheargumentisnotdominatedbythemaximalprojection
(e.g.,directobjects).Thesefeaturesalsohandleothercasesofdiscontinuousandnon-
localdependencies,suchasthosearisingduetocontrolverbs.Theperformancegain
fromthesenewfeatureswasnotable,especiallyinidentiﬁcation.Theperformanceon
ALLargumentsforthemodelusingonlythefeaturesinFigure3,andthemodelusing
theadditionalfeaturesaswell,areshowninFigure5.Fortheseresults,theconstraint
thatargumentphrasesdonotoverlapwasenforcedusingthealgorithmpresentedin
Section4.2.
4.2EnforcingtheNon-OverlappingConstraint
The most direct way to use trained local identiﬁcation and classiﬁcation models in
testing is to select a labeling L of the parse tree that maximizes the product of the
6 WeconsideraverbtobemissingitssubjectifthehighestVPinthechainofVPsdominatingtheverb
doesnothaveanNPorS(BAR)asitsimmediateleftsister.
173
ComputationalLinguistics Volume34,Number2
Figure5
PerformanceoflocalclassiﬁersonALLarguments,usingthefeaturesinFigure3onlyandusing
theadditionallocalfeatures.UsinggoldstandardparsetreesonSection23.
probabilitiesaccordingtothetwomodels,asinEquation(1).Becausethesemodelsare
local,thisisequivalenttoindependentlymaximizingtheproductoftheprobabilitiesof
thetwomodelsforthelabell
i
ofeachparsetreenoden
i
asshownbelowinEquation(2).
P
lscript
SRL
(L|t,v)=
productdisplay
n
i
∈t
P
ID
(Id(l
i
)|t,v)
productdisplay
n
i
∈t
P
CLS
(l
i
|t,v,Id(l
i
)) (2)
Aproblemwiththisapproachisthatamaximizinglabelingofthenodescouldpossibly
violatetheconstraintthatargumentnodesshouldnotoverlapwitheachother.There-
fore,toproduceaconsistentsetofargumentswithlocalclassiﬁers,wemusthaveaway
ofenforcingthenon-overlappingconstraint.
Whenlabelingparsetreenodes,previousworkhaseitherusedgreedyalgorithms
to ﬁnd a non-overlapping assignment, or the general-purpose ILP approach of
Punyakanoketal.(2004).Forlabelingchunksanexactalgorithmbasedonshortest
pathswasproposedinPunyakanokandRoth(2001).Itscomplexityisquadraticinthe
lengthofthesentence.
Herewedescribeafasterexactdynamicprogrammingalgorithmtoﬁndthemost
likelynon-overlapping(consistent)labelingofallnodesintheparsetree,according
toaproductofprobabilitiesfromlocalmodels,asinEquation(2).Forsimplicity,we
describethedynamicprogramforthecasewhereonlytwoclassesarepossible:ARGand
NONE.Thegeneralizationtomoreclassesisstraightforward.Intuitively,thealgorithm
issimilartotheViterbialgorithmforcontext-freegrammars,becausewecandescribe
thenon-overlappingconstraintbya“grammar”thatdisallowsARGnodeshavingARG
descendants.
Subsequently,wewilltalkaboutmaximizingthesumofthelogsoflocalproba-
bilitiesratherthantheproductoflocalprobabilities,whichisequivalent.Thedynamic
programworksfromtheleavesofthetreeupandﬁndsabestassignmentforeach
subtree,usingalreadycomputedassignmentsforitschildren.Supposewewantthe
mostlikelyconsistentassignmentforsubtree t withchildtrees t
1,...,t
k
eachstoring
themostlikelyconsistentassignmentofitsnodes,aswellasthelog-probabilityofthe
ALLNONEassignment:theassignmentofNONEtoallnodesinthetree.Themostlikely
assignmentfortistheonethatcorrespondstothemaximumof:
a114
Thesumofthelog-probabilitiesofthemostlikelyassignmentsofthechild
subtreest
1,...,t
k
plusthelog-probabilityofassigningthenodettoNONE.
a114
Thesumofthelog-probabilitiesoftheALLNONEassignmentsoft
1,...,t
k
plusthelog-probabilityofassigningthenodettoARG.
174
Toutanova,Haghighi,andManning AGlobalJointModelforSRL
Figure6
PerformanceoflocalmodelonALLargumentswhenenforcingthenon-overlappingconstraint
ornot.
Thelog-probabilityoftheALLNONEassignmentforatree t isthelog-probability
ofassigningtherootnodeof t to NONEplusthesumofthelog-probabilitiesofthe
ALLNONEassignmentsofthechildsubtreesoft.
Propagating this procedure from the leaves to the root of t we have our most
likelynon-overlappingassignment.Byslightlymodifyingthisprocedure,weobtainthe
mostlikelyassignmentaccordingtoaproductoflocalidentiﬁcationandclassiﬁcation
models.Weusethelocalmodelsinconjunctionwiththissearchproceduretoselecta
most-likelylabelingintesting.
Thecomplexityofthisalgorithmislinearinthenumberofnodesintheparsetree,
whichisusuallymuchlessthanthesquareofthenumberofwordsinthesentence(l
2
),
thecomplexityofthePunyakanokandRoth(2001)algorithm.Forexample,forabinary-
branchingparsetree,thenumberofnodesisapproximately2l.Thespeedupisdueto
thefactthatwhenwelabelparsetreenodes,wemakeuseofthebracketingconstraints
imposedbytheparsetree.TheshortestpathalgorithmproposedbyPunyakanokand
Rothcanalsobeadaptedtoachievethislowercomputationalcomplexity.
Itturnsoutthatenforcingthenon-overlappingconstraintdoesnotleadtolarge
gainsinperformance.TheresultsinFigure5arefrommodelsthatusethedynamicpro-
gramforselectingnon-overlappingarguments.Toevaluatethegainfromenforcingthe
constraint,Figure6showstheperformanceofthesamelocalmodelusingallfeatures,
whenthedynamicprogramisusedversuswhenamostlikelypossiblyoverlapping
assignmentischosenintesting.
Thelocalmodelwithbasicplusadditionalfeaturesisourﬁrstpassmodelused
inre-ranking.Thenon-overlappingconstraintisenforcedusingthedynamicprogram.
Thisisastate-of-the-artmodel.ItsF-MeasureonALLargumentsis88.4accordingtoour
argument-basedscoringmeasure.Thisisverysimilartothebestreportedresults(asof
2004)usinggold-standardparsetreeswithoutnullconstituentsandfunctionaltags:89.4
F-MeasurereportedforthePradhanetal.(2004)model.
7
AmoredetailedanalysisoftheresultsobtainedbythelocalmodelisgiveninFig-
ure7(a),andthetwoconfusionmatricesinFigures7(b)and7(c),whichdisplaythe
numberoferrorsofeachtypethatthemodelmade.Theﬁrstconfusionmatrixcon-
centratesonCOREargumentsandmergesallmodifyingargumentlabelsintoasingle
ARGMlabel.Thesecondconcentratesonconfusionsamongmodifyingarguments.
FromtheconfusionmatrixinFigure7(b),wecanseethatthelargestnumberof
errorsareconfusionsofargumentlabelswithNONE.Thenumberofconfusionsbetween
pairsofcoreargumentsislow,asisthenumberofconfusionsbetweencoreandmodiﬁer
labels.Ifweignorethecolumnandrowcorrespondingto NONEinFigure7(b),the
numberofoff-diagonalentriesisverysmall.ThiscorrespondstothehighF-Measures
7 TheresultsinPradhanetal.(2004)arebasedonameasurewhichismorelenientthanour
argument-basedscoring(SameerPradhan,personalcommunication,July2005).Ourestimated
performanceusinghismeasureis89.9.
175
ComputationalLinguistics Volume34,Number2
Figure7
Performancemeasuresforlocalmodelusingalllocalfeaturesandenforcingthe
non-overlappingconstraint.ResultsareonSection23usinggoldstandardparsetrees.
on COARSEARGMCLSand CORECLS,98.1and98.0respectively,showninFigure7(a).
ThenumberofconfusionsofargumentlabelswithNONE,shownintheNONEcolumn,
islargerthanthenumberofconfusionsofNONEwithargumentlabels,showninthe
NONErow.Thisshowsthatthemodelgenerallyhashigherprecisionthanrecall.We
experimentedwiththeprecision–recalltradeoffbutthisdidnotresultinanincreasein
F-Measure.
FromtheconfusionmatrixinFigure7(c)wecanseethatthenumberofconfusions
betweenmodiﬁerargumentlabelsishigherthanthenumberofconfusionsbetween
coreargumentlabels.Thiscorrespondstothe ALLCLSF-Measureof95.7versusthe
CORECLSF-Measureof98.0.Theper-labelF-Measuresinthelastcolumnshowthatthe
performanceonsomeveryfrequentmodiﬁerlabelsisinthelowsixtiesorseventies.
TheconfusionsbetweenmodiﬁerlabelsandNONEarequitenumerous.
Thus,toimprovetheperformanceonCOREarguments,weneedtoimproverecall
withoutloweringprecision.Inparticular,whenthemodelisuncertainwhichofseveral
likelyCORElabelstoassign,weneedtoﬁndadditionalsourcesofevidencetoimprove
itsconﬁdence.Toimprovetheperformanceonmodiﬁerarguments,wealsoneedto
lowertheconfusionsamongdifferentmodiﬁerarguments.Wewillseethatourjoint
model improves the overall performance mainly by improving the performance on
176
Toutanova,Haghighi,andManning AGlobalJointModelforSRL
COREarguments,throughincreasingrecallandprecisionbylookingatwidersentence
context.
4.3OnSplitConstituents
As discussed in Section 3, multiple constituents can be part of the same semantic
argument as speciﬁed by Propbank. An automatic system that has to recover such
informationneedstohaveawayofindicatingwhenmultipleconstituentslabeledwith
thesamesemanticroleareapartofthesameargument.Someresearchers(Pradhanetal.
2004;Punyakanoketal.2004)havechosentomakelabelsoftheformC-ARGXdistinct
argumentlabelsthatbecomeadditionalclassesinamulti-classconstituentclassiﬁer.
TheseC-ARGXareusedtoindicatecontinuingargumentsasillustratedinthetwotrees
inFigure2.Wechosetonotintroduceadditionallabelsofthisform,becausetheymight
unnecessarilyfragmentthetrainingdata.Ourautomaticclassiﬁerslabelconstituents
withoneofthecoreormodiﬁersemanticrolelabels,andasimplepost-processing
ruleisappliedtotheoutputofthesystemtodeterminewhichconstituentsthatare
labeledthesamearetobemergedasthesameargument.Thepost-processingruleis
thefollowing:ForeveryconstituentthatbearsacoreargumentlabelARGX,ifthereis
aprecedingconstituentwiththesamelabel,re-labelthecurrentconstituent C-ARGX.
Therefore,accordingtoouralgorithm,allconstituentshavingthesamecoreargument
labelarepartofthesameargument,andallconstituentshavingthesamemodiﬁerlabels
areseparateargumentsbythemselves.Thisruleisfairlyaccurateforcoreargumentsbut
isnotalwayscorrect;itfailsmoreoftenonmodiﬁerarguments.Anevaluationofthis
ruleusingtheCoNLLdatasetandevaluationmeasureshowsthatourupperboundin
performancebecauseofthisruleisapproximately99.0F-MeasureonALLarguments.
5.JointClassiﬁers
Weproceedtodescribeourmodelsincorporatingdependenciesbetweenlabelsofnodes
intheparsetree.Aswediscussedbrieﬂybefore,thedependencieswewouldliketo
modelarehighlynon-local.AfactorizedsequencemodelthatassumesaﬁniteMarkov
horizon,suchasachainCRF(Lafferty,McCallum,andPereira2001),wouldnotbe
abletoencodesuchdependencies.WedeﬁneaCRFwithamuchricherdependency
structure.
5.1FormoftheJointClassiﬁers
MotivationforRe-Ranking.Forargumentidentiﬁcation,thenumberofpossibleas-
signmentsforaparsetreewithnnodesis2
n
.Thisnumbercanrunintothehundreds
of billions for a normal-sized tree. For argument labeling, the number of possible
assignmentsis ≈20
m,ifm isthenumberofargumentsofaverb(typicallybetween
2and5),and20istheapproximatenumberofpossiblelabelsifconsideringbothcore
andmodifyingarguments.Trainingamodelwhichhassuchahugenumberofclasses
isinfeasibleifthemodeldoesnotfactorizeduetostrongindependenceassumptions.
Therefore,inordertobeabletoincorporatelong-rangedependenciesinourmodels,
wechosetoadoptare-rankingapproach(Collins2000),whichselectsfromlikelyas-
signmentsgeneratedbyamodelwhichmakesstrongerindependenceassumptions.We
utilizethetopnassignmentsofourlocalsemanticrolelabelingmodelP
lscript
SRL
togenerate
likelyassignments.AscanbeseenfromFigure8(a),forrelativelysmallvaluesofn,our
177
ComputationalLinguistics Volume34,Number2
re-rankingapproachdoesnotpresentaseriousbottlenecktoperformance.Weuseda
valueofn=10fortraining.InFigure8(a)wecanseethatifwecouldpick,usingan
oracle,thebestassignmentoutofthetop10assignmentsaccordingtothelocalmodel,
wewouldachieveanF-Measureof97.3onallarguments.Increasingthenumberofnto
30resultsinaverysmallgainintheupperboundonperformanceandalargeincrease
inmemoryrequirements.Wethereforeselectedn=10asagoodcompromise.
Generation of top n Most Likely Joint Assignments. We generate the top n most
likelynon-overlappingjointassignmentsoflabelstonodesinaparsetreeaccording
to a local model P
lscript
SRL, using an exact dynamic programming algorithm, which is a
directgeneralizationofthealgorithmforﬁndingthetopnon-overlappingassignment
describedinSection4.2.
ParametricModels.Welearnlog-linearre-rankingmodelsforjointsemanticrolelabel-
ing,whichusefeaturemapsfromaparsetreeandlabelsequencetoavectorspace.The
formofthemodelsisasfollows.LetΦ(t,v,L)∈ R
s
denoteafeaturemapfromatreet,
targetverbv,andjointassignmentLofthenodesofthetree,tothevectorspaceR
s
.Let
L
1,L
2,···,L
N
denotethetopNpossiblejointassignments.Welearnalog-linearmodel
withaparametervectorW,withoneweightforeachofthesdimensionsofthefeature
vector.Theprobability(orscore)ofanassignmentLaccordingtothisre-rankingmodel
isdeﬁnedas
P
r
SRL
(L|t,v)=
e
<Φ(t,v,L),W>
summationtext
N
j=1
e
<Φ(t,v,L
j
),W>
(3)
ThescoreofanassignmentLnotinthetopniszero.Wetrainthemodeltomaximizethe
sumoflog-likelihoodsofthebestassignmentsminusaquadraticregularizationterm.
Inthisframework,wecandeﬁnearbitraryfeaturesoflabeledtreesthatcapturegeneral
propertiesofpredicate–argumentstructure.
5.2JointModelFeatures
Wewillintroducethefeaturesofthejointre-rankingmodelinthecontextoftheexample
parsetreeshowninFigure9.Wemodeldependenciesnotonlybetweenthelabelofa
Figure8
Oracleupperboundsfortopnnon-overlappingassignmentsfromlocalmodelonCOREandALL
arguments,usinggold-standardparsetrees.
178
Toutanova,Haghighi,andManning AGlobalJointModelforSRL
Figure9
AnexampletreefromPropbankwithsemanticroleannotations,forthesentenceFinal-hour
tradingacceleratedto108.1 millionsharesyesterday.
nodeandthelabelsofothernodes,butalsodependenciesbetweenthelabelofanode
andinputfeaturesofotherargumentnodes.Thefeaturesarespeciﬁedbyinstantiation
oftemplatesandthevalueofafeatureisthenumberoftimesaparticularpatternoccurs
inthelabeledtree.
Foratreet,predicatev,andjointassignmentLoflabelstothenodesofthetree,we
deﬁnethecandidateargumentsequenceasthesequenceofnon-NONElabelednodes
[n
1,l
1,...,v
PRED,...,n
m,l
m
](l
i
isthelabelofnoden
i
).Areasonablecandidateargument
sequenceusuallycontainsveryfewofthenodesinthetree—about2to7—asthisis
thetypicalnumberofargumentsforaverb.Tomakeitmoreconvenienttoexpress
ourfeaturetemplates,weincludethepredicatenodevinthesequence.Thissequence
oflabelednodesisdeﬁnedwithrespecttotheleft-to-rightorderofconstituentsinthe
parsetree.Becausenon-NONElabelednodesdonotoverlap,thereisastrictleft-to-right
orderamongthesenodes.Thecandidateargumentsequencethatcorrespondstothe
correctassignmentinFigure9isthen:
[NP
1
-ARG1,VBD
1
-PRED,PP
1
-ARG4,NP
3
-ARGM-TMP]
FeaturesfromLocalModels.Allfeaturesincludedinthelocalmodelsarealsoincluded
inourjointmodels.Inparticular,eachtemplateforlocalfeaturesisincludedasajoint
templatethatconcatenatesthelocaltemplateandthenodelabel.Forexample,forthe
localfeaturePATH,wedeﬁneajointfeaturetemplatethatextractsPATH fromevery
node in the candidate argument sequence and concatenates it with the label of the
node.Bothafeaturewiththespeciﬁcargumentlabelandafeaturewiththegeneric
back-off ARGlabelarecreated.Thisissimilartoaddingfeaturesfromidentiﬁcation
and classiﬁcation models. In the case of the example candidate argument sequence
provided,forthenodeNP
1
wehavethefeatures:
{(NP↑S↓VP↓VBD)-ARG1,(NP↑S↓VP↓VBD)-ARG}
Whencomparingalocalandajointmodel,weusethesamesetoflocalfeature
templatesinthetwomodels.Iftheseweretheonlyfeaturesthatajointmodelused,
we would expect its performance to be roughly the same as the performance of a
localmodel.Thisisbecausethetwomodelswillinfactbeinthesameparametric
family but will only differ slightly in the way the parameters are estimated. In
particular, the likelihood of an assignment according to the joint model with local
featureswilldifferfromthelikelihoodofthesameassignmentaccordingtothelocal
modelonlyinthedenominator(thepartitionfunction).Thejointmodelsumsover
179
ComputationalLinguistics Volume34,Number2
afewlikelyassignmentsinthedenominator,whereasthelocalmodelsumsoverall
assignments;also,thejointmodeldoesnottreatthedecompositionintoidentiﬁcation
andclassiﬁcationmodelsinexactlythesamewayasthelocalmodel.
WholeLabelSequenceFeatures.Asobservedinpreviouswork(GildeaandJurafsky
2002;Pradhanetal.2004),includinginformationaboutthesetorsequenceoflabels
assignedtoargumentnodesshouldbeveryhelpfulfordisambiguation.Forexample,
includingsuchinformationwillmakethemodellesslikelytopickmultiplenodesto
ﬁllthesameroleortocomeupwithalabelingthatdoesnotcontainanobligatory
argument.Weaddedawholelabelsequencefeaturetemplatethatextractsthelabels
ofallargumentnodes,andpreservesinformationaboutthepositionofthepredicate.
Twotemplatesforwholelabelsequenceswereadded:onehavingthepredicatevoice
only,andanotheralsoincludingthepredicatelemma.Thesetemplatesareinstantiated
asfollowsfortheexamplecandidateargumentsequence:
[voice:active,ARG1,PRED,ARG4,ARGM-TMP]
[voice:active,lemma:accelerate,ARG1,PRED,ARG4,ARGM-TMP]
Wealsoaddvariantsofthesetemplatesthatuseageneric ARGlabelinsteadof
speciﬁclabelsforthearguments.Thesefeaturetemplateshavetheeffectofcountingthe
numberofargumentstotheleftandrightofthepredicate,whichprovidesusefulglobal
informationaboutargumentstructure.Alocalmodelisnotabletorepresentthecount
ofargumentssincethelabelofeachnodeisdecidedindependently.Thisfeaturecan
verydirectlyandsuccinctlyencodepreferencesforrequiredargumentsandexpected
numberofarguments.
Aspreviouslyobserved(Pradhanetal.2004),includingmodifyingargumentsin
sequencefeaturesisnothelpful.Thiscorrespondstothestandardlinguisticunderstand-
ingthattherearenoprevalentconstraintsonthepositionorpresenceofadjunctsinan
argumentframe,andwasconﬁrmedinourexperiments.Weredeﬁnedthewholelabel
sequencefeaturestoexcludemodifyingarguments.
Thewholelabelsequencefeaturesaretheﬁrsttypeoffeaturesweaddtorelax
the independence assumptions of the local model. Because these features look at
the sequence oflabels of all arguments, theycapture joint information. There isno
limitonthelengthofthelabelsequenceandthusthereisno n-gramMarkovorder
independenceassumption(inpracticethecandidateargumentsequencesinthetop
n completeassignmentsarerarelymorethan7nodeslong).Additionally,thenodes
inthecandidateargumentsequencesareingeneralnotinthesamelocaltreeinthe
syntacticanalysisandatree-CRFmodel(CohnandBlunsom2005)wouldnotbeable
toencodethesedependencies.
JointSyntactic–SemanticFeatures.Thisclassoffeaturesissimilartothewholelabel
sequencefeatures,butinadditiontolabelsofargumentnodes,itincludessyntactic
featuresofthenodes.Thesefeaturescancapturethejointmappingfromthesyntactic
realizationofthepredicate’sargumentstoitssemanticframe.Theideaofthesefeatures
istocaptureknowledgeaboutthelabelofaconstituentgiventhesyntacticrealization
andlabelsofallotherargumentsoftheverb.Thisishelpfulincapturingsyntactic
alternations,suchasthedativealternation.Forexample,considerthesentence(i)[Shaw
Publishing]
ARG0
[offered]
PRED
[Mr.Smith]
ARG2
[areimbursement]
ARG1
andthealternativere-
alization(ii)[ShawPublishing]
ARG0
[offered]
PRED
[areimbursement]
ARG1
[toMr.Smith]
ARG2
.
180
Toutanova,Haghighi,andManning AGlobalJointModelforSRL
WhenclassifyingtheNPinobjectposition,itisusefultoknowwhetherthefollowing
argumentisaPP.Ifitis,theNPwillmorelikelybeanARG1,andifnot,itwillmore
likelybeanARG2.Afeaturetemplatethatcapturessuchinformationextracts,foreach
candidateargumentnode,itsphrasetypeandlabel.Forexample,theinstantiationsof
suchtemplatesin(ii),includingonlythepredicatevoiceoralsothepredicatelemma,
wouldbe:
[voice:active,NP-ARG0,PRED,NP-ARG1,PP-ARG2]
[voice:active,lemma:offer,NP-ARG0,PRED,NP-ARG1,PP-ARG2]
We experimented withextracting several kinds of features fromeach argument
nodeandfoundthatthephrasetypeandtheheadofadirectlydominatingPP—ifone
exists—weremosthelpful.
Local models normally consider only features of the phrase being classiﬁed in
additiontofeaturesofthepredicate.Theycannottakeintoaccountthefeaturesofother
argumentnodes,becausetheyareonlygiventheinput(parsetree),andtheidentityof
theargumentnodesisunknown.Itisconceivablethatalocalmodelcouldconditionon
thefeaturesofallnodesinthetreebutthenumberofparameters(features)wouldbe
extremelylarge.Thejointsyntactic–semanticfeaturesproposedhereencodeimportant
dependenciesusingaverysmallnumberofparameters,aswewillshowinSection5.4.
WeshouldnotethatXueandPalmer(2004)deﬁneasimilarfeaturetemplate,called
syntacticframe,whichoftencapturessimilarinformation.Theimportantdifferenceis
thattheirtemplateextractscontextualinformationfromnounphrasessurroundingthe
predicate,ratherthanfromthesequenceofargumentnodes.Becauseweuseajoint
model,weareabletouseinformationaboutotherargumentnodeswhenlabelinga
node.
RepetitionFeatures.Wealsoaddfeaturesthatdetectrepetitionsofthesamelabelin
acandidateargumentsequence,togetherwiththephrasetypesofthenodeslabeled
withthatlabel.Forexample,(NP-ARG0,WHNP-ARG0)isacommonpatternofthisform.
Variantsofthisfeaturetemplatealsoindicatewhetherallrepeatedargumentsaresisters
intheparsetree,orwhetherallrepeatedargumentsareadjacentintermsofwordspans.
Thesefeaturescanproviderobustnesstoparsererrors,makingitmorelikelytoassign
thesamelabeltoadjacentphrasesthatmayhavebeenincorrectlysplitbytheparser.In
Section5.4wereportresultsfromthejointmodelandanablationstudytodetermine
thecontributionofeachofthetypesofjointfeatures.
5.3ApplyingJointModelsinTesting
Herewedescribetheapplicationintestingofajointmodelforsemanticrolelabeling,
usingalocalmodelP
lscript
SRL
andajointre-rankingmodelP
r
SRL
.ThelocalmodelP
lscript
SRL
isused
togenerateNnon-overlappingjointassignmentsL
1,...,L
N
.
OneoptionistoselectthebestL
i
accordingtoP
r
SRL,asinEquation(3),ignoringthe
scorefromthelocalmodel.Inourexperiments,wenoticedthatforlargervaluesofN,
theperformanceofourre-rankingmodelP
r
SRL
decreased.Thiswasprobablyduetothe
factthatattesttimethelocalclassiﬁerproducesverypoorargumentframesnearthe
bottomofthetop n forlarge n.Becausethere-rankingmodelistrainedonrelatively
181
ComputationalLinguistics Volume34,Number2
fewgoodargumentframes,itcannoteasilyruleoutverybadframes.Itmakessense
thentoincorporatethelocalmodelintoourﬁnalscore.Ourﬁnalscoreisgivenby:
P
SRL
(L|t,v)=(P
lscript
SRL
(L|t,v))
α
P
r
SRL
(L|t,v)
whereαisatunableparameterdeterminingtheamountofinﬂuencethelocalscorehas
ontheﬁnalscore(wefoundα =1.0toworkbest).Suchinterpolationwithascorefrom
aﬁrst-passmodelwasalsousedforparsere-rankingin(Collins2000).Giventhisscore,
attesttimewechooseamongthetopnlocalassignmentsL
1,...,L
n
accordingto:
argmax
L∈L
1,...,L
n
αlogP
lscript
SRL
(L|t,v)+logP
r
SRL
(L|t,v)(4)
5.4JointModelResults
Wecomparetheperformanceofjointre-rankingmodelsandlocalmodels.Weused
n=10jointassignmentsfortrainingre-rankingmodels,and n=15fortesting.The
weightαofthelocalmodelwassetto1.Usingdifferentnumbersofjointassignments
intrainingandtestingisingeneralnotideal,butduetomemoryrequirements,we
couldnotexperimentwithlargervaluesofnfortraining.
Figure10showsthesummaryperformanceofthelocalmodel(LOCAL),repeated
fromearlierﬁgures,ajointmodelusingonlylocalfeatures(JOINTLOCAL),ajointmodel
usinglocal+wholelabelsequencefeatures(LABELSEQ),andajointmodelusingall
describedtypesoffeatures(ALLJOINT).Theevaluationisongold-standardparsetrees.
Inadditiontoperformancemeasures,theﬁgureshowsthenumberofbinaryfeatures
includedinthemodel.Thenumberoffeaturesisameasureofthecomplexityofthe
hypothesisspaceoftheparametricmodel.
Wecanseethatajointmodelusingonlylocalfeaturesoutperformsalocalmodel
by.5pointsofF-Measure.Thejointmodelusinglocalfeaturesestimatesthefeature
weightsonlyusingthetopnconsistentassignments,thusmakingthelabelsofdifferent
nodesnon-independentaccordingtotheestimationprocedure,whichmaybeacause
oftheimprovedperformance.AnotherfactorcouldbethatthemodelJOINTLOCALisa
combinationoftwomodelsasspeciﬁedinEquation(4),whichmayleadtogains(asis
usualforclassiﬁercombination).
ThelabelsequencefeaturesaddedinModelLABELSEQresultinanother1.5points
jumpinF-Measureonallarguments.Anadditional.8gainresultsfromtheinclusion
ofsyntactic–semanticandrepetitionfeatures.TheerrorreductionofmodelALLJOINT
Figure10
PerformanceoflocalandjointmodelsonID&CLSonSection23,usinggold-standardparsetrees.
Thenumberoffeaturesofeachmodelisshowninthousands.
182
Toutanova,Haghighi,andManning AGlobalJointModelforSRL
overthelocalmodelis36.8%in COREargumentsF-Measure,33.3%in COREarguments
wholeframeaccuracy,24.1%in ALLargumentsF-Measure,and21.7%in ALLarguments
whole frame accuracy. All differences in ALL arguments F-Measure are statistically
signiﬁcantaccordingtoapairedWilcoxonsignedranktest.JOINTLOCALissigniﬁcantly
betterthan LOCAL (p < .001), LABELSEQissigniﬁcantlybetterthan JOINTLOCAL(p <
.001),andALLJOINTissigniﬁcantlybetterthanLABELSEQ(p<.001).Weperformedthe
Wilcoxonsignedranktestonper-propositionALLargumentsF-Measureforallmodels.
Wealsonotethatthejointmodelshavefewerfeaturesthanthelocalmodel.Thisis
duetothefactthatthelocalmodelhasseenmanymorenegativeexamplesandtherefore
moreuniquefeatures.Thejointfeaturesarenotverynumerouscomparedtothelocal
featuresinthejointmodels.TheALLJOINTmodelhasaround30%morefeaturesthan
theJOINTLOCALmodel.
Theseexperimentsshowedthatthelabelsequencefeatureswereveryuseful,es-
pecially on CORE arguments, increasing the F-Measure on these arguments by two
points when added to the JOINTLOCAL model. This shows that even though the
local model is optimized to use a large set of features and achieve state-of-the-art
performance,itisstilladvantageoustomodelthejointinformationinthesequence
oflabelsinapredicate’sargumentframe.Additionally,thejointsyntactic–semantic
featuresimprovedperformancefurther,showingthatwhenpredictingthelabelofan
argument,itisusefultoconditiononthefeaturesofotherarguments,inadditionto
theirlabels.
A more detailed analysis of the results obtained by the joint model ALLJOINT
is given in Figure 11(a) (Summary results), and the two confusion matrices in Fig-
ures11(b)and11(c),whichdisplaythenumberoferrorsofeachtypethatthemodel
made. The ﬁrst confusion matrix concentrates on CORE arguments and merges all
modifying argument labels into a single ARGM label. The second confusion matrix
concentratesonconfusionsamongmodifyingarguments.Thisﬁgurecanbecompared
toFigure7,whichsummarizestheresultsforthelocalmodelinthesameform.The
biggestdifferencesareintheperformanceonCOREarguments,whichcanbeseenby
comparingtheconfusionmatricesinFigures7(b)and11(b).TheF-Measureoneach
ofthecoreargumentlabelshasincreasedbyatleastthreepoints:theF-Measureon
ARG2 by5.7points,andtheF-Measureon ARG3 byeightpoints.Theconfusionsof
core argument labels with NONE have gone down signiﬁcantly, and also there is a
largedecreaseintheconfusionsofNONEwithARG1.Thereisgenerallyaslightincrease
inF-Measureonmodiﬁerlabelsaswell,buttheperformanceonsomeofthemodiﬁer
labels has gone down. This makes sense because our joint features are targeted at
capturingthedependenciesamongcorearguments.Theremaybeusefulregularities
formodiﬁerargumentsaswell,butcapturingthemmayrequiredifferentjointfeature
templates.
Figure12liststhefrequencywithwhicheachofthetop k assignmentsfromthe
LOCAL model was ranked ﬁrst by the re-ranking model ALLJOINT.For example, for
84.1%ofthepropositions,there-rankingmodelchosethesameassignmentthatthe
LOCALmodelwouldhavechosen.ThesecondbestassignmentaccordingtotheLOCAL
modelwaspromotedtoﬁrst8.6%ofthetime.Theﬁgureshowsstatisticsforthetopten
assignmentsonly.Therestoftheassignments,ranked11through15,werechosenas
bestbythere-rankingmodelforatotalof0.3%ofthepropositions.
The labeling of the tree in Figure 9 is a speciﬁc example of the kind of errors
ﬁxedbythejointmodels.Thelocalclassiﬁerlabeledtheﬁrstargumentinthetreeas
ARG0insteadof ARG1,probablybecausean ARG0labelismorelikelyforthesubject
position.
183
ComputationalLinguistics Volume34,Number2
6.SemanticRoleLabelingofAutomaticParses
Wenowevaluateourmodelswhentrainedandtestedusingautomaticparsesproduced
byCharniak’sparser.ThePropbanktrainingsetSections2–21isalsothetrainingsetof
theparser.Theperformanceoftheparseristhereforebetteronthetrainingset.Whenthe
constituentsofanargumentdonothavecorrespondingconstituentsinanautomatically
producedparsetree,itwillbeveryhardforamodeltogetthesemanticrolelabeling
correct.However,thisisnotimpossibleandsystemswhicharemorerobusttoparser
errorhavebeenproposed(Pradhanetal.2005;M`arquezetal.2005).Oursystemcanalso
theoreticallyguessthecorrectsetofwordsbylabelingasetofconstituentsthatcover
Figure11
Performancemeasuresforjointmodelusingallfeatures(AllJoint).ResultsareonSection23
usinggold-standardparsetrees.
Figure12
PercentageoftestsetpropositionsforwhicheachofthetoptenassignmentsfromtheLocal
modelwasselectedasbestbythejointmodelAllJoint.
184
Toutanova,Haghighi,andManning AGlobalJointModelforSRL
Figure13
PercentageofargumentconstituentsthatarenotpresentintheautomaticparsesofCharniak’s
parser.ConstituentsshowsthepercentageofmissingconstituentsandPropositionsshowsthe
percentageofpropositionsthathavemissingconstituents.
theargumentwords,butwefoundthatthisrarelyhappensinpractice.Figure13shows
thepercentageofargumentconstituentsthataremissingintheautomaticparsetrees
producedbyCharniak’sparser.Wecanseethatthepercentageofmissingconstituents
isquitehigh.
WereportlocalandjointmodelresultsinFigures14(a)and14(b),respectively.As
forgold-standardparses,wetestonallargumentsregardlessofwhethertheycorre-
spondtoconstituentsthathavebeenrecoveredbytheparserandusethesamemeasures
detailedinSection3.2.Wealsocomparetheconfusionmatricesforthelocalandjoint
models,ignoringtheconfusionsamongmodiﬁerargumentlabels(COARSEARGMsetting)
inFigure15.Theerrorreductionofthejointoverthelocalmodelis10.3%in CORE
argumentsF-Measureand8.3%in ALLargumentsF-Measure.
6.1UsingMultipleAutomaticParseGuesses
Semanticrolelabelingisverysensitivetothecorrectnessofthegivenparsetree,asthe
resultsshow.Ifanargumentdoesnotcorrespondtoanyconstituentinaparsetree,or
aconstituentexistsbutisnotattachedorlabeledcorrectly,ourmodelwillhaveavery
hardtimeguessingthecorrectlabeling.
Thus,ifthesyntacticparsermakeserrors,theseerrorsinﬂuencedirectlytheseman-
ticrolelabelingsystem.Thetheoreticallycorrectwaytopropagatetheuncertaintyof
thesyntacticparseristoconsider(sumover)multiplepossibleparsetrees,weightedby
theirlikelihood.InFinkel,Manning,andNg(2006),thisisapproximatedbysampling
Figure14
ComparisonoflocalandjointmodelresultsonSection23usingChaniak’sautomaticparser.
185
ComputationalLinguistics Volume34,Number2
Figure15
COARSEARGMargumentconfusionmatricesforlocalandjointmodelusingCharniak’s
automaticparses.
parsetrees.Weimplementthisideabyanargmaxapproximation,usingthetopkparse
treesfromtheparserofCharniak(2000).
Weusethesealternativeparsesasfollows:Supposet
1,...,t
k
aretreesforsentence
swithprobabilitiesP(t
i
|s)givenbytheparser.Thenforaﬁxedpredicatev,letL
i
denote
thebestjointlabelingoftree t
i,withscore score
SRL
(L
i
|t
i
)accordingtoourﬁnaljoint
model.ThenwechoosethelabelingLwhichmaximizes
argmax
i∈{1,...,k}
βlogP(t
i
|S)+score
SRL
(L
i
|t
i
)
Thismethodofusingmultipleparsetreesisverysimpletoimplementandfactors
intheuncertaintyoftheparsertosomeextent.However,accordingtothismethod(due
totheargmaxoperation)wearechoosingasingleparseandacompletesemanticframe
derivedfromthatparse.Othermethodsareabletoderivedifferentargumentsofthe
semanticframefromdifferentsyntacticannotationswhichmaymakethemmorerobust
(M`arquezetal.2005;Pradhan,Wardetal.2005;Punyakanok,Roth,andYih2005).
Figure16showssummaryresultsforthetestsetwhenusingthetoptenparsesand
thejointmodel.Theweightingparameterfortheparserprobabilitieswasβ =1.Wedid
notexperimentextensivelywithdifferentvaluesofβ.Preliminaryexperimentsshowed
thatconsidering15parseswasabitbetter,andconsideringthetop20wasabitworse.
6.2EvaluationontheCoNLL2005SharedTask
TheCoNLL2005dataisderivedfromPropbankversionI,whichistheﬁrstofﬁcial
releasein2005,whereastheresultswehavebeenreportingintheprevioussectionsused
thepre-ﬁnalFebruary2004data.UsingtheCoNLL2005evaluationstandardensures
that results obtained by different groups are evaluated in exactly the same way. In
186
Toutanova,Haghighi,andManning AGlobalJointModelforSRL
Figure16
PerformanceofthejointmodelusingthetoptenparsesfromCharniak’sparser.Resultsareon
Section23.
PropbankI,therehavebeenseveralchangesintheannotationconventions,aswellas
errorﬁxesandadditionofnewpropositions.TherewasalsoachangeinthewayPP
argumentsareannotated:IntheFebruary2004datasomePPargumentsareannotated
attheheadNPchild,butinPropbankIallPPargumentsareannotatedatthePPnodes.
Inordertoachievemaximalperformancewithrespecttotheseannotations,itwould
probablybebesttochangethefeaturedeﬁnitionstoaccountforthechanges.However,
wedidnoadaptationofthefeatures.
ThetrainingsetconsistsoftheannotationsinSections2to21,thedevelopmentset
issection24(Devset),andoneofthetestsetsissection23(TestWSJ).Theothertestset
isfromtheBrowncorpus(TestBrown).TheCoNLLannotationsdistinguishreferring
arguments,oftheformR-ARGX,asdiscussedinSection3.
Ourapproachtodealingwithreferringargumentsanddecidingwhenmultiple
identicallylabeledconstituentsarepartofthesameargumentwastolabelconstituents
withonlythesetofargumentlabelsand NONEandthenmapsomeoftheselabels
into referring or continuation labels. We converted an ARGX into a R-ARGX if and
onlyifthelabeloftheconstituentbeganwith“WH”.Therulefordecidingwhento
addcontinuationlabelswasthesameasforoursystemsfortheFebruary2004data
describedinSection4.3:Aconstituentlabelbecomescontinuingifandonlyifitisa
coreargumentlabelandthereisanotherconstituentwiththesamecoreargumentlabel
totheleft.Therefore,fortheCoNLL2005sharedtaskweemploythesamesemantic
rolelabelingsystem,justusingadifferentpost-processingruletomaptoCoNLL-style
labelingsofsetsofwords.
Wetestedtheupperboundinperformanceduetoourconversionschemeinthe
followingway:Takethegold-standardCoNLLannotationsforthedevelopmentset
(includingreferringandcontinuinglabels),convertthesetobasicargumentlabelsofthe
formARGX,thenconverttheresultinglabelingtoCoNLL-stylelabelingusingourrules
torecoverthereferringandcontinuingannotations.TheF-Measureobtainedwas99.0.
Figure17showstheperformanceofthelocalandjointmodelononeoftheCoNLL
testsets—TestWSJ(Section23)—whenusinggold-standardparsetrees.Performance
ongold-standardparsetreeswasnotmeasuredintheCoNLL2005sharedtask,butwe
reportitheretoprovideabasisforcomparisonwiththeresultsofotherresearchers.
Figure17
ResultsontheCoNLLWSJTestset,whenusinggold-standardparsetrees.
187
ComputationalLinguistics Volume34,Number2
Figure18
ResultsontheCoNLLdataset,whenusingCharniakautomaticparsetreesasprovidedinthe
CoNLL2005sharedtaskdata.
Figure19
ResultsontheCoNLLdataset,usingautomaticparsetreesfromtheMay2005versionofthe
Charniakparserwithcorrecttreatmentofforwardquotes.
NextwepresentresultsusingCharniak’sautomaticparsesonthedevelopment
andtwotestsets.Wepresentresultsforthelocalandjointmodelsusingthemax-
scoringCharniakparsetree.Additionally,wereportresultsforthejointmodelusing
thetopﬁveCharniakparsetreesaccordingtothealgorithmdescribedinSection6.1.
Theperformancemeasuresreportedherearehigherthantheresultsofoursubmission
intheCoNLL2005sharedtask(Haghighi,Toutanova,andManning2005),becauseof
twochanges.Onewaschangingtherulethatproducescontinuingargumentstoonly
addcontinuationlabelstocoreargumentlabels;inthepreviousversiontheruleadded
continuation labels to all repeated labels. Another was ﬁxing a bug in the way the
sentenceswerepassedinasinputtoCharniak’sparser,leadingtoincorrectanalyses
offorwardquotes.
8
Weﬁrstpresentresultsofourlocalandjointmodelusingtheparsesprovidedas
partoftheCoNLL2005data(andhavingwrongforwardquotes)inFigure18.We
thenreportresultsfromthesamelocalandjointmodel,andthejointmodelusingthe
topﬁveCharniakparses,wheretheparseshavecorrectrepresentationoftheforward
quotesinFigure19.FortheseresultsweusedtheversionoftheCharniakparserfrom
4May2005.Theresultswereverysimilartotheresultsweobtainedwiththeversion
from18March2005.Wedidnotexperimentwiththenewre-rankingmodelofCharniak
andJohnson(2005),eventhoughitimprovesuponCharniak(2000)signiﬁcantly.
Forcomparison,thesystemwesubmittedtoCoNLL2005hadanF-Measureof
78.45ontheWSJTestset.Thewinningsystem(Punyakanok,Roth,andYih2005)had
anF-Measureof79.44andourcurrentsystemhasanF-Measureof80.32.FortheBrown
Testset,oursubmittedversionhadanF-Measureof67.71,thewinningsystemhad
67.75,andourcurrentsystemhas68.81.
Figure20showstheper-labelperformanceofourjointmodelusingthetopﬁve
CharniakparsetreesontheTestWSJtestset.ThecolumnsshowthePrecision,Recall,
F-Measure,andthetotalnumberofargumentsforeachlabel.
8 TheCharniakparsesprovidedaspartoftheCoNLLsharedtaskdatauniformlyignorethedistinction
betweenforwardandbackwardquotesandallquotesarebackward.Were-rantheparserandobtained
analyseswithcorrecttreatmentofquotes.
188
Toutanova,Haghighi,andManning AGlobalJointModelforSRL
7.Conclusions
Inaccordwithstandardlinguisticassumptions,wehaveshownthattherearesub-
stantial gains to be had by jointly modeling the argument frames of verbs. This is
especiallytruewhenwemodelthedependencieswithdiscriminativemodelscapable
ofincorporatingnon-localfeatures.Weincorporatedjointinformationbyusingtwo
typesoffeatures:featuresofthecompletesequenceofargumentlabelsandfeatures
modelingdependenciesbetweenthelabelsofargumentsandsyntacticfeaturesofother
arguments.Weshowedthatbothtypesoffeaturesyieldedsigniﬁcantperformancegains
overastate-of-the-artlocalmodel.
Forfurtherimprovingperformanceinthepresenceofperfectsyntacticparses,we
seeatleastthreepromisingavenuesforimprovement.First,onecouldimprovethe
identiﬁcationofargumentnodes,bybetterhandlingoflong-distancedependencies;for
example,byincorporatingmodelswhichrecoverthetraceandnullelementinformation
inPennTreebankparsetrees,asinLevyandManning(2004).Second,itmaybepossible
toimprovetheaccuracyonmodiﬁerlabels,byenhancingtheknowledgeaboutthe
semanticcharacteristicsofspeciﬁcwordsandphrases,suchasbyimprovinglexical
statistics;forinstance,ourperformanceonARGM-TMProlesisratherworsethanthat
of some other groups. Finally, it is worth exploring alternative handling of multi-
constituentarguments;ourcurrentmodelusesasimpleruleinapost-processingstep
Figure20
Per-labelperformanceofjointmodelusingthetopﬁveCharniakautomaticparsetreesonthe
TestWSJtestset.
189
ComputationalLinguistics Volume34,Number2
todecidewhichconstituentsgiventhesamelabelarepartofthesameargument.This
couldbedonemoreintelligentlybythemachinelearningmodel.
Becauseperfectsyntacticparsersdonotyetexistandthemajorbottlenecktothe
performanceofcurrentsemanticrolelabelingsystemsissyntacticparserperformance,
themoreimportantquestionishowtoimproveperformanceinthepresenceofparser
errors.Weexploredasimpleapproachofchoosingfromamongthetopkparsesfrom
Charniak’sparser,whichresultedinanimprovement.Othermethodshavealsobeen
proposed,aswediscussedinSection2(M`arquezetal.2005;Pradhan,Wardetal.2005;
Punyakanok,Roth,andYih2005;YiandPalmer2005;Finkel,Manning,andNg2006).
Thisisaverypromisinglineofresearch.
Acknowledgments
Thisresearchwascarriedoutwhileallthe
authorswereatStanfordUniversity.We
thankthejournalreviewersandthe
reviewersandaudienceatACL2005and
CoNLL2005fortheirhelpfulcomments.We
alsothankDanJurafskyforhisinsightful
commentsandusefuldiscussions.Thiswork
wassupportedinpartbytheDisruptive
TechnologyOrganization(DTO)’sAdvanced
QuestionAnsweringforIntelligence
(AQUAINT)Program.
References
Baker,Collin,CharlesFillmore,andJohn
Lowe.1998.TheBerkeleyFramenet
project.InProceedingsofCOLING-ACL,
pages86–90,SanFrancisco,CA.
Carreras,XavierandLu´ısM`arquez.2004.
IntroductiontotheCoNLL-2004shared
task:Semanticrolelabeling.InProceedings
of CoNLL,pages89–97,Boston,MA.
Carreras,XavierandLu´ısM`arquez.2005.
IntroductiontotheCoNLL-2005shared
task:Semanticrolelabeling.InProceedings
of CoNLL,pages152–164,AnnArbor,MI.
Charniak,Eugene.2000.A
maximum-entropy-inspiredparser.In
Proceedingsof NAACL,pages132–139,
Seattle,WA.
Charniak,EugeneandMarkJohnson.2005.
Coarse-to-ﬁnen-bestparsingandMaxEnt
discriminativereranking.InProceedingsof
ACL,pages173–180,AnnArbor,MI.
Cohn,TrevorandPhilipBlunsom.2005.
Semanticrolelabellingwithtree
conditionalrandomﬁelds.InProceedingsof
CoNLL,pages169–172,AnnArbor,MI.
Collins,Michael.2000.Discriminative
rerankingfornaturallanguageparsing.
InProceedingsofICML,pages175–182,
Stanford,CA.
Finkel,Jenny,ChristopherManning,and
AndrewNg.2006.Solvingtheproblemof
cascadingerrors:Approximatebayesian
inferenceforlinguisticannotation
pipelines.InProceedingsofEMNLP,
pages618–626,Sydney,Australia.
Gildea,DanielandDanielJurafsky.2002.
Automaticlabelingofsemanticroles.
Computational Linguistics,28(3):245–288.
Hacioglu,Kadri.2004.Alightweight
semanticchunkingmodelbasedon
tagging.InProceedingsofHLT-NAACL:
Short Papers,pages145–148,Boston,MA.
Haghighi,Aria,KristinaToutanova,and
ChristopherD.Manning.2005.Ajoint
modelforsemanticrolelabeling.In
Proceedingsof CoNLL,pages173–176,
AnnArbor,MI.
Lafferty,John,AndrewMcCallum,and
FernandoPereira.2001.Conditional
randomﬁelds:Probabilisticmodelsfor
segmentingandlabelingsequencedata.
InProceedingsofICML,pages282–289,
Williamstown,MA.
Levy,RogerandChrisManning.2004.
Deepdependenciesfromcontext-free
statisticalparsers:correctingthe
surfacedependencyapproximation.
InProceedingsofACL,pages327–334,
Barcelona,Spain.
M`arquez,Lu´ıs,MihaiSurdeanu,Pere
Comas,andJordiTurmo.2005.Arobust
combinationstrategyforsemanticrole
labeling.InProceedingsofEMNLP,
pages644–651,Vancouver,Canada.
McCallum,Andrew,DayneFreitag,and
FernandoPereira.2000.Maximumentropy
Markovmodelsforinformationextraction
andsegmentation.InProceedingsof ICML,
pages591–598,Stanford,CA.
Palmer,Martha,DanGildea,andPaul
Kingsbury.2005.Thepropositionbank:
Anannotatedcorpusofsemantic
roles.ComputationalLinguistics,
31(1):71–105.
Pradhan,Sameer,KadriHacioglu,Valerie
Krugler,WayneWard,JamesMartin,
andDanJurafsky.2005.Support
vectorlearningforsemanticargument
190
Toutanova,Haghighi,andManning AGlobalJointModelforSRL
classiﬁcation.Machine LearningJournal,
60(1):11–39.
Pradhan,Sameer,WayneWard,Kadri
Hacioglu,JamesMartin,andDan
Jurafsky.2004.Shallowsemanticparsing
usingsupportvectormachines.In
ProceedingsofHLT-NAACL,pages233–240,
Boston,MA.
Pradhan,Sameer,WayneWard,Kadri
Hacioglu,JamesMartin,andDaniel
Jurafsky.2005.Semanticrolelabelingusing
differentsyntacticviews.InProceedingsof
ACL,pages581–588,AnnArbor,MI.
Punyakanok,VasinandDanRoth.2001.The
useofclassiﬁersinsequentialinference.
InProceedingsof NIPS,pages995–1001,
Vancouver,Canada.
Punyakanok,Vasin,DanRoth,andWen-tau
Yih.2005.Thenecessityofsyntactic
parsingforsemanticrolelabeling.In
ProceedingsofIJCAI,pages1117–1123,
Acapulco,Mexico.
Punyakanok,Vasin,DanRoth,Wen-tauYih,
DavZimak,andYuanchengTu.2004.
Semanticrolelabelingviageneralized
inferenceoverclassiﬁers.InProceedings
of CoNLL,pages130–133,Boston,MA.
Roland,DouglasandDanielJurafsky.2002.
Verbsenseandverbsubcategorization
probabilities.InPaolaMerloand
SuzanneStevenson,editors,TheLexical
BasisofSentenceProcessing:Formal,
Computational,and Experimental
Issues.JohnBenjamins,Amsterdam,
pages325–345.
Sha,FeiandFernandoPereira.2003.
Shallowparsingwithconditional
randomﬁelds.InProceedingsof
HLT-NAACL,pages134–141,
Edmonton,Canada.
Surdeanu,Mihai,SandaHarabagiu,
JohnWilliams,andPaulAarseth.
2003.Usingpredicate-argument
structuresforinformationextraction.
InProceedingsof ACL,pages8–15,
Sapporo,Japan.
Xue,NianwenandMarthaPalmer.2004.
Calibratingfeaturesforsemanticrole
labeling.InProceedingsof EMNLP,
pages88–94,Barcelona,Spain.
Yi,Szu-tingandMarthaPalmer.2005.The
integrationofsyntacticparsingand
semanticrolelabeling.InProceedingsof
CoNLL,pages237–240,AnnArbor,MI.
191


