Other approaches combine lattices or N-best lists from several different MT systems (Frederking and Nirenburg, 1994).
A94-1016
The model parameters are trained iteratively in an unsupervised manner with the EM algorithm using the GIZA++ toolkit (Och and Ney, 2003).
J03-1002
The selection is made based on the scores of translation, language, and other models (Nomoto, 2004; Paul et al., 2005).
P04-1063
The final alignments are determined using cost matrices defined by the state occupation probabilities of the trained HMM (Matusov et al., 2004).
C04-1032
We use the IBM Model 1 (Brown et al., 1993) (uniform distribution) and the Hidden Markov Model (HMM, first-order dependency, (Vogel et al., 1996)) to estimate the alignment model.
C96-2141 J93-2003
Criteria Well-established objective evaluation measures like the word error rate (WER), positionindependent word error rate (PER), and the BLEU score (Papineni et al., 2002) were used to assess the translation quality.
P02-1040
