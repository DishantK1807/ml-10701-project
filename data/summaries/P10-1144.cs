dence by Stoyanov et al. (2009) that differences in
P09-1074
• CEAF (Luo, 2005). It finds the best one-to-
H05-1004 H05-1083
Aria Haghighi and Dan Klein. 2009. Simple coref-
D09-1120
Eric Bengtson and Dan Roth. 2008. Understanding
D08-1031
Xiaoqiang Luo. 2005. On coreference resolution
H05-1004 H05-1083
Haghighi and Klein, 2009; Ng, 2009). It is not our
D09-1120 N09-1065
Hoifung Poon and Pedro Domingos. 2008. Joint unsu-
D08-1068
but following Ng and Cardie (2002)’s best
P02-1014
(2002) and Luo et al. (2004) to generate most
P04-1018
10STRONG and WEAK MATCH are similar to Luo et al.(2004)’s entity-mention and mention-pair models.
P04-1018
as zero subjects (Recasens and Hovy, 2009).
W09-2411
ent) entity (van Deemter and Kibble, 2000). Fi-
J00-4005
We follow Soon et al. (2001), Ng and Cardie
J01-4004
Kees van Deemter and Rodger Kibble. 2000. On core-
J00-4005
(Hall et al., 2007).
D07-1097
definition (van Deemter and Kibble, 2000), the
J00-4005
oped in the past (Culotta et al., 2007; Finkel
N07-1011
and Manning, 2008; Poon and Domingos, 2008;
D08-1068
• MUC (Vilain et al., 1995). It computes the
M95-1005
the ACE program (Luo and Zitouni, 2005), prob-
H05-1004 H05-1083
Xiaoqiang Luo and Imed Zitouni. 2005. Multi-lingual
H05-1004 H05-1083
Taku Kudoh and Yuji Matsumoto. 2000. Use of sup-
W00-0730
Thorsten Brants. 2000. TnT – A statistical part-of-
A00-1031
Bengtson and Roth, 2008) but combines them si-
D08-1031
Soon et al. (2001)’s first-link approach.
J01-4004
Marta Recasens and Eduard Hovy. 2009. A
W09-2411
2008; Haghighi and Klein, 2009). Testing on both
D09-1120
classification and clustering (Soon et al., 2001;
J01-4004
al., 2007; Bengtson and Roth, 2008; Denis and
D08-1031
Vincent Ng. 2009. Graph-cut-based anaphoricity de-
N09-1065
Vincent Ng and Claire Cardie. 2002. Improving
P02-1014
Marta Recasens and M. Ant`onia Mart´ı. 2009. AnCora-
W09-2411
chunker (Kudoh and Matsumoto, 2000), and parse
W00-0730
(Brants, 2000), and with the built-in WordNet lem-
A00-1031
