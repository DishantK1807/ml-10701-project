<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>Yehoshua Bar-Hilel</author>
</authors>
<title>The Present Status of Automatic Translation of Languages. Advances in Computers. Engelberg, Stefan and Lothar Lemnitzer (204). Lexikographie und Wörterbuchbenutzung</title>
<date>1960</date>
<journal>Staufenburg-Verlag, Tübingen. Gabrilovich, Evgeniy, and Shaul Markovitch</journal>
<booktitle>In Procedings of the 21st National Conference on Artificial Inteligence</booktitle>
<contexts>
<context>us data, and provide world knowledge that is mising in corpora. Dictionary and encyclopaedic knowledge resources have a long history as semantic resources, from the early days in machine translation (Bar-Hilel, 1960), aproaches to word sense disambiguation (Lesk, 1986), and more recently –relying on Wikipedia– in NLP tasks such as text categorisation (Gabrilovich and Markovitch, 206), word sense disambiguation (</context>
</contexts>
<marker>Bar-Hilel, 1960</marker>
<rawString>Bar-Hilel, Yehoshua (1960). The Present Status of Automatic Translation of Languages. Advances in Computers. Engelberg, Stefan and Lothar Lemnitzer (204). Lexikographie und Wörterbuchbenutzung. Staufenburg-Verlag, Tübingen. Gabrilovich, Evgeniy, and Shaul Markovitch (206). Overcoming the Britlenes Botleneck using Wikipedia: Enhancing Text Categorization with Encyclopedic Knowledge. In Procedings of the 21st National Conference on Artificial Inteligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zelig Haris</author>
</authors>
<title>Distributional Structure</title>
<date>1968</date>
<journal>In Jerold J. Katz (Eds.), The Philosophy of Linguistics</journal>
<pages>26--47</pages>
<institution>Oxford University Pres</institution>
<contexts>
<context>ocuments. Folowing the distributional hypothesis, namely that ‘each language can be described in terms of a distributional structure, i.e., in terms of the ocurence of parts relative to other parts’ (Haris, 1968), distributional, corpus-based descriptions have frequently ben aplied to model aspects of word meaning. For example, variants of the vector space model (Salton et al., 1975) that uses words in docum</context>
</contexts>
<marker>Haris, 1968</marker>
<rawString>Haris, Zelig (1968). Distributional Structure. In Jerold J. Katz (Eds.), The Philosophy of Linguistics, p. 26-47. Oxford University Pres.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Lesk</author>
</authors>
<title>Automatic Sense Disambiguation using Machine Readable Dictionaries: How to tel a Pine Cone from an Ice Cream Cone</title>
<date>1986</date>
<journal>Journal of Artificial Inteligence Research</journal>
<booktitle>In Procedings of the SIGDOC</booktitle>
<tech>Ph.D. thesis</tech>
<volume>30</volume>
<institution>Stockholm University</institution>
<location>Lund, Kevin, Curt</location>
<contexts>
<context>pora. Dictionary and encyclopaedic knowledge resources have a long history as semantic resources, from the early days in machine translation (Bar-Hilel, 1960), aproaches to word sense disambiguation (Lesk, 1986), and more recently –relying on Wikipedia– in NLP tasks such as text categorisation (Gabrilovich and Markovitch, 206), word sense disambiguation (Mihalcea, 207), and co-reference resolution (Ponzeto </context>
</contexts>
<marker>Lesk, 1986</marker>
<rawString>Lesk, Michael (1986). Automatic Sense Disambiguation using Machine Readable Dictionaries: How to tel a Pine Cone from an Ice Cream Cone. In Procedings of the SIGDOC Conference. Lin, Dekang (198). Automatic Retrieval and Clustering of Similar Words. In Procedings of the 17th Conference on Computational Linguistics. Lowe, Wil, and Scot McDonald (200). The Direct Route: Mediated Priming in Semantic Space. In Procedings of the 2nd Anual Conference of the Cognitive Science Society. Lund, Kevin, Curt Burges, and Ruth An Atchley (195). Semantic and Asociative Priming in High-Dimensional Semantic Space. In Procedings of the 17th Anual Conference of the Cognitive Science Society of America. Melinger, Alisa, and Andrea Weber (206): Database of Noun Asociations for German. URL: htp:/ww.coli.uni-sarland.de/projects/nag/ Mihalcea, Rada (207). Using Wikipedia for Automatic Word Sense Disambiguation. In Procedings of the North American Chapter of the Asociation for Computational Linguistics. Padó, Sebastian, and Mirela Lapata (207). Dependency-based Construction of Semantic Space Models. Computational Linguistics 3(2). Poesio, Masimo, Tomonori Ishikawa, Sabine Schulte im Walde, and Renata Vieira (202). Acquiring Lexical Knowledge for Anaphora Resolution. In Procedings of the 3rd Conference on Language Resources and Evaluation. Ponzeto, Simone Paolo, and Michael Strube (207). Knowledge Derived from Wikipedia For Computing Semantic Relatednes. Journal of Artificial Inteligence Research 30. Sahlgren, Magnus (206). The Word-Space Model: Using Distributional Analysis to Represent Syntagmatic and Paradigmatic Relations betwen Words in High-Dimensional Vector Spaces. Ph.D. thesis. Stockholm University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Salton</author>
<author>Anita Wong</author>
<author>Chung Sue Yang</author>
</authors>
<title>A Vector Space Model for Automatic Indexing. Comunications of the ACM 18(1). Schütze, Hinrich (198). Automatic Word Sense Discrimination. Computational Linguistics. Special Isue on Word Sense Disambiguation. Schulte im alde, Sabine (206). Experiments on the Automatic Induction of German Semantic Verb Clases. Computational Linguistics 32(2). Schulte</title>
<date>1975</date>
<booktitle>An Empirical Characterisation of Response Types in German Asociation Norms. Research on Language and Computation. Schulte im Walde, Sabine, and Alisa Melinger (to apear). An In-Depth Lok into the Co-Ocurence Distribution of Semantic Asociates. Italian Journal of Linguistics. Special Isue on „From Context to Meaning: Distributional Models of the Lexicon in Linguistics and Cognitive Science“. Viglioco, Gabriela, David Vinson, Wiliam Lewis, and Meril Garet (204). Representing the Meanings of Object and Action Words: The Featural and Unitary Semantic Space Hypothesis. Cognitive Psychology 48. Weber, Nico, editor (196). Semantik, Lexikographie und Computeranwendungen. Max Niemeyer Verlag. 7. Apendix This apendix lists the 10</booktitle>
<editor>im Walde, Sabine, Alisa Melinger, Michael Roth, and Andrea Weber (to apear</editor>
<contexts>
<context>f parts relative to other parts’ (Haris, 1968), distributional, corpus-based descriptions have frequently ben aplied to model aspects of word meaning. For example, variants of the vector space model (Salton et al., 1975) that uses words in documents to describe the contents of the respective documents, have ben used in various NLP tasks and aplications including word sense discrimination (Schütze, 198), anaphora res</context>
</contexts>
<marker>Salton, Wong, Yang, 1975</marker>
<rawString>Salton, Gerard, Anita Wong, and Chung Sue Yang (1975). A Vector Space Model for Automatic Indexing. Comunications of the ACM 18(1). Schütze, Hinrich (198). Automatic Word Sense Discrimination. Computational Linguistics. Special Isue on Word Sense Disambiguation. Schulte im alde, Sabine (206). Experiments on the Automatic Induction of German Semantic Verb Clases. Computational Linguistics 32(2). Schulte im Walde, Sabine, Alisa Melinger, Michael Roth, and Andrea Weber (to apear). An Empirical Characterisation of Response Types in German Asociation Norms. Research on Language and Computation. Schulte im Walde, Sabine, and Alisa Melinger (to apear). An In-Depth Lok into the Co-Ocurence Distribution of Semantic Asociates. Italian Journal of Linguistics. Special Isue on „From Context to Meaning: Distributional Models of the Lexicon in Linguistics and Cognitive Science“. Viglioco, Gabriela, David Vinson, Wiliam Lewis, and Meril Garet (204). Representing the Meanings of Object and Action Words: The Featural and Unitary Semantic Space Hypothesis. Cognitive Psychology 48. Weber, Nico, editor (196). Semantik, Lexikographie und Computeranwendungen. Max Niemeyer Verlag. 7. Apendix This apendix lists the 10 strongest stimulus-asociate pairs for each cros-comparison of resources. The pairs are acompanied by the asociation strength (i.e., how often an asociation was provided in response to a certain stimulus; column 1), the part-of-spech of the asociation (column 4), as wel as the frequencies of the stimuli and the asociations within the respective resources (in brackets folowing the stimulus/asociate words).</rawString>
</citation>
</citationList>
</algorithm>

