Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 49–58,
Portland, Oregon, June 17-18, 2011. c©2011 Association for Computational Linguistics
The Impact of Task-Oriented Feature Sets on 
HMMs for Dialogue Modeling 
 
 
Kristy Elizabeth Boyer 
 
Eun Young Ha 
 
Robert Philips* 
 
James Lester 
 
Department of Computer Science 
North Carolina State University 
*Dual afiliation with Applied Research Asociates, Inc. 
Raleigh, North Carolina, USA 
{keboyer, eha, rphilli, lester}@ncsu.edu 
 
 
Abstract 
Human dialogue serves as a valuable model 
for learning the behavior of dialogue systems. 
Hiden Markov models’ sequential structure is 
wel suited to modeling human dialogue, and 
their theoretical underpinnings are consistent 
with the conception of dialogue as a stochastic 
proces with a layer of implicit, highly influen-
tial structure. HMMs have ben shown to be 
effective for a variety of descriptive and pre-
dictive dialogue tasks. For task-oriented dia-
logue, understanding the learning behavior of 
HMMs is an important step toward building 
unsupervised models of human dialogue. This 
paper examines the behavior of HMs under 
six experimental conditions including diferent 
task-oriented feature sets and preprocesing 
approaches. The findings highlight the im-
portance of providing HM learning algo-
rithms with rich task-based information. 
Additionally, the results sugest how specific 
metrics should be used depending on whether 
the models wil be employed primarily in a de-
scriptive or predictive maner. 
1 Introduction

Human dialogue serves as a valuable model for 
learning the behavior of dialogue systems. For this 
reason, corpus-based approaches to dialogue man-
agement tasks have been an increasingly active area 
of research (Bangalore, Di Fabrizio, & Stent, 
2006; Di Eugenio, Xie, & Serafin, 2010; Georgila, 
Lemon, Henderson, & More, 209; Rotaru & 
Litman, 209). Modeling the dialogue policies that 
humans employ permits us to directly extract con-
versational and task-based expertise. These tech-
niques hold great promise for scaling gracefully to 
large corpora, and for transferring wel acros do-
mains.    
The richnes and flexibility of human dialogue 
introduce nondeterministic and complex patterns 
that present challenges for machine learning ap-
proaches. One aproach that has been sucessfuly 
employed in dialogue modeling is the hidden Mar-
kov model (HMM) (Rabiner, 1989). These models 
are well suited to the sequential nature of dialogue 
(Stolcke et al., 200). Moreover, their theoretical 
underpinnings are consistent with the conception of 
dialogue as a stochastic proces whose observations 
are influenced by a layer of implicit, yet highly rel-
evant, structure (Boyer et al., 209; Woszczyna & 
Waibel, 194).  
HMMs have ben shown to perform wel on 
important dialogue management tasks such as au-
tomatic dialogue act clasification (Stolcke et al., 
2000). Our work has employed HMs for a difer-
ent goal: learning dialogue policies, or strategies, 
from corpora (Boyer, Philips, et al., 2010; Boyer, 
Philips, Ingram, et al., in pres). This work can be 
viewed from two perspectives. First, a descriptive 
goal of the work is to learn models that describe the 
nature of human dialogues in succinct probabilistic 
terms, in a way that facilitates important qualitative 
investigations. The second and complementary goal 
is predictive: learning models that acurately pre-
dict the dialogue moves of humans, in order to cap-
ture a dialogue policy that can be used within a 
system.  
49
Both of these goals are of paramount im-
portance in tutorial dialogue, in which tutors and 
students engage in dialogue in suport of a learning 
task (Boyer, Ha, et al., 2010; VanLehn et al., 2007). 
Descriptive modeling represents a critical step to-
ward more fuly understanding the phenomena that 
contribute to the high effectiveness of human tutor-
ing, which has to date ben unmatched by tutorial 
dialogue systems. Predictive models, on the other 
hand, may be used directly as dialogue policies 
within systems.  
The HMs considered here were learned from 
an annotated corpus of textual human-human tuto-
rial dialogue. In this domain, HMs have ben 
shown to corespond qualitatively to widely held 
conceptions of tutorial dialogue strategies, and ad-
jacency pair analysis before model learning has 
been shown to enhance this qualitative correspond-
ence (Boyer et al., 209). Moreover, HMs can 
identify in an unsupervised fashion structural com-
ponents that corelate with student knowledge gain 
(Boyer, Philips, Ingram, et al., in pres).  
However, to date, several important questions 
have not been explored. The answers to these ques-
tions have implications for learning HMs for 
task-oriented dialogues. The questions include the 
folowing: 1) How reliably does the HM learning 
framework converge to the hyperparameter N, the 
best-fit number of hiden states? 2) What are the 
effects of preprocessing approaches, specifically, 
adjacency pair analysis, on the resulting HMs? 
3) How do diferent feature sets for task-oriented 
dialogue impact the descriptive fit and predictive 
power of learned HMMs? This paper addreses 
these questions. The findings suggest that model 
stability and predictive power benefit from the 
richest posible input sequences, which include not 
only dialogue acts but also information about the 
task state and the absence of particular tutor dia-
logue moves. Additionaly, we find that traditional 
measures of HM godnes-of-fit may not identify 
the most highly predictive models under some con-
ditions. 
2 Background

HMMs have ben used for dialogue modeling tasks 
for many years. Early work utilized HMMs to 
model underlying linguistic structure for the pur-
poses of identifying spech acts and reducing per-
plexity for speech recognition (Stolcke et al., 200; 
Woszczyna & Waibel, 194). These projects treat-
ed underlying dialogue structure as the hiden lay-
er, and dialogue utterances as observations. This 
treatment is analogous to the work presented in this 
paper, except that our observations are dialogue act 
tags only, rather than being constituent words in 
each uterance. Our goals are also diferent: to cre-
ate a qualitatively interpretable model of dialogue 
structure that coresponds to widely acepted no-
tions of task-oriented dialogue, and to learn a high-
ly predictive dialogue policy from a human-human 
dialogue corpus. 
HMMs rely on treating dialogue as a sequential 
Markov proces in which each observation depends 
only on a finite set of preceding observations. Some 
other approaches that rely on this assumption treat 
dialogue as a Markov decision proces or partialy 
observable arkov decision proces, in which state 
changes are associated with actions and rewards 
(e.g., Young et al., 2010). Such work focuses on 
learning an optimal policy, typically utilizing a 
combination of human and simulated dialogue cor-
pora. Reinforcement learning techniques can then 
be applied to learn the optimal policy based on the 
observed rewards. In contrast, we start with a rich 
corpus of human-human dialogue, which may have 
poor coverage in some areas (though the dialogue 
act tags were empirically derived and therefore mit-
igate this problem to some extent), and subsequent-
ly learn a model that explains the variance in that 
human corpus as wel as posible. 
Capturing the dialogue policy implicit within a 
corpus of human-human dialogue has been ex-
plored in other work in a catalogue-ordering do-
main (Bangalore, Di Fabrizio, & Stent, 206). 
That work utilized maximum entropy modeling to 
predict human agents’ dialogue moves within a 
vector-based framework. Although a vector-based 
approach difers in many regards from the sequen-
tial HM aproach described here, both aproach-
es assume a dependence only on a finite history. 
HMMs acomplish this through graphical depend-
encies, while vector-based approaches acomplish 
it by including features for a restricted window of 
left-hand context. The results of this catalogue-
ordering project highlight how chalenging it is to 
predict human agents’ dialogue moves in a task-
oriented domain. 
50
3 Corpus

The corpus was colected during a human-human 
tutoring study. Students solved an introductory 
computer programming problem in the Java pro-
graming language. Tutors were located in a sepa-
rate room and comunicated with students through 
textual dialogue while viewing a synchronized 
view of the student’s problem-solving workspace. 
Forty-eight students interacted for approximately 
one hour each with a tutor. Students exhibited sta-
tistically significant learning gains from pretest to 
postest, indicating that the tutoring was efective 
(Boyer, Phillips, Ingram, et al., in pres). The cor-
pus contains 1,468 student moves and 3,38 tutor 
moves. Overlaping uterances, which are comon 
in dialogue platforms such as instant mesaging, 
were prevented by permiting only one user to con-
struct a dialogue message at a time. Because the 
corpus is textual, uterances were segmented at tex-
tual mesage boundaries except when the lead dia-
logue annotator noted the presence of two separate 
dialogue acts within non-overlapping chunks of 
text. In these events the utterance was segmented 
by the primary annotator prior to being tagged by 
the second dialogue act anotator. 
In adition to dialogue act anotation, the cor-
pus was manualy annotated for task structure and 
corectness (Section 3.2), and for delayed tutor 
feedback (Seciton 3.3). The apendix displays an 
excerpt from the annotated corpus. 
3.1 Dialogue
Act Annotation 
As part of prior work, the corpus was annotated 
with dialogue acts for both tutor (Boyer, Phillips, 
Ingram, et al., in pres) and student (Boyer, Ha, et 
al., 2010) utterances (Table 1). One anotator 
taged the entire corpus, while a second anotator 
independently taged a randomly selected 10% of 
tutoring sesions. The inter-annotator agreement 
Kapa score was 0.80. 
3.2 Task
Anotation 
The corpus includes 97,509 keystroke-level task 
events (computer programming actions), all taken 
by the student. Tutors viewed synchronously, but 
could not edit, the computer program. The task ac-
tions were manually clustered and labeled for sub-
task structure (Boyer, Philips, et al., 2010). The 
task structure anotation was hierarchical, with 
leaves coresponding to specific subtasks such as 
creating a temporary variable in order to swap two 
variables’ values (subtask 3-c-iii-2). Each problem-
solving cluster, or subtask, was then labeled for 
corectness (Table 2). These corectnes labels are 
utilized in the models presented in this paper. The 
Kapa agrement statistic for the corectnes ano-
tation on 20% of the corpus was 0.80. 
Table 1. Dialogue act tags 
Dialogue Act Tutor Example 
ASSESSING Q. Which type should that be? 
EXTRA-DOMAIN A cordinator wil be there son. 
GROUNDING Ok. 
LUKEWARM 
FDBK 
That’s close. 
LUKEWARM 
CONTENT FDBK 
Almost there, but the second 
parameter isn’t quite right. 
NEGATIVE FDBK That’s not right. 
NEGATIVE 
CONTENT FDBK 
No, the counter has to be an int. 
POSITIVE FDBK Perfect. 
POSITIVE 
CONTENT FDBK 
Right, the aray is a local varia-
ble. 
QUESTION Which aproach do you prefer? 
RESPONSE It wil be an int. 
STATEMENT They start at 0. 
Table 2. Task corectnes tags 
Corectnes 
Tag Description 
CORRECT 
Fuly conforming to the require-
ments of the task. 
BUGGY 
Violating the requirements of the 
task. These task events typicaly 
require tutorial remediation. 
INCOMPLETE 
Not violating, but not yet fulfiling, 
the requirements of the task. 
DISPREFERED 
Technicaly fulfiling requirements 
but not utilizing the target con-
cepts being tutored. These 
events typically require tutorial 
remediation. 
3.3 Annotation
for Delayed Tutor Fedback 
The dialogue act and task anotations reflect posi-
tive evidence regarding what did occur in the dia-
logues. An aditional anotation was introduced for 
what did not occur—specificaly, instances in 
which tutors did not to make a dialogue move in 
response to students’ relevant task actions. The task 
in our corpus is computer programing, so bugs in 
the task corespond to erors either in syntax or se-
51
mantics of the computer program compared to the 
desired outcome. The human tutors were working 
with only one student at a time and were carefuly 
monitoring student task actions during the dialogue, 
so we take the absence of a dialogue move at a rel-
evant point to be an intentional choice by the tutor 
to delay fedback as part of the tutorial strategy. 
The automatic annotation for delayed feedback in-
troduced two new event tags: NO-MENTION of cor-
rectly completed subtasks, and NO-REMEDIATION 
of existing bugs within the task. 
The intuition behind these tags is that within a 
learned dialogue policy, specifically modeling 
when not to intervene is crucial. Typicaly human 
tutors mention corectly completed subtasks, but at 
times other tutorial goals eclipse the importance of 
doing so. The NO-MENTION tag captures these in-
stances. On the other hand, typicaly when working 
with novices, human tutors remediate an existing 
bug quickly. However, tutors may choose to delay 
this remediation for a variety of reasons such as 
remediating a diferent bug instead or asking a con-
ceptual question to encourage the student to reflect 
on the isue. The NO-REMEDIATION tag captures 
these instances of the absence of remediation given 
that a bug was present. These two anotations for 
delayed fedback were performed automaticaly 
(Boyer, Philips, Ha, et al., in pres).  
3.4 Adjacency
Pair Modeling 
Prior work has demonstrated that adjacency pairs 
can be identified in an unsupervised fashion from a 
corpus (Midgley, Harrison, & MacNish, 206). 
This technique relies on statistical analysis to de-
termine the significant dependencies that exist be-
twen pairs of dialogue acts, or in our task-oriented 
corpus, pairs of dialogue acts or task actions. After 
the pairs of dependent events are identified, they 
are joined within the corpus algorithmically (Boyer 
et al., 209). Joining a pair of dependent moves in 
this way is equivalent to introducing a deterministic 
(probability=1) sucesion betwen observation 
symbols. This type of dependency canot be 
learned in the traditional first-order HM frame-
work, but is desirable when two observations are 
strongly linked.
1
 
                                                             
1
 Enhanced HM structures, such as autoregresive HMs, 
which alow for direct graphical links between observation 
symbols, can learn such a dependency but only in stochastic 
terms. 
The experiment that is described in Section 4 
utilizes different feature sets to learn and compare 
HMMs. Table 3 shows these feature sets and their 
most highly statisticaly significant adjacency pairs. 
Table 3. Experimental conditions and top thre ad-
jacency pairs (subscripts denote speaker, Student or 
Tutor) 
Condition Description 
Significant Adjacency 
Pairs 
DAONLY 
Dialogue acts 
only 
Q
S
~Rsp
T
 
Ground
S
~Ground
T
 
AssesQ
T
~PosFdbk
S
 
DATASK 
Dialogue acts 
& task cor-
rectnes 
events 
Q
S
~Rsp
T
 
CorectTask
S
~CorrectTask
S
 
Ground
S
~Ground
T
 
DATASK-
DELAY 
Dialogue 
acts, task 
corectness, 
& delayed 
feedback 
Q
S
~Rsp
T 
NoRemediate
T
~BuggyTask
S
 
CorectTask
S
~CorrectTask
S
 
4 Models

HMMs were selected as the modeling framework 
for this work because their sequential nature is well 
suited to the structure of human dialogue, and their 
“hiden” variable coresponds to widely held con-
ceptions of dialogue as having an unobservable, but 
influential, layer of stochastic structure. For exam-
ple, in tutoring, an “explanation” mode is comon, 
in which the tutor presents new information and the 
student provides acknowledgments or takes task 
actions accordingly. Although the presence of the 
“explanation” goal is not directly observable in 
most dialogues, it may be infered from the obser-
vations. These sequences corespond to the input 
observations for learning an HM. 
4.1 Hiden
Markov Models 
HMMs explicitly model hiden states within a 
doubly stochastic structure (Rabiner, 1989). A first-
order HM, in which each hidden state depends 
only on the imediately preceding hidden state, is 
defined by the following components: 
• ∑ = {σ
1, σ
2, …, σ
M
}, the observation sym-
bol alphabet 
• S = {s
1,s
2,…,s
N
}, the set of hidden states 
52
• Π=[π
i
], i=1,…,N, the initial probability dis-
tribution, where π
i
 is the probability of the 
model beginning in hidden state s
i
 in S 
• A=[a
ij
], a transition probability distribution, 
where a
ij
 is the probability of the model 
transitioning from hidden state i to hidden 
state j for i,j=1,…,N 
• B=[b
ik
], an emision probability distribu-
tion where b
ik
 is the probability of state i 
(i=1,…,N) emiting (or generating) obser-
vation symbol k (k=1,…,M). 
4.2 Dialogue
Modeling with HMs 
In this work, the observation symbol alphabet ∑ is 
given. For each experimental condition, ∑ is either 
1) all dialogue act tags, 2) all dialogue acts plus 
task corectnes tags, or 3) dialogue act, task cor-
rectnes, and delayed feedback tags. The transition 
probability distribution A, emission probability dis-
tribution B, and initial probability distribution Π are 
learned by the standard Baum-Welch algorithm for 
optimizing HMM parameters (Rabiner, 1989). This 
algorithm is susceptible to becoming trapped in 
local optima, so our aproach uses ten-time random 
restart with new initial parameters for each model 
to reduce the probability of selecting a model that 
represents only a local optimum. 
The hyperparameter N, which is the best number 
of hidden states, is also learned rather than fixed. 
This proces involves runing the ful HM train-
ing algorithm, including random restarts in ten-fold 
cros-validation, acros the data and selecting the N 
that coresponds to the best mean godnes-of-fit 
measure. For HMs, a typical godnes-of-fit 
measure is log-likelihod, which captures how like-
ly the observations would be under the current 
model. The log is taken for practical reasons, to 
avoid numerical underflow. Higher log-likelihod 
coresponds to improved model fit. However, typi-
cally it is desirable to penalize a higher number of 
hidden states, since increasing the model complexi-
ty results in tradeofs that may not be fully warant-
ed by the improvement in model fit. In this work, 
we utilize the Akaike Information Criterion (AIC), 
a standard penalized log-likelihod metric (Akaike, 
1976).  
 
 
 
AIC = 2*N – 2*ln(likelihod) 
Lower values of AIC indicate beter model fit. 
4.3 Experimental
Conditions 
HMMs were learned using thre separate feature 
sets, each providing a progresively more complete 
picture of the task-oriented dialogues: dialogue acts 
only (DAONLY), dialogue acts and task events 
(DATASK), and dialogue acts with both task cor-
rectnes events and tags for delayed tutor feedback 
(DATASKDELAY). 
In adition to the thre different feature sets, 
each condition included one of two types of pre-
procesing. Each type of model was trained on un-
altered sequences of the annotated tags, which we 
refer to as the UNIGRAM condition. Aditionally, 
each type of model was trained on sequences with 
statisticaly dependent adjacency pairs joined in a 
preprocesing step as described in Section 3.4. The 
UNIGRAM and ADJPAIR conditions were explored 
for each of the thre feature sets, resulting in six 
experimental conditions. These conditions were 
chosen in order to explore the convergence behav-
ior of HMs under the different feature sets and 
preprocesing, and to compare measures of descrip-
tive fit with measures of predictive power. 
4.4 Learned
HMs 
Figures 1 and 2 show a subset of the DAONLY 
UNIGRAM model and the DATASKDELAY ADJPAIR 
model. These figures depict the structure of our 
HMMs: each hiden state is asociated with an 
emision probability distribution over the posible 
observation symbols. 
5 Goodnes-of-Fit Curves 
The learning algorithm described in Section 4.2 
was aplied to input sequences under the six exper-
imental conditions to learn the best-fit HM pa-
rameters. Figure 3 displays these AIC results, 
which are discused in detail in the remainder of 
this section.  
 
53
 
Figure 1. Subset of learned HM (N=13) for 
DAONLY UNIGRAM condition 
 
 
Figure 2. Subset of learned HM (N=9) for 
DATASKDELAY ADJPAIR condition 
5.1 Impact
of Experimental Conditions  
For the DAONLY condition, both the UNIGRAM and 
ADJPAIR models generaly improve until N=12 or 
13, after which the fit generaly worsens. A difer-
ent pattern emerges for the DATASK condition, in 
which the UNIGRAM sequences are optimaly fit to 
a model with 16 states, while the ADJPAIR se-
quences are fit to a model with 8 states. Finaly, for 
the DATASKDELAY condition, the UNIGRAM se-
quences are best fit by a model with 10 hidden 
states, while the ADJPAIR sequences are fit best 
by 9. Typicaly, we se that ADJPAIR sequences are 
fit to slightly simpler models in terms of the hy-
perparameter N, number of hidden states. 
 
Figure 3. Number of hidden states and cor-
responding adjusted AIC, shifted to a mini-
mum score of zero indicating the best-fit N 
Ad
j
u
s
t
e
d
 
AI
C
 
a) Dialogue ActsOnly (DAONLY) 
 
 N (number of hiden states) 
Ad
j
u
s
t
e
d
 
AI
C
 
b) Dialogue Act and Task Events (DATASK) 
 
 N (number of hiden states) 
Ad
j
u
s
t
e
d
 
AI
C
 
c) Dialogue Act, Task, & Delayed Fedback 
(DATASKDELAY) 
 
 N (number of hiden states) 
54
Stability in the hyperparameter N is an im-
portant consideration because an underlying as-
sumption of our work is that the hiden states 
corespond to unobserved stochastic structures of 
the real world process—that is, we hypothesize 
that a “true” value for N exists. We would like 
models to exhibit decreasing variation in goodnes 
of fit measures around this true N. To examine this 
stability we consider the thre best AIC values for 
each condition and their coresponding Ns: the set 
{N
k-best
 | k=1,2,3}. The range of this set indicates 
how “far apart” the best thre Ns are: for example, 
in the DAONLY UNIGRAM condition, the top three 
models have Ns of {13,10,15}, yielding a range of 
5. Intuitively, a smal value for this metric indicates 
that the model has converged tightly on N. 
Figure 4 shows the stability results for the six 
diferent experimental conditions. As shown in the 
figure, for the DATASK and DATASKDELAY condi-
tions, the ADJPAIR models achieve the smallest 
range among the top three values of N; these mod-
els converge most tightly to the “best” value.  
 
Figure 4. Stability of N (range of {N
1best, 
N
2best, 
N
3best
}) – smaler implies tighter convergence to 
“best” N 
6 Predictive
Analysis 
Section 5 presented an analysis of the godnes-of-
fit curves of HMMs learned from the corpus. The 
measures of stability and discrimination for N cap-
ture important aspects of the behavior of HMs 
toward this parameter, which is conceived of as 
representing “true” real-world stochastic behavior. 
In this way, Section 5 has presented a descriptive 
view of HM dialogue models. 
This section presents a predictive view of the 
models. Specificaly, we consider prediction accu-
racy, defined as the percent of tutor dialogue moves 
that the model is able to corectly predict given the 
dialogue history sequence up to that point.  
6.1 Impact
of Dependent Adjacency Pairs 
We first explore whether the preprocesing step of 
joining dependent adjacency pairs impacted predic-
tion acuracy. The prediction accuracy of the best-
fit model in each condition is displayed in Figure 5. 
This figure includes prediction acuracy on training 
data, which were used to learn model parameters, 
as well as prediction accuracy on testing data, 
which were witheld from odel training. 
 
Figure 5. Prediction acuracy for tutor moves 
 
As shown in Figure 5, joining the adjacency 
pairs improved model performance on the training 
sets of al thre conditions, indicating that the varia-
tion within the training data was beter explained 
by ADJPAIR models. (This measure of predictive 
power is different from a godnes-of-fit criterion 
as described in the previous section, a relationship 
that will be discused further in Section 7.) In con-
trast to the training set performance, the ADJPAIR 
models performed beter than UNIGRAM models for 
the testing set only in the DATASKDELAY condi-
tion.  
6.2 Impact
of Task-Oriented Feature Sets 
As ilustrated in Figure 5, the thre feature sets per-
form similarly under the UNIGRAM condition. This 
performance is slightly above baseline (DAONLY 
and DATASK baselines = 0.38; DATASKDELAY 
baseline = 0.30), and diminishes litle between the 
training and testing sets. In contrast, under the 
ADJPAIR condition, performance between condi-
tions and acros training and testing sets varies. The 
DATask model performs far beter on predicting 
observations in the training than the testing set, 
55
sugesting possible overfiting to the training set. 
This relationship is discused further in Section 7. 
The DATASKDELAY model performs wel during 
both training and testing, though with a slight de-
crease in accuracy on the testing set.  
6.3 Relationship
Betwen Predictive and De-
scriptive Metrics 
Measures of fit such as log-likelihod and AIC cap-
ture the likelihod of observing the data given a 
model. Predictive acuracy, on the other hand, 
measures the probability that the model can predict 
the next observation given a partial sequence. In 
general, we would expect these measures to corre-
late well; however, there is not perfect correlation 
betwen these metrics because the mechanism by 
which log-likelihod (and thereby AIC) is derived 
involves maximizing likelihod over complete se-
quences, while prediction is performed over partial 
sequences. 
To examine how well AIC and prediction accu-
racy correlate, Figure 6 displays these values for a 
subset of the models in the DAONLY UNIGRAM 
condition and the DATASKDELAY ADJPAIR condi-
tion. These two conditions represent the extremes 
of the experimental conditions, with DAONLY con-
taining the least information about the task-oriented 
dialogue while DATASKDELAY contains the most 
information.  
As shown in Figure 6, the corelation for 
DAONLY UNIGRAM roughly conforms to what 
would be expected: lower AIC, indicating beter 
model fit, is asociated with the highest prediction 
accuracies. The relationship is less clear for the 
DATASKDELAY ADJPAIR condition. While its 
worst AIC is asociated with the lowest prediction 
accuracy as expected, the best AIC is not associated 
with the highest prediction acuracy. This phenom-
enon may be due to the lack of spread among AIC 
values overal for this condition; as sen in Figure 
3, the DATASKDELAY ADJPAIR condition has the 
flatest AIC curve of al conditions, indicating that 
for this condition the difference betwen best-fit 
and worst-fit models is smaler than for any other 
condition. The inconsistent relationship between 
AIC and prediction acuracy, therefore, may be the 
product of noise surrounding a large set of “good” 
models, whereas for the DAONLY UNIGRAM condi-
tion, the set of god models is smaller.  
 
 
7 Discusion

The results sugest several important findings re-
garding feature sets and preprocesing for learning 
HMMs of task-oriented dialogue. First, the models’ 
convergence patterns to a best-fit N, number of 
hidden states, indicate that more information em-
bedded within the sequences may corespond with 
a flatter goodnes-of-fit curve. Adding more infor-
mation to the input sequences may introduce some 
regularities that partly mitigate the limitations of 
even a porly fit HM. This aditional infor-
mation may come in the form of adjacency pairs 
discovered in an unsupervised fashion, which im-
proved the stability of convergence on the best-fit 
N under the DATASK and DATASKDELAY condi-
tions. This increased stability is likely due to the 
fact that under these conditions, leveraging adja-
cency pair information augments the HM’s struc-
ture with contextual dependencies that could 
otherwise not be learned under the traditional 
HMM framework. 
For predictive acuracy, the benefits of richer 
input sequences are also highlighted. The most 
highly predictive models included all thre sources 
Pr
e
d
i
c
t
i
o
n
 
Ac
c
u
r
a
c
y
 
a) DAOnly UNIGRAM Condition 
 
 AIC 
Pr
e
d
i
c
t
i
o
n
 
Ac
c
u
r
a
c
y
 
b) DATASKDELAY ADJPAIR Condition 
 
 AIC 
Figure 6. Prediction acuracy vs. AIC 
56
of information: dialogue acts, task events, and de-
layed fedback tags. However, with the adition of 
this rich information to the input sequences and the 
accompanying flatter godness-of-fit curve as dis-
cused above, we noted an iregular pattern of cor-
relation betwen godnes-of-fit and predictive 
accuracy that is worthy of future exploration. Spe-
cifically, it appears that the most highly predictive 
DATASKDELAY ADJPAIR model, which is the most 
highly predictive of al models in al conditions, 
does not corespond to the best (lowest) AIC for 
that condition (Figure 3). This finding sugests that 
when a predictive task is the primary goal, a predic-
tive metric should be used to select the best-fit 
model. Additional suport for such an aproach is 
provided by the close corespondence between 
training and testing set prediction accuracy. 
8 Conclusion

Understanding how HMMs behave under diferent 
feature sets is an important step toward learning 
effective models of task-oriented dialogue. This 
paper has examined how HMs converge to a best 
number of hidden states under diferent experi-
mental conditions. We have also considered how 
wel HMMs under these conditions predict tutor 
dialogue acts within a corpus of task-oriented tutor-
ing, a crucial step toward learning dialogue policies 
from human corpora. The findings highlight the 
importance of ading rich task-based features to the 
input sequences in order to learn HMs that con-
verge tightly on the best-fit number of hiden 
states. The results also indicate that caution should 
be used when utilizing traditional goodnes-of-fit 
metrics, which are apropriate for descriptive ap-
plications, if the goal is to learn a highly predictive 
model.  
This line of research is part of a larger research 
program of learning unsupervised models of human 
task-oriented dialogue that can be used to define 
the behavior of dialogue systems. Developing a 
framework for learning a dialogue policy from hu-
man corpora, as discused here, is a critical step 
toward that goal. Future work should focus on un-
supervised dialogue act classification, and address 
the challenges of user plan recognition. 
Acknowledgments. This work is suported in part by 
National Science Foundation through Grants REC-
0632450, IS-0812291, DRL-1007962 and the STARS 
Alliance Grant CNS-0739216. Any opinions, findings, 
conclusions, or recomendations expressed in this re-
port are those of the participants, and do not necessarily 
represent the oficial views, opinions, or policy of the 
National Science Foundation. 
References 
Akaike, H. (1976). An information criterion (AIC). 
Math. Sci., 14(153), 5-9. 
Bangalore, S., Di Fabrizio, G., & Stents, A. (206). 
Learning the structure of task-driven human-human 
dialogs. Procedings of ACL ’06, 201-208. 
Boyer, K. E., Ha, E. Y., Philips, R., Walis, M. D., 
Vouk, M. A., & Lester, J. C. (2010). Dialogue Act 
Modeling in a Complex Task-Oriented Domain. 
Procedings of SIGDIAL (pp. 297-305). 
Boyer, K. E., Philips, R., Ha, E. Y., Walis, M. D., 
Vouk, M. A., & Lester, J. C. (in pres). Learning a 
Tutorial Dialogue Policy for Delayed Fedback. 
Procedings of the 24th International FLAIRS Con-
ference. 
Boyer, K. E., Philips, R., Ha, E. Y., Walis, M. D., 
Vouk, M. A., & Lester, J. C. (209). Modeling dia-
logue structure with adjacency pair analysis and hid-
den Markov models. Procedings of NAACL HLT, 
Companion Volume, 49-52. 
Boyer, K. E., Philips, R., Ha, E. Y., Wallis, M. D., 
Vouk, M. A., & Lester, J. C. (2010). Leveraging 
Hiden Dialogue State to Select Tutorial Moves. 
Procedings of the NAACL HLT 2010 Fifth Work-
shop on Inovative Use of NLP for Building Educa-
tional Aplications (pp. 6-73). 
Boyer, K. E., Phillips, R., Ingram, A., Young, E., Wallis, 
M., Vouk, M., et al. (in pres). Investigating the Re-
lationship Betwen Dialogue Structure and Tutoring 
Effectivenes: A Hidden Markov Modeling Ap-
proach. International Journal of Artificial Inteli-
gence in Education. 
Di Eugenio, B., Xie, Z., & Serafin, R. (2010). Dialogue 
Act Clasification, Higher Order Dialogue Structure, 
and Instance-Based Learning. Dialogue & Dis-
course, 1(2), 1-24. 
Georgila, K., Lemon, O., Henderson, J., & More, J. D. 
(209). Automatic anotation of context and speech 
acts for dialogue corpora. Natural Language Engi-
neering, 15(3), 315-353. 
Midgley, T. D., Harison, S., & MacNish, C. (206). 
Empirical verification of adjacency pairs using dia-
logue segmentation. Procedings of SIGDIAL, 104-
108. 
Rabiner, L. R. (1989). A tutorial on hiden Markov 
models and selected aplications in spech recogni-
tion. Procedings of the IEEE, 77(2), 257-286. 
57
Rotaru, M., & Litman, D. J. (209). Discourse Structure 
and Performance Analysis : Beyond the Corelation. 
Procedings of SIGDIAL (pp. 178-187). 
Stolcke, A., Ries, K., Cocaro, N., Shriberg, E., Bates, 
R., Jurafsky, D., et al. (200). Dialogue Act Model-
ing for Automatic Taging and Recognition of Con-
versational Speech. Computational Linguistics, 
26(3), 39-373. 
VanLehn, K., Graeser, A. C., Jackson, G. T., Jordan, P., 
Olney, A., & Rose, C. P. (207). When Are Tutorial 
Dialogues More Efective Than Reading? Cognitive 
Science: A Multidisciplinary Journal, 30(1), 3-62. 
Woszczyna, ., & Waibel, A. (194). Infering linguis-
tic structure in spoken language. Procedings of the 
International Conference on Spoken Language Pro-
cessing (pp. 847-850). 
Young, S., Gašić, M., Keizer, S., Mairese, F., 
Schatzman, J., Thomson, B., et al. (2010). The Hid-
den Information State model: A practical framework 
for POMDP-based spoken dialogue management. 
Computer Spech & Language, 24(2), 150-174. 
 
Appendix. Excerpt from task-oriented textual human-human tutoring corpus. 
Speaker Utterance or Event Tag 
Student: [Task action on subtask 3-c-i-4] BUGGY 
Student: [Task action on subtask 3-c-ii-5] CORRECT 
Tutor: [Does not provide remediation for existing bug] NOREMEDIATION 
Student: [Task action on subtask 3-c-iii-1] BUGGY 
Student: i don't remember off the top of my head how the swap 
function worked. most of the time i just copied and 
pasted it from some of my older code 
NEGATIVECONTENTFDBK 
Tutor: The easiest way to swap x and y is to make a tempo-
rary variable 
 
Student: Ok ACK 
Student: do i need to pas the entire aray and the indecies of the 
items to swap? 
ASSESSQ 
Tutor: if you want to use a seperate method to swap, then yes, 
you'l have to pas those things 
 
POSCONTENTFDBK 
Tutor: [Does not mention a corectly completed subtask]	   NOMENTIONCOMP 
Student: oh. i gues i could just swap it in the same method. it is 
problably easier that way, and les code. we were 
showed in class how to do it separately, but i had never 
thought of doing it the other way.  
STMT 
Student: [Task action on subtask 3-c-iii-2] DISPREFERED 
Tutor: Both ways work, but it’s definitely les code to just do 
it inside this method.  
STMT 
Student: Ok ACK 
 
58

