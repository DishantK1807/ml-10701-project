Processing Unknown Words in HPSG 
Petra Barg and Markus Walther* 
Seminar ftir Allgemeine Sprachwissenschaft 
Heinrich~Heine-Universit~it Dfisseldorf 
Universit:dtsstr. 1, D-40225 Dtisseldorf, Germany 
{barg, walther}@ling.uni-.duesseldorf, de 
Abstract 
The lexical acquisition system presented in this pa
per increlnenlally updates linguistic properties of un
known words inferred lrom their surrounding con
lexI by parsing senlences wilh an liPSG gramnmr 
for Gerlmm. We employ a gradual, infornmtion
based concept of "tlnknowntless" providing a uni
form treatment for the range oi completely known to 
maximally unknown lexical entries. "Unknown" in
formation is viewed as revisable inR)rmation, which 
is either generalizable or specializable. Updating 
takes place after parsing, which only requires a mod
ified lexical lookup. Revisable pieces of informa
lion are idenlilied by grammar-specilied declaralions 
which provide access pmhs into lhe parse feature 
slructure. The updating nlechanism revises the col 
responding places in the lexical lcalure stmclures iff 
the conlext actually provides new information. For 
revising generalizable inlbrmalioi< (ype union is re
quired. A worked-out example demonstrates the in
Iercntial capacily of our implemented system. 
1 Introduction

It is a ,emarkable fact thai humans can often un
derstand sentences containing unknown words, in
let their grammatical properties and incrementally 
refine hypotheses aboul these words when encoun
tering laler instances. In conlrasl, many current NLP 
systems still prestlppose a complele lexicon. Notable 
exceptions include Zernik (1989), Erbach (199()), 
Hastings & Lylinen (1994). See Zernik lot an intro
duction to the general issues involved. 
11fis paper describes an HPSG-based system 
which can incrementally learn and reline proper
lies of unknown words after parsing individual sen
*This work was tan'ted out within the ,S'onde@)rschungs
bereich 282 '77worie des Lexikol~s' (project B3), funded by the 
German Federal Research Agency DFG. We thank James Kil
bury and lnembers of the B3 group for fruitful discussion. 
tences. It focusses oll extracting linguislic proper
ties, as compared to e.g. general concept learning 
(Hahn, Klenner & Schnatiinger 1996). Unlike Er
bach (1990), however, it is not conlined to siul
pie morpho-synlactic information but can also han
(lie selectional reslriciions, senianlic types and argu
ment slructure. Finally, while statistical approaches 
like Brenl (1991) can gather e.g. valence inloruia
lion lioni large corpora, we rote more interested in 
full gralmnatical processing of individual sentences 
to maximally exploil each context. 
The following three goals serve to struclure 
our model. It should i) incorporate a gradual, 
informalion-based conceptualization of "unknown
ness". Words are not unknown as a whole, but 
may contain ux~k~mw~t, i.e. revisable pieces of b(for,la*iom Consequently, even known words can un
der(,o> revision 1o e.>.<) acquire new senses. This view 
replaces the binm-y distinclion belween open and 
closed class wordx. 1l should it) maxinmlly exph)il 
lhe rich represeniaiions and nlodelling convenlions 
of IiPSG and associaled formalisnls, wiih essen
iially the same grammar anti lexicon as compared 
(o closed-lexicon approaches. This is important bolh 
lo facilitate reuse of existing grammars and li) en
able meaningful feedback for linguistic theorizing. 
Finally, it should iii) possess donlain-independenl in
ference and lexicon-updating capabililies. The gram
mar writer must be able to fully declae which pieces 
of inlbrmalion are open to revision. 
The system was implemenled using MicroCUF, 
a simplilied version of the CUF typed unification 
lormalisin (D6rre & Dorna 1993) thai we imple
mented in SICStus Prolog. It shares both the feature 
logic and the definite clause extensions with ils big 
brother, but substitutes a closed-world type system 
li)r CUF's open-world regime. A fealure of our lype 
system impletnenlation lhaI will be signilicant later 
on is (hat type infornmtion in internal IEalure sittic
91 
tures (FSs) can be easily updated. 
The HPSG grammar developed with MicroCUF 
models a fragment of German. Since our focus is on 
the lexicon, the range of syntactic variation treated 
is currently limited to simplex sentences with canon
ical word order. We have incorporated some recent 
developments of HPSG, esp. the revisions of Pol
lard & Sag (1994, ch. 9), Manning & Sag (1995)'s 
proposal for an independent level of argument struc
ture and Bouma (1997)'s use of argument structure 
to eliminate procedural lexical rules in *:avour of re
lational constraints. Our elaborate ontology of se
mantic types useful for non-trivial acquisition of 
selectional restrictions and nominal sorts was de
rived from a systematic corpus study of a biological 
domain (Knodel 1980, 154-188). The grammar also 
covers all valence classes encountered in the corpus. 
As for the lexicon format, we currently list full forms 
only. Clearly, a morphology component would sup
ply more contextual information from known affixes 
but would still require the processing of unknown 
stems. 
2 Incremental
Lexical Acquisition 
When compared to a previous instance, a new sen
tential context can supply either identical, more spe
cial, more general, or even conllicting inIormation 
along a given dimension. Example pairs illustrating 
the latter three relationships are given under (1)-(3) 
(words assumed to be unknown in bold face). 
(1) a. hn Axon tritt ein Ruhepotential auf. 
'a rest potential occurs in the axon' 
b. Das Potential wandert tiber das Axon. 
'the potential travels along the axon' 
(2) a. Das Ohr reagiert auf akuslische Reize. 
'the ear reacts to acoustic stimuli' 
b. Ein Sinnesorgan reagiert auf Reize. 
'a sense organ reacts to stimuli' 
a. Die Nase ist ftir Gertiche sensibel. 
'the nose is sensitive to smells' 
b. Die sensible Nase reagiert auf Gertiche. 
'the sensitive nose reacts to smells' 
(3) 
In contrast to (la), which provides the inff)rmation 
that the gender of Axon is not feminine (via ira), the 
context in (lb) is more specialized, assigning neuter 
gender (via das). Conversely, (2b) differs from (2a) 
in providing a more general selectional restriction for 
the subject of reagiert, since sense organs include 
ears as a subtype. Finally, the adjective sensibel is 
used predicatively in (3a), but attributively in (3b). 
The usage types must be formally disjoint, because 
some German adjectives allow for just one usage 
(ehemalig 'former, attr.', schuld 'guilty, pred.'). 
On the basis of contrasts like those in (1)-(3) it 
makes sense to statically assign revisable informa
tion to one of two classes, namely specializable or 
generalizable, l Apart from the specializable kinds 
'semantic type of nouns' and 'gender', the inllec
tional class of nouns is another candidate (given a 
morphological component). Generalizable kinds of 
information include 'selectional restrictions of verbs 
and adjectives', 'predicative vs attributive usage of 
adjectives' as well as 'case and lbrm of PP argu
ments' and 'valence class of verbs'. Note that spe
cializable and generalizable inlbrmation can cooccur 
in a given lexical entry. A particular kind of intbrma
tion may also figure in both classes, as e.g. seman
tic type of nouns and selectional restrictions of verbs 
are both drawn from the same semantic ontology. Yet 
the former must be invariantly specializedindepen
dent of the order in which contexts are processed -, 
whereas selectional restrictions on NP complemenls 
should only become more general with further con
texts. 
2.1 Representation

We require all revisable or updateable information to 
be expressible as formal types. 2 As relational clauses 
can be defined to map types to FSs, this is not much 
of a restriction in practice. Figure 1 shows a rele
vant fragment. Whereas the combination of special
/~Srd geI~der u_g 
nom seln /~ I~ 
~...~pred attXr ! 
____ non 
masc neut sound smell nose ear 
Figure 1: Excerpt from t)7)e hierarchy 
izable information translates into simple type unifi
cation (e.g. nora_fern A ~,eut = rteut), combining 
1The different behaviour underlying this classification has 
previously been noted by e.g. Erbach (1990) and Hastings & 
Lytinen (1994) hut received either no implementational status o1' 
no systematic association with arbitrary kinds of information. 
2In HPSG types are sometimes also refmTed to as sorts. 
92 
~:eeneralizable inlormalion requires 0'Pe union (e.~,,. 
pred V (Lttr = prd). qqle latter might pose problems 
tot type systems requiring the explicit delinition el 
all possible unions, corresponding to least common 
supertypes. However, type union is easy lot (Mi
cro)CUF and similm: systems which allow for arbi
trary boolean combinations of types. Generalizable 
inlormation exhibits another peculiarity: we need 
a disjoint auxiliary type u_g Io colTectly mark the 
initial unknown inlormalion slate. 3 This is because 
'content' types like prd, pred, atlr are to be inter
preted as recording whal contextual information was 
encountered in the past. Thus, using any of lhese to 
prespecify the initial value--, either as the side-effect 
of a feature appropriateness declaration (e.g. prd) or 
through gramlnar-conlrolled specification (e.g. pred, 
attr) -would be wrong (of. prdi,,ti, l V al:l,r == prd, 
but tt-.(,lir~iti,l V aLl, r" :: lt_.q V a,l,l,r). 
Generalizable inlormalion evokes another ques
lion: can we simply have types like those in fig. 1 
within HPSG signs and do in-place type union, just 
like type unification? The answer is no, li)r essen
tially two reasons. First, we slill want to rule out 
ungran\]malicaI constructions through (type) unifica
lion failure of coindexed wdues, so lhat generalizable 
types cannot always be combined by nonfailing type 
union (e.g. *tier sensible Geruch 'the sensitive smell' 
must be ruled out via ,~c'n:~,:_org.';~ A amcll -Z.). 
We would ideally like to order all type tmilicalions 
pertaining Io a value before all unions, but this vi
olates the order independence of constraint solv
ing. Secondly, we already know that a given inlbr
mational token can ,vimulta~wously be generalizable 
and specializable, e.g. by being coindexed through 
HPSG's valence principle, tlowever, silnullaneous 
in-place union and unilication is conlradiclory. 
To avoid these problems and keep the declarative 
monotonic setting, we employ two independent fea
tures gen and ctxt. ctxt is the repository of contex
tually unified inlbrmation, where conllicts result in 
ungrammalicality, gen holds generalizable informa
tion. Since all gen values contain u_g as a type dis
junct, they are always unifiable and lhus not restric
live during the parse. To nevertheless get correct gen 
values we perform type union after parsing, i.e. dur
ing lexicon update. We will see below how this works 
out. 
3Actually, the situatkm is more symmetrical, as we need a 
dual type uor t(} con'ectly mark "unknown" sT)ecializable infl)r
marion. This In'events incon'cct updating i~t known inforlmition. 
ltowever, uov is tlnllccessaly li~i' the examples presented below. 
ql~e last representalional issue is how to identify 
revisable infornlation in (subslrnctures el) tile parse 
FS. D)r this purpose lhe grammar delines revisabilily 
clauses like the following: 
(4) a. generalizable(\[j\], \[23) := 
gen s> omllooloa, lhead \[ot×, 
b. specializable(W):= 
\[cat lhead noun \]\] \[synseml 
OC\[centl ind J gend\[~J\] 
2.2 Processing

The firsl step in processing sentences wflh unknown 
or revisable words consists of conventional parsing. 
Any HPSG-compalible parser may be used, subject 
to the obvious requiren\]ent that lexical lookup must 
not lail if a word's phonology is unknown. A canon
ical entry for such unknowil words is delined as lhe 
disjunction of maximally underspecilied generic lex
ical entries for nottns, adjectives anti verbs. 
The actual updating of lexical enlries consists of 
lout major steps. Step 1 projects the parse FS derived 
from the whole sentence onto all parlicipaling word 
lokens. This resulls in word FSs which are conlexlu
ally enriched (as compared to their original lexicon 
state) and disambiguated (choosing the compatible 
disjuncl per parse solution if the entry was disjunc
tive). It then filters the set of word FSs by unification 
with the right-hand side of revisability chmses like in 
(4). The oulput of step 1 is a list of update candidates 
for those words which were unifiable. 
Slop 2 determines concrete update values lor each 
word: for each matching generalizable chmse we 
lake the type tmion oflhe gen value of the old, lexical 
state of the word (Lca:Cc~ 0 with lhe ctxt value of its 
parse projection (Ctzt): 5l'17 = Lcz(;eTzuCt:c~. For 
each matching specializabIe(Spec) chmse we take 
the parse value Spec. 
Step 3 checks whether updating would make a dif
ference w.r.t, the original lexical entry of each word. 
The condition to bc met by generalizable information 
is that 7'U D L :xGeu, lot specializal~le inlormation 
we similaly require Spec C l, exSpcc. 
In step 4 the lexical entries of words surviving slep 
3 are actually modilied. We retract the old lexical en
try, revise the entry and re-asserl it. For words never 
encountered before, revision lnUSt obviously be pre
ceded by making a copy of the generic unknown en
try, but wilh the new word's phonology. Revision it
self is the destructive modilicalion of type informa
93 
tion according to the values determined in step 2, 
at the places in a word FS pointed to by the revis
ability clauses. Tiffs is easy in MicroCUE as types 
are implemented via the attributed variable mecha
nism of SICStus Prolog, wlffch allows us to substi
tute the type in-place. In comparison, general updat
ing of Prolog-encoded FSs would typically require 
the traversal of large structures and be dangerous if 
structure-sharing between substituted and unaffected 
p',u-ts existed. Also note that we currently assume 
DNF-expanded entries, so that updates work on the 
contextually selected disjunct, qTtis can be motivated 
by the advantages of working with presolved struc
tures at run-time, avoiding description-level opera
tions and incremental grammar recompilation. 
2.3 A
Worked-Out Example 
We will illustrate how incremental lexical revision 
works by going through the examples under (5)-(7). 
(5) Die Nase ist ein Sinnesorgan. 
'the nose is a sense organ' 
(6) Das Ohr perzipiert. 
'the ear perceives' 
(7) Eine verschnupfte Nase perzipiert den 
Gestank. 
'a bunged up nose perceives the stench' 
The relevant substructures corresponding to the lex
ical FSs of the unknown noun and verb involved 
are depicted in fig. 2. The leading feature paths 
synsemlloc\[eont for Nase and synsemlloclcatlarg-st 
for perzipiert have been onfftted. 
Afler parsing (5) the gender of the unknown noun 
Nase is instantiated to fern by agreement with the 
determiner die. As the special&able clause (4b) 
matches and the gend parse value differs from its 
lexical value gender, gender is updated to fern. Fur
thermore, the object's semantic type has percolated 
to the subject \]Vase. Since the object's sense~grgan 
type differs from generic initial nora_rein, Nase's ctxt 
value is updated as well. In place of the still nonex
isting entry for perzipiert, we have displayed the rel
evant part of the generic unknown verb entry. 
Having parsed (6) the system then knows thai 
perzipiert can be used intransitively with a nomi
native subject referring to ears. Formally, an HPSG 
mapping principle was successful in mediating be
tween surface subject and complement lists and the 
argument list. Argument list instantiations are them
selves related to corresponding types by a further 
Nase 
after (5) 
gendfem \] 
gen u.g \[ 
ctxt sense~organJ 
perzipiert 
ctxt arg~rtntcJ 
after (6) 
gend/em \] 
gen u..g I ctxt sense~grgan\[ 
alter (7) 
gend fern \] 
gen u_g / 
ctxt noseJ 
gen u~,Vnpnom I\] ctxt arg.vtrue 
.rg../\[,oo I cont \[ gen It-gVear\]\] 1_ \ L L taxt n°m"renuJ 
gen l,t_gVttpnornVnpnom~lpacc 1 
ctxt arg_rtruc I 
r, , .rgen u_gVsense~vrgan\]\] I /\[,oo loom \[ot~t.,o,,,_~., JJ'\/ 
args I \\[Ioccont rgenu-gvs'ellTl' /)| 
L L \[~t~t,,o.,_,~,,, JJ I_ J 
Figure 2: Updates on Iexical FSs 
mapping. On the basis of tiffs type classification of 
argument structure patterns, the parse derived the 
clxt value npnom. Since gen values are generaliz
able, this new value is unioned with the old lexi
cal gen value. Note that ctxt is properly unaffected. 
The first (subject) element on the args list itself is 
targeted by another revisability clause. Tiffs has the 
side-effect of further instantiating the underspecified 
lexical FS. Since selectional restrictions on nominal 
subjects must become more general with new con
textual evidence, the union of ear and the old value 
u_g is indeed appropriate. 
Sentence (7) first of all provides more specific evi
dence about the semantic type of partially known ,Vase by way of attributive modification through ver
schnupfte. The system detects tiffs through the differ
ence between lexical ctxt value sense_organ and the 
parse value nose, so that the entry is specialized ac
cordingly. Since the subject's synsem value is coin
dexed with tim first args element, \[ctxt ,,ose\] simulta
neously appears in the FS ofperzipiert. However, the 
revisability clause matching there is of class general
izable, so union takes place, yielding ear" V nose = 
sense_organ (w.r.t. the simplified ontology of iig. 
1 used in this paper). An analogous match with the 
second element of args identifies the necessary up
date to be the unioning-in of smell, the semantic type 
of Gestank. Finally, the system has learned that an 
accusative NP object can cooccur withperzipiert, so 
the argument structure type of gen receives another 
update through union with npnom_npacc. 
94 
3 Discussion

The inccemenlal lexical acquisition approach de
scribed above attains the goals stated earlier. It re
alizes a gradual, infornmtion-based conceptualiza~ 
lion of unknownness by providing updateable lbrmal 
types classilied as either generalieable or special
<able logelher with grammar-delined revisability 
clauses, it maximally exploits standard HPSG red 
resenlalions, requiring moderate rearrangements in 
grammars at best wtfile keeping with the standard 
assumptions of typed unification formalisms. One 
noteworlhy demand, however, is the need for a type 
union operation. Parsing is conventional modulo a 
modilied lexical lookup. The actual lexical revision 
is done in a domain-independent poslprocessing step 
guided by lhe revisability clauses. 
Of course Ihere are areas requiring furlher consid
eration. In conlrasl to humans, who seem to leap to 
conclusions based on incomplete evidence, our ap
proach employs a conservalive form of generaliza
lion, taking file disjunction of actually observed val
ties only. While this has the advantage of not leading 
lo overgeneralization, lhc requirement of having to 
encounter all subtypes in order lo infer their con> 
men superlype is not realistic (sparse-da|a problem). 
In (2) se~zse_orgatt as lhe senlanlic type of lhe tirsl 
argument olperzil)iert is only acquired because tile 
siulplilied hierarchy in lig. l has ~to.s'e and ear as its 
only subtypes. Here lhe work of Li & Abe (1995) 
who use the MDL principle to generalize over the 
slots of observed case frames nfight prove li-uitful. 
An important question is how to administrate 
allernative parses and lheir update hypotlteses. In 
Dax Aktiot~Sl)Oterttial erreicht del~ l)ettdt'itelt 'the 
aclion polenlial reaches lhe dendrite(s)', l)endriten 
is' ' alnblguous between acc.sg, and dat.pl., giving 
rise to lwo wtlence bYt)olheses Itpzlomotpacc anti 
tqmomatpdat for errz'.ic:ht. Details relnain to be 
worked out on how to delay the choice between such 
alternative hypoll~eses until flmher contexts provide 
enough inforulation. 
Another topic concerns the treatment of 'cooc
currence reslriclions'. In lig. 2 llle system has in
depettdetttly generalized over the selectional reslric
lions for subject and object, yet there are clear cases 
where this overgenerales (e.g. *Das Ohr perzipiert 
de~ Ge.rtcmk 'the ear perceives the stench'). An idea 
worth exploring is to have a partial, extensible list of 
lype reoccurrences, which is traversed by a recursive 
principle at parse lime. 
A molc gcnct-al issue is the al)parenl antagonism 
95 
between the desire 1o have both sharp grammatical 
predictions and continuing openness to contextual 
revision. If after parsing (7) we transler the fact that 
smells are acceptable objects toper~ipiert into tile re
stricting ctxt feature, a later usage with an objecl of 
type sound fails. The opposite case concerns newly 
acquired specializable values. If in a later context 
these are used to update a 9en value, tile result may 
be too general. It is a topic of future research when 
to consider inR~rmation oct-lain and when to make re
visable information restrictive. 

References 

Bouma, G. (1997). Valmme Alternation without Lexical Rules. in: Papers from the seventh CLIN Meeting 1996, Emdhoven, 25-40. 

Brent, M. R. (1991). Automatic Acquisilion of Subcategorization Fr~unes From Untagged Text. in: Proceedings of 29th ACL, Berkeley, 209-214. 

Dt~rre, J. & M. Doma (1993). CUFA Formalism for Linguistic Knowledge Representation. In: J. D(~rre tEd.), Computational A.v~ects of Constraint-llased Linguistic Description. IMS, Universit~it Stuttgart. Deliverable R 1.2.A, DYANA-2 ESPRIT Project 6852. 

Erbach, G. (1990). Syntactic Processing of Unknown Words. IWBS Report 131, Institute for Knowledge-Based Systems (IWBS), IBM S tuttg~ut. 

Hahn, U., M. Klenner & K. Schnattinger (1996). Learning from Texts A Terminological Meta-Reasoning Perspective. In: S. Wennter, E. Riloff & G. Scheler tEd.), Connectiotzist, Statistical, and Symbolic Approaches to Learning.for Natural Language Processing, 453-468. Berlin: Springer. 

Hastings, E M. & S. L. Lytinen (1994). The Ups and Downs of Lexical Acquisition. in: Ptv¢'eediltgs oJ' AAAI'94, 754-759. 

Knodel, ft. (1980). Linder Biologie Lehrbuch fiir die Oberstufe. Stuttgart: J.13. Metzlersche Verlagsbuchhandlung. 

Li, H. & N. Abe (1995). Generalizing C~tse Fr~unes Using a ~lllesaurus ;rod the MDL Principle. in: Proceedings qf Recent Advantages in Natural Language Processing, Velingrad, Bulgaria, 239-248. 

Manning, C. & I. Sag (1995). Dissociations between argument structure and grammatical relations. Ms., Stanford University. 

Pollard, C. & l. Sag (1994). Head-Driven Phrase Slructure Grammar. Chicago University Press. 

Zemik, U. (1989). Paradigms in Lexical Acquisition. In: U. Zernik ted.), Proceedings of the k)rst biternational Lexical Acquisition Workshop, Detroit. 

