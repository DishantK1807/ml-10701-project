Extending Lambek grammars: a logical account of minimalist grammars Alain Lecomte CLIPS-IMAG Universit´e Pierre Mend`es-France, BSHM 1251 Avenue Centrale, Domaine Universitaire de St Martin d’H`eres BP 47 38040 GRENOBLE cedex 9, France Alain.Lecomte@upmf-grenoble.fr Christian Retor´e IRIN, Universit´e de Nantes 2, rue de la Houssini`ere BP 92208 44322 Nantes cedex 03, France retore@irisa.fr Abstract We provide a logical definition of Minimalist grammars, that are Stabler’s formalization of Chomsky’s minimalist program.
Our logical definition leads to a neat relation to categorial grammar, (yielding a treatment of Montague semantics), a parsing-asdeduction in a resource sensitive logic, and a learning algorithm from structured data (based on a typing-algorithm and type-unification).
Here we emphasize the connection to Montague semantics which can be viewed as a formal computation of the logical form.
1 Presentation
The connection between categorial grammars (especially in their logical setting) and minimalist grammars, which has already been observed and discussed (Retor´e and Stabler, 1999), deserve a further study: although they both are lexicalized, and resource consumption (or feature checking) is their common base, they differ in various respects.
On the one hand, traditional categorial grammar has no move operation, and usually have a poor generative capacity unless the good properties of a logical system are damaged, and on the other hand minimalist grammars even though they were provided with a precise formal definition (Stabler, 1997), still lack some computational properties that are crucial both from a theoretical and a practical viewpoint.
Regarding applications, one needs parsing, generation or learning algorithms, and, considering more conceptual aspects, such algorithms are needed too to validate or invalidate linguistic claims regarding economy or efficiency.
Our claim is that a logical treatment of these grammars leads to a simpler description and well defined computational properties.
Of course among these aspects the relation to semantics or logical form is quite important; it is claimed to be a central notion in minimalism, but logical forms are rather obscure, and no computational process from syntax to semantics is suggested.
Our logical presentation of minimalist grammar is a first step in this direction: to provide a description of minimalist grammar in a logical setting immediately set up the computational framework regarding parsing, generation and even learning, but also yields some good hints on the computational connection with logical forms.
The logical system we use, a slight extension of (de Groote, 1996), is quite similar to the famous Lambek calculus (Lambek, 1958), which is known to be a neat logical system.
This logic has recently shown to have good logical properties like the subformula property which are relevant both to linguistics and computing theory (e.g.
for modeling concurrent processes).
The logic under consideration is a super-imposition of the Lambek calculus (a non commutative logic) and of intuitionistic multiplicative logic (also known as Lambek calculus with permutation).
The context, that is the set of current hypotheses, are endowed with an order, and this order is crucial for obtaining the expected order on pronounced and interpreted features but it can also be relaxed when necessary: that is when its effects have already been recorded (in the labels) and the corresponding hypotheses can therefore be discharged.
Having this logical description of syntactic analyses allows to reduce parsing (and production) to deduction, and to extract logical forms from the proof; we thus obtain a close connection between syntax and semantics as the one between Lambek-style analyses and Montague semantics.
2 The
grammatical architecture The general picture of these logical grammars is as follows.
A lexicon maps words (or, more generally, items) onto a logical formula, called the (syntactic) type of the word.
Types are defined from syntactic of formal features a0 (which are propositional variables from the logical viewpoint): a1 categorial features (categories) involved in merge: BASE a2a4a3a6a5a8a7a10a9a11a7a10a12a13a7a15a14a11a7a17a16a18a7a20a19a20a19a20a19a22a21 a1 functional features involved in move: FUN a2a4a3 a23a18a7 a24a13a7 a25a27a26a18a7a20a19a20a19a20a19a28a21 The connectives in the logic for constructing formulae are the Lambek implications (or slashes) a29 a7a31a30 together with the commutative product of linear logic a32. 1 Once an array of items has been selected, a sentence (or any phrase) is a deduction of IP (or of the phrasal category) under the assumptions provided by the syntactic types of the involved items.
This first step works exactly as Lambek grammars, except that the logic and the formulae are richer.
Now, in order to compute word order, we proceed by labeling each formula in the proof.
These labels, that are called phonological and semantic features in the transformational tradition, are computed from the proofs and consist of two parts that can be superimposed: a phonological label, denoted by a30a34a33a36a35a38a37a6a39a40a30, and a semantic label2 denoted by a41a42a33a36a35a38a37a6a39a40a43 — the super-imposition of both 1The logical system also contains a commutative implication, a44a6a45, and a non commutative product a46 but they do not appear in the lexicon, and because of the subformula property, they are not needed for the proofs we use.
2We prefer semantic label to logical form not to confuse logical forms with the logical formulae present at each node of the proof.
label being denoted by a33a36a35a38a37a6a39 . The reason for having such a double labeling, is that, as usual in minimalism, semantic and phonological features can move separately.
It should be observed that the labels are not some extraneous information; indeed the whole information is encoded in the proof, and the labeling is just a way to extract the phonological form and the logical form from the proof.
We rather use chains or copy theory than movements and traces: once a label or one aspect (semantic or phonological) has been met it should be ignored when it is met again.
For instance a label a47a49a48a51a50a52a48 a37a53a41a55a54a4a56a57a37a59a58a60a43a62a61a63a35a38a64 a48a34a65 a54a66a56a27a37a59a58 corresponds to a semantic label a41 a47a49a48a51a50a52a48 a37a67a43a68a41a55a54a66a56a27a37a59a58a69a43a70a41a63a61a63a35a38a64 a48 a43 and to the phonological form a30 a47a49a48a20a50a10a48 a37a57a30a71a30a38a61a63a35a34a64 a48a72a65 a30a73a30a74a54a66a56a27a37a59a58a69a30 . 3 Logico-grammatical rules for merge and phrasal movement Because of the sub-formula property we need not present all the rules of the system, but only the ones that can be used according to the types that appear in the lexicon.
Further more, up to now there is no need to use introduction rules (called hypothetical reasoning in the Lambek calculus): so our system looks more like Combinatory Categorial Grammars or classical ABgrammars.
Nevertheless some hypotheses can be cancelled during the derivation by the productelimination rule.
This is essential since this rule is the one representing chains or movements.
We also have to specify how the labels are carried out by the rules.
At this point some non logical properties can be taken into account, for instance the strength of the features, if we wish to take them into account.
They are denoted by lower-case variables.
The rules of this system in a Natural Deduction format are: a75a77a76a79a78a81a80a27a82 a30a38a83 a84 a76 a58 a80 a83 a85 a30a38a86a68a87 a75a89a88 a84 a76a90a78 a58 a80a57a82 a84 a76 a58 a80 a83 a75a77a76a79a78a81a80 a83 a29 a82 a85 a29 a86a70a87 a84 a88a15a75a91a76 a58 a78a92a80a57a82 a75 a85 a41a55a84a79a93 a88 a84a95a94a51a43a96a87 a76a97a82 a48a20a98a99a50 a37a59a35a31a100a101a58 a75 a85 a41a55a84a79a93a51a7a102a84a95a94a51a43a96a87 a76a97a82 a75a77a76a97a103a104a80a67a82 a32a105a83 a84a97a7 a78a81a80a57a82 a7a10a58 a80 a83a90a7a102a84a95a106 a76a90a107a108a80a40a109 a85 a32a73a86a70a87 a84a97a7 a75 a7a102a84 a106 a76a110a107 a85 a103 a30a57a3 a78 a7a10a58a11a21a20a87 a80a40a109 This later rule encodes movement and deserves special attention.
The label a107 a85a103 a30a57a3 a78 a7a10a58a11a21a20a87 means the substitution of a103 to the unordered set a3 a78, a58a11a21 that is the simultaneous substitution of a103 for both a78 and a58, no matter the order between a78 and a58 is.
Here some non logical but linguistically motivated distinction can be made.
For instance according to the strength of a feature (e.g.
weak case a23 versus strong case a24 ), it is possible to decide that only the semantic part that is a41 a103 a43 is substituted with a78 . In the figure 1, the reader is provided with an example of a lexicon and of a derivation.
The resulting label is a41a63a56a1a0 a35a59a35a3a2a60a43a18a37 a48 a56a40a39 a65 a56a4a0 a35a38a35a3a2 phonological form is a30a34a37 a48 a56a27a39 a65 a30a70a30a38a56a5a0 a35a38a35a3a2a60a30 while the resulting logical form is a41a63a56a6a0 a35a59a35a3a2a60a43 a41a42a37 a48 a56a40a39 a65 a43 . Notice that language variation from SVO to SOV does not change the analysis.
To obtain the SOV word order, one should simply use a24 (strong case feature) instead of a23 (weak case feature) in the lexicon, and use the same analysis.
The resulting label would be a56a5a0 a35a59a35a3a2a53a37 a48 a56a27a39 a65 a56a5a0 a35a38a35a3a2 which yields the phonological from a30a38a56a7a0a31a35a59a35a3a2a60a30a73a30a34a37 a48 a56a40a39 a65 a30 and the logical form remains the same a41a63a56a6a0 a35a59a35a3a2a60a43 a41a42a37 a48 a56a40a39 a65 a43 . Observe that although entropy which suppresses some order has been used, the labels consist in ordered sequences of phonological and logical forms.
It is so because when using [/ E] and [a29 E], we necessarily order the labels, and this order is then recorded inside the label and is never suppressed, even when using the entropy rule: at this moment, it is only the order on hypotheses which is relaxed.
In order to represent the minimalist grammars of (Stabler, 1997), the above subsystem of partially commutative intuitionistic linear logic (de Groote, 1996) is enough and the types appearing in the lexicon also are a strict subset of all possible types: Definition 1 a8a10a9 -proofs contain only three kinds of steps: a1 implication steps (elimination rules for / and a29 ) a1 tensor steps (elimination rule for a32 ) a1 entropy steps (entropy rule) Definition 2 A lexical entry consists in an axiom a76 a33 a80a12a11 where a11 is a type: a41a10a41a14a13 a94 a29 a41a14a13a16a15 a29 a19 a19 a19a22a41a14a13a18a17 a29 a41a20a19a53a93a74a32a6a19a73a94a72a32 a19 a19 a19a32a21a19a23a22a70a32 a82 a43a10a43a10a43a10a43a10a30a24a13a89a93a74a43 where: a1 m and n can be any number greater than or equal to 0, a1 F a93, ..., Fa17 are attractors, a1 G a93, ..., Ga22 are features, a1 A is the resulting category type Derivations in this system can be seen as Tmarkers in the Chomskyan sense.
[/E] and [a29 E] steps are merge steps.
[a32 E] gives a co-indexation of two nodes that we can see as a move step.
For instance in a tree presentation of natural deduction, we shall only keep the coindexation (corresponding to the cancellation of a82 and a83 : this is harmless since the conclusion is not modified, and makes our natural deduction T-markers).
Such lexical entries, when processed with a8a10a9 -rules encompass Stabler minimalist grammars; this system nevertheless overgenerates, because some minimalist principles are not yet satisfied: they correspond to constraints on derivations.
3.1 Conditions
on derivations The restriction which is still lacking concerns the way the proofs are built.
Observe that this is an algorithmic advantage, since it reduces the search space.
The simplest of these restriction is the following: the attractor F in the label L of the target a25 locates the closest F’ in its domain.
This simply corresponds to the following restriction.
Definition 3 (Shortest Move) : A a8a10a9 -proof is said to respect the shortest move condition if it is such that: a1 the same formula never occurs twice as a hypothesis of any sequent a1 every active hypothesis during the proof process is discharged as soon as possible The consequences of this definition are the following: Figure 1: reads a book a37 a48 a56a27a39 a65 a80 a80 a2 a76 a37 a48 a56a40a39 a65a49a80 a41a10a41 a23 a29 a12a1a0a11a43a10a30a38a14a8a43 a56 a80 a80 a2 a76 a56 a80 a41a10a41a63a14a70a32 a23a60a43a10a30a51a16a11a43 a0a31a35a59a35a3a2 a80 a80 a2 a76 a0 a35a59a35 a2 a80 a16 a76 a56 a80 a41a10a41a63a14a68a32 a23a69a43a10a30a51a16a11a43 a76 a0 a35a59a35a3a2 a80 a16 a85 a30a38a86a70a87 a76 a56a6a0 a35a59a35a3a2 a80 a14a70a32 a23 a58 a80 a23 a76 a58 a80 a23 a76 a37 a48 a56a40a39 a65a53a80 a41a10a41 a23 a29 a12a2a0a11a43a10a30a38a14a8a43 a78a81a80 a14 a76a79a78a81a80 a14 a85 a30a38a86a68a87 a78a92a80 a14 a76 a37 a48 a56a27a39 a65 a78a81a80 a41 a23 a29 a12a2a0a101a43 a85 a29 a86a70a87 a58 a80 a23 a88a10a78a81a80 a14 a76 a58a70a37 a48 a56a40a39 a65 a78a92a80 a12a1a0 a85 a48a51a98a99a50 a37a6a35a31a100a101a58a27a87 a58 a80 a23a18a7 a78a81a80 a14 a76 a58a70a37 a48 a56a40a39 a65 a78a92a80 a12a1a0 a85 a32a70a86a70a87 a76 a41a63a56 a0 a35a59a35a3a2a60a43a99a37 a48 a56a40a39 a65 a56a21a0a31a35a59a35a3a2 a80 a12a2a0 1.
a3a5a4 ...
a3a6a4 ...
a3a51a94 ...
a76 C is forbidden 2.
a1 if there is a sequent ...
a3 ...
a76 a3 a106 a29 C a1 if there is a type a3 a106 such that a75a77a76 a3 a106 a32a7a3 is a (proper or logical) axiom, a1 then a hypothesis a3 a106 must be introduced, rather than any constant a3 a106, in order to discharge a3 We may see an application of this condition in the fact that sentences like: *Whoa94 do you know [whoa93 ea94 likes ea93 ] *Whoa94 do you know [whoa93 ea93 likes ea94 ] are ruled out.
Let us look at the beginning of their derivation (in a tree-like presentation of natural deduction proofs): at the stage where we stop the deduction on figure 2, we cannot introduce a new hypothesis a8a38a94 a80 a23 a32 a14 because there is already an active one (a8a67a93 ), the only possible continuation is to discharge a58 a94 and a78 a94 altogether by means of a ”constant”, like a9 a56a57a37a59a58, so that, in contrast: You know [whoa93 Mary likes ea93 ] is correct.
3.2 Extension
to head-movement We have seen above that we are able to account for SVO and SOV orders quite easily.
Nevertheless we could not handle this way VSO language.
Indeed this order requires head-movement.
In order to handle head-movement, we shall also use the product a32 but between functor types.
As a first example, let us take the very simple example of: peter loves mary.
Starting from the following lexicon in figure 3 we can build the tree given in the same figure; it represents a natural deduction in our system, hence a syntactic analysis.
The resulting phonological form is a30 a47a49a48a51a50a52a48 a37a57a30a6a30a38a61a42a35a38a64 a48a72a65 a30a6a30a74a54a66a56a27a37a59a58a69a30 while the resulting logical form is a41 a47a49a48a51a50a52a48 a37a67a43a74a41a55a54a4a56a27a37a38a58a60a43a74a41a63a61a63a35a38a64 a48a72a65 a43 — the possibility to obtain SOV word order with a a24 instead of a a23 also applies here.
4 The
interface between syntax and semantics In categorial grammar (Moortgat, 1996), the production of logical forms is essentially based on the association of pairs a10 a65a72a50 a37a5a11 a98a13a12 a7 a50 a58a34a100 a48a15a14 with lambda terms representing the logical form of the items, and on the application of the Curry-Howard homomorphism: each (a30 or a29 ) elimination rule translates into application and each introduction step into abstraction.
Compositionality assumes that each step in a derivation is associated with a semantical operation.
In generative grammar (Chomsky, 1995), the production of logical forms is in last part of the derivation, performed after the so-called Spell Out point, and consists in movements of the semantical features only.
Once this is done, two forms can be extracted from the result of the derivation: a phonological form and a logical one.
These two approaches are therefore very differFigure 2: Complex NP constraint a58a67a94 a80 a23 a41a10a41 a23 a29 a9a60a43a10a30a34a12a1a0a11a43 a78 a94 a80 a14 a0 a4 a80 a23a49a32a105a14 a1 a58 a93 a80 a23 a61 a11 a2 a48a34a65a53a80 a41a10a41 a23 a29 a41a63a14 a29 a12a2a0a101a43a10a43a10a30a38a14a69a43 a1a78 a93 a80 a14 a61 a11 a2 a48a72a65 a78 a93 a80 a41 a23 a29 a41a63a14 a29 a12a2a0a11a43a10a43 a58a8a93 a61 a11 a2 a48a72a65 a78 a93 a80 a41a63a14 a29 a12a1a0a11a43 a8a67a93 a61 a11 a2 a48a34a65a53a80 a41a63a14 a29 a12a2a0a101a43 a78 a94 a8 a93 a61 a11 a2 a48a72a65a53a80 a12a1a0 a78 a94 a8a6a93 a61 a11 a2 a48a34a65a53a80 a41 a23 a29 a9a60a43 a58a67a94 a78 a94 a8a6a93 a61 a11 a2 a48a72a65a53a80 a9 Figure 3: Peter loves Mary a61a63a35a38a64 a48a34a65 a80 a80 a2 a76 a61a63a35a34a64 a48a72a65a49a80 a41a10a41 a23 a29a3a2 a0a11a43a10a30a34a12a1a0a11a43a62a32 a41a10a41 a23 a29 a41a63a14 a29 a12a1a0a13a43a10a43a10a30a38a14a69a43 a100 a48a51a50a52a48 a37 a80 a80 a2 a76 a100 a48a20a50a10a48 a37 a80 a23a49a32a105a14 a9 a56a27a37a59a58 a80 a80 a2 a76 a9 a56a57a37a59a58 a80 a23a68a32 a14 a2 a0 peter a23 a93 a41 a23 a29a3a2 a0a101a43 lovesa4 a41a10a41 a23 a29a3a2 a0a101a43a10a30a34a12a2a0a11a43 a12a1a0 a14 a93 a41a63a14 a29 a12a2a0a11a43 (mary) a23 a94 a41 a23 a29 a41a63a14 a29 a12a2a0a11a43a10a43 (to love) a41a10a41 a23 a29 a41a63a14 a29 a12a1a0a11a43a10a43a10a30a38a14a8a43 a15 mary a14 a94 ent, but we can try to make them closer by replacing semantic features by lambda-terms and using some canonical transformations on the derivation trees.
Instead of converting directly the derivation tree obtained by composition of types, something which is not possible in our translation of minimalist grammars, we extract a logical tree from the previous, and use the operations of CurryHoward on this extracted tree.
Actually, this extracted tree is also a deduction tree: it represents the proof we could obtain in the semantic component, by combining the semantic types associated with the syntactic ones (by a homomorphism a0 to specify).
Such a proof is in fact a proof in implicational intuitionistic linear logic.
4.1 Logical
form for example 3 Coindexed nodes refer to ancient hypotheses which have been discharged simultaneously, thus resulting in phonological features and semantical ones at their right place3.
By extracting the subtree the leaves of which are full of semantic content, we obtain a structure that can be easily seen as a composition: (peter)((mary)(to love)) If we replace these ”semantic features” by a1 terms, we have: a41a2a1a4a3 a19a5a3 a41a100 a48a51a50a52a48 a37a57a43a31a7a72a41a2a1a4a3 a19a5a3 a41 a9 a56a27a37a38a58a60a43a31a7a6a1 a78 a19a7a1a60a58a11a19a61a63a35a38a64 a48 a41a42a58a11a7 a78 a43a10a43a10a43 This shows that necessarily raised constituants in the structure are not only ”syntactically” raised but also ”semantically” lifted, in the sense that a1a4a3 a19a5a3 a41a100 a48a51a50a52a48 a37a57a43 is the high order representation of the individual peter4.
4.2 Subject
raising Let us look at now the example: mary seems to work From the lexicon in figure 4 we obtain the deduction tree given in the same figure.
3For the time being, we make abstraction of the representation of time, mode, aspect... that would be supported by the inflection category.
4It is important to notice that if we consider a8a10a9a12a11a9a14a13a16a15a18a17a20a19a6a21a23a22 a typed lambda term, we must only assume it is of some type freely raised from a24, something we can represent by a13a25a13a16a24a27a26a29a28a30a22a31a26a29a28a30a22, where X is a type-variable, here X = a13a16a24a32a26a34a33a35a22 becausea8a10a36a12a11a8a10a21a37a11a38a40a39a42a41a20a43a44a13a16a21a46a45a47a36a37a22 has type a13a16a24a32a26a48a13a16a24a32a26a34a33a49a22a25a22 This time, it is not so easy to obtain the logical representation: a65a38a48a72a48 a9 a41 a50 a35 a33a36a35a38a37 a2a99a41 a9 a56a57a37a59a58a60a43a10a43 The best way to handle this situation consists in assuming that: a1 the verbal infinitive head (here to work) applies to a variable a78 which occupies the a14 position, a1 the semantics of the main verb (here to seem) applies to the result, in order to obtain a65a34a48a34a48 a9 a41 a50 a35 a33a36a35a38a37 a2a99a41 a78 a43a10a43, a1 the a78 variable is abstracted in order to obtain a1 a78 a19a65a34a48a34a48 a9 a41 a50 a35 a33a36a35a38a37 a2a99a41 a78 a43a10a43 just before the semantic content of the specifier (here the nominative position, occupied by a1a4a3 a19a5a3 a41 a9 a56a27a37a38a58a60a43 ) applies.
This shows that the semantic tree we want to extract from the derivation tree in types logic is not simply the subtree the leaves of which are semantically full.
We need in fact some transformation which is simply the stretching of some nodes.
These stretchings correspond to a50 -introduction steps in a Natural deduction tree.
They are allowed each time a variable has been used before, which is not yet discharged and they necessarily occur just before a semantically full content of a specifier node (that means in fact a node labelled by a functional feature) applies.
Actually, if we say that the tree so obtained represents a deduction in a natural deduction format, we have to specify which formulae it uses and what is the conclusion formula.
We must therefore define a homomorphism between syntactic and semantic types.
Let a0 be this homomorphism.
We shall assume: a1 a0 (a2 a0 )=t, a0 (a12a1a0 )a51 a3 t,a41a47a52a53a50a55a54a38a43a102a21, a0 (a14 )=e, a1 a0a77a41a2a56 a29a20a57 a43 =a0a77a41 a57 a30a46a56a27a43 = a41 Ha41a2a56a40a43a58a50 Ha41 a57 a43a10a43, a1a60a59 a61 H a41 a61 a43a62a51a91a3a27a41a10a41a47a52a63a50a65a64a97a43a66a50a29a64 a43a31a7a72a41a47a64a67a50a29a64 a43a102a21 5 5X is a variable of type.
This may appear as nondeterminism but the instantiation of X is always unique.
Moreover, when a68 is of type a13a16a69a70a26a29a69a71a22, it is in fact endowed with the identity function, something which happens everytime a68 is linked by a chain to a higher node.
Figure 4: Mary seems to work a65a38a48a72a48 a9 a65 a80 a80 a2 a76a97a65a34a48a34a48 a9 a65a49a80 a41a10a41 a23 a29a3a2 a0a11a43a10a30a34a12a1a0a11a43a62a32 a41a42a12a2a0a11a30a34a12a1a0a101a43 a9 a56a27a37a59a58 a80 a80 a2 a76 a9 a56a57a37a59a58 a80 a14a73a32 a23 a50 a35 a33a71a35a34a37 a2 a80 a80 a2 a76a79a50 a35 a33a36a35a38a37 a2 a80 a41a63a14 a29 a12a1a0a11a43 a2 a0 mary a23 a93 a41 a23 a29a3a2 a0a11a43 seemsa0 a41a10a41 a23 a29a3a2 a0a11a43a10a30a34a12a2a0a101a43 a12a1a0 (to seem) a41a42a12a1a0a11a30a34a12a1a0a11a43 a94 a12a1a0 a14 a93 to work a41a63a14 a29 a12a1a0a11a43 With this homomorphism of labels, the transformation of trees consisting in stretching ”intermediary projection nodes” and erasing leaves without semantic content, we obtain from the derivation tree of the second example, the following ”semantic” tree: seem(to work(mary)) a54 a8a10a9a12a11a9a14a13a16a15a30a17a20a19a42a21a23a22 a41a10a41a47a52a53a50a55a54a38a43a58a50a55a54a38a43 a8a10a36 a11a1a49a43a35a43a49a15 a13 a2 a39 a3 a39a6a19a5a4 a13a16a36a46a22a25a22 a41a47a52a63a50a55a54a38a43 a93 t a8a10a41 a11a1a49a43a42a43a49a15 a13a16a41 a22 a41 a54a30a50a29a54a38a43 to work(x) a54 a8a10a21a46a11 a2 a39 a3 a39a42a19a5a4 a13a16a21a23a22 a41a47a52a63a50a29a54a38a43 x a52 a93 where coindexed nodes are linked by the discharging relation.
Let us notice that the characteristic weak or strong of the features may often be encoded in the lexical entries.
For instance, Head-movement from V to I is expressed by the fact that tensed verbs are such that: a1 the full phonology is associated with the inflection component, a1 the empty phonology and the semantics are associated with the second one, a1 the empty semantics occupies the first one6 Unfortunately, such rigid assignment does not always work.
For instance, for phrasal movement (say of a a14 to a a23 ) that depends of course on the particular a23 -node in the tree (for instance the situation is not necessary the same for nominative and for accusative case).
In such cases, we may assume that multisets are associated with lexical entries instead of vectors.
4.3 Reflexives
Let us try now to enrich this lexicon by considering other phenomena, like reflexive pronouns.
The assignment for himself is given in figure 5 — where the semantical type of himself is assumed to be a41a10a41 a48 a50 a41 a48 a50 a50 a43a10a43 a50 a41 a48 a50 a50 a43a10a43 . We obtain for paul shaves himself as the syntactical tree something similar to the tree obtained for our first little example (peter loves mary), and the semantic tree is given in figure 5.
5 Remarks
on parsing and learning In our setting, parsing is reduced to proof search, it is even optimized proof-search: indeed the re6as long we don’t take a semantical representation of tense and aspect in consideration.
Figure 5: Computing a semantic recipe: shave himself a65a1a0 a56a27a64 a48a72a65 a80 a80 a2 a85 a65a2a0 a56a57a64 a48a72a65a53a80a4a3 a80 a41a10a41 a23 a29a3a2 a0a101a43a10a30a34a12a2a0a101a43a96a87a69a32 a85a6a5 a80 a1 a78 a19a7a1a60a58a13a19 a65a2a0 a56a57a64 a48 a41a42a58a13a7 a78 a43 a80 a41a10a41 a23 a29 a41a63a14 a29 a12a1a0a11a43a10a43a10a30a38a14a69a43a96a87 a0 a11 a9 a65a34a48 a61a8a7 a80 a80 a2 a85a6a5 a80 a1 a3 a19a7a1 a8a69a19a5a3 a41 a8a69a7 a8a27a43 a80 a23a27a87a8a32 a85 a0 a11 a9 a65a38a48 a61a9a7 a80a6a78a81a80 a14a67a87 shave(paul,paul) a54 a8a10a9a12a11a9a14a13a6a10 a17a20a9a46a38a16a22 a41a10a41a47a52a63a50a29a54a59a43a58a50a55a54a38a43 a8a12a11a23a11a1a14a13a23a17 a41a20a43a44a13a15a11a23a45a8a11a44a22 a41a47a52a53a50a55a54a38a43a17a16 shave(z,z) a54 z a52a18a16 a8a12a11a23a11a1a19a13a10a17a20a41a20a43a20a13a15a11 a45a9a11a44a22 a41a47a52a53a50a55a54a59a43 a8a10a9a12a11a8a12a11a23a11a9a14a13a15a11 a45a20a11a44a22 a41a10a41a47a52 a50 a41a47a52 a50a55a54a59a43a10a43 a50 a41a47a52a53a50a55a54a38a43a10a43 a8a10a36a12a11a8a10a21a46a11a1a14a13a23a17 a41a20a43a44a13a16a21a46a45a47a36a46a22 a41a47a52 a50 a41a47a52 a50a55a54a59a43 a4 a43 a8a10a21a46a11a1a14a13a23a17 a41a20a43a44a13a16a21a46a45a47a36a46a22 a41a47a52a53a50a55a54a38a43 a8a10a36 a11a8a10a21a46a11a1a19a13a10a17a20a41a20a43a44a13a16a21a37a45a36a37a22 a41a47a52a63a50 a41a47a52a63a50a29a54a38a43a10a43 a36 a52 a4 striction on types, and on the structure of proof imposed by the shortest move principle and the absence of introduction rules considerably reduce the search space, and yields a polynomial algorithm.
Nevertheless this is so when traces are known: otherwise one has to explore the possible places of theses traces.
Here we did focus on the interface with semantics.
Another excellent property of categorial grammars is that they allow — especially when there are no introduction rules — for learning algorithms, which are quite efficient when applied to structured data.
This kind of algorithm applies here as well when the input of the algorithm are derivations.
6 Conclusion
In this paper, we have tried to bridge a gap between minimalist program and the logical view of categorial grammar.
We thus obtained a description of minimalist grammars which is quite formal and allows for a better interface with semantics, and some usual algorithms for parsing and learning.
References Noam Chomsky.
1995. The minimalist program.
MIT Press, Cambridge, MA.
Philippe de Groote.
1996. Partially commutative linear logic.
In M.
Abrusci and C.
Casadio, editors, Third Roma Workshop: Proofs and Linguistics Categories, pages 199-208.
Bologna:CLUEB. Joachim Lambek.
1958. The mathematics of sentence structure.
American mathematical monthly, 65:154-169.
Michael Moortgat.
1996. Categorial type logic.
In J.
van Benthem and A.
ter Meulen, editors, Handbook of Logic and Language, chapter 2, pages 93-177.
North-Holland Elsevier, Amsterdam.
Christian Retore and Edward Stabler.
1999. Resource logics and minimalist grammars: introduction to the ESSLLI workshop.
To appear in Language and Computation RR-3780 Edward Stabler.
1997. Derivational minimalism.
In Christian Retore, editor, LACL-96, volume 1328 of LNCS/LNAI, pages 68-95. Springer-Verlag .

