This temporal constraint is based on empirical investigation of multimodal interaction (Oviatt et al 1997).
W97-1401
Wittenburg et al (1991) employ a unification-based grammar formalism augmented with functional constraints (F-PATR, Wittenburg 1993), and a bottomup, incremental, Earley-style (Earley 1970) tabular parsing algorithm.
P93-1029
Johnston et al (1997) model this integration using a unification operation over typed feature structures.
P97-1036
It is currently undergoing extensive user testing and evaluation (McGee et al 1998).
P98-2136
In the approach to multimodal integration proposed by Johnston et al 1997, integration of spoken and gestural input is driven by a unification operation over typed feature structures (Carpenter 1992) representing the semantic contributions of the different modes.
P97-1036
Empirical investigation (Oviatt 1996, Oviatt et al 1997) has shown that multimodal utterances rarely contain more than two or three elements.
W97-1401
The addition of functional constraints is common in HPSG and other unification grammar formalisms (Wittenburg 1993).
P93-1029
in Multidimensional Space The integrator in Johnston et al 1997 does in essence parse input, but the resulting structures can only be unary or binary trees one level deep; unimodal spoken or gestural commands and multimodal combinations consisting of a single spoken element and a single gesture.
P97-1036
The approach of Johnston et al 1997 also faces fundamental architectural problems.
P97-1036
The system has undergone a form of pro-active evaluation in that its design is informed by detailed predictive modeling of how users interact multimodally, and incorporates the results of empirical studies of multimodal interaction (Oviatt 1996, Oviatt et al 1997).
W97-1401
The basic multimodal integration strategy of Johnston et al 1997 is now just one rule among many (Figure 7).
P97-1036
