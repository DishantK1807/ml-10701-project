1:211	IJCNLP 2008    Sixth SIGHAN Workshop on Chinese Language Processing  Proceedings of the Workshop      1112 January 2008 Hyderabad, India 2008 Asian Federation of Natural Language Processing                                                                                                                        ii Preface Welcome to Hyderabad for the Sixth SIGHAN Workshop on Chinese Language Processing!
2:211	As the workshop co-chairs, we are indeed honored to pen the first few words in the SIGHAN-6 proceedings.
3:211	Over the last few years, exciting research endeavors in Chinese language processing have been pursued vigorously all over the world.
4:211	We feel privileged to be able to chair the Sixth SIGHAN, particularly at this juncture in our history when the Chinese language is receiving worldwide attention which places us at an important period of growth and change.
5:211	SIGHAN-6 received 14 regular paper submissions this year, 9 of which are accepted for presentation, contributing to yet another stimulating and inspiring scientific program.
6:211	We would like to thank all the authors who submitted their research work, and all the reviewers who have put an immense amount of timely and quality work into the paper review.
7:211	We would also like to express our gratitude and appreciation to the chair of SIGHAN, Prof. Benjamin Tsou, who has led SIGHAN to what it is today, especially for his invaluable advice at various stages of the development of SIGHAN-6.
8:211	Our workshop also uniquely features the Fourth International Chinese Language Processing Bakeoff, which was jointly held with the First CIPS Chinese Language Processing Evaluation over the summer of 2007.
9:211	In addition to the classic Chinese word segmentation and named entity recognition tasks, there is a new track on Chinese POS-tagging.
10:211	The bakeoff was co-organized by SIGHAN, ChineseLDC, and the Verifying Center on Chinese Language and Character Standards of the State Language Commission of PRC, and coordinated by Dr. Guangjin Jin of the Institute of Applied Linguistics, MOE, China.
11:211	Special thanks to Dr. Jin and the bakeoff organizing committee for organizing another successful bakeoff.
12:211	The generous support from the benchmarking corpora providers (Academia Sinica; City University of Hong Kong; Institute of Applied Linguistics, MOE, China; Microsoft Research Asia; Peking University; Shanxi University; and University of Colorado) is greatly appreciated.
13:211	Certainly the bakeoff cannot stand without the support from the 28 participating teams.
14:211	We have collected 23 bakeoff system reports in this volume.
15:211	SIGHAN-6 marks its second time to co-locate with IJCNLP, the flagship conference of the Asian Federation of Natural Language Processing.
16:211	The organization of our workshop will not be so smooth without all the logistic support from the IJCNLP-08 committee, particularly the Workshop Committee, the Publication Chair Dr. Jing-Shin Chang, as well as everyone in the Local Organizing Committee.
17:211	To them we would like to express our heartiest gratitude.
18:211	Last but not least, thank you for your active participation.
19:211	Enjoy our program, and we wish you an educational and entertainment-filled experience in Hyderabad.
20:211	Olivia Oi Yee Kwong and Haizhou Li November 2007 iii  Organizers Workshop Co-Chairs: Olivia Oi Yee Kwong, City University of Hong Kong Haizhou Li, Institute for Infocomm Research Bakeoff Organizing Committee: Guangjin Jin, Institute of Applied Linguistics, MOE, PRC (Co-ordinator) Xiao Chen, City University of Hong Kong Yongsheng Guo, Institute of Applied Linguistics, MOE, PRC Changning Huang, Microsoft Research Asia Qun Liu, Chinese Academy of Sciences Program Committee: Keh-Jiann Chen, Academia Sinica Minghui Dong, Institute for Infocomm Research Jianfeng Gao, Microsoft Chu-Ren Huang, Academia Sinica Xuanjing Huang, Fudan University Donghong Ji, Wuhan University Daniel Jurafsky, Stanford University Chunyu Kit, City University of Hong Kong Kui-Lam Kwok, Queens College Gina-Anne Levow, University of Chicago Dekang Lin, Google Qun Liu, Chinese Academy of Sciences Qin Lu, Hong Kong Polytechnic University Qing Ma, Ryukoku University Jianyun Nie, University of Montreal Hwee Tou Ng, National University of Singapore Martha Palmer, University of Colorado Scott Piao, University of Manchester Richard Sproat, University of Illinois at Urbana-Champaign Keh-Yih Su, Behavior Design Corporation Maosong Sun, Tsinghua University Bing Swen, Peking University Benjamin Tsou, City University of Hong Kong Haifeng Wang, Toshiba (China) R&D Center Kam-Fai Wong, Chinese University of Hong Kong Dekai Wu, Hong Kong University of Science and Technology Yujie Zhang, National Institute of Information and Communications Technology of Japan Jun Zhao, Chinese Academy of Sciences v Tiejun Zhao, Harbin Institute of Technology Ming Zhou, Microsoft Research Asia Jingbo Zhu, Northeastern University Additional Reviewers: Xiangyu Duan, Chinese Academy of Sciences Wei Gao, Chinese University of Hong Kong Shiqi Li, Harbin Institute of Technology Nianwen Xue, University of Colorado Yongzheng Xue, Harbin Institute of Technology vi Workshop Program Friday, 11 January 2008 09:0009:10 Opening Remarks Session 1: Translation and Transliteration 09:1009:35 An Example-based Decoder for Spoken Language Machine Translation Zhou-Jun Li, Wen-Han Chao and Yue-Xin Chen 09:3510:00 Automatic Extraction of English-Chinese Transliteration Pairs using Dynamic Window and Tokenizer Chengguo Jin, Seung-Hoon Na, Dong-Il Kim and Jong-Hyeok Lee 10:0010:25 Mining Transliterations from Web Query Results: An Incremental Approach Jin-Shea Kuo, Haizhou Li and Chih-Lung Lin 10:2511:00 Break Session 2: Information Extraction and Word Sense Disambiguation 11:0011:25 An Effective Hybrid Machine Learning Approach for Coreference Resolution Feiliang Ren and Jingbo Zhu 11:2511:50 Use of Event Types for Temporal Relation Identification in Chinese Text Yuchang Cheng, Masayuki Asahara and Yuji Matsumoto 11:5012:15 Chinese Word Sense Disambiguation with PageRank and HowNet Jinghua Wang, Jianyi Liu and Ping Zhang 12:1514:15 Lunch vii Friday, 11 January 2008 (continued) Session 3: Word Segmentation and Parsing 14:1514:40 Stochastic Dependency Parsing Based on A* Admissible Search Bor-shen Lin 14:4015:05 Analyzing Chinese Synthetic Words with Tree-based Information and a Survey on Chinese Morphologically Derived Words Jia Lu, Masayuki Asahara and Yuji Matsumoto 15:0515:30 Which Performs Better on In-Vocabulary Word Segmentation: Based on Word or Character?
21:211	Zhenxing Wang, Changning Huang and Jingbo Zhu 15:3016:00 Break Session 4: Bakeoff Overview and Presentations 16:0016:20 The Fourth International Chinese Language Processing Bakeoff: Chinese Word Segmentation, Named Entity Recognition and Chinese POS Tagging Guangjin Jin and Xiao Chen 16:2016:40 A Two-Stage Approach to Chinese Part-of-Speech Tagging Aitao Chen, Ya Zhang and Gordon Sun 16:4017:00 NOKIA Research Center Beijing Chinese Word Segmentation System for the SIGHAN Bakeoff 2007 Jiang Li, Rile Hu, Guohua Zhang, Yuezhong Tang, Zhanjiang Song and Xia Wang 17:0017:20 Chinese Word Segmentation and Named Entity Recognition Based on Conditional Random Fields Xinnian Mao, Yuan Dong, Saike He, Sencheng Bao and Haila Wang viii Saturday, 12 January 2008 Session 5: Bakeoff Presentations 09:1009:30 BUPT Systems in the SIGHAN Bakeoff 2007 Ying Qin, Caixia Yuan, Jiashen Sun and Xiaojie Wang 09:3009:50 The Character-based CRF Segmenter of MSRA&NEU for the 4th Bakeoff Zhenxing Wang, Changning Huang and Jingbo Zhu 09:5010:10 Chinese NER Using CRFs and Logic for the Fourth SIGHAN Bakeoff Xiaofeng Yu, Wai Lam, Shing-Kit Chan, Yiu Kei Wu and Bo Chen 10:1010:30 Unsupervised Segmentation Helps Supervised Learning of Character Tagging for Word Segmentation and Named Entity Recognition Hai Zhao and Chunyu Kit 10:3011:00 Break 11:0012:30 SIGHAN Business Meeting ix  Table of Contents Preface . . .
22:211	iii Organizers . . .
23:211	v Workshop Program . . .
24:211	vii An Example-based Decoder for Spoken Language Machine Translation Zhou-Jun Li, Wen-Han Chao and Yue-Xin Chen . . .
25:211	1 Automatic Extraction of English-Chinese Transliteration Pairs using Dynamic Window and Tokenizer Chengguo Jin, Seung-Hoon Na, Dong-Il Kim and Jong-Hyeok Lee . . .
26:211	9 Mining Transliterations from Web Query Results: An Incremental Approach Jin-Shea Kuo, Haizhou Li and Chih-Lung Lin . . .
27:211	16 An Effective Hybrid Machine Learning Approach for Coreference Resolution Feiliang Ren and Jingbo Zhu . . .
28:211	24 Use of Event Types for Temporal Relation Identification in Chinese Text Yuchang Cheng, Masayuki Asahara and Yuji Matsumoto . . .
29:211	31 Chinese Word Sense Disambiguation with PageRank and HowNet Jinghua Wang, Jianyi Liu and Ping Zhang . . .
30:211	39 Stochastic Dependency Parsing Based on A* Admissible Search Bor-shen Lin . . .
31:211	45 Analyzing Chinese Synthetic Words with Tree-based Information and a Survey on Chinese Morphologically Derived Words Jia Lu, Masayuki Asahara and Yuji Matsumoto . . .
32:211	53 Which Performs Better on In-Vocabulary Word Segmentation: Based on Word or Character?
33:211	Zhenxing Wang, Changning Huang and Jingbo Zhu . . .
34:211	61 The Fourth International Chinese Language Processing Bakeoff: Chinese Word Segmentation, Named Entity Recognition and Chinese POS Tagging Guangjin Jin and Xiao Chen . . .
35:211	69 A Two-Stage Approach to Chinese Part-of-Speech Tagging Aitao Chen, Ya Zhang and Gordon Sun . . .
36:211	82 NOKIA Research Center Beijing Chinese Word Segmentation System for the SIGHAN Bakeoff 2007 Jiang Li, Rile Hu, Guohua Zhang, Yuezhong Tang, Zhanjiang Song and Xia Wang . . .
37:211	86 xi Chinese Word Segmentation and Named Entity Recognition Based on Conditional Random Fields Xinnian Mao, Yuan Dong, Saike He, Sencheng Bao and Haila Wang.
38:211	.90 BUPT Systems in the SIGHAN Bakeoff 2007 Ying Qin, Caixia Yuan, Jiashen Sun and Xiaojie Wang . . .
39:211	94 The Character-based CRF Segmenter of MSRA&NEU for the 4th Bakeoff Zhenxing Wang, Changning Huang and Jingbo Zhu . . .
40:211	98 Chinese NER Using CRFs and Logic for the Fourth SIGHAN Bakeoff Xiaofeng Yu, Wai Lam, Shing-Kit Chan, Yiu Kei Wu and Bo Chen . . .
41:211	102 Unsupervised Segmentation Helps Supervised Learning of Character Tagging for Word Segmentation and Named Entity Recognition Hai Zhao and Chunyu Kit . . .
42:211	106 An Agent-Based Approach to Chinese Word Segmentation Samuel W.K. Chan and Mickey W.C. Chong . . .
43:211	112 Nanjing Normal University Segmenter for the Fourth SIGHAN Bakeoff Xiaohe Chen, Bin Li, Junzhi Lu, Hongdong Nian and Xuri Tang . . .
44:211	115 Two Step Chinese Named Entity Recognition Based on Conditional Random Fields Models Yuanyong Feng, Ruihong Huang and Le Sun . . .
45:211	120 A Morpheme-based Part-of-Speech Tagger for Chinese Guohong Fu and Jonathan J. Webster . . .
46:211	124 Chinese Named Entity Recognition and Word Segmentation Based on Character Jingzhou He and Houfeng Wang . . .
47:211	128 HMM and CRF Based Hybrid Model for Chinese Lexical Analysis Degen Huang, Xiao Sun, Shidou Jiao, Lishuang Li, Zhuoye Ding and Ru Wan.
48:211	.133 Chinese Tagging Based on Maximum Entropy Model Ka Seng Leong, Fai Wong, Yiping Li and Ming Chui Dong . . .
49:211	138 Training a Perceptron with Global and Local Features for Chinese Word Segmentation Dong Song and Anoop Sarkar . . .
50:211	143 A Study of Chinese Lexical Analysis Based on Discriminative Models Guang-Lu Sun, Cheng-Jie Sun, Ke Sun and Xiao-Long Wang . . .
51:211	147 Word Boundary Token Model for the SIGHAN Bakeoff 2007 Jia-Lin Tsai . . .
52:211	151 An Improved CRF based Chinese Language Processing System for SIGHAN Bakeoff 2007 Xihong Wu, Xiaojun Lin, Xinhao Wang, Chunyao Wu, Yaozhong Zhang and Dianhai Yu . . .
53:211	155 xii Description of the NCU Chinese Word Segmentation and Part-of-Speech Tagging for SIGHAN Bakeoff 2007 Yu-Chieh Wu, Jie-Chi Yang and Yue-Shi Lee.
54:211	.161 CRF-based Hybrid Model for Word Segmentation, NER and even POS Tagging Zhiting Xu, Xian Qian, Yuejie Zhang and Yaqian Zhou . . .
55:211	167 CRFs-Based Named Entity Recognition Incorporated with Heuristic Entity List Searching Fan Yang, Jun Zhao and Bo Zou . . .
56:211	171 A Chinese Word Segmentation System Based on Cascade Model Jianfeng Zhang, Jiaheng Zheng, Hu Zhang and Hongye Tan . . .
57:211	175 Achilles: NiCT/ATR Chinese Morphological Analyzer for the Fourth Sighan Bakeoff Ruiqiang Zhang and Eiichiro Sumita . . .
58:211	178 Author Index . . .
59:211	183 xiii  An Example-based Decoder for Spoken Language Machine Translation   Zhou-Jun Li Wen-Han Chao Abstract In this paper, we propose an example-based decoder for a statistical machine translation (SMT) system, which is used for spoken language machine translation.
60:211	In this way, it will help to solve the re-ordering problem and other problems for spoken language MT, such as lots of omissions, idioms etc. Through experiments, we show that this approach obtains improvements over the baseline on a Chinese-English spoken language translation task.
61:211	1 Introduction The state-of-the-art statistical machine translation (SMT) model is the log-linear model (Och and Ney, 2002), which provides a framework to incorporate any useful knowledge for machine translation, such as translation model, language model etc. In a SMT system, one important problem is the re-ordering between words and phrases, especially when the source language and target language are very different in word order, such as Chinese and English.
62:211	For the spoken language translation, the reordering problem will be more crucial, since the spoken language is more flexible in word order.
63:211	In addition, lots of omissions and idioms make the translation more difficult.
64:211	However, there exists some "useful" features, such as, most of the spoken text is shorter than the written text and there are some fixed translation structures.
65:211	For example,  ( ?
66:211	/ Would you please  ? ), (?/May I?).
67:211	We can learn these fixed structures and take them as rules, Chiang (2005) presents a method to learn these rules, and uses them in the SMT.
68:211	Generally, the number of these rules will be very large.
69:211	In this paper, we propose an example-based decoder in a SMT model, which will use the translation examples to keep the translation structure, i.e. constraint the reordering, and make the omitted words having the chance to be translated.
70:211	The rest of this paper is organized as follows: Since our decoder is based on the inversion transduction grammars (ITG) (Wu, 1997), we introduce the ITG in Section 2 and describe the derived SMT model.
71:211	In Section 3, we design the example-based decoder.
72:211	In Section 4, we test our model and compare it with the baseline system.
73:211	Then, we conclude in Section 5 and Section 6.
74:211	2 The SMT model ITG is a synchronous context-free grammar, which generates two output streams simultaneously.
75:211	It consists of the following five types of rules: jiji p ececAAAAA /|/|/||][ >< (1) Where A is the non-terminal symbol, [] and <> represent the two operations which generate outputs in straight and inverted orientation respectively.
76:211	and  are terminal symbols, which represent the words in both languages, i c j e   is the null National Laboratory for Parallel and Distributed Processing, Changsha, China School of Computer Science and Engineering, Beihang University, China lizj@buaa.edu.cn National Laboratory for Parallel and Distributed Processing, Changsha, China cwh2k@163.com Yue-Xin Chen National Laboratory for Parallel and Distributed Processing, Changsha, China  1 Sixth SIGHAN Workshop on Chinese Language Processing words.
77:211	The last three rules are called lexical rules.
78:211	is the probability of the rule.
79:211	p In this paper, we consider the phrase-based SMT, so the  and  represent phrases in both languages, which are consecutive words.
80:211	And a pair of   and  is called a phrase-pair, or a block.
81:211	i c j e i c j e During the process of decoding, each phrase in the source sentence is translated into a target phrase  through lexical rules, and then rules [] or <>  are used to merge two adjacent blocks into a larger block in straight or inverted orientation, until the whole source sentence is covered.
82:211	In this way, we will obtain a binary branching tree, which is different from the traditional syntactical tree, since each constituent in the branching tree is not a syntactical constituent.
83:211	i c j e Thus, the model achieves a great flexibility to interpret almost arbitrary reordering during the decoding, while keeping a weak but effective constraint.
84:211	Figure 1(a) gives an example to illustrate a derivation from the ITG model.
85:211	 1   2   3   4   5  6  where 1  s 2  the 3  nearest 4  cassino 5  ? 6  (b)  A word alignment (a)  An ITG tree  / the    / where s   / nearest  / cassino   / ?  Figure 1.
86:211	(a) An ITG tree derived from the ITG where the line between the branches means an inverted orientation, otherwise a straight one, (b) A word alignment corresponds to the ITG tree in (a).
87:211	Since we regard the process of the decoding as a sequence of applications of rules in (1), i.e., the output sentence pair (C,E) will be a derivation D of the ITG, where C represents the source sentence and E is the target sentence.
88:211	Following Och and Ney (2002), we define the probability for each rule as:  = i i i rulehrule  )()Pr( (2) Where the h i  represents the feature and  i  is the corresponding weight of the feature.
89:211	We will consider mainly the following features for rules: z Translation Models: , ,  and . The first two models consider the probability of phrase translation; and the latter two consider the lexical translation, i.e., the probability that the words in source (or target) phrase translate to the ones in the target (or source) phrase.
90:211	)|( ceP )|( ecP )|( ceP lex )|( ecP lex z Reordering model: , where o is the output orientation and b ),|( 21 bboP 1 , b 2  are the two blocks in the rule.
91:211	z Language model: )(Pr e lm  , which considers the increment of the language model for each rule.
92:211	And the probability for the derivation will be:  = Dr rD )Pr()Pr( (3) So the decoder searches the best E* derived from the best derivation D*, when given a source sentence C. )Pr(maxarg* )( DD CDc = =  (4) 2.1 Building the models In our SMT model, we use the translation models and reordering model.
93:211	They will be built from the training corpus, which is a word-aligned bilingual corpus satisfying the ITG constraint.
94:211	We define the word alignment A for the sentence pair (C,E) in the following ways: z A region : ),( tsji ji  represents a sequence of position index in sentence C, i.e. jii ,,1, +  and  represents a sequence of position index in sentence E, i.e. ts tss ,,1, + . We also call the  and ji ts  are regions in monolingual sentences.
95:211	The region corresponds to a phrase pair, which we called as a block.
96:211	The length of the block is |)1||,1max(| ++ stij . 2 Sixth SIGHAN Workshop on Chinese Language Processing z A link : And each link represents the alignment between the consecutive words in both of the sentences, which position indexes are in  and ),( tsjil = ji ts . If one of the and ji ts  is  , i.e. an empty region, we call the link a null-align.
97:211	z A word alignment A: a set of links . },,,{ 21 n lllA = We can merge two links  and  to form a larger link, if the two links are adjacent in both of the sentences, i.e.  is adjacent to  where ),( 11111 tsjil = ),( 22222 tsjil = 11  ji 22  ji 1 12 += ji  or , or  (or ) is  , so do the to . If the region can be formed by merging two adjacent links gradually, we call the region is independent, and the corresponding block is also independent.
98:211	1 21 += ji 11  ji 22  ji 11 ts 22 ts ),( tsji In our system, the word alignment must satisfy the ITG constraint, i.e. the word alignment is able to form a binary branching tree.
99:211	Figure 1(b) illustrates a word alignment example; the number below the word is the position index.
100:211	In the example, the region (13, 35) is independent, and the block (   the nearest cassino) is also independent.
101:211	In order to obtain the word alignment satisfying the ITG constraint, Wu(1997) propose a DP algorithm, and we (Chao and Li, 2007) have transferred the constraint to four simple position judgment procedures in an explicit way, so that we can incorporate the ITG constraint as a feature into a loglinear word alignment model (Moore, 2005).
102:211	After obtaining the word-aligned corpus, in which each word alignment satisfy the ITG constraint, we can extract the blocks in a straightforward way.
103:211	For the word alignment forms a hierarchical binary tree, we choose each constituent as a block.
104:211	Each block is formed by combining one or more links, and must be independent.
105:211	Considering the data sparseness, we limit the length of each block as N (here N=3~5).
106:211	We can also collect the reordering information between two blocks according to the orientation of the branches.
107:211	Thus, we will build the translation models , ,  and , using the frequencies of the blocks, and the re-ordering model , )|( ceP )|( ecP )|( ceP lex )|( ecP lex ),|( 21 bboP },{ invertstraighto  in the following way:  ),( of freq.
108:211	)),(( of freq.
109:211	),|( 21 21 21 bbcooccur obbO bbop = =  (5) Considering the data sparseness, we transfer the re-ordering model in the following way: )*,|(,*)|(),|( 2121 bopbopbbop =  (6) where * represents any block, represents the probability when , i.e., when  occurs, the orientation it merges with any other block is o . So we can estimate the merging orientation through the two blocks respectively.
110:211	,*)|( 1 bop obO =,*)( 1 1 b 2.2 A Baseline Decoder In order to evaluate the example-based decoder, we develop a CKY style decoder as a baseline (Chao et al. 2007), which will generate a derivation from the ITG in a DP way.
111:211	And it is similar with the topical phrase-based SMT system, while maintaining the ITG constraint.
112:211	3 The Example-based Decoder The SMT obtains the translation models during training, and does not need the training corpus when decoding; while the example-based machine translation system (EBMT) using the similar examples in the training corpus when decoding.
113:211	However, both of them use the same corpus; we can generate a hybrid MT, which is a SMT system while using an example-based decoder, to benefit from the advantages within the two systems.
114:211	Our example-based decoder consists of two components: retrieval of examples and decoding.
115:211	Figure 2 shows the structure of the decoder.
116:211	Training Corpus SMT Models Input sentence Decoding Merging Retrieval of examples Matching Output  Figure 2.
117:211	The structure of the example-based decoder.
118:211	3 Sixth SIGHAN Workshop on Chinese Language Processing 3.1 Retrieval of Examples Our training corpus is a sentence-aligned bilingual corpus.
119:211	For each sentence pair (C,E), we obtained the word alignment A, satisfying the ITG constaint through the methods described in section 2.
120:211	We call the triple (C,A,E) as an example.
121:211	So, the problem of retrieval of examples is: given the input source sentence C 0 and the training corpus, collecting a set of translation examples {( C 1 , A 1 , E 1 ) , ( C 2 , TA 2 , E 2 ),} from the corpus, where each translation example (Ci, Ai, Ei)  is similar to the input sentence C 0 . The quality of the retrieval of the similar examples is very import to the hybrid MT. For the translating may run in a large-scale corpus and in a realtime way, we divide the retrieval of similar examples into two phases: z Fast Retrieval Phase: retrieving the similar examples from the corpus quickly, and take them as candidates.
122:211	The complexity should not be too high.
123:211	z Refining Phase: refining the candidates to find the most similar examples.
124:211	3.1.1 The Similarity Metric for Fast Retrieval Given an input sentence  and an example (C, A, E), we calculate the number of the matched source words between the input sentence and the source sentence C  in the example firstly.
125:211	n wwwI  21 = ),,()( *2 ),( EACLenILen Match ExamISim w w + =  (7) where  is the number of the matched words and  is the number of words in w Match )(ILen I , and is the number of the words in the in C . ),,( EACLen Given an input sentence , we obtain the relative blocks in the translation model for each word . We use to represent the blocks, in which for each block , the source phrase c  use the word as the first word, and the length of  c   is , i.e. the . For each c , there may exists more than one blocks with c  as the source phrase, so we will sort them by the probability and keep the best N (here set N=5) blocks.
126:211	Now we represent the input sentence as: n wwwI  21 = },2,1{( niw i  i gramk B  ),( ec i w k )1( + = kii wc }1,1,|{)( nkniBbbI i gramk =   (8)  For example, in an input sentence    , )},(),,(),,(),,{( 1 1 MinemymeiB gram =   Note, some  may be empty, e.g. , since no blocks with    as the source phrase.
127:211	i gramk B  =  2 2 gram B In the same way, we represent the example  as:  ),,( EAC *},|{),,( AbBbbEAC i gramk =   (9) where *A  represents the blocks which are links in the alignment  or can be formed by merging adjacent links independently.
128:211	In order to accelerate the retrieval of similar examples, we generate the block set for the example during the training process and store them in the corpus.
129:211	A Now, we can use the number of the matched blocks to measure the similarity of the input and the example: Exam gram I gram b b BB Match ExamISim + = *2 ),(  (10) where  is the number of the matched blocks and  is the number of ( ) in b Match I gram B i gramk B    i gramk B )(I , and is the number of the blocks in Exam gram B ),,( EAC . Since each block is attached a probability, we can compute the similarity in the following way: Exam gram I gram Matchb p BB bob ExamISim b +  =  )(Pr*2 ),(  (11) So the final similarity metric for fast retrieval of the candidates is: pbwfast SimSimSimExamISim  ++=),(  (12) where 11,,0 =++  . Here we use mean values, i.e. 3/1===  . During the fast retrieval phase, we first filter out the examples using the , then calculate the  for each example left, and retrieve the best N examples.
130:211	w Sim fast Sim 4 Sixth SIGHAN Workshop on Chinese Language Processing 3.1.2 The Alignment Structure Metric After retrieving the candidate similar examples, we refine the candidates using the word alignment structure with the example, to find the best M similar examples (here set M=10).
131:211	The word alignment in the example satisfies the ITG constraint, which provides a weak structure constraint.
132:211	Given the input sentence I  and an example , we first search the matched blocks, at this moment the order of the source phrases in the blocks must correspond with the order of the words in the input.
133:211	),,( EAC As Figure 3 shows, the matching divides the input and the example respectively into several regions, where some regions are matched and some un-matched.
134:211	And we take each region as a whole and align them between the input and the example according to the order of the matched regions.
135:211	For example, the region (13,35) in  is unmatched, which aligns to the region (11) in ),,( EAC I . In this way, we can use a similar edit distance method to measure the similarity.
136:211	We count the number of the Deletion / Insertion / Substitution operations, which take the region as the object.
137:211	 1   2   3   4   5  6 where 1  s 2  the 3  nearest 4  cassino 5  ? 6 (a)  An example  1   2   3   4  (b)  An input  Figure 3.
138:211	An input and an example.
139:211	After matching, there are three regions in both sides, which are included in the line box, where the region (45,12) in the example matches the region (23) in the input, so do (66,66) to (44).
140:211	And the region (13,35) in the example should be substituted to (11) in the input.
141:211	We set the penalty for each deletion and insertion operation as 1, while considering the unmatched region in the example may be independent or not, we set the penalty for substitution as 0.5 if the region is independent, otherwise as 1.
142:211	E.g., the distance is 0.5 for substituting the region (13,35) to (11).
143:211	We get the metric for measuring the structure similarity of the I  and : ),,( EAC exmapleinput align RR SID ExamISim + ++ =1),( (13) where D, I, S are the deletion, insertion and substitution distances, respectively.
144:211	And the  and are the region numbers in the input and example.
145:211	input R exmaple R In the end, we obtain the similarity metric, which considers all of the above metrics: alignfastfinal SimSimExamISim ''),(  += (14) where  1''1','0 =+  . Here we also use mean values 2/1'' ==  . After the two phrases, we obtain the most similar examples with the input sentence.
146:211	3.2 Decoding After retrieving the translation examples, our goal is to use these examples to constrain the order of the output words.
147:211	During the decoding, we iterate the following two steps.
148:211	3.2.1 Matching For each translation example (C k , Ak, Ek) consists of the constituent structure tree, we can match the input sentence with the tree as in Section 3.1.2.
149:211	After matching, we obtain a translation of the input sentence, in which some input phrases are matched to blocks in the tree, i.e. they are translated, and some phrases are un-translated.
150:211	The order of the matched blocks must be the same as the input phrases.
151:211	We call the translation as a translation template for the input.
152:211	If we take each un-translated phrase as a nullaligned block, the translation template will be able to form a new constituent tree.
153:211	And the matched blocks in the template will restrict the translation structure.
154:211	Figure 4(a-c) illustrates the matching process, and Figure 4(c) is a translation template, in which "   " and "  " have been translated and "    " is not translated.
155:211	And the translation 5 Sixth SIGHAN Workshop on Chinese Language Processing template can be derived from the ITG as follows (here we remove the un-matched phrase):  couldA youA A AAA AAA / / /?
156:211	][ 4 3 2 431 21    > > > >>< >  (15) Since we have M (here M=10) similar examples, we will get more than one translation template for the input sentence.
157:211	So we define the evaluation function f for each translation template as : )(log)(log)( untranstrans CHDPtempf +=  (16) Where  is the probability for the new ITG tree without the un-translated phrases, which is a derivation from the ITG, so we can calculate it using the SMT model in Section 2 ( formula 3).
158:211	)( trans DP And the  is the estimated score for the un-translated phrases.
159:211	In order to obtain , we estimate the score for each un-translated phrase  in the following way: )( untrans CH )( untrans CH nm c  )}|*(),()(max{)(  *  maxmax nm e nkkm k nm cepcHcHcH = (17) That is, using the best translation to estimate the translation score.
160:211	Thus we can estimate the  as: )( untrans CH  = c nmuntrans cHCH )()(   (18) We call the un-translated phrases as child inputs, and try to translate them literately, i.e., decoding them using the examples.
161:211	If there are no untranslated phrases in the input, the decoding is completed, and the decoder returns the translation template with the best score as the result.
162:211	3.2.2 Merging If one child input is translated completely, i.e. no phrase is un-translated.
163:211	Then, it should be merged into the parent translation template to form a new template.
164:211	When merging, we must satisfy the ITG constraint, so we use the rules [] and <> to merge the child input with the adjacent blocks.
165:211	Figure 4(c-f) illustrates a merging process.
166:211	(b) Example A        could you spell it ?   / spell  / could / ? /   / it /you          (a) Input (c) Translation Tempate after match input with Example A        could you ?        / could / ?  /you  (d) Example B      please open your bag   / your / open  / .  /bag /please (e) Translation Tempate after match the child input with Example B  / your/ open  /bag     open your bag (f) Final translation after merged (c) and (e)    ?   could you    open your bag  / could / ?  /you   / your/ open  /bag  Figure 4.
167:211	An example to illustrate the examplebased decoding process, in which there are two translation examples.
168:211	When merging, it may modify some rules which are adjacent to the child inputs.
169:211	For example, when merging Figure 4(c) and (e), we may add a new rule: ]  [ 1 ' 1 child AAA > (19) A child  is the root non-terminal for the child input.
170:211	And we should modify the rule  as: ][ 21 AAA > ][ 2 ' 1 AAA >  (20) The merged template may vary due to the following situations: z The orientation may vary.
171:211	The orientation between the new block formed from the child 6 Sixth SIGHAN Workshop on Chinese Language Processing template and the preceding or posterior blocks may be straight or inverted.
172:211	z The position to merge may vary.
173:211	We may merge the new block with either the whole preceding or posterior blocks, or only the child blocks of them respectively, i.e. we may take the preceding or posterior blocks as the whole blocks or not.
174:211	Thus, we will obtain a collection of the merged translation templates, the decoder will evaluate them using the formualte (16).
175:211	If all the templates have no un-translated phrases, return the template with the best score.
176:211	3.2.3 Decoding Algorithm The decoding algorithm is showed in Figure 5.
177:211	In line 5~8, we match the input sentence with each similar example, and generate a collection of translation templates, using the formular (16) to evaluate the templates.
178:211	In line 9~11, we verify whether the set of the templates for the input is null: If it is null, decoding the input using the normal CKY decoder, and return the translations.
179:211	In lin 12~23, we decode the un-matched phrase in each template, and merge it with the parent template, until all of the template are translated completely.
180:211	In line 24, we return the best N translations.
181:211	4 Experiments We carried out experiments on an open ChineseEnglish translation task IWSLT2007, which consisting of sentence-aligned spoken language text for traveling.
182:211	There are five development set, and we take the third development set, i.e. the IWSLT07_devset3_*, to tune the feature weights.
183:211	Chinese English stemmed Sentences 39,963 Words 351,060 377,890 Train.
184:211	corpus Vocabulary 11,302 7,610 Sentences 506 Dev.
185:211	Set Words 3,826 Sentences 489 Test Set Words 3,189 Table 1.
186:211	The statistics of the corpus  1: Function Example_Decoder(I,examples) 2: Input: Input sentence I Similar Examples examples 3: Output: The best N tranlsations 4: Begin 5:   For each exampleA in examples Do 6:     templates = Match(exampleA,I); 7:     AddTemplate(templates,I); 8:  End {For} 9:  If templates is null then 10:    templates = CYK_Decoder(I); 11:    return templates; 12: For each templateA in templates Do 13:   If templateA is complete then 14:      AddTemplate_Complete(templateA,I); 15:   Else 16:      RemoveTemplate(templateA,I); 17:      For each untranslated phraseB in templateA do 18:        childTemplates = Example_Decoder(phraseB); 19:        For each childTemplateC in childTemplates Do 20:          templateD=MergeTemplate(templateA,childTemplateC); 21:    End{If} 22:    AddTemplate(templateD,I); 23:  End{For} 24:  return BEST_N(complete_templates); 28: End Figure 5.
187:211	The decoding algorithm.
188:211	Considering the size of the training corpus is relatively small, and the words in Chinese have no morphological changes, we stemmed the words in the English sentences.
189:211	Table 1 shows the statistics for the training corpus, development set and test set.
190:211	In order to compare with the other SMT systems, we choose the Moses 1 , which is an extension to the state-of-the-art SMT system Pharaoh (Koehn, 2004).
191:211	We use the default tool in the Moses to train the model and tune the weights, in which the word alignment tool is Giza++ (Och and Ney 2003) and the language model tool is SRILM(Stolcke, 2002).
192:211	The test results are showed in Table2.
193:211	The first column lists the different MT systems, and the second column lists the Bleu scores (Papineni et.
194:211	al, 2002) for the four decoders.
195:211	The first system is the Moses, and the second is our SMT system described in section 2, which using a CKY-style decoder.
196:211	We take them as baseline systems.
197:211	The third is the hybrid system but  1  http://www.statmt.org/moses/.
198:211	7 Sixth SIGHAN Workshop on Chinese Language Processing only using the fast retrieval module and the fourth is the hybrid system with refined retrieval module.
199:211	Considering the result from the Moses, we think that maybe the size of the training corpus is too small, so that the word alignment obtained by Giza++ is poor.
200:211	The results show that the example-based decoder achieves an improvement over the baseline decoders.
201:211	Decoder Bleu Moses 22.61 SMT-CKY 28.33 Hybrid MT with fast retrieval 30.03 Hybrid MT with refined retrieval 33.05 Table 2.
202:211	Test results for several systems.
203:211	5 Related works There is some works about the hybrid machine translation.
204:211	One way is to merge EBMT and SMT resources, such as Groves and Way (2005).
205:211	Another way is to implement an exmaple-based decoder, Watanabe and Sumita (2003) presents an example-based decoder, which using a information retrieval framework to retrieve the examples; and when decoding, which runs a hill-climbing algorithm to modify the translation example ( C k , E k , A k ) to obtain an alignment ( C 0 , E' k , A' k ).
206:211	6 Conclusions In this paper, we proposed a SMT system with an example-based decoder for the spoken language machine translation.
207:211	This approach will take advantage of the constituent tree within the translation examples to constrain the flexible word reordering in the spoken language, and it will also make the omitted words have the chance to be translated.
208:211	Combining with the re-ordering model and the translation models in the SMT, the example-based decoder obtains an improvement over the baseline phrase-based SMT system.
209:211	In the future, we will test our method in the written text corpus.
210:211	In addition, we will improve the methods to handle the morphological changes from the stemmed English words.
211:211	Acknowledgements This work is supported by the National Science Foundation of China under Grants No. 60573057, 60473057 and 90604007.

