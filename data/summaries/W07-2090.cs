SUPERSENSELEARNER brings together under one system the features previously used in the SENSELEARNER (Mihalcea and Csomai, 2005) and the SUPERSENSE (Ciaramita and Altun, 2006) all-words word sense disambiguation systems.
P05-3014 W06-1670
Although more general than models that are built individually for each word in a test corpus (Decadt et al., 2004), the applicability of the semantic models built as part of SENSELEARNER is still limited to those words previously seen in the training corpus, and therefore their overall coverage is not 100%.
W04-0827
A detailed description of the features used and the tagger can be found in (Ciaramita and Altun, 2006).
W06-1670
The tagger is a Hidden Markov Model trained with the perceptron algorithm introduced in (Collins, 2002), which applies Viterbi decoding and is regularized using averaging.
W02-1001
We base our experiments on SemCor (Miller et al., 1993), a balanced, semantically annotated dataset, with all content words manually tagged by trained lexicographers.
H93-1061
The first is the set of WordNet supersenses (Ciaramita and Altun, 2006): a mapping of WordNetâ€™s synsets to 45 broad lexicographers categories, 26 for nouns, 15 for verbs, 3 for adjectives and 1 for adverbs.
W06-1670
mans et al., 2001), which was previously found useful for the task of word sense disambiguation (Hoste et al., 2002; Mihalcea, 2002).
C02-1039 W02-0814
