with forest-based decoding. Chiang (2010) also ob-
P10-1146
Zhongqiang Huang and Mary Harper. 2009. Self-
D09-1087 N09-2054
Deyi Xiong, Min Zhang, and Haizhou Li. 2010. Learn-
N10-1016
Liang Huang, Kevin Knight, and Aravind Joshi. 2006.
W06-3601
Franz Josef Och and Hermann Ney. 2000. Improved
P00-1056
Liang Huang and David Chiang. 2005. Better k-best
W05-1506
ley et al., 2004; Liu et al., 2006)) utilize structures
P06-1077
either forest-based decoding (Mi et al., 2008) or
D08-1022 P08-1023
Hao Zhang, Daniel Gildea, and David Chiang. 2008. Ex-
C08-1136
els (Chiang, 2007; Galley et al., 2004; Liu et
J07-2003
1993; Och and Ney, 2000). An aligned sentence pair
P00-1056
tated corpus (Chiang, 2007). Linguistically syntax-
J07-2003
representation (Huang and Chiang, 2005), the hy-
W05-1506
Haitao Mi, Liang Huang, and Qun Liu. 2008. Forest-
D08-1022 P08-1023
error-rate training (Och, 2003) to optimize feature
P03-1021
Deyi Xiong, Min Zhang, Aiti Aw, and Haizhou Li. 2009.
P09-1036
parser (Huang and Harper, 2009) trained on the
D09-1087 N09-2054
lated research, Matsuzaki et al. (2005) and Petrov et
P05-1010
hierarchical phrase-based model of Chiang (2007),
J07-2003
used phrase-based models (Och and Ney, 2004) to
J04-4002
Andreas Zollmann and Ashish Venugopal. 2006. Syntax
W06-3119
Franz Josef Och. 2003. Minimum error rate training in
P03-1021
Yang Liu, Qun Liu, and Shouxun Lin. 2006. Tree-to-
P06-1077
pairs (Zhang et al., 2008). A tight phrase pair is the
C08-1136
Zhongqiang Huang, Mary Harper, and Slav Petrov. 2010.
D10-1002
et al., 2006; Huang et al., 2006), even when at-
W06-3601
Kenji Yamada and Kevin Knight. 2001. A syntax-based
P01-1067
based models (e.g., (Yamada and Knight, 2001; Gal-
P01-1067
forest-based rule extraction (Mi and Huang, 2008).
D08-1022 P08-1023
els of Mi and Huang (2008) can actually signif-
D08-1022 P08-1023
Franz Josef Och and Hermann Ney. 2004. The align-
J04-4002
Xiong et al., 2010). These approaches are all or-
N10-1016
model (Chiang, 2007) studied in this paper explores
J07-2003
rithm of Chiang (2007) is based on the property that
J07-2003
Yuval Marton and Philip Resnik. 2008. Soft syntactic
P08-1114
Dekai Wu. 1997. Stochastic inversion transduction
J97-3002
cal phrase-based models of Chiang (2007), which
J07-2003
David Chiang. 2010. Learning to translate with source
P10-1146
Zollmann and Venugopal (2006) attempted to ad-
W06-3119
ing, and Huang et al. (2009) used a similar approach
D09-1087 N09-2054
(Marton and Resnik, 2008; Xiong et al., 2009;
P08-1114 P09-1036
David Chiang. 2007. Hierarchical phrase-based transla-
J07-2003
els (e.g., (Wu, 1997; Chiang, 2007)) extract syn-
J07-2003 J97-3002
nonterminals. Chiang (2007) also introduced several
J07-2003
Venugopal et al. (2009) addressed this problem by
N09-1027
in phrase-based models (Och and Ney, 2004), a pair
J04-4002
model of Zhou et al. (2008) or by imposing con-
W08-0403
parse forests as in (Mi and Huang, 2008). Third,
D08-1022 P08-1023
Zhang et al. (2008) exploited this property to con-
C08-1136
preference vectors. Chiang (2010) also avoided hard
P10-1146
Haitao Mi and Liang Huang. 2008. Forest-based transla-
D08-1022 P08-1023
