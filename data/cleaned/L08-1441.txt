<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>CKIP</author>
</authors>
<title>Knowledge Information Processing Group) (1995/1998). The Content and Illustration of Academica Sinica Corpus. (Technical Report no 95-02/98-04). Taipei: Academia Sinica Kilgarriff</title>
<date>2003</date>
<journal>Computational Linguistics</journal>
<volume>29</volume>
<pages>333--347</pages>
<marker>CKIP, 2003</marker>
<rawString>CKIP (Chinese Knowledge Information Processing Group) (1995/1998). The Content and Illustration of Academica Sinica Corpus. (Technical Report no 95-02/98-04). Taipei: Academia Sinica Kilgarriff, A. and  Grefenstette, G. (2003). Introduction to the Special Issue on the Web as Corpus. Computational Linguistics, 29 (3), pp. 333-347.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W-Y Ma</author>
<author>K-J Chen</author>
</authors>
<date>2005</date>
<booktitle>Design of CKIP Chinese Word Segmentation System. Chinese and Oriental Languages Information Processing Society</booktitle>
<volume>14</volume>
<pages>235--249</pages>
<contexts>
<context> Tagged with two Different Tagsets 3.1 Academia Sinica’s CKIP Annotator There are two major missions of CKIP automatic annotator: word segmentation and POS tagging. We enhanced Sinica Word Segmenter (Ma &amp; Chen, 2005) to segment the corpus into the words. And we utilized HMM method for POS tagging and morpheme-analysis-based method (Tseng &amp; Chen, 2002) to predict POSs for new words. All the annotated text is trad</context>
</contexts>
<marker>Ma, Chen, 2005</marker>
<rawString>Ma, W.-Y. and Chen, K.-J. (2005). Design of CKIP Chinese Word Segmentation System. Chinese and Oriental Languages Information Processing Society, 14(3), pp. 235-249.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W-Y Ma</author>
<author>C-R Huang</author>
</authors>
<title>Uniform and Effective Tagging of a Heterogeneous Giga-word Corpus</title>
<date>2006</date>
<booktitle>Proceedings of the 5 th International Conference on Language Resources and Evaluation (LREC-5</booktitle>
<contexts>
<context> Chinese Gigaword Corpus currently has a segmented and tagged version available. This version adopts the CKIP tagset and was performed automatically with automatic and partially manual post-checking (Ma &amp; Huang, 2006). The precision accuracy is estimated to be over 95% for Central New Agency part of data from Taiwan. However, for the Xinhua New Agency data from PRC, they were not able to independently verify thei</context>
</contexts>
<marker>Ma, Huang, 2006</marker>
<rawString>Ma, W.-Y. and Huang, C.-R. (2006). Uniform and Effective Tagging of a Heterogeneous Giga-word Corpus. Proceedings of the 5 th International Conference on Language Resources and Evaluation (LREC-5).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H H Tseng</author>
<author>K J Chen</author>
</authors>
<title>Design of Chinese Morphological Analyzer</title>
<date>2002</date>
<booktitle>Proceedings of 1 st SIGHAN Workshop on Chinese Language Processing</booktitle>
<contexts>
<context> segmentation and POS tagging. We enhanced Sinica Word Segmenter (Ma &amp; Chen, 2005) to segment the corpus into the words. And we utilized HMM method for POS tagging and morpheme-analysis-based method (Tseng &amp; Chen, 2002) to predict POSs for new words. All the annotated text is traditional characters in Big5 encoding. And the full numbers are adopted. Fig. 2 shows an example with CKIP-POS tags. The annotator generate</context>
</contexts>
<marker>Tseng, Chen, 2002</marker>
<rawString>Tseng, H. H. and Chen, K. J. (2002). Design of Chinese Morphological Analyzer.  Proceedings of 1 st SIGHAN Workshop on Chinese Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Xia</author>
<author>M Palmer</author>
<author>N Xue</author>
<author>M E Okurowski</author>
<author>J Kovarik</author>
<author>F-D Chiou</author>
<author>S Huang</author>
<author>T Kroch</author>
<author>M Marcus</author>
</authors>
<title>Developing Guidelines and Ensuring Consistency for Chinese Text Annotation</title>
<date>2000</date>
<booktitle>Proceedings of the 2 nd International Conference on Language Resources and Evaluation (LREC-2</booktitle>
<marker>Xia, Palmer, Xue, Okurowski, Kovarik, Chiou, Huang, Kroch, Marcus, 2000</marker>
<rawString>Xia, F., Palmer, M., Xue, N., Okurowski, M. E., Kovarik, J., Chiou, F.-D., Huang, S., Kroch, T. and Marcus, M. (2000). Developing Guidelines and Ensuring Consistency for Chinese Text Annotation. Proceedings of the 2 nd International Conference on Language Resources and Evaluation (LREC-2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Yu</author>
<author>H Duan</author>
<author>X Zhu</author>
<author>B Sun</author>
</authors>
<title>The Basic Processing of Contemporary Chinese Corpus at Peking UniversitySpecification</title>
<date>2002</date>
<journal>Journal of Chinese Information Processing</journal>
<volume>16</volume>
<pages>49--64</pages>
<contexts>
<context>et &lt;HEADLINE&gt; The institute of Computational Linguistics, Peking University made a specification (as known as Specification 2001) for the word segmentation and POS tagging of its People Daily corpus (Yu et al, 2002). The size of this corpus is over 26 million Chinese characters. In order to build the phonetically annotated corpus (1 million Chinese characters), the added Phonetic Notation was made in Specificat</context>
</contexts>
<marker>Yu, Duan, Zhu, Sun, 2002</marker>
<rawString>Yu, S., Duan, H., Zhu, X. and Sun, B. (2002). The Basic Processing of Contemporary Chinese Corpus at Peking UniversitySpecification. Journal of Chinese Information Processing, 16(5&amp;6), pp. 49-64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Yu</author>
<author>H Duan</author>
<author>X Zhu</author>
<author>B Swen</author>
<author>B Chang</author>
</authors>
<title>Specification for Corpus Processing at Peking University: Word Segmentation, POS Tagging and Phonetic Notation</title>
<date>2003</date>
<journal>Journal of Chinese Language and Computing</journal>
<volume>13</volume>
<pages>121--158</pages>
<contexts>
<context>e of this corpus is over 26 million Chinese characters. In order to build the phonetically annotated corpus (1 million Chinese characters), the added Phonetic Notation was made in Specification 2003 (Yu et al., 2003). 印度平静迎接新千年 &lt;/HEADLINE&gt; &lt;DATELINE&gt; 新华社新德里 1 月 1 日电 &lt;/DATELINE&gt; &lt;TEXT&gt; &lt;P&gt; (记者熊昌义)10 亿印度人以平静的心情迎来了新千年。虽然 官方 1 日没有计划举行迎接新千年的活动, 但印度首都新德 里一些著名的五星饭店、购物中心, 商业街和集贸市场, 到处 张灯结彩, 火树银花, 充满了节日气氛。 A team from PR</context>
</contexts>
<marker>Yu, Duan, Zhu, Swen, Chang, 2003</marker>
<rawString>Yu, S., Duan, H., Zhu, X., Swen, B. and Chang, B. (2003). Specification for Corpus Processing at Peking University: Word Segmentation, POS Tagging and Phonetic Notation. Journal of Chinese Language and Computing, 13(2), pp.121-158.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H-P Zhang</author>
<author>Q Liu</author>
<author>X-Q Cheng</author>
<author>Hao Zhang</author>
<author>H-K Yu</author>
</authors>
<title>Chinese Lexical Analysis Using Hierarchical Hidden Markov Model</title>
<date>2003</date>
<booktitle>Proceedings of the 2 nd SIGHAN Workshop on Chinese Language Processing</booktitle>
<contexts>
<context>te of Computing Technology, Chinese Lexical Analysis System) aiming to incorporate Chinese word segmentation, POS tagging, disambiguation and unknown words recognition into a whole theoretical frame (Zhang et al., 2003a, b). &lt;/P&gt; &lt;P&gt; 1 日凌晨, 新德里虽下起了小雨, 但马路上仍然有不少车辆在 行驶, 街头可以看到一群群青年人伴随着欢乐的乐曲翩翩起 舞。偶而还能看到人们施放的礼花, 听到一些鞭炮声。 &lt;/P&gt; The result of tagging Xinhua data was completed without human intervention. All the tagged tex</context>
</contexts>
<marker>Zhang, Liu, Cheng, Zhang, Yu, 2003</marker>
<rawString>Zhang, H.-P., Liu, Q., Cheng, X.-Q., Zhang, Hao and Yu, H.-K. (2003a). Chinese Lexical Analysis Using Hierarchical Hidden Markov Model. Proceedings of the 2 nd SIGHAN Workshop on Chinese Language Processing.</rawString>
</citation>
</citationList>
</algorithm>

