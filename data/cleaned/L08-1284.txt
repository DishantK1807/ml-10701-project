<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>Steven Abney</author>
</authors>
<title>Stochastic attribute-value grammars</title>
<date>1997</date>
<journal>Computational Linguistics</journal>
<pages>23--597</pages>
<marker>Abney, 1997</marker>
<rawString>Steven Abney. 1997. Stochastic attribute-value grammars. Computational Linguistics, 23:597–618.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Emily M Bender</author>
<author>Dan Flickinger</author>
<author>Ara Kim</author>
<author>Stephan Oepen</author>
</authors>
<title>Road-testing the English Resource Grammar over the British National Corpus</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC 2004</booktitle>
<location>Lisbon, Portugal</location>
<marker>Baldwin, Bender, Flickinger, Kim, Oepen, 2004</marker>
<rawString>Timothy Baldwin, Emily M. Bender, Dan Flickinger, Ara Kim, and Stephan Oepen. 2004. Road-testing the English Resource Grammar over the British National Corpus. In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC 2004), Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
</authors>
<title>Bootstrapping deep lexical resources: Resources for courses</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL-SIGLEX Workshop on Deep Lexical Acquisition</booktitle>
<pages>67--76</pages>
<location>Michigan , USA</location>
<marker>Baldwin, 2005</marker>
<rawString>Timothy Baldwin. 2005. Bootstrapping deep lexical resources: Resources for courses. In Proceedings of the ACL-SIGLEX Workshop on Deep Lexical Acquisition, pages 67–76, Michigan , USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francis Bond</author>
</authors>
<title>Sanae Fujita, Chikara Hashimoto, Kaname Kasahara, Shigeko Nariyama, Eric Nichols, Akira Ohtani, Takaaki Tanaka, and Shigeaki Amano</title>
<date>2004</date>
<marker>Bond, 2004</marker>
<rawString>Francis Bond, Sanae Fujita, Chikara Hashimoto, Kaname Kasahara, Shigeko Nariyama, Eric Nichols, Akira Ohtani, Takaaki Tanaka, and Shigeaki Amano. 2004. The Hinoki Treebank: a treebank for text understanding.</rawString>
</citation>
<citation valid="false">
<booktitle>In Proceedings of the 1st International Joint Conference on Natural Language Processing (IJCNLP 2004</booktitle>
<pages>554--562</pages>
<location>Hainan Island, China</location>
<marker></marker>
<rawString>In Proceedings of the 1st International Joint Conference on Natural Language Processing (IJCNLP 2004), pages 554–562, Hainan Island, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
<author>Rebecca Watson</author>
</authors>
<date>2006</date>
<contexts>
<context>practical estimation of RMRS similarities described by Dridan and Bond (2006). The semantic outputs of different partial parse selection models were compared to the RMRS outputs from the RASP system (Briscoe et al., 2006). If taken comparatively, all the results suggested that the model in (2.) performed much better than the baseline. But they failed to tell a clear story about the quality of the partial parse select</context>
</contexts>
<marker>Briscoe, Carroll, Watson, 2006</marker>
<rawString>Ted Briscoe, John Carroll, and Rebecca Watson. 2006.</rawString>
</citation>
<citation valid="true">
<title>The second release of the RASP system</title>
<booktitle>In Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions</booktitle>
<pages>77--80</pages>
<location>Sydney, Australia</location>
<marker></marker>
<rawString>The second release of the RASP system. In Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions, pages 77–80, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrich Callmeier</author>
<author>Andreas Eisele</author>
<author>Ulrich Sch¨afer</author>
<author>Melanie Siegel</author>
</authors>
<title>The DeepThought core architecture framework</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC 2004</booktitle>
<location>Lisbon, Portugal</location>
<marker>Callmeier, Eisele, Sch¨afer, Siegel, 2004</marker>
<rawString>Ulrich Callmeier, Andreas Eisele, Ulrich Sch¨afer, and Melanie Siegel. 2004. The DeepThought core architecture framework. In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC 2004), Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrich Callmeier</author>
</authors>
<title>Efficient parsing with large-scale unification grammars</title>
<date>2001</date>
<booktitle>Master’s thesis, Universit¨at des Saarlandes</booktitle>
<location>Saarbr¨ucken, Germany</location>
<contexts>
<context>g from a grammar engineering platform, theLKBsystem (cf., Copestake (2002)), to performance profiling and teebanking systems, the [incr tsdb()] platform (cf., Oepen (2001)), an efficient parser, PET (Callmeier, 2001), and a hybrid processing middle-ware, the HoG architecture (Callmeier et al., 2004), linguists and computer scientists are able to work together to develop language resources and applications with p</context>
<context>the input. Given large-scale grammars like the ERG, it is crucial to have an efficient parser that can discover analyses licensed by the grammar. With continuous development in recent years, the PET (Callmeier, 2001) parser has grown to be one of the central components in the DELPH-IN software tool-chain. PET is based on a bottom-up chart-based algorithm, equipped with various efficient processing techniques, in</context>
</contexts>
<marker>Callmeier, 2001</marker>
<rawString>Ulrich Callmeier. 2001. Efficient parsing with large-scale unification grammars. Master’s thesis, Universit¨at des Saarlandes, Saarbr¨ucken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Carpenter</author>
</authors>
<title>The Logic of Typed Feature Structures</title>
<date>1992</date>
<publisher>Cambridge University Press</publisher>
<location>Cambridge, UK</location>
<marker>Carpenter, 1992</marker>
<rawString>Bob Carpenter. 1992. The Logic of Typed Feature Structures. Cambridge University Press, Cambridge, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>Stephan Oepen</author>
</authors>
<title>High efficiency realization for a wide-coverage unification grammar</title>
<date>2005</date>
<booktitle>In Proceedings of the 2nd International Joint Conference on Natural Language Processing (IJCNLP</booktitle>
<pages>165--176</pages>
<location>Jeju Island, Korea</location>
<marker>Carroll, Oepen, 2005</marker>
<rawString>John Carroll and Stephan Oepen. 2005. High efficiency realization for a wide-coverage unification grammar. In Proceedings of the 2nd International Joint Conference on Natural Language Processing (IJCNLP 2005), pages 165–176, Jeju Island, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
<author>Carl J Pollard</author>
<author>Ivan A Sag</author>
</authors>
<title>Minimal recursion semantics: an introduction</title>
<date>2005</date>
<journal>Research on Language and Computation</journal>
<volume>3</volume>
<marker>Copestake, Flickinger, Pollard, Sag, 2005</marker>
<rawString>Ann Copestake, Dan Flickinger, Carl J. Pollard, and Ivan A. Sag. 2005. Minimal recursion semantics: an introduction. Research on Language and Computation, 3(4):281–332.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
</authors>
<title>Implementing Typed Feature Structure Grammars</title>
<date>2002</date>
<publisher>Thomas</publisher>
<location>CSLI, Stanford, USA</location>
<marker>Copestake, 2002</marker>
<rawString>Ann Copestake. 2002. Implementing Typed Feature Structure Grammars. CSLI, Stanford, USA. Thomas H. Cormen, Charles E. Leiserson, and Ronald L.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rivest</author>
</authors>
<title>Introduction to Algorithms</title>
<date>1990</date>
<publisher>MIT Press</publisher>
<marker>Rivest, 1990</marker>
<rawString>Rivest. 1990. Introduction to Algorithms. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Dridan</author>
<author>Francis Bond</author>
</authors>
<title>Sentence comparison using Robust Minimal Recursion Semantics and an ontology</title>
<date>2006</date>
<booktitle>In Proceedings of the ACL Workshop on Linguistic Distances</booktitle>
<pages>35--42</pages>
<location>Sydney, Australia</location>
<marker>Dridan, Bond, 2006</marker>
<rawString>Rebecca Dridan and Francis Bond. 2006. Sentence comparison using Robust Minimal Recursion Semantics and an ontology. In Proceedings of the ACL Workshop on Linguistic Distances, pages 35–42, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Flickinger</author>
</authors>
<title>On building a more efficient grammar by exploiting types</title>
<date>2002</date>
<booktitle>Collaborative Language Engineering</booktitle>
<pages>1--17</pages>
<editor>In Stephan Oepen, Dan Flickinger, Jun’ichi Tsujii, and Hans Uszkoreit, editors</editor>
<publisher>CSLI Publications</publisher>
<marker>Flickinger, 2002</marker>
<rawString>Dan Flickinger. 2002. On building a more efficient grammar by exploiting types. In Stephan Oepen, Dan Flickinger, Jun’ichi Tsujii, and Hans Uszkoreit, editors, Collaborative Language Engineering, pages 1–17. CSLI Publications.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Walter Kasper</author>
<author>Bernd Kiefer</author>
</authors>
<location>Hans-Ulrich Krieger, C.J</location>
<marker>Kasper, Kiefer, </marker>
<rawString>Walter Kasper, Bernd Kiefer, Hans-Ulrich Krieger, C.J.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rupp</author>
<author>Karsten Worm</author>
</authors>
<title>Charting the depths of robust speech processing</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics (ACL</booktitle>
<pages>405--412</pages>
<location>Maryland, USA</location>
<marker>Rupp, Worm, 1999</marker>
<rawString>Rupp, and Karsten Worm. 1999. Charting the depths of robust speech processing. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics (ACL 1999), pages 405–412, Maryland, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tracy H King</author>
<author>Richard Crouch</author>
<author>Stefan Riezler</author>
<author>Mary Dalrymple</author>
<author>Ronald M Kaplan</author>
</authors>
<title>The PARC 700 Dependency Bank</title>
<date>2003</date>
<booktitle>In Proceedings of the 4th International Workshop on Linguistically Interpreted Corpora, held at the 10th Conference of the European Chapter of the Association for Computational Linguistics (EACL’03</booktitle>
<location>Budapest, Hungary</location>
<contexts>
<context>easons, a manual evaluation has been carried out for the new proposed partial parsing model in this paper. For the experiment, we selected a subset of 267 sentences from the PARC 700 Dependency Bank (King et al., 2003), which have full lexical span licensed by the ERG. Among these sentences, 213 are parsed out of the box. For the remaining 54 sentences, the two-stage partial parsing model built pseudo-derivation t</context>
</contexts>
<marker>King, Crouch, Riezler, Dalrymple, Kaplan, 2003</marker>
<rawString>Tracy H. King, Richard Crouch, Stefan Riezler, Mary Dalrymple, and Ronald M. Kaplan. 2003. The PARC 700 Dependency Bank. In Proceedings of the 4th International Workshop on Linguistically Interpreted Corpora, held at the 10th Conference of the European Chapter of the Association for Computational Linguistics (EACL’03), Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Oepen</author>
<author>Kristina Toutanova</author>
<author>Stuart Shieber</author>
<author>Christopher Manning</author>
<author>Dan Flickinger</author>
<author>Thorsten Brants</author>
</authors>
<title>The LinGO Redwoods treebank: motivation and preliminary applications</title>
<date>2002</date>
<booktitle>In Proceedings of COLING 2002: The 17th International Conference on Computational Linguistics: Project Notes</booktitle>
<location>Taipei, Taiwan</location>
<contexts>
<context>erived. By applying grammar rules on the lexical entries in the way indicated by a derivation tree, one can easily recreate the whole typed feature structure. For this reason, the DELPH-IN treebanks (Oepen et al., 2002; Bond et al., 2004) only record derivation trees. Theoretically, the computational complexity in unificationbased parsing is exponential to the length of the input. Given large-scale grammars like th</context>
</contexts>
<marker>Oepen, Toutanova, Shieber, Manning, Flickinger, Brants, 2002</marker>
<rawString>Stephan Oepen, Kristina Toutanova, Stuart Shieber, Christopher Manning, Dan Flickinger, and Thorsten Brants. 2002. The LinGO Redwoods treebank: motivation and preliminary applications. In Proceedings of COLING 2002: The 17th International Conference on Computational Linguistics: Project Notes, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Oepen</author>
<author>Helge Dyvik</author>
<author>Jan Tore Lønning</author>
<author>Erik Velldal</author>
<author>Dorothee Beermann</author>
<author>John Carroll</author>
<author>Dan Flickinger</author>
<author>Lars Hellan</author>
<author>Janne Bondi Johannessen</author>
<author>Paul Meurer</author>
<author>Torbjørn Nordg˚ard</author>
<author>Victoria Ros´en</author>
</authors>
<title>Som ˚a kapp-ete med trollet? Towards MRS-Based Norwegian– English Machine Translation</title>
<date>2004</date>
<booktitle>In Proceedings of the 10th International Conference on Theoretical and Methodological Issues in Machine Translation</booktitle>
<location>Baltimore, USA</location>
<marker>Oepen, Dyvik, Lønning, Velldal, Beermann, Carroll, Flickinger, Hellan, Johannessen, Meurer, Nordg˚ard, Ros´en, 2004</marker>
<rawString>Stephan Oepen, Helge Dyvik, Jan Tore Lønning, Erik Velldal, Dorothee Beermann, John Carroll, Dan Flickinger, Lars Hellan, Janne Bondi Johannessen, Paul Meurer, Torbjørn Nordg˚ard, and Victoria Ros´en. 2004. Som ˚a kapp-ete med trollet? Towards MRS-Based Norwegian– English Machine Translation. In Proceedings of the 10th International Conference on Theoretical and Methodological Issues in Machine Translation, Baltimore, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Oepen</author>
</authors>
<title>incr tsdb()] — competence and performance laboratory. User manual</title>
<date>2001</date>
<tech>Technical report</tech>
<institution>Computational Linguistics, Saarland University</institution>
<location>Saarbr¨ucken, Germany</location>
<marker>Oepen, 2001</marker>
<rawString>Stephan Oepen. 2001. [incr tsdb()] — competence and performance laboratory. User manual. Technical report, Computational Linguistics, Saarland University, Saarbr¨ucken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl J Pollard</author>
<author>Ivan A Sag</author>
</authors>
<title>Head-Driven Phrase Structure Grammar</title>
<date>1994</date>
<publisher>University of Chicago Press</publisher>
<location>Chicago, USA</location>
<marker>Pollard, Sag, 1994</marker>
<rawString>Carl J. Pollard and Ivan A. Sag. 1994. Head-Driven Phrase Structure Grammar. University of Chicago Press, Chicago, USA. Kristina Toutanova, Christoper D. Manning, Stuart M.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Flickinger Shieber</author>
<author>Stephan Oepen</author>
</authors>
<date>2002</date>
<marker>Shieber, Oepen, 2002</marker>
<rawString>Shieber, Dan Flickinger, and Stephan Oepen. 2002.</rawString>
</citation>
<citation valid="true">
<title>Parse ranking for a rich HPSG grammar</title>
<date>2002</date>
<booktitle>In Proceedings of the 1st Workshop on Treebanks and Linguistic Theories (TLT</booktitle>
<pages>253--263</pages>
<location>Sozopol, Bulgaria</location>
<contexts>
<context>urces, precision grammars have been very much underusedinrealworldapplicationsinthepastdecades. Baldwin et al. (2004) reported that the jun-04 version of the English Resource Grammar (ERG; Flickinger (2002)) achieves full lexical span1 over a mere 32% of a random sample of 20K BNC strings. Among these inputs, 57% receive at least one analysis. Through a series of parsing coverage tests, Zhang and Kordon</context>
<context>elivered the most promising multilingual parallel grammar development with HPSG to date. With a complete software tool-chain, ranging from a grammar engineering platform, theLKBsystem (cf., Copestake (2002)), to performance profiling and teebanking systems, the [incr tsdb()] platform (cf., Oepen (2001)), an efficient parser, PET (Callmeier, 2001), and a hybrid processing middle-ware, the HoG architectur</context>
<context>ions with profound linguistic knowledge. One of the most well-developed grammars in DELPH-IN (also among hand-crafted grammars in any other framework) is the English Resource Grammar (ERG, Flickinger (2002)). The grammar achieves broad coverage on variouslinguisticphenomena, butstillremainsratherrestricted. Therefore, it is not only used for parsing, but also for text generation tasks. On the semantic l</context>
<context> full analyses, but it also helps simplify the partial parse disambiguation process. In recent years, the log-linear model shown in (3.) has been widely used in many parsing systems. Toutanova et al. (2002) proposed an inventory of features that perform well in HPSG parse selection. P(t|w) = exp summationtextn j=1 λjfj(t,w)summationtext tprime∈T exp summationtextn j=1 λjfj(tprime,w) (2) FortheDELPH-INgr</context>
</contexts>
<marker>2002</marker>
<rawString>Parse ranking for a rich HPSG grammar. In Proceedings of the 1st Workshop on Treebanks and Linguistic Theories (TLT 2002), pages 253–263, Sozopol, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi Zhang</author>
<author>Valia Kordoni</author>
</authors>
<title>Automated deep lexical acquisition for robust open texts processing</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>275--280</pages>
<location>Genoa, Italy</location>
<marker>Zhang, Kordoni, 2006</marker>
<rawString>Yi Zhang and Valia Kordoni. 2006. Automated deep lexical acquisition for robust open texts processing. In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC 2006), pages 275–280, Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi Zhang</author>
<author>Valia Kordoni</author>
<author>Erin Fitzgerald</author>
</authors>
<title>Partial parse selection for robust deep processing</title>
<date>2007</date>
<booktitle>In Proceedings of ACL 2007 Workshop on Deep Linguistic Processing</booktitle>
<pages>128--135</pages>
<location>Prague, Czech</location>
<contexts>
<context>seen data without extra robust processing techniques. Also, the cost of manually extending the grammar would be too high to be easily acceptable for other precision grammar-based parsing systems. In (Zhang et al., 2007a), we have pointed out that most applications are only interested in certain aspects of parsing results. Full analyses are preferable, but not always necessary. In fact, most of the contemporary deep</context>
<context>ecursion Semantics (MRS, Copestake et al. (2005)) is used as the semantic representation in these grammars. For recording syntactic structures, derivation trees are usually used. Based on this fact, (Zhang et al., 2007a) have proposed to use partial parsing models to recover the most useful fragment analyses from the intermediate parsing results in cases of unsuccessful parses. To this effect, two statistical parti</context>
<context>ally, a uniform disambiguation model should be used in both cases. 3. A Two-stage Robust Parsing Model One common shortcoming of the partial parsing models proposed in both (Kasper et al., 1999) and (Zhang et al., 2007a) is that the results of partial parsing are sets of disjoint sub-analyses, either in the form of derivation subtrees, or in the form of MRS fragments. It is not informativeenoughtoshowtheinterconnec</context>
</contexts>
<marker>Zhang, Kordoni, Fitzgerald, 2007</marker>
<rawString>Yi Zhang, Valia Kordoni, and Erin Fitzgerald. 2007a. Partial parse selection for robust deep processing. In Proceedings of ACL 2007 Workshop on Deep Linguistic Processing, pages 128–135, Prague, Czech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi Zhang</author>
<author>Stephan Oepen</author>
<author>John Carroll</author>
</authors>
<title>Efficiency in unification-based N-best parsing</title>
<date>2007</date>
<booktitle>In Proceedings of the 10th International Conference on Parsing Technologies (IWPT</booktitle>
<pages>48--59</pages>
<location>Prague, Czech</location>
<contexts>
<context>seen data without extra robust processing techniques. Also, the cost of manually extending the grammar would be too high to be easily acceptable for other precision grammar-based parsing systems. In (Zhang et al., 2007a), we have pointed out that most applications are only interested in certain aspects of parsing results. Full analyses are preferable, but not always necessary. In fact, most of the contemporary deep</context>
<context>ecursion Semantics (MRS, Copestake et al. (2005)) is used as the semantic representation in these grammars. For recording syntactic structures, derivation trees are usually used. Based on this fact, (Zhang et al., 2007a) have proposed to use partial parsing models to recover the most useful fragment analyses from the intermediate parsing results in cases of unsuccessful parses. To this effect, two statistical parti</context>
<context>ally, a uniform disambiguation model should be used in both cases. 3. A Two-stage Robust Parsing Model One common shortcoming of the partial parsing models proposed in both (Kasper et al., 1999) and (Zhang et al., 2007a) is that the results of partial parsing are sets of disjoint sub-analyses, either in the form of derivation subtrees, or in the form of MRS fragments. It is not informativeenoughtoshowtheinterconnec</context>
</contexts>
<marker>Zhang, Oepen, Carroll, 2007</marker>
<rawString>Yi Zhang, Stephan Oepen, and John Carroll. 2007b. Efficiency in unification-based N-best parsing. In Proceedings of the 10th International Conference on Parsing Technologies (IWPT 2007), pages 48–59, Prague, Czech.</rawString>
</citation>
</citationList>
</algorithm>

