<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>B Del Bimbo Bertini</author>
<author>A D</author>
<author>C Torniai</author>
</authors>
<title>Soccer Video Annotation Using Ontologies Extended with Visual Prototypes</title>
<date>2007</date>
<booktitle>In Proceedings of the International Workshop on Content-Based Multimedia Indexing, CBMI '07</booktitle>
<volume>vol., no.</volume>
<pages>25--27</pages>
<marker>Bertini, D, Torniai, 2007</marker>
<rawString>Bertini, B. Del Bimbo, A. D. and Torniai, C. (2007). Soccer Video Annotation Using Ontologies Extended with Visual Prototypes, In Proceedings of the International Workshop on Content-Based Multimedia Indexing, CBMI '07, vol., no. 25-27, pp. 212--218.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A D Bimbo</author>
</authors>
<title>Visual Information Retrieval</title>
<date>1999</date>
<publisher>Morgan Kaufmann</publisher>
<marker>Bimbo, 1999</marker>
<rawString>Bimbo, A. D. (1999). Visual Information Retrieval. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Chang</author>
<author>D Ellis</author>
<author>W Jiang</author>
<author>K Lee</author>
<author>A Yanagawa</author>
<author>A C Loui</author>
<author>J Luo</author>
</authors>
<title>Large-Scale Multimodal Semantic Concept Detection for Consumer Video</title>
<date>2007</date>
<booktitle>In Proceedings of the international workshop on Workshop on multimedia information retrieval</booktitle>
<pages>255--264</pages>
<location>Augsburg, Bavaria, Germany</location>
<marker>Chang, Ellis, Jiang, Lee, Yanagawa, Loui, Luo, 2007</marker>
<rawString>Chang, S., Ellis D., Jiang, W., Lee, K., Yanagawa, A., Loui, A. C. and Luo, J. (2007). Large-Scale Multimodal Semantic Concept Detection for Consumer Video, In Proceedings of the international workshop on Workshop on multimedia information retrieval, Augsburg, Bavaria, Germany, pp: 255--264.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Cunningham</author>
<author>D Maynard</author>
<author>K Bontcheva</author>
<author>V Tablan</author>
</authors>
<title>GATE: A Framework and Graphical Development Environment for Robust NLP Tools and Applications</title>
<date>2002</date>
<booktitle>In Proceedings of the 40 th Anniversary Meeting of the Association for Computational Linguistics(ACL'02</booktitle>
<location>Philadelphia</location>
<marker>Cunningham, Maynard, Bontcheva, Tablan, 2002</marker>
<rawString>Cunningham, H., Maynard, D., Bontcheva, K. and Tablan, V. (2002). GATE: A Framework and Graphical Development Environment for Robust NLP Tools and Applications. In Proceedings of the 40 th Anniversary Meeting of the Association for Computational Linguistics(ACL'02). Philadelphia, July 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Gillam</author>
</authors>
<title>Systems of concepts and their extraction from text. Unpublished PhD thesis</title>
<date>2004</date>
<booktitle>In Proc. 3rd European Semantic Web Conference, Budva</booktitle>
<institution>University of Surrey</institution>
<marker>Gillam, 2004</marker>
<rawString>Gillam, L. (2004). Systems of concepts and their extraction from text. Unpublished PhD thesis, University of Surrey Hare, J. S., Sinclair, P.A.S., Lewis, P.H., Martinez, K., Enser, P.G.B., and Sandom, C. J. (2006). Bridging the semantic gap in multimedia information retrieval top-down and bottom-up approaches. In Proc. 3rd European Semantic Web Conference, Budva.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Jacquemin</author>
</authors>
<title>Spotting and Discovering Terms through Natural Language Processing</title>
<date>2001</date>
<publisher>The MIT Press</publisher>
<contexts>
<context> identify all the nouns and verbs in the transcripts, and to provide a basis for the identification of compound nouns according to specified patterns of part of speech annotations (extended from e.g. Jacquemin 2001, p27). Some basic stemming does occur for the initial assessment of potential object and action concepts. At this point no frequency or other statistical information is considered. 2.2 Statistical Co</context>
</contexts>
<marker>Jacquemin, 2001</marker>
<rawString>Jacquemin, C. (2001) Spotting and Discovering Terms through Natural Language Processing. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Jaimes</author>
<author>J R Smith</author>
</authors>
<title>Semi-automatic, data-driven construction of multimedia ontologies</title>
<date>2003</date>
<booktitle>In Proc. of IEEE Int’l Conference on Multimedia &amp; Expo</booktitle>
<marker>Jaimes, Smith, 2003</marker>
<rawString>Jaimes, A. and Smith, J.R. (2003). Semi-automatic, data-driven construction of multimedia ontologies. In Proc. of IEEE Int’l Conference on Multimedia &amp; Expo.</rawString>
</citation>
<citation valid="false">
<date>2003</date>
<volume>1</volume>
<pages>6--9</pages>
<contexts>
<context>re. The description of the framework for linking the ontology with Computer Vision technology has been described previously (Vrusias et. al, 2007). Similar approaches include that of Jaimes and Smith (2003) who process text, available with multimedia, and extract terms using combinations of word frequency, TFDIF and entropy, and application of stemming. Resulting keywords are used in the manual construc</context>
</contexts>
<marker>2003</marker>
<rawString>Volume 1,  6-9 July 2003, pp. 781--4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Mori</author>
<author>H Takahashi</author>
<author>R Oka</author>
</authors>
<title>Image-to-word transformation based on dividing and vector quantizing images with words</title>
<date>1999</date>
<booktitle>In Proceedings of the First International Workshop on Multimedia Intelligent Storage and Retrieval Management (MISRM’99</booktitle>
<marker>Mori, Takahashi, Oka, 1999</marker>
<rawString>Mori, Y., Takahashi, H., and Oka, R.. (1999). Image-to-word transformation based on dividing and vector quantizing images with words. In Proceedings of the First International Workshop on Multimedia Intelligent Storage and Retrieval Management (MISRM’99).</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Newbold</author>
<author>L Gillam</author>
</authors>
<title>Automatic Document Quality Control</title>
<date>2007</date>
<booktitle>In Proceedings of the Sixth Language Resources and Evaluation Conference (LREC</booktitle>
<location>Marrakech</location>
<marker>Newbold, Gillam, 2007</marker>
<rawString>Newbold, N. and Gillam, L. (2007). Automatic Document Quality Control. In Proceedings of the Sixth Language Resources and Evaluation Conference (LREC). Marrakech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A F Smeaton</author>
<author>P Over</author>
<author>W Kraaij</author>
</authors>
<title>Evaluation campaigns and TRECVid</title>
<date>2006</date>
<booktitle>In Proceedings of the 8th ACM International Workshop on Multimedia Information Retrieval</booktitle>
<pages>321--330</pages>
<publisher>ACM Press</publisher>
<location>Santa Barbara, California, USA</location>
<marker>Smeaton, Over, Kraaij, 2006</marker>
<rawString>Smeaton, A. F., Over, P., and Kraaij, W. (2006). Evaluation campaigns and TRECVid. In Proceedings of the 8th ACM International Workshop on Multimedia Information Retrieval,  Santa Barbara, California, USA, October 26 27,  MIR '06. ACM Press, New York, NY, pp. 321--330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R K Srihari</author>
</authors>
<title>Use of Collateral Text in Understanding Photos, Artificial Intelligence Review, special issue on Integrating Language and Vision</title>
<date>1995</date>
<journal>IEEE Intelligent Systems</journal>
<volume>8</volume>
<pages>409--430</pages>
<note>Also reprinted as book chapter in Paul McKevitt (ed), Kluwer</note>
<contexts>
<context> is used for training annotation systems to recognise objects and events within unseen video footage. The derivation of key concepts and their terms from these texts and other related, or collateral (Srihari 1995), texts is used in combination with information extracted from the visual scenes. Current research into video annotation, and particularly this kind of auto-annotation, is largely undertaken within t</context>
</contexts>
<marker>Srihari, 1995</marker>
<rawString>Srihari, R. K., (1995). Use of Collateral Text in Understanding Photos, Artificial Intelligence Review, special issue on Integrating Language and Vision, Volume 8, pp. 409--430. [* Also reprinted as book chapter in Paul McKevitt (ed), Kluwer, 1995.] Stoilos, G., Simou, N., Stamou, G. and Kollias, S. (2006) “Uncertainty and the Semantic Web”, IEEE Intelligent Systems, vol. 21,  no. 5,  pp. 84-87,  Sept/Oct,  20.</rawString>
</citation>
</citationList>
</algorithm>

