ACLLifetimeAchievementAward
OnWhoseShoulders?
YorickWilks
∗
UniversityofShefﬁeld
Introduction
The title of this piece refers to Newton’s only known modest remark: “If I have seen
fartherthanothermen,itwasbecauseIwasstandingontheshouldersofgiants.”Since
he himself was so much greater than his predecessors, he was in fact standing on the
shoulders of dwarfs, a much less attractive metaphor. I intend no comparisons with
Newtoninwhatfollows:NLP/CLhasnoNewtonsandnoNobelPrizessofar,andquite
rightly.Iintendonlytodrawattentiontoatendencyinourﬁeldtoignoreitsintellectual
inheritance and debt; I intend to discharge a little of this debt in this article, partly as
an encouragement to others to improve our lack of scholarship and knowledge of our
ownroots,oftendrivenbythedesirefornoveltyandtonameourownsystems.Roger
SchankusedtoarguethatitwascrucialtonameyourownNLPsystemandthenhave
lotsofstudentstocolonizeallmajorCSdepartments,althoughtimehasnotbeenkindto
hismanyachievementsandoriginalities,eventhoughhedidbuildjustsuchanEmpire.
But to me one of the most striking losses from our corporate memory is the man who
istomethegreatestoftheﬁrstgenerationandstillwithus:VicYngve.Thisistheman
whogaveusCOMIT,theﬁrstNLPprogramminglanguage;theﬁrstrandomgeneration
of sentences; and the ﬁrst direct link from syntactic structure to parsing processes and
storage(thedepthhypothesis).Iﬁndstudentsnowrarelyrecognizehisname,andﬁnd
thatincredible.
This phenomenon is more than corporate bad memory, or being too busy with en-
gineeringtodothescholarship.ItissomethingendemicinthewiderﬁeldofComputer
Science and Artiﬁcial Intelligence, although bottom-up wiki techniques are now ﬁlling
many historical gaps for those who know where to look, as the generation of pioneers
has time to reminisce in retirement.
1
There are costs to us from this general lack of
awareness, though: a difﬁculty of “standing on the shoulders” of others and acknowl-
edgingdebts,letalonepassingonsoftwarepackages.AlanBundyusedtohighlightthis
intheAISBQuarterlywitharegularcolumnwherehelocatedandpilloriedreinventions
intheﬁeldofAI;healsorecommendedgivingobituariesforone’sownwork,andthis
papercouldbeseeninthatway,too.
∗ DepartmentofComputerScience,TheUniversityofShefﬁeld,RegentCourt,211PortobelloStreet,
Shefﬁeld,S14DP,UK.E-mail:Y.Wilks@dcs.shef.ac.uk.Thisarticleisthetextofthetalkgivenonreceiptof
theACL’sLifetimeAchievementAwardin2008.
1 SeethevideointerviewwithVictorYngveonmyWebsiteat
http://www.dcs.shef.ac.uk/∼yorick/YngveInterview.html.
©2008AssociationforComputationalLinguistics
ComputationalLinguistics Volume34,Number4
EarlyAcademicLife
My overwhelming emotion on getting this honor was, after surprise, a feeling of in-
adequacy in measuring up to previous honorees, but nonetheless, I want to grasp at
this moment of autobiography, or at what in his own acceptance paper Martin Kay
called: “but one chance for such gross indulgence.” I was born in 1939 in London at
just about the moment the Second World War started in Europe; this was, brieﬂy, a
severe career slowdown. However, the British Government had a policy of exporting
most children out of the range of bombs and I was sent to Torquay, a seaside town in
southwest England that happened to have palm trees on all the main streets, a fact it
is often difﬁcult to convince outsiders of. The town had, and has, a Grammar School
for Boys, which had a very good Cambridge-trained mathematician as its headmaster,
andeventuallyImademywaybackacrossEnglandtoPembrokeCollege,Cambridge,
to study mathematics, a college now for ever associated with my comedian contem-
poraries: Peter Cook, Clive James, Eric Idle, Tim Brooke-Taylor, and similar wastrels. I
began a series of changes of subject of study, downhill towards easier and easier ones:
frommathematicstophilosophyto(whatintheendaftergraduationbecame)NLP/AI.
It was not that I could not do the mathematics, but rather that I experienced the shock
thatmanydoofﬁndinghowwidetherangeoftalentinmathematicsis,andthatbeing
verygoodinaprovincialgrammarschooldoesnotmakeoneverygoodatCambridge.
This is a feeling peculiar to mathematics, I think, because the talent range is so much
widerthaninmostsubjects,evenatthetoplevel.
MargaretMasterman,whowastobecomethemainintellectualinﬂuenceinmylife,
was the philosophy tutor for my college, although her main vocation was running the
Institute she had founded, outside the University in a Cambridge suburb: CLRU, the
CambridgeLanguageResearchUnit.Itwasaneccentricandinformaloutﬁt,housedin
whathadbeenamuseumofBuddhistart,someofwhosesculptureswerebuiltintothe
walls. MMB (as she was known) ran the CLRU from the mid 1950s to the early 1980s
on a mix of US, UK, and EU grants and did pioneering work in MT, AI, and IR. Of
those honored by the ACL with this award over the last ﬁve years, three have been
graduatesofthatlittleBuddhistshed,andincludeMartinKayandKarenSp¨arckJones,
aremarkabletributetoMMB.Thelivesandworkofwethreehavebeenquitedifferent
but all in different ways stem from MMB’s interests and vision: She had been a pupil
of Wittgenstein and, had she known it, would have approved of Longuet-Higgins’s
remark that “AI is the pursuit of metaphysics by other means.” She believed that
practical research into the structure of language could give insight into metaphysics,
butwasinnowayother-worldly:ShewasthedaughterofaCabinetMinisterandknew
whatitwastocommand.
In a ﬁnal twist, I found after her death in 1986 that she had made me her literary
executor:Shehadneverwrittenabookandwantedmetoconstructonefromherpapers
posthumously.Ittookmetwentyyearstogettherequiredpermissionsbutthevolume
ﬁnallyappearedin2005(Mastermanetal.2005).
ThesisBuildingandCLRU
When I started work at CLRU in 1962 to do a doctorate, it had no computer in the
normal sense, only a Hollerith card sorter of the sort built for the US census half a
century before. Basically, you put a stack of punched cards into one of these things—
which looked like a metal horse on four legs—and the cards fell into (I think) 10 slots
472
Wilks OnWhoseShoulders?
dependingonhowyouhadpluggedinasetofwiresatthebacktoidentifydestination
slots for sorted cards with hole patterns on the cards. With some effort, these could
be turned into quite interesting Boolean machines; my ﬁrst task was to take a notion
of Fred Parker-Rhodes that a Hallidayan grammar could be expressed as a lattice of
typedclasses,andthenprogramthecardsortersothatrepeatedsortsofpunchedcards
could be used to parse a sentence. It was triumph of ingenuity over practicality. Later
the CLRU owned an ICL 1202 computer with 1,200 registers on a drum, but it was
a so-called bini-ten machine designed for UK cash transactions when there were still
12 pennies to a shilling, and so the 1202 has print wheel characters for 10, 11, and 12
(as well as 0–9), a fact on which Parker-Rhodes built a whole world of novel print
conventions for his research. This was the period at CLRU when Karen Sp¨arck Jones
wascompletingherhighlyoriginalthesis(publishedtwentyyearslaterasJones[1986])
onunsupervisedclusteringofthesaurusterms—whosegoalwastoproduceprimitives
forMT,itisoftenforgotten—untilshehadtomovehercomputationstoarealcomputer
attheUniversityComputingLaboratory,wheresheeventuallycreatedanewcareerin
IR, essentially using the same clump algorithms—created by Parker-Rhodes and her
husbandRogerNeedham—todoIR.
My own interests shifted to notions in an early Masterman paper titled “Semantic
message detection using an interlingua” (Masterman 1961), an area in which Martin
Kay had also originally worked on an interlingua for MT. My thesis computation was
done in LISP 1.6 on an IBM360 (under a one-man US Air Force contract, administered
by E. Mark Gold, who later became famous as the founder of learnability theory), at
SDC in Santa Monica, where I was attached loosely in 1966 to the NLP group there
run by Bob Simmons. My thesis was to be entitled “Argument and proof in Meta-
physicsfromanempiricalpointofview”andmyadvisorwasMMB’shusband,Richard
Braithwaite, Knightbridge Professor of Moral Philosophy at the University. He was a
philosopher of science and a logician, and was given the chair of moral philosophy—
a subject about which he knew nothing—because it was the only one available at
Cambridge at the time. This produced an extraordinary inaugural lecture in which
he effectively founded a new subject: “The theory of games as a tool for the moral
philosopher.”
Unfortunately for me he was not interested in my thesis, and took me on only as
a favor to MMB. My interest was the demarcation of metaphysical text: what it was, if
anything,thatdistinguisheditfromordinarylanguagetext.Wittgensteinhadoncesaid
that words were “on holiday” in metaphysical text, but also that he wanted to “bring
wordsbackfromtheirmetaphysicaltotheireverydayusage”(Wittgenstein1973).This
is exactly what I wanted to capture with computation, and the thesis was eventually
submitted to the Cambridge Philosophy faculty in 1967—then called Moral Sciences—
with a large appendix of LISP program code at the back, something they had never
seenbefore,orsince.Thethesiswasboundinyellow,thoughtheregulationsstipulated
blackorbrownbindings;Imusthavehadsomeextraordinaryideathatsomeonemight
cruisethelongcorridorsofCambridgetheseslookingforonethatstoodoutbycolor—
thearroganceofyouth!
The thesis’s starting point was Carnap’s monumental Logische Syntax der Sprache
(1937) and his claim that meaningfulness in text could be determined by “logical
syntax”—rulesofformationandtransformation(anotionwhichmaywellsoundfamil-
iar;ChomskywasastudentofCarnap).Myclaimwasthatthiswasabaddemarcation
andabettercriterionofmeaningfulnesswouldbetohaveoneinterpretationratherthan
many,namely,thatword-sensediscrimination(WSD)waspossibleforagiventext.On
that view, the “meaningless” text had too many interpretations rather than none (or
473
ComputationalLinguistics Volume34,Number4
one). A word in isolation is thus often meaningless. Preference Semantics was a WSD
programtodojustthat,andtoprovideanewsensewhereWSDfailed.
TheotherstartingpointofthethesiswasaslimpaperbyBosanquetonthenatureof
metaphysical discourse, entitled “Some Remarks on Spinoza’s Ethics.” He argued that
Spinoza’s logical arguments are all false, but that what Spinoza was actually doing is
rhetorical, not logical: imposing a new sense on the reader. The system as implemented
was, of course, a toy system, in the sense that all symbolic NLP systems were in that
era. It consisted of an analysis of ﬁve metaphysical texts (by Wittgenstein, Spinoza,
Descartes,Kant,andLeibniz)alongwithﬁverandomlychosenpassagesfromeditorials
intheLondonTimes,assomesortofcontroltexts.
The vocabulary was only about 500 words, but this was many years before
Boguraev declared the average size of vocabularies in working NLP systems to be
36 words. The semantic structures derived—via what we would now call chunk
parsing—consisted of tree structures of primitives (from a set of about 80), one tree
for each participating word sense in the text chunk, that ﬁtted into preformed triples
called templates. These templates were subject–predicate–object triples that deﬁned
well-formed sequences of the triples of trees (i.e., the ﬁrst tree for the sense of the
subject, the second for the action and so on), whose tree-heads had to ﬁt those of the
template’s three primitive items in order. The overall system selected the word senses
that ﬁtted into these structures by means of a notion of “semantic preference” (see
subsequent discussion), and then declared those to be the appropriate senses for the
words,thusdoingaprimitivekindofWSD.
There was in the thesis an additional “sense constructor” mode, called if the WSD
didnotwork,whichtriedtoidentifysomesenseofawordinthetextwhoserepresenta-
tionwouldﬁtintheoverallstructurederived,andsocouldbedeclaredasuitable“new”
senseforthewordwhichhadpreviouslyfailedtoﬁtin.Unsurprisingly,itidentiﬁed,say,
a sense of “God” in the Spinoza text with an existing sense of “Nature” so that, after
thissubstitution,thewholethingﬁttedtogetherandWSDcouldproceed,andthusthe
passagebedeclaredmeaningful,giventhecriterionofhavingasingle,ambiguity-free,
interpretation.ThiswasthetoyprocedurethatallowedmetoarguethatSpinoza’sreal
aim, whether he knew it or not, was to persuade us that the word “God” could have
thesenseof“Nature”andthatthiswastherealpointofhisphilosophy—exactlyinline
withwhatBosanquethadpredicted.
The philosophy work was never really published, outside an obscure McGill Uni-
versityphilosophyjournal,althoughthemeaningfulnesscriterionappearedinMindin
1971underthetitle“DecidabilityandNaturalLanguage”(Wilks1971).Sincepublishing
inMindwas,atthetime,theambitionofeveryyoungphilosopher,Iwasnowsatisﬁed
and could move to the simpler world of NLP. The thesis, shorn of the metaphysics,
appearedasmyﬁrstbook,Grammar,MeaningandtheMachineAnalysisofLanguage(Wilks
1972); the title was intended as a variation on the title of some strange German play,
popularatthetime,andwhoseactualnameIcannolongerremember.
PreferenceSemantics
I returned from California to CLRU but left again for the Stanford AI Lab in 1969.
I had fantasized at CLRU about all the things one could do with a methodology of
trying to base a fairly complex compositional semantics on a foundation of superﬁcial
pattern matching. This had earlier produced speculations like my 1964 CLRU paper
“Text searching with templates,” procedures that we could not possibly have carried
474
Wilks OnWhoseShoulders?
I.1 ((*ANI 1)((SELF IN)(MOVE CAUSE))(*REAL 2))→(1(*JUDG)2)
Or,insemi-English:
[animate-1 cause-to-move-in-self real-object-2]→[1 *judges 2]
I.2 (1 BE (GOOD KIND))↔((*ANI 2)WANT 1)
Or,again:
[1 is good]↔[animate-2 wants 1]
Figure1
InferencerulesinPreferenceSemantics.
out with the machines then available, but which I now choose to see as wanting to
do Information Extraction: though, of course, it was Naomi Sager who did IE ﬁrst on
medicaltextsatNYU(seeSagerandGrishman1975).
AtStanfordasapost-doc,IwasonthesamecorridorasWinograd,justarrivedfrom
MIT;Schank,thenstartingtobuildhisConceptualDependencyempire;andColbyand
hislargeteambuildingthePARRYdialoguesystem,whichincludedLarryTesler,later
theApplesoftwarearchitect.SchankandIagreedonfarmorethanwedisagreedonand
sawthatwewouldbestrongertogetherthanseparately,butneitherofuswantedtogive
upournotation:Herealized,rightly,thattherewasmorepersuasivepowerindiagrams
thanintalkofprocesseslike“preference.”Itwasanextraordinaryperiod,whenAIand
NLP were probably closer than ever before or since: Around 1972 Colmerauer passed
through the Stanford AI Lab, describing Prolog for the ﬁrst time but, as you may or
maynotremember,asatoolformachinetranslation!Ispentmytimetheredeﬁningand
expanding the coherence-based semantics underlying my thesis, calling it “Preference
Semantics” (PS), adding larger scale structures such as inference rules (see Figure 1)
andthesauri,andbuildingitintothecoreofasmallsemantics-basedEnglish-to-French
machine translation system programmed in LISP. At one point the code of this MT
systemendedupintheBostonComputerMuseum,butIhavenoideawhereitisnow.
TheprinciplesbehindPSwereasfollows:
a114
anemphasisonprocesses,notdiagrams;
a114
thenotionofafﬁnityandrepulsionbetweensenserepresentations
(cf.WaltzandPollack’sWSDconnectionism[1985]);
a114
seekingthe“bestﬁt”interpretation—theonewithmostsatisﬁed
preferences(normallyofverbs,prepositions,andadjectives);
a114
yieldingtheleastinformative/effortinterpretation;
a114
usingnoexplicitsyntax,onlysegmentationandorderofitems;
a114
meaningfulnessasbeingconnectedtoauniqueinterpretation/sense
choice;
a114
meaningseenasrepresentedinotherwords,sincenootherequivalentfor
thenotionworks(e.g.,objectsorconcepts);
a114
gistsortemplatesofutterancesascoreunderlyingentities;and
a114
thereisnocorrectinterpretationorsetofprimitiveconcepts,onlythebest
available.
475
ComputationalLinguistics Volume34,Number4
One could put some of these, admittedly programmatic and imprecise, points as
follows:
a114
Semanticsisnotnecessarilydeepbutalsosuperﬁcial(seemorerecent
resultsontheinterrelationsbetweenWSD,POS,andIE,e.g.Stevenson
andWilks[2001]).
a114
Quantitativephenomenaareunavoidableinlanguage:JohnMcCarthy
thoughttheyhadnoplaceanywhereinAI,exceptperhapsinlow-level
computervision.
a114
Referencestructures(likelexicons)areonlytemporarysnapshotsofa
languageinaparticularstate(ofexpansionorcontraction).
a114
Whatisimportantistolocatetheupdatemechanismoflanguage,
includingcruciallythecreationofnewwordsenses,whichisnot
Chomsky’ssenseofthecreativityoflanguage.
ConstructibleBeliefSystems
I returned to Europe in the mid 1970s, ﬁrst to the ISSCO institute in Lugano, where
CharniakwasandSchankhadjustleft,andthentoEdinburghasavisitorbeforetaking
a job at Essex. I began a long period of interest in belief systems, in particular seeking
some representation of the beliefs of others, down to any required degree of nesting—
for example, A’s belief about B’s belief about C—that could be constructed recursively
at need, rather than being set out in advance, as in the pioneering systems emerging
fromtheTorontogroupunderRayPerrault(AllenandPerrault1980).Ibeganthinking
about this with Janusz Bien of the University of Warsaw, who had also published a
paper arguing that CL/NLP should consider “least effort” methods: in the sense that
the brain might well, due to evolution, be a lazy processor and seek methods for
understanding that minimized some value that could be identiﬁed with processing
effort.IhadarguedinPSforchoosingshortestchainsofinferencesbetweentemplates,
and that the most connected/preferred template structure for a piece of text should be
the one found ﬁrst. I am not sure we ever proved any of this: It was just speculation,
as was the preference for the most semantically connected representation, and the
representationwiththeleastinformation.Allthisisreallyonlyelementaryinformation
theory: a random string of words contains the maximum information, but that is not
very helpful. Clearly, the preferred interpretation of “He was named after his father”
(i.e.,namedthesameratherthanlaterintime)isnottheleastinformative,sincethelatter
contains no information at all—being necessarily true—so one would have to adapt
any such slogan to: “prefer the interpretation with the least information, unless it is
zero!”
The belief work, ﬁrst with Bien, later with Afzal Ballim (Wilks and Ballim 1987)
and John Barnden, has not been a successful paradigm in terms of take-up, in that
it has not got into the general discourse, even in the way that Fauconnier’s “Mental
Spaces” (Fauconnier 1985) has. That approach uses the same spatial metaphor, but for
strictlylinguisticratherthanbeliefandknowledgepurposes.ButIthinktheVIEWGEN
belief paradigm, as it became, had virtues, and I want to exploit this opportunity to
remindpeopleofit.Itwasmeanttocapturetheintuitionthatifwewant,forlanguage
476
Wilks OnWhoseShoulders?
understanding purposes, to construct X’s beliefs about Y’s beliefs—what I called the
environmentofY-for-X—then:
1. Itmustbeaconstructionthatcanbedoneinrealtimetoanylevelof
nestingrequired,becausewecannotimagineitpre-storedforallfuture
nestings,asPerraultelal.ineffectassumed.
2. Itmustcapturetheintuitionthatmuchofourbeliefisacceptedbydefault
fromothers:AsVIEWGENexpressesit,Iwillacceptasabeliefwhatyou
say,becauseIhavenormallynowayofchecking,orexperimentingon,let
alonerefuting,thethingsyoutellme,e.g.,thatyouhadeggsforbreakfast
yesterday.Assomeoneinpoliticsonceputit,“Thereisnoalternative.”
Unless,thatis,whatyousaycontradictssomethingIbelieveorcaneasily
provefromwhatIbelieve.
3. Wemustbeabletomaintainapparentlycontradictorybeliefs,provided
theyareheldinseparatespacesandwillnevermeetascontradictions.I
canthusmaintainwithinmy-space-for-youbeliefsofyours(accordingto
me)thatIdonotinfacthold.
In VIEWGEN, belief construction is done in terms of a “push down” metaphor: A
permeable “container” of your beliefs is pushed into a ”container” of my beliefs and
whatpercolatesthroughthemembrane,frommetoyou,willbebelievedandascribed
to you, unless it is explicitly contradicted, namely, by some contrary belief I already
ascribe to you, and which, as it were, keeps mine from percolating through. The idea
is to construct the appropriate “inner belief space” at the relevant level of nesting, so
thatinferencecanbedone,andtoderiveconsequences(withinthatconstrainedcontent
space) that also serve to model, in this case, you the belief holder in terms of goals
and desires, in addition to beliefs. This approach is quite different not only from the
Perrault/Torontosystemofbelief-relevantplansbutalsotoAItheoriesthatmakeuseof
sets-of-supportpremises,sincethisisaboutbelief-inheritance-by-default.Itisalsoquite
distinct from linguistic theories like Wilson and Sperber’s Relevance Theory, which
take no account at all of belief as relative to individuals, but perform all operations
in some space that is the same for everyone, which is an essentially Chomskyan ideal
competence-stylenotionofbeliefthatisnotrelativetoindividuals—whichisofcourse
absurd.
Mark Lee and a number of my students have created implementations of this
approachandlinkedittodialogueandotherapplications,buttherehasbeennomajor
application showing its essential role in a functioning conversational theory where
complex belief states are created in real time. However, the ﬁeld is, I believe, now
moving in that direction (e.g., with POMDP theories [Williams and Young 2007]) since
the possibility of populating belief theories with a realistic base from text by means of
InformationExtractionorSemanticWebparsingtoRDFformatisnowreal(amatterwe
shallreturntosubsequently).
There were, for me at least, two connections between the VIEWGEN belief work
and Preference Semantics, in terms of meaning and its relation to processes. First,
there was the role of choice and alternatives, crucial to PS, in that an assigned mean-
ing interpretation for a text was no more than a choice of the best available among
alternatives, because preference implies choice, in a way that generative linguistics—
though not of course traditions like Halliday’s—always displayed alternatives but
consideredchoicebetweenthemamatterformereperformance.Whatwasdispensable
477
ComputationalLinguistics Volume34,Number4
to generative linguistics was the heart of the matter, I argued, to NLP/CL. Secondly,
VIEWGEN suggested a view of meaning, consistent locally with PS, dependent on
which individuals or classes one chose to see in terms of each other—the key notion
herewasseeingonethingasanotheranditsconsequencesformeaning.So,ifonechose
to identify (as being the same person under two names) Joe (and what one believed
abouthim)withFred’sfather(andwhatoneknewabouthim),thehypothesiswasthat
a belief environment should be constructed for Joe-as-Fred’s-father by percolating one
set of beliefs into the other, just as was done by the basic algorithm for creating A’s-
beliefs-about-B’s-beliefs from the component beliefs of A and B. This process created
a hybrid entity, with intensional meaning captured by the set of propositions in that
innerenvironmentofbeliefspace,butwhichwasnowneitherJoenorFred’sfatherbut
ratherthesystem’spointofviewoftheirdirectionalamalgamation:Joe-as-Fred’s-father
(whichmightcontaindifferentpropositionsfromtheresultofFred’s-father-as-Joe).
Morenatural,andfundable,scenarioswereconstructedforthistechniqueinthose
days,suchasknowledgerepresentations forNavyships’captainsgenuinelyuncertain
as to whether ship-in-my-viewﬁnder-now was or was not to be identiﬁed with the
storedrepresentationforenemy-ship-number-X.Theimportantunderlyingnotionwas
onegoingbacktoFrege,andwhichﬁrsthadanoutinginWinograd’sthesis(Winograd
1972), where he showed you could have representations for blocks that did not in fact
exist on the Blocks World table. A semantics must be able to represent things without
knowingwhethertheyexistornot;thatisabasicrequirement.
Later, and working with John Barnden and Afzal Ballim, this same underly-
ing process of conﬂating two belief objects was extended to the representation of
“metaphorical objects,” which could be described, quite traditionally in the literature,
as A-viewed-as-B (e.g., an atom viewed as a billiard ball). The metaphorical object
atom-as-billiard-ball was again created by the same push-down or fusion of belief sets
as in the basic belief point-of-view procedure. All this may well have been fanciful,
and was never fully exploited in published work with programs, but it did have a
certain intellectual appeal in wanting to treat belief, points of view, metaphor and
identiﬁcationofintensionalindividuals—normallyquiteseparateissuesinsemantics—
as being modellable by the same simple underlying process (see Ballim, Wilks, and
Barnden 1991). One novel element that did emerge from this analysis was that, in
theconstructionofthesecomplexintensionalidentiﬁcations,suchasbetween“today’s
Wimbledon winner” and “the top male tennis seed,” one could choose directions of
“viewing as” with the belief sets that led to objects which were neither the classicdere
nordedictooutcomes:Thosebecamejusttwoamongarangeofchoices,andtheothers
ofcoursehadnohandyLatinnames.
Adaptingtothe“EmpiricalWave”inNLP
Forme,aswithmanyothers,especiallyinEurope,thebeginningoftheempiricalwave
inNLPwastheworkofLeechandhiscolleaguesatLancaster:CLAWS4(anamewhich
hidesaUKpoliticaljoke),theirpart-of-speechtaggerbasedonlarge-scaleannotationof
corpora.SuchtaggingisnowthestandardﬁrststageofalmosteveryNLPprocessandit
maybehardforsometorealizetheskepticsmitsarrivalprovoked:”Whatcouldanyone
want that for?” was a common reaction from those still preoccupied by computational
syntaxorsemantics.ThatsystemwassoldtoIBM,whosespeechgroup,underJelinek,
Mercer, and Brown, subsequently astonished the CL/NLP world with their statistical
machine translation system CANDIDE. I wrote critical papers about it at the time, not
totallyunconnectedtothefactthatIwasfundedbyDARPAonthePANGLOSSproject
478
Wilks OnWhoseShoulders?
at NMSU (along with CMU and ISI/USC) to do MT by competing, but non-statistical,
methods.
In one paper, I used the metaphor of “stone soup” (Wilks 1996): A reference to the
old peasant folk-tale of the traveler who arrives at a house seeking food and claiming
to have a stone that makes soup from water. He begs a ham bone to stir the water
and stone and eventually cons out of his hosts all the ingredients for real soup. The
aspectofthestoryIwasfocusingonwasthat,intheCANDIDEsystem,Iwasnotsure
that the “stone,” namely IBM’s “fundamental equation of MT,” was in fact producing
the results, and suggested that something else they were doing was giving them their
remarkablesuccessrateofabout50%ofsentencescorrectlytranslated.Astheirgeneral
methodology has penetrated the whole of NLP/CL, I no longer stand by my early
criticisms;IBMwasofcourseright,andhadeverythingtoteachtherestofus.
Early critics of data-driven, alias empirical, CL found it hard to accept, whatever
its successes in, say, POS tagging, that its methods could extend to the heartland of
semanticsandpragmatics.Likeothers,Icametoseethisassumptionwasquiteuntrue,
and myself moved towards Machine Learning (ML) approaches to word-sense disam-
biguation (e.g., Stevenson and Wilks 2001) and I now work in ML methods applied to
dialogue corpora (as I shall mention subsequently). But the overall shift in approaches
tosemanticssince1990hasnotonlybeenintheintroductionofstatisticalmethods,and
ML in particular, but also in the unexpected advantages that have been gained from
what one might call non-statistical empirical linguistics, and in particular Information
Extraction(IE;seeWilks1997).
I referred earlier to the fact that my early work could be called, in a general sense,
semantic parsing, and that it was in fact some form of superﬁcial pattern matching
onto language chunks that was then transformed to different layers of compositional
semantic representation. There were obvious relations between that general approach
andwhatemergedfromtheDARPAcompetitionsintheearly1990sasIE,atechnology
that, when honed by many teams, and especially when ML techniques were added to
it later, had remarkable success and a range of applications; it also expanded out into
other,traditionallyseparate,NLPareassuchasquestionansweringandsummarization.
This approach is not in essence statistical at all, however, although it is in a clear
sense “superﬁcial,” with the assumption that semantics is not necessarily a “deep”
phenomenon but present on the language surface. I believe the IE movement is also
oneofthedriversbehindtheSemanticWebmovement,towhichInowturn,andwhich
I think has brought NLP back to a position nearer the core of AI, from which it drifted
awayinthe1980s.
MeaningandtheSemanticWeb
The Semantic Web(SW; Berners-Lee, Hendler, and Lassila 2001) is what one could call
Berners-Lee’s second bigidea, aftertheWorld WideWeb;itcan bedescribed brieﬂyas
turning the Web into something that can also be understood by computers in the way
thatitisunderstoodbypeoplenow,asaweboftextsandpictures.Dependingonone’s
attitudetothisenterprise,alreadywell-fundedbytheEuropeanCommissionatleast,it
canbedescribedasanyofthefollowing:
1. AsarevivalofthetraditionalAIgoal(atleastsinceMcCarthyandHayes
[1969])ofreplacinglanguage,withallitsvagueness,bysomeformof
logicalrepresentationuponwhichinferencecanbedone.
479
ComputationalLinguistics Volume34,Number4
2. Asahierarchyofformsofannotation—orwhatIshallcallaugmentation
ofcontent—reachingupfromsimplePOStaggingtosemanticclass
annotation(e.g.CITY,PERSON-NAME)toontologymembershipand
logicalforms.DARPA/MUC/NISTcompetitionshaveworkedtheirway
uppreciselythishierarchyovertheyearsandmanynowconsiderthat
contentcanbe“annotatedontolanguage”reliablyuptoanyrequired
level.ThiscanbethoughtofasextendingIEtechniquestoanylinguistic
levelbyvarietiesofMLandannotation.
3. Asasystemofaccesstotrusteddatabasesthatgroundthemeaningsof
termsinlanguage;yourtelephoneorsocialsecuritynumbermightground
youuniquely(inwhatiscalledaURI),orbetterstill—andthisisnowthe
standardview—auniqueidentifyingobjectnumberforyouoverand
abovephonesandsocialsystems.ThisisverymuchTimBerners-Lee’s
ownviewoftheSW.
There is also a fourth view, much harder to express, that says roughly that, if we keep
ourheads,theSWcancomeintobeingwithanysystemofcodingthatwilltoleratethe
expansion of scale of the system, in the way that, miraculously, the hardware under-
pinnings of the World Wide Webhave tolerated its extraordinary expansion without
major breakdown. This is an engineering view that believes there are no fundamental
problemsaboutthemeaningsandreferenceofSWtermsin,forexample,theontologies
withintheSW,andeverythingwillbeallrightifwejustholdtight.
This view may turn out to be true but it is impossible to discuss it. Similarly, view
(3)hasnospecialprivilegebecauseitistheWorldWideWebfounder’sownview:Marx
was notoriously not a very consistent Marxist, and one can ﬁnd multiple examples
of this phenomenon. View (3) is highly interesting and close to philosophical views
of meaning expressed over many years by Putnam, which can be summarized as the
ideathatscientists(andBerners-Leewasbyoriginadatabaseexpertandphysicist)are
“guardians of meaning” in some sense because they know what terms really mean, in
a way that ordinary speakers do not. Putnam’s standard example is that of metals like
molybdenum and aluminum, which look alike and, to the man in the street, have the
same conceptual, intensional meaning, namely light, white, shiny metal. But only the
scientist (says Putnam) knows the real meanings of those words because he knows
theatomicweightsofthetwometalsandmethodsfordistinguishingthem.
No one who takes Wittgenstein—and his view that we, the users of the language,
areinchargeofwhattermsmean,andnotanyexpert—atallseriouslycanevenconsider
suchaview.OntheviewweareattributingtoWittgenstein,thetermsaresynonymous
inapubliclanguage,justaswaterandheavywaterare,andanyevidencetothecontrary
isaprivatematterforscience,notformeaning.
View (1) of the Semantic Webis a well-supported one, particularly by recycled AI
researchers:Theyhave,ofcourse,changedtackconsiderablyandproducedformalisms
for the SW, some of which are far closer to the surface of language than logic (what
is known as RDF triples), as well as inference mechanisms like DAML-OIL that gain
advantages over traditional AI methods on the large and practical scale the SW is
intended to work over. On the other hand there are those in AI who say they have
ignored much of the last 40 years of AI research that would have helped them. This
dispute has a conventional ﬂavor and it must be admitted that, in more than 40 years,
AIitselfdidnotcomeupwithsuchformalismsthatstoodanychanceatallofworking
onalargescaleonunstructuredmaterial(i.e.,text).
480
Wilks OnWhoseShoulders?
ThisleavesuswithView(2),whichismyown:namely,thatweshouldseetheSW
partially in NLP terms, however much Berners-Lee rejects such a view and says NLP
is irrelevant to the SW. The whole trend of SW research, in Europe at least, has been
to build up to higher and higher levels of semantic annotation—a technology that has
grown directly out of IE’s success in NLP—as a way of adding content to surface text.
It seems to me obvious that any new SW will evolve from the existing WWW of text
by some such method, and that method is basically a form of large-scale NLP, which
now takes the form of transducers from text to RDF (such as the recently advertised
ReutersAPI).TheideathattheSWcanstartfromscratchinsomeotherplace,ignoring
the existing World Wide Web, seems to me unthinkable; successful natural evolution
alwaysadaptsthefunctionofwhatisavailableandalmostneverstartsagainafresh.
I have set out my views on this recently in more detail (Wilks 2008), but it is
important to see that the SW movement—at least as I interpret it herein, and that does
seem pretty close to the way research in it is currently being funded, under calls and
titleslike“semanticcontent”—isonethatlinkstothethemesalreadydevelopedinthis
paper in several ways, and which correspond closely to issues in my own early work,
butwhichhavenotgoneaway:
1. TheSWtakessemanticannotationofcontentasbeingamethod—whether
donebyhumansoraftermachinelearning—ofrecodingcontentwith
specialterms,termsclosetowhathavetraditionallybeencalledsemantic
primitives.Itisexactlythisthatwasdeniedbytheearlyformsof,say,
statisticalMT,wheretherewasnothingavailabletothemechanismexcept
thewordsthemselves.ThisisalsoquiteexplicitintraditionalIR,where,
forexample,KarenSp¨arckJonesconsistentlyarguedagainstanyformof
contentrecoding,includingtheSW.Assheputit:“Oneofthese[simple,
revolutionaryIR]ideasistakingwordsastheystand”(Sp¨arckJones2003).
2. TheSWaccordsakeyroletoontologiesasknowledgestructures:partially
hierarchicalstructurescontainingkeyterms—primitivesagainunder
anotherguise—whosemeaningsmustbemadeclear,particularlyatthe
moreabstractlevels.TheoldAItraditioninlogic-basedknowledge
structuring—descendingfromMcCarthyandHayes(1969)—wassimply
todeclarewhattheseprimitivepredicatesmeant.Theproblemwasthat
predicates,normallyEnglishwordswrittenincapitalletters(asall
linguisticprimitivesintheendseemtobe),becameaffectedbytheir
inferentialrolesovertimeandtheprocessofcodingitself.Thisbecame
veryclearinthelong-termCycproject(Lenat1995)wherethekey
predicateschangedtheirmeaningsover30yearsofcoding,buttherewas
nowayofdescribingthatfactwithinthesystem,soastoguarantee
consistency.InNirenburgandWilks(2000),NirenburgandIdebatethis
issueindepth,andIdefendthepositionthatonecannotsimplymaintain
themeaningsofsuchtermsbyﬁatandindependentoftheirusage—they
looklikewordsandtheyfunctionlikewordsbecause,intheend,theyare
words.TheSWoffersawayoutofthisclassicAIdilemmabybuildingup
thehierarchyofannotationswithempiricalprocesseslikeontology
inductionfromcorpora(e.g.,ABRAXAS;seeIriaetal.2006);inthisway
themeaningsofhigherleveltermsareconnectedbackdirectlytotext
usage.Braithwaite,mythesisadvisor,describedinhisclassic“Scientiﬁc
explanation”(Braithwaite1953)aprocessinthephilosophyofsciencehe
481
ComputationalLinguistics Volume34,Number4
called“semanticascent”bywhichtheabstracthigh-leveltermsina
scientiﬁctheory,seenasalogicalhierarchyofdeductiveprocesses—terms
suchas“neutron,“possiblycorrespondingtounobservables—acquired
meaningbyanascentofsemanticinterpretationupthetheoryhierarchy
frommeaningsgroundedinexperimentaltermsatthebottom.Itissome
suchgroundingprocessIenvisagetheSWasprovidingforthemeanings
ofprimitiveontologicaltermsinaknowledgestructure.
3. TheRDFforms,basedontriplesofsurfaceitems,asaknowledge
base—usuallywithsubject–action–objectasbasicform—canprovidealess
formalbutmoretractablebaseforknowledgethantraditionalFirstOrder
PredicateLogic(FOPL).Theyhaveaclearrelationshipbacktothecrude
templatesofmyearlyworkandthelatertemplatesofIE.Iclaimno
precedencehere,butonlynotethereturnofafunctioningbutplausible
notionof“superﬁcialsemantics.”Itseemstomenotuntruehistoricallyto
claimthatRDF,therepresentationalbaseoftheSW,isareturnofthelevel
ofrepresentationthatSchank(underthenameConceptualDependency,in
Schank[1975])andI(underthenamePreferenceSemantics)developedin
thelate1960sandearly1970s(Wilks1975).IrememberthatattheStanford
AILabatthattime,JohnMcCarthy,astrongadvocateofFOPLastheright
levelofrepresentationoflanguagecontent,wouldcommentthat
formalismslikethesetwomighthavearoleasahalfwayhouseonaroute
fromlanguagetoafulllogicrepresentation.OnoneviewoftheSWthat
intermediatestagemayprovetobetherightstage,becausefullAI
representationshaveneverbeenabletodeliverintermsofscaleand
tractability.Timewilltell,andfairlysoon.
The most important interest of the SW, from the point of view of this paper, is that
it provides at last a real possibility of a large-scale test of semantic and knowledge
coding:Onethingtheempiricalmovementhastaughtusisthevitalimportanceofscale
and the need to move away from toy systems and illustrative examples. I mentioned
earlier the freely available Reuters API for RDF translation which Slashdot advertised
underthetitle“IstheSemanticWebaRealityatLast?”Thisisexactlythekindofmove
to the large scale that we can hope will settle deﬁnitively some of these ancient issues
aboutmeaningandknowledge.
ALateInterestinDialogue:TheCompanionsProject
MyonlyearlyexposuretodialoguesystemswasColby’sPARRY:AsInotedearlier,his
team was on the same corridor as me at Stanford AI Labin the early 1970s. I was a
great admirer of the PARRY system: It seemed to me then, and still does, probably the
most robust dialogue system ever written. It was available over the early ARPANET
and tried out by thousands, usually at night: It was written in LISP and never broke
down;makingallowancesforthefactitwassupposedtobeparanoid,itwasplausible
and sometimes almost intelligent. In any case it was inﬁnitely more interesting than
ELIZA, and it is one of the great ironies of our subject that ELIZA is so much better
known. PARRY remembered what you had said, had elementary emotion parameters
and, above all, had something to say, which chatbots never do. John McCarthy, who
ran the AI Lab, would never admit that PARRY was AI, even though he tolerated it
under his roof, as it were, for many years; he would say “It doesn’t even know who
482
Wilks OnWhoseShoulders?
the President is,” as if most of the world’s population did! PARRY was in fact a semi-
refutation of the claim that you need knowledge to understand and converse, because
it plainly knew nothing; what it had was primitive “intentionality,” in the sense that it
hadthings“itwantedtosay.”
My own introduction to practical work on dialogue was when I was contacted in
the late 1990s by David Levy, who had written 40 books on chess and ran a company
that made chess machines. He already had a footnote in AI as the man who had bet
McCarthy,Michie,andotherAIleadersthatachessmachinewouldnotbeathimwithin
tenyears,andhewonthebetmorethanonce.Inthe1990sheconceivedadesiretowin
theLoebnerPrize
2
forthebestdialogueprogramoftheyear,andcametousatShefﬁeld
tofundateamtowinitforhim,whichwedidin1997.Idesignedthesystemanddrew
upon my memories of PARRY, along with obvious advances in the role of knowledge
basesandinference,andtheimportanceofcorporaandmachinelearning.Forexample,
wetookthewholesetofwinningLoebnerdialoguesofftheWebsoastolearnthekinds
of things that the journalist-testers actually said to the trial systems to see if they were
reallyhumansormachines.
Our system, called CONVERSE (see Levy et al. 1997), claimed to be Catherine, a
34-year old female British journalist living in New York, and it owed something to
PARRY, certainly in Catherine’s desire to tell people things. It was driven by frames
corresponding to each of about 80 topics that such a person might want to discuss;
death, God, clothes, make-up, sex, abortion, and so on. It was far too top-down and
unwilling to shift from topic to topic but it could seem quite smart on a good day, and
probably won because we had built in news from the night before the competition of
a meeting Bill Clinton had had that day at the White House with Ellen de Generes, a
lesbian actress. This gave a certain immediacy to the responses intended to sway the
judges,asin“DidyouseethatmeetingEllenhadwithClintonlastnight?”
This was all great fun and gave me an interest in modeling dialogue that has
persisted for a decade and is now exercised through COMPANIONS (Wilks 2004), a
largeEU15-sitefour-yearprojectthatIrun.COMPANIONSaimstochangethewaywe
think about the relationships of people to computers and the Internet by developing a
virtualconversational“Companion.”Thiswillbeanagentor“presence”thatstayswith
theuserforlongperiodsoftime,developingarelationshipand“knowing”itsowner’s
preferences and wishes. It will communicate with the user primarily by using and un-
derstandingspeech,butalsousingothertechnologiessuchastouchscreensandsensors.
Another general motivation for the project is the belief that the current Internet
cannot serve all social groups well, and it is one of our objectives to empower citizens
(includingthenon-technical,thedisabled,andtheelderly)withanewkindofinterface
based on language technologies. The vision of the Senior Companion—currently our
main prototype—is that of an artiﬁcial agent that communicates with its user on a
long-termbasis,adaptingtotheirvoice,needs,andinterests:Acompanionthatwould
entertain, inform, and react to emergencies. It aims to provide access to information
and services as well as company for the elderly by chatting, remembering past con-
versations,andorganizing(andmakingsenseof)theowner’sphotographicandimage
memories. This Companion would assume a user with a low level of technical knowl-
edge, and who might have lost the ability to read or produce documents themselves
unaided,butwhomightneedhelpdealingwithletters,messages,bills,andgettingin-
formationfromtheInternet.Duringitsconversationswithitsuserorowner,thesystem
2Seehttp://www.loebner.net/Prizef/loebner-prize.html.
483
ComputationalLinguistics Volume34,Number4
builds up a knowledge inventory of family relations, family events in photos, places
visited, and so on. This knowledge base is currently stored in RDF, the Semantic Web
format, which has two advantages: ﬁrst, a very simple inference scheme with which
to drive further conversational inferences, and second, the possibility, not yet fulﬁlled,
ofaccessingarbitraryamountsofworldinformationfromWikipedia,alreadyavailable
in RDF, which could not possibly have been pre-coded in the dialogue manager, nor
elicitedinaconversationofreasonablelength.So,iftheusersaysaphotowastakenin
Paris,theCompanionshouldbeabletoaskaquestionaboutPariswithoutneedingthat
knowledgepre-coded,butonlyusingrapidlyaccessedWikipediaRDFsaboutParis.An
ultimateaimofthisaspectoftheSeniorCompanionistheprovisionofalifenarrative,
anassistedautobiographyforeveryone,onethatcouldbegiventorelativeslaterifthe
ownerchosetoleaveittothem.ThereisalotoftechnicalstuffintheSeniorCompanion:
script-likestructures—calledDAFsorDialogueActionForms—designedtocapturethe
courseofdialoguesonspeciﬁctopicsorindividualsorimages,andtheseDAFsweare
tryingtolearnfromtiledcorpora.TheDAFsarepushedandpoppedonasinglestack,
and that simple virtual machine is the Dialogue Manager, where DAFs being pushed,
popped,orreenteredatalowerstackpointareintendedtocapturetheexitsfrom,and
returns to, abandoned topics and the movement of conversational initiative between
the system and the user. We are halfway through the project and currently have two
prototype Companions: The other, based not at Shefﬁeld but at Tampere, is a Health
and Fitness Companion (HFC).
3
It is more task-oriented than the Senior Companion
and aims to advise on exercise and diet. The HFC is on a mobile phone architecture as
wellasaPC,andwemayseektocombinethetwoprototypeslater.Thecentralnotionof
aCompanionisthatofthesame“personality,”withitsmemoryandvoicebeingpresent
nomatterwhattheplatform.Itisnotarobot,andcouldbeembodiedlaterinsomething
likeachattyfurryhandbag,beingheldonasofaandperhapsremindingyouaboutthe
previousepisodesofyourfavoriteTVprogram.
Finale
Thisarticlehashadsomethingoftheformofalifestory,andeveryonewantstobelieve
theirlifeissome kindofnarrative ratherthanarandom chase fromfunding agency to
funding agency, with occasional pauses to carry out a successful proposal. But let us
returntoNewtonforamomentinclosing;forusinCLheisthegreatcounter-example,
ofwhywedonotdoscienceorengineeringinthatclassicsolitarymanner:
...wherethestatuestood
OfNewton,withhisprismandsilentface,
Themarbleindexofamindforever
VoyagingthroughstrangeseasofThought,alone.
—WilliamWordsworth(1770–1850)
ThePrelude,bookiii,line61
Theemphasisthereformeisonalone,whichisprettymuchunthinkableinourresearch
world of teams and research groups. Our form of research is essentially corporate and
cooperative; we may not be sure whose shoulders we are standing on, but we know
whose hands we are holding. I have worked in such a way since my thirties and, at
3 AnearlydemoofaCompanioncanbeseenonYouTubeat
http://www.youtube.com/watch?v=SqIP6sTt1Dw.
484
Wilks OnWhoseShoulders?
Shefﬁeld, my work would not have been possible without a wide range of colleagues
and former students in the NLP group there over many years and including Louise
Guthrie, RobGaizauskas, Hamish Cunningham, Fabio Ciravegna, Mark Stevenson,
Mark Hepple, Kalina Bontcheva, Roberta Catizone, Nick Webb, and many others. In
recent years, what one could call “DARPA culture”—of competitions and cooperation
subtlymixed—aswellasthegreatrepositoriesofsoftwareanddatalikeLDCandELRA,
havegonealongwaytomitigatethepersonalandgroupisolationintheﬁeld.
But we do have to face the fact that, in many ways, we do not do classic science:
We have no Newtons and will never have any. That is not to deny that we need real
ideas and innovations, and now may be a time for fresh ones. We have stood on the
shouldersofFredJelinek,KenChurch,andothersfornearlytwodecadesnow,andthe
strain is beginning to tell as papers still strive to gain that extra 1% in their scores on
some small task. We know that some change is in the air and I have tried to hint in
thisarticleastosomeoftheplaceswherethatmightbe,evenifthatwillmeanapartial
returntoolder,unfashionableideas;forthereisnothingnewunderthesun.Butlocating
themandexploitingthemwillnotbeinmyhandsbutinyours,readersofComputational
Linguistics!
Acknowledgments
Firstofcoursetoallthosewhohaveworked
withmeovermanyyearsandtowhomI
owesomuch,particularlyinconnection
withthisaward.Thentomycurrentsponsor:
ThisworkwasfundedbytheCompanions
project(www.companions-project.org)
sponsoredbytheEuropeanCommissionas
partoftheInformationSocietyTechnologies
(IST)programmeunderECgrantnumber
IST-FP6-034434.
References
Allen,JamesF.andC.RaymondPerrault.
1980.Analyzingintentioninutterances.
ArtiﬁcialIntelligence,15:143–178.
Ballim,Afzal,YorickWilks,andJohnA.
Barnden.1991.Beliefascription,metaphor,
andintensionalidentiﬁcation.Cognitive
Science,15(1):133–171.
Berners-Lee,T.,J.Hendler,andO.Lassila.
2001,September.Thesemanticweb.
ScientiﬁcAmerican,28–37.
Braithwaite,RichardBevan.1953.
ScientiﬁcExplanation.AStudyofthe
FunctionofTheory,ProbabilityandLawin
Science.CambridgeUniversityPress,
Cambridge,UK.
Carnap,Rudolf.1937.TheLogicalSyntaxof
Language.KeganPaul,London.
Fauconnier,Gilles.1985.MentalSpaces.
CambridgeUniversityPress,
Cambridge,UK.
Iria,Jos´e,ChristopherBrewster,Fabio
Ciravegna,andYorickWilks.2006.An
incrementaltri-partiteapproachto
ontologylearning.InProceedingsofthe
LanguageResourcesandEvaluation
Conference(LREC-06),22–28May.
Lenat,DouglasB.1995.CYC:Alarge-scale
investmentinknowledgeinfrastructure.
CommunicationsoftheACM,38(11):33–38.
Levy,D.,R.Catizone,B.Battacharia,
A.Krotov,andY.Wilks.1997.Converse:
Aconversationalcompanion.In
ProceedingsoftheFirstInternational
WorkshopofHuman-Computer
Conversation.Bellagio,Italy.
Masterman,Margaret.1961.Semantic
messagedetectionformachine
translation,usinganinterlingua.In
ProceedingsoftheFirstInternational
ConferenceonMachineTranslationof
LanguagesandAppliedLanguageAnalysis,
pages438–475.HMSO,Teddington,
Middlesex,UK.
Masterman,Margaret.2005.InYorickWilks,
editor,Language,CohesionandForm(Studies
inNaturalLanguageProcessing).Cambridge
UniversityPress,NewYork.
McCarthy,J.andP.J.Hayes.1969.Some
philosophicalproblemsfromthe
standpointofartiﬁcialintelligence.In
B.MeltzerandD.Michie,editors,Machine
Intelligence,volume4.Edinburgh
UniversityPress,Edinburgh,
pages463–502.
Nirenburg,SergeiandYorickWilks.2000.
Machinetranslation.Advancesin
Computers,52:160–189.
Sager,NaomiandRalphGrishman.
1975.Therestrictionlanguagefor
computergrammarsofnaturallanguage.
CommunicationsoftheACM,
18(7):390–400.
485
ComputationalLinguistics Volume34,Number4
Schank,RogerC.1975.ConceptualInformation
Processing.ElsevierScienceInc.,NewYork.
Sp¨arckJones,Karen.1986.Synonymyand
semanticclassiﬁcation.Edinburgh
UniversityPress,Edinburgh,Scotland.
Sp¨arckJones,Karen.2003.Document
retrieval:Shallowdata,deeptheories;
historicalreﬂections,potentialdirections.
InAdvancesinInformationRetrieval,Lecture
NotesinComputerScience,1–11.Springer,
Berlin/Heidelberg.
Stevenson,MarkandYorickWilks.2001.The
interactionofknowledgesourcesinword
sensedisambiguation.Computational
Linguistics,27(3):321–349.
Waltz,DavidL.andJordanB.Pollack.
1985.Massivelyparallelparsing:A
stronglyinteractivemodelofnatural
languageinterpretation.CognitiveScience,
9(1):51–74.
Wilks,Y.1975.Preferencesemantics.
InE.L.Keenan,editor,FormalSemanticsof
NaturalLanguage.CambridgeUniversity
Press,Cambridge,pages329–348.
Wilks,Yorick.1971.Decidabilityandnatural
language.Mind,80:497–520.
Wilks,Yorick.1972.Grammar,Meaningand
MachineAnalysisofLanguage.Routledge
andKeganPaul,London.
Wilks,Yorick.1996.Statisticalversus
knowledge-basedmachinetranslation.
IEEEExpert:IntelligentSystemsandTheir
Applications,11(2):12–18.
Wilks,Yorick.1997.Informationextractionas
acorelanguagetechnology.InInternational
SummerSchoolonInformationExtraction:A
MultidisciplinaryApproachtoanEmerging
InformationTechnology,volume1299of
LectureNotesInComputerScience,
pages1–9,Springer,Berlin.
Wilks,Yorick.2004.Artiﬁcialcompanions.In
MachineLearningforMultimodalInteraction:
FirstInternationalWorkshop,pages36–45.
Wilks,Yorick.2008.Thesemanticweb:
Apotheosisofannotation,butwhatareits
semantics?IEEEIntelligentSystems,
23(3):41–49.
Wilks,YorickandAfzalBallim.1987.Multiple
agentsandtheheuristicascriptionof
belief.InProceedingsoftheInternational
JointConferenceArtiﬁcialIntelligence
(IJCAI-87),pages118–124,Milan,Italy.
Williams,JasonD.andSteveYoung.2007.
PartiallyobservableMarkovdecision
processesforspokendialogsystems.
ComputerSpeechandLanguage,
21(2):393–422.
Winograd,Terry.1972.UnderstandingNatural
Language.AcademicPress,Orlando,FL.
Wittgenstein,Ludwig.1973.Philosophical
Investigations.BlackwellPublishers,
Oxford,UK.
486

