<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>H Bonneau-Maynard</author>
<author>A Allauzen</author>
<author>D D´echelotte</author>
<author>H Schwenk</author>
</authors>
<title>Combining morphosyntactic enriched representation with n-best reranking in statistical translation</title>
<date>2007</date>
<booktitle>In proc. Syntax and Structure in Statistical Translation (SSST), NAACL-HLT 2007 / AMTA Workshop</booktitle>
<marker>Bonneau-Maynard, Allauzen, D´echelotte, Schwenk, 2007</marker>
<rawString>H. Bonneau-Maynard, A. Allauzen, D. D´echelotte, and H. Schwenk. 2007. Combining morphosyntactic enriched representation with n-best reranking in statistical translation. In proc. Syntax and Structure in Statistical Translation (SSST), NAACL-HLT 2007 / AMTA Workshop, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>Some advances in rule based part-of-speech tagging</title>
<date>1994</date>
<booktitle>In AAAI, editor, Proceedings of the Twelfth National Conference on Artificial Intelligence</booktitle>
<pages>722--727</pages>
<location>Seattle, WA</location>
<contexts>
<context> 1. Introduction The most widely used French Part of Speech (POS) tagger is the French version of the Treetagger (Schmid, 1994) which is freely available on the web1. A version of the Brill’s tagger (Brill, 1994), trained on the GRACE (Paroubek et al., 1998) corpus is also frequently cited2. Both taggers are trained with small tagsets (around 50 tags) which do not include number or gender distinction. Moreov</context>
<context>ive evaluation, a part of the corpus is excluded from the training data to provide an unseen test set. For this experiment, three state-of-the-art statistical taggers are trained: the Brill’s tagger (Brill, 1994), Treetagger (Schmid, 1994) and a standard Hidden Markov Model (HMM) tagger (Charniak et al., 1993). This paper is organized as follows. Next section addresses the feasible integration of POS informa</context>
<context>on probabilities : p(T) = nproductdisplay i=1 p(ti|ti−1,ti−2) To deal with data sparseness, the trigram probabilities are estimated by growing a decision tree. 3.3. Brill’s tagger The Brill’s tagger (Brill, 1994) starts with a more simple assumption: each word is first labeled with its most probable POS tag based on the training corpus. This first and raw POS tagging is then corrected with sequencing transfo</context>
</contexts>
<marker>Brill, 1994</marker>
<rawString>E. Brill. 1994. Some advances in rule based part-of-speech tagging. In AAAI, editor, Proceedings of the Twelfth National Conference on Artificial Intelligence, pages 722– 727, Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Curtis Hendrickson</author>
<author>Neil Jacobson</author>
<author>Mike Perkowitz</author>
</authors>
<title>Equations for part-of-speech tagging</title>
<date>1993</date>
<booktitle>In National Conference on Artificial Intelligence</booktitle>
<pages>784--789</pages>
<contexts>
<context>een test set. For this experiment, three state-of-the-art statistical taggers are trained: the Brill’s tagger (Brill, 1994), Treetagger (Schmid, 1994) and a standard Hidden Markov Model (HMM) tagger (Charniak et al., 1993). This paper is organized as follows. Next section addresses the feasible integration of POS information in SMT systems. The section 3. provides an overview of the three tested taggers. The content o</context>
<context>can be completely predicted knowing its previous tag or the bigram transition probabilities. Despite these simplifications, smoothing methods must be used to deal with data sparseness as proposed in (Charniak et al., 1993). Therefore the training process aims to estimate the transition and observation probabilities. Toanswerthedecodingquestion,thebesttagsequence is assigned using the standard Viterbi algorithm. This a</context>
</contexts>
<marker>Charniak, Hendrickson, Jacobson, Perkowitz, 1993</marker>
<rawString>Eugene Charniak, Curtis Hendrickson, Neil Jacobson, and Mike Perkowitz. 1993. Equations for part-of-speech tagging. In National Conference on Artificial Intelligence, pages 784–789.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maxim Khalilov Costa-juss`a</author>
<author>Rafael Banchs</author>
<author>Jos´e B Mari˜no</author>
<author>Jos´e A R Fonollosa</author>
</authors>
<title>N-gram-based smt system enhanced with reordering patterns</title>
<date>2006</date>
<booktitle>In Proceedings on the Workshop on Statistical Machine Translation, pages162–165</booktitle>
<location>New</location>
<marker>Costa-juss`a, Banchs, Mari˜no, Fonollosa, 2006</marker>
<rawString>JosepM.Crego, Adri`adeGispert, PatrikLambert, MartaR. Costa-juss`a, Maxim Khalilov, Rafael Banchs, Jos´e B. Mari˜no, and Jos´e A. R. Fonollosa. 2006. N-gram-based smt system enhanced with reordering patterns. In Proceedings on the Workshop on Statistical Machine Translation, pages162–165, New YorkCity, June.Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Fiscus</author>
</authors>
<title>A post-processing system to yield reduced word error rates: Recogniser output voting error reduction (rover</title>
<date>1997</date>
<contexts>
<context> produced by the systems which participated to the GRACE evaluation. The Rover combination consists in a voting strategy to select the correct annotation among the hypotheses provided by the systems (Fiscus, 1997). A manual correction has been performed only on annotations on which systems did not converge (no majority vote). The MULTITAG corpus size 840k words (30k sentences) is very promising for statis</context>
</contexts>
<marker>Fiscus, 1997</marker>
<rawString>J. Fiscus. 1997. A post-processing system to yield reduced word error rates: Recogniser output voting error reduction (rover).</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Nelson Francis</author>
<author>Henry Kucera</author>
</authors>
<title>Frequency Analysis of English Usage: Lexicon and Grammar</title>
<date>1982</date>
<publisher>Houghton Mifflin Company</publisher>
<contexts>
<context>he training step). This last kind of rules are not used for the following experiments. 4. Corpus For English, two well-known POS tagged corpus are usually used to train POS taggers: the Brown Corpus (Francis and Kucera, 1982) and the Penn Treebank (Marcus et al., 1994). For French, there are no such widely used linguistic resources. 4.1. Corpus description The GRACE French Part-Of-Speech tagging evaluation project (Parou</context>
</contexts>
<marker>Francis, Kucera, 1982</marker>
<rawString>W. Nelson Francis and Henry Kucera. 1982. Frequency Analysis of English Usage: Lexicon and Grammar. Houghton Mifflin Company.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
</authors>
<title>Factored translation models</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL</booktitle>
<pages>868--876</pages>
<contexts>
<context> (public European Parliament Plenary Sessions translation). Further experiments are underway to evaluate a tighter integration of morphosyntactic information in SMT such as the use of factored model (Koehn and Hoang, 2007). Morphosyntactic information has also been successfully introduced in SMT to perform word reordering, as proposed in (Popovic and Ney, 2006) or in (Crego et al., 2006) for the language pair Spanish-</context>
<context>or named entities. This kind of flexibility is not possible with the Treetagger. The next step will be to evaluate the usability of each tagger in a phrase based SMT experiment using factored models (Koehn and Hoang, 2007). Preliminary examples show that, in the case of translating from English to French, the use of a tagset including gender and number is efficient in correcting some translation errors. 7. Acknowledgm</context>
</contexts>
<marker>Koehn, Hoang, 2007</marker>
<rawString>Philipp Koehn and Hieu Hoang. 2007. Factored translation models. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 868–876.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Hinrich Sch¨utze</author>
</authors>
<date>1999</date>
<booktitle>Foundations of Statistical Natural Language Processing. The</booktitle>
<publisher>MIT Press</publisher>
<location>Cambridge, Massachusetts</location>
<marker>Manning, Sch¨utze, 1999</marker>
<rawString>Christopher D. Manning and Hinrich Sch¨utze. 1999. Foundations of Statistical Natural Language Processing. The MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of english: The penn treebank</title>
<date>1994</date>
<journal>Computational Linguistics</journal>
<volume>19</volume>
<contexts>
<context>t used for the following experiments. 4. Corpus For English, two well-known POS tagged corpus are usually used to train POS taggers: the Brown Corpus (Francis and Kucera, 1982) and the Penn Treebank (Marcus et al., 1994). For French, there are no such widely used linguistic resources. 4.1. Corpus description The GRACE French Part-Of-Speech tagging evaluation project (Paroubek et al., 1998) was carried on a 20k word </context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1994</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1994. Building a large annotated corpus of english: The penn treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Paroubek</author>
<author>Josette Lecomte</author>
<author>Gilles Adda</author>
<author>Joseph Mariani</author>
<author>Martin Rajman</author>
</authors>
<title>The grace french part-of-speech tagging evaluation task</title>
<date>1998</date>
<booktitle>In First International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>433--441</pages>
<contexts>
<context>d French Part of Speech (POS) tagger is the French version of the Treetagger (Schmid, 1994) which is freely available on the web1. A version of the Brill’s tagger (Brill, 1994), trained on the GRACE (Paroubek et al., 1998) corpus is also frequently cited2. Both taggers are trained with small tagsets (around 50 tags) which do not include number or gender distinction. Moreover, no confident comparative evaluation of thi</context>
<context> 1982) and the Penn Treebank (Marcus et al., 1994). For French, there are no such widely used linguistic resources. 4.1. Corpus description The GRACE French Part-Of-Speech tagging evaluation project (Paroubek et al., 1998) was carried on a 20k word corpus. Text data were extracted from articles of the French newspaper Le Monde. These texts were manually tagged using 50 different tags. Even if a version of the Brill’s </context>
</contexts>
<marker>Paroubek, Lecomte, Adda, Mariani, Rajman, 1998</marker>
<rawString>Patrick Paroubek, Josette Lecomte, Gilles Adda, Joseph Mariani, and Martin Rajman. 1998. The grace french part-of-speech tagging evaluation task. In First International Conference on Language Resources and Evaluation (LREC), pages 433–441, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Paroubek</author>
</authors>
<title>Language resources as by-product of evaluation: the multitag example</title>
<date>2000</date>
<booktitle>In Second International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>151--154</pages>
<contexts>
<context>LF: http://www.inalf.cnrs.fr/scripts/mep.exe?HTML ¯mep winbrill.txt 3Grace evaluation home page: http://www.limsi.fr/TLP/grace/ for French on a same corpus using the same tagset: the French MULTITAG (Paroubek, 2000) corpus, which is a by-product of the GRACE project. This large corpus (more than 840k words) includes a very large tagset (more than 1500 tags). As one of our goal is to provide a comparative evalua</context>
<context>the investigated application. For example there is no gender or number distinction. The problem seems to be similar for the corpus on which the French version of Treetagger was trained. The MULTITAG (Paroubek, 2000) corpus is a by-product oftheGRACEproject. This1millionwordcorpushasbeen produced by a Rover combination of the data produced by the systems which participated to the GRACE evaluation. The Rover comb</context>
</contexts>
<marker>Paroubek, 2000</marker>
<rawString>Patrick Paroubek. 2000. Language resources as by-product of evaluation: the multitag example. In Second International Conference on Language Resources and Evaluation (LREC) 2000, pages 151–154.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maja Popovic</author>
<author>Hermann Ney</author>
</authors>
<title>Pos-based word reorderings for statistical machine translation</title>
<date>2006</date>
<booktitle>In 5th International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>1278--1283</pages>
<contexts>
<context>ctic information in SMT such as the use of factored model (Koehn and Hoang, 2007). Morphosyntactic information has also been successfully introduced in SMT to perform word reordering, as proposed in (Popovic and Ney, 2006) or in (Crego et al., 2006) for the language pair Spanish-English. Therefore, a preprocessing reordering step is done before training and translation in both source and target language sequences. 3. </context>
</contexts>
<marker>Popovic, Ney, 2006</marker>
<rawString>Maja Popovic and Hermann Ney. 2006. Pos-based word reorderings for statistical machine translation. In 5th International Conference on Language Resources and Evaluation (LREC), pages 1278–1283, May.</rawString>
</citation>
</citationList>
</algorithm>

