The only similar performing tool is the Trigrams `n' Tags tagger (Brants, 2000) which uses a much simpler statistical model.
A00-1031
This set of context vectors is then clustered into a predetermined number of coherent clusters or context groups using Buckshot (Cutting et al.1992), a combination of the EM algorithm and agglomerative clustering.
A92-1018
Brants. 2000.
A00-1031
The semi-supervised model described in Cutting et al.(1992), makes use of both labeled training text and some amount of unlabeled text.
A92-1018
It has been noted that 14% words in the open testing text are unknown with respect to the training set, which is also a little higher compared to the European languages (Dermatas et al., 1995) 3.3 Results We define the tagging accuracy as the ratio of the correctly tagged words to the total number of words.
J95-2001
33. oravecz@nytud.hu Abstract In the world of non-proprietary NLP software the standard, and perhaps the best, HMM-based POS tagger is TnT (Brants, 2000).
A00-1031
Even without a formal survey it is clear that TnT (Brants, 2000) is used widely in research labs throughout the world: Google Scholar shows over 400 citations.
A00-1031
For the most part, these features are clever hacks, and it is unfortunate that neither Brants (2000) nor the standard HMM textbooks mention them, especially as they often yield more significant error reduction than the move from HMM to other architectures.
A00-1031
System using a decision tree based learning algorithm (CN2) has been developed for statistical Hindi POS tagging (Singh et al., 2006).
P06-2100
Stochastic models (Cutting et al., 1992; Dermatas et al., 1995; Brants, 2000) have been widely used in POS tagging for simplicity and language independence of the models.
A00-1031 A92-1018 J95-2001
Furthermore, in order to estimate the relative performance of the models, experiments were carried out with two existing taggers: TnT (Brants, 2000) and ACOPOST 3 . The accuracy achieved using TnT are 87.44% and 87.36% respectively with bigram and trigram model for 40K training data.
A00-1031
Another body of related work is the literature on word clustering in computational linguistics (Brown et al.1992; Finch 1993; Pereira, Tishby, and Lee 1993; Grefenstette 1994a) and document clustering in information retrieval (van Rijsbergen 1979; Willett 1988; Sparck-Jones 1991; Cutting et al.1992). In contrast to this earlier work, we cluster contexts or, equivalently, word tokens here, not words (or, more precisely, word types) or documents.
A92-1018
It has been observed that the corpus ambiguity (mean number of possible tags for each word) in the training text is 1.77 which is much larger compared to the European languages (Dermatas et al., 1995).
J95-2001
In such cases, additional information may be coded into the HMM model to achieve higher accuracy (Cutting et al., 1992).
A92-1018
