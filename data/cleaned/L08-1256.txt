<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>A Santaholma</author>
<author>M Starlander</author>
<author>M Isahara</author>
<author>H Kanzaki</author>
<author>K Nakao</author>
<author>A Y</author>
</authors>
<title>Generic Multi-Lingual Open Source Platform for Limited-Domain Medical Speech Translation, in</title>
<date>2005</date>
<booktitle>Proceedings of the Tenth Conference on European Association of Machine Translation</booktitle>
<pages>30--31</pages>
<location>Budapest, Hungary</location>
<marker>Santaholma, Starlander, Isahara, Kanzaki, Nakao, Y, 2005</marker>
<rawString>A., Santaholma, M., Starlander, M., Isahara, H., Kanzaki, K., Nakao, Y., A (2005). Generic Multi-Lingual Open Source Platform for Limited-Domain Medical Speech Translation, in: Proceedings of the Tenth Conference on European Association of Machine Translation, 30-31, May, Budapest, Hungary, pp. 51-58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Bouillon</author>
<author>S Halimi</author>
<author>M Rayner</author>
<author>B A Hockey</author>
</authors>
<date>2007</date>
<contexts>
<context>us platform (Rayner et al, 2006). Early versions of the system used a single core grammar per language; more recent ones have gone further, and merged together grammars for closely related languages (Bouillon et al, 2007b). These core grammars are automatically specialized, using corpus-driven methods based on small corpora, to derive simpler grammars. Specialization will typically be along all of the following dimen</context>
<context>es it to a TTS engine for realisation in spoken form. In previous work, we have presented initial results for several languages, including Japanese (Rayner et al 2005c; Nakao et al, 2006) and Arabic (Bouillon et al 2007a). The current paper focuses on enhancements recently added to the platform, which aim to simplify the task of developing functionality in these and other non-European languages. In Section 2, we des</context>
</contexts>
<marker>Bouillon, Halimi, Rayner, Hockey, 2007</marker>
<rawString>Bouillon P., Halimi S., Rayner M., Hockey B.A, (2007a).</rawString>
</citation>
<citation valid="true">
<title>Adapting a Medical Speech to Speech Translation System (MedSLT) to Arabic, in</title>
<date>2007</date>
<booktitle>Proceedings of the Workshop on Computational Approaches to Semitic Languages: Common Issues and Resources, ACL</booktitle>
<pages>41--48</pages>
<location>Prague, Czech Republic</location>
<marker>2007</marker>
<rawString>Adapting a Medical Speech to Speech Translation System (MedSLT) to Arabic, in: Proceedings of the Workshop on Computational Approaches to Semitic Languages: Common Issues and Resources, ACL 2007, June 27, Prague, Czech Republic, pp. 41-48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Bouillon</author>
<author>M Rayner</author>
<author>Novellas Vall Br</author>
<author>M Starlander</author>
<author>M Santaholma</author>
<author>Y Nakao</author>
<author>N Chatzichrisafis</author>
</authors>
<title>Une grammaire partagée multi-tâche pour le traitement de la parole : application aux langues romanes, in</title>
<date>2007</date>
<booktitle>TAL (Traitement Automatique des Langues), Volume 47, 3/2006, Hermes &amp; Lavoisier</booktitle>
<contexts>
<context>us platform (Rayner et al, 2006). Early versions of the system used a single core grammar per language; more recent ones have gone further, and merged together grammars for closely related languages (Bouillon et al, 2007b). These core grammars are automatically specialized, using corpus-driven methods based on small corpora, to derive simpler grammars. Specialization will typically be along all of the following dimen</context>
<context>es it to a TTS engine for realisation in spoken form. In previous work, we have presented initial results for several languages, including Japanese (Rayner et al 2005c; Nakao et al, 2006) and Arabic (Bouillon et al 2007a). The current paper focuses on enhancements recently added to the platform, which aim to simplify the task of developing functionality in these and other non-European languages. In Section 2, we des</context>
</contexts>
<marker>Bouillon, Rayner, Br, Starlander, Santaholma, Nakao, Chatzichrisafis, 2007</marker>
<rawString>Bouillon P., Rayner M., Novellas Vall Br., Starlander M., Santaholma M., Nakao Y. and Chatzichrisafis N., (2007b) . Une grammaire partagée multi-tâche pour le traitement de la parole : application aux langues romanes, in: TAL (Traitement Automatique des Langues), Volume 47, 3/2006, Hermes &amp; Lavoisier.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chatzichrisafis</author>
<author>P Bouillon</author>
<author>M Rayner</author>
<author>M Santaholma</author>
<author>M Starlander</author>
<author>B A Hockey</author>
</authors>
<title>Evaluating Task Performance for a Unidirectional Controlled Language Medical Speech Translation System, in</title>
<date>2006</date>
<booktitle>Proceedings of the First International Workshop on Medical Speech Translation, HLT-NAACL</booktitle>
<location>New York</location>
<contexts>
<context>nition using a backup statistical recognizer, and uses the result to select examples from the library which are similar to the statistical recognizer's result in terms of a backed-off N-gram metric. (Chatzichrisafis et al, 2006) describes an experiment in which medical students with no previous exposure to MedSLT used it to perform a diagnosis task on simulated patients, acquiring all their knowledge of grammar coverage fro</context>
<context>nt in performance resulting from interlingua-based N-best rescoring, we ran recorded and transcribed speech data for three langages through offline versions of the system, using the French data from (Chatzichrisafis et al 2006), the English data from (Rayner et al 2005b) and the Japanese data from (Rayner et al 2005c). In each case, we judged examples by hand to determine which ones produced correct interlingua representat</context>
</contexts>
<marker>Chatzichrisafis, Bouillon, Rayner, Santaholma, Starlander, Hockey, 2006</marker>
<rawString>Chatzichrisafis, N., Bouillon, P., Rayner, M., Santaholma, M., Starlander, M. and Hockey, B.A., (2006). Evaluating Task Performance for a Unidirectional Controlled Language Medical Speech Translation System, in: Proceedings of the First International Workshop on Medical Speech Translation, HLT-NAACL, June 9, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Nakao</author>
<author>M Rayner</author>
<author>N Chatzichrisafis</author>
<author>K Kanzaki</author>
<author>P Bouillon</author>
<author>B A Hockey</author>
<author>H Isahara</author>
</authors>
<date>2006</date>
<pages>.</pages>
<contexts>
<context>l'arrière de la tête?&amp;quot; and passes it to a TTS engine for realisation in spoken form. In previous work, we have presented initial results for several languages, including Japanese (Rayner et al 2005c; Nakao et al, 2006) and Arabic (Bouillon et al 2007a). The current paper focuses on enhancements recently added to the platform, which aim to simplify the task of developing functionality in these and other non-Europea</context>
</contexts>
<marker>Nakao, Rayner, Chatzichrisafis, Kanzaki, Bouillon, Hockey, Isahara, 2006</marker>
<rawString>Nakao, Y., Rayner, M., Chatzichrisafis, N., Kanzaki, K., Bouillon, P., Hockey, B.A. and Isahara, H., (2006) .</rawString>
</citation>
<citation valid="true">
<title>Making MedSLT Easier to Use: Back-Translation and the Help System, in</title>
<date>2006</date>
<booktitle>Proceedings of NLP</booktitle>
<pages>16</pages>
<location>Yokohama, Japan</location>
<note>in Japanese</note>
<marker>2006</marker>
<rawString>Making MedSLT Easier to Use: Back-Translation and the Help System, in: Proceedings of NLP 2006, 16, March, 2006, Yokohama, Japan (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
<author>P Bouillon</author>
<author>M Santaholma</author>
<author>Y Nakao</author>
</authors>
<title>Representational and architectural issues in a limited-domain medical speech translator, in</title>
<date>2005</date>
<booktitle>Proceedings of TALN/RECITAL</booktitle>
<pages>6--10</pages>
<location>Dourdan, France</location>
<contexts>
<context>rm &amp;quot;avez-vous mal à l'arrière de la tête?&amp;quot; and passes it to a TTS engine for realisation in spoken form. In previous work, we have presented initial results for several languages, including Japanese (Rayner et al 2005c; Nakao et al, 2006) and Arabic (Bouillon et al 2007a). The current paper focuses on enhancements recently added to the platform, which aim to simplify the task of developing functionality in these a</context>
<context>-best rescoring, we ran recorded and transcribed speech data for three langages through offline versions of the system, using the French data from (Chatzichrisafis et al 2006), the English data from (Rayner et al 2005b) and the Japanese data from (Rayner et al 2005c). In each case, we judged examples by hand to determine which ones produced correct interlingua representations. Table 2 presents the results. As usua</context>
</contexts>
<marker>Rayner, Bouillon, Santaholma, Nakao, 2005</marker>
<rawString>Rayner, M., Bouillon, P., Santaholma, M. and Nakao, Y., (2005a). Representational and architectural issues in a limited-domain medical speech translator, in: Proceedings of TALN/RECITAL, 6-10, June, Dourdan, France, pp.163-172.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
<author>P Bouillon</author>
<author>N Chatzichrisafis</author>
<author>B A Hockey</author>
<author>M Santaholma</author>
<author>M Starlander</author>
<author>H Isahara</author>
<author>K Kanzaki</author>
<author>Y Nakao</author>
</authors>
<title>A Methodology for Comparing Grammar-Based and Robust Approaches to Speech Understanding, in</title>
<date>2005</date>
<booktitle>Proceedings of the 9th International Conference on Spoken Language Processing (ICSLP</booktitle>
<pages>1103--1107</pages>
<location>Lisboa, Portugal</location>
<contexts>
<context>rm &amp;quot;avez-vous mal à l'arrière de la tête?&amp;quot; and passes it to a TTS engine for realisation in spoken form. In previous work, we have presented initial results for several languages, including Japanese (Rayner et al 2005c; Nakao et al, 2006) and Arabic (Bouillon et al 2007a). The current paper focuses on enhancements recently added to the platform, which aim to simplify the task of developing functionality in these a</context>
<context>-best rescoring, we ran recorded and transcribed speech data for three langages through offline versions of the system, using the French data from (Chatzichrisafis et al 2006), the English data from (Rayner et al 2005b) and the Japanese data from (Rayner et al 2005c). In each case, we judged examples by hand to determine which ones produced correct interlingua representations. Table 2 presents the results. As usua</context>
</contexts>
<marker>Rayner, Bouillon, Chatzichrisafis, Hockey, Santaholma, Starlander, Isahara, Kanzaki, Nakao, 2005</marker>
<rawString>Rayner, M., Bouillon, P., Chatzichrisafis, N., Hockey, B.A., Santaholma, M., Starlander, M., Isahara, H., Kanzaki, K. and Nakao, Y. (2005b) A Methodology for Comparing Grammar-Based and Robust Approaches to Speech Understanding, in: Proceedings of the 9th International Conference on Spoken Language Processing (ICSLP), Lisboa, Portugal, pp. 1103-1107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
<author>N Chatzichrisafis</author>
<author>P Bouillon</author>
<author>Y Isahara Nakao</author>
<author>H Kanzaki</author>
<author>K Hockey</author>
<author>B A Santaholma</author>
<author>M</author>
<author>M Starlander</author>
</authors>
<title>Japanese Speech Understanding Using Grammar Specialization, in</title>
<date>2005</date>
<booktitle>Proceedings of HLT-EMNLP</booktitle>
<pages>6--8</pages>
<location>Vancouver, British Columbia</location>
<contexts>
<context>rm &amp;quot;avez-vous mal à l'arrière de la tête?&amp;quot; and passes it to a TTS engine for realisation in spoken form. In previous work, we have presented initial results for several languages, including Japanese (Rayner et al 2005c; Nakao et al, 2006) and Arabic (Bouillon et al 2007a). The current paper focuses on enhancements recently added to the platform, which aim to simplify the task of developing functionality in these a</context>
<context>-best rescoring, we ran recorded and transcribed speech data for three langages through offline versions of the system, using the French data from (Chatzichrisafis et al 2006), the English data from (Rayner et al 2005b) and the Japanese data from (Rayner et al 2005c). In each case, we judged examples by hand to determine which ones produced correct interlingua representations. Table 2 presents the results. As usua</context>
</contexts>
<marker>Rayner, Chatzichrisafis, Bouillon, Nakao, Kanzaki, Hockey, Santaholma, M, Starlander, 2005</marker>
<rawString>Rayner, M., Chatzichrisafis, N., Bouillon, P., Nakao, Y. Isahara, H., Kanzaki, K., Hockey, B.A., Santaholma, M. and Starlander, M. (2005c). Japanese Speech Understanding Using Grammar Specialization, in: Proceedings of HLT-EMNLP, 6-8, October, Vancouver, British Columbia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
<author>B A Hockey</author>
<author>P Bouillon</author>
</authors>
<title>Putting Linguistics into Speech Recognition</title>
<date>2006</date>
<location>CSLI, Stanford</location>
<contexts>
<context>is that all grammars used (for recognition, analysis and generation) are compiled from a small number of general linguistically motivated unification grammars, using the Open Source Regulus platform (Rayner et al, 2006). Early versions of the system used a single core grammar per language; more recent ones have gone further, and merged together grammars for closely related languages (Bouillon et al, 2007b). These c</context>
<context>ssociated with a simple artificial syntax. We also stress that the grammars used to define the source and target languages are not semantic grammars. For example, the general English Regulus grammar (Rayner et al 2006, Chapter 8) is a complex, linguistically motivated feature grammar, whose non-terminals and features represent standard linguistic concepts such as S, NP, agreement, gapping and so on. A typical rule</context>
</contexts>
<marker>Rayner, Hockey, Bouillon, 2006</marker>
<rawString>Rayner, M., Hockey, B.A. and Bouillon, P., (2006) . Putting Linguistics into Speech Recognition, CSLI, Stanford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Starlander</author>
<author>P Bouillon</author>
<author>N Chatzichrisafis</author>
<author>M Santaholma</author>
<author>M Rayner</author>
<author>B A Hockey</author>
<author>H Isahara</author>
<author>K Kanzaki</author>
<author>Y Nakao</author>
</authors>
<title>Practising Controlled Language through a Help System integrated into the Medical Speech Translation System (MedSLT), in</title>
<date>2005</date>
<booktitle>Proceedings of the MT Summit X</booktitle>
<pages>12--16</pages>
<location>Phuket, Thailand</location>
<contexts>
<context>n in-grammar coverage, a well-known problem is brittleness: users need to know what language the grammar supports. Our approach to this problem is to equip the system with an intelligent help module (Starlander et al, 2005) which after each utterance provides the user with in-coverage examples, chosen to be as close to the user's actual utterance as possible. The help module's output is based on a library of utterances</context>
</contexts>
<marker>Starlander, Bouillon, Chatzichrisafis, Santaholma, Rayner, Hockey, Isahara, Kanzaki, Nakao, 2005</marker>
<rawString>Starlander, M., Bouillon, P., Chatzichrisafis, N., Santaholma, M., Rayner, M., Hockey, B.A., Isahara, H., Kanzaki, K and Nakao, Y., (2005). Practising Controlled Language through a Help System integrated into the Medical Speech Translation System (MedSLT), in: Proceedings of the MT Summit X, 12-16 September, Phuket, Thailand.</rawString>
</citation>
</citationList>
</algorithm>

