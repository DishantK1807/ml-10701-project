Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 835–845,
Portland, Oregon, June 19-24, 2011. c©2011 Association for Computational Linguistics
Binarized Forest to String Translation
Hao Zhang
Google Research
haozhang@google.com
Licheng Fang
Computer Science Department
University of Rochester
lfang@cs.rochester.edu
Peng Xu
Google Research
xp@google.com
Xiaoyun Wu
Google Research
xiaoyunwu@google.com
Abstract
Tree-to-string translation is syntax-aware and
efficientbutsensitivetoparsingerrors. Forest-
to-string translation approaches mitigate the
risk of propagating parser errors into transla-
tion errors by considering a forest of alterna-
tive trees, as generated by a source language
parser. We propose an alternative approach to
generating forests that is based on combining
sub-trees within the first best parse through
binarization. Provably, our binarization for-
est can cover any non-consitituent phrases in
a sentence but maintains the desirable prop-
erty that for each span there is at most one
nonterminal so that the grammar constant for
decoding is relatively small. For the purpose
of reducing search errors, we apply the syn-
chronous binarization technique to forest-to-
string decoding. Combining the two tech-
niques, we show that using a fast shift-reduce
parser we can achieve significant quality gains
in NIST 2008 English-to-Chinese track (1.3
BLEU points over a phrase-based system, 0.8
BLEU points over a hierarchical phrase-based
system). Consistent and significant gains are
also shown in WMT 2010 in the English to
German, French, Spanish and Czech tracks.
1 Introduction
In recent years, researchers have explored a wide
spectrum of approaches to incorporate syntax and
structure into machine translation models. The uni-
fying framework for these models is synchronous
grammars (Chiang, 2005) or tree transducers
(Graehl and Knight, 2004). Depending on whether
or not monolingual parsing is carried out on the
source side or the target side for inference, there are
four general categories within the framework:
• string-to-string (Chiang, 2005; Zollmann and
Venugopal, 2006)
• string-to-tree (Galley et al., 2006; Shen et al.,
2008)
• tree-to-string (Lin, 2004; Quirk et al., 2005;
Liu et al., 2006; Huang et al., 2006; Mi et al.,
2008)
• tree-to-tree (Eisner, 2003; Zhang et al., 2008)
In terms of search, the string-to-xmodels exploreall
possible source parses and map them to the target
side, while the tree-to-x models search over the sub-
space of structures of the source side constrained
by an input tree or trees. Hence, tree-to-x mod-
els are more constrained but more efficient. Mod-
els such as Huang et al. (2006) can match multi-
level tree fragments on the source side which means
larger contexts are taken into account for transla-
tion (Poutsma, 2000), which is a modeling advan-
tage. To balance efficiency and accuracy, forest-to-
string models (Mi et al., 2008; Mi and Huang, 2008)
use a compact representation of exponentially many
trees to improve tree-to-string models. Tradition-
ally, such forests are obtained through hyper-edge
pruning in the k-best search space of a monolin-
gual parser (Huang, 2008). The pruning parameters
that control the size of forests are normally hand-
tuned. Such forests encode both syntactic variants
and structural variants. By syntactic variants, we re-
fer to the fact that a parser can parse a substring into
either a noun phrase or verb phrase in certain cases.
835
We believe that structuralvariants which allow more
source spans to be explored during translation are
more important (DeNeefe et al., 2007), while syn-
tactic variants might improve word sense disam-
biguation but also introduce more spurious ambi-
guities (Chiang, 2005) during decoding. To focus
on structural variants, we propose a family of bina-
rization algorithms to expand one single constituent
tree into a packed forest of binary trees containing
combinations of adjacent tree nodes. We control the
freedomof tree node binary combinationby restrict-
ing the distance to the lowest common ancestor of
two tree nodes. We show that the best results are
achieved when the distance is two, i.e., when com-
bining tree nodes sharing a common grand-parent.
In contrast to conventional parser-produced-forest-
to-string models, in our model:
• Forests are not generated by a parser but by
combiningsub-structuresusinga treebinarizer.
• Instead of using arbitary pruning parameters,
we controlforestsizeby an integernumber that
defines the degree of tree structure violation.
• There is at most one nonterminal per span so
that the grammar constant is small.
Since GHKM rules (Galley et al., 2004) can cover
multi-level tree fragments, a synchronous grammar
extracted using the GHKM algorithm can have syn-
chronous translation rules with more than two non-
terminals regardless of the branching factor of the
source trees. For the first time, we show that simi-
lar to string-to-tree decoding, synchronous binariza-
tionsignificantlyreducessearcherrorsandimproves
translation quality for forest-to-string decoding.
To summarize, the whole pipeline is as follows.
First, a parser produces the highest-scored tree for
an input sentence. Second, the parse tree is re-
structured using our binarization algorithm, result-
ing in a binary packed forest. Third, we apply the
forest-based variant of the GHKM algorithm (Mi
and Huang, 2008) on the new forest for rule extrac-
tion. Fourth, on the translation forest generated by
all applicable translation rules, which is not neces-
sarily binary, we apply the synchronous binarization
algorithm (Zhang et al., 2006) to generate a binary
translation forest. Finally, we use a bottom-up de-
coding algorithm with intergrated LM intersection
using the cube pruning technique (Chiang, 2005).
The rest of the paper is organized as follows. In
Section 2, we give an overview of the forest-to-
string models. In Section 2.1, we introduce a more
efficient and flexible algorithm for extracting com-
posed GHKM rules based on the same principle as
cube pruning (Chiang, 2007). In Section 3, we in-
troduce our source tree binarization algorithm for
producing binarized forests. In Section 4, we ex-
plain how to do synchronous rule factorization in a
forest-to-string decoder. Experimental results are in
Section 5.
2 Forest-to-string Translation
Forest-to-string models can be described as
e = Y( argmax
dnullD(T), TnullF(f)
P(d|T) ) (1)
where f stands for a source string, e stands for a tar-
get string, F stands for a forest, D stands for a set
of synchronous derivations on a given tree T, and
Y stands for the target side yield of a derivation.
The search problem is finding the derivation with
the highest probability in the space of all deriva-
tions for all parse trees for an input sentence. The
log probability of a derivation is normally a lin-
ear combination of local features which enables dy-
namic programming to find the optimal combination
efficiently. In this paper, we focus on the models
based on the Synchronous Tree Substitution Gram-
mars(STSG)definedbyGalleyetal.(2004). Incon-
trast to a tree-to-string model, the introduction of F
augments the search space systematically. When the
first-best parse is wrong or no good translation rules
are applicable to the first-best parse, the model can
recover good translations from alternative parses.
In STSG, local features are defined on tree-to-
string rules, which are synchronous grammar rules
defining how a sequence of terminals and nontermi-
nals on the source side translates to a sequence of
target terminals and nonterminals. One-to-one map-
ping of nonterminals is assumed. But terminals do
not necessarily need to be aligned. Figure 1 shows a
typical English-Chinese tree-to-stringrule with a re-
ordering pattern consisting of two nonterminals and
different numbers of terminals on the two sides.
836
VP
VBD
was
VP-C
.x1:VBN PP
P
by
.x2:NP-C
→ beinull x2 x1
Figure 1: An example tree-to-string rule.
Forest-to-string translation has two stages. The
first stage is rule extraction on word-aligned parallel
texts with source forests. The second stage is rule
enumeration and DP decoding on forests of input
strings. In both stages, at each tree node, the task on
the source side is to generate a list of tree fragments
by composing the tree fragments of its children. We
propose a cube-pruning style algorithm that is suit-
able for both rule extraction during training and rule
enumeration during decoding.
At the highest level, our algorithm involves three
steps. In the first step, we label each node in the in-
putforestby abooleanvariableindicatingwhetherit
is a site of interest for tree fragment generation. If it
is marked true, it is an admissible node. In the case
of rule extraction, a node is admissible if and only if
it corresponds to a phrase pair according to the un-
derlying word alignment. In the case of decoding,
every node is admissible for the sake of complete-
ness of search. An initial one-node tree fragment is
placed at each admissible node for seeding the tree
fragment generation process. In the second step,
we do cube-pruning style bottom-up combinations
to enumerate a pruned list of tree fragments at each
tree node. In the third step, we extract or enumerate-
and-match tree-to-string rules for the tree fragments
at the admissible nodes.
2.1 A
Cube-pruning-inspired Algorithm for
Tree Fragment Composition
Galley et al. (2004) defined minimal tree-to-string
rules. Galley et al. (2006) showed that tree-to-string
rules made by composing smaller ones are impor-
tant to translation. It can be understood by the anal-
ogy of going from word-based models to phrase-
based models. We relate composed rule extraction
to cube-pruning (Chiang, 2007). In cube-pruning,
the process is to keep track of the k-best sorted lan-
guage model states at each node and combine them
bottom-up with the help of a priority queue. We
can imagine substituting k-best LM states with k
composed rules at each node and composing them
bottom-up. We can also borrow the cube pruning
trick to compose multiple lists of rules using a pri-
ority queue to lazily explore the space of combina-
tions starting from the top-most element in the cube
formed by the lists.
We need to define a ranking function for com-
posed rules. To simulate the breadth-first expansion
heuristics of Galley et al. (2006), we define the fig-
ure of merit of a tree-to-string rule as a tuple m =
(h,s,t), where h is the height of a tree fragment,
s is the number of frontier nodes, i.e., bottom-level
nodes including both terminals and non-terminals,
and t is the number of terminals in the set of frontier
nodes. We define an additive operator +:
m1 + m2
= ( max{h1,h2}+1, s1 + s2, t1 + t2 )
and a min operator based on the order <:
m1 < m2 ⇐⇒



h1 < h2 ∨
h1 = h2 ∧ s1 < s2 ∨
h1 = h2 ∧ s1 = s2 ∧ t1 < t2
The + operator corresponds to rule compositions.
The< operatorcorrespondstorankingrulesby their
sizes. A concrete example is shown in Figure 2,
in which case the monotonicity property of (+,<)
holds: if ma < mb, ma+mc < mb+mc. However,
thisisnottrueingeneralfortheoperatorsinourdef-
inition, which implies that our algorithm is indeed
like cube-pruning: an approximate k-shortest-path
algorithm.
3 Source
Tree Binarization
The motivation of tree binarization is to factorize
large and rare structures into smaller but frequent
ones to improve generalization. For example, Penn
Treebank annotations are often flat at the phrase
level. Translationrulesinvolvingflatphrasesare un-
likely to generalize. If long sequences are binarized,
837







VBD (1,1,0)
VBD
was
(2,1,1)







×



















VP-C (1,1,0)
VP-C
VPB PP
(2,2,0)
VP-C
VPB PP
P NP-C
(3,3,1)



















=
(1,1,0) (2,2,0) (3,3,1)
(1,1,0) VP
VBD VP-C
(2,2,0) VP
VBD VP-C
VPB PP
(3,3,0) VP
VBD VP-C
VPB PP
P NP-C
(4,4,1)
(2,1,1) VP
VBD
was
VP-C
(3,2,1) VP
VBD
was
VP-C
VPB PP
(3,3,1) VP
VBD
was
VP-C
VPB PP
P NP-C
(4,4,2)
Figure 2: Tree-to-string rule composition as cube-pruning. The left shows two lists of composed rules sorted by their
geometric measures (height,# frontiers,# frontier terminals), under the gluing rule of VP → VBD VP−C.
The right part shows a cube view of the combination space. We explore the space from the top-left corner to the
neighbors.
the commonality of subsequences can be discov-
ered. For example, the simplest binarization meth-
ods left-to-right, right-to-left, and head-out explore
sharingofprefixesorsuffixes. Amongexponentially
many binarization choices, these algorithms pick a
single bracketing structure for a sequence of sibling
nodes. To explore all possible binarizations, we use
a CYK algorithm to produce a packed forest of bi-
nary trees for a given sibling sequence.
With CYK binarization, we can explore any span
that is nested within the original tree structure, but
still miss all cross-bracket spans. For example,
translating from English to Chinese, The phrase
“There is” should often be translated into one verb
in Chinese. In a correct English parse tree, however,
the subject-verb boundary is between “There” and
“is”. As a result, tree-to-string translation based on
constituent phrases misses the good translation rule.
The CYK-n binarization algorithm shown in Al-
gorithm 1 is a parameterization of the basic CYK
binarization algorithm we just outlined. The idea is
that binarization can go beyond the scope of parent
nodes to more distant ancestors. The CYK-n algo-
rithm first annotates each node with its n nearest
ancestors in the source tree, then generates a bina-
rization forest that allows combining any two nodes
with common ancestors. The ancestor chain labeled
at each node licenses the node to only combine with
nodes having common ancestors in the past n gener-
ations.
The algorithm creates new tree nodes on the fly.
New tree nodes need to have their own states in-
dicated by a node label representing what is cov-
ered internally by the node and an ancestor chain
representing which nodes the node attaches to ex-
ternally. Line 22 and Line 23 of Algorithm 1 up-
date the label and ancestor annotations of new tree
nodes. Using the parsing semiring notations (Good-
man, 1999), the ancestor computation can be sum-
marized by the (∩,∪) pair. ∩ produces the ances-
tor chain of a hyper-edge. ∪ produces the ancestor
chain of a hyper-node. The node label computation
can be summarized by the (concatenate,min) pair.
concatenate produces a concatenation of node la-
bels. min yields the label with the shortest length.
A tree-sequence (Liu et al., 2007) is a sequence of
sub-trees covering adjacent spans. It can be proved
that the final label of each new node in the forest
corresponds to the tree sequence which has the min-
imum length among all sequences covered by the
node span. The ancestor chain of a new node is the
common ancestors of the nodes in its minimum tree
sequence.
Forclarity,wedofullCYKloopsoverallO(|w|2)
spans and O(|w|3) potential hyper-edges, where |w|
is the length of a source string. In reality, only de-
scendants under a shared ancestor can combine. If
we assume trees have a bounded branching factor
b, the number of descendants after n generations is
still bounded by a constant c = bn. The algorithm is
O(c3 ·|w|), which is still linear to the size of input
sentence when the parameter n is a constant.
838
VP
VBD+VBN
VBD
was
VBN
PP
P
by
NP-C
VP
VBD
was
VP-C
VBN+P
VBN P
by
NP-C
(a) (b)
VP
VBD+VBN+P
VBD+VBN
VBD
was
VBN
P
by
NP-C
VP
VBD+VBN+P
VBD
was
VBN+P
VBN P
by
NP-C
(c) (d)
1 2 3 4
0 VBD
VBD+VBN VBD+VBN+P VP
1 VBN
VBN+P VP-C
2 P
PP
3 NP-C
Figure 3: Alternative binary parses created for the origi-
nal tree fragment in Figure 1 through CYK-2binarization
(a and b) and CYK-3 binarization (c and d). In the chart
representation at the bottom, cells with labels containing
the concatenation symbol + hold nodes created through
binarization.
Figure3showssomeexamplesofalternativetrees
generatedby the CYK-n algorithm. In this example,
standard CYK binarization will not create any new
trees since the input is already binary. The CYK-2
and CYK-3 algorithms discover new trees with an
increasing degree of freedom.
4 Synchronous
Binarization for
Forest-to-string Decoding
In this section, we deal with binarization of transla-
tion forests, also known as translation hypergraphs
(Mi et al., 2008). A translation forest is a packed
forest representation of all synchronous derivations
composed of tree-to-string rules that match the
source forest. Tree-to-string decoding algorithms
work on a translationforest, rather than a source for-
est. A binary source forest does not necessarily al-
ways result in a binary translation forest. In the tree-
to-string rule in Figure 4, the source tree is already
ADJP
RB+JJ
x0:RB JJ
responsible
PP
IN
for
NP-C
NPB
DT
the
x1:NN
x2:PP
→ x0 fuzenullnull x2 denull x1
ADJP
RB+JJ
x0:RB JJ
responsible
x1:PP
→ x0 fuzenullnull x1
PP
IN
for
NP-C
NPB
DT
the
x0:NN
x1:PP
→ x1 denull x0
Figure 4: Synchronous binarization for a tree-to-string
rule. The top rule can be binarized into two smaller rules.
binary with the help of source tree binarization, but
the translationrule involves three variables in the set
of frontier nodes. If we apply synchronous binariza-
tion (Zhang et al., 2006), we can factorize it into
two smaller translation rules each having two vari-
ables. Obviously, the second rule, which is a com-
mon pattern, is likely to be shared by many transla-
tion rules in the derivation forest. When beams are
fixed, search goes deeper in a factorized translation
forest.
The challenge of synchronous binarization for a
forest-to-string system is that we need to first match
large tree fragments in the input forest as the first
step of decoding. Our solution is to do the matching
using the original rules and then run synchronous
binarization to break matching rules down to factor
rules which can be shared in the derivation forest.
Thisisdifferentfromtheofflinebinarizationscheme
described in (Zhang et al., 2006), although the core
algorithm stays the same.
5 Experiments
We ran experiments on public data sets for English
to Chinese, Czech, French, German, and Spanish
839

