In general lines, this model corresponds to models such as (Fulie and Matsumoto, 1998; Haruno et al., 1998; Uchimoto et al., 1999).
E99-1026 P98-1083
Approaches with a grmnnmr There have been nlally l)rOl)osals tbr statistical t'rameworks particularly designed tbr 1)arsers with hand-crafted grmnmars (Schal)es, 1992; Briscoe and Carroll, 1993; Abney, 1996; Inui et al., 1!)97).
J93-1002
P(i -~ c,d dJ P(n I ¢,~, %.,, %~) (.n = 1,2)(8) P(~ -~ c,~),,~r p(,~ I ¢'i, %,,,I,~,,I%) (,n = 1, 2,/)(9) 2This heuristics is a Japanese version of a left-association rule: see (Mitsuishi et M., 1998) for detail.
P98-2144
This idea is sinfilar to that of Sekine (2000)'s study, which restricts the candidates to five, i)ut in his case, without a granmmr.
C00-2110
: Japanese Grammar The Japanese grammar which we adopted, SLUNG (Mitsuishi et al., 1998), is an HPSG-based underspecified grammar.
P98-2144
There are some models which calculate the likelihood values of a dependency between bunsetsu i and j as in (6), such as a decision tree model (Haruno et al., 1998), a maximum entropy model (Uchimoto et al., 1999), a model based on distance and lexical information (Pujio and Matsumoto, 1998).
E99-1026 P98-1083
We report that our parsing framework achieved high accuracy (88.6%) in dependency analysis of Japanese with a combination of an underspecified HPSG-based Japanese grammar, SLUNG (Mitsuishi et al., 1998) and the maximum entropy method (Berger et al., 1996).
J96-1002 P98-2144
There have been many attempts to combine handcrafted high-level gramnmrs, such as FB-UfAG, HPSG and LFG, and statistical disambiguation techniques to ol)tain precise linguistic struc, tures (Schabes, 1992; Almey, 1996; Carroll el, al., 1998).
C92-2066 W98-1114
The decision tree model (Haruno et al., 1998) achieves around 85%, the integrated model of lexical/syntactic information (Slfirai et al., 1998) achieves around 86%, and the lexicalized statistical model (Ft0io and Matsumoto, 1999) achieves 86.8% in bunsets'u accuracy.
P98-1083
