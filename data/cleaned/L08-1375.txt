<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>C Barras</author>
<author>E Geoffrois</author>
<author>Z Wu</author>
<author>M Liberman</author>
</authors>
<title>Transcriber: a free tool for segmenting, labeling and transcribing speech</title>
<date>1998</date>
<booktitle>In Proceedings of the First International Conference on Language Resources and Evaluation (LREC</booktitle>
<location>Arcueil, France, and Philadelphia, USA</location>
<contexts>
<context> words as well as several sentences. The corpus is made up of 1,633 speech turns which last from 1 second to 1 minute and 21 seconds. Scripts are checked and annotated using the software Transcriber (Barras et al., 1998). The words which deviate from a correct pronunciation and the spelt acronyms are rewritten by taking account of what the speaker said. Deep breathings and long pauses (more than 1 second) are annota</context>
</contexts>
<marker>Barras, Geoffrois, Wu, Liberman, 1998</marker>
<rawString>Barras, C., E. Geoffrois, Z. Wu, and M. Liberman, 1998. Transcriber: a free tool for segmenting, labeling and transcribing speech. In Proceedings of the First International Conference on Language Resources and Evaluation (LREC). Arcueil, France, and Philadelphia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Bechet</author>
</authors>
<title>Liaphon un systeme complet de phonetisation de textes. Traitement Automatique des Langues (T.A.L.) edition Hermes</title>
<date>2001</date>
<volume>42</volume>
<contexts>
<context>on the HTK tool (Young et al., 2002). 3.1. Grapheme/Phoneme conversion An automatic phonemic transcription using a set of 36 phonemes of the French language is carried out with the software Lia phon (Bechet, 2001) which performs a rulesbased grapheme-phoneme conversion. Only a few proper names and foreign words are manually transcribed in a small dictionnary (around 600 words). From the Lia phon outputs, the </context>
</contexts>
<marker>Bechet, 2001</marker>
<rawString>Bechet, F., 2001. Liaphon un systeme complet de phonetisation de textes. Traitement Automatique des Langues (T.A.L.) edition Hermes, 42(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Boeffard</author>
<author>L Miclet</author>
<author>S White</author>
</authors>
<title>Automatic generation of optimal unit dictionaries for text-to-speech synthesis</title>
<date>1992</date>
<booktitle>In proceedings of the 2nd International Conference on Spoken Language Processing (ICSLP’92</booktitle>
<location>Banff, Alberta, Canada</location>
<contexts>
<context>on the language, moreover it requires great skill in acoustic phonetics. Many researchers were interested in automating the segmentation process. The most effective approaches consider HMM modelling (Boeffard et al., 1992) (Ljolje and Riley, 1993) (Brugnara et al., 1993), and a post-processing stage can possibly be defined (Zhao et al., 2005). Concerning the HMM, many studies were interested in optimising modelling an</context>
</contexts>
<marker>Boeffard, Miclet, White, 1992</marker>
<rawString>Boeffard, O., L. Miclet, and S. White, 1992. Automatic generation of optimal unit dictionaries for text-to-speech synthesis. In proceedings of the 2nd International Conference on Spoken Language Processing (ICSLP’92). Banff, Alberta, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Brugnara</author>
<author>D Falavigna</author>
<author>M Omologos</author>
</authors>
<title>Automatic segmentation and labeling of speech based on hidden markov models</title>
<date>1993</date>
<journal>Speech Communication</journal>
<volume>12</volume>
<pages>370</pages>
<contexts>
<context> in acoustic phonetics. Many researchers were interested in automating the segmentation process. The most effective approaches consider HMM modelling (Boeffard et al., 1992) (Ljolje and Riley, 1993) (Brugnara et al., 1993), and a post-processing stage can possibly be defined (Zhao et al., 2005). Concerning the HMM, many studies were interested in optimising modelling and training parameters. Furthermore, many studies </context>
</contexts>
<marker>Brugnara, Falavigna, Omologos, 1993</marker>
<rawString>Brugnara, F., D. Falavigna, and M. Omologos, 1993. Automatic segmentation and labeling of speech based on hidden markov models. Speech Communication, 12:357– 370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kawai</author>
<author>T Toda</author>
</authors>
<title>An evaluation of automatic phone segmentation for concatenative speech synthesis</title>
<date>2004</date>
<contexts>
<context>orpora. In the case of a text-to-speech synthesis system based on concatenation of non uniform acoustic units, a speech corpus of about 10 hours is required to obtain a good synthetic speech quality (Kawai and Toda, 2004). These corpora are annotated by a set of phonetic and phonological tags synchronised with the acoustic signal (Torre Toledano et al., 2003). The quality of the produced synthetic signal relies stron</context>
</contexts>
<marker>Kawai, Toda, 2004</marker>
<rawString>Kawai, H. and T. Toda, 2004. An evaluation of automatic phone segmentation for concatenative speech synthesis.</rawString>
</citation>
<citation valid="false">
<booktitle>In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing 2004 (ICASSP apos;04</booktitle>
<location>Montr´eal, Qu´ebec, Canada</location>
<marker></marker>
<rawString>In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing 2004 (ICASSP apos;04). Montr´eal, Qu´ebec, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ljolje</author>
<author>M D Riley</author>
</authors>
<title>Automatic segmentation of speech for tts</title>
<date>1993</date>
<booktitle>In proceedings of the third European Conference on Speech Communication and Technology (EUROSPEECH’93</booktitle>
<location>Berlin, Germany</location>
<contexts>
<context>r it requires great skill in acoustic phonetics. Many researchers were interested in automating the segmentation process. The most effective approaches consider HMM modelling (Boeffard et al., 1992) (Ljolje and Riley, 1993) (Brugnara et al., 1993), and a post-processing stage can possibly be defined (Zhao et al., 2005). Concerning the HMM, many studies were interested in optimising modelling and training parameters. Fu</context>
</contexts>
<marker>Ljolje, Riley, 1993</marker>
<rawString>Ljolje, A. and M.D. Riley, 1993. Automatic segmentation of speech for tts. In proceedings of the third European Conference on Speech Communication and Technology (EUROSPEECH’93). Berlin, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S S Park</author>
<author>N S Kim</author>
</authors>
<title>On using multiple models for automatic speech segmentation. Audio, Speech and Language Processing</title>
<date>2007</date>
<journal>IEEE Transactions on</journal>
<pages>15--8</pages>
<contexts>
<context>g strategies. We decided not to focus here on the various strategies of HMM initialisation (flat initialisation, initialising from speaker independent models or from a manually segmented sub corpus) (Park and Kim, 2007). We have considered the optimal case, which consists in initialising the models by a subset of manually segmented sentences. The various comparisons between context dependent, context independent an</context>
</contexts>
<marker>Park, Kim, 2007</marker>
<rawString>Park, S.S. and N.S. Kim, 2007. On using multiple models for automatic speech segmentation. Audio, Speech and Language Processing, IEEE Transactions on, 15(8):2202–2212.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Torre Toledano</author>
<author>A Hernandez Gomez D</author>
<author>L Villarrubia Grande</author>
</authors>
<title>Automatic phonetic segmentation</title>
<date>2003</date>
<journal>IEEE Transactions on Speech and Audio Processing</journal>
<volume>11</volume>
<contexts>
<context>hours is required to obtain a good synthetic speech quality (Kawai and Toda, 2004). These corpora are annotated by a set of phonetic and phonological tags synchronised with the acoustic signal (Torre Toledano et al., 2003). The quality of the produced synthetic signal relies strongly on the phonic segmentation. A manual segmentation process is extremely time consuming. Kawai (Kawai and Toda, 2004) reports that such a </context>
<context>alues): [*-fricative] and [pauses] in almost any context. Finally, other areas show disparate results for close phonetic classes, notably vowels. We could notice that in opposition to Toledano (Torre Toledano et al., 2003) remarks, we can find better results of context dependent models on some non stationary phones as plosives. i l @ (.)s ~o (.)t a m ł n e WORD1 WORD2 WORD3 Figure 1: Phonetic transcription of “ils son</context>
</contexts>
<marker>Toledano, D, Grande, 2003</marker>
<rawString>Torre Toledano, D., A. Hernandez Gomez, and L. Villarrubia Grande, 2003. Automatic phonetic segmentation. IEEE Transactions on Speech and Audio Processing, 11(6):617–625.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Torre Toledano</author>
<author>A Moreno Sandoval D</author>
<author>L Colas Pasamontes</author>
<author>J Garrido Salas</author>
</authors>
<title>Acoustic-phonetic decoding of different types of spontaneous speech in spanish</title>
<date>2005</date>
<booktitle>In proceedings of Disfluency in Spontaneous Speech Workshop (DiSS’05). Aix-en-Provence</booktitle>
<location>France</location>
<contexts>
<context>ted to the good accuracy of the system and the use of a phonological graph but also to the clear pronuncition of the speaker and the kind of speech studied here. Indeed as shown by Toledano in (Torre Toledano et al., 2005) best results in phonetic decoding are obtained on formal speech which is the kind of speech this study refers to. 4.2. label alignments The precision of the alignment is measured comparing manual an</context>
</contexts>
<marker>Toledano, D, Pasamontes, Salas, 2005</marker>
<rawString>Torre Toledano, D., A. Moreno Sandoval, L. Colas Pasamontes, and J. Garrido Salas, 2005. Acoustic-phonetic decoding of different types of spontaneous speech in spanish. In proceedings of Disfluency in Spontaneous Speech Workshop (DiSS’05). Aix-en-Provence, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Van Bael</author>
<author>L Boves</author>
<author>H van den Heuvel</author>
<author>H Strik</author>
</authors>
<title>Automatic phonetic transcription of large speech corpora. Computer Speech and Langage</title>
<date>2007</date>
<pages>21--652</pages>
<marker>Van Bael, Boves, van den Heuvel, Strik, 2007</marker>
<rawString>Van Bael, C., L. Boves, H. van den Heuvel, and H. Strik, 2007. Automatic phonetic transcription of large speech corpora. Computer Speech and Langage, 21:652–668.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Young</author>
<author>G Evermann</author>
<author>D Kershaw</author>
<author>G Moore</author>
<author>J Odell</author>
<author>D Ollason</author>
<author>D Povey</author>
<author>V Valtchev</author>
<author>P Woodland</author>
</authors>
<date>2002</date>
<booktitle>In The HTK Book (for HTK Version 3.2</booktitle>
<location>Cambridge, U.K</location>
<contexts>
<context>equence of phonetic symbols and their synchronisation to the signal is produced by the segmentation system from the acoustic signal and the words sequence. The HMM modelling is built on the HTK tool (Young et al., 2002). 3.1. Grapheme/Phoneme conversion An automatic phonemic transcription using a set of 36 phonemes of the French language is carried out with the software Lia phon (Bechet, 2001) which performs a rule</context>
</contexts>
<marker>Young, Evermann, Kershaw, Moore, Odell, Ollason, Povey, Valtchev, Woodland, 2002</marker>
<rawString>Young, S., G. Evermann, D. Kershaw, G. Moore, J. Odell, D. Ollason, D. Povey, V. Valtchev, and P. Woodland, 2002. In The HTK Book (for HTK Version 3.2). Cambridge, U.K.</rawString>
</citation>
</citationList>
</algorithm>

