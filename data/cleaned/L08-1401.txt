<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>G Bonnin</author>
<author>V Prince</author>
</authors>
<title>Emphasizing Syntax for French to German Machine Translation</title>
<date>2007</date>
<booktitle>Proceedings of the Seventh Symposium on Natural Language Processing</booktitle>
<pages>12--20</pages>
<location>Pattaya, Thailand</location>
<contexts>
<context>she must possibly correct the translation. In other words, treat the words as if it had only one possible equivalency (the first one). This has worked for our translation prototype in other contexts (Bonnin and Prince, 2007), in which, by chance, the first equivalency was the good one in quite a few cases. By attracting the user’s attention to the item, we believe that it will help him/her focus on translating manually </context>
</contexts>
<marker>Bonnin, Prince, 2007</marker>
<rawString>Bonnin G. and V. Prince. 2007. Emphasizing Syntax for French to German Machine Translation. Proceedings of the Seventh Symposium on Natural Language Processing, Pattaya, Thailand. pages 12-20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Chauch´e</author>
</authors>
<title>Un Outil Multidimensionnel d’Analyse du Discours</title>
<date>1984</date>
<booktitle>Proceedings of COLING84</booktitle>
<location>Stanford, California</location>
<marker>Chauch´e, 1984</marker>
<rawString>Chauch´e, J. 1984. Un Outil Multidimensionnel d’Analyse du Discours. Proceedings of COLING84, Stanford, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Chauch´e</author>
</authors>
<title>D´etermination s´emantique en analyse structurelle : une exp´erience bas´ee sur une d´efinition de distance</title>
<date>1990</date>
<journal>TA Information</journal>
<volume>1</volume>
<pages>17--24</pages>
<marker>Chauch´e, 1990</marker>
<rawString>Chauch´e J. 1990. D´etermination s´emantique en analyse structurelle : une exp´erience bas´ee sur une d´efinition de distance .TA Information vol 1/1, p 17-24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Deerwester</author>
<author>S Dumais</author>
<author>T Landauer</author>
<author>G Furnas</author>
<author>R Harshman</author>
</authors>
<title>Indexing by latent semantic analysis</title>
<journal>In Journal of the American, Society of Information science</journal>
<volume>1990</volume>
<pages>391--407</pages>
<marker>Deerwester, Dumais, Landauer, Furnas, Harshman, </marker>
<rawString>Deerwester S. and S. Dumais, T. Landauer, G. Furnas, R. Harshman, Indexing by latent semantic analysis. In Journal of the American, Society of Information science, 1990, 416(6), p 391-407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Inkpen</author>
<author>G Hirst</author>
</authors>
<title>Automatic sense disambiguation of the near-synonyms in a dictionary entry</title>
<date>2003</date>
<contexts>
<context> concepts were represented as aggregate vectors, thus accounting for polysemy. Other works have followed this approach, but mostly focusing on context vectors in a WSD task : (Niwa and Nitta, 1994), (Inkpen and Hirst, 2003) and (Patwardhan and Pedersen, 2006) with their gloss vectors based on Wordnet semantic relations. 4. Using the Roget as a Semantic Vector Space Simultaneously with Wilks et al., (Chauche, 1990) pres</context>
</contexts>
<marker>Inkpen, Hirst, 2003</marker>
<rawString>D. Inkpen and G. Hirst. 2003. Automatic sense disambiguation of the near-synonyms in a dictionary entry.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Text categorisation with support vector machines : learning with many relevant features</title>
<date>1998</date>
<booktitle>Proceedings of the 4th Conference on Intelligent Text Processing and Computational Linguistics (CICLing2003</booktitle>
<pages>258267</pages>
<contexts>
<context>ts of texts as possible corpora, the Saltonian vector-based approaches were rehabilitated (Salton and MacGil, 1983), and other vector-based techniques such as LSI (Deerwester et all. , 1990) and SVM (Joachims, 1998), appeared and provided successful solutions to Information Retrieval issues. Most works have used vector representation for tasks such as indexation, classification or retrieval. Few have suggested </context>
</contexts>
<marker>Joachims, 1998</marker>
<rawString>Proceedings of the 4th Conference on Intelligent Text Processing and Computational Linguistics (CICLing2003) , pages 258267 Joachims T. 1998. Text categorisation with support vector machines : learning with many relevant features Proceedings of ECML-98, 10th European Conference on Machine Learning pages 137142 .</rawString>
</citation>
<citation valid="true">
<authors>
<author>Larousse</author>
</authors>
<title>Th´esaurus Larousse des id´ees aux mots, des mots aux id´ees. Ed.Larousse</title>
<date>1992</date>
<location>Paris</location>
<contexts>
<context>hundred references are nowadays available mentioning the Roget. Other languages have their version of the Roget Thesaurus. Larousse lexicologists provided their main draft for the French language in (Larousse, 1992), followed by an electronic version in 2000. At the same time also, vector-based representations of texts, presented long ago (Salton, 1968) were beginning to regain popularity, after having receded </context>
</contexts>
<marker>Larousse, 1992</marker>
<rawString>Larousse. 1992. Th´esaurus Larousse des id´ees aux mots, des mots aux id´ees. Ed.Larousse, Paris.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Niwa</author>
<author>Y Nitta</author>
</authors>
<title>Co-occurrence vectors from corpora versus distance vectors from dictionaries</title>
<date>1994</date>
<booktitle>Proceedings of the Fifteenth International Conference on Computational Linguistics</booktitle>
<pages>304309</pages>
<contexts>
<context>nce matrices), and LDOCE concepts were represented as aggregate vectors, thus accounting for polysemy. Other works have followed this approach, but mostly focusing on context vectors in a WSD task : (Niwa and Nitta, 1994), (Inkpen and Hirst, 2003) and (Patwardhan and Pedersen, 2006) with their gloss vectors based on Wordnet semantic relations. 4. Using the Roget as a Semantic Vector Space Simultaneously with Wilks et</context>
</contexts>
<marker>Niwa, Nitta, 1994</marker>
<rawString>Y. Niwa and Y. Nitta. 1994. Co-occurrence vectors from corpora versus distance vectors from dictionaries. Proceedings of the Fifteenth International Conference on Computational Linguistics. pages 304309.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patwardhan Siddharth</author>
<author>Ted Pedersen</author>
</authors>
<title>Using WordNet-based Context Vectors to Estimate the Semantic Relatedness of Concepts</title>
<date>2006</date>
<booktitle>Proceedings of EACL</booktitle>
<marker>Siddharth, Pedersen, 2006</marker>
<rawString>Patwardhan Siddharth and Ted Pedersen. 2006. Using WordNet-based Context Vectors to Estimate the Semantic Relatedness of Concepts . Proceedings of EACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Prince</author>
<author>J Chauch´e</author>
</authors>
<title>Classifying texts through natural language parsing and semantic filtering</title>
<date>2007</date>
<booktitle>Proceedings of Third International Language and Technology Conference</booktitle>
<marker>Prince, Chauch´e, 2007</marker>
<rawString>Prince V. and Chauch´e J.. 2007. Classifying texts through natural language parsing and semantic filtering . Proceedings of Third International Language and Technology Conference.</rawString>
</citation>
<citation valid="false">
<authors>
<author>P Roget</author>
</authors>
<booktitle>1852 Thesaurus of English Words and Phrases Longman</booktitle>
<location>London</location>
<marker>Roget, </marker>
<rawString>Roget P. 1852 Thesaurus of English Words and Phrases Longman, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Salton</author>
</authors>
<title>Automatic Information Organisation and Retrieval</title>
<date>1968</date>
<publisher>McGraw-Hill</publisher>
<location>New York</location>
<contexts>
<context>sts provided their main draft for the French language in (Larousse, 1992), followed by an electronic version in 2000. At the same time also, vector-based representations of texts, presented long ago (Salton, 1968) were beginning to regain popularity, after having receded for a long while into a second place position. With the emergence of the Web, offering huge amounts of texts as possible corpora, the Salton</context>
</contexts>
<marker>Salton, 1968</marker>
<rawString>Salton G. 1968. Automatic Information Organisation and Retrieval. McGraw-Hill New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Salton</author>
<author>M J MacGill</author>
</authors>
<title>Introduction to Modern Information Retrieval</title>
<date>1983</date>
<location>McGraw-Hill, New-York</location>
<marker>Salton, MacGill, 1983</marker>
<rawString>Salton G. and M. J. MacGill. 1983. Introduction to Modern Information Retrieval. McGraw-Hill, New-York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Wilks</author>
<author>D Fass</author>
<author>C Guo</author>
<author>J McDonald</author>
<author>T Plate</author>
<author>B Slator</author>
</authors>
<title>Providing machine tractable dictionary tools</title>
<date>1990</date>
<booktitle>Machine Translation,. Volume5</booktitle>
<pages>99154</pages>
<contexts>
<context> have suggested a mathematical representation of dictionaries in the like of vectors. One of the most important ones and probably one of the earliest, is the LDOCE vector representation suggested by (Wilks et al., 1990)) for machine translation. The algorithm calculated a context vector for words (through co-occurrence matrices), and LDOCE concepts were represented as aggregate vectors, thus accounting for polysemy</context>
</contexts>
<marker>Wilks, Fass, Guo, McDonald, Plate, Slator, 1990</marker>
<rawString>Y. Wilks, D. Fass, C. Guo, J. McDonald, T. Plate, and B. Slator. 1990. Providing machine tractable dictionary tools. Machine Translation,. Volume5, pages 99154.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Wilks</author>
</authors>
<title>Language processing and the thesaurus</title>
<date>1998</date>
<booktitle>Proceedings of the National Language Research Institute</booktitle>
<location>Tokyo, Japan</location>
<contexts>
<context>f the language, that is, about 50;000. (v) Concepts are about 1;000. 3. Related Works The idea that an ontology of language could be useful has been already present in works such as (Yarowsky, 1992) (Wilks, 1998) and a few hundred references are nowadays available mentioning the Roget. Other languages have their version of the Roget Thesaurus. Larousse lexicologists provided their main draft for the French l</context>
</contexts>
<marker>Wilks, 1998</marker>
<rawString>Wilks, Y. 1998 Language processing and the thesaurus. Proceedings of the National Language Research Institute. Tokyo, Japan.</rawString>
</citation>
</citationList>
</algorithm>

