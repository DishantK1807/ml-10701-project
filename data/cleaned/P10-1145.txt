Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1433–1442,
Uppsala, Sweden, 11-16 July 2010. c©2010 Association for Computational Linguistics
Constituency to Dependency Translation with Forests
Haitao Mi and Qun Liu
Key Laboratory of Intelligent Information Processing
Institute of Computing Technology
Chinese Academy of Sciences
P.O. Box 2704, Beijing 100190, China
nullhtmi,liuqunnull@ict.ac.cn
Abstract
Tree-to-string systems (and their forest-
based extensions) have gained steady pop-
ularity thanks to their simplicity and effi-
ciency, but there is a major limitation: they
are unable to guarantee the grammatical-
ity of the output, which is explicitly mod-
eled in string-to-tree systems via target-
side syntax. We thus propose to com-
bine the advantages of both, and present
a novel constituency-to-dependency trans-
lation model, which uses constituency
forests on the source side to direct the
translation, and dependency trees on the
target side (as a language model) to en-
sure grammaticality. Medium-scale exper-
iments show an absolute and statistically
significant improvement of +0.7 BLEU
points over a state-of-the-art forest-based
tree-to-string system even with fewer
rules. This is also the first time that a tree-
to-tree model can surpass tree-to-string
counterparts.
1 Introduction
Linguistically syntax-based statistical machine
translation models have made promising progress
in recent years. By incorporating the syntactic an-
notations of parse trees from both or either side(s)
of the bitext, they are believed better than phrase-
based counterparts in reorderings. Depending on
the type of input, these models can be broadly di-
vided into two categories (see Table 1): the string-
based systems whose input is a string to be simul-
taneously parsed and translated by a synchronous
grammar, and the tree-based systems whose input
is already a parse tree to be directly converted into
a target tree or string. When we also take into ac-
count the type of output (tree or string), the tree-
based systems can be divided into tree-to-string
and tree-to-tree efforts.
tree on examples (partial) fast gram. BLEU
source Liu06, Huang06 + +
target Galley06, Shen08 + +
both Ding05, Liu09 + + -
both our work + + +
Table 1: A classification and comparison of lin-
guistically syntax-based SMT systems, where
gram. denotes grammaticality of the output.
On one hand, tree-to-string systems (Liu et al.,
2006; Huang et al., 2006) have gained significant
popularity, especially after incorporating packed
forests (Mi et al., 2008; Mi and Huang, 2008; Liu
et al., 2009; Zhang et al., 2009). Compared with
their string-based counterparts, tree-based systems
are much faster in decoding (linear time vs. cu-
bic time, see (Huang et al., 2006)), do not re-
quire a binary-branching grammar as in string-
based models (Zhang et al., 2006; Huang et al.,
2009), and can have separate grammars for pars-
ing and translation (Huang et al., 2006). However,
they have a major limitation that they do not have a
principled mechanism to guarantee grammatical-
ity on the target side, since there is no linguistic
tree structure of the output.
On the other hand, string-to-tree systems ex-
plicitly model the grammaticality of the output
by using target syntactic trees. Both string-to-
constituency system (e.g., (Galley et al., 2006;
Marcu et al., 2006)) and string-to-dependency
model (Shen et al., 2008) have achieved signif-
icant improvements over the state-of-the-art for-
mally syntax-based system Hiero (Chiang, 2007).
However, those systems also have some limita-
tions that they run slowly (in cubic time) (Huang
et al., 2006), and do not utilize the useful syntactic
information on the source side.
We thus combine the advantages of both tree-to-
string and string-to-tree approaches, and propose
1433
a novel constituency-to-dependency model, which
uses constituency forests on the source side to di-
rect translation, and dependency trees on the tar-
get side to guarantee grammaticality of the out-
put. In contrast to conventional tree-to-tree ap-
proaches (Ding and Palmer, 2005; Quirk et al.,
2005; Xiong et al., 2007; Zhang et al., 2007;
Liu et al., 2009), which only make use of a sin-
gle type of trees, our model is able to combine
two types of trees, outperforming both phrase-
based and tree-to-string systems. Current tree-to-
tree models (Xiong et al., 2007; Zhang et al., 2007;
Liu et al., 2009) still have not outperformed the
phrase-based system Moses (Koehn et al., 2007)
significantly even with the help of forests.1
Our new constituency-to-dependency model
(Section 2) extracts rules from word-aligned pairs
of source constituency forests and target depen-
dency trees (Section 3), and translates source con-
stituency forests into target dependency trees with
a set of features (Section 4). Medium data exper-
iments (Section 5) show a statistically significant
improvement of +0.7 BLEU points over a state-
of-the-art forest-based tree-to-string system even
with less translation rules, this is also the first time
that a tree-to-tree model can surpass tree-to-string
counterparts.
2 Model
Figure 1 shows a word-aligned source con-
stituency forest nullc and target dependency tree nulle,
our constituency to dependency translation model
can be formalized as:
P(nullcnullnulle) =
summationdisplay
CcnullFc
P(nullcnullnulle)
=
summationdisplay
CcnullFc
summationdisplay
onullO
P(null)
=
summationdisplay
CcnullFc
summationdisplay
onullO
productdisplay
rnullo
P(null)null
(1)
where nullc is a constituency tree in nullc, null is a deriva-
tion that translates nullc to nulle, null is the set of deriva-
tion, null is a constituency to dependency translation
rule.
1According to the reports of Liu et al. (2009), their forest-
based constituency-to-constituency system achieves a com-
parable performance against Moses (Koehn et al., 2007), but
a significant improvement of +3.6 BLEU points over the 1-
best tree-based constituency-to-constituency system.
2.1 Constituency
Forests on the Source Side
A constituency forest (in Figure 1 left) is a com-
pact representation of all the derivations (i.e.,
parse trees) for a given sentence under a context-
free grammar (Billot and Lang, 1989).
More formally, following Huang (2008), such
a constituency forest is a pair nullc = nullf =
nullnull fnullnullfnull, where null f is the set of nodes, and nullf
the set of hyperedges. For a given source sen-
tence null1:m = null1 nullnullnullnullm, each node nullf null null f is
in the form of nulli,j, which denotes the recognition
of nonterminal null spanning the substring from po-
sitions null through null (that is, nulli+1 nullnullnullnullj). Each hy-
peredge nullf nullnullf is a pairnulltails(nullf)nullhead(nullf)null,
where head(nullf)nullnull f is the consequent node in
the deductive step, and tails(nullf) null (null f)null is the
list of antecedent nodes. For example, the hyper-
edge nullf0 in Figure 1 for deduction (*)
NPB0,1 CC1,2 NPB2,3
NP0,3 null (*)
is notated:
null(NPB0,1null CC1,2null NPB2,3)null NP0,3nullnull
where
nullnullnullnull(nullf0) =nullNP0,3null,
and
nullnullnullnullnull(nullf0) =nullNPB0,1nullCC1,2nullNPB2,3null.
The solid line in Figure 1 shows the best parse
tree, while the dashed one shows the second best
tree. Note that common sub-derivations like those
for the verb VPB3,5 are shared, which allows the
forest to represent exponentially many parses in a
compact structure.
We also denote IN(nullf) to be the set of in-
coming hyperedges of node nullf, which represents
the different ways of deriving nullf. Take node IP0,5
in Figure 1 for example, IN(IP0,5) = nullnullf1nullnullf2null.
There is also a distinguished root node TOP in
each forest, denoting the goal item in parsing,
which is simply S0,m where S is the start symbol
and null is the sentence length.
2.2 Dependency
Trees on the Target Side
A dependency tree for a sentence represents each
word and its syntactic dependents through directed
arcs, as shown in the following examples. The
main advantage of a dependency tree is that it can
explore the long distance dependency.
1434
1: talk
blank a blan blan
2: held
Bush bla blk talk
a bl
with
b Sharon
We use the lexicon dependency grammar (Hell-
wig, 2006) to express a projective dependency
tree. Take the dependency trees above for exam-
ple, they will be expressed:
1: ( a ) talk
2: ( Bush ) held ( ( a ) talk ) ( with ( Sharon ) )
where the lexicons in brackets represent the de-
pendencies, while the lexicon out the brackets is
the head.
More formally, a dependency tree is also a pair
nulle = nulld = nullnull dnullnulldnull. For a given target sen-
tence null1:n = null1 nullnullnullnulln, each node nulld null null d is
a word nulli (1 lessorequalslant null lessorequalslant null), each hyperedge nulld null
nulld is a directed arc nullnulldi nullnulldjnull from node nulldi to
its head node nulldj . Following the formalization of
the constituency forest scenario, we denote a pair
nulltails(nulld)nullhead(nulld)nullto be a hyperedge nulld, where
head(nulld) is the head node, tails(nulld) is the node
where nulld leaves from.
We also denote nulll(nulld) and nullr(nulld) to be the left
and right children sequence of node nulld from the
nearest to the farthest respectively. Take the node
nulld2 = “held” for example:
nulll(nulld2) =nullBushnull,
nullr(nulld2) =nulltalk, withnull.
2.3 Hypergraph
Actually, both the constituency forest and the de-
pendency tree can be formalized as a hypergraph
null, a pairnullnullnullnullnull. We use nullf and nulld to distinguish
them. For simplicity, we also use nullc and nulle to de-
note a constituency forest and a dependency tree
respectively. Specifically, the size of nullnullnullnullnull(nulld) of
a hyperedge nulld in a dependency tree is a constant
one.
IP
NP
null1:NPB CC
yˇu
null2:NPB
null3:VPBnull(null
1) null3 (with (null2))
Figure 2: Example of the rule null1. The Chinese con-
junction yˇu “and” is translated into English prepo-
sition “with”.
3 Rule
Extraction
We extract constituency to dependency rules from
word-aligned source constituency forest and target
dependency tree pairs (Figure 1). We mainly ex-
tend the tree-to-string rule extraction algorithm of
Mi and Huang (2008) to our scenario. In this sec-
tion, we first formalize the constituency to string
translation rule (Section 3.1). Then we present
the restrictions for dependency structures as well
formed fragments (Section 3.2). Finally, we de-
scribe our rule extraction algorithm (Section 3.3),
fractional counts computation and probabilities es-
timation (Section 3.4).
3.1 Constituency
to Dependency Rule
More formally, a constituency to de-
pendency translation rule null is a tuple
nulllhs(null)nullrhs(null)nullnull(null)null, where lhs(null) is the
source side tree fragment, whose internal nodes
are labeled by nonterminal symbols (like NP and
VP), and whose frontier nodes are labeled by
source language words nulli (like “yˇu”) or variables
from a setnull =nullnull1nullnull2nullnullnullnullnull; rhs(null) is expressed
in the target language dependency structure with
words nullj (like “with”) and variables from the set
null; and null(null) is a mapping from null to nontermi-
nals. Each variable nulli nullnull occurs exactly once in
lhs(null) and exactly once in rhs(null). For example,
the rule null1 in Figure 2,
lhs(null1) = IP(NP(null1 CC(yˇu) null2) null3)null
rhs(null1) = (null1) null3 (with (null2))null
null(null1) =nullnull1nullNPB, null2nullNPB, null3nullVPBnullnull
3.2 Well
Formed Dependency Fragment
Following Shen et al. (2008), we also restrict
rhs(null) to be well formed dependency fragment.
The main difference between us is that we use
more flexible restrictions. Given a dependency
1435
IP0,5
“(Bush) .. Sharon))”
nullf1
NP0,3
“(Bush) null (with (Sharon))”
NPB0,1
“Bush”
B`ush´ı
nullf0
CC1,2
“with”
yˇu
VP1,5
“held .. Sharon))”
PP1,3
“with (Sharon)”
P1,2
“with”
NPB2,3
“Sharon”
Sh¯al´ong
VPB3,5
“held ((a) talk)”
VV3,4
“held ((a)*)”
jˇux´ıngle
NPB4,5
“talk”
hu`ıt´an
nullf2
Minimal rules extracted
IP (NP(null1:NPB null2:CC null3:NPB) null4:VPB)
null(null1) null4 (null2 (null3) )
IP (null1:NPB null2:VP)null(null1) null2
VP (null1:PP null2:VPB)nullnull2 (null1)
PP (null1:P null2:NPB)nullnull1 (null2)
VPB (VV(jˇux´ıngle)) null1:NPB)
nullheld ((a) null1)
NPB (B`ush´ı)nullBush
NPB (hu`ıt´an)nulltalk
CC (yˇu)nullwith
P (yˇu)nullwith
NPB (Sh¯al´ong)nullSharon
( Bush ) held ( ( a ) talk ) ( with ( Sharon ) )
Figure 1: Forest-based constituency to dependency rule extraction.
fragment nulli:j composed by the words from null to null,
two kinds of well formed structures are defined as
follows:
Fixed on one node nulldone, fixed for short, if it
meets the following conditions:
null the head of nulldone is out of [nullnullnull], i.e.: nullnulld, if
tails(nulld) = nulldonenullhead(nulld) nullnullnulli:j.
null the heads of other nodes except nulldone are in
[nullnullnull], i.e.: nullnull null [nullnullnull] and nulldk null= nulldonenullnullnulld if
tails(nulld) = nulldk nullhead(nulld)nullnulli:j.
Floating with multi nodes null, floating for
short, if it meets the following conditions:
null all nodes in null have a same head node,
i.e.: nullnull nullnull [nullnullnull]nullnullnulld if tails(nulld) null null null
head(nulld) = nullhx.
null the heads of other nodes not in null are in
[nullnullnull], i.e.: nullnull null [nullnullnull] and nulldk nullnull nullnullnullnulld if
tails(nulld) = nulldk nullhead(nulld)nullnulli:j.
Take the “ (Bush) held ((a) talk))(with (Sharon))
” for example: partial fixed examples are “ (Bush)
held ” and “ held ((a) talk)”; while the partial float-
ing examples are “ (talk) (with (Sharon)) ” and “
((a) talk) (with (Sharon)) ”. Please note that the
floating structure “ (talk) (with (Sharon)) ” can not
be allowed in Shen et al. (2008)’s model.
The dependency structure “ held ((a))” is not a
well formed structure, since the head of word “a”
is out of scope of this structure.
3.3 Rule
Extraction Algorithm
The algorithm shown in this Section is mainly ex-
tended from the forest-based tree-to-string extrac-
tion algorithm (Mi and Huang, 2008). We extract
rules from word-aligned source constituency for-
est and target dependency tree pairs (see Figure 1)
in three steps:
(1) frontier set computation,
(2) fragmentation,
(3) composition.
The frontier set (Galley et al., 2004) is the po-
tential points to “cut” the forest and dependency
tree pair into fragments, each of which will form a
minimal rule (Galley et al., 2006).
However, not every fragment can be used for
rule extraction, since it may or may not respect
to the restrictions, such as word alignments and
well formed dependency structures. So we say a
fragment is extractable if it respects to all re-
strictions. The root node of every extractable tree
fragment corresponds to a faithful structure on
the target side, in which case there is a “transla-
tional equivalence” between the subtree rooted at
the node and the corresponding target structure.
For example, in Figure 1, every node in the forest
is annotated with its corresponding English struc-
ture. The NP0,3 node maps to a non-contiguous
structure “(Bush) null (with (Sharon))”, the VV3,4
node maps to a contiguous but non-faithful struc-
ture “held ((a) *)”.
1436

