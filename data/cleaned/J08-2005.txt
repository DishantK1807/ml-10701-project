TheImportanceofSyntacticParsingand
InferenceinSemanticRoleLabeling
VasinPunyakanok
∗‡
BBNTechnologies
DanRoth
∗∗
UniversityofIllinoisat
Urbana-Champaign
Wen-tauYih
†‡
MicrosoftResearch
Wepresentageneralframeworkforsemanticrolelabeling.Theframeworkcombinesamachine-
learning technique with an integer linear programming–based inference procedure, which in-
corporates linguistic and structural constraints into a global decision process. Within this
framework, we study the role of syntactic parsing information in semantic role labeling. We
showthatfullsyntacticparsinginformationis,byfar,mostrelevantinidentifyingtheargument,
especially, in the very ﬁrst stage—the pruning stage. Surprisingly, the quality of the pruning
stage cannot be solely determined based on its recall and precision. Instead, it depends on the
characteristics of the output candidates that determine the difﬁculty of the downstream prob-
lems. Motivated by this observation, we propose an effective and simple approach of combining
differentsemanticrolelabelingsystemsthroughjointinference,whichsigniﬁcantlyimprovesits
performance.
Our system has been evaluated in the CoNLL-2005 shared task on semantic role labeling,
andachievesthehighestF
1
scoreamong19participants.
1.Introduction
Semanticparsingofsentencesisbelievedtobeanimportanttaskontheroadtonatural
languageunderstanding,andhasimmediateapplicationsintaskssuchasinforma-
tionextractionandquestionanswering. Semantic Role Labeling (SRL)isashallow
semanticparsingtask,inwhichforeachpredicateinasentence,thegoalistoidentify
allconstituentsthatﬁllasemanticrole,andtodeterminetheirroles(Agent,Patient,
Instrument,etc.)andtheiradjuncts(Locative,Temporal,Manner,etc.).
∗ 10MoultonSt.,Cambridge,MA02138,USA.E-mail:vpunyaka@bbn.com.
∗∗ DepartmentofComputerScience,UniversityofIllinoisatUrbana-Champaign,201N.GoodwinAve.,
Urbana,IL61801,USA.E-mail:danr@uiuc.edu.
† OneMicrosoftWay,Redmond,WA98052,USA.E-mail:scottyih@microsoft.com.
‡ MostoftheworkwasdonewhentheseauthorswereattheUniversityofIllinoisatUrbana-Champaign.
Submissionreceived:15July2006;revisedsubmissionreceived:3May2007;acceptedforpublication:
19June2007.
©2008AssociationforComputationalLinguistics
ComputationalLinguistics Volume34,Number2
ThePropBankproject(KingsburyandPalmer2002;Palmer,Gildea,andKingsbury
2005),whichprovidesalargehuman-annotatedcorpusofverbpredicatesandtheirar-
guments,hasenabledresearcherstoapplymachinelearningtechniquestodevelopSRL
systems(GildeaandPalmer2002;ChenandRambow2003;GildeaandHockenmaier
2003;Pradhanetal.2003;Surdeanuetal.2003;Pradhanetal.2004;XueandPalmer2004;
Koomenetal.2005).However,mostsystemsrelyheavilyonfullsyntacticparsetrees.
Therefore,theoverallperformanceofthesystemislargelydeterminedbythequality
oftheautomaticsyntacticparsersofwhichthestateoftheart(Collins1999;Charniak
2001)isstillfarfromperfect.
Alternatively,shallowsyntacticparsers(i.e.,chunkersandclausers),althoughthey
donotprovideasmuchinformationasafullsyntacticparser,havebeenshownto
bemorerobustintheirspeciﬁctasks(LiandRoth2001).Thisraisestheverynatural
andinterestingquestionofquantifyingtheimportanceoffullparsinginformationto
semanticparsingandwhetheritispossibletouseonlyshallowsyntacticinformationto
buildanoutstandingSRLsystem.
AlthoughPropBankisbuiltbyaddingsemanticannotationstotheconstituentsin
thePennTreebanksyntacticparsetrees,itisnotclearhowimportantsyntacticparsing
isforanSRLsystem.Tothebestofourknowledge,thisproblemwasﬁrstaddressed
byGildeaandPalmer(2002).Intheirattempttouselimitedsyntacticinformation,the
parsertheyusedwasvery shallow—clauseswerenotavailableandonlychunkswere
used.Moreover,thepruningstagetherewasverystrict—onlychunkswereconsidered
asargumentcandidates.Thisresultsinover60%oftheactualargumentsbeingignored.
Consequently,theoverallrecallintheirapproachwasverylow.
TheuseofonlyshallowparsinginformationinanSRLsystemhaslargelybeen
ignoreduntiltherecentCoNLL-2004sharedtaskcompetition(CarrerasandM`arquez
2004).Inthatcompetition,participantswererestrictedtousingonlyshallowparsing
information,whichincludedpart-of-speechtags,chunks,andclauses(thedeﬁnitionsof
chunksandclausescanbefoundinTjongKimSangandBuchholz[2000]andCarreras
etal.[2002],respectively).Asaresult,theperformanceofthebestshallowparsing–
basedsystem(Haciogluetal.2004)inthecompetitionisabout10pointsinF
1
belowthe
bestsystemthatusesfullparsinginformation(Koomenetal.2005).However,thisisnot
theoutcomeofatrueandfairquantitativecomparison.TheCoNLL-2004sharedtask
usedonlyasubsetofthedatafortraining,whichpotentiallymakestheproblemharder.
Furthermore,anSRLsystemisusuallycomplicatedandconsistsofseveralstages.It
wasstillunclearhowmuchsyntacticinformationhelpsandpreciselywhereithelpsthe
most.
Thegoalofthispaperisthreefold.First,wedescribeanarchitectureforanSRL
systemthatincorporatesalevelofglobalinferenceontopoftherelativelycommon
processingsteps.Thisinferencestepallowsustoincorporatestructuralandlinguistic
constraintsoverthepossibleoutcomesoftheargumentclassiﬁerinaneasyway.The
inferenceprocedureisformalizedviaanIntegerLinearProgrammingframeworkand
isshowntoyieldstate-of-the-artresultsonthistask.Second,weprovideafaircom-
parisonbetweenSRLsystemsthatusefullparsetreesandsystemsthatonlyuseshal-
lowsyntacticinformation.Aswithourfullsyntacticparse–basedSRLsystem(Koomen
etal.2005),ourshallowparsing–basedSRLsystemisbasedonthesystemthatachieves
verycompetitiveresultsandwasoneofthetopsystemsintheCoNLL-2004shared
taskcompetition(CarrerasandM`arquez2004).Thiscomparisonbringsforwardacare-
fulanalysisofthesigniﬁcanceoffullparsinginformationintheSRLtask,andprovides
anunderstandingofthestagesintheprocessinwhichthisinformationmakesthemost
difference.Finally,torelievethedependencyoftheSRLsystemonthequalityof
258
Punyakanok,Roth,andYih ImportanceofParsingandInferenceinSRL
automaticparsers,wesuggestawaytoimprovesemanticrolelabelingsigniﬁcantlyby
developingaglobalinferencealgorithm,whichisusedtocombineseveralSRLsystems
basedondifferentstate-of-the-artfullparsers.Thecombinationprocessisdonethrough
ajointinferencestage,whichtakestheoutputofeachindividualsystemasinputand
generatesthebestpredictions,subjecttovariousstructuralandlinguisticconstraints.
Theunderlyingsystemarchitecturecanlargelyaffecttheoutcomeofourstudy.
Therefore,tomaketheconclusionsofourexperimentalstudyasapplicableaspossible
togeneralSRLsystems,thearchitectureofourSRLsystemfollowsthemostwidely
usedtwo-stepdesign.Intheﬁrststep,thesystemistrainedtoidentifyargumentcandi-
datesforagivenverbpredicate.Inthesecondstep,thesystemclassiﬁestheargument
candidatesintotheirtypes.Inaddition,itisalsoasimpleproceduretopruneobvious
non-candidatesbeforetheﬁrststep,andtousepost-processinginferencetoﬁxincon-
sistentpredictionsafterthesecondstep.Thesetwoadditionalstepsarealsoemployed
byoursystem.
Ourstudyofshallowandfullsyntacticinformation–basedSRLsystemswasdone
bycomparingtheirimpactateachstageoftheprocess.Speciﬁcally,ourgoalistoinvesti-
gateatwhatstagefullparsinginformationismosthelpfulrelativetoashallowparsing–
basedsystem.Therefore,ourexperimentsweredesignedsothatthecomparedsystems
areassimilaraspossible,andtheadditionofthefullparsetree–basedfeaturesisthe
onlydifference.Themostinterestingresultofthiscomparisonisthatalthougheach
stepoftheshallowparsinginformation–basedsystemexhibitsverygoodperformance,
theoverallperformanceissigniﬁcantlyinferiortothesystemthatusesfullparsing
information.Ourexplanationisthat chaining multipleprocessingstagestoproduce
theﬁnalSRLanalysisiscrucialtounderstandingthisanalysis.Speciﬁcally,thequality
oftheinformationpassedfromonestagetotheotherisadecisiveissue,anditis
notnecessarilyjudgedsimplybyconsideringtheF-measure.Weconcludethat,for
thesystemarchitectureusedinourstudy,thesigniﬁcanceoffullparsinginformation
comesintoplaymostlyatthepruningstage,wherethecandidatestobeprocessedlater
aredetermined.Inaddition,weproduceastate-of-the-artSRLsystembycombining
differentSRLsystemsbasedontwoautomaticfullparsers(Collins1999;Charniak2001),
whichachievesthebestresultintheCoNLL-2005sharedtask(CarrerasandM`arquez
2005).
Therestofthispaperisorganizedasfollows.Section2introducesthetaskof
semanticrolelabelinginmoredetail.Section3describesthefour-stagearchitectureof
ourSRLsystem,whichincludespruning,argumentidentiﬁcation,argumentclassiﬁ-
cation,andinference.Thefeaturesusedforbuildingtheclassiﬁersandthelearning
algorithmappliedarealsoexplainedthere.Section4explainswhyandwherefull
parsinginformationcontributestoSRLbyconductingaseriesofcarefullydesigned
experiments.Inspiredbytheresult,weexaminetheeffectofinferenceinasinglesystem
andproposeanapproachthatcombinesdifferentSRLsystemsbasedonjointinference
inSection5.Section6presentstheempiricalevaluationofoursystemintheCoNLL-
2005sharedtaskcompetition.Afterthat,wediscusstherelatedworkinSection7and
concludethispaperinSection8.
2.TheSemanticRoleLabeling(SRL)Task
Thegoalofthesemanticrolelabelingtaskistodiscoverthepredicate–argumentstruc-
tureofeachpredicateinagiveninputsentence.Inthiswork,wefocusonlyontheverb
predicate.Forexample,givenasentenceIleftmypearlstomydaughter-in-lawinmywill,
259
ComputationalLinguistics Volume34,Number2
thegoalistoidentifythedifferentargumentsoftheverbpredicateleftandproducethe
output:
[
A0
I][
V
left][
A1
mypearls][
A2
tomydaughter-in-law][
AM-LOC
inmywill].
HereA0representstheleaver,A1representsthething left,A2representsthebeneﬁciary,
AM-LOCisanadjunctindicatingthelocationoftheaction,andVdeterminesthe
boundariesofthepredicate,whichisimportantwhenapredicatecontainsmanywords,
forexample,aphrasalverb.Inaddition,eachargumentcanbemappedtoaconstituent
initscorrespondingfullsyntacticparsetree.
FollowingthedeﬁnitionofthePropBankandCoNLL-2004and2005sharedtasks,
therearesixdifferenttypesofargumentslabeledasA0–A5andAA.Theselabelshave
differentsemanticsforeachverbandeachofitssensesasspeciﬁedinthePropBank
Frameﬁles.Inaddition,therearealso13typesofadjunctslabeledasAM-adjwhereadj
speciﬁestheadjuncttype.Forsimplicityinourpresentation,wewillalsorefertothese
adjunctsasarguments.Insomecases,anargumentmayspanoverdifferentpartsof
asentence;thelabelC-argisthenusedtospecifythecontinuityofthearguments,as
showninthisexample:
[
A1
Thepearls],[
A0
I][
V
said],[
C-A1
werelefttomydaughter-in-law].
Insomeothercases,anargumentmightbearelativepronounthatinfactreferstotheac-
tualagentoutsidetheclause.Inthiscase,theactualagentislabeledastheappropriate
argumenttype,arg,whiletherelativepronounisinsteadlabeledasR-arg.Forexample,
[
A1
Thepearls][
R-A1
which][
A0
I][
V
left][
A2
tomydaughter-in-law]arefake.
Becauseeachverbmayhavedifferentsensesproducingdifferentsemanticroles
forthesamelabels,thetaskofdiscoveringthecompletesetofsemanticrolesshould
involvenotonlyidentifyingtheselabels,butalsotheunderlyingsenseforagiven
verb.However,asinallcurrentSRLwork,thisarticlefocusesonlyonidentifyingthe
boundariesandthelabelsofthearguments,andignorestheverbsensedisambiguation
problem.
Thedistributionoftheseargumentlabelsisfairlyunbalanced.Intheofﬁcialrelease
ofPropBankI,corearguments(A0–A5andAA)occupy71.26%ofthearguments,where
thelargestpartsareA0(25.39%)andA1(35.19%).Therestmostlyconsistsofadjunct
arguments(24.90%).Thecontinued(C-arg)andreferential(R-arg)argumentsarerela-
tivelyfew,occupying1.22%and2.63%,respectively.FormoreinformationonPropBank
andthesemanticrolelabelingtask,readerscanrefertoKingsburyandPalmer(2002)
andCarrerasandM`arquez(2004,2005).
Notethatthesemanticargumentsofthesameverbdonotoverlap.Wedeﬁneover-
lappingargumentstobethosethatsharesomeoftheirparts.Anargumentisconsidered
embeddedinanotherargumentifthesecondargumentcompletelycoverstheﬁrstone.
Argumentsareexclusivelyoverlappingiftheyareoverlappingbutarenotembedded.
3.SRLSystemArchitecture
AdheringtothemostcommonarchitectureforSRLsystems,ourSRLsystemconsistsof
fourstages:pruning,argumentidentiﬁcation,argumentclassiﬁcation,andinference.
Inparticular,thegoalofpruningandargumentidentiﬁcationistoidentifyargument
candidatesforagivenverbpredicate.Intheﬁrstthreestages,however,decisions
areindependentlymadeforeachargument,andinformationacrossargumentsisnot
260
Punyakanok,Roth,andYih ImportanceofParsingandInferenceinSRL
incorporated.Theﬁnalinferencestageallowsustousethistypeofinformationalong
withlinguisticandstructuralconstraintsinordertomakeconsistentglobalpredictions.
Thissystemarchitectureremainsunchangedwhenusedforstudyingtheimpor-
tanceofsyntacticparsinginSRL,althoughdifferentinformationandfeaturesareused.
Throughoutthisarticle,when full parsing informationisavailable,weassumethat
thesystemispresentedwiththefullphrase-structureparsetreeasdeﬁnedinthePenn
Treebank(Marcus,Marcinkiewicz,andSantorini1993)butwithouttraceandfunctional
tags.Ontheotherhand,whenonlyshallow parsinginformationisavailable,thefull
parsetreeisreducedtoonlythechunksandtheclauseconstituents.
A chunk isaphrasecontainingsyntacticallyrelatedwords.Roughlyspeaking,
chunksareobtainedbyprojectingthefullparsetreeontoaﬂattree;hence,theyare
closelyrelatedtothebasephrases.Chunkswerenotdirectlydeﬁnedaspartofthe
standardannotationofthetreebank,but,rather,theirdeﬁnitionwasintroducedinthe
CoNLL-2000sharedtaskontextchunking(TjongKimSangandBuchholz2000),which
aimedtodiscoversuchphrasesinordertofacilitatefullparsing.Aclause,ontheother
hand,istheclausalconstituentasdeﬁnedbythetreebankstandard.Anexampleof
chunksandclausesisshowninFigure1.
3.1Pruning
Whenthefullparsetreeofasentenceisavailable,onlytheconstituentsintheparse
treeareconsideredasargumentcandidates.Oursystemexploitstheheuristicrules
introducedbyXueandPalmer(2004)toﬁlteroutsimpleconstituentsthatarevery
unlikelytobearguments.Thispruningmethodisarecursiveprocessstartingfromthe
targetverb.Itﬁrstreturnsthesiblingsoftheverbascandidates;thenitmovestothe
parentoftheverb,andcollectsthesiblingsagain.Theprocessgoesonuntilitreaches
theroot.Inaddition,ifaconstituentisaPP(prepositionalphrase),itschildrenarealso
collected.Forexample,inFigure1,ifthepredicate(targetverb)isassume,thepruning
heuristicwilloutput:[
PP
by John Smith who has been elected deputy chairman],[
NP
John
Smithwhohasbeenelecteddeputychairman],[
VB
be],[
MD
will],and[
NP
Hisduties].
3.2ArgumentIdentiﬁcation
Theargumentidentiﬁcationstageutilizesbinaryclassiﬁcationtoidentifywhethera
candidateisanargumentornot.Whenfullparsingisavailable,wetrainandapply
thebinaryclassiﬁersontheconstituentssuppliedbythepruningstage.Whenonly
shallowparsingisavailable,thesystemdoesnothaveapruningstage,andalsodoes
nothaveconstituentstobeginwith.Therefore,conceptually,thesystemhastoconsider
allpossiblesubsequences(i.e.,consecutivewords)inasentenceaspotentialargument
candidates.Weavoidthisbyusingalearningschemethatutilizestwoclassiﬁers,oneto
predictthebeginningsofpossiblearguments,andtheothertheends.Thepredictions
arecombinedtoformargumentcandidates.However,wecanemployasimpleheuristic
toﬁlteroutsomecandidatesthatareobviouslynotarguments.Theﬁnalpredication
includesthosethatdonotviolatethefollowingconstraints.
1. Argumentscannotoverlapwiththepredicate.
2. Ifapredicateisoutsideaclause,itsargumentscannotbeembeddedin
thatclause.
3. Argumentscannotexclusivelyoverlapwiththeclauses.
261
ComputationalLinguistics Volume34,Number2
Figure1
Anexampleofaparsetreeanditspredicate–argumentstructure.
Theﬁrstconstraintcomesfromthedeﬁnitionofthistaskthatthepredicatesimply
cannottakeitselforanyconstituentsthatcontainitselfasarguments.Theothertwo
constraintsareduetothefactthataclausecanbetreatedasaunitthathasitsown
verb–argumentstructure.Ifaverbpredicateisoutsideaclause,thenitsargumentcan
onlybethewholeclause,butmaynotbeembeddedinorexclusivelyoverlapwiththe
clause.
Fortheargumentidentiﬁcationclassiﬁer,thefeaturesusedinfullparsingand
shallowparsingsettingsareallbinaryfeatures,whicharedescribedsubsequently.
3.2.1 Features
Used When Full Parsing is Available. Mostofthefeaturesusedinour
systemarecommonfeaturesfortheSRLtask.ThecreationofPropBankwasinspired
bytheworksofLevin(1993)andLevinandHovav(1996),whichdiscusstherelation
betweensyntacticandsemanticinformation.Followingthisphilosophy,thefeatures
aimtoindicatethepropertiesofthepredicate,theconstituentwhichisanargument
candidate,andtherelationshipbetweenthemthroughtheavailablesyntacticinfor-
mation.Weexplainthesefeaturesherein.Forfurtherdiscussionofthesefeatures,we
262
Punyakanok,Roth,andYih ImportanceofParsingandInferenceinSRL
referthereaderstothearticlebyGildeaandJurafsky(2002),whichintroducedthese
features.
a114
PredicateandPOStagofpredicate:indicatethelemmaofthepredicate
verbanditsPOStag.
a114
Voice:indicatespassive/activevoiceofthepredicate.
a114
Phrasetype:providesthephrasetypeoftheconstituent,whichisthetag
ofthecorrespondingconstituentintheparsetree.
a114
HeadwordandPOStagoftheheadword:providestheheadwordofthe
constituentanditsPOStag.WeusetherulesintroducedbyCollins(1999)
toextractthisfeature.
a114
Position:describesiftheconstituentisbeforeorafterthepredicate,
relativetothepositioninthesentence.
a114
Path:recordsthetagsofparsetreenodesinthetraversalpathfromthe
constituenttothepredicate.Forexample,inFigure1,ifthepredicateis
assumeandtheconstituentis[
S
whohasbeenelecteddeputychairman],the
pathisS↑NP↑PP↑VP↓VBN,where↑and↓indicatethetraversaldirection
inthepath.
a114
Subcategorization:describesthephrasestructurearoundthepredicate’s
parent.Itrecordstheimmediatestructureintheparsetreethatexpandsto
itsparent.Asanexample,ifthepredicateiselectinFigure1,its
subcategorizationisVP→(VBN)-NPwhilethesubcategorizationofthe
predicateassumeisVP→(VBN)-PP.Parenthesesindicatethepositionofthe
predicate.
Generallyspeaking,weconsideronlytheargumentsthatcorrespondtosomecon-
stituentsinparsetrees.However,insomecases,weneedtoconsideranargumentthat
doesnotexactlycorrespondtoaconstituent,forexample,inourexperimentinSec-
tion4.2wherethegold-standardboundariesareusedwiththeparsetreesgeneratedby
anautomaticparse.Insuchcases,iftheinformationontheconstituent,suchasphrase
type,needstobeextracted,thedeepestconstituentthatcoversthewholeargumentwill
beused.Forexample,inFigure1,thephrasetypeforby John SmithisPP,anditspath
featuretothepredicateassumeisPP↑VP↓VBN.
Wealsousethefollowingadditionalfeatures.Thesefeatureshavebeenshown
tobeusefulforthesystemsbyexploitingotherinformationintheabsenceofthe
fullparsetreeinformation(Punyakanoketal.2004),and,hence,canbehelpfulin
conjunctionwiththefeaturesextractedfromafullparsetree.Theyalsoaimtoencode
thepropertiesofthepredicate,theconstituenttobeclassiﬁed,andtheirrelationshipin
thesentence.
a114
ContextwordsandPOStagsofthecontextwords:thefeature
includesthetwowordsbeforeandaftertheconstituent,andtheir
POStags.
a114
Verbclass:thefeatureistheVerbNet(Kipper,Palmer,andRambow2002)
classofthepredicateasdescribedinPropBankFrames.Notethata
263
ComputationalLinguistics Volume34,Number2
verbmayinhabitmanyclassesandwecollectalloftheseclassesas
features,regardlessofthecontext-speciﬁcsensewhichwedonotattempt
toresolve.
a114
Lengths:oftheconstituent,inthenumbersofwordsandchunks
separately.
a114
Chunk:tellsiftheconstituent“is,”“embeds,”“exclusivelyoverlaps,”or
“isembeddedin”achunkwithitstype.Forinstance,inFigure1,ifthe
constituentsare[
NP
Hisduties],[
PP
byJohnSmith],and[
VBN
elected],then
theirchunkfeaturesare“is-NP,”“embed-PP&embed-NP,”and
“embedded-in-VP,”respectively.
a114
Chunkpattern:encodesthesequenceofchunksfromtheconstituentto
thepredicate.Forexample,inFigure1thechunksequencefrom[
NP
His
duties]tothepredicateelectisVP-PP-NP-NP-VP.
a114
Chunkpatternlength:thefeaturecountsthenumberofchunksinthe
chunkpatternfeature.
a114
Clauserelativeposition:encodesthepositionoftheconstituentrelative
tothepredicateinthepseudo-parsetreeconstructedonlyfromclause
constituents,chunks,andpart-of-speechtags.Inaddition,welabelthe
clausewiththetypeofchunkthatimmediatelyprecedestheclause.
Thisisasimpleruletodistinguishthetypeofclausebasedon
theintuitionthatasubordinateclauseoftenmodiﬁesthepartofthe
sentenceimmediatelybeforeit.Figure2showsthepseudo-parse
treeoftheparsetreeinFigure1.Bydisregardingthechunks,there
arefourconﬁgurations—“targetconstituentandpredicateare
siblings,”“targetconstituent’sparentisanancestorofpredicate,”
“predicate’sparentisanancestoroftargetword,”or“otherwise.”
ThisfeaturecanbeviewedasageneralizationofthePathfeature
describedearlier.
a114
Clausecoverage:describeshowmuchofthelocalclausefromthe
predicateiscoveredbythetargetargument.
a114
NEG:thefeatureisactiveifthetargetverbchunkhasnotorn’t.
a114
MOD:thefeatureisactivewhenthereisamodalverbintheverbchunk.
TherulesoftheNEGandMODfeaturesareusedinabaselineSRLsystem
developedbyErikTjongKimSang(CarrerasandM`arquez2004).
Figure2
Thepseudo-parsetreegeneratedfromtheparsetreeinFigure1.
264
Punyakanok,Roth,andYih ImportanceofParsingandInferenceinSRL
Inaddition,wealsousetheconjunctionsoffeatureswhichconjoinanytwofeatures
intoanewfeature.Forexample,theconjunctionofthepredicateandpathfeatures
forthepredicateassumeandtheconstituent[
S
who has been elected deputy chairman]in
Figure1is(S↑NP↑PP↑VP↓VBN,assume).
3.2.2 Features
Used When Only Shallow Parsing is Available.Mostfeaturesusedhereare
similartothoseusedbythesystemwithfullparsinginformation.However,forfeatures
thatneedfullparsetreesintheirextractionprocedures,weeithertrytomimicthem
withsomeheuristicrulesordiscardthem.Thedetailsofthesefeaturesareasfollows.
a114
Phrasetype:usesasimpleheuristictoidentifythetypeoftheargument
candidateasVP,PP,orNP.
a114
HeadwordandPOStagoftheheadword:aretherightmostwordfor
NP,andtheleftmostwordforVPandPP.
a114
Shallow-Path:recordsthetraversalpathinthepseudo-parsetree.
ThisaimstoapproximatethePathfeaturesextractedfromthefull
parsetree.
a114
Shallow-Subcategorization:describesthechunkandclausestructure
aroundthepredicate’sparentinthepseudo-parsetree.Thisaimsto
approximatetheSubcategorizationfeatureextractedfromthefullparse
tree.
3.3ArgumentClassiﬁcation
Thisstageassignslabelstotheargumentcandidatesidentiﬁedinthepreviousstage.
Amulti-classclassiﬁeristrainedtopredictthetypesoftheargumentcandidates.In
addition,toreducetheexcessivecandidatesmistakenlyoutputbythepreviousstage,
theclassiﬁercanalsolabelanargumentas“null”(meaning“notanargument”)todis-
cardit.
Thefeaturesusedherearethesameasthoseusedintheargumentidentiﬁcation
stage.However,whenfullparsingisavailable,anadditionalfeatureintroducedbyXue
andPalmer(2004)isused.
a114
Syntacticframe:describesthesequentialpatternofthenounphrasesand
thepredicateinthesentencewhichaimstocomplementthePathand
Subcategorizationfeatures.
Thelearningalgorithmusedfortrainingtheargumentclassiﬁerandargumentiden-
tiﬁerisavariationoftheWinnowupdateruleincorporatedinSNoW (Roth1998;
Carlsonetal.1999),amulti-classclassiﬁerthatistailoredforlargescalelearningtasks.
SNoWlearnsasparsenetworkoflinearfunctions,inwhichthetargets(argument
borderpredictionsorargumenttypepredictions,inthiscase)arerepresentedaslinear
functionsoveracommonfeaturespace;multi-classdecisionsaredoneviaawinner-
take-allmechanism.ItimprovesthebasicWinnowmultiplicativeupdaterulewitha
regularizationterm,whichhastheeffectofseparatingthedatawithalargemargin
separator(Dagan,Karov,andRoth1997;GroveandRoth2001;Zhang,Damerau,and
Johnson2002)andvoted(averaged)weightvector(FreundandSchapire1999;Golding
andRoth1999).
265
ComputationalLinguistics Volume34,Number2
Thesoftmaxfunction(Bishop1995)isusedtoconvertrawactivationtoconditional
probabilities.Iftherearenclassesandtherawactivationofclassiisact
i,theposterior
estimationforclassiis
Prob(i)=
e
act
i
summationtext
1≤j≤n
e
act
j
Notethatintrainingthisclassiﬁer,unlessspeciﬁedotherwise,theargumentcan-
didatesusedtogeneratethetrainingexamplesareobtainedfromtheoutputofthe
argumentidentiﬁer,notdirectlyfromthegold-standardcorpus.Inthiscase,weau-
tomaticallyobtainthenecessaryexamplestolearnforclass“null.”
3.4Inference
Inthepreviousstages,decisionswerealwaysmadeforeachargumentindependently,
ignoringtheglobalinformationacrossargumentsintheﬁnaloutput.Thepurpose
oftheinferencestageistoincorporatesuchinformation,includingbothlinguistic
andstructuralknowledge,suchas“argumentsdonotoverlap”or“eachverbtakes
atmostoneargumentofeachtype.”Thisknowledgeisusefultoresolveanyincon-
sistenciesofargumentclassiﬁcationinordertogenerateﬁnallegitimatepredictions.
Wedesignaninferenceprocedurethatisformalizedasaconstrainedoptimization
problem,representedasanintegerlinearprogram(RothandYih2004).Ittakesas
inputtheargumentclassiﬁers’conﬁdencescoresforeachtypeofargument,along
withalistofconstraints.Theoutputistheoptimalsolutionthatmaximizesthelin-
earsumoftheconﬁdencescores,subjecttotheconstraintsthatencodethedomain
knowledge.
Theinferencestagecanbenaturallyextendedtocombinetheoutputofseveral
differentSRLsystems,aswewillshowinSection5.Inthissectionweﬁrstintroduce
theconstraintsandformalizetheinferenceproblemforthesemanticrolelabelingtask.
Wethendemonstratehowweapplyintegerlinearprogramming(ILP)togeneratethe
globallabelassignment.
3.4.1 Constraints
over Argument Labeling.Formally,theargumentclassiﬁersattemptto
assignlabelstoasetofarguments,S
1:M,indexedfrom1toM.EachargumentS
i
cantake
anylabelfromasetofargumentlabels,P,andtheindexedsetofargumentscantakea
setoflabels,c
1:M
∈ P
M
.Ifweassumethattheclassiﬁersreturnascorescore(S
i
=c
i
)that
correspondstothelikelihoodofargumentS
i
beinglabeledc
i
then,givenasentence,the
unalteredinferencetaskissolvedbymaximizingtheoverallscoreofthearguments,
ˆc
1:M
=argmax
c
1:M
∈P
M
score(S
1:M
=c
1:M
)=argmax
c
1:M
∈P
M
M
summationdisplay
i=1
score(S
i
=c
i
)(1)
Inthepresenceofglobalconstraintsderivedfromlinguisticinformationandstruc-
turalconsiderations,oursystemseekstooutputalegitimatelabelingthatmaximizesthis
score.Speciﬁcally,itcanbethoughtofasifthesolutionspaceislimitedthroughtheuse
ofaﬁlterfunction,F,whicheliminatesmanyargumentlabelingsfromconsideration.
266
Punyakanok,Roth,andYih ImportanceofParsingandInferenceinSRL
Here,weareconcernedwithglobalconstraintsaswellasconstraintsonthearguments.
Therefore,theﬁnallabelingbecomes
ˆc
1:M
= argmax
c
1:M
∈F(P
M
)
M
summationdisplay
i=1
score(S
i
=c
i
)(2)
Whentheconﬁdencescorescorrespondtotheconditionalprobabilitiesestimatedby
theargumentclassiﬁers,thevalueoftheobjectivefunctionrepresentstheexpected
numberofcorrectargumentpredictions.Hence,thesolutionofEquation(2)istheone
thatmaximizesthisexpectedvalueamongalllegitimateoutputs.
Theﬁlterfunctionusedconsidersthefollowingconstraints:
1
1. Argumentscannotoverlapwiththepredicate.
2. Argumentscannotexclusivelyoverlapwiththeclauses.
3. Ifapredicateisoutsideaclause,itsargumentscannotbeembeddedin
thatclause.
4. Nooverlappingorembeddingarguments.
Thisconstraintholdsbecausesemanticargumentsarelabeledon
non-embeddingconstituentsinthesyntacticparsetree.Inaddition,as
deﬁnedintheCoNLL-2004and2005sharedtasks,thelegitimateoutputof
anSRLsystemmustsatisfythisconstraint.
5. Noduplicateargumentclassesforcorearguments,suchasA0–A5andAA.
Theonlyexceptioniswhenthereisaconjunctioninthesentence.For
example,
[
A0
I][
V
left][
A1
mypearls][
A2
tomydaughter]and[
A1
mygold][
A2
to
myson].
Despitethisexception,wetreatitasahardconstraintbecauseitalmost
alwaysholds.
6. IfthereisanR-argargument,thentherehastobeanargargument.Thatis,
ifanargumentisareferencetosomeotherargumentarg,thenthis
referencedargumentmustexistinthesentence.Thisconstraintisdirectly
derivedfromthedeﬁnitionofR-argarguments.
7. IfthereisaC-argargument,thentherehastobeanargargument;in
addition,theC-argargumentmustoccurafterarg.Thisisstricterthan
thepreviousrulebecausetheorderofappearancealsoneedstobe
considered.Similarly,thisconstraintisdirectlyderivedfromthedeﬁnition
ofC-argarguments.
8. Giventhepredicate,someargumentclassesareillegal(e.g.,predicate
stalkcantakeonlyA0orA1).Thisinformationcanbefoundin
PropBankFrames.
1Thereareotherconstraintssuchas“exactlyoneVargumentperclass,”or“V–A1–C-Vpattern”as
introducedbyPunyakanoketal.(2004).However,wedidnotﬁndthemparticularlyhelpfulinour
experiments.Therefore,weexcludethoseconstraintsinthepresentationhere.
267
ComputationalLinguistics Volume34,Number2
Thisconstraintcomesfromthefactthatdifferentpredicatestake
differenttypesandnumbersofarguments.Bycheckingthe
PropBankFrameﬁleofthetargetverb,wecanexcludesomecore
argumentlabels.
Notethatconstraints1,2,and3areactuallyimplementedintheargumentidentiﬁ-
cationstage(seeSection3.2).Inaddition,theyneedtobeexplicitlyenforcedonlywhen
fullparsinginformationisnotavailablebecausetheoutputofthepruningheuristics
neverviolatestheseconstraints.
Theoptimizationproblem(Equation(2))canbesolvedusinganILPsolverby
reformulatingtheconstraintsaslinear(in)equalitiesovertheindicatorvariablesthat
representthetruthvalueofstatementsoftheform[argumentitakeslabelj],asdescribed
indetailnext.
3.4.2 Using
Integer Linear Programming. Asdiscussedpreviously,acollectionofpo-
tential arguments is not necessarily a valid semantic labeling because it may not
satisfyalloftheconstraints.Weenforcealegitimatesolutionusingthefollowing
inferencealgorithm.Inourcontext,inferenceistheprocessofﬁndingthe best (ac-
cordingtoEquation(1))validsemanticlabelsthatsatisfyallofthespeciﬁedcon-
straints.Wetakeasimilarapproachtotheonepreviouslyusedforentity/relation
recognition(RothandYih2004),andmodelthisinferenceprocedureassolvinganILP
problem.
An integer linear program isa linear program withintegralvariables.Thatis,
thecostfunctionandthe(in)equalityconstraintsarealllinearintermsofthevariables.
Theonlydifferenceinanintegerlinearprogramisthatthevariablescanonlytake
integersastheirvalues.Inourinferenceproblem,thevariablesareinfactbinary.A
generalbinaryintegerlinearprogrammingproblemcanbestatedasfollows.
Givenacostvectorp ∈Rfractur
d,acollectionofvariablesu=(u
1,...,u
d
)andcostma-
tricesC
1
∈Rfractur
c
1
×Rfractur
d,C
2
∈Rfractur
c
2
×Rfractur
d,wherec
1
andc
2
arethenumbersofinequalityand
equalityconstraintsanddisthenumberofbinaryvariables,theILPsolutionu
∗
isthe
vectorthatmaximizesthecostfunction,
u
∗
=argmax
u∈{0,1}
d
p·u
subjectto
C
1
u ≥ b
1,andC
2
u=b
2
whereb
1
∈Rfractur
c
1,b
2
∈Rfractur
c
2,andforallu ∈{0,1}
d
.
To solve the problem of Equation (2) in this setting, we ﬁrst reformulate the
originalcostfunction
summationtext
M
i=1
score(S
i
=c
i
)asalinearfunctionoverseveralbinaryvari-
ables,andthenrepresenttheﬁlterfunctionFusinglinearinequalitiesandequalities.
Wesetupabijectionfromthesemanticlabelingtothevariablesetu.Thisisdone
bysettingutobeasetofindicatorvariablesthatcorrespondtothelabelsassignedtoar-
guments.Speciﬁcally,letu
ic
=[S
i
=c]betheindicatorvariablethatrepresentswhether
268
Punyakanok,Roth,andYih ImportanceofParsingandInferenceinSRL
ornottheargumenttypecisassignedtoS
i,andletp
ic
=score(S
i
=c).Equation(1)can
thenbewrittenasanILPcostfunctionas
argmax
u
ic
∈{0,1}:∀i∈[1,M],c∈P
M
summationdisplay
i=1
summationdisplay
c∈P
p
ic
u
ic
subjectto
summationdisplay
c∈P
u
ic
=1 ∀i ∈[1,M]
whichmeansthateachargumentcantakeonlyonetype.Notethatthisnewconstraint
comesfromthevariabletransformation,andisnotoneoftheconstraintsusedinthe
ﬁlterfunctionF.
Oftheconstraintslistedearlier,constraints1through3canbeevaluatedonaper-
argumentbasisand,forthesakeofefﬁciency,argumentsthatviolatetheseconstraints
areeliminatedevenbeforebeinggiventotheargumentclassiﬁer.Next,weshowhowto
transformtheconstraintsintheﬁlterfunctionintotheformoflinear(in)equalitiesover
uandusetheminthisILPsetting.ForamorecompleteexampleofthisILPformulation,
pleaseseeAppendixA.
Constraint 4: No overlapping or embedding.IfargumentsS
j
1,...,S
j
k
coverthesameword
inasentence,thenthisconstraintensuresthatatmostoneoftheargumentsisassigned
toanargumenttype.Inotherwords,atleastk−1argumentswillbethespecialclass
null.Ifthespecialclassnullisrepresentedbythesymbolφ,thenforeverysetofsuch
arguments,thefollowinglinearequalityrepresentsthisconstraint.
k
summationdisplay
i=1
u
j
i
φ
≥ k−1
Constraint 5: No duplicate argument classes. Withinthesameclause,severaltypesof
argumentscannotappearmorethanonce.Forexample,apredicatecanonlytakeone
A0.Thisconstraintcanberepresentedusingthefollowinginequality.
M
summationdisplay
i=1
u
iA0
≤1
Constraint 6: R-arg arguments. SupposethereferencedargumenttypeisA0andthe
referentialtypeisR-A0.Thelinearinequalitiesthatrepresentthisconstraintare:
∀m ∈{1,...,M}:
M
summationdisplay
i=1
u
iA0
≥ u
mR-A0
Ifthereareγreferentialtypes,thenthetotalnumberofinequalitiesneededisγM.
Constraint 7: C-argarguments.Thisconstraintissimilartothereferenceargumentcon-
straints.ThedifferenceisthatthecontinuedargumentarghastooccurbeforeC-arg.
269
ComputationalLinguistics Volume34,Number2
AssumethattheargumentpairisA0andC-A0,andargumentsaresortedbytheir
beginningpositions,i.e.,ifi < k,thepositionofthebeginningofS
j
k
isnotbeforethatof
thebeginningofS
j
i
.Thelinearinequalitiesthatrepresentthisconstraintare:
∀m ∈{2,...,M}:
m−1
summationdisplay
i=1
u
j
i
A0
≥ u
j
m
C-A0
Constraint 8: Illegal argument types.Givenaspeciﬁcverb,someargumenttypesshould
neveroccur.Forexample,mostverbsdonothaveargumentsA5.Thisconstraintis
representedbysummingallthecorrespondingindicatorvariablestobe0.
M
summationdisplay
i=1
u
iA5
=0
UsingILPtosolvethisinferenceproblemenjoysseveraladvantages.Linearcon-
straintsareverygeneral,andareabletorepresentanyBooleanconstraint(Gu´eret,Prins,
andSevaux2002).Table1summarizesthetransformationsofcommonconstraints(most
areBoolean),whicharerevisedfromGu´eret,Prins,andSevaux(2002),andcanbeused
forconstructingcomplicatedrules.
Previous approaches usually rely on dynamic programming to resolve non-
overlapping/embeddingconstraints(i.e.,Constraint4)whentheconstraintstructure
is sequential. However, they are not able to handle more expressive constraints
suchasthosethattakelong-distancedependenciesandcountingdependenciesinto
account(RothandYih2005).TheILPapproach,ontheotherhand,isﬂexibleenough
tohandlemoreexpressiveandgeneralconstraints.AlthoughsolvinganILPproblemis
NP-hardintheworstcase,withthehelpoftoday’snumericalpackages,thisproblem
canusuallybesolvedveryquicklyinpractice.Forinstance,inourexperimentsit
onlytookabout10minutestosolvetheinferenceproblemfor4,305sentences,using
Table1
Rulesofmappingconstraintstolinear(in)equalitiesforBooleanvariables.
Originalconstraint Linearform
exactlykofx
1,x
2,···,x
n
x
1
+x
2
+···+x
n
=k
atmostkofx
1,x
2,···,x
n
x
1
+x
2
+···+x
n
≤ k
atleastkofx
1,x
2,···,x
n
x
1
+x
2
+···+x
n
≥ k
a → ba≤ b
a=
¯
=1−b
a →
¯
+b ≤1
¯a → +b ≥1
a ↔ ba=b
a → b∧ca≤ banda ≤ c
a → b∨ ≤ b+c
b∧c → aa≥ b+c−1
b∨c → ≥(b+c)/2
a→atleastkofx
1,x
2,···,x
n
a ≤(x
1
+x
2
+···+x
n
)/k
Atleastkofx
1,x
2,···,x
n
→aa≥(x
1
+x
2
+···+x
n
−(k−1))/(n−(k−1))
270
Punyakanok,Roth,andYih ImportanceofParsingandInferenceinSRL
Xpress-MP(2004)runningonaPentium-III800MHzmachine.Notethatordinary
search methods (e.g., beam search) are not necessarily faster than solving an ILP
problemanddonotguaranteetheoptimalsolution.
4.TheImportanceofSyntacticParsing
Weexperimentallystudythesigniﬁcanceofsyntacticparsingbyobservingtheeffects
ofusingfullparsingandshallowparsinginformationateachstageofanSRLsystem.
Weﬁrstdescribe,inSection4.1,howwepreparethedata.Thecomparisonoffull
parsingandshallowparsingontheﬁrstthreestagesoftheprocessispresentedinthe
reverseorder(Sections4.2,4.3,4.4).Notethatinthefollowingsections,inaddition
totheperformancecomparisonatvariousstages,wepresentalsotheoverallsystem
performanceforthedifferentscenarios.Inallcases,theoverallsystemperformanceis
derivedaftertheinferencestage.
4.1ExperimentalSetting
WeusePropBankSections02through21astrainingdata,Section23astesting,and
Section24asavalidationsetwhennecessary.InordertoapplythestandardCoNLL
sharedtaskevaluationscript,oursystemconformstoboththeinputandoutputformat
deﬁnedinthesharedtask.
Thegoaloftheexperimentsinthissectionistounderstandtheeffectivecontribu-
tionoffullparsinginformationversusshallowparsinginformation(i.e.,usingonlythe
part-of-speechtags,chunks,andclauses).Inaddition,wealsocompareperformance
whenusingthecorrect(gold-standard)dataversususingautomaticparsedata.The
performanceismeasuredintermsofprecision,recall,andtheF
1
measure.Notethat
allthenumbersreportedheredonottakeintoaccounttheVargumentsasitisquite
trivialtopredictVand,hence,thisgivesoveroptimisticoverallperformanceifincluded.
Whendoingthecomparison,wealsocomputethe95%conﬁdenceintervalofF
1
us-
ingthebootstrapresamplingmethod(Noreen1989),andthedifferenceisconsidered
signiﬁcantifthecomparedF
1
liesoutsidethisinterval.Theautomaticfullparsetrees
arederivedusingCharniak’sparser(2001)(version0.4).Inautomaticshallowparsing,
theinformationisgeneratedbydifferentstate-of-the-artcomponents,includingaPOS
tagger(Even-ZoharandRoth2001),achunker(PunyakanokandRoth2001),anda
clauser(Carreras,M`arquez,andCastro2005).
4.2ArgumentClassiﬁcation
Toevaluatetheperformancegapbetweenfullparsingandshallowparsinginargument
classiﬁcation,weassumetheargumentboundariesareknown,andonlytrainclassiﬁers
toclassifythelabelsofthesearguments.Inthisstage,theonlydifferencebetweenthe
usesoffullparsingandshallowparsinginformationistheconstructionofphrase type,
head word,POStag of the head word,path,subcategorization,andsyntactic framefeatures.
AsdescribedinSection3.2.2,mostofthesefeaturescanbeapproximatedusingchunks
andclauses,withtheexceptionofthesyntacticframefeature.Itisunclearhowthis
featurecanbemimickedbecauseitreliesontheinternalstructureofafullparsetree.
Therefore,itdoesnothaveacorrespondingfeatureintheshallowparsingcase.
Table2reportstheexperimentalresultsofargumentclassiﬁcationwhenargument
boundariesareknown.Inthiscase,becausetheargumentclassiﬁerofourSRLsystem
doesnotoverpredictormissanyarguments,wedonotneedtotrainwithanullclass,
271
ComputationalLinguistics Volume34,Number2
Table2
Theaccuracyofargumentclassiﬁcationwhenargumentboundariesareknown.
FullParsing ShallowParsing
Gold 91.50±0.48 90.75±0.45
Auto 90.32±0.48 89.71±0.50
andwecansimplymeasuretheperformanceusingaccuracyinsteadofF
1
.Thetraining
examplesinclude90,352propositionswithatotalof332,381arguments.Thetestdata
contain5,246propositionsand19,511arguments.Asshowninthetable,althoughthe
full-parsingfeaturesaremorehelpfulthantheshallow-parsingfeatures,theperfor-
mancegapisquitesmall(0.75%ongold-standarddataand0.61%withtheautomatic
parsers).
Therathersmalldifferenceintheperformancebetweenargumentclassiﬁersusing
fullparsingandshallowparsinginformationalmostdisappearswhentheiroutputis
processedbytheinferencestage.Table3showstheﬁnalresultsinrecall,precision,and
F
1,whentheargumentboundariesareknown.Inallcases,thedifferencesinF
1
between
thefullparsing–basedandtheshallowparsing–basedsystemsarenotstatistically
signiﬁcant.
Conclusion. Whentheargumentboundariesareknown,theperformanceofthefull
parsing–basedSRLsystemisaboutthesameastheshallowparsing–basedSRLsystem.
4.3ArgumentIdentiﬁcation
Argumentidentiﬁcationisanimportantstagethateffectivelyreducesthenumberof
argumentcandidatesafterthepruningstage.Givenanargumentcandidate,anargu-
mentidentiﬁerisabinaryclassiﬁerthatdecideswhetherornotthecandidateshouldbe
consideredasanargument.Toevaluatetheinﬂuenceoffullparsinginformationinthis
stage,thecandidatelistusedhereistheoutputsofthepruningheuristicappliedonthe
gold-standardparsetrees.Theheuristicresultsinatotalnumberof323,155positiveand
686,887negativeexamplesinthetrainingset,and18,988positiveand39,585negative
examplesinthetestset.
Similar to the argument classiﬁcation stage, the only difference between full
parsing–andshallowparsing–basedsystemsisintheconstructionofsomefeatures.
Speciﬁcally,phrase type,head word,POStag of the head word,path,andsubcategorization
featuresareapproximatedusingchunksandclauseswhenthebinaryclassiﬁeristrained
usingshallowparsinginformation.
Table4reportstheperformanceoftheargumentidentiﬁeronthetestsetusing
thedirectpredictionsofthetrainedbinaryclassiﬁer.Therecallandprecisionofthe
Table3
Theoverallsystemperformancewhenargumentboundariesareknown.
FullParsing ShallowParsing
Prec Rec F
1
Prec Rec F
1
Gold 91.58 91.90 91.74±0.51 91.14 91.48 91.31±0.51
Auto 90.71 91.14 90.93±0.53 90.50 90.88 90.69±0.53
272
Punyakanok,Roth,andYih ImportanceofParsingandInferenceinSRL
Table4
Theperformanceofargumentidentiﬁcationafterpruning(basedonthegoldstandardfullparse
trees).
FullParsing ShallowParsing
Prec Rec F
1
Prec Rec F
1
Gold 96.53 93.57 95.03±0.32 93.66 91.72 92.68±0.38
Auto 94.68 90.60 92.59±0.39 92.31 88.36 90.29±0.43
fullparsing–basedsystemarearound2to3percentagepointshigherthantheshallow
parsing–basedsystemonthegold-standarddata.Asaresult,theF
1
scoreis2.5percent-
agepointshigher.Theperformanceonautomaticparsedataisunsurprisinglylower
butthedifferencebetweenthefullparsing–andtheshallowparsing–basedsystemsis
asobservedpreviously.Intermsofﬁlteringefﬁciency,around25%oftheexamplesare
predictedaspositive.Inotherwords,bothargumentidentiﬁersﬁlteroutaround75%
oftheargumentcandidatesafterpruning.
Becausetherecallintheargumentidentiﬁcationstagesetstheupper-boundthe
recallinargumentclassiﬁcation,thethresholdthatdetermineswhenexamplesare
predictedtobepositiveisusuallyloweredtoallowmorepositivepredictions.That
is,acandidateispredictedaspositivewhenitsprobabilityestimationislargerthan
thethreshold.Table5showstheperformanceoftheargumentidentiﬁerswhenthe
thresholdis0.1.
2
Becauseargumentidentiﬁcationisjustanintermediatestepinacompletesystem,
amorerealisticevaluationmethodistoseehoweachﬁnalsystemperforms.Usingan
argumentidentiﬁerwiththreshold=0.1(i.e.,Table5),Table6reportstheﬁnalresults
inrecall,precision,andF
1
.TheF
1
differenceis1.5pointswhenusingthegold-standard
data.However,whenautomaticparsersareused,theshallowparsing–basedsystemis,
infact,slightlybetter;althoughthedifferenceisnotstatisticallysigniﬁcant.Thismaybe
duetothefactthatchunkandclausepredictionsareveryimportanthere,andshallow
parsersaremoreaccurateinchunkorclausepredictionsthanafullparser(LiandRoth
2001).
Conclusion.Fullparsinginformationhelpsinargumentidentiﬁcation.However,when
theautomaticparsersareused,usingthefullparsinginformationmaynothavebetter
overallresultscomparedtousingshallowparsing.
4.4Pruning
Asshownintheprevioustwosections,theoverallperformancegapsoffullparsingand
shallowparsingaresmall.Whenautomaticparsersareused,thedifferenceislessthan1
pointinF
1
oraccuracy.Therefore,weconcludethatthemaincontributionoffullparsing
isinthepruningstage.Becausetheshallowparsingsystemdoesnothaveenoughin-
formationforthepruningheuristics,wetraintwoword-basedclassiﬁerstoreplacethe
pruningstage.Oneclassiﬁeristrainedtopredictwhetheragivenwordisthestart(S)of
2Thevaluewasdeterminedbyexperimentingwiththecompletesystemusingautomaticfullparsetrees,
onthedevelopmentset.Inourtests,loweringthethresholdinargumentidentiﬁcationalwaysleadsto
higheroverallrecallandloweroverallprecision.Asaresult,thegaininF
1
islimited.
273
ComputationalLinguistics Volume34,Number2
Table5
Theperformanceofargumentidentiﬁcationafterpruning(basedonthegold-standardfullparse
trees)andwiththreshold=0.1.
FullParsing ShallowParsing
Prec Rec F
1
Prec Rec F
1
Gold 92.13 95.62 93.84±0.37 88.54 94.81 91.57±0.42
Auto 89.48 94.14 91.75±0.41 86.14 93.21 89.54±0.47
Table6
Theoverallsystemperformanceusingtheoutputfromthepruningheuristics,appliedonthe
gold-standardfullparsetrees.
FullParsing ShallowParsing
Prec Rec F
1
Prec Rec F
1
Gold 86.22 87.40 86.81±0.59 84.14 85.31 84.72±0.63
Auto 84.21 85.04 84.63±0.63 86.17 84.02 85.08±0.63
anargument;theotherclassiﬁeristopredicttheend(E)ofanargument.Iftheproduct
ofprobabilitiesofapairofSandEpredictionsislargerthanapredeﬁnedthreshold,
thenthispairisconsideredasanargumentcandidate.Thethresholdusedherewas
obtainedbyusingthevalidationset.Bothclassiﬁersuseverysimilarfeaturestothose
usedbytheargumentidentiﬁerasexplainedinSection3.2,treatingthetargetwordas
aconstituent.Particularly,thefeaturesarepredicate,POStagofthepredicate,voice,
contextwords,POStagsofthecontextwords,chunkpattern,clauserelativeposition,
andshallow-path.TheheadwordanditsPOStagarereplacedbythetargetwordandits
POStag.ThecomparisonofusingtheclassiﬁersandtheheuristicsisshowninTable7.
Evenwithouttheknowledgeoftheconstituentboundaries,theclassiﬁersseem
surprisinglybetterthanthepruningheuristics.Usingeitherthegold-standarddataset
ortheoutputofautomaticparsers,theclassiﬁersachievehigherF
1
scores.Onepossible
reasonforthisphenomenonisthattheaccuracyofthepruningstrategyislimitedby
thenumberofagreementsbetweenthecorrectargumentsandtheconstituentsofthe
parsetrees.Table8summarizesthestatisticsoftheexamplesseenbybothstrategies.
Thepruningstrategyneedstodecidewhicharethepotentialargumentsamongallcon-
stituents.Thisstrategyisupper-boundedbythenumberofcorrectargumentsthatagree
withsomeconstituent.Ontheotherhand,theclassiﬁersdonothavethislimitation.The
numberofexamplestheyobserveisthetotalnumberofwordstobeprocessed,andthe
positiveexamplesarethoseargumentsthatareannotatedassuchinthedataset.
Table7
Theperformanceofpruningusingheuristicsandclassiﬁers.
FullParsing ClassiﬁerThreshold=0.04
Prec Rec F
1
Prec Rec F
1
Gold 25.94 97.27 40.96±0.51 29.58 97.18 45.35±0.83
Auto 22.79 86.08 36.04±0.52 24.68 94.80 39.17±0.79
274
Punyakanok,Roth,andYih ImportanceofParsingandInferenceinSRL
Table8
Statisticsofthetrainingandtestexamplesforthepruningstage.
Words Arguments Constituents Agreements
Gold Auto Gold Auto
Train 2,575,665 332,381 4,664,954 4,263,831 327,603 319,768
Test 147,981 19,511 268,678 268,482 19,266 18,301
TheAgreementscolumnshowsthenumberofargumentsthatmatchtheboundariesofsome
constituents.
Notethatbecauseeachverbisprocessedindependently,asentenceisprocessed
onceforeachverbinthesentence.Therefore,thewordsandconstituentsineach
sentencearecountedasmanytimesasthenumberofverbstobeprocessed.
Asbefore,inordertocomparethesystemsthatusefullparsingandshallow
parsinginformation,weneedtoseetheimpactontheoverallperformance.There-
fore,webuilttwosemanticrolesystemsbasedonfullparsingandshallowparsing
information.Thefullparsing–basedsystemfollowsthepruning,argumentidentiﬁca-
tion,argumentclassiﬁcation,andinferencestages,asdescribedearlier.Fortheshallow
parsingsystem,thepruningheuristicisreplacedbytheword-basedpruningclassi-
ﬁers,andtheremainingstagesaredesignedtouseonlyshallowparsingasdescribedin
previoussections.Table9showstheoverallperformanceofthetwoevaluationsystems.
Asindicatedinthetables,thegapinF
1
betweenfullparsingandshallowparsing–
basedsystemsenlargestomorethan11pointsonthegold-standarddata.Atﬁrstglance,
thisresultseemstocontradictourconclusioninSection4.3.Afterall,ifthepruning
stageofshallowparsingSRLsystemperformsequallywellorevenbetter,theoverall
performancegapinF
1
shouldbesmall.
Afterwecarefullyexaminedtheoutputoftheword-basedclassiﬁer,werealized
thatitﬁltersouteasycandidates,andleavesexamplesthataredifﬁculttothelater
stages.Speciﬁcally,theseargumentcandidatesoftenoverlapanddifferonlyinoneor
twowords.Ontheotherhand,thepruningheuristicbasedonfullparsingneveroutputs
overlappingcandidatesandconsequentlyprovidesinputthatiseasierforthenextstage
tohandle.Indeed,thefollowingargumentidentiﬁcationstageturnsouttobegoodin
discriminatingthesenon-overlappingcandidates.
Conclusion.Themostcrucialcontributionoffullparsingisinthepruningstage.The
internaltreestructuresigniﬁcantlyhelpsindiscriminatingargumentcandidates,which
makestheworkdonebythefollowingstageseasier.
Table9
Theoverallsystemperformance.
FullParsing ShallowParsing
Prec Rec F
1
Prec Rec F
1
Gold 86.22 87.40 86.81±0.59 75.34 75.28 75.31±0.76
Auto 77.09 75.51 76.29±0.76 75.48 67.13 71.06±0.80
275
ComputationalLinguistics Volume34,Number2
5.TheEffectofInference
Ourinferenceprocedureplaysanimportantroleinimprovingaccuracywhenthelocal
predictionsviolatetheconstraintsamongargumentlabels.Inthissection,weﬁrst
presenttheoverallsystemperformancewhenmostconstraintsarenotused.Wethen
demonstratehowtheinferenceprocedurecanbeusedtocombinetheoutputofseveral
systemstoyieldbetterperformance.
5.1InferencewithLimitedConstraints
Theinferencestageinoursystemarchitectureprovidesaprincipledwaytoresolve
conﬂictinglocalpredictions.Itisinterestingtoseewhetherthisprocedureimprovesthe
performancedifferentlyforthefullparsing–vs.theshallowparsing–basedsystem,as
wellasgold-standardvs.automaticparsinginput.
Table10showstheresultsofusingonlyconstraints1,2,3,and4.Asmentioned
previously,theﬁrstthreeconstraintsarehandledbeforetheargumentclassiﬁcation
stage.Constraint4,whichforbidsoverlappingorembeddingarguments,isrequired
inordertousetheofﬁcialCoNLL-2005evaluationscriptandisthereforekept.
BycomparingTable9withTable10,wecanseethattheeffectofaddingmore
constraintsisquiteconsistentoverthefoursettings.Precisionisimprovedby1to2per-
centagepointsbutrecallisdecreasedalittle.Asaresult,thegaininF
1
isabout0.5to1
point.Itisnotsurprisingtoseethislowerrecallandhigherprecisionphenomenonafter
theconstraintsdescribedinSection3.4.1areexamined.Mostconstraintspunishfalse
non-nulloutput,butdonotregulatefalsenullpredictions.Forexample,anassignment
thathastwoA1argumentsclearlyviolatesthenon-duplicationconstraint.However,if
anassignmenthasnopredictedargumentsatall,itstillsatisﬁesalltheconstraints.
5.2JointInference
TheempiricalstudyinSection4indicatesthattheperformanceofanSRLsystem
primarilydependsontheveryﬁrststage—pruning,whichisdirectlyderivedfrom
thefullparsetrees.Thisalsomeansthatinpracticethequalityofthesyntacticparser
isdecisivetothequalityoftheSRLsystem.Toimprovesemanticrolelabeling,one
possiblewayistocombinedifferentSRLsystemsthroughajointinferencestage,given
thatthesystemsarederivedusingdifferentfullparsetrees.
Totestthisidea,weﬁrstbuildtwoSRLsystemsthatuseCollins’sparser(Collins
1999)
3
andCharniak’sparser(Charniak2001),respectively.Infact,thesetwoparsers
havenoticeablydifferentoutputs.Applyingthepruningheuristicsontheoutputof
Collins’sparserproducesalistofcandidateswith81.05%recall.Althoughthisnumber
issigniﬁcantlylowerthanthe86.08%recallproducedbyCharniak’sparser,theunion
ofthetwocandidatelistsstillsigniﬁcantlyimprovesrecallto91.37%.Weconstructthe
twosystemsbyimplementingtheﬁrstthreestages,namely,pruning,argumentidentiﬁ-
cation,andargumentclassiﬁcation.Whenatestsentenceisgiven,ajointinferencestage
isusedtoresolvetheinconsistencyoftheoutputofargumentclassiﬁcationinthesetwo
systems.
Weﬁrstbrieﬂyreviewtheobjectivefunctionusedintheinferenceprocedurein-
troducedinSection3.4.Formallyspeaking,theargumentclassiﬁersattempttoassign
3WeusetheCollinsparserimplementedbyBikel(2004).
276
Punyakanok,Roth,andYih ImportanceofParsingandInferenceinSRL
Table10
Theimpactofremovingmostconstraintsinoverallsystemperformance.
FullParsing ShallowParsing
Prec Rec F
1
Prec Rec F
1
Gold 85.07 87.50 86.27±0.58 73.19 75.63 74.39±0.75
Auto 75.88 75.81 75.84±0.75 73.56 67.45 70.37±0.80
labelstoasetofarguments,S
1:M,indexedfrom1toM.EachargumentS
i
cantakeany
labelfromasetofargumentlabels, P,andtheindexedsetofargumentscantakea
setoflabels,c
1:M
∈ P
M
.Ifweassumethattheargumentclassiﬁerreturnsanestimated
conditionalprobabilitydistribution,Prob(S
i
=c
i
),then,givenasentence,theinference
procedureseeksaglobalassignmentthatmaximizestheobjectivefunctiondenotedby
Equation(2),whichcanberewrittenasfollows,
ˆc
1:M
= argmax
c
1:M
∈F(P
M
)
M
summationdisplay
i=1
Prob(S
i
=c
i
)(3)
wherethelinguisticandstructuralconstraintsarerepresentedbytheﬁlterF.Inother
words,thisobjectivefunctionreﬂectstheexpectednumberofcorrectargumentpredic-
tions,subjecttotheconstraints.
WhentherearetwoormoreargumentclassiﬁersfromdifferentSRLsystems,ajoint
inferenceprocedurecantaketheoutputestimatedprobabilitiesforallthesecandidates
asinput,althoughsomecandidatesmayrefertothesamephrasesinthesentence.For
example,Figure3showsthetwocandidatesetsforafragmentofasentence,...,traders
say,unableto cool thesellingpanicinbothstocksandfutures.Inthisexample,systemAhas
twoargumentcandidates,a
1
=tradersanda
4
=thesellingpanicinbothstocksandfutures;
systemBhasthreeargumentcandidates,b
1
=traders,b
2
=thesellingpanic,andb
3
=in
bothstocksandfutures.
Astraightforwardsolutiontothecombinationistotreateachargumentproduced
byasystemasapossibleoutput.Eachpossiblelabelingoftheargumentisassociated
withavariablewhichisthenusedtosetuptheinferenceprocedure.However,theﬁnal
predictionwillbelikelydominatedbythesystemthatproducesmorecandidates,which
issystemBinthisexample.Thereasonisthatourobjectivefunctionisthesumofthe
probabilitiesofallthecandidateassignments.
Thisbiascanbecorrectedbythefollowingobservation.AlthoughsystemAonly
hastwocandidates,a
1
anda
4,itcanbetreatedasifitalsohastwoadditionalphantom
candidates,a
2
anda
3,wherea
2
andb
2
refertothesamephrase,andsodoa
3
andb
3
.
Similarly,systemBhasaphantomcandidateb
4
thatcorrespondstoa
4
.BecausesystemA
doesnotreallygeneratea
2
anda
3,wecanassumethatthesetwophantomcandidatesare
predictedbyitas“null”(i.e.,notanargument).Weassignthesamepriordistributionto
eachphantomcandidate.Inparticular,theprobabilityofthe“null”classissettobe0.55
basedonempiricaltests,andtheprobabilitiesoftheremainingclassesaresetbasedon
theiroccurrencefrequenciesinthetrainingdata.
Then,wetreateachpossibleﬁnalargumentoutputasasingleunit.Eachprobability
estimationbyasystemcanbeviewedasevidenceintheﬁnalprobabilityestimationand,
therefore,wecansimplyaveragetheirestimation.Formally,letS
i
betheargumentset
277
ComputationalLinguistics Volume34,Number2
Figure3
TheoutputoftwoSRLsystems:systemAhastwocandidates,a
1
=tradersanda
4
=theselling
panicinbothstocksandfutures;systemBhasthreeargumentcandidates,b
1
=traders,b
2
=the
sellingpanic,andb
3
=inbothstocksandfutures.Inaddition,wecreatetwophantomcandidatesa
2
anda
3
forsystemAthatcorrespondtob
2
andb
3
respectively,andb
4
forsystemBthat
correspondstoa
4
.
outputbysystemi,andS =
uniontext
k
i=1
S
i
bethesetofallargumentswherekisthenumber
ofsystems;letNbethecardinalityofS.Ouraugmentedobjectivefunctionisthen:
ˆc
1:N
= argmax
c
1:N
∈F(P
N
)
N
summationdisplay
i=1
Prob(S
i
=c
i
)(4)
whereS
i
∈ S,and
Prob(S
i
=c
i
)=
1
k
k
summationdisplay
j=1
Prob
j
(S
i
=c
i
)(5)
whereProb
j
istheprobabilityoutputbysystemj.
Notethatwemayalsotreattheindividualsystemsdifferentlybyapplyingdifferent
priors(i.e.,weights)ontheestimatedprobabilitiesoftheargumentcandidates.For
example,iftheperformanceofsystemAismuchbetterthansystemB,thenwemay
wantto trust systemA’soutputmorebymultiplyingtheoutputprobabilitiesbya
largerweight.
Table11reportstheperformanceoftwoindividualsystemsbasedonCollins’s
parserandCharniak’sparser,aswellasthejointsystem,wherethetwoindividual
systemsareequallyweighted.Thejointsystembasedonthisstraightforwardstrategy
signiﬁcantlyimprovestheperformancecomparedtothetwooriginalSRLsystemsin
bothrecallandprecision,andthusachievesamuchhigherF
1
.
6.EmpiricalEvaluation—CoNLLSharedTask2005
Inthissection,wepresentthedetailedevaluationofourSRLsystem,inthecompeti-
tiononsemanticrolelabeling—theCoNLL-2005sharedtask(CarrerasandM`arquez
278
Punyakanok,Roth,andYih ImportanceofParsingandInferenceinSRL
Table11
TheperformanceofindividualandcombinedSRLsystems.
Prec Rec F
1
Collins’parser 75.92 71.45 73.62±0.79
Charniak’sparser 77.09 75.51 76.29±0.76
Combinedresult 80.53 76.94 78.69±0.71
2005).Thesettingofthissharedtaskisbasicallythesameasitwasin2004,with
someextensions.First,itallowsmuchrichersyntacticinformation.Inparticular,full
parse trees generated using Collins’s parser (Collins 1999) and Charniak’s parser
(Charniak2001)wereprovided.Second,thefull parsing standard partitionwasused—
thetrainingsetwasenlargedandcoveredSections02–21,thedevelopmentsetwas
Section24,andthetestsetwasSection23.Finally,inadditiontotheWall Street Journal
(WSJ)data,threesectionsoftheBrowncorpuswereusedtoprovidecross-corpora
evaluation.
ThesystemweusedtoparticipateintheCoNLL-2005sharedtaskisanenhanced
versionofthesystemdescribedinSections3and5.Themaindifferencewasthat
thejoint-inferencestagewasextendedtocombinesixbasicSRLsystemsinsteadof
two.Speciﬁcallyforthisimplementation,weﬁrsttrainedtwoSRLsystemsthatuse
Collins’sparserandCharniak’sparser,respectively,becauseoftheirnoticeablydif-
ferentoutputs.Inevaluation,weranthesystemthatwastrainedwithCharniak’s
parserﬁvetimes,withthetop-5parsetreesoutputbyCharniak’sparser.Togetherwe
havesixdifferentoutputsperpredicate.Foreachparsetreeoutput,werantheﬁrst
threestages,namely,pruning,argumentidentiﬁcation,andargumentclassiﬁcation.
Then,ajoint-inferencestage,whereeachindividualsystemisweightedequally,was
usedtoresolvetheinconsistencyoftheoutputofargumentclassiﬁcationinthese
systems.
Table12showstheoverallresultsonthedevelopmentsetanddifferenttestsets;the
detailedresultsonWSJsection23areshowninTable13.Table14showstheresultsof
individualsystemsandtheimprovementgainedbythejointinferenceprocedureonthe
developmentset.
OursystemreachedthehighestF
1
scoresonallthetestsetsandwasthebestsystem
amongthe19participatingteams.Afterthecompetition,weimprovedthesystem
slightlybytuningtheweightsoftheindividualsystemsinthejointinferenceprocedure,
wheretheF
1
scoresonWSJtestsectionandtheBrowntestsetare79.59pointsand67.98
points,respectively.
Table12
OverallCoNLL-2005sharedtaskresults.
Prec. Rec. F
1
Development 80.05 74.83 77.35
TestWSJ 82.28 76.78 79.44
TestBrown 73.38 62.93 67.75
TestWSJ+Brown 81.18 74.92 77.92
279
ComputationalLinguistics Volume34,Number2
Table13
DetailedCoNLL-2005sharedtaskresultsontheWSJtestset.
TestWSJ Prec. Rec. F
1
Overall 82.28 76.78 79.44
A0 88.22 87.88 88.05
A1 82.25 77.69 79.91
A2 78.27 60.36 68.16
A3 82.73 52.60 64.31
A4 83.91 71.57 77.25
AM-ADV 63.82 56.13 59.73
AM-CAU 64.15 46.58 53.97
AM-DIR 57.89 38.82 46.48
AM-DIS 75.44 80.62 77.95
AM-EXT 68.18 46.88 55.56
AM-LOC 66.67 55.10 60.33
AM-MNR 66.79 53.20 59.22
AM-MOD 96.11 98.73 97.40
AM-NEG 97.40 97.83 97.61
AM-PNC 60.00 36.52 45.41
AM-TMP 78.16 76.72 77.44
R-A0 89.72 85.71 87.67
R-A1 70.00 76.28 73.01
R-A2 85.71 37.50 52.17
R-AM-LOC 85.71 57.14 68.57
R-AM-TMP 72.34 65.38 68.69
Intermsofthecomputationtime,forboththeargumentidentiﬁerandtheargument
classiﬁer,thetrainingofeachmodel,excludingfeatureextraction,takes50–70minutes
usinglessthan1GBmemoryona2.6GHzAMDmachine.Onthesamemachine,the
averagetesttimeforeachstage,excludingfeatureextraction,isaround2minutes.
7.RelatedWork
Thepioneeringworkonbuildinganautomaticsemanticrolelabelerwasproposed
byGildeaandJurafsky(2002).Intheirsetting,semanticrolelabelingwastreatedasa
taggingproblemoneachconstituentinaparsetree,solvedbyatwo-stagearchitecture
consistingofanargumentidentiﬁerandanargumentclassiﬁer.Thisissimilartoour
Table14
Theresultsofindividualsystemsandtheresultwithjointinferenceonthedevelopmentset.
Prec. Rec. F
1
Charniak-1 75.40 74.13 74.76
Charniak-2 74.21 73.06 73.63
Charniak-3 73.52 72.31 72.91
Charniak-4 74.29 72.92 73.60
Charniak-5 72.57 71.40 71.98
Collins 73.89 70.11 71.95
Jointinference 80.05 74.83 77.35
280
Punyakanok,Roth,andYih ImportanceofParsingandInferenceinSRL
mainarchitecturewiththeexclusionofthepruningandinferencestages.Thereare
two additional key differences between their system and ours. First, their system
usedaback-offprobabilisticmodelasitsmainengine.Second,itwastrainedon
FrameNet(Baker,Fillmore,andLowe1998)—anotherlargecorpus,besidesPropBank,
thatcontainsselectedexamplesofsemanticallylabeledsentences.
Laterthatyear,thesameapproachwasappliedonPropBankbyGildeaandPalmer
(2002).Theirsystemachieved57.7%precisionand50.0%recallwithautomaticparse
trees,and71.1%precisionand64.4%recallwithgold-standardparsetrees.Itisworth
noticingthatatthattimethePropBankprojectwasnotﬁnishedandthedataset
availablewasonlyafractioninsizeofwhatitistoday.Sincethesepioneeringworks,the
taskhasgainedincreasingpopularityandcreatedanewlineofresearch.Thetwo-step
constituent-by-constituentarchitecturebecameacommonblueprintformanysystems
thatfollowed.
PartlyduetotheexpansionofthePropBankdataset,researchershavegradually
madeimprovementontheperformanceofautomaticSRLsystemsbyusingnewtech-
niquesandnewfeatures.SomeoftheearlysystemsaredescribedinChenandRambow
(2003),GildeaandHockenmaier(2003),andSurdeanuetal.(2003).Allarebasedona
two-stagearchitecturesimilartotheoneproposedbyGildeaandPalmer(2002)with
thedifferencesinthemachine-learningtechniquesandthefeaturesused.Theﬁrst
breakthroughintermsofperformancewasduetoPradhanetal.(2003),whoﬁrst
viewedthetaskasamassiveclassiﬁcationproblemandappliedmultipleSVMstoit.
Theirﬁnalresult(afterafewmoreimprovements)reportedinPradhanetal.(2004)
achieved84%and75%inprecisionandrecall,respectively.
Asecondsigniﬁcantcontributionbeyondthetwo-stagearchitectureisduetoXue
andPalmer(2004),whointroducedthepruningheuristicstothetwo-stagearchitecture,
andremarkablyreducedthenumberofcandidateargumentsasystemneedstocon-
sider;thisapproachwasadoptedbymanysystems.Anothersigniﬁcantadvancement
wasintherealizationthatglobalinformationcanbeexploitedandbeneﬁtstheresults
signiﬁcantly.Inferencebasedonanintegerlinearprogrammingtechnique,whichwas
originallyintroducedbyRothandYih(2004)onarelationextractionproblem,was
ﬁrstappliedtotheSRLproblembyPunyakanoketal.(2004).Itshowedthatdomain
knowledgecanbeeasilyencodedandcontributessigniﬁcantlythroughinferenceover
theoutputofclassiﬁers.Theideaofexploitingglobalinformation,whichisdetailedin
thispaper,waspursuedlaterbyotherresearchers,indifferentforms.
Besidestheconstituent-by-constituentbasedarchitecture,othershavealsobeen
explored.Thealternativeframeworksincluderepresentingsemanticrolelabelingas
asequence-taggingproblem(M`arquez,PereComas,andCatal`a2005)andtaggingthe
edgesinthecorrespondingdependencytrees(Hacioglu2004).However,themostpop-
ulararchitecturebyfaristheconstituent-by-constituentbasedmulti-stagearchitecture,
perhapsduetoitsconceptualsimplicityanditssuccess.IntheCoNLL-2005shared
taskcompetition(CarrerasandM`arquez2005),themajorityofthesystemsfollowed
theconstituent-by-constituentbasedtwo-stagearchitecture,andtheuseofthepruning
heuristicswasalsofairlycommon.
TheCoNLL-2005sharedtaskalsohighlightedtheimportanceofsystemcombina-
tion,suchasourILPtechniquewhenusedinjointinference,inordertoachievesuperior
performance.Thetopfoursystems,whichproducedsigniﬁcantlybetterresultsthanthe
rest,allusedsomeschemestocombinetheoutputofseveralSRLsystems,rangingfrom
usingaﬁxedcombinationfunction(Haghighi,Toutanova,andManning2005;Koomen
etal.2005)tousingamachine-learnedcombinationstrategy(M`arquez,PereComas,
andCatal`a2005;Pradhan,Hacioglu,Wardetal.2005).
281
ComputationalLinguistics Volume34,Number2
TheworkofGildeaandPalmer(2002)pioneerednotonlythefundamentalarchi-
tectureofSRL,butwasalsotheﬁrsttoinvestigatetheinterestingquestionregarding
thesigniﬁcanceofusingfullparsingforhighqualitySRL.Theycomparedtheirfull
systemwithanothersystemthatonlyusedchunking,andfoundthatthechunk-based
systemperformedmuchworse.Theprecisionandrecalldroppedfrom57.7%and
50.0%to27.6%and22.0%,respectively.Thatledtotheconclusionthatfullparsing
informationisnecessarytosolvingtheSRLproblem,especiallyatthestageofargu-
mentidentiﬁcation—aﬁndingthatisquitesimilartooursinthisarticle.However,
theirchunk-basedapproachwasveryweak—onlychunkswereconsideredaspossible
candidates;hence,itisnotverysurprisingthattheboundariesoftheargumentscould
notbereliablyfound.Incontrast,ourshallowparse–basedsystemdoesnothavethese
restrictionsontheargumentboundariesandthereforeperformsmuchbetteratthis
stage,providingamorefaircomparison.
ArelatedcomparisoncanbefoundalsointheworkbyPradhan,Hacioglu,Krugler
etal.(2005)(theirearlierversionappearedinPradhanetal.[2003]),whichreported
theperformanceonseveralsystemsusingdifferentinformationsourcesandsystem
architectures.Theirshallowparse–basedsystemismodeledasasequencetaggingprob-
lemwhilethefullsystemisaconstituent-by-constituentbasedtwo-stagesystem.Due
totechnicaldifﬁculties,though,theyreportedtheresultsofthechunk-basedsystems
onlyonasubsetofthefulldataset.Theirshallowparse–basedsystemachieved60.4%
precisionand51.4%recallandtheirfullsystemachieved80.6%precisionand67.1%
recallonthesamedataset(but84%precisionand75%recallwiththefulldataset).
Therefore,duetotheuseofdifferentarchitecturesanddatasetsizes,thequestions
of“howmuchonecangainfromfullparsingovershallowparsingwhenusingthe
fullPropBankdataset”and“whatarethesourcesoftheperformancegain”wereleft
open.
Similarly,intheCoNLL-2004sharedtask(CarrerasandM`arquez2004),participants
wereaskedtodevelopSRLsystemswiththerestrictionthatonlyshallowparsinginfor-
mation(i.e.,chunksandclauses)wereallowed.Theperformanceofthebestsystemwas
at72.43%precisionand66.77%recall,whichwasabout10pointsinF
1
lowerthanthe
bestsystembasedonfullparsingintheliterature.However,thetrainingexampleswere
derivedfromonly5sectionsandnotallthe19sectionsusuallyusedinthestandard
setting.Hence,thequestionwasnotyetfullyanswered.
Ourexperimentalstudy,ontheotherhand,isdonewithaconsistentarchitecture,
byconsideringeachstageinacontrolledmanner,andusingthefulldataset,allowing
onetodrawdirectconclusionsregardingtheimpactofthisinformationsource.
8.Conclusion
Thispaperstudiestheimportanttaskofsemanticrolelabeling.Wepresentedanap-
proachtoSRLandaprincipledandgeneralapproachtoincorporatingglobalinforma-
tioninnaturallanguagedecisions.Beyondpresentingthisapproachwhichleadstoa
state-of-the-artSRLsystem,wefocusedoninvestigatingthesigniﬁcanceofusingfull
parsetreeinformationasinputtoanSRLsystemadheringtothemostcommonsystem
architecture,andthestagesintheprocesswherethisinformationhasthemostimpact.
Weperformedadetailedandfairexperimentalcomparisonbetweenshallowandfull
parsinginformationandconcludedthat,indeed,fullsyntacticinformationcanimprove
theperformanceofanSRLsystem.Inparticular,wehaveshownthatthisinformation
ismostcrucialinthepruningstageofthesystem,andrelativelylessimportantinthe
followingstages.
282
Punyakanok,Roth,andYih ImportanceofParsingandInferenceinSRL
Inaddition,weshowedtheimportanceofglobalinferencetogoodperformancein
thistask,characterizedbyrichstructuralandlinguisticconstraintsamongthepredicted
labelsofthearguments.Ourintegerlinearprogramming–basedinferenceprocedure
isapowerfulandﬂexibleoptimizationstrategythatﬁndsthebestsolutionsubjectto
theseconstraints.Aswehaveshown,itcanbeusedtoresolveconﬂictingargument
predictionsinanindividualsystembutcanalsoserveasaneffectiveandsimple
approachtocombiningdifferentSRLsystems,resultinginasigniﬁcantimprovement
inperformance.
Inthefuture,weplantoextendourworkinseveraldirections.Byaddingmore
constraints to the inference procedure, an SRL system may be further improved.
Currently,theconstraintsareprovidedbyhumanexpertsinadvance.Learningboth
hardandstatisticalconstraintsfromthedatawillbeourtoppriority.Someworkon
combiningstatisticalanddeclarativeconstraintshasalreadystartedandisreported
inRothandYih(2005).Anotherissuewewanttoaddressisdomainadaptation.
IthasbeenclearlyshownintheCoNLL-2005sharedtaskthattheperformanceof
currentSRLsystemsdegradessigniﬁcantlywhentestedonacorpusdifferentfrom
theoneusedintraining.Thismaybeduetotheunderlyingcomponents,especially
thesyntacticparserswhichareverysensitivetochangesindatagenre.Developing
abettermodelthatmorerobustlycombinesthesecomponentscouldbeapromising
direction.Inaddition,althoughtheshallowparsing–basedsystemwasshownhereto
beinferior,shallowparserswereshowntobemorerobustthanfullparsers(Liand
Roth2001).Therefore,combiningthesetwosystemsmaybringforwardbothoftheir
advantages.
AppendixA:AnILPFormulationforSRL
Inthissection,weshowacompleteexampleoftheILPformulationformulatedtosolve
theinferenceproblemasdescribedinSection3.4.
Example. Assume the sentence is four words long with the following argument
candidates,andthefollowingillegalargumenttypesforthepredicateofinterest.
Sentence: w
1
w
2
w
3
w
4
Candidates: [ S
1
][S
2
][S
3
][S
5
]
[ S
4
]
Illegalargumenttypes: A3,A4,A5
Indicator Variables and Their Costs.Thefollowingsaretheindicatorvariablesandtheir
associatedcostssetupfortheexample.
IndicatorVariables:
u
1A0,u
1A1,...,u
1AM-LOC,...,u
1C-A0,...,u
1R-A0,...,u
1φ
u
2A0,u
2A1,...,u
2AM-LOC,...,u
2C-A0,...,u
2R-A0,...,u
2φ
.
.
.
u
5A0,u
5A1,...,u
5AM-LOC,...,u
5C-A0,...,u
5R-A0,...,u
5φ
Costs:
p
1A0,p
1A1,...,p
1AM-LOC,...,p
1C-A0,...,p
1R-A0,...,p
1φ
p
2A0,p
2A1,...,p
2AM-LOC,...,p
2C-A0,...,p
2R-A0,...,p
2φ
.
.
.
p
5A0,p
5A1,...,p
5AM-LOC,...,p
5C-A0,...,p
5R-A0,...,p
5φ
283
ComputationalLinguistics Volume34,Number2
ObjectiveFunction.Theobjectivefunctioncanbewrittenasthefollowing.
argmax
u
ic
∈{0,1}:∀i∈[1,5],c∈P
summationtext
5
i=1
summationtext
c∈P
p
ic
u
ic
where
P ={A0,A1,...,AM-LOC,...,C-A0,...,R-A0,...,φ}
subjectto
u
1A0
+u
1A1
+...+u
1AM-LOC
+...+u
1C-A0
+...+u
1R-A0
+...+u
1φ
= 1
u
2A0
+u
2A1
+...+u
2AM-LOC
+...+u
2C-A0
+...+u
2R-A0
+...+u
2φ
= 1
.
.
.
u
5A0
+u
5A1
+...+u
5AM-LOC
+...+u
2C-A0
+...+u
5R-A0
+...+u
5φ
= 1
AdditionalConstraints.Therestoftheconstraintscanbeformulatedasthefollowing.
Constraint4:Nooverlappingorembedding
u
3φ
+u
4φ
≥ 1
u
4φ
+u
5φ
≥ 1
Constraint5:Noduplicateargumentclasses
u
1A0
+u
2A0
+...+u
5A0
≤ 1
u
1A1
+u
2A1
+...+u
5A1
≤ 1
u
1A2
+u
2A2
+...+u
5A2
≤ 1
Constraint6:R-argarguments
u
1A0
+u
2A0
+...+u
5A0
≥ u
1R-A0
u
1A0
+u
2A0
+...+u
5A0
≥ u
2R-A0
.
.
.
u
1A0
+u
2A0
+...+u
5A0
≥ u
5R-A0
u
1A1
+u
2A1
+...+u
5A1
≥ u
1R-A1
.
.
.
u
1AM-LOC
+u
2AM-LOC
+...+u
5AM-LOC
≥ u
1R-AM-LOC
.
.
.
Constraint7:C-argarguments
u
1A0
≥ u
2C-A0
u
1A0
+u
2A0
≥ u
3C-A0
.
.
.
u
1A0
+u
2A0
+...+u
4A0
≥ u
5C-A0
u
1A1
≥ u
2C-A1
.
.
.
u
1AM-LOC
≥ u
2C-AM-LOC
.
.
.
284
Punyakanok,Roth,andYih ImportanceofParsingandInferenceinSRL
Constraint8:Illegalargumenttypes
u
1A3
+u
2A3
+...+u
5A3
= 0
u
1A4
+u
2A4
+...+u
5A4
= 0
u
1A5
+u
2A5
+...+u
5A5
= 0
Acknowledgments
WethankXavierCarrerasandLlu´ısM`arquez
forthedataandscripts,Szu-tingYiforher
helpinimprovingourjointinference
procedure,andNickRizzoloaswellasthe
anonymousreviewersfortheircomments
andsuggestions.WearealsogratefultoDash
Optimizationforthefreeacademicuseof
Xpress-MPandAMDfortheirequipment
donation.Thisresearchissupportedbythe
AdvancedResearchandDevelopment
Activity(ARDA)’sAdvancedQuestion
AnsweringforIntelligence(AQUAINT)
Program,aDOIgrantundertheReﬂex
program,NSFgrantsITR-IIS-0085836,
ITR-IIS-0085980,andIIS-9984168,
EIA-0224453,andanONRMURIAward.
References
Baker,CollinF.,CharlesJ.Fillmore,and
JohnB.Lowe.1998.TheBerkeleyFramenet
project.InProceedingsofCOLING-ACL,
pages86–90,Montreal,Canada.
Bikel,DanielM.2004.IntricaciesofCollins’
parsingmodel.ComputationalLinguistics,
30(4):479–511.
Bishop,ChristopherM.,1995.Neural
NetworksforPatternRecognition,chapter
6.4:Modellingconditionaldistributions,
page215.OxfordUniversityPress,
Oxford,UK.
Carlson,AndrewJ.,ChadM.Cumby,JeffL.
Rosen,andDanRoth.1999.TheSNoW
learningarchitecture.TechnicalReport
UIUCDCS-R-99-2101,UIUCComputer
ScienceDepartment.
Carreras,XavierandLl´uisM`arquez.2004.
IntroductiontotheCoNLL-2004shared
tasks:Semanticrolelabeling.InProceedings
ofCoNLL-2004,pages89–97,Boston,MA.
Carreras,XavierandLl´uisM`arquez.2005.
IntroductiontotheCoNLL-2005shared
task:Semanticrolelabeling.InProceedings
oftheNinthConferenceonComputational
NaturalLanguageLearning(CoNLL-2005),
pages152–164,AnnArbor,MI.
Carreras,Xavier,Ll´uisM`arquez,andJorge
Castro.2005.Filtering–rankingperceptron
learningforpartialparsing.Machine
Learning,60:41–71.
Carreras,Xavier,Ll´uisM`arquez,Vasin
Punyakanok,andDanRoth.2002.
Learningandinferenceforclause
identiﬁcation.InProceedingsofthe13th
EuropeanConferenceonMachineLearning
(ECML-2002),pages35–47,Helsinki,
Finland.
Charniak,Eugene.2001.Immediate-head
parsingforlanguagemodels.In
Proceedingsofthe39thAnnualMeetingofthe
AssociationofComputationalLinguistics
(ACL-2001),pages116–123,Toulouse,
France.
Chen,JohnandOwenRambow.2003.Useof
deeplinguisticfeaturesfortherecognition
andlabelingofsemanticarguments.In
Proceedingsofthe2003Conferenceon
EmpiricalMethodsinNaturalLanguage
Processing(EMNLP-2003),pages41–48,
Sapporo,Japan.
Collins,Michael.1999.Head-driven
StatisticalModelsforNaturalLanguage
Parsing.Ph.D.thesis,ComputerScience
Department,UniversityofPennsylvania,
Philadelphia,PA.
Dagan,Ido,YaelKarov,andDanRoth.
1997.Mistake-drivenlearningintext
categorization.InProceedingsofthe
SecondConferenceonEmpiricalMethods
inNaturalLanguageProcessing
(EMNLP-1997),pages55–63,
Providence,RI.
Even-Zohar,YairandDanRoth.2001.A
sequentialmodelformulti-class
classiﬁcation.InProceedingsofthe2001
ConferenceonEmpiricalMethodsinNatural
LanguageProcessing(EMNLP-2001),
pages10–19,Pittsburgh,PA.
Freund,YoavandRobertE.Schapire.1999.
Largemarginclassiﬁcationusingthe
Perceptronalgorithm.MachineLearning,
37(3):277–296.
Gildea,DanielandJuliaHockenmaier.2003.
Identifyingsemanticrolesusing
combinatorycategorialgrammar.In
Proceedingsofthe2003Conferenceon
EmpiricalMethodsinNaturalLanguage
Processing(EMNLP-2003),pages57–64,
Sapporo,Japan.
Gildea,DanielandDanielJurafsky.2002.
Automaticlabelingofsemanticroles.
ComputationalLinguistics,28(3):245–288.
285
ComputationalLinguistics Volume34,Number2
Gildea,DanielandMarthaPalmer.2002.
Thenecessityofparsingforpredicate
argumentrecognition.InProceedings
ofthe40thAnnualMeetingofthe
AssociationofComputationalLinguistics
(ACL-2002),pages239–246,
Philadelphia,PA.
Golding,AndrewR.andDanRoth.1999.
AWinnowbasedapproachto
context-sensitivespellingcorrection.
MachineLearning,34(1-3):107–130.
Grove,AdamJ.andDanRoth.2001.Linear
conceptsandhiddenvariables.Machine
Learning,42(1–2):123–141.
Gu´eret,Christelle,ChristianPrins,andMarc
Sevaux.2002.ApplicationsofOptimization
withXpress-MP.DashOptimization.
TranslatedandrevisedbySusanne
Heipcke.http://www.dashoptimization.
com/home/downloads/book/booka4.pdf.
Hacioglu,Kadri.2004.Semanticrolelabeling
usingdependencytrees.InProceedingsof
the20thInternationalConferenceon
ComputationalLinguistics(COLING),
Geneva,Switzerland.
Hacioglu,Kadri,SameerPradhan,Wayne
Ward,JamesH.Martin,andDaniel
Jurafsky.2004.Semanticrolelabelingby
taggingsyntacticchunks.InProceedingsof
CoNLL-2004,pages110–113,Boston,MA.
Haghighi,Aria,KristinaToutanova,and
ChristopherD.Manning.2005.Ajoint
modelforsemanticrolelabeling.In
ProceedingsoftheNinthConferenceon
ComputationalNaturalLanguage
Learning(CoNLL-2005),pages173–176,
AnnArbor,MI.
Kingsbury,PaulandMarthaPalmer.2002.
FromTreebanktoPropBank.InProceedings
ofLREC-2002,LasPalmas,CanaryIslands,
Spain.
Kipper,Karin,MarthaPalmer,andOwen
Rambow.2002.ExtendingPropBankwith
VerbNetsemanticpredicates.In
ProceedingsofWorkshoponApplied
Interlinguas,Tiburon,CA.
Koomen,Peter,VasinPunyakanok,Dan
Roth,andWen-tauYih.2005.Generalized
inferencewithmultiplesemanticrole
labelingsystems.InProceedingsoftheNinth
ConferenceonComputationalNatural
LanguageLearning(CoNLL-2005),
pages181–184,AnnArbor,MI.
Levin,Beth.1993.EnglishVerbClassesand
Alternations:APreliminaryInvestigation.
UniversityofChicagoPress,Chicago.
Levin,BethandMalkaR.Hovav.1996.From
lexicalsemanticstoargumentrealization.
Unpublishedmanuscript.
Li,XinandDanRoth.2001.Exploring
evidenceforshallowparsing.In
ProceedingsofCoNLL-2001,pages107–110,
Toulouse,France.
Marcus,MitchellP.,MaryAnn
Marcinkiewicz,andBeatriceSantorini.
1993.Buildingalargeannotatedcorpusof
English:ThePennTreebank.Computational
Linguistics,19(2):313–330.
M`arquez,Ll´uis,JesusGim´enezPereComas,
andNeusCatal`a.2005.Semanticrole
labelingassequentialtagging.In
ProceedingsoftheNinthConferenceon
ComputationalNaturalLanguage
Learning(CoNLL-2005),pages193–196,
AnnArbor,MI.
Noreen,EricW.1989.Computer-Intensive
MethodsforTestingHypotheses.NewYork:
JohnWiley&Sons.
Palmer,Martha,DanielGildea,andPaul
Kingsbury.2005.Thepropositionbank:An
annotatedcorpusofsemanticroles.
ComputationalLinguistics,31(1):71–106.
Pradhan,Sameer,KadriHacioglu,Valerie
Krugler,WayneWard,JamesH.Martin,
andDanielJurafsky.2005.Supportvector
learningforsemanticargument
classiﬁcation.MachineLearning,60:11–39.
Pradhan,Sameer,KadriHacioglu,Wayne
Ward,JamesH.Martin,andDaniel
Jurafsky.2003.Semanticroleparsing
addingsemanticstructureto
unstructuredtext.InProceedingsofthe
3rdIEEEInternationalConferenceonData
Mining(ICDM2003),pages629–632,
Melbourne,FL.
Pradhan,Sameer,KadriHacioglu,Wayne
Ward,JamesH.Martin,andDaniel
Jurafsky.2005.Semanticrolechunking
combiningcomplementarysyntactic
views.InProceedingsoftheNinthConference
onComputationalNaturalLanguage
Learning(CoNLL-2005),pages217–220,
AnnArbor,MI.
Pradhan,Sameer,WayneWard,Kadri
Hacioglu,JamesH.Martin,andDaniel
Jurafsky.2004.Shallowsemanticparsing
usingsupportvectormachines.In
ProceedingsofNAACL-HLT2004,
pages233–240,Boston,MA.
Punyakanok,Vasin,DanRoth,Wen-tauYih,
andDavZimak.2004.Semanticrole
labelingviaintegerlinearprogramming
inference.InProceedingsthe20th
InternationalConferenceonComputational
Linguistics(COLING),pages1346–1352,
Geneva,Switzerland.
Punyakanok,VasinandDanRoth.2001.The
useofclassiﬁersinsequentialinference.In
286
Punyakanok,Roth,andYih ImportanceofParsingandInferenceinSRL
ToddK.Leen,ThomasG.Dietterich,and
VolkerTresp,editors,AdvancesinNeural
InformationProcessingSystems13,
pages995–1001.MITPress.
Roth,Dan.1998.Learningtoresolve
naturallanguageambiguities:Auniﬁed
approach.InProceedingsoftheFifteenth
NationalConferenceonArtiﬁcial
Intelligence(AAAI-98),pages806–813,
Madison,WI.
Roth,DanandWen-tauYih.2004.Alinear
programmingformulationforglobal
inferenceinnaturallanguagetasks.In
ProceedingsofCoNLL-2004,pages1–8,
Boston,MA.
Roth,DanandWen-tauYih.2005.Integer
linearprogramminginferencefor
conditionalrandomﬁelds.InProceedingsof
the22ndInternationalConferenceonMachine
Learning(ICML-2005),pages737–744,
Bonn,Germany.
Surdeanu,Mihai,SandaHarabagiu,John
Williams,andPaulAarseth.2003.Using
predicate-argumentstructuresfor
informationextraction.InProceedingsofthe
41stAnnualMeetingonAssociationfor
ComputationalLinguistics,pages8–15,
Sapporo,Japan.
TjongKimSang,ErikF.andSabine
Buchholz.2000.Introductiontothe
CoNLL-2000sharedtask:Chunking.In
ProceedingsofCoNLL-2000andLLL-2000,
pages127–132,Lisbon,Portugal.
Xpress-MP.2004.DashOptimization.
Xpress-MP.http://www.
dashoptimization.com.
Xue,NianwenandMarthaPalmer.2004.
Calibratingfeaturesforsemanticrole
labeling.InProceedingsofthe2004
ConferenceonEmpiricalMethodsinNatural
LanguageProcessing(EMNLP-2004),
pages88–94,Barcelona,Spain.
Zhang,Tong,FredDamerau,andDavid
Johnson.2002.Textchunkingbasedona
generalizationofWinnow.Journalof
MachineLearningResearch,2:615–637.
287


