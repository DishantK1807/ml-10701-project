Managing Dialogue Interaction: A Multi-Layered Approach
Oliver Lemon
School of Informatics
University of Edinburgh
2 Buccleugh
Place
Edinburgh EH8 9LW, UK
olemon@inf.ed.ac.uk
Lawrence Cavedon
CSLI
Stanford University
220 Panama St
Stanford, CA 94306, USA
lcavedon@csli.stanford.edu
Barbara Kelly
Department of Linguistics
UCSB
Santa Barbara
CA 93106-3100, USA
bfk0@umail.ucsb.edu
Keywords: dialogue management architecture, in-
teraction, communication channel management
Abstract
We present evidence for the importance
of low-level phenomena in dialogue in-
teraction and use this to motivate a
multi-layered approach to dialogue pro-
cessing. We describe an architecture
that separates content-level communica-
tive processes from interaction-level phe-
nomena (such as feedback, grounding,
turn-management), and provide details of
speci c implementations of a number of
such phenomena.
1 Introduction
Real dialogue between human participants involves
phenomena that do not so much contribute to the
content of communication as relate directly to the
interactive process between the participants. This
includes turn management, providing feedback, ut-
terance  llers, error and false-start management, and
utterance timing.
Recent work on dialogue and natural language
processing in general has acknowledged the pres-
ence of such phenomena in natural speech, and in
some cases the importance of its role in dialogue in-
teraction. However, treatment of such phenomena
has generally been part of the standard processing
model; for example, some parsers are able to han-
dle  llers such as  um , while recent versions of the
TRIPS system (Allen et al., 2001) uses incremental
parsing and other techniques to handle a range of re-
lated phenomena.
We believe that greater focus on  interaction
level phenomena is appropriate and will lead to
bene ts in building dialogue systems for more ro-
bust natural interaction. In this paper, we outline a
two-layer architecture for dialogue systems, where
one layer uses a range of  shallow processing tech-
niques to maintain a smooth interaction between the
dialogue participants.
1.1 Managing
interaction
The inspiration for a clean separation into a two-
layer architecture comes from two sources. Clark
(1996) distinguishes between two separate commu-
nication tracks, which he calls communicative and
meta-communicative. These are simultaneously oc-
curring communications, the  rst dealing with the
information at hand, and the other relating to the
performance itself. Dialogue participants use what
Clark refers to as signals to refer to the performance
itself: e.g. timing, delays, re-phrasing, mistakes, re-
pairs, etc.1
A second motivation is work on architectures for
robots and autonomous agents embedded in com-
plex, dynamic, unpredictable environments. Sev-
eral researchers in this area have argued for multi-
layered architectures for agents that plan action se-
quences to achieve some goal or task, but need to
react quickly to change in the environment (e.g.
1Clark’s distinction does not necessarily carry over directly
to the design of a dialogue system architecture, but it motivates
focus on the low-level communication channel.
(Firby, 1994; Mcurrency1uller, 1996)). In such architectures,
the role of the bottom layer is to monitor the envi-
ronment and initiate appropriate actions within the
broader context of the goal-directed plan, which is
provided by the higher layer of the architecture. The
layers operate independently and asynchronously,
but communicate as necessary: e.g. goals and plans
are passed down to the execution layer, while obser-
vations or problems (which may trigger replanning)
are passed up to the planning layer.
We view the process of natural interaction with
a dialogue participant as analogous to the interac-
tion with a dynamic environment: dialogue phenom-
ena arise which need to be negotiated (as a new
obstacle must be avoided by a robot). In the case
of a human user involved in activity-oriented dia-
logue, timeliness is particularly important in order
to keep the user engaged and focussed otherwise,
performance of the joint activity may be adversely
affected. In particular, dialogic interaction is a con-
tinuous process which cannot be broken without the
risk of some breakdown: signal-level phenomena
must be handled as smoothly as possible, without
necessarily resorting to content-level processes, in
order to maintain a tight interaction between the par-
ticipants.
1.2 A
multi-layered architecture
Motivated partially by some of the same issues we
discuss here, Allen et al. (2001) describe a new ar-
chitecture for their TRIPS system that breaks dia-
logue management into multiple asynchronous com-
ponents. We concur with their concerns but focus on
a different architectural shift.
We outline below an architecture that sepa-
rates interaction-focussed techniques from context-
management and conversation planning. An initial
version of the architecture has been implemented at
the Center for the Study of Language and Informa-
tion (CSLI) at Stanford University.
This breakdown into separate architectural levels
is analogous to the multi-level agent/robot architec-
tures. However, many of the same motivations per-
tain, especially those related to design considera-
tions (e.g. separating different types of phenomena
into different layers) and performance (e.g. high-
level planning from low-level execution and mon-
itoring running in parallel2). Further, the manner
in which Mcurrency1uller and Firby’s systems handle reac-
tive tasks (e.g. obstacle avoidance, object tracking,
etc.) completely at the low-level whenever possible
re ects our view of how certain dialogue interaction
phenomena are best handled. Much like these sys-
tems, dialogue communicative goals are produced
at the higher level and imposed as constraints on
the lower-level. Environment-level processes  ll in
the detail of these goals and handle contingencies
which may otherwise prevent the achievement of
these goals.
A number of interaction-management techniques
are present in the current implementation, including:
a0 A back-up recognition pass, using statistical
processing to extend grammar-based coverage
and provide immediate user  help feedback
for unrecognized utterances (Hockey et al.,
2003);
a0 Turn management timing of system output is
governed by monitoring the speech channel and
the (prioritized) agenda of speech outputs. If
the system need to take the turn, it grabs it using
only low-level processing;
a0 Handling user barge-in user speech interrupts
system output and automatically grabs the turn;
a0 Immediate Grounding of recognized com-
mands (e.g. system says  OK immediately af-
ter recognizing the user:   y to the tower );
a0 NP selection  choosing anaphoric or salient
noun-phrases at the point of generation;
a0 Incremental aggregation of system-generated
utterances  appropriately condensing and
forming elliptical system output at the point of
generation.
While this accounts for only a small number of
signals that arise during natural dialogue, the ar-
chitecture provides a framework for incorporat-
ing further techniques in particular, using shallow
2Note: we are talking about very different parallel threads
here than those which occur in multi-modal fusion, such as oc-
curs in the SmartKom (Wahlster, 2002) system.
processing for making use of such signals to pro-
vide more natural and robust interactions between
dialogue systems and human participants.
In the next section, we describe work from the lin-
guistic and psychology literature that demonstrates
the importance of asynchronous interaction-level
processing. In Section 3, we propose a speci c ar-
chitecture that provides a framework for integrat-
ing various processes for channel-management. In
Sections 4 and 5, we describe speci cs of the CSLI
implementation, outlining  rst the more abstract di-
alogue management layer, followed by techniques
employed at the interaction layer. In Section 6, we
discuss further possibilities and in Section 7 we con-
clude.
2 The
Importance of Channel Phenomena
The standard processing model for dialogue systems
involves a sequence of modules from speech recog-
nition to speech synthesis, as illustrated in Figure 1,
which essentially illustrates (a simpli cation of) the
original TRIPS architecture, as described in (Fergu-
son and Allen, 1998). Typically, each module is self-
contained and relatively independent of other mod-
ules.
Recent  ndings in the psycholinguistic literature
have suggested various shortcomings of this mod-
ular approach. For example, work on alignment
indicates that conversation participants’ processing
interacts on multiple levels, contravening the strict
modular model (Pickering and Garrod, 2003). This
is one of the considerations we address below, but
we are primarily concerned with other interaction-
level phenomena.
One of our prime motivations for an interaction
level processing layer is to ensure timely response
to interaction. Parsing and processing takes time 
this can be alleviated by incremental parsing tech-
niques, but meta-communication signals typically
do not need to be interpreted and processed to the
same extent as communicative utterances, and in-
stead require immediate attention that precludes full
processing.
For example, researchers have looked at the use
of um and uh in conversation and found that these
are often used as place-holders for a speaker who
wants to maintain their speaking turn (Clark and Fox
Tree, 2002). The detection of  llers such as these
generally acts to inhibit (to some extent) the listener
from interrupting or taking the turn from the current
speaker. Hence, not only should such discontinu-
ities not be ignored but they must also be processed
immediately in order to maintain the ongoing inter-
action.
Conversely, listeners also use what is known as
back-channel feedback to indicate to the speaker that
they are listening and paying attention. For En-
glish, back-channels include uh-huh, mhm and yeah.
Back-channels differ from other devices used to
keep a conversation  owing, such as repetitions and
collaborative  nishes, in that they tend to be non-
speci c to the current utterance. Moreover, back-
channel feedback is often produced without think-
ing, in response to simple prosodic clues such as a
speaker pause, a lowering of speaker pitch, or a rise
in speaker intonation (Ward and Tsukahara, 1999).
Most importantly, however, back-channel feed-
back is important to the speaker.3 Bavelas et al.
(2000) investigated how a speaker in a conversation
(in this case someone narrating a story) is affected
when listener responses are inhibited. They found
that speakers with distracted and unresponsive lis-
teners did not  nish their stories effectively, measur-
ably faltering at what should have been the dramatic
ending. Speakers needed an interlocutor’s feedback
to be able to maintain  uency and continue the dia-
logue effectively. Bavelas et al also found that re-
sponse latency in one-on-one conversations is ex-
tremely short and may be simultaneous: listeners
can provide back-channels without fully listening to
the conversation partner and without being respon-
sible for taking up a speaking turn.
These results indicate that the nature of interac-
tion between participants is crucial to the collabora-
tive act of dialogue signals and feedback that carry
effectively no communicative content are still im-
portant for keeping the interaction smooth and to en-
sure that the participants stay attentive and focussed
on the task at hand. When the dialogue task involves,
say, a human user being guided through a safety-
critical activity by an automated system, then such
issues are of particular importance.
3Allwood (1995) refers to such feedback morphemes as the
most important cohesion device in spoken language.
Speech Input Speech Output 
Speech Recog Generation NL Parser Speech Synth Dialogue Manager 
Problem-Solving 
Manager Discourse context 
Figure 1: Traditional Dialogue System Architecture
Conversely, communicative behavior contains
signals regarding a participant’s attention, and in
particular may indicate a loss of focus. In tuto-
rial settings one of the dialogue applications we
are speci cally concerned with this can be used
to determine students’ con dence in their responses.
For example, phenomena such as timing between re-
sponses, hesitance markers, and intonation can all
be implicit clues that a student is having a problem
(Graesser et al., 1995).
3 A
Two-Level Architecture
The traditional architecture for dialogue systems ba-
sically involves a linear approach to processing, as
illustrated in Figure 1. In this standard architecture,
modules tend to be self-contained and only loosely
dependent. Evidence outlined above, particularly
that related to alignment, suggests that this tightly
encapsulated approach will deal poorly with the in-
teractive nature of real dialogue. Allen et al’s (2001)
revised TRIPS architecture introduces a more non-
linear approach to dialogue processing, with asyn-
chronous processes managing interpretation, gener-
ation, and interface to behavioral aspects.
We augment the TRIPS approach by combining
multiple processes for interpreting utterances (e.g.
structured parsing versus statistical techniques) and
for generating responses (e.g. generation from se-
mantic representation versus template-based). More
fundamental to the architectural distinction we pro-
pose, the processing of an utterance and generat-
ing an appropriate response may proceed without
full processing by the Dialogue Management com-
ponent: information gleaned from an utterance will
always be passed up to the Dialogue Manager, but to
ensure timely response, an appropriate response may
be produced directly from a low-level component.
Other processes included at the interaction layer de-
tect non-communicative information, such as gaps
or delays in the user’s speech.
Figure 2 illustrates various aspects of the speci c
two-level architecture we are developing. The lower
level interfaces directly with the user and, impor-
tantly, is driven by this interaction. For example the
low level includes a Turn Manager which manipu-
lates the speech channel to ensure that:
a0 user inputs are respected without interruption
(except when necessary);
a0 turn passes to the appropriate participant, based
on the highest priority Agenda item and the di-
alogue move that generated it;
a0 generated outputs are natural and timely;
a0 recognized user inputs are acknowledged
quickly using simple feedback utterances.
The upper level is responsible for modeling other
aspects of the conversational context, as well as
communicative goals and intentions. The con-
tent (i.e. logical forms) of user utterances are pro-
cessed using the dialogue model (e.g. updates and
adding nodes to the Dialogue Move Tree (Lemon et
al., 2002b)), and system utterances are constructed
which are in line with the system’s communicative
Dialogue 
Move 
Tree 
Activity 
Model 
Context 
Mgr Conversation Planner 
Agent 
intentions 
goals 
plans 
observations 
Content layer: 
utterance planning 
communicative intentions 
grounding 
content management 
interaction with agent arch 
Speech 
recogition 
and 
Parsing 
Backup 
Shallow 
Processor 
(Helper) 
Speech channel 
Turn 
Mgr 
TTS 
Generation 
Module Output 
Agenda 
Attention 
Monitor 
Interaction layer 
timing 
form 
engagement 
acknowledgement 
Generation: 
anaphora 
pronouns 
aggregation 
echoing 
ack 
Figure 2: System Architecture
goals and intentions, whether they be imparting in-
formation to the user or requesting clari cation or
further information.
The higher level also interacts with the rest of the
agent architecture, mediated by an Activity Model
(i.e. a representation of the agent activities about
which dialogue may occur (Gruenstein, 2002)). The
agent may wish to communicate its own goals, the
progress of its activities, or report on any observa-
tions it makes regarding its environment.
As with multi-layered agent architectures, the
two levels operate semi-autonomously and asyn-
chronously: the lower level is driven by tight in-
teraction with the user, while the upper level is
driven by longer-range communicative goals from
its activities and responses to user utterances. How-
ever, various types of information exchange connect
the two levels. For instance, user utterances rec-
ognized at the lower level must clearly be passed
to the content-management level to be parsed and
then incorporated into the dialogue context, while
high-level communication goals must be passed to
the lower level’s Output Agenda for generation and
speech-synthesis.
The Output Agenda plays a crucial role in medi-
ating utterances to be communicated, whether they
be system-initiated or responses, and generated from
the planner or a low-level component. The Output
Agenda is a prioritized list, where an utterance’s pri-
ority is in uenced by a number of factors, such as:
whether it is in response to an error or misunder-
standing (i.e.  Pardon ); the importance of the com-
municative content (i.e. an urgent observation); and
the dialogue move that generated it (e.g. answering a
question). The Agenda runs asynchronously, aggre-
gating multiple utterances when appropriate as well
as in uencing speaker turn (see below).
Of perhaps greater interest, the interaction level
can be used to monitor user engagement and at-
tention in other ways  e.g. time between utter-
ances, speaking rate, use of speech  llers  to de-
tect potential problems as soon as possible, and to
provide early warning to the content layer that the
user may have, for example, misunderstood some
instruction. This can be used to generate a clari -
cation or grounding sub-dialogue, in order to estab-
lish mutual understanding before proceeding (thus
improving robustness of the system as a whole).
Conversely, expectations at the upper-layer can
in uence processing at the interaction layer: for ex-
ample, open points of attachment on the Dialogue
Move Tree represent types of utterances the system
expects from the user, and these are used to prime
the recognition of incoming utterances for faster
processing, as well as in uencing the turn.
In engineering terms, this division of labour is
attractive in that the clarity and modularity of dia-
logue management is enhanced. Rather than con at-
ing, for example, turn-management with utterance
planning in a single generation component of a dia-
logue system, the separation into multiple levels of
processing allows different turn-taking and utterance
planning strategies to be developed independently,
and various combinations to be experimented with.
In the rest of the paper, we discuss our dialogue
management architecture and, in particular, the tech-
niques employed so far at each of the two levels de-
scribed here to enhance user experience and improve
overall system performance. The current implemen-
tation based on the above architecture is still being
re ned; we focus on the features that have already
been implemented.
4 Top-Level Context Management
The approach to dialogue modeling we have imple-
mented is based on the theory of dialogue games
(Carlson, 1983; Power, 1979), and, for task-oriented
dialogues, discourse segments (Grosz and Sidner,
1986). These accounts rely on the observation that
answers generally follow questions, commands are
usually acknowledged, and so on, so that dialogues
can be partially described as consisting of adjacency
pairs of such dialogue moves. The notion of  attach-
ment of dialogue moves on a Dialogue Move Tree
(DMT) (Lemon et al., 2002b) embodies this idea.
An Activity Tree represents hierarchical and tem-
poral information about the task-state of the dia-
logue. Activities are the joint tasks managed by the
dialogue: e.g. booking a  ight or moving a robot 
again, see (Lemon et al., 2002b) for details. Nodes
on the Activity Tree can be in various states (active,
complete, failed, a1a2a1a2a1 ), and any change in the state of
a node (typically because of an action by the agent)
is placed onto the system’s Output Agenda for po-
tential verbal report to the user, via the low-level
message selection and generation module.
This level of the architecture is where conversa-
tion planning and generation of system-initiated top-
ics occur. Any planned communication (whether it
be system-initiated or in response to a user utter-
ance) is put on to the Output Agenda, where it is
scheduled for generation.4 Conversely, true ground-
ing  i.e. acknowledging that an utterance is un-
derstood within the context of the rest of the dia-
logue  only occurs after the utterance has been in-
terpreted with respect to the DMT. Since a simple
acknowledgment may already have been generated
4The order in which outputs are generated, or even whether
they end up generated at all, depends on the priority of the cor-
responding information as well other interactions with the user.
after recognition, output after interpretation is only
needed if a response is required (e.g. the user asked
a question), or if a problem is detected (e.g. an am-
biguity must be resolved).
Since system communication is planned here, this
layer is also the one that interacts with the rest of the
agent architecture: any goals, state-changes, or ob-
servations that the agent may wish to communicate
are added as communicative goals, typically via the
Activity Model. For command-and-control applica-
tions (e.g. guiding a robot or UAV), system-initiated
utterances tend to be fairly short and simple and
conversation-planning is minimal; however, for our
dialogue-enabled tutorial application (Clark et al.,
2001), conversation-planning is quite complex and
the system may generate multiple, relatively long ut-
terances on its own initiative.
5 Low-level Conversation Management:
Maintaining the Communication
Channel
We currently employ a range of shallow processing
techniques to maintain a smooth interaction with the
human dialogue participant. By  shallow process-
ing we mean processing that does not necessarily
result in or concern itself with the semantic repre-
sentation or pragmatic interpretation of the utterance
in the context of the dialogue. In particular, informa-
tion at this level is not processed in the context of the
Dialogue Move Tree or the Activity Tree.
In the following, we describe a number of the low-
level processing techniques currently implemented
in our system. Future work will address more of the
interaction phenomena described earlier.
5.1 Case
study 1: Helper Feedback
In cases where a user utterance is not recognized, the
input is passed to a statistical recognizer of wider
coverage. This recognizer is often able to detect
lexical items and grammatical structures in the in-
put that are not covered by the  rst (grammar-based)
recognizer. In these cases, the results of the second
recognition pass are used to inform the user of the
system’s shortcomings, for example:  The system
heard you say ‘Look around for a red car’, but the
system does not know the word ‘around’. You could
say ‘Look for a red car’  .
None of these utterances is planned or represented
at the top level of dialogue management. They are
produced simply to inform the user of a communi-
cation breakdown and to try to keep the communi-
cation  owing. If the user were to indulge in meta-
dialogue about the help message, then that message
would need to be represented in the high-level con-
text. However, we present the help message as being
generated by a different  helper agent, which dis-
appears (from the GUI) as soon as the help message
is produced, thus discouraging the user from engag-
ing it in dialogue.
User tests have shown that the use of this low level
module (which can be installed independently of the
high-level dialogue manager) signi cantly improves
task completion (both percentage of tasks completed
and time taken). By the  fth task, 100% of users
with the helper completed the task as compared with
80% of those without, and those without the helper
took on average 53% longer to complete the tasks.
For full details of the evaluation see (Hockey et al.,
2003).
5.2 Case
study 2: Turn Taking
Here we use a turn-marker at the low-level of dia-
logue processing. The turn can be marked as user,
system or none, and is set in a variety of ways. If
the user begins to speak (start-of-speech signal is re-
ceived from the recognizer) the turn becomes user
and any system audio output is stopped. If the sys-
tem needs to take the turn (e.g. if it has urgent in-
formation it needs to communicate), but turn is set
to user, and the user is not speaking, the system will
output  Just a moment and so take the turn before
generating its required utterance. Again, note that
this turn-grabbing utterance is not planned or repre-
sented at the top-level of dialogue moves. It does
not need to enter into such high-level plans or rep-
resentations because it is required only in order to
manipulate and maintain the channel, and does not
carry any content of its own.
The demonstration system displays a turn marker
on the GUI, allowing observers to monitor the
changing possession of the turn.
5.3 Case
study 3: Incremental aggregation
Aggregation (Appelt, 1985) combines and com-
presses utterances to make them more concise, avoid
repetitious language structure, and make the sys-
tem’s speech more natural and understandable over-
all. In our system, this process is carried out not
at the level of content planning, but at the lower-
level of processing, where content logical forms are
manipulated (possibly combined) and converted into
strings for speech synthesis. Indeed, it is impor-
tant that aggregation functions at this lower level,
because the process needs access to:
a0 the message to be uttered (A),
a0 what has just been said (B),
a0 what is to be said next (C),
and the precise surface form of B is only represented
at the low-level. High-level processing only plans
the content of the utterance to be generated, and
passes it down, and so cannot determine the details
of the eventual surface form of the generated utter-
ance.
Aggregation techniques on a prewritten body of
text combine and compress sentences that have al-
ready been determined and ordered. In a complex
dialogue system however, aggregation should pro-
duce similarly natural output, but must function in-
crementally because utterances are generated on the
 y. In fact, when constructing an utterance we often
have no information about the utterances that will
follow it, and thus the best we can do is to com-
press it or  retro-aggregate it with utterances that
preceded it (see the example below). Only occasion-
ally does the Output Agenda contain enough unsaid
utterances to perform reasonable  pre-aggregation .
At the low-level of processing, the generator re-
ceives an item (on the Output Agenda) to be con-
verted into synthesized speech. This item consists
of a dialogue move type along with some content
(e.g. wh-answer, location(tower)).
Each dialogue move type (e.g. report, wh-
question, wh-answer) has its own aggregation rules,
stored in the class for that logical form (LF) type. In
each type, rules specify which other dialogue move
types can aggregate with it, and exactly how ag-
gregation works. The rules note identical portions
of LFs and unify them, and then combine the non-
identical portions appropriately.
For example, the LF that represents the phrase  I
will  y to the tower and I will land at the parking
lot , will be converted to one representing  I will  y
to the tower and land at the parking lot according
to the compression rules. Similarly,  I will  y to the
tower and  y to the hospital gets converted to  I
will  y to the tower and the hospital .
In contrast, the  retro-aggregation rules result in
sequences of system utterances such as,
Sys: I have cancelled flying to the base
Sys: and the tower
Sys: and landing at the school
Again, this process happens only at the low-level
processing stage of content realization, and needs
no access to the high-level representations of di-
alogue structure, history, and plans. A separate
thread running in the Output Agenda component
asynchronously performs aggregation as needed and
appropriate.
5.4 Case
study 4: Choosing NPs
Another low-level process in utterance realization is
choosing appropriate NPs  anaphoric expressions
such as  it or  there , or NPs which  echo those
already used by the human operator. Again, this rou-
tine does not need access to the high-level dialogue
management representations, but only to the list of
NPs employed in the dialogue thus far (the Salience
List).
Echoing is achieved by accessing the Salience
List whenever generating referential terms, and us-
ing whatever noun-phrase (if any) the user has pre-
viously employed to refer to the object in question.
Anaphoric phrases are generated whenever the ref-
erence object is the same as the one at the top of the
Salience List.
As in the case of aggregation, the top level content
generation algorithm does not manage the details of
utterance realization  this is better handled at the
instant that the content logical form is to be trans-
lated into a string for the speech synthesizer. Other-
wise the top level would have to replan utterances af-
ter every intervening dialogue move. This example
shows how respecting the multi-level architecture is
desirable from an engineering point of view.
6 Current
Implementation and Further
Possibilities
An initial version of the CSLI dialogue system based
on the described architecture has been implemented,
and is able to engage in conversations such as illus-
trated in Figure 3.
The system has been applied to both command-
and-control and tutorial applications; this is of inter-
est since the former generally involves user-initiated
conversations while in the latter, conversation tends
to be system-initiated. The Output Agenda me-
diates by handling both standard logical forms or
generation-templates.
Only a small number of the interaction-level phe-
nomena that arise in human-human dialogue have
been implemented, but we believe a number of them
could be treated within our framework. For in-
stance, processes at the lower level could detect mis-
communication and channel breakdown, and send a
request to the top level to replan the long-range dia-
logue strategy. This is particularly relevant in the tu-
torial setting, where low-level processes could detect
problems with user attention and responsiveness,
and prompt a switch to a different high-level strat-
egy. Particularly important for safety-critical appli-
cations, but of general use, would be low-level moni-
toring of channel noise and other environmental fac-
tors such as user gestures and gaze. Again, certain
combinations of these inputs would have high-level
consequences for interpretation and dialogue plan-
ning.
Recent work makes use of Icarus (Shapiro, 2001),
a reactive planning system that learns and adapts to
user behavior, to cover timing and realization of sys-
tem turns as well as handling delays in the user in-
put. In future, we anticipate that this will allow,
for instance, turn-taking facilities to be more eas-
ily adapted as personalities or situations require: for
example, after noticing a particular event the system
may be more likely to interrupt a speaker, or may
adapt to become less prone to interruption when in-
teracting with a speaker who responds poorly to sys-
tem barge-in.
7 Conclusion
We have presented evidence from the psycholinguis-
tic literature that demonstrates the importance of
Figure 3: Demonstration system, November 2002
Utterance Dialogue Move
Operator (O): Fly around the school Command
Helper (H): I heard you say  Fly around the school but the
system does not know the word  around . You could say   y
to the school 
Helper feedback
O: Fly to the school Command
Robot (R): OK. Con rmation
O: Then pick up the medical supplies at the hospital Take turn, Command
R: OK. Wait a minute Con rmation, System grab turn
R: I am supposed to always  y high Report Global Constraint
R: Shall I  y to the hospital at low altitude anyway? Negotiate constraint relaxation, Re-
lease Turn
O: Yes. Do it anyway Yn-Answer
R: OK. Wait a minute Con rmation, System grab turn
R: There is a  re at the tower Report observation
R: I am  ying to the hospital Report Current Activity
O: Why? Why-question, Release Turn
R: Because I am picking up the medical supa1a2a1a2a1 Why-Answer, User barge-in
O: Stop that. Command (Barge-in)
R: OK. I have cancelled  ying there Con rmation, Report Activity State,
Anaphoric NP
O: Fight the  re at the tower Command
R: OK. I am  ying to the lake Con rmation, Report Activity State
O: Why are you doing that? Why-question, Release Turn
R: Because I am picking up water there. Why-Answer, Anaphoric NP
interaction-level phenomena in dialogue. Phenom-
ena such as  llers, timing, and feedback must be
dealt with properly and in a timely manner; other-
wise, the interaction and even the collaborative ac-
tivity being performed may be adversely affected.
Our approach is to cleanly separate the architec-
ture of dialogue systems to provide for an asyn-
chronous layer that is designed to handle interaction
signals, analogously to agent/robot architectures that
include a layer to manage interaction with a dynamic
environment. This allows processing outside the full
context of a dialogue history when required for pro-
cessing speed, while allowing the context to still in-
 uence such processes when able.
A system has been implemented based on this
architecture, containing a range of low-level pro-
cesses, which we have described here in some detail:
shallow-helper feedback; turn-management; aggre-
gation; NP selection. Current work is directed to-
wards incorporating techniques to manage further
phenomena such as predictors of uncertainty and
loss of attention in both command-and-control and
tutoring applications.
Acknowledgements
This research was partially supported by the Wallen-
berg Foundation’s WITAS project, Linkcurrency1oping Uni-
versity, Sweden, and by grant number N00014-02-
1-0417 from the Department of the US Navy. The
dialogue system was implemented while the  rst au-
thor was employed at CSLI, Stanford University.

References

James F. Allen, Bradford W. Miller, Eric K. Ringger, and
Teresa Sikorski. 1996. A robust system for natural
spoken dialogue. In Proceedings of ACL.

James Allen, George Ferguson, and Amanda Stent. 2001.
An architecture for more realistic conversational sys-
tems. In Proceedings of Intelligent User Interfaces
2001, Santa Fe, NM.

Jens Allwood. 1995. An activity based approach to prag-
matics. In Gothenburg Papers in Theoretical Linguis-
tics 76, Dept. of Linguistics, Uni. of Gcurrency1oteborg.
Douglas E. Appelt. 1985. Planning english referring ex-
pressions. Arti cial Intelligence, 26(1):1  33.

J. B. Bavelas, L. Coates, and T. Johnson. 2000. Listeners
and co-narrators. Journal of Personality and Social
Psychology, 79:941 952.

Lauri Carlson. 1983. Dialogue Games: An Approach to
Discourse Analysis. D. Reidel.

Herbert H. Clark and Jean E. Fox Tree. 2002. Using uh
and um in spontaneous speaking. Cognition, 84:73 
111.

Brady Clark, John Fry, Matt Ginzton, Stanley Pe-
ters, Heather Pon-Barry, and Zachary Thomsen-Gray.
2001. Automated tutoring dialogues for training in
shipboard damage control. In Proceedings of SIGdial
2001.

Herbert H. Clark. 1996. Using Language. Cambridge
University Press.

George Ferguson and James Allen. 1998. TRIPS: An in-
telligent integrated problem-solving assistant. In Pro-
ceedings 15th National Conference on Arti cial Intel-
ligence (AAAI-98), pages 567 573, Madison, WI.
James Firby. 1994. Task networks for controlling con-
tinuous processes. In Proceedings 2nd Int’l Conf. on
AI Planning Systems, pages 49 54.

A. C. Graesser, N. K. Person, and J. P. Magliano. 1995.
Collaborative dialogue patterns in naturalistic one-to-
one tutoring. Applied Cognitive Psychology, 9:1 28.
Barbara Grosz and Candace Sidner. 1986. Attentions,
intentions, and the structure of discourse. Computa-
tional Linguistics, 12(3):175 204.

Alexander H. Gruenstein. 2002. Conversational inter-
faces: A domain-independent architecture for task-
oriented dialogues. Masters thesis, Computer Science
Department, Stanford University.

Beth-Ann Hockey, Oliver Lemon, Ellen Campana, Laura
Hiatt, Gregory Aist, Jim Hieronymus, Alexander Gru-
enstein, and John Dowding. 2003. Targeted help for
spoken dialogue systems: intelligent feed back im-
proves naive users’ performance. In Proceedings Eu-
ropean Assoc. for Computational Linguistics (EACL
03).

Oliver Lemon, Alexander Gruenstein, Alexis Battle, and
Stanley Peters. 2002a. Multi-tasking and collabo-
rative activities in dialogue systems. In Proceedings
of 3rd SIGdial Workshop on Discourse and Dialogue,
pages 113  124, Philadelphia.

Oliver Lemon, Alexander Gruenstein, and Stanley Pe-
ters. 2002b. Collaborative activities and multi-tasking
in dialogue systems. Traitement Automatique des
Langues (TAL), 43(2):131  154. Special Issue on Di-
alogue.

Jorge P. Mcurrency1uller. 1996. The Design of Intelligent Agents 
A Layered Approach. Springer Verlag, Heidelberg,
Germany.

Martin Pickering and Simon Garrod. 2003. Toward a
mechanistic psychology of dialogue. Brain and Be-
havioral Science. to appear.

Richard Power. 1979. The organization of purposeful
dialogues. Linguistics, 17:107 152.

Daniel Shapiro. 2001. Value-driven agents. Ph.D. thesis,
Department of Management Science and Engineering,
Stanford University.

Jan van Kuppevelt, Ulrich Heid, and Hans Kamp. 2000.
Best practice in spoken language dialogue system en-
gineering. Natural Language Engineering, 6.

Wolfgang Wahlster. 2002. SmartKom: fusion and  ssion
of speech, gestures, and facial expressions. In Pro-
ceedings of the 1st International Workshop on Man-
Machine Symbiotic Systems, pages 213 225, Kyoto,
Japan.

N. Ward and W. Tsukahara. 1999. A responsive dialog
system. In Y. Wilks, editor, Machine Conversations,
pages 169 174. Kluwer.

