This score is computed by considering four different features for each sentence as explained in (Pasca and Harabagiu, 2001).
P01-1037
Extraction The procedure for answer extraction that we used is reported in (Pasca and Harabagiu, 2001), it has 3 steps: Step 1) Identification of Relevant Sentences: The Knowledge about the semantic class of the expected answer generates two cases: (a) When the semantic class of the expected answers is known, all sentences from each paragraph, that contain a word identified by the Named Entity recognizer as having the same semantic classes as the expected answers, are extracted.
P01-1037
The basic Q/A system that we employed is based on the architecture described in (Pasca and Harabagiu, 2001), which is the current state-of-the-art.
P01-1037
To determine which word indicates the semantic class of the expected answer, the syntactic dependencies1 between the question words may be employed (Harabagiu 1Syntactic parsers publicly available, e.g., (Charniak, 2000; et al., 2000; Pasca and Harabagiu, 2001; Harabagiu et al., 2001).
A00-2018 C00-1043 P01-1037
Harabagiu. 2001.
P01-1037
Step 3) Answer Extraction: We select the top 5 ranked sentences and return them as Collins, 1997), can be used to capture the binary dependencies between the head of each phrase.
P97-1003
Q/A systems incorporate a paragraph retrieval engine, to find paragraphs that contain candidate answers, as reported in (Clark et al., 1999; Pasca and Harabagiu, 2001).
P01-1037
