<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>C S Butler</author>
</authors>
<title>Statistics in linguistics</title>
<publisher>Basil Blackwell</publisher>
<location>Oxford</location>
<marker>Butler, </marker>
<rawString>Butler, C. S.,1985. Statistics in linguistics, Oxford.: Basil Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chinchor</author>
</authors>
<title>Evaluating message understanding systems: an analysis of the third Message Understanding Conference (MUC-3</title>
<date>1993</date>
<journal>Computational Linguistics</journal>
<volume>19</volume>
<pages>409--449</pages>
<marker>Chinchor, 1993</marker>
<rawString>Chinchor, N., et al, 1993. &amp;quot;Evaluating message understanding systems: an analysis of the third Message Understanding Conference (MUC-3),&amp;quot; Computational Linguistics, vol. 19, no. 3, pp. 409-449.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
<author>W Gale</author>
</authors>
<title>Concordances for parallel text</title>
<date>1991</date>
<booktitle>in Proceedings of the Seventh Annual Conference of the UW Centre for the New OED and Text Research</booktitle>
<pages>40--62</pages>
<marker>Church, Gale, 1991</marker>
<rawString>Church, K. and Gale, W., 1991, &amp;quot;Concordances for parallel text,&amp;quot; in Proceedings of the Seventh Annual Conference of the UW Centre for the New OED and Text Research. pp. 40-62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Cormen</author>
</authors>
<title>Introduction to Algorithms</title>
<date>2001</date>
<volume>2</volume>
<editor>ed</editor>
<publisher>MIT Press</publisher>
<marker>Cormen, 2001</marker>
<rawString>Cormen, T., et al, 2001. Introduction to Algorithms, 2 ed. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R L Donaway</author>
</authors>
<title>A comparison of rankings produced by summarization evaluation measures</title>
<date>2000</date>
<booktitle>in Proceedings of NAACL-ANLP 2000 Workshop on Text Summarisation</booktitle>
<pages>69--78</pages>
<marker>Donaway, 2000</marker>
<rawString>Donaway, R. L., 2000. &amp;quot;A comparison of rankings produced by summarization evaluation measures,&amp;quot; in Proceedings of NAACL-ANLP 2000 Workshop on Text Summarisation.  pp. 69-78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>DUC</author>
</authors>
<title>The Document Understanding Conference. http://duc.nist.gov</title>
<date>2004</date>
<journal>Journal of the Association for Computing Machinery</journal>
<volume>16</volume>
<pages>264--285</pages>
<contexts>
<context> (Voorhees and Harman, 1999), Message Understanding Conferences (MUC) (Chinchor et al, 1993), TIPSTER SUMMAC Text Summarization Evaluation (Mani et al, 1998), Document Understanding Conference (DUC) (DUC, 2004), and Text Summarization Challenge (TSC) (Fukushima and Okumura, 2001), have attested the importance of this topic. The main difficulty in evaluating a summarization system is that there is not as ye</context>
</contexts>
<marker>DUC, 2004</marker>
<rawString>DUC, 2004. The Document Understanding Conference. http://duc.nist.gov/ Edmundson, H. P., 1969. &amp;quot;New methods in automatic abstracting,&amp;quot; Journal of the Association for Computing Machinery, vol. 16, no. 2, pp. 264-285.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Fukushima</author>
<author>M Okumura</author>
</authors>
<title>Text summarization challenge: text summarization in Japan</title>
<date>2001</date>
<booktitle>in Proceedings of NAACL 2001 Workshop Automatic Summarization</booktitle>
<pages>51--59</pages>
<contexts>
<context>Conferences (MUC) (Chinchor et al, 1993), TIPSTER SUMMAC Text Summarization Evaluation (Mani et al, 1998), Document Understanding Conference (DUC) (DUC, 2004), and Text Summarization Challenge (TSC) (Fukushima and Okumura, 2001), have attested the importance of this topic. The main difficulty in evaluating a summarization system is that there is not as yet, a clear definition for what constitutes a good summary. Another dif</context>
</contexts>
<marker>Fukushima, Okumura, 2001</marker>
<rawString>Fukushima, T. and Okumura, M., 2001. &amp;quot;Text summarization challenge: text summarization in Japan,&amp;quot; in Proceedings of NAACL 2001 Workshop Automatic Summarization. pp. 51-59.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T F Hand</author>
</authors>
<title>A proposal for task-based evaluation of text summarisation systems</title>
<date>1997</date>
<booktitle>in Proceedings of the ACL/EACL'97 Workshop on Intelligent Scalable Text Summarization</booktitle>
<pages>31--38</pages>
<marker>Hand, 1997</marker>
<rawString>Hand, T. F., 1997. &amp;quot;A proposal for task-based evaluation of text summarisation systems,&amp;quot; in Proceedings of the ACL/EACL'97 Workshop on Intelligent Scalable Text Summarization. pp. 31-38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kilgarriff</author>
</authors>
<title>Comparing corpora</title>
<date>2001</date>
<journal>International Journal of Corpus Linguistics</journal>
<volume>6</volume>
<pages>1--37</pages>
<marker>Kilgarriff, 2001</marker>
<rawString>Kilgarriff, A., 2001. &amp;quot;Comparing corpora,&amp;quot; International Journal of Corpus Linguistics, vol. 6, no. 1, pp. 1-37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C-Y Lin</author>
</authors>
<title>ROUGE: a package for automatic evaluation of summaries</title>
<date>2004</date>
<booktitle>in Proceedings of the Workshop on Text Summarization Branches Out (WAS</booktitle>
<contexts>
<context> Retrieval (IR)-metrics. The first method is called VERT-C and the second is called VERT-F. The idea for the name is derived from two previous systems, namely BLEU2 (Papineni et al, 2001) and ROUGE3 (Lin, 2004). 2.1 VERT-C: Chi-Square (χ2) Statistics This metric is based on the Chi-Square (χ2) goodness-of-fit test. This test measures whether or not 1 VERT stands for Valuation using Enhanced Rationale Techn</context>
<context>etary 2 1 (1.2) Total 57 35 Figure 1: An example of a contingency table 2.2 VERT-F: N-gram Matching N-gram matching procedures are used typically in linguistic pattern recognition models (e.g. ROUGE (Lin, 2004) and BLEU (Papineni et al, 2001)). Also, there is a considerable interest in machine translation in this context when cross-lingual patterns between source and target translation are matched to asses</context>
<context>evaluation metric must be assessed through correlation comparison between the automatic metric scores and human scores. This means that the automatic scores should correlate highly with human scores (Lin, 2004). If they do correlate, we can affirm that the automatic metric can be used to evaluate summaries. We believe that this criterion forms the fundamental ‘ground-truth’ for the evaluation of our two me</context>
</contexts>
<marker>Lin, 2004</marker>
<rawString>Lin, C-Y., 2004. &amp;quot;ROUGE: a package for automatic evaluation of summaries,&amp;quot; in Proceedings of the Workshop on Text Summarization Branches Out (WAS 2004).</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Mani</author>
</authors>
<title>The TIPSTER SUMMAC text summarisation evaluation: Final report</title>
<date>1998</date>
<booktitle>The MITRE Corporation. MTR 98W0000138</booktitle>
<marker>Mani, 1998</marker>
<rawString>Mani, I., et al, 1998. The TIPSTER SUMMAC text summarisation evaluation: Final report. The MITRE Corporation. MTR 98W0000138.</rawString>
</citation>
<citation valid="true">
<title>Networks assignment and transportation. [3]. The Open University</title>
<date>2001</date>
<institution>Open University</institution>
<contexts>
<context>is of Church and Gale (1991), where pairs of words in source and target texts were identified using the same test for a text of aligned corpora in source and target language. More recently Kilgarriff (2001) has used the test to compare two corpora. We have used the χ2 test to measure similarity between a text and its surrogate summary, following the procedure proposed by Siegel and Castellan (1988): We </context>
<context>ch that there are no hits in the same row or column. Double-counting is avoided through the use of the “maximum bipartite matching problem” (MBMP), which is discussed in graph theory (Open University (2001), Cormen, et al (2001)). In graph theory, a bipartite graph is a special graph where the set of vertices can be divided into two disjoint sets with two vertices of the same set never sharing an edge (</context>
</contexts>
<marker>2001</marker>
<rawString>Open University, 2001. Networks assignment and transportation. [3].  The Open University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Paice</author>
</authors>
<title>Constructing literature abstracts by computer: techniques and prospects</title>
<date>1990</date>
<booktitle>Information Processing and Management</booktitle>
<volume>26</volume>
<pages>171--186</pages>
<marker>Paice, 1990</marker>
<rawString>Paice, C. D., 1990. &amp;quot;Constructing literature abstracts by computer: techniques and prospects,&amp;quot; Information Processing and Management, vol. 26, no. 1, pp. 171-186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
</authors>
<title>BLEU: a Method for Automatic Evaluation of Machine Translation</title>
<date>2001</date>
<note>IBM Research Report RC22176</note>
<marker>Papineni, 2001</marker>
<rawString>Papineni, K., et al, 2001. BLEU: a Method for Automatic Evaluation of Machine Translation. IBM Research Report RC22176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Pedersen</author>
</authors>
<title>Significant lexical relationships</title>
<date>1996</date>
<booktitle>in Proceedings of 13th National Conference on Artificial Intelligence</booktitle>
<marker>Pedersen, 1996</marker>
<rawString>Pedersen, T., et al, 1996. &amp;quot;Significant lexical relationships,&amp;quot; in Proceedings of 13th National Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Radev</author>
</authors>
<title>Centroid-based summarization of multiple documents: sentence extraction, utility based evaluation, and user studies</title>
<date>2000</date>
<booktitle>in Proceedings of NAACL-ANLP 2000 Workshop on Text Summarisation</booktitle>
<pages>21--29</pages>
<marker>Radev, 2000</marker>
<rawString>Radev, D., 2000. &amp;quot;Centroid-based summarization of multiple documents: sentence extraction, utility based evaluation, and user studies,&amp;quot; in Proceedings of NAACL-ANLP 2000 Workshop on Text Summarisation. pp. 21-29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Saggion</author>
</authors>
<title>Developing Infrastructure for the Evaluation of Single and Multi-document Summarization Systems in a Cross-lingual Environment</title>
<date>2002</date>
<booktitle>in Proceedings of the Third International Conference On Language Resources And Evaluation (LREC</booktitle>
<pages>747--754</pages>
<marker>Saggion, 2002</marker>
<rawString>Saggion, H., et al, 2002. &amp;quot;Developing Infrastructure for the Evaluation of Single and Multi-document Summarization Systems in a Cross-lingual Environment,&amp;quot; in Proceedings of the Third International Conference On Language Resources And Evaluation (LREC 2002). pp. 747-754.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Salton</author>
<author>M J McGill</author>
</authors>
<title>Introduction to Modern Information Retrieval</title>
<date>1983</date>
<booktitle>Handbook of Parametric and Nonparametric Statistical Procedures</booktitle>
<volume>2</volume>
<editor>McGraw Hill, Sheskin, D. J</editor>
<marker>Salton, McGill, 1983</marker>
<rawString>Salton, G. and McGill, M. J., 1983. Introduction to Modern Information Retrieval, McGraw Hill, Sheskin, D. J., 2000. Handbook of Parametric and Nonparametric Statistical Procedures, 2 ed. Florida.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Siegel</author>
<author>Castellan Jr</author>
<author>N J</author>
</authors>
<title>Nonparametric Statistics for the Behavioral Sciences</title>
<date>1988</date>
<publisher>McGraw-Hill</publisher>
<location>New York</location>
<marker>Siegel, Jr, J, 1988</marker>
<rawString>Siegel, S. and Castellan Jr, N. J., 1988. Nonparametric Statistics for the Behavioral Sciences, New York: McGraw-Hill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J P Turian</author>
</authors>
<title>Evaluation of Machine Translation and its Evaluation</title>
<date>2003</date>
<booktitle>in Proceedings of MT Summit IX</booktitle>
<marker>Turian, 2003</marker>
<rawString>Turian, J. P., et al, 2003. &amp;quot;Evaluation of Machine Translation and its Evaluation,&amp;quot; in Proceedings of MT Summit IX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C van Rijsbergen</author>
</authors>
<date>1979</date>
<booktitle>Information Retrieval, 2nd ed</booktitle>
<location>London: Butterworths</location>
<marker>van Rijsbergen, 1979</marker>
<rawString>van Rijsbergen, C., 1979. Information Retrieval, 2nd ed. London: Butterworths.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E M Voorhees</author>
<author>D K Harman</author>
</authors>
<date>1999</date>
<booktitle>The Eight Text Retrieval Conference (TREC-8),&amp;quot; eds. National Institute of Standards and Technology (NIST</booktitle>
<contexts>
<context>? Research on summary evaluation over the last decades has tried to respond to these complex questions. In acknowledgment of this fact, a series of conferences like Text Retrieval Conferences (TREC) (Voorhees and Harman, 1999), Message Understanding Conferences (MUC) (Chinchor et al, 1993), TIPSTER SUMMAC Text Summarization Evaluation (Mani et al, 1998), Document Understanding Conference (DUC) (DUC, 2004), and Text Summar</context>
</contexts>
<marker>Voorhees, Harman, 1999</marker>
<rawString>Voorhees, E. M. and Harman, D. K., 1999. &amp;quot;The Eight Text Retrieval Conference (TREC-8),&amp;quot; eds. National Institute of Standards and Technology (NIST).</rawString>
</citation>
<citation valid="true">
<authors>
<author>E M Voorhees</author>
<author>D M Tice</author>
</authors>
<title>Overview of the TREC-9 question answering track</title>
<date>2000</date>
<booktitle>in Proceedings of the Ninth Text REtrieval Conference (TREC-9</booktitle>
<marker>Voorhees, Tice, 2000</marker>
<rawString>Voorhees, E. M. and Tice, D. M., 2000. &amp;quot;Overview of the TREC-9 question answering track.,&amp;quot; in Proceedings of the Ninth Text REtrieval Conference (TREC-9).</rawString>
</citation>
</citationList>
</algorithm>

