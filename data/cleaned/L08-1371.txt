<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>Blum</author>
<author>Mitchell</author>
</authors>
<title>Combining labelled and unlabelled data with co-training</title>
<date>1998</date>
<booktitle>In Proc. 11th Conference on Computational Learning Theory</booktitle>
<pages>92--100</pages>
<contexts>
<context>as input to a bootstrapping process that attempts to extend annotation coverage to the corpus as a whole. A number of techniques for combining labelled and unlabelled data exist. CO-TRAINING METHODS (Blum and Mitchell, 1998; Yarowsky, 1995) make crucial usage of redundant models of the data. A family of approaches known as ACTIVE LEARNING have also been developed, in which some of the unlabelled data are selected and ma</context>
</contexts>
<marker>Blum, Mitchell, 1998</marker>
<rawString>Blum and Mitchell. 1998. Combining labelled and unlabelled data with co-training. In Proc. 11th Conference on Computational Learning Theory,, pages 92–100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Burnard</author>
</authors>
<title>The British National Corpus reference guide</title>
<date>2000</date>
<tech>Technical report</tech>
<institution>Oxford University Computing Services</institution>
<location>Oxford</location>
<note>http://www.natcorp.ox.ac. uk/World/HTML/urg.html</note>
<contexts>
<context>orpora are too small. Unfortunately, the creation of 100M-plus corpora via hand-annotation is likely to be prohibitively expensive, as already realized by the creators of the British National Corpus (Burnard, 2000), much of whose annotation was done automatically. Such a large hand-annotation effort would be even less sensible in the case of semantic annotation tasks such as coreference or wordsense disambigua</context>
</contexts>
<marker>Burnard, 2000</marker>
<rawString>L. Burnard. 2000. The British National Corpus reference guide. Technical report, Oxford University Computing Services, Oxford. http://www.natcorp.ox.ac. uk/World/HTML/urg.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Diab</author>
<author>P Resnik</author>
</authors>
<title>An unsupervised method for word sense tagging using parallel corpora</title>
<date>2002</date>
<booktitle>In Proc. of ACL 2002</booktitle>
<location>Philadelphia</location>
<contexts>
<context>er than data which was labelled using automatic means such as EM or co-training. Finally, in the case of parallel corpora where one of the languages has already been annotated, projection techniques (Diab and Resnik, 2002) can be used to ‘transfer’ the annotation to other languages. None of these techniques however produces improvements comparable to those achievable with more annotated data. 2.2. Creating Resources f</context>
</contexts>
<marker>Diab, Resnik, 2002</marker>
<rawString>M. Diab and P. Resnik. 2002. An unsupervised method for word sense tagging using parallel corpora. In Proc. of ACL 2002, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Hovy</author>
<author>M Marcus</author>
<author>M Palmer</author>
<author>L Ramshaw</author>
<author>R Weischedel</author>
</authors>
<title>Ontonotes: the 90% solution</title>
<date>2006</date>
<booktitle>In Proc. HLT-NAACL</booktitle>
<contexts>
<context>onomous Language Exploitation GALE are beginning to change this situation through the creation of 1 Million word annotated corpora such as PropBank (Palmer et al., 2005) and the OntoNotes initiative (Hovy et al., 2006), but just at a time when the community begins to realize that even such corpora are too small. Unfortunately, the creation of 100M-plus corpora via hand-annotation is likely to be prohibitively expe</context>
</contexts>
<marker>Hovy, Marcus, Palmer, Ramshaw, Weischedel, 2006</marker>
<rawString>E. Hovy, M. Marcus, M. Palmer, L. Ramshaw, and R. Weischedel. 2006. Ontonotes: the 90% solution. In Proc. HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
<author>D Gildea</author>
<author>Kingsbury</author>
</authors>
<title>The proposition bank: A corpus annotated with semantic roles. Computational Linguistics</title>
<date>2005</date>
<contexts>
<context>xtraction and Summarization (TIDES), and Global Autonomous Language Exploitation GALE are beginning to change this situation through the creation of 1 Million word annotated corpora such as PropBank (Palmer et al., 2005) and the OntoNotes initiative (Hovy et al., 2006), but just at a time when the community begins to realize that even such corpora are too small. Unfortunately, the creation of 100M-plus corpora via h</context>
<context>ce or wordsense disambiguation, given, on one side, the greater difficulty of agreeing on a ‘neutral’ theoretical framework for the annotation, an essential prerequisite (see, e.g., discussion in (?; Palmer et al., 2005)); on the other, the difficulty of achieving more than moderate agreement on semantic judgments (Poesio and Artstein, 2005; Zaenen, 2006). For this reason, a great deal of effort is underway to devel</context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>M. Palmer, D. Gildea, and Kingsbury. 2005. The proposition bank: A corpus annotated with semantic roles. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
<author>R Artstein</author>
</authors>
<title>The reliability of anaphoric annotation, reconsidered: Taking ambiguity into account</title>
<date>2005</date>
<booktitle>Proc. of ACL Workshop on Frontiers in Corpus Annotation</booktitle>
<pages>76--83</pages>
<editor>In A. Meyers, editor</editor>
<contexts>
<context>mework for the annotation, an essential prerequisite (see, e.g., discussion in (?; Palmer et al., 2005)); on the other, the difficulty of achieving more than moderate agreement on semantic judgments (Poesio and Artstein, 2005; Zaenen, 2006). For this reason, a great deal of effort is underway to develop and/or improve semi-automatic methods for creating annotated resources and/or for using the existing data, such as activ</context>
<context>i, OntoWiki, Semantic Wikipedia, etc. 3. Methods 3.1. Annotating anaphoric information ANAWIKI will build on the proposals for marking anaphoric information allowing for ambiguity developed in ARRAU (Poesio and Artstein, 2005) and previous projects (Poesio, 2004). In these projects we developed, first of all, instructions for volunteers to mark anaphoric information in a reliable way that were tested in a series of agreem</context>
<context>the (mediocre) results at evaluating agreement among annotators, made it abundantly clear that for many types of semantic information in text–wordsense above all (Véronis, 1998) but also coreference (Poesio and Artstein, 2005) –small differences in interpretation are the rule and often major differences are possible,especiallywhenfine-grainedmeaningdistinctions are required (Poesio and Artstein, 2005). Forcing volunteers </context>
</contexts>
<marker>Poesio, Artstein, 2005</marker>
<rawString>M. Poesio and R. Artstein. 2005. The reliability of anaphoric annotation, reconsidered: Taking ambiguity into account. In A. Meyers, editor, Proc. of ACL Workshop on Frontiers in Corpus Annotation, pages 76–83, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
</authors>
<title>The MATE/GNOME scheme for anaphoric annotation, revisited</title>
<date>2004</date>
<booktitle>In Proc. of SIGDIAL</booktitle>
<location>Boston</location>
<contexts>
<context>.1. Annotating anaphoric information ANAWIKI will build on the proposals for marking anaphoric information allowing for ambiguity developed in ARRAU (Poesio and Artstein, 2005) and previous projects (Poesio, 2004). In these projects we developed, first of all, instructions for volunteers to mark anaphoric information in a reliable way that were tested in a series of agreement studies. These instructions speci</context>
</contexts>
<marker>Poesio, 2004</marker>
<rawString>M. Poesio. 2004. The MATE/GNOME scheme for anaphoric annotation, revisited. In Proc. of SIGDIAL, Boston, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Singh</author>
</authors>
<title>The public acquisition of commonsense knowledge. InProc.AAAISpringSymposiumonAcquiring (and using) Linguistic (and World) knowledge for information access</title>
<date>2002</date>
<contexts>
<context>creation, but it is not an isolated case. The willingness of Web surfers to help extends to projects to create resources for Artificial Intelligence. One example is the Open Mind Commonsense project (Singh, 2002),2 a project to mine commonsense knowledge to which 14500 participants contributed nearly 700,000 facts. If the 15,000 volunteers who participated in Open Mind Commonsense each annotated 7 texts of 1</context>
</contexts>
<marker>Singh, 2002</marker>
<rawString>P. Singh. 2002. The public acquisition of commonsense knowledge. InProc.AAAISpringSymposiumonAcquiring (and using) Linguistic (and World) knowledge for information access.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Véronis</author>
</authors>
<title>A study of polysemy judgments and inter-annotator agreement</title>
<date>1998</date>
<booktitle>In Proc. of SENSEVAL-1</booktitle>
<contexts>
<context>tional Linguistics, and particularly the (mediocre) results at evaluating agreement among annotators, made it abundantly clear that for many types of semantic information in text–wordsense above all (Véronis, 1998) but also coreference (Poesio and Artstein, 2005) –small differences in interpretation are the rule and often major differences are possible,especiallywhenfine-grainedmeaningdistinctions are required</context>
</contexts>
<marker>Véronis, 1998</marker>
<rawString>J. Véronis. 1998. A study of polysemy judgments and inter-annotator agreement. In Proc. of SENSEVAL-1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Vlachos</author>
</authors>
<title>Active annotation</title>
<date>2006</date>
<booktitle>In Proc. EACL 2006 Workshop on Adaptive Text Extraction and Mining</booktitle>
<location>Trento</location>
<contexts>
<context>rucial usage of redundant models of the data. A family of approaches known as ACTIVE LEARNING have also been developed, in which some of the unlabelled data are selected and manually labelled (e.g., (Vlachos, 2006)). NLP systems trained on this labelled data almost invariably produce better results than systems trained on data which was not specially selected and certainly better than data which was labelled u</context>
</contexts>
<marker>Vlachos, 2006</marker>
<rawString>A. Vlachos. 2006. Active annotation. In Proc. EACL 2006 Workshop on Adaptive Text Extraction and Mining, Trento.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luis von Ahn</author>
</authors>
<title>Games with a purpose</title>
<date>2006</date>
<journal>Computer</journal>
<volume>39</volume>
<marker>von Ahn, 2006</marker>
<rawString>Luis von Ahn. 2006. Games with a purpose. Computer, 39(6):92–94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>Unsupervised wordsense disambiguation rivalling supervised methods</title>
<date>1995</date>
<booktitle>In Proc. 33rd ACL</booktitle>
<contexts>
<context>ng process that attempts to extend annotation coverage to the corpus as a whole. A number of techniques for combining labelled and unlabelled data exist. CO-TRAINING METHODS (Blum and Mitchell, 1998; Yarowsky, 1995) make crucial usage of redundant models of the data. A family of approaches known as ACTIVE LEARNING have also been developed, in which some of the unlabelled data are selected and manually labelled </context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>D. Yarowsky. 1995. Unsupervised wordsense disambiguation rivalling supervised methods. In Proc. 33rd ACL.</rawString>
</citation>
</citationList>
</algorithm>

