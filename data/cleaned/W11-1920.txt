Proceedings of the 15th Conference on Computational Natural Language Learning: Shared Task, pages 122–126,
Portland, Oregon, 23-24 June 2011. c©2011 Association for Computational Linguistics
ReconcilingOntoNotes:UnrestrictedCoreferenceResolutionin
OntoNoteswithReconcile
VeselinStoyanov
CLSP
JohnsHopkinsUniversity
Baltimore,MD
UdayBabbar and PracheerGupta and Claire Cardie
Departmentof ComputerScience
CornellUniversity
Ithaca,NY
Abstract
This paperdescribes our entry to the 2011 CoNLL
closedtask (Pradhanet al., 2011)on modelingun-
restrictedcoreferencein OntoNotes. Our systemis
based on the Reconcilecoreferenceresolutionre-
searchplatform.Reconcileis a generalsoftware in-
frastructurefor the developmentof learning-based
noun phrase (NP) coreferenceresolutionsystems.
Ourentryfor the CoNLLclosedtaskis a configura-
tionof Reconcileintendedto do wellon OntoNotes
data. Thispaperdescribesourconfigurationof Rec-
oncileas well as the changesthat we had to imple-
mentto integratewiththeOntoNotestaskdefinition
and data formats. We also presentand discussthe
performanceof our system under different testing
conditionson a withheldvalidationset.
1 Introduction
Nounphrase(NP)coreferenceresolutionis oneof
the fundamentaltasks of the field of NaturalLan-
guageProcessing(NLP).Recently, the creationof
the OntoNotescorpus (Pradhanet al., 2007) has
provided researcherswith a large standard data
collection with which to create and empirically
comparecoreferenceresolutionsystems.
Reconcile(Stoyanov et al., 2010b)is a general
coreferenceresolutionresearchplatformthataims
to abstract the architectureof different learning-
based coreferencesystemsand to provide infras-
tructure for their quick implementation. Recon-
cileis distributedwithseveralstate-of-theart NLP
componentsand a set of optimizedfeature imple-
mentations. We decided to adapt Reconcilefor
the OntoNotes corpus and enter it in the 2011
CoNLLsharedtaskwiththreegoalsin mind:(i) to
comparethe architectureand componentsof Rec-
oncilewith other state-of-the-artcoreferencesys-
tems, (ii) to implementand provide the capabil-
ity of runningReconcileon the OntoNotescorpus,
and,(iii)to providea baselinefor futurealgorithm
implementationsin Reconcilethat evaluateon the
OntoNotescorpus.
Although Reconcile can be easily adapted to
new corpora, doing so requires introducingnew
components. More precisely, the system has to
be modifiedto be consistentwith the specificdef-
inition of the coreferencetask embodied in the
OntoNotesannotationinstructions. Additionally,
differentcorporause differentdataformats,so the
systemneedsto implementcapabilitiesfordealing
withthesenew formats.Finally, Reconcilecan be
configuredwithdifferentfeaturesandcomponents
to createan instantiationthat modelswellthe par-
ticulardata.
In this paper we describe, ReconcileCoNLL,
ourentryto the 2011CoNLLsharedtaskbasedon
the Reconcileresearchplatform.We begin by de-
scribingthe general Reconcilearchitecture (Sec-
tion 2), then describethe changesthat we incor-
porated in order to enable Reconcileto work on
OntoNotesdata (Sections3 and 4). Finally, we
describeour experimentalset up and resultsfrom
runningReconcileCoNLL under different condi-
tions(Section5).
2 Overviewof
Reconcile
In thissectionwegive a high-level overview of the
Reconcileplatform. We refer the readerfor more
detailsto Stoyanov et al. (2010a)and Stoyanov et
al. (2010b). Results from running a Reconcile-
based coreferenceresolutionsystem on different
corporacan be foundin Stoyanov et al. (2009).
Reconcile was developed to be a coreference
resolutionresearchplatformthat allows for quick
implementationof coreferenceresolutionsystems.
The platformabstractsthe majorprocessingsteps
(components)of currentstate-of-the-artlearning-
based coreferenceresolutionsystems. A descrip-
tion of the stepsand the availablecomponentscan
be foundin the referencedpapers.
3 TheReconcileCoNLL
System
To participatein the 2011CoNLLsharedtask,we
configuredReconcileto conformto theOntoNotes
general coreferenceresolutiontask. We will use
the name ReconcileCoNLL, to refer to this par-
ticularinstantiationof the generalReconcileplat-
form. The remainderof this sectiondescribethe
changesrequiredto enableReconcileCoNLL to
run (accurately)on OntoNotesdata.
122
ReconcileCoNLL employs the same basic
pipelinedarchitectureas Reconcile. We describe
the specificcomponentsusedin eachstep.
1. Preprocessing. Documentsin theOntoNotes
corpus are manually(or semi-automatically) an-
notatedwithmany typesof linguisticinformation.
This informationincludes tokens, part-of-speech
tags, and named entity informationas well as a
constituentsyntacticparseof the text. For the pur-
poseof participatingin the sharedtask,we relyon
these manualannotations,when available. Thus,
we do not run mostof the standard Reconcilepre-
processingcomponents.One type of information
not provided in the OntoNotescorpusis a depen-
dency parse. Several of Reconcile’s featuresrely
on a dependency parse of the text. Thus, we ran
the Stanforddependency parser (Klein and Man-
ning, 2003), which performsa constituent parse
andusesrulesto convert to a dependency format.1
Two additional changes to the preprocessing
step werenecessaryfor runningon the OntoNotes
data. The first is the implementationof compo-
nents that can convert data from the OntoNotes
formatto the Reconcileinternalformat. The sec-
ondis adaptationof theCoreferenceElement(CE)
extractorto conformto the OntoNotesdefinition
of whatcan constitutea CE. Our implementations
for these two tasks are briefly describedin Sec-
tions4.1 and 4.2, respectively.
2. Feature generation.ReconcileCoNLL was
configuredwith 61 featuresthat have proven suc-
cessful for coreferenceresolution on other data
sets. Due to the lack of time we performed
no feature engineering or selection specific to
OntoNotes.We used a new componentfor gener-
ating the pairwiseCEs that comprisetrainingand
testinstances,whichwedubSMARTPG (for smart
pair generator).Thisis describedin Section4.3.
3. Classification.We traina linearclassifierus-
ingtheaveragedperceptronalgorithm(Freundand
Schapire,1999).We use a subsetof 750randomly
selecteddocumentsfor training,since trainingon
the entire set requiredtoo much memory.2 As a
result, we had ample validation data for tuning
thresholds,etc.
1A betterapproachwouldbe to use the rulesto createthe
dependency parsefromthe manualconstituentparse. We de-
cidedagainstthis approachdue to implementationoverhead.
2It is easyto addressthe memoryissuein the on-lineper-
ceptronsetting,but in the interestof timewe choseto reduce
the size of the training data. Trainingon the set of 750 docu-
mentsis doneefficientlyin memoryby allocating4GBto the
Java virtualmachine.
4. Clustering. We use Reconcile’s single-link
clusteringalgorithm.In otherwords, we compute
the transitive closureof the positive pairwisepre-
dictions.Notethat whatconstitutesa positive pre-
dictiondependson a thresholdset for the classifier
from the previous step. This clusteringthreshold
is optimizedusing validationdata. More details
about the influenceof the validationprocess can
be foundin Section5.
5. Scoring. The 2011 CoNLLsharedtask pro-
vides a scorer that computesa set of commonly
used coreference resolution evaluation metrics.
We report results using this scorer in Section 5.
However, we usedthe Reconcile-internalversions
of scorers to optimize the threshold. This was
done for pragmaticreasons – time pressure pre-
ventedus fromincorporatingthe CoNLLscorerin
the system. We also reportthe Reconcile-internal
scoresin the experimentsection.
This concludes the high-level description of
the ReconcileCoNLL system. Next, we describe
in more detail the main changesimplementedto
adaptto the OntoNotesdata.
4 Adaptingto
OntoNotes
The first two subsection below describe the two
maintasksthatneedto be addressedwhenrunning
Reconcileon a new data set: annotationconver-
sion and CE extraction. The third subsectionde-
scribesthe new Smart CE Pairwiseinstancegen-
erator— a generalcomponentthatcanbe usedfor
any coreferencedataset.
4.1 AnnotationConversion
Therearefundamentaldifferencesbetweenthean-
notationformatused by OntoNotesand that used
internallyby Reconcile. While OntoNotesrelies
on token-basedrepresentations,Reconcileuses a
stand-off bytespanannotation. A significantpart
of the developmentof ReconcileCoNLL was de-
voted to conversion of the OntoNotes manualto-
ken, parse, named-entityand coreferenceannota-
tions. In general,we preferthe stand-off bytespan
formatbecauseit allows the referencetext of the
documentto remain unchangedwhile annotation
layersare addedas needed.
4.2 CoreferenceElementExtraction
The definitionof what can constitute an element
participatingin the coreference relation (i.e., a
CoreferenceElementor CE) dependson the par-
ticulardataset.OptimizingtheCEextractioncom-
123
Optimized ThresBCEAF MUC
Metric hold Cubed
BCubed 0.4470 0.7112 0.1622 0.6094
CEAF 0.4542 0.7054 0.1650 0.6141
MUC 0.4578 0.7031 0.1638 0.6148
Table 1: Reconcile-internal scores for different
thresholds. The table lists the best thresholdfor
thevalidationdataandresultsusingthatthreshold.
Pair Gen. BCubed CEAFe MUC
SMARTPG 0.6993 0.1634 0.6126
All Pairs 0.6990 0.1603 0.6095
Table3: Influenceof differentpair generators.
ponentfor the particulartask definitioncan result
in dramaticimprovementsin performance.An ac-
curate implementationlimits the number of ele-
ments that the coreferencesystem needs to con-
siderwhilekeepingthe recallhigh.
The CE extractor that we implemented for
OntoNotesextendsthe existingReconcile ACE05
CE extractor (ACE05, 2005) via the following
modifications:
NamedEntities:We excludenamedentitiesof
type CARDINAL NUMBER, MONEY and NORP,
the latter of which captures nationality, religion,
politicaland otherentities.
Possessives: In the OntoNotescorpus,posses-
sives are includedas coreferenceelements,while
in ACE they are not.
ReconcileCoNLL ignoresthe factthatverbscan
alsobe CEsfor the OntoNotescoreferencetaskas
this change would have constituteda significant
implementationeffort.
Overall,ourCEextractorachieves recallof over
96%,extractingroughlytwicethe numberof CEs
in the answerkey (precisionis about50%). High
recallis desirablefortheCEextractorat thecostof
precisionsincethejobof thecoreferencesystemis
to furthernarrow down the set of anaphoricCEs.
4.3 SmartPair
Generator
Like mostcurrentcoreferenceresolutionsystems,
at the heart of Reconcilelies a pairwiseclassifier.
Thejobof the classifieris to decidewhetheror not
two CEs are coreferentor not. We use the term
pairgenerationto refer to the processof creating
theCEpairsthattheclassifierconsiders.Themost
straightforward way of generatingpairsis by enu-
meratingall possibleunique combinations. This
approachhas two undesirableproperties – it re-
quirestime in the orderof O(n2) for a given doc-
ument(wheren is the numberof CEsin the docu-
ment)and it produceshighlyimbalanceddatasets
with the numberof positive instances(i.e., coref-
erentCEs)beinga smallfractionof the numberof
negative instances. The latter issue has been ad-
dressedby a techniquenamedinstancegeneration
(Soon et al., 2001): during training, each CE is
matchedwiththe first precedingCE withwhichit
corefersand all other CEs that reside in between
the two. Duringtesting, a CE is comparedto all
precedingCEs until a coreferentCE is found or
the beginning of the documentis reached. This
techniquereducesclass imbalance,but it has the
sameworst-caseruntimecomplexity of O(n2).
We employ a new type of pair generationthat
aims to address both the class imbalance and
improves the worst-case runtime. We will use
SMARTPG to refer to this component. Our pair
generator relies on linguistic intuitions and is
based on the type of each CE. For a given CE,
we use a rule-basedalgorithmto guess its type.
Basedon the type, we restrictthe scope of possi-
ble antecedentsto which the CE can refer in the
followingway:
ProperName(NamedEntity):A propername
is comparedagainstallpropernamesin the20pre-
cedingsentences.In addition,it is comparedto all
otherCEsin the two precedingsentences.
Definitenounphrase:Comparedto all CEs in
the six precedingsentences.
Commonnoun phrase: Comparedto all CEs
in the two precedingsentences.
Pronoun: Comparedto all CEs in the two pre-
cedingsentencesunlessit is a firstpersonpronoun.
First person pronounsare additionallycompared
to first person pronounsin the preceding20 sen-
tences.
During development, we used SMARTPG
on coreference resolution corpora other than
OntoNotesand determinedthat the pair generator
tends to lead to more accurateresults. It also has
runtime linear in the number of CEs in a docu-
ment, which leads to a sizable reductionin run-
ningtime for large documents.Trainingfiles gen-
erated by SMARTPG also tend to be more bal-
anced. Finally, by omitting pairs that are un-
likely to be coreferent,SMARTPG producesmuch
smallertrainingsets. This leads to faster learning
and allows us to trainon moredocuments.
124
OptimizedMetric Threshold BCubed CEAFe MUC BLANC CEAFm Combined
BCubed 0.4470 0.6651 0.4134 0.6156 0.6581 0.5249 0.5647
CEAF 0.4542 0.6886 0.4336 0.6206 0.7012 0.5512 0.5809
MUC 0.4578 0.6938 0.4353 0.6215 0.7108 0.5552 0.5835
Table2: CoNLLscoresfor differentthresholdson validationdata.
CoNLLOfficialTest Scores BCubed CEAFe MUC BLANC CEAFm Combined
ClosedTask 0.6144 0.3588 0.5843 0.6088 0.4608 0.5192
GoldMentions 0.6248 0.3664 0.6154 0.6296 0.4808 0.5355
Table4: OfficialCoNLL2011testscores.Combinedscoreis the averageof MUC,BCubedandCEAFe.
5 Experiments
In this sectionwe presentand discussthe results
for ReconcileCoNLLwhen trained and evaluated
on OntoNotesdata. For all experiments,we train
on a set of 750randomlyselecteddocumentsfrom
the OntoNotescorpus. We use another 674 ran-
domlyselecteddocumentsfor validation. We re-
port scores using the scorers implementedinter-
nally in Reconcileas well as the scorerssupplied
by the CoNLLsharedtask.
In therestof thesection,we describeourresults
when controllingtwo aspectsof the system– the
thresholdof the pairwiseCE classifier, which is
tuned on training data, and the method used for
pair generation. We concludeby presentingthe
officialresultsfor the CoNLLsharedtask.
Influence of Classifier Threshold As previ-
ously mentioned,the thresholdabove which the
decision of the classifier is considered positive
provides us with a knob that controls the preci-
sion/recalltrade-off. Reconcileincludes a mod-
ule that can automatically search for a threshold
value that optimizesa particularevaluation met-
ric. Results using three Reconcile-internalscor-
ers (BCubed, CEAF, MUC) are shown in Table
1. First, we see that the thresholdthat optimizes
performanceon the validation data also exhibits
the best results on the test data. The same does
not hold when using the CoNLL scorer for test-
ing, however: as Table 2 shows, the best results
for almostall of the CoNLLscoresare achieved at
thethresholdthatoptimizestheReconcile-internal
MUCscore. Notethatwe did not optimizethresh-
olds for the external scorer in the name of sav-
ing implementationeffort. Unfortunately, the re-
sults that we submittedfor the officialevaluations
were for the suboptimal thresholdthat optimizes
Reconcile-internalBCubedscore.
Influenceof Pair GenerationStrategies Next,
we evaluate the performanceof SMARTPG pair
generators. We run the same system set-up as
above substitutingthepairgenerationmodule.Re-
sults(usingthe internalscorer),displayedin Table
3, show our SMARTPG performsidenticallyto the
generatorproducingall pairs,whileit runsin time
linearin the numberof CEs.
Official Scores for the CoNLL 2011 Shared
Task Table 4 summarizesthe official scores of
ReconcileCoNLL on the CoNLLsharedtask. Sur-
prisingly, the scoresare substationally lower than
the scoreson our held-outtrainingset. So far, we
have noexplanationforthesedifferencesin perfor-
mance. We also observe that using gold-standard
insteadof system-extractedCEsleadsto improve-
mentin scoreof aboutpointand a half.
The official score places us 8th out of 21 sys-
tems on the closed task. We note that because
of the thresholdoptimizationmix-upwe suffered
about 2 points in combined score performance.
Realisticallyour systemshouldscorearound0.54
placingus 5th or 6th on the task.
6 Conclusions
In this paper, we presentedReconcileCoNLL, our
systemfor the 2011 CoNLLsharedtask basedon
the Reconcile research platform. We described
the overall Reconcileplatform,our configuration
for the CoNLLtask and the changesthat we im-
plementedspecificto the task. We presentedthe
results of an empirical evaluation performedon
held-outtrainingdata. We discovered that results
for our systemon thisdataare quitedifferentfrom
the officialscorethat our systemachieved.
Acknowledgments
This material is based upon work supported by
the National Science Foundation under Grant #
0937060to the ComputingResearchAssociation
for the CIFellows Project.
125
References
ACE05. 2005. NIST ACE evaluation website. In
http://www.nist.gov/speech/tests/ace/2005.
Yoav Freund and Robert E. Schapire. 1999. Large
marginclassificationusingtheperceptronalgorithm.
In MachineLearning, pages277–296.
D. Kleinand C. Manning. 2003. Fast ExactInference
with a FactoredModel for NaturalLanguagePars-
ing. In Advancesin Neural InformationProcessing
(NIPS2003).
Sameer S. Pradhan, Lance Ramshaw, Ralph
Weischedel, Jessica MacBride,and Linnea Micci-
ulla. 2007. Unrestrictedcoreference: Identifying
entities and events in ontonotes. In Proceedings
of the International Conference on Semantic
Computing.
Sameer Pradhan, Lance Ramshaw, Mitchell Marcus,
Martha Palmer, Ralph Weischedel, and Nianwen
Xue. 2011. Conll-2011sharedtask: Modelingun-
restrictedcoreferencein ontonotes. In Proceedings
of the FifteenthConferenceon ComputationalNat-
ural Language Learning(CoNLL2011), Portland,
Oregon,June.
W. Soon, H. Ng, and D. Lim. 2001. A Machine
LearningApproachto Coreferenceof NounPhrases.
ComputationalLinguistics, 27(4):521–541.
V. Stoyanov, N. Gilbert,C. Cardie,andE. Riloff. 2009.
Conundrumsin nounphrasecoreferenceresolution:
Makingsenseof the state-of-the-art.InProceedings
ofACL/IJCNLP.
V. Stoyanov, C. Cardie, N. Gilbert,E. Riloff, D. But-
tler, and D. Hysom. 2010a. Reconcile: A corefer-
enceresolutionresearchplatform.Technicalreport,
CornellUniversity.
VeselinStoyanov, ClaireCardie,NathanGilbert,Ellen
Riloff, David Buttler, and David Hysom. 2010b.
Coreferenceresolutionwith reconcile. In Proceed-
ingsoftheACL2010.
126

