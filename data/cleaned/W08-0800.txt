ACL-08:HLT
Workshopon
MobileLanguage
Processing
ProceedingsoftheWorkshop
June20,2008
TheOhioStateUniversity
Columbus,Ohio,USA
Production and Manufacturing by
Omnipress Inc.
2600 Anderson Street
Madison, WI 53707
USA
c©2008 The Association for Computational Linguistics
Order copies of this and other ACL proceedings from:
Association for Computational Linguistics (ACL)
209 N. Eighth Street
Stroudsburg, PA 18360
USA
Tel: +1-570-476-8006
Fax: +1-570-476-0860
acl@aclweb.org
ISBN 978-1-932432-13-8
ii
Introduction
Mobile devices such as ultra-mobile PCs, personal digital assistants, and smart phones have many
unique characteristics that make them both highly desirable as well as difficult to use. On the positive
side, they are small, convenient, personalizable, and provide an anytime-anywhere communication
capability. On the other hand, they have limited input and output capabilities, limited bandwidth,
limited memory, and restricted processing power.
In anticipation of new and exciting applications for natural and spoken language processing on mobile
devices, this workshop provided a forum for discussing some of the challenges that are unique to this
domain. For instance, mobile devices are beginning to integrate sensors (most commonly for location
detection through GPS, Global Positioning Systems) that can be exploited by context/location aware
NLP systems. Another interesting research direction is the use of information from multiple devices
for “distributed” language modeling and inference. To give some concrete examples, knowing the type
of web queries made from nearby devices or from a specific location or ’context’ can be combined
for various applications and could potentially improve information retrieval results. Learned language
models could be transferred from device to device, propagating and updating the language models
continuously and in a decentralized manner.
Processing and memory limitations faced by the execution of NLP and speech recognition software
on small devices need to be addressed. Several papers addressed this issue. In “Information
extraction using finite state automata and syllable n-grams” Seon et al. proposed a modified HMM
for information extraction in a mobile environment. This kind of model has the advantage of being
compact. Huggins-Daines et al. proposed a simple entropy-based technique to improve the scalability
of acoustic models in embedded systems; they showed a significant speed-up in recognition with
a negligible increase in word error rate (“Mixture Pruning and Roughening for Scalable Acoustic
Models.”) Ganchev and Dredze in “Small Statistical Models by Random Feature Mixing” showed
how it is possible to do efficient NLP learning by reducing the number of parameters on resource
constrained devices with little loss in performance; and “A Wearable Headset Speech-to-Speech
Translation System” by Krstovski et al. shrunk a speech translation system to fit into a wearable
speech-to-speech translation system.
Some applications and practical considerations may require a client/server or distributed architecture:
what are the implications for language processing systems in using such architectures? Homola (“A
Distributed Database for Mobile NLP Applications”) proposed a distributed database for lexical
transfer in machine translation. The database contains data shared among multiple devices and
automatically synchronizes them.
The limitation of the input and output channels necessitates typing on increasingly smaller keyboards
which can be quite difficult, and similarly reading on small displays is challenging. Speech interfaces
for dictation or for understanding navigation commands and/or language models for typing suggestions
would enhance the input channel, while NLP systems for text classification, summarization and
iii
information extraction would be helpful for the output channel. Speech and multimodal interfaces,
language generation and dialog systems would provide a natural way to interact with mobile devices. A
multimodal dialogue system for interacting with a home entertainment center via a mobile device was
proposed by Gruenstein et al. in “A Multimodal Home entertainment Interface via a Mobile Device.”
Furthermore, the growing market of cell phones in developing regions can be used for delivering
applications in the areas of health, education and economic growth to rural communities. Some of
the challenges in this area are the limited literacy, the many languages and dialects spoken and the
networking infrastructure.
For the health domain, Nikolova and Ma in their paper “Assistive Mobile Communication Support”
discussed the role of mobile technologies in a system for communication support for people with
speech and language disabilities.
We believe that the issues raised by the papers in this Workshop represent just the tip of the iceberg,
and we hope that by raising awareness of these issues, more research will be aimed at mobile language
processing. The ACL 2008 Workshop on Mobile Language Processing took place on June 20 in
Columbus, Ohio following ACL-08: HLT with an invited talk by Dr. Lisa Stifelman, Principal User
Experience Manager at Tellme/Microsoft, seven oral paper presentations, a poster and a demo session
and a panel discussion.
We thank the members of the Program Committee for their diligent and insightful reviews, as well as
our illustrious Panel Session members.
Barbara Rosario and Tim Paek
Co-Organizers
iv
Organizers:
Barbara Rosario, Intel Research
Tim Paek, Microsoft Research
Program Committee:
Alex Acero, Microsoft Research
Alan Black, CMU
Dilek Hakkani Tur, ICSI
Marti Hearst, iSchool, UC Berkeley
Michael Johnston, AT&T
Maryam Kamvar, Google and Columbia University
Kevin Knight, USC/Information Sciences Institute
Julian Kupiec, Google
Dekang Lin, University of Alberta, Canada
Maryam Mahdaviani, University of British Columbia, Canada
Wolfgang Minker, University of Ulm, Germany
Noah Smith, CMU
Bo Thiesson, Microsoft Research
Gokhan Tur , SRI
Fuliang Weng, Bosch
Thomas Zheng , Tsinghua University
Geoffrey Zweig, Microsoft Research
Invited Speaker:
Lisa Stifelman, Principal User Experience Manager at Tellme/Microsoft.
v

Table of Contents
A Multimodal Home Entertainment Interface via a Mobile Device
Alexander Gruenstein, Bo-June (Paul) Hsu, James Glass, Stephanie Seneff, Lee Hetherington,
Scott Cyphers, Ibrahim Badr, Chao Wang and Sean Liu ......................................... 1
A Wearable Headset Speech-to-Speech Translation System
Kriste Krstovski, Michael Decerbo, Rohit Prasad, David Stallard, Shirin Saleem and Premkumar
Natarajan..................................................................................10
Information extraction using finite state automata and syllable n-grams in a mobile environment
Choong-Nyoung Seon, Harksoo Kim and Jungyun Seo....................................13
Small Statistical Models by Random Feature Mixing
Kuzman Ganchev and Mark Dredze ..................................................... 19
Mixture Pruning and Roughening for Scalable Acoustic Models
David Huggins-Daines and Alexander I. Rudnicky........................................21
Assistive Mobile Communication Support
Sonya Nikolova and Xiaojuan Ma.......................................................25
A Distributed Database for Mobile NLP Applications
Petr Homola .......................................................................... 27
vii

Workshop Program
Friday, June 20, 2008
8:45–9:00 Opening Remarks
9:00–10:00 Invited Talk by Dr. Lisa Stifelman, Principal User Experience Manager at
Tellme/Microsoft. Say it and See it! Applying User-Centered Design to Mobile
and Multimodal Search.
10:00–10:30 A Multimodal Home Entertainment Interface via a Mobile Device
Alexander Gruenstein, Bo-June (Paul) Hsu, James Glass, Stephanie Seneff, Lee
Hetherington, Scott Cyphers, Ibrahim Badr, Chao Wang and Sean Liu
10:30–11:00 Break
11:00–11:25 A Wearable Headset Speech-to-Speech Translation System
Kriste Krstovski, Michael Decerbo, Rohit Prasad, David Stallard, Shirin Saleem
and Premkumar Natarajan
11:25–11:50 Information extraction using finite state automata and syllable n-grams in a mobile
environment
Choong-Nyoung Seon, Harksoo Kim and Jungyun Seo
11:50–12:15 Small Statistical Models by Random Feature Mixing
Kuzman Ganchev and Mark Dredze
12:15–1:15 Lunch
1:15–1:40 Mixture Pruning and Roughening for Scalable Acoustic Models
David Huggins-Daines and Alexander I. Rudnicky
1:40–2:05 Assistive Mobile Communication Support
Sonya Nikolova and Xiaojuan Ma
2:05–2:30 A Distributed Database for Mobile NLP Applications
Petr Homola
2:30–3:30 Demos and Posters
3:30–4:00 Break
4:00–5:00 Panel Session
ix


