For the first level, following Daelemans et al.(1999), I use as features all words and tags in a window ranging from five tokens to the left to three tokens to the right.
W99-0707
5) In the LOB WPDV model, the Penn wordclass tags (as produced by the Brill tagger) are replaced by the output of a WPDV tagger trained on 90% of the LOB corpus (van Halteren, 2000b).
W00-0724
When comparing with the NP scores of Daelemans et al.(1999), we see a comparable accuracy (actually slightly higher because of the second level classification).
W99-0707
van Halteren (2000a).
W00-0724
Tjong Kim Sang (2000)), I use a smaller window, four left and two right, but add the IOB suggestions made by the first level for one token left and right (but not the focus).
A00-2007 W00-0726
Except for one base chunker, which uses the memory-based machine learning systern TiMBL, 1 all modules are based on WPDV models (van Halteren, 2000a).
W00-0724
The TiMBL results are worse than the ones reported by Buchholz et al.(1999), 5 but the latter were based on training on WSJ sections 0019 and testing on 20-24.
W99-0629
nl 1 Introduction In this paper I describe the application of the WPDV algorithm to the CoNLL-2000 shared task, the identification of base chunks in English text (Tjong Kim Sang and Buchholz, 2000).
A00-2007 W00-0726
