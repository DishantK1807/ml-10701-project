The model is composed of three parts (Collins, 2002a): a set of candidate SAPTs GEN, which is the top n SAPTs of a sentence from SCISSOR; a function Φ that maps a sentence Inputs: A set of training examples (xi,y∗i ), i = 1...n, where xi is a sentence, and y∗i is a candidate SAPT that has the highest similarity score with the gold-standard SAPT Initialization: Set ¯W = 0 Algorithm: For t = 1...T,i = 1...n Calculate yi = argmaxy∈GEN(xi) Φ(xi,y) · ¯W If (yi negationslash= y∗i ) then ¯W = ¯W +Φ(xi,y∗i ) − Φ(xi,yi) Output: The parameter vector ¯W Figure 2: The perceptron training algorithm.
P02-1034 P02-1062 W02-1001
To put this in perspective, Charniak and Johnson (2005) reported that reranking improves the F-measure of syntactic parsing from 89.7% to 91.0% with a 50best oracle F-measure score of 96.8%.
P05-1022
Here, we only describe changes made to SCISSOR for reranking, for a full description of SCISSOR see Ge and Mooney (2005).
W05-0602
4.2.1 Baseline Results Table 2 shows the results comparing the baseline learner SCISSOR using both the back-off parameters in Ge and Mooney (2005) (SCISSOR) and the revised parameters in Section 2.2 (SCISSOR+).
W05-0602
In comparison with shallow semantic analysis tasks, such as wordsense disambiguation (Ide and Jean´eronis, 1998) and semantic role labeling (Gildea and Jurafsky, 2002; Carreras and M`arquez, 2005), which only partially tackle this problem by identifying the meanings of target words or finding semantic roles of predicates, semantic parsing (Kate et al., 2005; Ge and Mooney, 2005; Zettlemoyer and Collins, 2005) pursues a more ambitious goal – mapping natural language sentences to complete formal meaning representations (MRs), where the meaning of each part of a sentence is analyzed, including noun phrases, verb phrases, negation, quantifiers and so on.
J02-3001 J98-1001 W05-0602 W05-0620
We also plan to explore other types of reranking features, such as the features used in semantic role labeling (SRL) (Gildea and Jurafsky, 2002; Carreras and M`arquez, 2005), like the path between a target predicate and its argument, and kernel methods (Collins, 2002b).
J02-3001 P02-1034 P02-1062 W02-1001 W05-0620
For a full description of the algorithm, see (Collins, 2002a).
P02-1034 P02-1062 W02-1001
The syntactic features introduced by Collins (2000) for reranking syntactic parse trees have been proven successfully in both English and Spanish (Cowan and Collins, 2005).
H05-1100
Collins. 1997.
P97-1003
Semantic parsing enables logic reasoning and is critical in many practical tasks, such as speech understanding (Zue and Glass, 2000), question answering (Lev et al., 2004) and advice taking (Kuhlmann et al., 2004).
W04-0902
Experimenting with other effective reranking algorithms, such as SVMs (Joachims, 2002) and MaxEnt (Charniak and Johnson, 2005), is also a direction of our future research.
P05-1022
While reranking has benefited many tagging and parsing tasks (Collins, 2000; Collins, 2002c; Charniak and Johnson, 2005) including semantic role labeling (Toutanova et al., 2005), it has not yet been applied to semantic parsing.
P02-1034 P02-1062 P05-1022 P05-1073 W02-1001
To deal with the sparse data problem, the expansion of a non-terminal (parent) is decomposed into primitive steps: a child is chosen as the head and is generated first, and then the other children (modifiers) are generated independently 264 BACK-OFFLEVEL PL1(Li|...) 1 P,H,w,t,∆,LC 2 P,H,t,∆,LC 3 P,H,∆,LC 4 P,H 5 P Table 1: Extended back-off levels for the semantic parameter PL1(Li|...), using the same notation as in Ge and Mooney (2005).
W05-0602
SCISSOR is implemented by augmenting Collins’ (1997) head-driven parsing model II to incorporate the generation of semantic labels on internal nodes.
P97-1003
Averaged Perceptron Reranking Model Averaged perceptron (Collins, 2002a) has been successfully applied to several tagging and parsing reranking tasks (Collins, 2002c; Collins, 2002a), and in this paper, we employed it in reranking semantic parses generated by the base semantic parser SCISSOR.
P02-1034 P02-1062 W02-1001
Averaged perceptron (Collins, 2002a), which has been successfully applied to several tagging and parsing reranking tasks (Collins, 2002c; Collins, 2002a), was employed for training rerank267 CLANG GEOQUERY P R F P R F SCISSOR 89.5 73.7 80.8 98.5 74.4 84.8 SCISSOR+ 87.0 78.0 82.3 95.5 77.2 85.4 Table 2: The performance of the baseline model SCISSOR+ compared with SCISSOR (with the best result in bold), where P = precision, R = recall, and F = F-measure.
P02-1034 P02-1062 W02-1001
Ge and Mooney (2005) introduced an approach, SCISSOR, where the composition of meaning representations is guided by syntax.
W05-0602
