In this paper, we compare our algorithm against the incremental GAC algorithm(Brown, 2000).
C00-1019
Prior work has shown that EBMT requires large amounts of data (in the order of two to three million words) (Brown, 2000) of pre-translated text, to function reasonably well.
C00-1019
cÂ©2006 Association for Computational Linguistics Spectral Clustering for Example Based Machine Translation Rashmi Gangadharaiah LTI Carnegie Mellon University Pittsburgh P.A. 15213 rgangadh@andrew.cmu.edu Ralf Brown LTI Carnegie Mellon University Pittsburgh P.A. 15213 ralf@cs.cmu.edu Jaime Carbonell LTI Carnegie Mellon University Pittsburgh P.A. 15213 jgc@cs.cmu.edu Abstract Prior work has shown that generalization of data in an Example Based Machine Translation (EBMT) system, reduces the amount of pre-translated text required to achieve a certain level of accuracy (Brown, 2000).
C00-1019
Spectral clustering is seen to be superior to Group Average Clustering (GAC) (Brown, 2000) both in terms of semantic similarity of words falling in a single cluster, and overall BLEU score (Papineni.
C00-1019
