Proceedings of the ACL-08: HLT Workshop on Parsing German (PaGe-08), pages 16–23,
Columbus, Ohio, USA, June 2008. c©2008 Association for Computational Linguistics
Part-of-SpeechTaggingwitha SymbolicFullParser:
UsingtheTIGERTreebanktoEvaluateFips
YvesScherrer
LanguageTechnologyLaboratory(LATL)
UniversityofGeneva
1211Geneva 4, Switzerland
yves.scherrer@lettres.unige.ch
Abstract
In this paper, we introducethe German ver-
sion of the multilingual Fips parsingsystem.
We focus on the evaluation of its part-of-
speechtaggingcomponentwiththehelpofthe
TIGERtreebank.We explainhow Fipscanbe
adaptedto the tagsetused by TIGERand re-
port first resultsof this study: currently, 87%
ofwordsaretaggedcorrectly. We alsodiscuss
some commonerrors and explore a possible
extensionofthisstudyto parsing.
1 Introduction
Fips is a parsingframework based on the main as-
sumptionsof Chomsky’s generative linguistics. It
has been designed as a multilingual framework,
makingit easy to add new languages. Currently, it
is availableforsixlanguages(English,French,Ger-
man,Italian,SpanishandGreek).WhiletheFrench
version(providingthebestcoverage)hastaken part
in evaluationcampaigns(Adda et al., 1998; Gold-
man et al., 2005),the otherlanguagemoduleshave
only been subjectto internalqualitative evaluation.
However, theavailabilityofgoldstandardtreebanks
allowsforquantitativeevaluationofrule-basedpars-
ing systems. In particular, we propose to use the
TIGER treebankfor the evaluationof the German
versionof Fips.
This paperreportson researchin progress. As a
preliminarystep towards a quantitative assessment
of parserperformance,wefocusonthetaskof Part-
of-Speech(POS)tag comparisonhere. This task is
intendedtoyieldafirstappreciationofthequalityof
the GermanFips componentwithouthavingto deal
with the full parser output and its possibleincom-
patibilitiesduetounderlyingtheoreticaldifferences.
Tag comparisonoperateson a word-by-word basis
andprovidesbinarymeasuresofaccuracy (tagiden-
tityordifference).
We extendourworkto thetasksof lemmaidenti-
ficationandmorphologicalanalysis:Fipsas wellas
theTIGERtreebankprovidethisinformation.
Fips has been developed independently of the
TIGERtreebank. Therefore,a large partof this pa-
per deals with problems arising from mismatches
betweenthe designdecisionsmadefor Fips andthe
annotationguidelinesof TIGER.In our view, a de-
taileddiscussionofthesemismatchesisessentialfor
a fair assessmentof the performancesof Fips, but
mayalsobeinterestingforfutureresearchinvolving
evaluation.
This paperis organizedas follows. In Section2,
we present the Fips framework. In Section 3, we
recall the main characteristicsof the TIGER tree-
bank,explaintheadaptationsweappliedto theFips
tagger and give some informationabout the evalu-
ation setup. We go on to report the results for the
three main tasks: Part-of-Speechtagging (Section
4), lemma identification(Section 5), and morpho-
logicalanalysis(Section6). Section7 comparesour
work to statisticalPOS taggingand to parser eval-
uation. We concludeby giving an overview of the
benefitsofquantitative evaluation.
2 TheFipsframework
Fips(Wehrli,2007)isa deepsymbolicparserdevel-
oped at the Universityof Geneva. It currentlysup-
ports six languages,and others are under develop-
ment. The parseris basedon an adaptionof gener-
ative linguistics,borrowingconceptsfromthe Min-
imalist model (Chomsky, 1995), from the Simpler
16
CP
TP
VP
Part
an
DP
NP
N
Obergrenze
D
eine
AdvP
PP
DP
NP
N
Kuren
P
bei
AdvP
PP
DP
D
Zuzahlungen
P
für
C
deutete
DP
NP
N
Minister
D
Der
Figure1: ExampleoutputoftheGermanFipsparser.
Syntaxmodel(Culicover and Jackendoff, 2005),as
wellasfromLexicalFunctionalGrammar(Bresnan,
2001).Eachsyntacticconstituentisrepresentedasa
simplifiedX-barstructurewithoutintermediatelev-
els,intheform[XPLXR]. X denotesalexicalcate-
gory,LandRstandfor(possiblyempty)listsofleft
andrightsubconstituents,respectively.
Theoriginalityof Fips liesin its two-layerarchi-
tecture. Fundamentalpropertiesand structuresthat
are commonto all languagesare definedin an ab-
stract, language-independentlayer. On a theoreti-
cal level, this layer can be associatedto the con-
cept of “universal grammar”. On top of this layer,
a particular, language-dependentlayer extends the
abstractstructuresandaddslanguage-specificgram-
mar rules. The Fips lexiconcontainsdetailedmor-
phosyntacticand semanticinformationsuch as se-
lectional properties, subcategorization information
andsyntactico-semanticfeatures.Theparseris thus
basedon a stronglexicalistframework. In orderto
guideambiguityresolution,numericpenaltyvalues
canbeassignedto rulesandlexemes.
The Germancomponentof Fips containsaround
100 language-specificgrammarrules. The lexicon
contains39 000 lexemes and 410 000 word forms.
Thewordformsare generatedby a rule-basedmor-
phologicalgenerator. Thelexiconalsocontains500
multi-word expressions and 1500 high-frequency
compoundnouns. Unknown compoundnouns are
chunkedat runtime.
Fipsoperatesin two modes:parser(seeFigure1)
and tagger(see Figure2) output.1 The taggerout-
putallowsusto benefitfromtherichinformationof
theFipslexicon,beingatthesametimemorerobust
thantheparser.
3 Experimentalsetup
3.1 TheTIGERtreebank
The TIGER treebank contains about 50 000 sen-
tences of newspaper text, covering all domains
(Brantset al., 2002). The annotationhas been per-
formed with the help of interactive tools. This
methodologyallows the humanannotatorto easily
accept or reject proposals made by the computer.
Part-of-speechtagsareproposedbya statisticaltag-
ger trainedon a manuallyannotated corpus. It uses
the Stuttgart-Tübingen-Tagset (STTS) (Thielen et
al., 1999). The parse trees were constructedinter-
activelywiththehelpofastatisticalparser. Figure3
showsanexampleoftheTIGERexportfile.
3.2 Adaptations
InordertocomparetheFipsoutputwiththeTIGER
tags,someadaptationshad to be made. Firstof all,
the tagset had to be changed to match the STTS
tagset. While this procedure was straightforward
for most of the categories, it showed that the Ger-
mantaggingmoduleof Fips hadnever beensubject
1Theparseroutputisshownhereforillustration–wedonot
useit in thepresentstudy.
Given the scopeof this workshop,we forgo translatingGer-
manexamplesintoEnglish.
17
der ART SIN-MAS-NOM 311000336 0 der SUBJ
minister NN SIN-MAS-NOM 311019783 3 Minister
deutete VVFIN IND-KON-PRA-3-SIN 311021998 12 andeuten
für APPR 311050006 20 für
Zuzahlungen NE INN-ING-NOM-ACC-DAT 0 24 Zuzahlungen
bei APPR 311050009 36 bei
kuren NN PLU-FEM-NOM-ACC-DAT-GEN 311004912 40 Kur
eine ART SIN-FEM-NOM-ACC 311000346 46 ein OBJ
ober¬ NN SIN-MAS-NOM-ACC-DAT 311019956 51 Ober COMP-CHUNK
grenze NN SIN-FEM-NOM-ACC 311001176 55 Grenze COMP-HEAD
an PTKVZ 311050018 62 an
. $. 0 65 .
Figure2: Exampleoutputof the GermanFips tagger. The columnsshow: the word as found in the text; the POS
tagin theSTTStagset;morphologicalinformationin a proprietarytagset;thelexemenumberof theinternaldatabase
(0 standsfor unknown words); the characterpositionat whichthe word begins; the lemma. The rightmostcolumn
containsadditionalinformationlike grammaticalfunctionandcompoundnounsyntax.
NotethatthecompoundnounObergrenzewas automaticallychunked andthatthewordZuzahlungenwas notfound
in thelexicon;theparticlean is attachedto thelemmaofthemainverbdeutete.
to a rigorousevaluation. For example, there were
no particulartagsfor pronominalprepositions(e.g.,
darüber, deswegen), for prepositionswith articles
(e.g.,beim,ins), andfortheinfinitival particlezu.
Small adaptionsconcernedthe replacementof ß
byss (FipsusestheSwissStandardGermanorthog-
raphy, lackingtheletterß) andthedifferentlemma-
tizationof the particleverbs: in TIGERandin con-
trast to Fips, the particles are not attached to the
lemma(seetheverbandeutenin Figures2 and3).
Finally, the Fips tagger contains a compound
noun chunker which is automaticallyused for un-
known words and which outputsone line for each
chunk.Theselineshadto bereassembledto fitwith
the unchunked TIGER output (cf. the compound
nounObergrenzein Figures2 and3).
3.3 Evaluation
Fromthe TIGERexportfile, we extractedthe orig-
inal sentencesand submittedthem to the Fips tag-
ger. Then,wecompareditsresultswiththeinforma-
tion given in TIGER.Overall, 792 885 words were
compared. Thisnumberdoesnot correspondto the
888 578 tokens of the TIGERcorpus, becausethe
conceptof word is muchmoreflexiblein Fips than
inTIGER.Forexample,thetoken62jährigerissplit
into two words 62 and jähriger. By contrast, vor
allemisregardedasasinglelexicalitem(adverb)by
Fips, but as two words by TIGER.Moreover, for a
TIGERTag FipsTag Number Percentage
NN NE 12592 1.59
KON ADV 8000 1.01
ADJD ADV 6737 0.85
ADV PTKA 4976 0.63
NE NN 4782 0.60
VAFIN VVFIN 3529 0.45
ART PRELS 2935 0.37
VVFIN VVIMP 1937 0.24
VVINF VVFIN 1859 0.23
VVPP VVFIN 1624 0.20
Correcttags 692386 87.32
Testedwords 792885 100.00
Table 1: Results of the part-of-speechtag comparison.
The table shows the numberof tags correctlypredicted
by Fips (second last line), as well as the ten most fre-
quenterroneouspredictions.Thefirstcolumnshows the
correcttagasgivenbyTIGER,thesecondcolumnshows
theerroneoustagassignedbyFips.
currentlyunknownreason,somewordsdonotshow
upin theoutputoftheFipstagger.
4 Part-of-speechtaggingresults
Themostimportantpartof thisevaluationconcerns
the part-of-speechtags. As explained above, we
have adaptedFips to generateSTTS tags. Table 1
shows the number of correctlypredictedtags, and
18
the ten mostfrequenttaggingerrors. In the follow-
ingsections,wediscusssomeoftheseerrors.
4.1 Properandcommonnouns
Themostcommonerroris relatedto the distinction
betweenproper(NE)andcommonnouns(NN).This
erroraffects2.19%of words(seefirstand fifthline
in Table 1) and accountsfor 17.29%of all tagging
errors.Currently,thedistinctionbetweenproperand
commonnounsis implementedin Fipsasfollows.
A nounis regardedascommonnounif:
• it is present in the lexicon and not explic-
itly marked as proper noun: Chemie, Hirsch,
Konkurrenz, or
• itisacompoundnounthatcanbeanalyzedinto
chunkswhichare presentin the lexicon: Bun-
des+bank,Finanz+markt,Sitz+platz.
A nounis regardedaspropernounif:
• it is explicitlymarked as such in the lexicon:
Gregor, Berlin,Europa.
• it is not present in the lexicon and cannot
be fully analyzed as compound noun: Talk,
Gaullismus,Kibbuzarbeiter.
Taggingerrorsoccurin two ways. Wordsthatare
annotatedas commonnouns by TIGER are anno-
tated as proper nouns by Fips (see first line in Ta-
ble 1). Thishappensfor all commonnounsthatare
not present in the lexicon (e.g., Primadonna,Port-
folio, Niedersachse,Gaullismus). There are also
compoundnouns with a proper noun complement:
Vichy-Zeiten, Spreearm. While TIGER considers
these words as commonnounsbecausethe head is
a commonnoun, Fips still analyzesthemas proper
nouns.ForotherwordslikeMarseillaise,theTIGER
annotationascommonnounmaybequestioned.
Intheotherway, someTIGERpropernounshave
beentaggedbyFipsascommonnouns(cf. fifthline
inTable1). Onecommoncategoryoferroneoustag-
gingisthecaseofhomonymousproperandcommon
nouns. For example,Kohl and Teufel are common
nouns,butalsothenamesofGermanpoliticiansand
thereforepropernouns.Thesemisinterpretationsare
due to the fact that Fips does not containany spe-
cificNamedEntityRecognitionmodule.WhileFips
successfullyrelies on letter case to identifyproper
nouns in other languages,this approachobviously
doesnotworkin German.
Some proper nouns exhibit a more subtle phe-
nomenon: words like Mannheim, Wendland or
Kantstrasse are analyzed by Fips as common
compound nouns (Mann+Heim, wenden+Land,
Kante+Strasse). Again, a Named Entity Recogni-
tion systemwould prevent such unfortunateanaly-
ses. Furthermore,wedonotfinditcompellingtoan-
alyzeBuddha,BundesbankandBundeskriminalamt
aspropernouns.
Tosumup,thesourceofnounmistaggingisthree-
fold. First, the Fips lexicon contains some gaps.
Second, the lack of a Named Entity Recognition
modulein Fips causesan overgenerationof homo-
graphcommonnounswhereapropernounwouldbe
appropriate. Third, the distinctionbetweenproper
andcommonnounsisnotclear-cut,andsomediver-
gencescanbeconsideredasnormal.
4.2 Conjunctionsandadverbs
Conjunctionsare frequentlymistaggedas adverbs.
Above all, this error affects the words und, aber,
denn, whichcanhave an adverbial(ADV) or a con-
junction(KON)reading. In (1), the firstoccurrence
of und is erroneouslytaggedas adverb. However, if
we parsethe firstpartof the sentenceonly(2), Fips
obtainsthe correct conjunctionreading. This sug-
gests that the conjunctionreadingis available also
for(1),butthattherankingmechanismisflawedand
preferstheadverbreading.
(1) Automatensind dort nur in Geschäftenund
Restaurants erlaubt und nicht wie in der
BundesrepublikauchimFreien.
(2) Automatensind dort nur in Geschäftenund
Restaurantserlaubt.
Ingeneral,itseemsthatFipsgetstheconjunctions
rightinshortsentences,whileiteasilygetsconfused
withlongersentences. However, the preferencefor
theadverbialreadingcanbeeasilyexplained.In or-
der to proposea conjunction,the parsermustiden-
tifytwo conjunctsof thesamecategory, whereasan
adverb doesnot have that requirement.Thus,if the
parserfailstofindtwosuitableconjuncts,itwillpro-
posethelessconstrainedadverbialreading.
19
#BOS471490 10884279940
Der der ART Nom.Sg.Masc NK 500
Minister Minister NN Nom.Sg.Masc NK 500
deutete deuten VVFIN 3.Sg.Past.Ind HD 504
für für APPR – AC 503
Zuzahlungen Zuzahlung NN Acc.Pl.Fem NK 503
bei bei APPR – AC 501
Kuren Kur NN Dat.Pl.Fem NK 501
eine ein ART Acc.Sg.Fem NK 502
Obergrenze Obergrenze NN Acc.Sg.Fem NK 502
an an PTKVZ – SVP 504
. – $. – – 0
#500 – NP – SB 504
#501 – PP – MNR 503
#502 – NP – OA 504
#503 – PP – MO 504
#504 – S – – 0
#EOS47149
Figure3: Anexamplesentenceof theTIGERcorpus.The#BOS and#EOS linesmarkthebeginningandtheendof
a sentence. The columnsshow: the word (or word component)as foundin the text; the lemma;the POS tag in the
STTStagset;themorphologicalfeatures.Thefifthandsixthcolumn,aswellasthelinesbeginningwith#50x, contain
informationfortheconstructionoftheparsetreeandarenotrelevantforourstudy.
4.3 Adjectivesandadverbs
In contrast to English or French, there is no for-
mal difference in Germanbetweenadjectives used
aspredicates(e.g.,Eristschnell)orasadverbs(e.g.,
Erfährtschnell). Thisformalidentitymayhavemo-
tivatedthe developersof the STTStagsetto use the
sametag(ADJD)inbothcases.Incontrast,theGer-
manFips taggeris basedon earlierwork on French
and English,wheredistincttags for adverbialsand
predicatives are needed. Therefore,it alsousesdif-
ferenttagsforGerman.
We triedtocomeupwitha simplesolutiontothis
problemby assigningthe ADJD tag to all adverbs
whosebaseformsarehomographwithan adjective.
However, in this case, we also assignedthe ADJD
tag to words like ganz, natürlich, wirklich, which
are taggedas proper adverbs (ADV) in TIGER.In
short, we had the choice of either overgenerating
ADV tags (keeping the Fips output as-is) or over-
generatingADJD tags (with the homographmodi-
fication). Preliminarytestsshowedsimilar amounts
of overgenerationin bothcases. We have thuscho-
sento stickto theoriginalFipsanalyses.
4.4 Particlesfollowedbyadjectives
STTS introduces a special tag (PTKA) for parti-
cles“followedby adjectives or adverbs”,for exam-
ple am [schönsten], zu [schnell]. In Fips, the class
of comparative adverbs also containsauch, so and
mehr. Of course, these words are not always fol-
lowed by adjectives, and shouldthus not always be
given the PTKA tag. While different readingsare
indeedavailablein theFipslexicon,theresultssug-
gestthatFipsovergeneralizesthecomparative read-
ing and assignsthe PTKAtag even in cases where
a normalADV tag wouldbe adequate. (3) shows a
sentencewhereFipserroneouslyassignedthePTKA
tagto auch.
(3) Der Verkehrssenator, wie er künftig auch
heißenmöge,...
4.5 Pronouns
Theseventhlinereferstothehomographyofthedef-
inite determinerand the relative pronoun(PRELS)
whenever Fips cannot find an agreementbetween
thedeterminerandtheheadofthenounphrase.
(4) NeueDebatteüberdenAtomschild
20
In (4), the Fips lexicon only containsthe neuter
lexeme Schild (whichserves as a headof the com-
pound noun Atomschild), but not the rarer mas-
culine homograph lexeme. This lexical gap pre-
vents the masculinedeterminerden to be attached
to Atomschild as a determiner, and Fips resortsto
therelative pronounanalysisinstead.
4.6 Verbproblems
Verbtaggingseemsto be a seriousproblemto Fips:
fourof the ten mostfrequenttaggingerrorsinvolve
verbs.
Thefirsttypeof erroris relatedto the distinction
betweenauxiliaryandfullverbs.Thethreeauxiliary
verbs haben, sein, werden can also have full verb
readings,dependingonthecontext. We recentlyob-
servedthatFipspreferredtheauxiliaryreadingeven
in cases where a full verb readingis required,and
subsequentlymodifiedtheconstraintsonthelexeme
selection.It now turnsoutthattheseconstraintsare
too strong and lead to a massive overgenerationof
thefullverbreading.
Then, Fips tends to overgenerate imperatives:
thirdpersonsingularformsareerroneouslyanalyzed
as imperative plurals(e.g.,kommt,schreit). Again,
thisisduetoagreementconstraints:thethirdperson
singularrequiresan overt subject, while an imper-
ative does not. If Fips fails to find a subject that
agreeswiththeverb(forexamplebecauseof an un-
detectedlongdistancedependency), it willresortto
an imperative reading.In thefuturedevelopmentof
Fips, furtherrestrictionsshouldbe imposedon the
use of imperative formsas theseare extremelyrare
in newspapertext.
ThelasttwolinesinTable1revealthatfiniteverb
formsare preferredto infiniteforms: infinitives are
mistaggedas finite plural forms, and past partici-
pleswithoutge-prefixaremistaggedasthirdperson
singularforms (for regular verbs) or as past plural
form(forirregularverbswith-en participle).These
phenomenadepend on long distance relations and
shouldtypicallybenefitfromafullparsingapproach
like the one usedby Fips. Two factorsmayexplain
why this is not the case. First, many sentencesin
which such errors occur could not be parsed com-
pletelyby Fips; longdistancerelationsarenotfully
detectedin thesecases.Second,theimplementation
of passive and modal sentences is incompleteand
TIGERBaseForm FipsBaseForm
dieser diese
anderer ander
welche welcher
Beamte Beamter
Angestellte Angestellter
Figure4: Forsomepronounsandnouns,TIGERandFips
usedifferentbaseforms.
lackssomeessentialconstraintsonverbformselec-
tion.
5 Lemmatizerresults
On the whole TIGER corpus (792 885 words),
94.32% of the words (747 855) were correctly
lemmatized. Most errors were due to diverg-
ing base form choices. This especially holds for
pronouns and nominalized adjectives (cf. Fig-
ure 4), but also for pronouns. In TIGER, femi-
nine and neuter pronounsalways refer to the mas-
culine lemma, whereas Fips separates the gen-
ders more strictly: der (Dat.Sg.Fem) refers to the
lemma der (Nom.Sg.Masc) in TIGER, but to die
(Nom.Sg.Fem)in Fips. Moreover, participlesused
asadjectiveskeeptheinfinitiveasbaseforminFips,
but notin TIGER.
Some lemma errors are due to wrong POS tag-
ging.Forinstance,wefoundthatFipsovergenerates
imperatives. For example,einig is not analyzedas
adjective,butastheimperativesingular(withelision
offinale) ofsicheinigen; theadjectivenötigeisan-
alyzedas the imperative singularof nötigen. How-
ever, suchawkward analysesshouldbe easyto iron
out.
Globally, wefindthatveryfew errorsaredirectly
due to the lemmatizer;most of them are eitherdue
to differentbaseformsorto POStaggingerrors.
6 Morphologyresults
Afterthediscussionofthepart-of-speechtaggerand
lemmatizerfunctionalities of Fips, we now turn to
the last functionality, the morphologicalanalyzer.
We restrictedour evaluation to the words that ob-
tained correct POS tags: if the POS tag is already
wrong,it is very likely that the morphologywill be
wrongaswell.Table2reportstheresultsofthemor-
21
Type Number Percentage
Numbermismatch 15617 2.26
Casemismatch 12420 1.79
Gendermismatch 8461 1.22
Degreemismatch 514 0.07
Personmismatch 108 0.02
Correctanalysis
ornomorphology 665110 96.06
Testedwords 692386 100.00
Table2: Resultsofthemorphologicalanalysis.Thetable
presentsthe numbersof words that have been correctly
analyzedbyFips, andthetypesoferrorsthatoccurred.A
wordcanpresentseveralmismatchtypes.
phologyevaluation. Parts of speechwithoutinflec-
tionwereconsideredascorrectlyanalyzed.We split
the errors into five categories, accordingto the in-
flectionfeaturethat Fips failed to predictcorrectly.
Thedifferentmismatchtypesdonotsumupto100%
becauseawordcanshowseveralmismatches(e.g.,a
nouncanshowcaseandnumbermismatch),andbe-
causenotall typesof mismatch applyto all partsof
speech(for instance,degree mismatchonly applies
to adjectives).
It is not easy to find recurrentpatternsin the er-
rors. However, we foundthat most errorsoccurred
in noun phrases. Most inflected adjective and ar-
ticle forms admit several morphologicalanalyses,
but the ambiguitiescan usually be reduced by the
syntacticcontext. If the ambiguitiesare reducedin
an incorrectway, this meansthat the syntacticcon-
text has been analyzedbadly. In otherwords, such
morphologyerrorsoften reflectbad parses. There-
fore, it might be useful to addressthese errors be-
foreevaluatingtheparsingperformanceofFips. An-
otherratheroddfactisthatnounswithidenticalsin-
gular and pluralforms(for example,Minister, Un-
ternehmen) prefertobeanalyzedaspluralsbyFips.
Hereagain,thesecaseshintat badparses.
Degree mismatches result from a bug in Fips:
comparative formsin predicative positionsas in (5)
areassignedthepositive taginsteadofthecompara-
tive one.
(5) ...umnochtieferindenKosmosblickenzu
können.
7 Relatedwork
It maybe interestingto compareFipsto a statistical
part-of-speechtaggerfor German. The TnT tagger
(Brants,2000)is basedon HiddenMarkov Models,
andhasbeentrainedandtestedontheNEGRAcor-
pus(Skutetal.,1997);NEGRAisthepredecessorof
TIGERand usesthe sametagset. Brants(2000)re-
portsanoverallaccuracyof96.7%.However,TnTis
notdirectlycomparableto Fipsforseveralreasons.
First,weshowedthatFipsoriginallyusedadiffer-
enttagset,basedon differentlinguisticassumptions
thanSTTS.Thoseconceptionaldifferencesmakeup
a large part of the errors, as has been shown for
the distinctionbetween the ADJD and ADV tags.
By contrast,TnT has beentraineddirectlyover the
STTStagsetandshouldthusnotpresentsucherrors.
Second, the recurrenceof certain error patterns
withFipsillustratestheclassicalproblemofmanual
rulerankingandweightingin rule-basedsystems.
Third,Fips has beenconceived as a parser in the
firstplace,andits taggerfunctionalityshouldrather
beviewedasaby-product.Hence,itsalgorithmsare
notoptimizedforPOStagging.Whiletheremaybe
simplerapproachesto obtain hightaggingaccuracy,
themethodchosenforFipsseemstheoreticallymore
plausibleto us.
As we pointed out at the beginning, this tagger
evaluationhasbeenstartedasafirststeptowardsthe
evaluationoftheFipsparser. WhilePOStagginghas
theadvantageofoperatingword-by-wordandofbe-
ing rathertheory-independent,these two properties
donotholdforparsing.
The phrasetrees in TIGERare rather flat, while
the ones generated by Fips are deeper and closer
to recentgenerative grammarframeworks. We will
thusneedto definethe typeof constituentsthatcan
becompared.Anevenbiggerissueis theallowance
of discontinuousphrases and crossingbranchesin
TIGER,whereasFips resolves thesephenomenaby
resortingto projectionsandtraces. Furtherresearch
has to show if these structural differences can be
overcomein orderto lead to a meaningfulcompar-
ison. The exact evaluationmetricwill also have to
be chosen. WhilePARSEVAL (Blacket al., 1991)
isstilloneofthemostimportantmetrics,othermea-
suresmaybe moreadaptedto our problem(Carroll
et al.,2002;RehbeinandvanGenabith,2007).
22
8 Conclusion
As we remarked above, this articlereportson work
in progress. Untilnow, we have been able to show
thatthegeneral approachofevaluatingFipswiththe
helpoftheTIGERtreebankisvalid. Withverylittle
adaptationwork (see Section3.2), we managedto
obtain87.32%of POS-taggingaccuracy. This is a
verypromisingbeginning,andthediscussionof the
errorshas shown that thereare many “low hanging
fruits”to improve theperformance.
In any way, we find that the quantitative evalu-
ation of NLP systemscan be quite rewarding: de-
velopingrule-basedsystemsis a complex task, of-
ten guided by vague intuitionsabout parsingqual-
ity. Quantitative evaluation allows us to measure
the progressof the developmentand guaranteesus
thatimprovementsononeparameterdonotyieldun-
wantedsideeffectsonanother.
Finally, the quantitative evaluation of the POS
taggingperformancesyieldsimportantfeedbackon
theforcesandweaknessesof Fips. Theresultof the
evaluationcanbeviewedasa sortofprioritylistfor
thedeveloper. Byworkingon themostcommoner-
rors in a target-orientedway, (s)heis guaranteedto
investhis/hertimein a maximallyeffective manner.
Suchguidingprinciplesareveryvaluableforthefur-
therdevelopmentof any rule-basedparsingsystem,
independentlyof the preciseaccuracy figuresof the
evaluation. Even if the adaptationof two different
tagsets and taggingphilosophiesis not straightfor-
ward,weplanto extendourevaluationto otherlan-
guages of the Fips project for which suitablegold
standardcorporaexist.
Acknowledgements
We thank Eric Wehrli and for his precioussupport
forthisworkandforhisvaluablecommentsonpre-
viousversionsofthispaper.
References
G.Adda,J.Mariani,J.Lecomte,P.Paroubek,andM.Ra-
jman. 1998. The GRACE Frenchpart-of-speechtag-
ging evaluationtask. In Proceedingsof the First In-
ternationalConference on Language Resources and
Evaluation(LREC), Granada.
E. Black, S. Abney, S. Flickenger, C. Gdaniec, C. Gr-
ishman,P. Harrison,D. Hindle,R. Ingria, F. Jelinek,
J. Klavans, M. Liberman, M. Marcus, S. Roukos,
B. Santorini,and T. Strzalkowski. 1991. Procedure
forquantitativelycomparingthesyntacticcoverageof
Englishgrammars. In HLT ’91: Proceedingsof the
Workshop on Speech and Natural Language, pages
306–311,PacificGrove, California.
S.Brants,S.Dipper, S.Hansen,W.Lezius,andG.Smith.
2002. The TIGERTreebank. In Proceedingsof the
Workshopon Treebanksand LinguisticTheories, So-
zopol.
T.Brants. 2000. TnT–astatisticalpart-of-speechtagger.
InProceedingsof theSixthAppliedNatural Language
Processing(ANLP-2000), Seattle.
J. Bresnan.2001. LexicalFunctionalSyntax. Blackwell,
Oxford.
J. Carroll,A. Frank,D. Lin, D. Prescher, and H. Uszko-
reit. 2002. Beyond PARSEVAL – towards improved
evaluationmeasuresfor parsingsystems. In Proceed-
ings of the LREC 2002 Workshop, Las Palmas, Gran
Canaria.
N. Chomsky. 1995. The Minimalist Program. MIT
Press,Cambridge,Mass.
P. W. Culicover and R. Jackendoff. 2005. SimplerSyn-
tax. OxfordUniversityPress,Oxford.
J.-P. Goldman,C. Laenzlinger, G. Soare,and E. Wehrli.
2005. L’analyseursyntaxiquemultilingueFipsdansla
campagneEASy. In Proceedingsof TALN XII, vol-
ume2, pages35–49,Dourdan.
I. Rehbein and J. van Genabith. 2007. Treebank
annotation schemes and parser evaluation for Ger-
man. In Proceedings of the 2007 Joint Conference
on EmpiricalMethodsin Natural Language Process-
ing and ComputationalNatural Language Learning
(EMNLP/CoNLL2007), pages630–639,Prague.
W. Skut, B. Krenn, T. Brants, and H. Uszkoreit. 1997.
An annotationschemefor free word orderlanguages.
InProceedingsoftheFifthConferenceonAppliedNat-
uralLanguageProcessingANLP-97,Washington,DC.
C. Thielen,A. Schiller, S. Teufel,andC. Stöckert. 1999.
GuidelinesfürdasTaggingdeutscherTextkorporamit
STTS. Technicalreport, University of Stuttgart and
UniversityofTübingen.
E. Wehrli. 2007. Fips, a “deep”linguisticmultilingual
parser. In Proceedingsof the ACL 2007Workshopon
DeepLinguisticProcessing, pages120–127,Prague.
23

