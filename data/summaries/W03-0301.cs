Data A total of 447 English-French aligned sentences (Och and Ney, 2000), and 248 Romanian-English aligned sentences were released one week prior to the deadline.
C00-2163
Team System name Description Language Technologies Institute, CMU BiBr (Zhao and Vogel, 2003) MITRE Corporation Fourday (Henderson, 2003) RALI Universit´e the Montr´eal Ralign (Simard and Langlais, 2003) Romanian Academy Institute of Artificial Intelligence RACAI (Tufis¸ et al., 2003) University of Alberta ProAlign (Lin and Cherry, 2003) University of Minnesota, Duluth UMD (Thomson McInnes and Pedersen, 2003) Xerox Research Centre Europe XRCE (Dejean et al., 2003) Table 1: Teams participating in the word alignment shared task We conducted therefore 14 evaluations for each submission file: AER, Sure/Probable Precision, Sure/Probable Recall, and Sure/Probable F-measure, with a different figure determined for NULL-Align and NO-NULL-Align alignments.
W03-0302 W03-0303 W03-0304 W03-0305 W03-0306 W03-0309
Four teams had approaches that relied (to varying degrees) on an IBM model of statistical machine translation (Brown et al., 1993).
J93-2003
Henderson. 2003.
W03-0306
The English-French aligned data were produced by Franz Och and Hermann Ney (Och and Ney, 2000).
C00-2163
As expected, word alignment, like many other NLP tasks (Banko and Brill, 2001), highly benefits from large amounts of training data.
P01-1005
The fourth measure was originally introduced by (Och and Ney, 2000), and proposes the notion of quality of word alignment.
C00-2163
