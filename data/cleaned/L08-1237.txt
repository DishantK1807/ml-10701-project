<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>David Ahn</author>
<author>Valentin Jijkoun</author>
<author>Gilad Mishne</author>
<author>Karin Müller</author>
<author>Maarten de Rijke</author>
<author>Stefan Schlobach</author>
</authors>
<title>Using Wikipedia at the TREC QA Track</title>
<date>2004</date>
<booktitle>In Proceedings of TREC</booktitle>
<marker>Ahn, Jijkoun, Mishne, Müller, de Rijke, Schlobach, 2004</marker>
<rawString>David Ahn, Valentin Jijkoun, Gilad Mishne, Karin Müller, Maarten de Rijke, and Stefan Schlobach. 2004. Using Wikipedia at the TREC QA Track. In Proceedings of TREC 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Bauer</author>
<author>Gavin King</author>
</authors>
<title>Hibernate in Action. Practical Object/Relational Mapping</title>
<date>2004</date>
<publisher>Manning Publications Co</publisher>
<contexts>
<context>val. The data from the database is directly mapped to 14http://www.ukp.tu-darmstadt.de/software/ 15http://download.wikipedia.org/ Java objects using the Hibernate object-relational mapping framework (Bauer and King, 2004). This also means that JWPL is not restricted to using a certain database, but may run on top of the most common database systems.16 The design of the object-oriented programming interface is centere</context>
</contexts>
<marker>Bauer, King, 2004</marker>
<rawString>Christian Bauer and Gavin King. 2004. Hibernate in Action. Practical Object/Relational Mapping. Manning Publications Co.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandre Bouchard</author>
<author>Percy Liang</author>
<author>Thomas Griffiths</author>
<author>Dan Klein</author>
</authors>
<title>A probabilistic approach to diachronic phonology</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL</booktitle>
<pages>887--896</pages>
<contexts>
<context>nsively as Wikipedia. Interest has nonetheless already arisen, as it has recently been employed in areas like subjectivity and polarity classification (Chesley et al., 2006), or diachronic phonology (Bouchard et al., 2007). All these tasks require reliable lexical semantic information which usually comes from linguistic knowledge baseslikeWordNet(Fellbaum, 1998)orGermaNet(Kunze, 2004). They are usually shipped with ea</context>
</contexts>
<marker>Bouchard, Liang, Griffiths, Klein, 2007</marker>
<rawString>Alexandre Bouchard, Percy Liang, Thomas Griffiths, and Dan Klein. 2007. A probabilistic approach to diachronic phonology. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 887–896.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan Bunescu</author>
<author>Marius Pasca</author>
</authors>
<title>Using Encyclopedic Knowledge for Named Entity Disambiguation</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics</booktitle>
<pages>9--16</pages>
<location>Trento, Italy</location>
<contexts>
<context>ion (Ruiz-Casado et al., 2005), information retrieval (Gurevych et al., 2007), question answering (Ahn et al., 2004), computing semantic relatedness (Zesch et al., 2007), or named entity recognition (Bunescu and Pasca, 2006). Wiktionary has not yet been exploited for research purposes as extensively as Wikipedia. Interest has nonetheless already arisen, as it has recently been employed in areas like subjectivity and pol</context>
</contexts>
<marker>Bunescu, Pasca, 2006</marker>
<rawString>Razvan Bunescu and Marius Pasca. 2006. Using Encyclopedic Knowledge for Named Entity Disambiguation. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics, pages 9–16, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paula Chesley</author>
<author>Bruce Vincent</author>
<author>Li Xu</author>
<author>Rohini Srihari</author>
</authors>
<title>Using verbs and adjectives to automatically classify blog sentiment</title>
<date>2006</date>
<booktitle>In Proceedings of AAAI-CAAW-06, the Spring Symposia on Computational Approaches to Analyzing Weblogs</booktitle>
<contexts>
<context>yet been exploited for research purposes as extensively as Wikipedia. Interest has nonetheless already arisen, as it has recently been employed in areas like subjectivity and polarity classification (Chesley et al., 2006), or diachronic phonology (Bouchard et al., 2007). All these tasks require reliable lexical semantic information which usually comes from linguistic knowledge baseslikeWordNet(Fellbaum, 1998)orGermaN</context>
</contexts>
<marker>Chesley, Vincent, Xu, Srihari, 2006</marker>
<rawString>Paula Chesley, Bruce Vincent, Li Xu, and Rohini Srihari. 2006. Using verbs and adjectives to automatically classify blog sentiment. In Proceedings of AAAI-CAAW-06, the Spring Symposia on Computational Approaches to Analyzing Weblogs.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet An Electronic Lexical Database</title>
<date>1998</date>
<publisher>MIT Press</publisher>
<location>Cambridge, MA</location>
<contexts>
<context>n (Chesley et al., 2006), or diachronic phonology (Bouchard et al., 2007). All these tasks require reliable lexical semantic information which usually comes from linguistic knowledge baseslikeWordNet(Fellbaum, 1998)orGermaNet(Kunze, 2004). They are usually shipped with easy-to-use application programming interfaces (APIs), e.g. JWNL1 or GermaNetAPI2, thatallowforeasyintegrationintoapplications. However, Wikiped</context>
<context>boratively constructed by mainly nonprofessional volunteers on the web. We call such a knowledge base Collaborative Knowledge Base (CKB), as opposed to a Linguistic Knowledge Base (LKB) like WordNet (Fellbaum, 1998) or GermaNet (Kunze, 2004). In this section, we briefly analyze the CKBs Wikipedia and Wiktionary as lexical semantic knowledge bases, and compare them with traditionally used LKBs. 2.1. Wikipedia Wi</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet An Electronic Lexical Database. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeniy Gabrilovich</author>
<author>Shaul Markovitch</author>
</authors>
<title>Overcoming the Brittleness Bottleneck using Wikipedia: Enhancing Text Categorization with Encyclopedic Knowledge</title>
<date>2006</date>
<booktitle>In Proceedings of the Twenty-First National Conference on Artificial Intelligence and the Eighteenth Innovative Applications of Artificial Intelligence Conference</booktitle>
<publisher>AAAI Press</publisher>
<location>Boston, Massachusetts, USA</location>
<contexts>
<context> and current developments. In particular, the potential of Wikipedia as a lexical semantic knowledge base has recently started to get explored. It has been used in NLP tasks like text categorization (Gabrilovich and Markovitch, 2006), information extraction (Ruiz-Casado et al., 2005), information retrieval (Gurevych et al., 2007), question answering (Ahn et al., 2004), computing semantic relatedness (Zesch et al., 2007), or name</context>
</contexts>
<marker>Gabrilovich, Markovitch, 2006</marker>
<rawString>Evgeniy Gabrilovich and Shaul Markovitch. 2006. Overcoming the Brittleness Bottleneck using Wikipedia: Enhancing Text Categorization with Encyclopedic Knowledge. In Proceedings of the Twenty-First National Conference on Artificial Intelligence and the Eighteenth Innovative Applications of Artificial Intelligence Conference, Boston, Massachusetts, USA, July. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeniy Gabrilovich</author>
</authors>
<date>2007</date>
<note>WikiPrep. URL http://www.cs.technion. ac.il/~gabr/resources/code/wikiprep</note>
<contexts>
<context>everal seconds to retrieve a given article). Additionally, the time that is required to retrieve an article is not easily predictable, but depends on the article’s position in the XML dump. WikiPrep (Gabrilovich, 2007) is a preprocessor that transforms a Wikipedia XML dump into an optimized XML formatthatexplicitlyencodesinformationsuchasthecategory hierarchy or article redirects. However, as the resulting data is</context>
</contexts>
<marker>Gabrilovich, 2007</marker>
<rawString>Evgeniy Gabrilovich. 2007. WikiPrep. URL http://www.cs.technion. ac.il/~gabr/resources/code/wikiprep/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jim Giles</author>
</authors>
<title>Internet encyclopaedias go head to head</title>
<date>2005</date>
<journal>Nature</journal>
<volume>438</volume>
<contexts>
<context>acy and comprehensiveness, whereas LKBs typically enforce editorial quality control. However, the collaborative construction approach has been argued to yield remarkable factual quality in Wikipedia (Giles, 2005), and the quality of LKBs like WordNet has also been target of criticism (Kaplan and Schubert, 2001). 3. Related Work To our knowledge, there is no other API for Wiktionary than the one proposed and </context>
</contexts>
<marker>Giles, 2005</marker>
<rawString>Jim Giles. 2005. Internet encyclopaedias go head to head. Nature, 438(7070):900–901, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iryna Gurevych</author>
<author>Christof Müller</author>
<author>Torsten Zesch</author>
</authors>
<title>What to be? Electronic Career Guidance Based on Semantic Relatedness</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics</booktitle>
<pages>1032--1039</pages>
<location>Prague, Czech Republic</location>
<contexts>
<context> recently started to get explored. It has been used in NLP tasks like text categorization (Gabrilovich and Markovitch, 2006), information extraction (Ruiz-Casado et al., 2005), information retrieval (Gurevych et al., 2007), question answering (Ahn et al., 2004), computing semantic relatedness (Zesch et al., 2007), or named entity recognition (Bunescu and Pasca, 2006). Wiktionary has not yet been exploited for research</context>
<context>nalyzing and accessing the structure of the Wikipedia category graph (Zesch and Gurevych, 2007), computing semantic relatedness between words (Zesch et al., 2007), and semantic information retrieval (Gurevych et al., 2007). When analyzing the structure of the Wikipedia category graph, categories assigned to the articles of Wikipedia are viewed as nodes in a directed graph, where the subcategory relation between two ca</context>
</contexts>
<marker>Gurevych, Müller, Zesch, 2007</marker>
<rawString>Iryna Gurevych, Christof Müller, and Torsten Zesch. 2007. What to be? Electronic Career Guidance Based on Semantic Relatedness. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 1032–1039, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aaron N Kaplan</author>
<author>Lenhart K Schubert</author>
</authors>
<title>Measuring and improving the quality of world knowledge extracted from WordNet</title>
<date>2001</date>
<tech>Tech. Rep. 751 14627-0226</tech>
<institution>Dept. of Computer Science, Univ. of Rochester</institution>
<location>Rochester, NY</location>
<contexts>
<context>owever, the collaborative construction approach has been argued to yield remarkable factual quality in Wikipedia (Giles, 2005), and the quality of LKBs like WordNet has also been target of criticism (Kaplan and Schubert, 2001). 3. Related Work To our knowledge, there is no other API for Wiktionary than the one proposed and described in this paper. Thus, we focus in this section on a comparison of freely available Wikipedi</context>
</contexts>
<marker>Kaplan, Schubert, 2001</marker>
<rawString>Aaron N. Kaplan and Lenhart K. Schubert. 2001. Measuring and improving the quality of world knowledge extracted from WordNet. Tech. Rep. 751 14627-0226, Dept. of Computer Science, Univ. of Rochester, Rochester, NY, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudia Kunze</author>
</authors>
<title>Lexikalisch-semantische Wortnetze, chapter Computerlinguistik und Sprachtechnologie</title>
<date>2004</date>
<pages>423--431</pages>
<publisher>Spektrum Akademischer Verlag</publisher>
<contexts>
<context>or diachronic phonology (Bouchard et al., 2007). All these tasks require reliable lexical semantic information which usually comes from linguistic knowledge baseslikeWordNet(Fellbaum, 1998)orGermaNet(Kunze, 2004). They are usually shipped with easy-to-use application programming interfaces (APIs), e.g. JWNL1 or GermaNetAPI2, thatallowforeasyintegrationintoapplications. However, Wikipedia and Wiktionary have </context>
<context>nly nonprofessional volunteers on the web. We call such a knowledge base Collaborative Knowledge Base (CKB), as opposed to a Linguistic Knowledge Base (LKB) like WordNet (Fellbaum, 1998) or GermaNet (Kunze, 2004). In this section, we briefly analyze the CKBs Wikipedia and Wiktionary as lexical semantic knowledge bases, and compare them with traditionally used LKBs. 2.1. Wikipedia Wikipedia is a multilingual,</context>
</contexts>
<marker>Kunze, 2004</marker>
<rawString>Claudia Kunze, 2004. Lexikalisch-semantische Wortnetze, chapter Computerlinguistik und Sprachtechnologie, pages 423–431. Spektrum Akademischer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tyler Riddle</author>
</authors>
<title>Parse::MediaWikiDump. URL http://search. cpan.org/~triddle/Parse-MediaWikiDump-0.40/. MariaRuiz-Casado,EnriqueAlfonseca,andPabloCastells</title>
<date>2006</date>
<booktitle>In AWIC</booktitle>
<pages>380--386</pages>
<contexts>
<context>es a substantial overhead that might render large-scale NLP tasks impossible. This overhead can be avoided by directly accessing the database dumps. For example, the Perl module Parse::MediaWikiDump (Riddle, 2006) parses the Wikipedia XML dump to retrieve articles. As Wikipedia dumps are very large (over 3 GB of compressed data for the snapshot of the English Wikipedia from Feb 2008), the performance of parsi</context>
</contexts>
<marker>Riddle, 2006</marker>
<rawString>Tyler Riddle. 2006. Parse::MediaWikiDump. URL http://search. cpan.org/~triddle/Parse-MediaWikiDump-0.40/. MariaRuiz-Casado,EnriqueAlfonseca,andPabloCastells. 2005. Automatic Assignment of Wikipedia Encyclopedic Entries to WordNet Synsets. In AWIC, pages 380–386.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bayle Shanks</author>
</authors>
<title>Wikigateway: a library for interoperability and accelerated wiki development</title>
<date>2005</date>
<booktitle>In WikiSym ’05: Proceedings of the 2005 international symposium on Wikis</booktitle>
<pages>53--66</pages>
<publisher>ACM Press</publisher>
<location>New York, NY, USA</location>
<contexts>
<context>eatesmallprogramscalledbots acting on behalf of a normal user and usually employed for maintenancetasks, (ii)theWikiGatewaytoolbox, aunified API for interfacing with a variety of remote wiki engines (Shanks, 2005), and (iii) the system developed by Strube and Ponzetto (2006) relying on a modified version of the WWW::Wikipedia module to retrieve articles. Crawling can be avoided by running an own server using </context>
</contexts>
<marker>Shanks, 2005</marker>
<rawString>Bayle Shanks. 2005. Wikigateway: a library for interoperability and accelerated wiki development. In WikiSym ’05: Proceedings of the 2005 international symposium on Wikis, pages 53– 66, New York, NY, USA. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Strube</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>WikiRelate! Computing semantic relatedness using Wikipedia</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st National Conference on ArtificialIntelligence (AAAI-06</booktitle>
<pages>1419--1424</pages>
<location>Boston, Mass</location>
<marker>Strube, Ponzetto, 2006</marker>
<rawString>Michael Strube and Simone Paolo Ponzetto. 2006. WikiRelate! Computing semantic relatedness using Wikipedia. In Proceedings of the 21st National Conference on ArtificialIntelligence (AAAI-06), pages 1419–1424, Boston, Mass., July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ed Summers</author>
</authors>
<date>2006</date>
<note>WWW:Wikipedia. URL http://search.cpan.org/ ~esummers/WWW-Wikipedia-1.9</note>
<contexts>
<context>Wikipedia page is to enter a search term on the Wikipedia web site.8 However, this approach is not suited for automatic access to Wikipedia articles by an application. The Perl module WWW::Wikipedia (Summers, 2006) offers simple means for retrieving Wikipedia pages by programmatically querying the Wikipedia web site. However, this approach poses enormous load on the Wikipedia servers when used in large-scale a</context>
</contexts>
<marker>Summers, 2006</marker>
<rawString>Ed Summers. 2006. WWW:Wikipedia. URL http://search.cpan.org/ ~esummers/WWW-Wikipedia-1.9/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jakob Voss</author>
</authors>
<title>Collaborative thesaurus tagging the Wikipedia way. ArXiv Computer Science e-prints</title>
<date>2006</date>
<pages>0604036</pages>
<contexts>
<context>on of freely available knowledge.3 Articles in Wikipedia form a heavily interlinked knowledge base, enriched with a category system emerging from collaborative tagging, which constitutes a thesaurus (Voss, 2006). Wikipedia thus contains a rich body of lexical semantic information, whose aspects are thoroughly described in (Zesch et al., 2007). This includes knowledge about named entities, domain specific te</context>
</contexts>
<marker>Voss, 2006</marker>
<rawString>Jakob Voss. 2006. Collaborative thesaurus tagging the Wikipedia way. ArXiv Computer Science e-prints, cs/0604036.</rawString>
</citation>
<citation valid="false">
<authors>
<author>2008a Wikipedia</author>
</authors>
<note>URL http://www. wikipedia.org</note>
<marker>Wikipedia, </marker>
<rawString>Wikimedia Foundation. 2008a. Wikipedia. URL http://www. wikipedia.org.</rawString>
</citation>
<citation valid="false">
<authors>
<author>2008b Wiktionary</author>
</authors>
<note>URL http://www. wiktionary.org</note>
<marker>Wiktionary, </marker>
<rawString>Wikimedia Foundation. 2008b. Wiktionary. URL http://www. wiktionary.org.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Torsten Zesch</author>
<author>Iryna Gurevych</author>
</authors>
<title>Analysis of the Wikipedia Category Graph for NLP Applications</title>
<date>2007</date>
<booktitle>In Proceedings of the TextGraphs-2 Workshop (NAACL-HLT</booktitle>
<pages>1--8</pages>
<contexts>
<context>cess to Wikipedia and Wiktionary proposed in this paper have already been put into service for large-scale NLP research, such as analyzing and accessing the structure of the Wikipedia category graph (Zesch and Gurevych, 2007), computing semantic relatedness between words (Zesch et al., 2007), and semantic information retrieval (Gurevych et al., 2007). When analyzing the structure of the Wikipedia category graph, categori</context>
</contexts>
<marker>Zesch, Gurevych, 2007</marker>
<rawString>Torsten Zesch and Iryna Gurevych. 2007. Analysis of the Wikipedia Category Graph for NLP Applications. In Proceedings of the TextGraphs-2 Workshop (NAACL-HLT 2007), pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Torsten Zesch</author>
<author>Iryna Gurevych</author>
<author>Max Mühlhäuser</author>
</authors>
<date>2007</date>
<contexts>
<context>ilovich and Markovitch, 2006), information extraction (Ruiz-Casado et al., 2005), information retrieval (Gurevych et al., 2007), question answering (Ahn et al., 2004), computing semantic relatedness (Zesch et al., 2007), or named entity recognition (Bunescu and Pasca, 2006). Wiktionary has not yet been exploited for research purposes as extensively as Wikipedia. Interest has nonetheless already arisen, as it has re</context>
<context>system emerging from collaborative tagging, which constitutes a thesaurus (Voss, 2006). Wikipedia thus contains a rich body of lexical semantic information, whose aspects are thoroughly described in (Zesch et al., 2007). This includes knowledge about named entities, domain specific terms or domain specific word senses that is rarely available in LKBs. Additionally, the redirect system of Wikipedia articles can be u</context>
<context> put into service for large-scale NLP research, such as analyzing and accessing the structure of the Wikipedia category graph (Zesch and Gurevych, 2007), computing semantic relatedness between words (Zesch et al., 2007), and semantic information retrieval (Gurevych et al., 2007). When analyzing the structure of the Wikipedia category graph, categories assigned to the articles of Wikipedia are viewed as nodes in a d</context>
</contexts>
<marker>Zesch, Gurevych, Mühlhäuser, 2007</marker>
<rawString>Torsten Zesch, Iryna Gurevych, and Max Mühlhäuser. 2007.</rawString>
</citation>
</citationList>
</algorithm>

