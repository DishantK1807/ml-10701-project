Since there is no standard collection of texts used for benchmarking all MT systems, it is not clear how a system that achieves, e.g., BLEUr4n4 1 score 0.556 tested on “490 utterances selected from the WSJ” (Cmejrek et al, 2003:89) may be compared to another system which achieves, e.g., the BLEUr1n4 score 0.240 tested on 10,150 sentences from the “Basic Travel Expression Corpus” (Imamura et al., 2003:161).
E03-1004 E03-1029
Automated metrics such as BLEU (Papineni et al., 2002), RED (Akiba et al, 2001), Weighted N-gram model (WNM) (Babych, 2004), syntactic relation / semantic vector model (Rajman and Hartley, 2001) have been shown to correlate closely with scoring or ranking by different human evaluation parameters.
P02-1040
It was found to produce automated scores, which strongly correlate with human judgements about translation fluency (Papineni et al., 2002).
P02-1040
