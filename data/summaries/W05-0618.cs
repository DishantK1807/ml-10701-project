Recently, Roth & Yih (2004) applied an ILP model to the task of the simultaneous assignment of semantic roles to the entities mentioned in a sentence and recognition of the relations holding between them.
W04-2401
We view our work as an extension to Roth & Yih (2004) in two important aspects.
W04-2401
Reiter (1994), Reiter & Dale (2000)), and has been successfully used to combine standard preprocessing tasks such as part-of-speech tagging, chunking and named entity recognition (e.g.
W94-0319
Buchholz et al.(1999), Soon et al.(2001)). In this paper we address the problem of aggregating the outputs of classi ers solving different NLP tasks.
J01-4004 W99-0629
As noted by Daelemans & van den Bosch (1998), individual decisions that these tasks involve can be formulated as classi cation problems falling in either of two groups: disambiguation or segmentation.
W98-1223
If due to the scarcity of contextual information the accuracy of initial classi ers is low, erroneous values passed as input to subsequent tasks can cause further misclassi cations which can distort the nal outcome (also discussed by Roth and Yih and van den Bosch et al.(1998)). As can be seen in Figure 1, solving classi cation tasks sequentially corresponds to the bestrst traversal of a weighted multi-layered lattice.
W98-1223
A similar argument against sequential modularization in NLP applications was raised by van den Bosch et al.(1998) in the context of word pronunciation learning.
W98-1223
van den Bosch (1998).
W98-1223
An example of a generic pipeline architecture is GATE (Cunningham et al., 1997) which provides an infrastructure for building NLP applications.
A97-1035
We compare pipeline-based processing with discrete optimization modeling used in the eld of computer vision and image recognition (Kleinberg & Tardos, 2000; Chekuri et al., 2001) and recently applied in NLP by Roth & Yih (2004), Punyakanok et al.(2004) and Althaus et al.(2004). Whereas Roth and Yih used optimization to solve two tasks only, and Punyakanok et al.and Althaus et al.focused on a single task, we propose a general formulation capable of combining a large number of different NLP tasks.
C04-1197 P04-1051 W04-2401
