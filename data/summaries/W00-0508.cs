The sequence Ws is thought as a noisy version of WT and the best guess I)d~ is then computed as ^ W~ = argmax P(WTWs) wT = argmax P(WslWT)P(WT) (1) wT In (Brown et al., 1993) they propose a method for maximizing P(WTIWs) by estimating P(WT) and P(WsIWT) and solving the problem in equation 1.
J93-2003
Our approach to statistical machine translation differs from the model proposed in (Brown et al., 1993) in that: • We compute the joint model P(Ws, WT) from the bilanguage corpus to account for the direct mapping of the source sentence Ws into the target sentence I?VT that is ordered according to the • source language word order.
J93-2003
The statistical machine translation approach is based on the noisy channel paradigm and the Maximum-A-Posteriori decoding algorithm (Brown et al., 1993).
J93-2003
Finite state models have been extensively applied to many aspects of language processing including, speech recognition (Pereira and Riley, 1997; Riccardi et al., 1996), phonology (Kaplan and Kay, 1994), morphology (Koskenniemi, 1984), chunking (Abney, 1991; Srinivas, 1997) and parsing (Roche, 1.999).
J94-3001
In (Knight and A1-Onaizan, 1998), finite-state machine translation is based on (Brown et al., 1993) and is used for decoding the target language string.
J93-2003
There are other approaches to statistical machine translation where translation is achieved through transduction of source language structure to target language structure (Alshawi et al., 1998b; Wu, 1997).
J97-3002 P98-1006
(Riccardi et al., 1996; Riccardi et al., 1997; Riccardi and Bangalore, 1998).
W98-1122
