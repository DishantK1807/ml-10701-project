Proceedings of the ACL 2010 Conference Short Papers, pages 115–119,
Uppsala, Sweden, 11-16 July 2010. c©2010 Association for Computational Linguistics
Automatic Colocation Sugestion in Academic Writing 
 
Jian-Cheng Wu
1
 Yu-Chia Chang
1,*
 Teruko Mitamura
2
 Jason S. Chang
1
 
1 
National Tsing Hua University 
Hsinchu, Taiwan 
{wujc86, richtrf, jason.jschang} 
@gmail.com 
2
 Carnegie Melon University  
Pitsburgh, United States            
teruko@cs.cmu.edu 
 
Abstract 
In recent years, colocation has ben 
widely acknowledged as an esential 
characteristic to distinguish native speak-
ers from non-native speakers. Research 
on academic writing has also shown that 
colocations are not only comon but 
serve a particularly important discourse 
function within the academic comunity. 
In our study, we propose a machine 
learning aproach to implementing an 
online collocation writing asistant. We 
use a data-driven clasifier to provide 
colocation sugestions to improve word 
choices, based on the result of classifica-
tion. The system generates and ranks 
sugestions to assist learners’ colocation 
usages in their academic writing with sat-
isfactory results. 
*
 
1 Introduction

The notion of collocation has been widely dis-
cused in the field of language teaching for dec-
ades. It has ben shown that colocation, a suc-
cessive comon usage of words in a chain, is 
important in helping language learners achieve 
native-like fluency. In the field of English for 
Academic Purpose, more and more researchers 
are also recognizing this important feature in 
academic writing. It is often argued that coloca-
tion can influence the efectivenes of a piece of 
writing and the lack of such knowledge might 
cause cumulative los of precision (Howarth, 
1998). 
Many researchers have discused the function 
of collocations in the highly conventionalized 
and specialized writing used within academia. 
Research also identified noticeable increases in 
the quantity and quality of collocational usage by 
                                                             
*
 Coresponding author: Yu-chia Chang (Email address: 
richtrf@gmail.com) 
native speakers (Howarth, 1998). Granger (1998) 
reported that learners underuse native-like collo-
cations and overuse atypical word combinations. 
This disparity in colocation usage betwen na-
tive and non-native speakers is clear and should 
receive more atention from the language tech-
nology community. 
To tackle such word usage problems, tradi-
tional language technology often employs a da-
tabase of the learners' comon erors that are 
manualy taged by teachers or specialists (e.g. 
Shei and Pain, 200; Liu, 202). Such system 
then identifies erors via string or pattern match-
ing and ofer only pre-stored sugestions. Com-
piling the database is time-consuming and not 
easily maintainable, and the usefulnes is limited 
by the manual collection of pre-stored suges-
tions. Therefore, it is beneficial if a system can 
mainly use untaged data from a corpus contain-
ing correct language usages rather than the error-
taged data from a learner corpus. A large corpus 
of correct language usages is more readily avail-
able and useful than a small labeled corpus of 
incorrect language usages. 
For this sugestion task, the large corpus not 
only provides us with a rich set of common col-
locations but also provides the context within 
which these colocations appear. Intuitively, we 
can take acount of such context of colocation to 
generate more suitable sugestions. Contextual 
information in this sense often entails more lin-
guistic clues to provide suggestions within sen-
tences or paragraph. However, the contextual 
information is mesy and complex and thus has 
long ben overlooked or ignored. To date, most 
fashionable sugestion methods stil rely upon 
the linguistic components within collocations as 
wel as the linguistic relationship betwen mis-
used words and their corect counterparts (Chang 
et al., 208; Liu, 209). 
In contrast to other research, we employ con-
textual information to automate sugestions for 
verb-noun lexical collocation. Verb-noun collo-
cations are recognized as presenting the most 
115
challenge to students (Howarth, 196; Liu, 
2002). More specifically, in this preliminary 
study we start by focusing on the word choice of 
verbs in collocations which are considered as the 
most dificult ones for learners to master (Liu, 
2002; Chang, 2008). The experiment confirms 
that our collocation writing asistant proves the 
feasibility of using machine learning methods to 
automatically prompt learners with colocation 
sugestions in academic writing. 
2 Collocation
Checking and Suggestion 
This study aims to develop a web service, Colo-
cation Inspector (shown in Figure 1) that acepts 
sentences as input and generates the related can-
didates for learners. 
In this paper, we focus on automaticaly pro-
viding academic collocation suggestions when 
users are writing up their abstracts. After an ab-
stract is submited, the system extracts linguistic 
features from the user’s text for machine learning 
model. By using a corpus of published academic 
texts, we hope to match contextual linguistic 
clues from users’ text to help elicit the most rele-
vant suggestions. We now formaly state the 
problem that we are addresing: 
Problem Statement: Given a sentence S writ-
ten by a learner and a reference corpus RC, our 
goal is to output a set of most probable sugges-
tion candidates c
1, c
2, ... , c
m
. For this, we train a 
classifier MC to map the context (represented as 
feature set f
1, f
2, ..., f
n
) of each sentence in RC to 
the collocations. At run-time, we predict these 
colocations for S as sugestions. 
2.1 Academic
Colocation Checker Train-
ing Procedures 
Sentence Parsing and Colocation Extraction: 
We start by colecting a large number of ab-
stracts from the Web to develop a reference cor-
pus for collocation suggestion. And we continue 
to identify collocations in each sentence for the 
subsequent processing. 
Colocation extraction is an esential step in 
preprocesing data. We only expect to extract the 
colocation which comprises components having 
a syntactic relationship with one another. How-
ever, this extraction task can be complicated. 
Take the folowing scholarly sentence from the 
reference corpus as an example (example (1)): 
(1) We introduce a novel method 
for learning to find documents 
on the web. 
 
Figure 1. The interface for the colocation sugestion 
nsubj (introduce-2, We-1) 
det (method-5, a-3) 
amod (method-5, novel-4) 
dobj (introduce-2, method-5) 
prepc_for (introduce-2, learning-7) 
aux (find-9, to-8) 
… … 
Figure 2. Dependency parsing of Example (1) 
 
Traditionaly, through part-of-spech taging, 
we can obtain a taged sentence as folows (ex-
ample (2). We can observe that the desired col-
location “introduce method”, conforming to 
“VERB+NOUN” relationship, exists within the 
sentence. However, the distance betwen these 
two words is often flexible, not necesarily rigid. 
Heuristicaly writing patterns to extract such verb 
and noun might not be effective. The patterns 
betwen them can be tremendously varied. In 
addition, some verbs and nouns are adjacent, but 
they might be intervened by clause and thus have 
no syntactic relation with one another (e.g. “pro-
pose model” in example (3)). 
(2) We/PRP  introduce/VB  a/DT  
novel/JJ  method/NN  for/IN  
learning/VBG  to/TO  find/VB  
documents/NNS  on/IN  the/DT  
web/NN  ./.  
(3) We proposed that the web-
based model would be more ef-
fective than corpus-based one. 
A natural language parser can facilitate the ex-
traction of the target type of collocations. Such 
parser is a program that works out the gramati-
cal structure of sentences, for instance, by identi-
fying which group of words go together or which 
116
word is the subject or object of a verb. In our 
study, we take advantage of a dependency parser, 
Stanford Parser, which extracts typed dependen-
cies for certain gramatical relations (shown in 
Figure 2). Within the parsed sentence of example 
(1), we can notice that the extracted dependency 
“dobj (introduce-2, method-4)” mets the crite-
rion. 
 
Using a Clasifier for the Sugestion task: A 
classifier is a function generally to take a set of 
attributes as an input and to provide a tagged 
class as an output. The basic way to build a clas-
sifier is to derive a regression formula from a set 
of tagged examples. And this trained clasifier 
can thus make predication and assign a tag to any 
input data. 
The sugestion task in this study wil be sen 
as a classification problem. We treat the colloca-
tion extracted from each sentence as the clas tag 
(se examples in Table 1). Hopefuly, the system 
can learn the rules between tagged classes (i.e. 
colocations) and example sentences (i.e. schol-
arly sentences) and can predict which colocation 
is the most apropriate one given attributes ex-
tracted from the sentences. 
Another advantage of using a clasifer to 
automate sugestion is to provide alternatives 
with regard to the similar atributes shared by 
sentences. In Table 1, we can observe that these 
collocations exhibit a similar discourse function 
and can thus become interchangeable in these 
sentences. Therefore, based on the outputs along 
with the probability from the clasifier, we can 
provide more than one adequate suggestions. 
 
Feature Selection for Machine Learning: In 
the final stage of training, we build a statistical 
machine-learning model. For our task, we can 
use a supervised method to automaticaly learn 
the relationship betwen collocations and exam-
ple sentences. 
We chose Maximum Entropy (ME) as our train-
ing algorithm to build a collocation sugestion 
classifier. One advantage of an ME classifier is 
that in adition to asigning a clasification it can 
provide the probability of each asignment. The 
ME framework estimates probabilities based on 
the principle of making as few asumptions as 
possible. Such constraints are derived from the 
training data, expresing relationships betwen 
features and outcomes. 
Moreover, an efective feature selection can 
increase the precision of machine learning. In our 
study, we employ the contextual features which 
Table 1. Example sentences and clas tags (colloca-
tions) 
Example Sentence Clas tag   
We introduce a novel method for learning 
to find documents on the web. 
introduce 
We presented a method of improving Japa-
nese dependency parsing by using large-
scale statistical information.  
present 
In this paper, we wil describe a method of 
identifying the syntactic role of antece-
dents, which consists of two phases  
describe 
In this paper, we sugest a method that 
automatically constructs an NE tagged cor-
pus from the web to be used for learning of 
NER systems.  
sugest 
 
consist of two elements, the head and the ngram 
of context words: 
 
Head: Each collocation comprises two parts, 
colocate and head. For example, in a given verb-
noun collocation, the verb is the collocate as wel 
as the target for which we provide sugestions; 
the noun serves as the head of collocation and 
convey the essential meaning of the collocation. 
We use the head as a feature to condition the 
classifier to generate candidates relevant to a 
given head. 
 
Ngram: We use the context words around the 
target collocation by considering the corespond-
ing unigrams and bigrams words within the sen-
tence. Moreover, to ensure the relevance, those 
context words, before and after the punctuation 
marks enclosing the colocation in question, wil 
be excluded. We use the parsed sentence from 
previous step (example (2)) to show the extracted 
context features
1
 (example (4): 
(4) CN=method UniV_L=we 
UniV_R=a UniV_R=novel UniN_L=a 
UniN_L=novel UniN_R=for 
UniN_R=learn BiV_R=a_novel 
BiN_L=a_novel BiN_R=for_learn 
BiV_I=we_a BiN_I=novel_for  
                                                             
1
 CN refers to the head within colocation. Uni and Bi indi-
cate the unigram and bigram context words of window size 
two respectively. V and N diferentiate the contexts related 
to verb or noun. The ending alphabets L, R, I show the posi-
tion of the words in context, L = left, R = right, and I = in 
betwen. 
117
2.2 Automatic
Colocation Sugestion at 
Run-time 
After the ME clasifier is automaticaly trained, 
the model is used to find out the best collocation 
sugestion. Figure 3 shows the algorithm of pro-
ducing suggestions for a given sentence. The 
input is a learner’s sentence in an abstract, along 
with an ME model trained from the reference 
corpus. 
In Step (1) of the algorithm, we parse the sen-
tence for data preprocesing. Based on the parser 
output, we extract the collocation from a given 
sentence as wel as generate features sets in Step 
(2) and (3). After that in Step (4), with the 
trained machine-learning model, we obtain a set 
of likely collocates with probability as predicted 
by the ME model. In Step (5), SuggestionFilter 
singles out the valid colocation and returns the 
best collocation suggestion as output in Step (6). 
For example, if a learner inputs the sentence like 
Example (5), the features and output candidates 
are shown in Table 2. 
(5) There are many investiga-
tions about wireless network 
communication, especially it is 
important to add Internet 
transfer calculation speeds.  
3 Experiment

From an online research database, CiteSer, we 
have collected a corpus of 20,306 unique ab-
stracts, which contained 95,650 sentences. To 
train a Maximum Entropy clasifier, 46,25 col-
locations are extracted and 790 verbal collocates 
are identified as tagged classes for colocation 
sugestions. We tested the classifier on scholarly 
sentences in place of authentic student writings 
which were not available at the time of this pilot 
study. We extracted 364 colocations among 60 
randomly selected sentences as the held out test 
data not overlaping with the trainig set. To 
automate the evaluation, we blank out the verb 
colocates within these sentences and treat these 
verbs directly as the only correct suggestions in 
question, although two or more suggestions may 
be interchangeable or at least apropriate. In this 
sense, our evaluation is an underestimate of the 
performance of the proposed method. 
   While evaluating the quality of the sugestions 
provided by our system, we used the mean recip-
rocal rank (MR) of the first relevant suges-
tions returned so as to ases whether the suges-
tion list contains an answer and how far up the 
answer is in the list as a quality metric of the sys
Procedure ColocationSugestion(sent, MEmodel)  
(1)  parsedSen = Parsing(sent) 
(2)  extractedColl = CollocationExtraction(parsedSent) 
(3)  features = AsignFeature(ParsedSent)  
(4)  probCollection = MEprob(features, MEmodel)  
(5)  candidate = SugestionFilter(probCollection) 
(6)  Return candidate 
Figure 3. Colocation Sugestion at Run-time 
 
Table 2. An example from learner’s sentence 
Extracted 
Colocation 
Features 
Ranked 
Candidates 
add speed 
CN=sped 
UniV_L=important 
UniV_L=to 
UniV_R=internet 
UniV_R=transfer 
UniN_L=transfer 
UniN_L=calculation 
BiV_L=important_to 
BiV_R=internet_transfer 
BiN_L=transfer_calcula-
tion 
BiV_I=to_intenet 
improve 
increase 
determine 
maintain 
… … 
 
Table 3. MR for diferent feature sets 
Feature Sets Included In Clasifier MRR 
Features of HEAD 0.407 
Features of CONTEXT 0.469 
Features of HEAD+CONTEXT 0.518 
 
tem output. Table 3 shows that the best MR of 
our prototype system is 0.518. The results indi-
cate that on average users could easily find an-
swers (exactly reproduction of the blanked out 
colocates) in the first two to three ranking of 
suggestions. It is very likely that we get a much 
higher MMR value if we would go through the 
lists and evaluate each sgestin by hand. 
Moreover, in Table 3, we can further notice that 
contextual features are quite informative in com-
parison with the baseline feature set containing 
merely the feature of HEAD. Also the integrated 
feature set of HEAD and CONTEXT together 
achieves a more satisfactory sugestion result. 
4 Conclusion

Many avenues exist for future research that are 
important for improving the proposed method. 
For example, we ned to cary out the experi-
ment on authentic learners’ texts. We wil con-
duct a user study to investigate whether our sys-
tem would improve a learner’s writing in a real 
seting. Aditionaly, ading classifier features 
based on the translation of misused words in 
learners’ text could be beneficial  (Chang et al., 
118
2008). The translation can help to resolve preva-
lent collocation misuses influenced by a learner's 
native language. Yet another direction of this 
research is to investigate if our methodology is 
applicable to other types of colocations, such as 
AN and PN in adition to VN dealt with in this 
paper. 
In sumary, we have presented an unsuper-
vised method for suggesting collocations based 
on a corpus of abstracts collected from the Web. 
The method involves selecting features from the 
reference corpus of the scholarly texts. Then a 
classifier is automatically trained to determine 
the most probable collocation candidates with 
regard to the given context. The preliminary re-
sults show that it is beneficial to use classifiers 
for identifying and ranking colocation suges-
tions based on the context features.  
Reference 
Y. Chang, J. Chang, H. Chen, and H. Liou. 208. An 
automatic colocation writing assistant for Taiwan-
ese EFL learners: A case of corpus-based NLP 
technology. Computer Asisted Language Learn-
ing, 21(3), pages 283-299. 
S. Granger. 198. Prefabricated paterns in advanced 
EFL writing: colocations and formulae. In Cowie, 
A. (ed.) Phraseology: theory, analysis and aplica-
tions. Oxford University Pres, Oxford, pages 145-
160. 
P. Howarth. 196. Phraseology in English Academic 
Writing. Tübingen: Max Niemeyer Verlag. 
P. Howarth. 198. The phraseology of learner’s aca-
demic writing. In Cowie, A. (ed.) Phraseology: 
theory, analysis and aplications. Oxford Univer-
sity Press, Oxford, pages 161-186. 
D. Hawking and N. Craswel. 202. Overview of the 
TREC-2001 Web track. In Procedings of the 10th 
Text Retrieval Conference (TREC 201), pages 25-
31. 
L. E. Liu. 202. A corpus-based lexical semantic in-
vestigation of verb-noun miscollocations in Taiwan 
learners’ English. Unpublished master’s thesis, 
Tamkang University, Taipei, January. 
A. L. Liu, D. Wible, and N. L. Tsao. 209. Automated 
sugestions for miscolocations. In Procedings of 
the Fourth Workshop on Inovative Use of NLP for 
Building Educational Applications, pages 47-50. 
C. C. Shei and H. Pain. 200. An ESL writer’s colo-
cational aid. Computer Asisted Language Learn-
ing, 13, pages 167-182. 
119

