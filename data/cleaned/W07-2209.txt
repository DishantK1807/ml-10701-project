Proceedings of the 10th Conference on Parsing Technologies, pages 69–79, Prague, Czech Republic, June 2007.
c©2007 Association for Computational Linguistics Ambiguity Resolution by Reordering Rules in Text Containing Erors Sylvana Sofkova Hashemi Department of Linguistics, Göteborg University Box 200, SE-405 30 Göteborg, SWEDEN sylvana@ling.gu.se Abstract Writing aids such as spelling and grammar checkers are often based on texts by adult writers and are not sufficiently targeted to suport children in their writing process.
This paper reports on the development of a writing tol based on a corpus of Swedish text writen by children and on the parsing methods developed to handle text containing errors.
The system uses finite state techniques for finding grammar errors without actually specifying the error.
The ‘broadness’ of the grammar and the lexical ambiguity in words, necessary for parsing text containing errors, also yields ambiguous and/or alternative phrase annotations.
We block some of the (erroneous) alternative parses by the order in which phrase segments are selected, which causes bleeding of some rules and more ‘correct’ parsing results are achieved.
The technique shows god coverage results for agreement and verb selection phenomena.
1 Introduction
Writing on a computer in schol often involves making a fair copy from a handwriten draft.
Although a computer is an excellent means for the writing process, especially the linguistic tols are not used adequately.
Spelling and grammar correctors are in general developed for and adapted to adult writers and have difficulties to suport children in their writing development and give no space for acquisition or training.
Errors in texts writen by schol children are more frequent and the distribution of the error types is different from adult writers.
This paper reports on the development of a finite state system for finding grammar errors, called FiniteCheck, based on a corpus of Swedish text written by schol children.
The system applies descriptions of correct language use in the detection process of grammatical violations and contains no rules describing the nature of the erroneous segments the system searches for.
The approach (folowing Kartunen et al., 196) for finding errors involves developing automata that represent two ‘positive’ grammars with varying degree of detail and then subtracting the detailed one from the general one.
The difference between the automata corresponds to a grammar for errors.
2 Grammar
Checkers 2.1 Current Systems Whereas spelling checkers are standard in most word processors, grammar checking is a rather recent technology, especially for Swedish.
Different methods and techniques have been applied to handle nonsense words and thus operate on isolated words as most spelling correctors do.
Both statistical and rule-based methods and also algorithms that to some extent take into consideration the surrounding context (i.e.
context-sensitive errors) or how a word is pronounced have been used for spelling correction (cf.
Kukich, 192).
Gramar checkers involve techniques and solve problems above the single word level and require syntactic, semantic or even discourse analysis (see Section 2.2).
Grammar checking techniques started to develop first in the 1980’s with products mainly for English (see Jensen et al, 193; Vernon, 200) but also for other languages, e.g.
French (Chanod, 196), Dutch (Vose, 194), Czech (Kirschner, 69 194), Spanish and Greek (Bustamente and León, 196).
Computer-based grammar checking for Swedish is fairly recent and has primarily focused on the needs of adult writers.
The first product release of such a writing aid was in November 198 with the tol Gramatifix (Arpe, 200; Birn, 200), now part of the Swedish Microsoft Office 200.
Two other research groups developed grammar checking prototypes: Granska (Knutson, 201; Domeij, 203) and Scarie (Sågvall Hein, 199).
2.2 Methods
and Techniques Many of the grammar checking systems are commercial products and technical documentation is often minimal or even absent.
Critique (known until 1984 as Epistle) is an exception, a system developed in colaboration with IBM within the Programing Language for Natural Language Processing (PLNLP) project (Jensen et al., 193).
This tol is based on a parser using Augmented Phrase Structure Gramar (ACFG) and produces a complete analysis for all sentences (even ungrammatical) by aplication of relaxation rules when parsing fails on the first try or parse fiting procedure identifying the head and its constituents (Heidorn, 193; Jensen et al., 193).
This approach of providing analysis of all sentences had influenced other grammar formalisms such as Constraint Gramar (Karlson et al., 195) or Functional Dependency Gramar (Järvinen and Tapanainen, 198).
The methods of rule relaxation and parse fiting had an impact on the development of other grammar checking systems.
The three Swedish tols use different technology to analyze unrestricted text and detect grammar errors.
The lexical analysis in Gramatifix is based on the morphological analyzer SWETWOL, designed according to the principles of two-level morphology (Karlson, 192).
The part-of-speech assignment applies the Swedish Constraint Grammar (SWECG), a surface-syntactic parser applying context-sensitive disambiguation rules (Birn, 198).
Errors are detected by partial parsing and relaxation on rules, regarding certain word sequences as phrases despite grammar errors in them.
Granska combines probabilistic and rule-based methods, where specific error rules (around 60) and local applied rules detect ungrammaticalities in free text.
The lexical analyzer applies Hiden Markov Models and a rule matching system analyses the tagged text searching for grammatical violations defined in the detection rules and produces error description and a correction sugestion for the error (Carlberger & Kann, 199).
The grammar checker in Scarie is based on a previously developed parser, the Upsala Chart Parser (UCP), a procedural, botom-up parser, applying a longest path strategy (Sågvall Hein, 1983).
The parsing strategy of erroneous input is based on constraint relaxation and application of local error rules.
The grammar is in other words underspecified to a certain level, allowing feature violations and parsing of ungrammatical word sequences (Wedbjer Rambell, 199).
The Swedish approaches to detection of grammar errors vary from chart-based methods in Scarrie, application of constraint grammars in Grammatifix, to a combination of probabilistic and rulebased methods in Granska.
Scarie and Granska identify erroneous patterns by partial analysis, whereas Gramatifix produces ful analysis for both grammatical and ungrammatical sentences.
Al the tols define (wholy or to some extent) explicit error rules describing the nature of the error they search for.
In the process of error detection they either proceed sentence by sentence, requiring recognition of sentence boundaries, or they rely in their rules on for instance capitalization conventions.
2.3 Error
Coverage Current grammar checking systems are restricted to a small set of all posible writing errors, concerning mostly syntactic analysis.
The choice of what types of errors are detected in the Swedish tols is based on analysis of errors in writing of certain groups of writers (e.g.
professional writers, writers at work).
The coverage of error types is very similar between the systems, including errors in noun phrase agreement and agreement in predicative complement, pronoun case after preposition, word order, errors in verbs, etc.
Observations with children writing on a computer in schol (Hård af Segerstad & Sofkova Hashemi, 206; Sofkova Hashemi, forthcoming) and performance tests of the Swedish tols on texts writen by schol children (Sofkova Hashemi, 203) show that grammar checkers do not sufficiently suport schol children in their writing development.
The grammatical mistakes found in texts writen by children display different fre70 quency and distribution than in adults and the text structure as whole is different.
Main clauses are often joined together without conjunctions and punctuation marks often delimit larger textual units than syntactic sentences.
Sentence boundaries and capitalization are something the Swedish tols rely on in their detection process, which may have impact on the coverage results.
Although the systems cover many of the types of errors found in schol texts, they detect around 12% of all writing errors (Sofkova Hashemi, 203) (see Section 6).
Performance on text data such as newspaper texts and student compositions evaluated within the frames of the separate projects shows a much higher coverage of error detection on average 58% (Birn, 200; Knutson, 201; Sågvall Hein et al., 199).
3 The
Training Data 3.1 The Child Data Corpus FiniteCheck, the grammar error detector reported in this paper, is based on a corpus of Swedish text writen by schol children.
This Child Data corpus of 29 812 words (3 373 word types) is composed of computer writen and hand writen essays written by children between 9 and 13 years of age.
In general, the text structure of the compositions reveals clearly the influence of spoken language and performance difficulties in spelling, segmentation of words, the use of capitals and punctuation, with fairly wide variation both by individual and age.
In total, 260 instances of grammatical errors were found in 134 narratives.
3.2 The
Error Types The most frequent grammatical violation concerns the omision of finite verb inflection (42% of all errors), i.e. when the main finite verb in a clause lacks the appropriate present or past tense endings: (1) På naten *vakna jag av at brandlarmet tjöt in the-night wake[untensed] I from that firealarm howled – In the night I woke up from that the firealarm went off.
The correct form of the verb vakna ‘wake’ should be in the past tense, i.e. vaknade ‘woke’.
This type of error arises from the fact that the writing is highly influenced by spoken language.
In spoken Swedish regular weak verbs in the past tense often lack the appropriate ending and the spoken form then coincides with the infinitive (and for some verbs also imperative) form of the verb.
Other frequent grammar problems concern extra inserted or mising words in sentences (22%), here the preposition i ‘in’ is mising: (2) Gunar var på semester *_ norge och åkte skidor.
Gunar was on vacation _ Norway and went skis – Gunar was on vacation in Norway and skied.
word choice errors (11%), here the verb at vara lika ‘to be alike’ requires the particle til ‘to’ in combination with the noun phrase sätet ‘themanner’ and not på ‘on’ as the writer uses: (3) vi var väldigt lika *på sätet we were very like on the-manner – We were very alike in the manners.
errors in noun phrase agreement (6%), here the correct form of the noun phrase requires the noun to be definite as in den närmsta handuken ‘the nearest towel’: (4) jag tar den närmsta *handduk och slänger den i vasken I take the[def] nearest[def] towel [indef] and throw it in the sink – I take the nearest towel and throw it into the sink.
errors in verb chains (3%), here the auxiliary verb should be folowed by an infinitive, ska bli ‘wil become’, but in this case the present tense is used: (5) Men kom ihåg at det inte ska *blir någon riktig brand.
but remember that it not wil becomes[pres] some real fire – But remember that there wil not be a real fire.
Other grammar errors occurred less than ten times in the whole corpus, including reference errors, agreement between subject and predicative com71 plement, definiteness in single nouns, pronoun form, errors in infinitive phrases, word order.
Punctuation problems are also included in the analyses.
In general, the use of punctuation varies from no usage at all (mostly among the youngest children) to rather sparse marking.
In the folowing example the main clauses are joined together and the boundary between the sentences is not marked: (6) nase blev arg han gick och la sig med dom andra syskonen.
nasse became angry he went and lay himself with the other siblings – Nasse got angry.
He went and lay down with the other siblings.
The finite verb problem, verb form in verb chains and infinitive phrases and agreement problems in noun phrase are the four types of errors detected by the curent system, FiniteCheck.
4 System
architecture The framework for detection of grammar errors in FiniteCheck is built as a network of finite state transducers compiled from regular expressions including operators defined in the Xerox Finite State Tool (XFST) (Karttunen et al., 197).
Each automaton in the network composes with the result of previous aplication and in principle all the automata can be composed into a single transducer.
There are in general two types of transducers in use: one that annotates text in order to select certain segments and one that redefines or refines earlier decisions.
Anotations of any kind are handled by transducers defined as finite state markers that add reserved symbols into text and mark out syntactical segments, grammar errors, or other patterns aimed at selections.
Finite state filters are used for refinement and/or revision of earlier decisions.
The system runs under UNIX in a simple Emacs environment used for testing and development of finite state grammars.
The environment shows the results of an XFST-process run on the current Emacs buffer in a separate buffer.
An XFST-mode allows for menus to be used and recompile files in the system.
The sequenced finite state transducers of FiniteCheck are divided in four main modules: the lexicon lokup, the gramar, the parser and the error finder – see Figure 1.
text input Figure 1: The system architecture 4.1 The Lexicon Lookup The lexicon of around 160, 00 word forms, is built as a finite state transducer, using the Xerox tol Finite State Lexicon Compiler (Karttunen, 193).
The lexicon is composed from two resources and takes a string and maps inflected surface form to a tag containing part-of-speech and feature information, e.
g. applying the transducer to the string kvina ‘woman’ wil return [nn utr sin ind nom].
The morphosyntactic tags folow directly the relevant string or token.
More than one tag can be attached to a string, since no contextual information is taken into account.
The morphosyntactic information in the tags is further used in the grammars of the system.
The set of tags folows the Stockholm-Umeå Corpus project conventions (Ejerhed et al, 192), including 23 category classes and 29 feature classes that were extended with 3 aditional categories.
Below is an example of a lokup on the example sentence in (5): (7) Men[kn] kom[qmvb prt akt][vb prt akt] ihåg[ab][pl] att[sn][ie] det[pn neu sin def sub/obj] [dt neu sin def] inte[ab] ska[vb prs akt][mvb prs akt] blir[vb prs akt] någon[dt utr sin ind][pn utr sin ind sub/obj] riktig[jj pos utr sin ind nom] brand[nn utr sin ind nom] 72 4.2 The Gramar The grammar module includes two grammar sets with (positive) rules reflecting the grammatical structure of Swedish, differing in the level of detail.
The broad gramar is especially designed to handle text with ungrammaticalities and the linguistic descriptions are less accurate accepting both valid and invalid paterns.
The narow gramar is fine and accurate and accepts only the grammatical segments.
For example, the regular expresion in (8) belongs to the broad grammar set and recognizes potential verb clusters (VC) (both grammatical and ungrammatical) as a pattern consisting of a sequence of two or three verbs in combination with (zero or more) adverbs: (8) define VC [Verb Adv* Verb (Verb)]; This automaton accepts all the verb cluster examples in (9), including the ungrammatical instance (9c) (marked by an asterisk ‘*’), where a finite verb folows a (finite) auxiliary verb.
(9) a.
kan inte springa ‘can not run’ b.
skule ha sprungit ‘would have run [sup]’ c.
*ska blir ‘wil be [pres]’ Corresponding rules in the narrow grammar set represented by the regular expressions in (10) take into account the internal structure of a verb cluster and define the grammar of modal auxiliary verbs (Mod) folowed by (zero or more) adverb(s), and either a verb in infinitive form (VerbInf) as in (10a), or a temporal verb in infinitive (PerfInf) and a verb in supine form (VerbSup), as in (10b).
These rules thus accept only the grammatical segments in (9) and wil not include example (9c).
The actual grammar of grammatical verb clusters is a litle bit more complex.
(10) a.
define VC1 [Mod Adv* VerbInf]; b.
define VC2 [Mod Adv* PerfInf VerbSup]; 4.3 The parser The various kinds of constituents are marked out in a text using a lexical-prefix-first method, i.e. parsing first from left margin of a phrase to the head and then extending the phrase by adding on complements.
The actual parsing (based on the broad gramar definitions) is incremental in a similar fashion as the methods described in Ait-Mohtar and Chanod (197), where the output from one layer serves as input to the next, building on the segments.
The system recognizes the head phrases in certain order in the first phase (verbal head, prepositional head, adjective phrase) and then applies the second phase in the reverse order and extends the phrases with complements (noun phrase, prepositional phrase, verb phrase).
The parsing method is described in detail in Section 5.
4.4 Error
Detection The error finder is a separate module in the system, which means that the grammar and parser could potentially be used directly in a different application.
The nets of this module correspond to the difference between the two grammars, broad and narrow.
By subtracting the narrow grammar from the broad grammar we create machines that wil find ungrammatical phrases in a text.
For example, the regular expression in (11) identifies verb clusters that violate the narrow grammar of modal verb clusters (VC1 or VC2, defined in (10)) by subtracting these rules from the more general (overgenerating) rule in the broad grammar (VC, defined in (8)) within the boundaries of a verb cluster (‘<vc>’, ‘</vc>’), that have been previously marked out in the parsing stage.
(11) define VCerror [ "<vc>" [VC [VC1 | VC2]] "</vc>" ]; By application of a marking transducer in (12), the found error segment is annotated directly in the text as in example (13).
(12) define markVCerror [VCerror -> "<Error verb after Vaux>"..
"</Error>"]; (13) Men <vp> <vpHead> kom ihåg </vpHead> </vp> att <np> det </np> <vp> <vpHead> inte <Error verb after Vaux> <vc> ska blir </vc> </Error> </vpHead> <np> någon <ap> riktig </ap> brand </np> </vp> 73 5 Parsing 5.1 Parsing procedure The rules of the (underspecified) broad gramar are used to mark syntactic patterns in a text.
A partial, lexical-prefix-first, longest-match, incremental strategy is used for parsing.
The parsing procedure is partial in the sense that only portions of text are recognized and no ful parse is provided for.
Patterns not recognized by the rules of the (broad) grammar remain unchanged.
The maximal instances of a particular phrase are selected by application of the left-to-right-longest-match replacement operator.
The segments are built on in cascades in the sense that first the heads are recognized, starting from the left-most edge to the head (so called lexical-prefix) and then the segments are expanded in the next level by addition of complement constituents.
The regular expressions in (14) compose the marking transducers of separate segments into a three step process.
(14) define parse1[markVPhead .o.
markPPhead .o.
AP]; define parse2 [markNP]; define parse3 [markPP .o.
markVP]; First the verbal heads, prepositional heads and adjective phrases are recognized by composition in that order (parse1).
This output serves then as input to the next level, where the adjective phrases are extended and noun phrases are recognized and marked (parse2).
This output in turn serves as input to the last level, where the whole prepositional phrases and verb phrases are recognized in that order (parse3).
During and after this parsing annotation, some phrase types are further expanded with post-modifiers, split segments are joined and empty results are removed.
The ‘broadness’ of the grammar and the lexical ambiguity in words, necessary for parsing text containing errors, also yields ambiguous and/or alternative phrase annotations.
We block some of the (erroneous) alternative parses by the order in which phrase segments are selected, which causes bleeding of some rules (i.e.
the parsing order destroys application of another parsing rules; a feature mostly used of the ordering of phonological rules) and more ‘correct’ parsing results are achieved.
The order in which the labels are inserted into the string influences the segmentation of patterns into phrases.
Further ambiguity resolution is provided for by filtering automata.
5.2 The
Heuristics of Parsing Order Reordering rules used in parsing allows us to resolve certain ambiguities.
For example, marking verbal heads before noun phrases wil prefer a verb phrase interpretation of a string over a noun phrase interpretation and avoid merging constituents of verbal heads into noun phrases and yielding noun phrases with to-wide range.
For instance, marking first the sentence in (15) for noun phrases wil interpret the pronoun De ‘they’ as a determiner and the verb såg ‘saw’, that is exactly as in English homonymous with the noun ‘saw’, as a noun and merges these two constituents to a noun phrase as shown in (16).
De såg wil subsequently be marked as ungrammatical, since a number feature mismatch occurs between the plural De ‘they’ and singular såg ‘saw’.
(15) De såg ledsna ut they loked sad out They seemed sad.
(16) <np>De såg </np> <np>ledsna </np> ut . Composing the marking transducers by first marking the verbal head and then the noun phrase wil instead yield the more correct parse.
Although the alternative of the verb being parsed as verbal head or a noun remains (i.e.
såg ‘saw’ is stil tagged as a noun in a noun phrase), the pronoun De ‘they’ is now marked correctly as a separate noun phrase and not merged together with the main verb into a noun phrase: (17) <np> De </np> <vpHead> <np> såg </np> </vpHead> <np> ledsna </np> ut . The output at this stage is then further refined and/or revised by application of filtering transducers.
Earlier parsing decisions depending on lexical ambiguity are resolved (e.g.
adjectives parsed as verbs) and phrases extended (e.g.
with postnominal modifiers).
Other structural ambiguities, such as verb coordinations or clausal modifiers on nouns, are also taken care of.
74 This ordering strategy is not absolute however, since the oposite scenario is posible where parsing noun phrases before verbal heads is more suitable, as for instance in example (18) below, where the string det öpna fönstret ‘the open window’ wil be split in three separate noun phrase segments when applying the order of parsing verbal heads before noun phrases, due the homonymity between an adjective and an infinitive or imperative verb form (19).
(18) han titade genom det öpna fönstret he loked through the open window He loked through the open window (19) <np> han </np><vpHead> titade </vpHead> genom <np> det </np> <vpHead> <np> öpna </np> </vpHead> <np> fönstret </np> We analyzed the ambiguity frequency in the Child Data corpus and found that occurrences of nouns recognized as verbs are more frequent than the opposite.
On this ground, we chose the strategy of marking verbal heads before marking noun phrases.
In the case of the oposite scenario, the false parsing can be revised and corrected by an additional filter (see Section 5.3).
A similar problem occurs with homonymous prepositions and nouns.
For instance, the string vid is ambiguous between an adjective (‘wide’) and a preposition (‘by’) as shown in example (20) and influences the order of marking prepositional heads and noun phrases.
Parsing prepositional heads before noun phrases is more suitable for preposition occurrences as shown in (22) in order to prevent the preposition from being merged as part of a noun phrase, as in (21): (20) Jag sate mig vid bordet I sat me by the-table – I sat down at the table.
(21) <np> Jag </np> satte <np> mig </np> <np> <pHead> vid </pHead> bordet </np> (22) <np> Jag </np> satte <np> mig </np> <pHead> <np> vid </np> </pHead> <np> bordet </np> 5.3 Further Ambiguity Resolution Nouns, adjectives and pronouns are homonymous with verbs and might then be interpreted by the parser as verbal heads.
Adjectives homonymous with prepositions can be analyzed as prepositional heads.
These parsing decisions can be redefined at a later stage by application of filtering transducers.
As exemplified in (19) above, the consequence of parsing verbal heads before noun phrases may yield noun phrases that are split into parts, due to the fact that adjectives are interpreted as verbs.
The filtering transducer in (23) adjusts such segments and removes the erroneous (iner) syntactic tags (i.e.
replaces them with the empty string ‘0’) so that only the outer noun phrase markers remain and converts the split phrase in to one noun phrase yielding (24).
(23) define adjustNPAdj [ "</np><vpHead><np>" -> 0 || Det _ APPhr "</np></vpHead>" NPPhr, "</np></vpHead><np>" -> 0 || Det "</np><vpHead><np>" APPhr _ ]; (24) <np> han </np> <vpHead> titade </vpHead> genom <np> det öpna fönstret </np> The regular expression consists of two replacement rules that apply in parallel.
They are constrained by the surrounding context of a preceding determiner (Det) and a subsequent adjective phrase (APPhr) and a noun phrase (NPPhr) in the first rule, and a preceding determiner and an adjective phrase in the second rule.
5.4 Parsing
Expansion and Adjustment The text is now annotated with syntactic tags and some of the segments have to be further expanded with postnominal atributes and coordinations.
In the current system, partitive prepositional phrases are the only postnominal attributes taken care of.
The reason is that grammatical errors were found in these constructions.
By application of the filtering transducer in (25) the example text in (26) with the partitive noun phrase en av dom gamla husen ‘one of the old houses’ split into a noun phrase folowed by a prepositional head that includes the partitive preposition av ‘of’ and yet another noun phrase 75 from the parsing stage (27) is merged to form a single noun phrase, as shown in (28).
This automaton removes the redundant iner syntactic markers by application of two replacement rules, constrained by the right or left context.
The replacement occurs simultaneously by application of parallel replacement.
(25) define adjustNPPart [ "</np><pHead>" -> 0 || _ PPart "</pHead><np>", "</pHead><np>" -> 0 || "</np><pHead>" PPart _ ]; (26) Virginia hade öpnat en tygafär i en av dom gamla husen.
Virginia had opened a fabric-store in one of the old houses[def].
Virginia had opened a fabric-store in one of the old houses.
(27) <np> Virginia </np> <vp><vpHead> <vc> hade öpnat </vc> </vpHead> <np> en tygaffär </np> i <np> en </np> <pHead> av </pHead> <np> dom <ap> gamla </ap> husen </np> . (28) <np> Virginia </np> <vp> <vpHead> <vc> hade öpnat </vc> </vpHead> <np> en tygaffär </np> i <NPPart> en av dom <ap> gamla </ap> husen </np> Other filtering transducers are used for refining the parsing result and eliminate incomplete parsing decisions such as prepositional heads without a folowing noun phrase.
6 The
System Performance 6.1 Result on Child Data The implemented error detector, FiniteCheck, cannot at present be considered as a fuly developed grammar checking tol, but stil even with its restricted lexicon and small grammar the results are promising.
So far the technique was used to detect agreement errors in noun phrases, selection of finite and non-finite verb forms in main and subordinate clauses and infinitival complements.
The implementation proceeded in two steps.
In the first phase we devoted all effort to detection of the grammar errors, working mostly with the errors and not paying much attention to the text as a whole.
The second phase involved blocking of the resultant false alarms found in the first stage.
In Table 1 we show the final results of error detection in the training corpus of Child Data.
There were altogether 15 agreement errors in noun phrase, 10 errors in the form of finite verb, 7 errors in the verb form after an auxiliary verb and 4 errors in verbs after infinitive marker.
Eror type No.
Erors CA FA R P F Agrement in NP 15 15 62 10% 19% 3% Finite verb form 10 96 126 87% 43% 58% Verb form after aux.
verb 7 6 47 86% 1% 20% Verb form after inf.
marker 4 4 0 10% 10% 10% Total 136 121 235 89% 34% 49% Table 1.
Performance of FiniteCheck on Child Data: corect alarms (CA), false alarms (FA), recal (R), precision (P), F-value (F).
FiniteCheck detected all the agreement errors in noun phrases and all erroneous verb forms after an infinitive marker, only a portion of other errors in verb form was mised.
The precision of the system is rather low, primarily due the ambiguity of the texts and the number of alarms marking other errors such as segmentation or spelling errors.
This side-effect is difficult to eliminate totally and gives rather rise to new questions of how to handle also these types of writing problems that concern spelling rather than grammar.
The three Swedish grammar checkers mentioned above in Section 2: Gramatifix, Granska and Scarie, have been tested on the Child Data.
The result of their performance is shown in Figure 2, below, together with the results of FiniteCheck.
These three tols are designed to detect errors in text different from the nature of the Child Data and thus not surprisingly the accuracy rates are in overall low.
The total recall rate for the four error types covered by FiniteCheck is between 9% and 21% in these three tols and precision varies between 16% to 35%.
Errors in noun phrases seem to be better covered than verb errors.
76 In the case of Gramatifix, errors in verbs are not covered at all.
Half of the noun phrase errors were identified and only five errors in the finite verb form.
Granska covered all four error types and detected at most half of the errors for three of these types.
However, only seven instances of errors in finite verb form were identified.
Scarie had difficulties with errors in verb form after infinitive marker that were not detected at all.
Errors in noun phrase were the best detected type.
Figure 2: Performance of Al Systems on Child Data The detection performance of these three tols on Child Data is in general half that god in comparison to our detector and the fact that the error type with worst coverage (finite verbs) is the one most frequent among children indicates clearly the need for specialized grammar checking tols for children.
6.2 Result
on Text Written by Adult The current system was also tested on a text of 1 070 words writen by an adult, one of the demonstration texts used by Granska.
The performance of FiniteCheck on this text is presented in Table 2.
We found 17 noun phrase agreement errors, 5 errors in the form of finite verb and 1 error in the verbform after an auxiliary verb in the text.
FiniteCheck found all the verb form errors and most of the agreement errors, ending in a recall value of 87%.
False alarms occurred also only in the agreement errors, resulting in a precision rate of 71% and an F-value of 78%.
Eror type No.
Erors CA FA R P F Agrement in NP 17 14 6 82% 70% 76% Finite verb form 5 5 1 10% 83% 91% Verb form after aux.
verb 1 1 1 10% 50% 67% Total 23 20 8 87% 71% 78% Table 2.
Performance of FiniteCheck on Text Writen by Adult: corect alarms (CA), false alarms (FA), recal (R), precision (P), F-value (F).
The three Swedish grammar checkers were also tested on this adult text, that reflects more the text type these tols are designed for.
The results presented in Figure 3 show an average recall rate of 52% for the three Swedish grammar checkers, FiniteCheck scored 87%.
These tols had difficulties to detect the verb form errors, whereas most of the errors in noun phrase agreement were found.
The oposite scenario applies for precision, where FiniteCheck had slightly worse rate (71%) than Gramatifix and Granska, which had a precision above 90%.
Scarie’s precision was 65%.
In the combined measure of recall and precision (Fvalue) our system obtained 78%, which is slightly better in comparison to the other tols that had 70% or less in F-value.
Figure 3: Performance of Al Systems on Text Writen by Adult 77 7 Conclusion The simple finite state technique of subtraction presented in this paper, has the advantage that the grammars one needs to write to find errors are always positive grammars rather than grammars writen to find specific errors.
Thus, covering the valid rules of language means that the rule sets remain quite small and practically no prediction of errors is necessary.
The approach aimed further at minimal information los in order to be able to handle text containing errors.
The degree of ambiguity is maximal at the lexical level, where we chose to attach all lexical tags to strings.
At higher levels, structural ambiguity is treated by parsing order, grammar extension and some other heuristics.
There is an essential problem of ambiguity resolution on complement decisions that remains to be solved.
Sequences of words grammatical in one context and ungrammatical in another are treated the same.
The system overinterprets and gives rise to false alarms, mostly due the application of longestmatch, but more seriously information indicating an error may be filtered out by erroneous segmentation and errors overloked.
A ‘higher’ mechanism is needed in order to solve these problems that takes into consideration the complement distribution and solves these structural dependencies.
The linguistic accuracy of the system is comparable to other Swedish grammar checking tols, that actually performed worse on the Child Data.
The low performance of the Swedish tols on Child Data motivates clearly the need for adaptation of grammar checking techniques to children.
The other tols obtained in general much lower recall values and although the error type of particular error was defined, the systems had difficulties to identify the errors, probably due problems to handle such a disrupted structure with many adjoined sentences and high error frequency.
Further, the robustness and modularity of this system makes it posible to perform both error detection and diagnostics and that the grammars can be reused for other applications that do not necessarily have anything to do with error detection, e.
g. for educational purposes, speech recognition, and for other users such as dyslectics, aphasics, deaf and foreign speakers.
References Ait-Mohtar, Salah and Chanod, Jean-Piere (197) Incremental Finite-State Parsing, In ANLP’97, Washington, p.
72-79. Arpe, A.
(200) Developing a Gramar Checker for Swedish.In The 12th Nordic Conference of Computational Linguistics, NODALIDA-9, p.13-27.
Birn, J.
(198). Swedish Constraint Gramar: A Short Presentation.
[htp:/ww.lingsoft.fi/doc/swecg/]. Birn, J.
(200) Detecting Gramar Erors with Lingsoft's Swedish Gramar Checker.
In The 12th Nordic Conference of Computational Linguistics, NODALIDA-9, p.28-40.
Bustamente, F.
R. and León, F.
S. (196) GramCheck: A Gramar and Style Checker.
In The 16th International Conference on Computational Linguistics, Copenhagen, p.
175-181. Carlberger, J.
and Kan, V.
(199) Implementing an eficient part-f-spech tager.
Software – Practice and Experience, 29(9):815-832.
Chanod, J.-P.
(196) A Broad-Coverage French Grammar Checker: Some Underlying Principles.
In The Sixth International Conference on Symbolic and Logical Computing, Dakota State University Madison, South Dakota.
Domeij, R.
(203). Datorstöd språkgranskning under skrivprocesen.
Svensk språkontrol ur användarperspektiv.
Doktorsavhandling, Stockholms Universitet, Institutionen för lingvistik.
Ejerhed, E., Kälgren, G., Wenstedt, O.
and Åström, M.
(192) The Linguistic Anotation System of the Stockholm-Umeå Corpus Project.
Report 3.
University of Umeå, Department of Linguistics.
Heidorn, G.
(193). Experience with an easily computed metric for ranking alternative parses.
In Jensen, K., Heidorn, G., and Richardson, S.
D. (eds).
Natural Language Procesing: The PLNLP Aproach.
Kluwer Academic Publishers, Dordrecht.
Hård af Segerstad, Y.
and Sofkova Hashemi, S.
(206) Learning to Write in the Information Age: A Case Study of Scholchildren's Writing in Sweden.
In Van Waes, L., Leijten, M.
och Neuwirth, C.
(eds.), Writing and Digital Media, Elsevier.
Jensen, K., Heidorn, G.
and Richardson, S.
D. (eds).
(193) Natural Language Procesing: The PLNLP Aproach.
Kluwer Academic Publishers, Dordtrecht.
Järvinen, T.
and Tapanainen, P.
(198). Towards an implementable dependency gramar.
In Kahane, S.
and Polguere, A.
(eds). The Procedings of COLIN-78 GACL’98, Workshop on ‘Procesing of Dependency-Based Gramars’, pages 1–10.
Universite de Montreal, Canada.
Karlson, F.
(192). SWETWOL: Comprehensive morphological analyzer for Swedish.
Nordic Journal of Linguistics, 15:1–45.
Karlson, F., Voutilainen, A., Heikilä, J., and Antila, A.
(195). Constraint Gramar: a language-independent system for parsing unrestricted text.
Mouton de Gruyter, Berlin.
Kartunen, L.
(193) Finite State Lexicon Compiler.
Technical Report ISTL-NLT-193-04-02, Xerox Palo Alto Research Center, Palo Alto, California.
Kartunen, L., Chanod, J., Grefenstete, G.
and Schiler, A.
(196) Regular Expresions for Language Enginering, In Natural Language Enginering 2 (4) 305-328.
Kartunen, L., Gaál, T.
and Kempe, A.
(197) Xerox Finite State Tol.
Xerox Research Centre Europe.
Kirschner, Z.
(194) CZECKER -a Maquete Gramar-Checker for Czech.
In The Prague Buletin of Mathematical Linguistics 62, Praha: Universita Karlova.
Knutson, O.
(201). Automatisk språkgranskning av svensk text.
Licentiatavhandling, KTH, Institutionen för numerisk analys och datalogi, Stockholm.
Kukich, K.
(192) Techniques for Automaticaly Correcting Words in Text.
ACM Computing Surveys, Vol.
24, No.
4: 37 439.
Sofkova Hashemi, S.
(203) Automatic Detection of Gramar Erors in Primary Schol Children's Texts.
A Finite State Aproach.
Doctoral disertation.
Gothenburg Monographs in Linguistics 24.
Department of Linguistics, Göteborg University.
Sofkova Hashemi, S.
(forthcoming) The role of writing aid in the text production of schol children.
Department of Linguistics, Göteborg University Sågval Hein, A.
(1983). A Parser for Swedish.
Status Report for SveUcp.
(UCDLR-83-2). Upsala University, Department of Linguistics.
February 1983.
Sågval Hein, A.
(199) A gramar checking module for Swedish.
Report from the Scarie-project: DEL 6.6.3, June 199, Dept.
of Linguistics, Upsala University.
Sågval Hein, A., Olson, L.-G., Dahlqvist, B., and Mats, E.
(199). Evaluation report for the Swedish prototype.
In Sågval Hein, A.
(ed). Reports from the SCARIE project, Deliverable 8.1.3, June 199.
Upsala University, Department of Linguistics.
Vernon, A.
(200) Computerized gramar checkers 200: Capabilities, limitations, and pedagogical possibilities.
Computers and Composition 17, 329-349.
Vose, T.
G. (194) The Word Conection.
Gramar-based Speling Eror Corection in Dutch.
Enschede: Neslia Paniculata.
Wedbjer Rambel, O.
(199). Swedish phrase constituent rules.
A formalism for the expresion of local error rules for Swedish.
In Sågval Hein, A.
(ed). Reports from the SCARIE project.
Upsala University, Department of Linguistics .

