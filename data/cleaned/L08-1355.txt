<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>T Brants</author>
</authors>
<title>TnT – A Statistical Part-Of-Speech Tagger</title>
<date>2000</date>
<booktitle>In Proceedings of the 6th Applied NLP Conference ANLP-2000</booktitle>
<pages>224--231</pages>
<location>Seattle, WA</location>
<contexts>
<context>of speech (POS) tagging is known to be accurate. For English, experimental results show accuracies starting with 96% using various tag sets and training corpora sizes (Brill, 1996; Ratnaparkhi, 1998; Brants, 2000). In the case of Hidden Markov Models (HMM) POS tagging, what really makes the difference, is the accuracy obtained on unknown words (words that the tagger has not seen in the training phase) because</context>
<context>f i w , both of them in the context of (usually) the T-word sentence. Estimating the lexical probability of i w is based on evidence provided by the counts extracted from the training tagged corpora (Brants, 2000). By collecting frequency counts for each pair j tw, , one obtains a list of word forms w, each of them associated with a set of tag-frequency pairs }{ 11 &gt;&lt;&gt;&lt; kk ftft K called the lexical distributi</context>
</contexts>
<marker>Brants, 2000</marker>
<rawString>Brants, T. (2000). TnT – A Statistical Part-Of-Speech Tagger. In Proceedings of the 6th Applied NLP Conference ANLP-2000. Seattle, WA, pp 224--231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>A Simple Rule-Based Part-Of-Speech Tagger</title>
<date>1996</date>
<booktitle>In Proceedings of ANLP-92, 3rd Conference on Applied Natural Language Processing</booktitle>
<pages>152--155</pages>
<location>Trento, Italy</location>
<contexts>
<context>r results. 1. Introduction Part of speech (POS) tagging is known to be accurate. For English, experimental results show accuracies starting with 96% using various tag sets and training corpora sizes (Brill, 1996; Ratnaparkhi, 1998; Brants, 2000). In the case of Hidden Markov Models (HMM) POS tagging, what really makes the difference, is the accuracy obtained on unknown words (words that the tagger has not se</context>
</contexts>
<marker>Brill, 1996</marker>
<rawString>Brill, E. (1996). A Simple Rule-Based Part-Of-Speech Tagger. In Proceedings of ANLP-92, 3rd Conference on Applied Natural Language Processing. Trento, Italy, pp 152--155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Dermatas</author>
<author>G Kokkinakis</author>
</authors>
<title>Automatic Stochastic Tagging of Natural Texts</title>
<date>1995</date>
<journal>Computational Linguistics</journal>
<volume>21</volume>
<pages>137--164</pages>
<location>Bucharest</location>
<marker>Dermatas, Kokkinakis, 1995</marker>
<rawString>Dermatas, E., Kokkinakis G. (1995). Automatic Stochastic Tagging of Natural Texts. Computational Linguistics, vol. 21, Number 2, pp. 137--164 Ion, R. (2007). Word Sense Disambiguation Methods Applied to English and Romanian. PhD thesis (in Romanian). Romanian Academy, Bucharest.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Irimia</author>
</authors>
<title>ROG A Paradigmatic Morphological Generator for Romanian</title>
<date>2007</date>
<booktitle>In Proceedings of the 3rd Language &amp; Technology Conference: Human Language Technologies as a Challenge for Computer Science and Linguistics. Poznań</booktitle>
<location>Poland</location>
<contexts>
<context>gorithm. 4. Paradigm generation Paradigm generation relies on the paradigmatic morphology and its implementation for Romanian (Tufiş, 1989) as well as on the ROG paradigmatic morphological generator (Irimia, 2007). The term paradigm will be used with two distinct meanings: 1) the complete set of inflected word forms of a given lemma with a specific part of speech (for instance, English noun “car” has two memb</context>
</contexts>
<marker>Irimia, 2007</marker>
<rawString>Irimia, E. (2007). ROG A Paradigmatic Morphological Generator for Romanian. In Proceedings of the 3rd Language &amp; Technology Conference: Human Language Technologies as a Challenge for Computer Science and Linguistics. Poznań , Poland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ratnaparkhi</author>
</authors>
<title>Maximum Entropy Models for Natural Language Ambiguity Resolution. PhD thesis</title>
<date>1998</date>
<institution>University of Pennsylvania</institution>
<location>Philadelphia, PA</location>
<contexts>
<context> Introduction Part of speech (POS) tagging is known to be accurate. For English, experimental results show accuracies starting with 96% using various tag sets and training corpora sizes (Brill, 1996; Ratnaparkhi, 1998; Brants, 2000). In the case of Hidden Markov Models (HMM) POS tagging, what really makes the difference, is the accuracy obtained on unknown words (words that the tagger has not seen in the training </context>
</contexts>
<marker>Ratnaparkhi, 1998</marker>
<rawString>Ratnaparkhi, A. (1998). Maximum Entropy Models for Natural Language Ambiguity Resolution. PhD thesis. University of Pennsylvania, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Tufiş</author>
</authors>
<title>It Would Be Much Easier If WENT Were GOED</title>
<date>1989</date>
<booktitle>In Harry Somers &amp; Mary McGee Wood (Eds.), Proceedings of the 4th European Conference of the Association for Computational Linguistics</booktitle>
<location>Manchester, UK</location>
<contexts>
<context>orrect. The next section details the 3 rd step from the aforementioned algorithm. 4. Paradigm generation Paradigm generation relies on the paradigmatic morphology and its implementation for Romanian (Tufiş, 1989) as well as on the ROG paradigmatic morphological generator (Irimia, 2007). The term paradigm will be used with two distinct meanings: 1) the complete set of inflected word forms of a given lemma wit</context>
</contexts>
<marker>Tufiş, 1989</marker>
<rawString>Tufiş, D. (1989). It Would Be Much Easier If WENT Were GOED. In Harry Somers &amp; Mary McGee Wood (Eds.), Proceedings of the 4th European Conference of the Association for Computational Linguistics. Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Tufiş</author>
</authors>
<title>Tiered Tagging and Combined Classifiers. In</title>
<date>1999</date>
<booktitle>Nth (Eds.), Text, Speech and Dialogue, Lecture Notes in Artificial Intelligence</booktitle>
<pages>28--33</pages>
<publisher>Springer</publisher>
<contexts>
<context> the low frequency words, so, their ambiguity is essentially an intra-category ambiguity (ICA), a matter of distinguishing among various values for the attributes specific to a grammatical class. In (Tufiş, 1999) we argued that, for highly inflectional languages, the hard to solve ambiguities are ICAs and, that the main grammar category (part of speech) for the homonyms is easily predictable in context. The </context>
<context>morpho-syntactic attributes for each POS (see http://nl.ijs.si/ME/V2/msd/ for details) and a reduced tagset (CTAG). The two tagsets are not independent and they observe the tiered tagging philosophy (Tufiş, 1999). The implicit tagset is MSD, which although gives a slightly lower precision than CTAG, is much more informative. ⎥ ⎦ ⎤ ⎢ ⎣ ⎡ ∏ = −− T i iiiii tt twPtttP T 1 12 )|(),|(maxarg 1 K Figure 1: POS ambig</context>
</contexts>
<marker>Tufiş, 1999</marker>
<rawString>Tufiş, D. (1999). Tiered Tagging and Combined Classifiers. In F. Jelinek, E. Nth (Eds.), Text, Speech and Dialogue, Lecture Notes in Artificial Intelligence. Springer, pp. 28--33.</rawString>
</citation>
</citationList>
</algorithm>

