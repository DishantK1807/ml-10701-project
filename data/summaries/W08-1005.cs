ferred to Petrov et al. (2006). The correspond-
P06-1055
Charniak et al. (2005) 90.1 90.1 89.5 89.6
P05-1022
niak (1996) and Klein and Manning (2003), a PCFG
P03-1054
E. Charniak, S. Goldwater, and M. Johnson. 1998. Edge-
J98-4004 W98-1115
Charniak and Johnson, 2005; Petrov and Klein,
P05-1022
tation and symbol splitting (Johnson, 1998; Klein
J98-4004
In Petrov and Klein (2007) we trained models for
N07-1051
cate smoothing (Collins, 1999; Charniak, 2000).
A00-2018
A. Dubey. 2005. What to do when lexicalization fails:
P05-1039
other (Collins, 1999; Charniak, 2000; Charniak and
A00-2018
D. Klein and C. Manning. 2003. Accurate unlexicalized
P03-1054
E. Charniak and M. Johnson. 2005. Coarse-to-Fine N-
P05-1022
E. Charniak. 2000. A maximum–entropy–inspired
A00-2018
S. Petrov and D. Klein. 2007. Improved inference for
N07-1051
Petrov and Klein (2007) 80.8 80.7 80.1 80.1
N07-1051
plied to rules and to Matsuzaki et al. (2005)’s sen-
P05-1010
Prescher, 2005; Petrov et al., 2006), we learn
P06-1055
In Petrov et al. (2006) we show that a hierarchical
P06-1055
Petrov and Klein (2007). The parser, code,
N07-1051
J. Goodman. 1996. Parsing algorithms and metrics. ACL
P96-1024
T. Matsuzaki, Y. Miyao, and J. Tsujii. 2005. Probabilis-
P05-1010
M. Johnson. 1998. PCFG models of linguistic tree rep-
J98-4004
D. Chiang and D. Bikel. 2002. Recovering latent infor-
C02-1126
Charniak et al. (2005) 92.4 91.6 91.8 91.0
P05-1022
Dubey (2005) F1 76.3 -
P05-1039
Goodman (1996)’s labeled brackets algorithm ap-
P96-1024
S. Petrov, L. Barrett, R. Thibaux, and D. Klein. 2006.
P06-1055
Petrov and Klein (2007) 86.9 85.7 84.8 81.9
N07-1051
output of Charniak and Johnson (2005), but it out-
P05-1022
Chiang et al. (2002) 81.1 78.8 78.0 75.2
C02-1126
In latent variable parsing (Matsuzaki et al., 2005;
P05-1010
Petrov and Klein (2007) 90.7 90.5 90.2 89.9
N07-1051
to-fine inference scheme (Charniak et al., 1998;
W98-1115
