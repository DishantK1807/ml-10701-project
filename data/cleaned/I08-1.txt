1:328	IJCNLP 2008    Third International Joint Conference on Natural Language Processing  Proceedings of the Conference     Organizer Asian Federation of Natural Language Processing Local Host International Institute of Information Technology, India January 7-12 2008 Hyderabad, India 2008 Asian Federation of Natural Language Processing                                                                                                   Hosts/Organizers Asian Federation of Natural Language Processing (AFNLP) International Institute of Information Technology, Hyderabad, India (IIIT-H) Natural Language Processing Association of India (NLPAI) Supporters Yahoo!
2:328	Research & Development, India Department of Information Technology, MCIT, Government of India Information & Communication Technology, Government of Andhra Pradesh Microsoft Research, India Tata Consultancy Services Limited Centre for Development of Advanced Computing Indian School of Business Satyam Computer Service Limited Google India IBM India Defense Research and Development Organization Council for Scientific and Industrial Research Preface: Conference Chair Dear colleagues,  Welcome to the 2008 International Joint Conference on Natural Language Processing (IJCNLP-08).
3:328	This is the third biennial conference organized by the Asian Federation of Natural Language Processing (AFNLP), which was founded in 2004 to promote research and development efforts in the field of computational processing of natural languages of importance to the Asian region, without regard to differences in language, race, religious belief or political stand.
4:328	The first IJCNLP was held to celebrate the inauguration of AFNLP on the beautiful Hainan Island in China (March 22-24, 2004), and the second on the fantastic Jeju Island in Korea (October 10-13, 2005).
5:328	Following the continuing success of the previous two conferences, the third conference is held in yet another exotic and multicultural city of Hyderabad in India in January 7-12, 2008.
6:328	On behalf of the Conference Committees, I would like to welcome all researchers and scholars who are working in all areas of Natural Language Processing (NLP) around the world and who in particular have keen interest in Asian language processing.
7:328	As the world proceeds quickly into the Information Age, we face both successes and challenges in creating a global information society, and it is well recognized nowadays that Natural Language Processing provides the key to the Information Age and to solving many of these challenges, like breaking language barrier and overcoming information flood.
8:328	Over the last decades, a remarkable progress has been made in NLP research and development.
9:328	However, there has been a pervasive feeling that the progress of NLP for Asian languages has not been commensurate with that for Western languages.
10:328	Recently the importance of Asian languages has been steadily growing as Asia becomes the dominant region of the world, economically, politically and culturally.
11:328	In this context, this conference provides a forum for engineers and scientists to present and exchange their latest research findings in all aspects of NLP and thus to promote research and development activities for Asian language processing.
12:328	This is the major motivation of IJCNLP.
13:328	I would like to express my sincere appreciation to the authors of invited and contributed papers and to all conference participants for their active participations.
14:328	I also wish to express my heartfelt gratitude and thanks to the Committee Members, particularly the Organizing Co-chairs Rajeev Sangal and Raji Bagga, the Program Co-chairs Yuji Matsumoto and Ann Copestake, the Publication Chair Jing-Shin Chang, and all the other Committee Chairs for their tremendous efforts and substantial contributions to the conference.
15:328	I feel honored and blessed to be part of this conference as the Conference Chair working with such wonderful team.
16:328	With our team efforts, I am confident that this conference will be even more successful than the previous.
17:328	Finally, I hope that you will participate actively in all sessions and events to maximize the benefits from them, and I also wish all participants a very fruitful and enjoyable time during the conference in Hyderabad.
18:328	Jong-Hyeok Lee Conference Chair  i Preface: Program Committee Co-Chairs This volume contains the papers accepted for presentation at the third International Joint Conference on Natural Language Processing (IJCNLP-2008).
19:328	IJCNLP is held approximately every two years as the flagship conference of the AFNLP (Asian Federation of Natural Language Processing).
20:328	This year's conference, which follows the success of IJCNLP-2005 on Jeju Island in Korea, is in the city which is such a beautiful mixture of ancient civilization and modern industry: Hyderabad, India.
21:328	On behalf of the Program Committee, we are pleased to present this volume, which includes the accepted papers for oral and poster presentations at the conference.
22:328	We received 266 submissions from 28 different regions all over the world; 74% from Asia, 15% from North America, 9% from Europe, 3% from Australia, and 0.4% from Africa.
23:328	The paper selection was not easy with this large number of submission but with the devoted work of our 13 area chairs and 268 PC members, we were able to select very high quality papers.
24:328	75 papers (27.8%) were accepted for oral presentation and 62 papers (23.3%) were accepted for poster presentation.
25:328	After a few withdrawals, this volume contains 74 oral papers and 60 poster papers.
26:328	We are also very grateful to Professor Aravind Joshi (University of Pennsylvania), Professor Hyopil Shin (Seoul National University) and Dr S.H. Srinivasan (Yahoo!)
27:328	for accepting to give keynote and invited talks, which surely make the conference more attractive.
28:328	Organizing and hosting this size of international conference requires lots of help and effort from many people.
29:328	We would like to send our greatest thanks to the Honorary Conference Chair, Professor Aravind Joshi and the Conference Chair, Professor Jong-Hyoek Lee for their continuous support and timely guidance.
30:328	We would also thank the Local Organizing Co-Chairs Professor Rajeev Sangal and Dr Raji Bagga for their support, advice and responses to our numerous requests.
31:328	Special thanks are due to the Publication Chair Professor Jing-Shin Chang.
32:328	Without his very detailed format checking and efficient compilation, this volume of proceedings would not come out in the current form.
33:328	We would like to express our highest gratitude to all the other Committee Chairs.
34:328	Working with such a wonderful group of people has been great fun.
35:328	Last but not least, we would like to thank all the people who submitted their papers and all the people who attend this conference.
36:328	Welcome to IJCNLP-2008.
37:328	We hope you enjoy this conference as much as we do.
38:328	Ann Copestake and Yuji Matsumoto Program Committee Co-Chairs  ii Keynote Speech: PENN Discourse Treebank: Complexity of Dependencies at the Discourse Level and at the Sentence Level Aravind K. Joshi Department of Computer and Information Science and Institute for Research in Cognitive Science University of Pennsylvania, Philadelphia, PA, USA ABSTRACT First, I will describe the Penn Discourse Treebank (PDTB)*, a corpus in which we annotate the discourse connectives (explicit and implicit) and their arguments, together with "attributions" of the arguments and the relations denoted by the connectives, and also the senses of the connectives.
39:328	I will then discuss some issues concerning the complexity of dependencies in terms of the elements that bear the dependency relations, the graph theoretic properties of these dependencies such as nested and crossed dependencies, dependencies with shared arguments, and finally, the attributions and their relationship to the dependencies, among others.
40:328	We will compare these dependencies with those at the sentence level and then discuss some aspects that relate to the transition from the sentence level to the level of  "immediate discourse" and propose some conjectures.
41:328	----------------*  This 1 million-word corpus is the same as the WSJ corpus used by the Penn Treebank (PTB) for syntactic annotation and by Propbank for predicate-argument annotation.
42:328	PDTB 2.0 will be released by the Linguistic Data Consortium (LDC) in early February 2008.
43:328	Members of the PDTB project: Nikhil Dinesh, Aravind K. Joshi, Alan Lee, Eleni Miltsakaki, Rashmi Prasad, and Bonnie Webber (University of Edinburgh).
44:328	iii Invited Talk: The 21st Sejong Project: with a Focus on Building of the SELK (Sejong Electronic Lexicon of Korean) and  the KNC (Korean National Corpus) Hyopil Shin Dept. of Linguistics, Seoul National University School of Computer Engineering, Seoul National University ABSTRACT The 21st Sejong Project started in 1998 with a 10-year plan.
45:328	The project was funded by the Ministry of Culture and Tourism of the Korean government.
46:328	The goal of the project was to promote technological expertise in Korean language research and technology.
47:328	The project consists of 8 sub-projects ranging from construction of Korean language resources to management and distribution of outputs from the work.
48:328	The core part of the project is to compile an electronic lexical dictionary and to build a large-scale Korean corpus.
49:328	The SELK focuses on an exhaustive representation of Korean linguistic knowledge by harmonizing linguistic validity, psychological reality, and computational efficiency.
50:328	The SELK is composed of various sub-dictionaries corresponding to the parts-of-speech-based word categories such as nouns, verbs, adverbs etc. The lexicon shows a considerable differentiation from other paperback or machine-readable dictionaries in Korean in its precise and comprehensive representation.
51:328	The KNC project has two sub-divisions, one for a general corpus and the other for a special corpus.
52:328	The general corpus division collected a wide range of unconstrained materials and endeavored at annotating the data with parts-of-speech, syntactic, and semantic tags.
53:328	The special data division, on the other hand, constructed Korean-English and Korean-Japanese corpora, a historical corpus, and a corpus used by North Koreans and overseas Koreans.
54:328	The SELK and the KNC are beginning to serve as important research tools for investigators in natural language processing as well as in theoretical linguistics.
55:328	Annotated corpora and well-established electronic dictionaries promise to be valuable for enterprises such as the construction of statistical models for the grammar of written and spoken Korean, the development of software for Korean language processing, and even the publication of the paperback Korean dictionaries.
56:328	In this speech, I will introduce the 21st Sejong Project and review my experience with constructing one such large language resource the SELK, consisting of about 600,000 lexical entries, and the KNC, consisting of about 500 million word collections.
57:328	Considering the size and time needed to develop it, this project deserves great attention.
58:328	We, however, also experienced a lot of difficulties through trial and error, inevitably originating from such a long work period and the large scale of the work.
59:328	We hope sharing such experiences will help researchers with the same interests, to break through the obstacles and to avoid mistakes we have made for a decade.
60:328	iv Invited Talk: Language Processing for the Evolving Web Srinivasan Sengamedu Yahoo!, Bangalore ABSTRACT World Wide Web brings several new dimensions to language processing social, multimodal, structural, etc. The social dimension arises from the tagging phenomenon, multimodal from the coexistence of images and videos with text in web documents, and structure from rich formatting of web pages.
61:328	While the massive amounts of data available has made new approaches to translation, summarization, and extraction possible, next generation applications like semantic search require radically new theoretical ideas.
62:328	The talk will outline the phenomena, summarize recent achievements, and pose the new challenges.
63:328	v Conference Committee Honorary Conference Chair Prof. Aravind Joshi, University of Pennsylvania Conference Chair Prof. Jong-Hyeok Lee, POSTECH, Korea Local Organizing Co-chairs Prof. Rajeev Sangal, International Institute of Information Technology, India Dr. Raji Bagga, International Institute of Information Technology, India LOC Steering/Core Committee Members Dr. A Kumaran, Microsoft Research India Dr. Pushpak Bhattacharya, IIT Bombay, India Dr. M Sasikumar, CDAC, Mumbai, India Dr. Dipti Misra Sharma, International Institute of Information Technology, India Dr. Vasudeva Varma, International Institute of Information Technology, India Dr. KS Rajan, International Institute of Information Technology, India Dr. Anoop M Namboodri, International Institute of Information Technology, India Mr. KS Vijaya Sekhar, IJCNLP-08 LOC Secretariat Program Committee Co-chairs Prof. Yuji Matsumoto, NAIST, Japan Prof. Ann Copestake, University of Cambridge, UK Publication Committee Chair Prof. Jing-Shin Chang, National Chi-Nan University, Taiwan Publicity Committee Co-chairs Prof. Satoshi Sato, Nagoya University, Japan Prof. Jian-Yun Nie, Univ. of Montreal, Canada Financial Committee Co-chairs Prof. Kam-Fai Wong, Chinese Univ. of HK, Hong Kong Dr. A. Kumaran, Microsoft Research India Tutorial Committee Co-chairs Prof. Kemal Oflazer, Sabanci University, Turkey Prof. Key-Sun Choi, KAIST, Korea Workshops Committee Co-chairs Dr. Haizhou Li, Institute of Infocomm Research, Singapore Dr. Timothy Baldwin, University of Melbourne, Australia Exhibition/Demo Committee Co-chairs Prof. Pushpak Bhattacharya, Indian Institute of Technology Bombay, India Prof. Fei Xia, Univ. of Washington, USA  vi Program Committee Program Committee Chairs: Ann Copestake, University of Cambridge (Ann.Copestake@cl.cam.ac.uk) Yuji Matsumoto, Nara Institute of Science and Technology (matsu@is.naist.jp) Areas and Area Chairs: Information Retrieval Hang Li, Microsoft China Parsing/Grammatical Formalisms Beth Ann Hockey, UCSC Chunking/Shallow Parsing Srinivas Bangalore, AT&T Research Statistical Models/Machine Learning for NLP Robert Malouf, San Diego State University Machine Translation Philipp Koehn, University of Edinburgh Word Segmentation/POS Tagging Yuji Matsumoto, Nara Institute of Science and Technology Semantic Processing/Lexical Semantics Patrick St Dizier, IRIT Ontologies and Linguistic Resources Nancy Ide, Vassar College Paraphrasing/Entailment/Generation Kentaro Inui, NAIST Discourse Alistair Knott, University of Otago QA/Text Summarization Sanda Harabagiu, University of Texas at Dallas Text Mining/Information Extraction James Curran, University of Sydney Spoken Language Processing Gary Geunbae Lee, POSTECH Asian Language Processing and Linguistics Issues in NLP Chu-Ren Huang, Academia Sinica  vii Program Committee Members: Eugene Agichtein, Yaser Al-Onaizan, James Allen, Pascal Amsili, Alina Andreevskaia, Kenji Araki, Nick Asher Collin Baker, Jason Baldridge, Timothy Baldwin, Sivaji Bandyopadhyay, Srinivas angalore, Marco Baroni, Stephen Beale, Tilman Becker, Susham Bendre, Pushpak Bhattacharyya, Zhao Bing, Sasha Blair-Goldensohn, Francis Bond, Kalina ontcheva, Johan Bos, Pierrette Bouillon, Antonio Branco, Thorsten Brants, Paul Buitelaar, Razvan Bunescu, Harry Bunt, Miriam Butt, Ekaterina Buyko, Bill Byrne Aoife Cahill, Chris Callison-Burch, Nicoletta Calzolari, Joyce Chai, Hsin-Hsi Chen, Keh-Jiann Chen, David Chiang, Massimiliano Ciaramita, Philipp Cimiano, tephen Clark, Simon Clematide, Trevor Cohn, Nigel Collier, John Conroy, Nick Craswell, Dan Cristea, Andras Csomai, Silviu Cucerzan, Hang Cui Walter Daelemans, Robert Dale, Hal Daume, Thierry Declerck, Fernando Diaz, Hakkani-Tur Dilek, Pavel Dmitriev, Bill Dolan, Christy Doran, Bonnie Dorr, Mark Dras, Markus Dreyer Cecile Fabre, Hui Fang, Marcello Federico, Christiane Fellbaum, Dan Flickinger, J.Foster, Alex Fraser, Atsushi Fujita Bin Gao, Claire Gardent, Albert Gatt, Tanja Gaustad, Niyu Ge, Dan Gildea, Jade Goldstein-Stewart, Ralph Grishman, Claire Grover, Narendra Gupta Patrick Haffner, Jan Hajic, Keith Hall, Sanda Harabagiu, Samer Hassan, Toby Hawker, Mary Hearne, John Henderson, Andrew Hickl, Deidre Hogan, Tracy Holloway King, Shu-Kai Hsieh, Sarmad Hussain Kentaro Inui, Hitoshi Isahara, Masato Ishizaki Donghong Ji Laura Kallmeyer, Kyoko Kanzaki, Tatsuya Kawahara, Asanee Kawtrakul, Junichi Kazama, Andrew Kehler, Bernd Kiefer, Adam Killgariff, Byeongchang Kim, Jin Dong Kim, Atanis Kiryakov, Manfred Klenner, Kevin Knight, Anna Korhonen, Emiel Krahmer, Shankar Kumar, Sadoa Kurohashi Philippe Langlais, Mirella Lapata, Alon Lavie, Kiyong Lee, Alessandro Lenci, Yves Lepage, Baoli Li, Haizhou Li, Wenjie Li, Chin-Yew Lin, Tie-Yan Liu, Adam Lopez Ryan MacDonald, Bernardo Magnini, Steve Maiorano, Robert Malouf, Gideon Mann,Alda Mari, Katja Markert, Carlos Martin-Vide, Kathleen McCoy, Ryan McDonald, Marge McShane, Michael McTear, Arul Menezes, Helen Meng, Wolfgang Minker,Vibhu Mittal, Yusuke Miyao, Paola Monachesi, Bob Moore, Tony Mullen  viii  ix Program Committee Members (cont.)
64:328	: Sobha Nair, Hiroshi Nakagawa, Seiichi Nakagawa, Satoshi Nakamura, Shri Narayanan, Srini Narayanan, Vivi Nastase, Tetsuya Nasukawa, Roberto Navigli, Vincent Ng, Orace Ngai, Thi Minh Huyen Nguyen, Jianyun Nie, Joakim Nivre, Yongkyoon No, Tadashi Nomoto, Eric Nyberg Franz Och, Stephen Oepen, Kemal Oflazer, Miles Osborne, Lilja Ovreli Martha Palmer, Shimei Pan, Antonio Pareja-Lora, Jong Park, Jon Patrick, Wim Peters, Manfred Pinkal, Paul Piwek, Thierry Poibeau, David Powers, Kishore Prahallad, Rashmi Prasad Chris Quirk Allan Ramsay, Lance Ramshaw, Manny Rayner, Christian Retore, Brian Roark, Horacio Rodri'guez, Antti-Veikko Rosti, Rachel E. O. Roxas, Thomas Russ Kenji Sagae, Horacio Saggion, Patrick Saint-Dizier, Ted Sanders, Rajeev Sangal, Anoop Sarkar, Sudeshna Sarkar, Holger Schwenk, Donia Scott, Satoshi Sekine, Burr Settles, Vijay Shanker, Dipiti Misra Sharma, Libin Shen, Kiyoaki Shirai, Candy Sidner, Khalil Simaan, Michel Simard, Navjyoti Singh, Noah A Smith, David Smith, Virach Sornlertlamvanich, Wilbert Spooren, Caroline Sporleder, Manfred Stede, Mark Stevenson, Kristina Striegnitz, Michael Strube, Craig Struble, Jian Su, Mihai Sudreanu, Eiichiro Sumita, Yoshimi Suzuki, Hisami Suzuki Jie Tang, Simone Teufel, Thanaruk Theeramunkong, Jo"rg Tiedemann, Christoph Tillmann, Ivan Titov, Takenobu Tokunaga, Shisanu Tongchim, Kentaro Torisawa, Kristina Toutanova, David Traum, Shu-Chuan Tseng, Yoshimasa Tsuruoka Nicola Ueffing Ielka van der Sluis, Menno van Zaanen, Lucy Vanderwende, Vasudeva Varma, Sriram Venkatapathy, Ashish Venugopal, Jette Viethen, Andreas Vlachos, Stephan Vogel Marilyn Walker, Hsin-min Wang, Taro Watanabe, Bonnie Webber, Ralph Weischedel, Casey Whitelaw, Yuk Wah Wong, Yunfang Wu, Dekai Wu Peng Xu, Jun Xu, Nianwen Xue Naoki Yoshinaga, Yong Yu Annie Zaenen, Richard Zens, Jun Zhao, Ming Zhou, GuoDong Zhou, Jing-bo Zhu, Michael Zock  Table of Contents Volume I PrefaceConference Chair.i PrefaceProgram Committee Co-Chairsii Keynote Speech and Invited Talks PENN Discourse Treebank: Complexity of Dependencies at the Discourse Level and at the Sentence Level  Aravind K. Joshiiii The 21st Sejong Project: with a Focus on Building of the SELK (Sejong Electronic Lexicon of Korean) and the KNC (Korean National Corpus)  Hyopil Shiniv Language Processing for the Evolving Web  Srinivasan Sengameduv Word Segmentation/POS Tagging A Lemmatization Method for Modern Mongolian and its Application to Information Retrieval Badam-Osor Khaltar and Atsushi Fujii1 An Empirical Comparison of Goodness Measures for Unsupervised Chinese Word Segmentation with a Unified Framework Hai Zhao and Chunyu Kit9 A Hybrid Approach to the Induction of Underlying Morphology Michael Tepper and FeiXia17 Text Mining/Information Extraction (1) Context-Sensitive Convolution Tree Kernel for Pronoun Resolution GuoDong Zhou, Fang Kong and QiaoMing Zhu.25 Semi-Supervised Learning for Relation Extraction GuoDong Zhou, JunHui Li, LongHua Qian and QiaoMing Zhu.32   x Story Link Detection based on Dynamic Information Extending Xiaoyan Zhang, Ting Wang and Huowang Chen40 Asian Language Processing and Linguistics Issues Orthographic Disambiguation Incorporating Transliterated Probability Eiji Aramaki, Takeshi Imai, Kengo Miyo and Kazuhiko Ohe48 Name Origin Recognition Using Maximum Entropy Model and Diverse Features Min Zhang, Chengjie Sun, Haizhou Li, AiTi Aw, Chew Lim Tan and Xiaolong Wang.56 A More Discerning and Adaptable Multilingual Transliteration Mechanism for Indian Languages Harshit Surana and Anil Kumar Singh64 Parsing/Grammar UCSG: A Wide Coverage Shallow Parsing System G. Bharadwaja Kumar and Kavi Narayana Murthy.72 Memory-Inductive Categorial Grammar: An Approach to Gap Resolution in Analytic-Language Translation Prachya Boonkwan and Thepchai Supnithi80 Dependency Parsing with Short Dependency Relations in Unlabeled Data Wenliang Chen, Daisuke Kawahara, Kiyotaka Uchimoto, Yujie Zhang and Hitoshi Isahara88 Text Mining/Information Extraction (2) Effective Compositional Model for Lexical Alignment Beatrice Daille and Emmanuel Morin95 Determining the Unithood of Word Sequences Using a Probabilistic Approach Wilson Wong, Wei Liu and Mohammed Bennamoun103 Lexical Chains as Document Features Dinakar Jayarajan, Dipti Deodhare and Balaraman Ravindran111 Summarization Entity-driven Rewrite for Multi-document Summarization Ani Nenkova.118  xi A New Approach to Automatic Document Summarization Xiaofeng Wu and Chengqing Zong126 Generic Text Summarization Using Probabilistic Latent Semantic Indexing Harendra Bhandari, Masashi Shimbo, Takahiko Ito and Yuji Matsumoto133 Multiple Document Processing Identifying Cross-Document Relations between Sentences Yasunari Miyabe, Hiroya Takamura and Manabu Okumura141 Experiments on Semantic-based Clustering for Cross-document Coreference Horacio Saggion.149 Modeling Context in Scenario Template Creation Long Qiu, Min-Yen Kan and Tat-Seng Chua.157 Cross Language Text Categorization Using a Bilingual Lexicon Ke Wu, Xiaolin Wang and Bao-Liang Lu165 Information Retrieval Identify Temporal Websites Based on User Behavior Analysis Yong Wang, Yiqun Liu, Min Zhang, Shaoping Ma and Liyun Ru.173 A Comparative Study for Query Translation using Linear Combination and Confidence Measure Youssef Kadri and Jian-Yun Nie181 TSUBAKI: An Open Search Engine Infrastructure for Developing New Information Access Methodology Keiji Shinzato, Tomohide Shibata, Daisuke Kawahara, Chikara Hashimoto and Sadao Kurohashi189 A Study on Effectiveness of Syntactic Relationship in Dependence Retrieval Model Fan Ding and Bin Wang197 Spoken Language Processing Automatic Estimation of Word Significance oriented for Speech-based Information Retrieval Takashi Shichiri, Hiroaki Nanjo and Takehiko Yoshimi204   xii Rapid Prototyping of Robust Language Understanding Modules for Spoken Dialogue Systems Yuichiro Fukubayashi, Kazunori Komatani, Mikio Nakano, Kotaro Funakoshi, Hiroshi Tsujino, Tetsuya Ogata and Hiroshi G. Okuno.210 Automatic Prosodic Labeling with Conditional Random Fields and Rich Acoustic Features Gina-Anne Levow217 Machine Translation (1) Chinese Unknown Word Translation by Subword Re-segmentation Ruiqiang Zhang and Eiichiro Sumita.225 Hypothesis Selection in Machine Transliteration: A Web Mining Approach Jong-Hoon Oh and Hitoshi Isahara233 What Prompts Translators to Modify Draft Translations?
65:328	An Analysis of Basic Modification Patterns for Use in the Automatic Notification of Awkwardly Translated Text Takeshi Abekawa and Kyo Kageura.241 Improving Word Alignment by Adjusting Chinese Word Segmentation Ming-Hong Bai, Keh-Jiann Chen and Jason S. Chang.249 Text Mining/Information Extraction (3) The Telling Tail: Signals of Success in Electronic Negotiation Texts Marina Sokolova, Vivi Nastase and Stan Szpakowicz257 Automatic Extraction of Briefing Templates Dipanjan Das, Mohit Kumar and Alexander I. Rudnicky265 Mining the Web for Relations between Digital Devices using a Probabilistic Maximum Margin Model Oksana Yakhnenko and Barbara Rosario.273 Learning Patterns from the Web to Translate Named Entities for Cross Language Information Retrieval Yu-Chun Wang, Richard Tzong-Han Tsai and Wen-Lian Hsu.281     xiii Emotion/Sentiment Analysis Bootstrapping Both Product Features and Opinion Words from Chinese Customer Reviews with Cross-Inducing Bo Wang and Houfeng Wang289 Learning to Shift the Polarity of Words for Sentiment Classification Daisuke Ikeda, Hiroya Takamura, Lev-Arie Ratinov and Manabu Okumura296 Unsupervised Classification of Sentiment and Objectivity in Chinese Text Taras Zagibalov and John Carroll.304 Using Roget's Thesaurus for Fine-grained Emotion Recognition Saima Aman and Stan Szpakowicz312 Machine Translation (2) Heterogeneous Automatic MT Evaluation Through Non-Parametric Metric Combinations Jess Gimnez and Llus Mrquez319 Paraphrasing depending on Bilingual Context Toward Generalization of Translation Knowledge Young-Sook Hwang, Young-Kil Kim and Sangkyu Park.327 Named Entity Recognition A Framework Based on Graphical Models with Logic for Chinese Named Entity Recognition Xiaofeng Yu, Wai Lam and Shing-Kit Chan.335 A Hybrid Feature Set based Maximum Entropy Hindi Named Entity Recognition Sujan Kumar Saha, Sudeshna Sarkar and Pabitra Mitra343 Relation Extraction An Effective Methods of using Web based Information for Relation Extraction Stanley, Wai Keong Yong and Jian Su.350 Minimally Supervised Learning of Semantic Knowledge from Query Logs Mamoru Komachi and Hisami Suzuki.358     xiv Statistical Models/Machine Learning for NLP (1) Learning a Stopping Criterion for Active Learning for Word Sense Disambiguation and Text Classification Jingbo Zhu, Huizhen Wang and Eduard Hovy.366 Multi-View Co-Training of Transliteration Model Jin-Shea Kuo and Haizhou Li373 Identifying Sections in Scientific Abstracts using Conditional Random Fields Kenji Hirohata, Naoaki Okazaki, Sophia Ananiadou and Mitsuru Ishizuka381 Ontologies and Linguistic Resources (1) Formalising Multi-layer Corpora in OWL DL Lexicon Modelling, Querying and Consistency Control Aljoscha Burchardt, Sebastian Pad, Dennis Spohr, Anette Frank and Ulrich Heid389 Constructing Taxonomy of Numerative Classifiers for Asian Languages Kiyoaki Shirai, Takenobu Tokunaga, Chu-Ren Huang, Shu-Kai Hsieh, Tzu-Yi Kuo, Virach Sornlertlamvanich and Thatsanee Charoenporn.397 Translating Compounds by Learning Component Gloss Translation Models via Multiple Languages Nikesh Garera and David Yarowsky403 Question Answering Answering Definition Questions via Temporally-Anchored Text Snippets Marius Pasca.411 Corpus-based Question Answering for why-Questions Ryuichiro Higashinaka and Hideki Isozaki..418 Cluster-Based Query Expansion for Statistical Question Answering Lucian Vlad Lita and Jaime Carbonell .426 Statistical Models/Machine Learning for NLP (2) A Semantic Feature for Relation Recognition Using a Web-based Corpus Chen-Ming Hung434   xv Multilingual Text Entry using Automatic Language Detection Yo Ehara and Kumiko Tanaka-Ishii441 Using Contextual Speller Techniques and Language Modeling for ESL Error Correction Michael Gamon, Jianfeng Gao, Chris Brockett, Alexandre Klementiev, William B. Dolan, Dmitriy Belenko and Lucy Vanderwende.449 Ontologies and Linguistic Resources (2) Bilingual Synonym Identification with Spelling Variations Takashi Tsunakawa and Jun'ichi Tsujii.457 Minimally Supervised Multilingual Taxonomy and Translation Lexicon Induction Nikesh Garera and David Yarowsky.465 Japanese-Spanish Thesaurus Construction Using English as a Pivot Jessica Ramrez, Masayuki Asahara and Yuji Matsumoto.473 Event/Sentence Relation Automatic Identification of Rhetorical Roles using Conditional Random Fields for Legal Document Summarization M. Saravanan, B. Ravindran and S. Raman.481 Projection-based Acquisition of a Temporal Labeller Kathrin Spreyer and Anette Frank.489 Acquiring Event Relation Knowledge by Learning Cooccurrence Patterns and Fertilizing Cooccurrence Samples with Verbal Nouns Shuya Abe, Kentaro Inui and Yuji Matsumoto.497 Statistical Machine Translation Refinements in BTG-based Statistical Machine Translation Deyi Xiong, Min Zhang, AiTi Aw, Haitao Mi, Qun Liu and Shouxun Lin505 Simple Syntactic and Morphological Processing Can Help English-Hindi Statistical MT Ananthakrishnan Ramanathan, Jayprasad Hegde, Ritesh M. Shah, Pushpak Bhattacharyya and Sasikumar M513 Statistical Translation Models for Personalized Search Rohini U, Vamshi Ambati and Vasudeva Varma521  xvi Ontologies and Linguistic Resources (3) Repurposing Theoretical Linguistic Data for Tool Development and Search Fei Xia and William D. Lewis.529 Computing Paraphrasability of Syntactic Variants using Web Snippets Atsushi Fujita and Satoshi Sato537 Augmenting Wikipedia with Named Entity Tags Wisam Dakka and Silviu Cucerzan545 Semantic Similarity Context Feature Selection for Distributional Similarity Masato Hagiwara, Yasuhiro Ogawa and Katsuhiko Toyama553 Gloss-Based Semantic Similarity Metrics for Predominant Sense Acquisition Ryu Iida, Diana McCarthy and Rob Koeling.561 Benchmarking Noun Compound Interpretation Su Nam Kim and Timothy Baldwin.569              xvii Volume II Poster papers (Poster session 1) Vaakkriti: Sanskrit Tokenizer Aasish Pappu and Ratna Sanyal.577 A Bottom Up approach to Persian Stemming Amir Azim Sharifloo and Mehrnoush Shamsfard.583 Named Entity Recognition in Bengali: A Conditional Random Field Approach Asif Ekbal, Rejwanul Haque and Sivaji Bandyopadhyay589 An Online Cascaded Approach to Biomedical Named Entity Recognition Shing-Kit Chan, Wai Lam and Xiaofeng Yu595 Automatic rule acquisition for Chinese intra-chunk relations Qiang Zhou601 Japanese Named Entity Recognition Using Structural Natural Language Processing Ryohei Sasano and Sadao Kurohashi607 Dimensionality Reduction with Multilingual Resource YingJu Xia, Hao Yu and Gang Zou.613 A Web-based English Proofing System for English as a Second Language Users Xing YI, Jianfeng Gao and William B. Dolan.619 Analysis of Intention in Dialogues Using Category Trees and Its Application to Advertisement Recommendation Hung-Chi Huang, Hsin-Hsi Chen and Ming-Shun Lin..625 Term Extraction Through Unithood and Termhood Unification Thuy Vu, AiTi Aw and Min Zhang..631 Search Result Clustering Using Label Language Model Yeha Lee, Seung-Hoon Na and Jong-Hyeok Lee.637 Effects of Related Term Extraction in Transliteration into Chinese HaiXiang Huang and Atsushi Fujii643   xviii A Structured Prediction Approach for Statistical Machine Translation Dakun Zhang, Le Sun and Wenbo Li.649 Method of Selecting Training Data to Build a Compact and Efficient Translation Model Keiji Yasuda, Ruiqiang Zhang, Hirofumi Yamamoto and Eiichiro Sumita.655 Large and Diverse Language Models for Statistical Machine Translation Holger Schwenk and Philipp Koehn.661 A linguistic and navigational knowledge approach to text navigation Javier Couto and Jean-Luc Minel.667 Synset Assignment for Bi-lingual Dictionary with Limited Resource Virach Sornlertlamvanich, Thatsanee Charoenporn, Chumpol Mokarat, Hitoshi Isahara, Hammam Riza and Purev Jaimai..673 Ranking words for building a Japanese defining vocabulary Tomoya Noro and Takehiro Tokuda.679 Automatically Identifying Computationally Relevant Typological Features William D. Lewis and Fei Xia.685 Automatic Paraphrasing of Japanese Functional Expressions Using a Hierarchically Organized Dictionary Suguru Matsuyoshi and Satoshi Sato691 Generation of Referring Expression Using Prefix Tree Structure Sibabrata Paladhi and Sivaji Bandyopadhyay697 Coverage-based Evaluation of Parser Generalizability Tuomo Kakkonen and Erkki Sutinen703 Learning Reliability of Parses for Domain Adaptation of Dependency Parsing Daisuke Kawahara and Kiyotaka Uchimoto.709 Resolving Ambiguities of Chinese Conjunctive Structures by Divide-and-conquer Approaches Duen-Chi Yang, Yu-Ming Hsieh and Keh-Jiann Chen.715 Dependency Annotation Scheme for Indian Languages Rafiya Begum, Samar Husain, Arun Dhwaj, Dipti Misra Sharma, Lakshmi Bai and Rajeev Sangal721  xix Non-Factoid Japanese Question Answering through Passage Retrieval that Is Weighted Based on Types of Answers Masaki Murata, Sachiyo Tsukawaki, Toshiyuki Kanamaru, Qing Ma and Hitoshi Isahara.727 A Multi-Document Multi-Lingual Automatic Summarization System Mohamad Ali Honarpisheh, Gholamreza Ghassem-Sani and Ghassem Mirroshandel.733 Summarization by Analogy: An Example-based Approach for News Articles Megumi Makino and Kazuhide Yamamoto739 Sentence Ordering based on Cluster Adjacency in Multi-Document Summarization Donghong Ji and Yu Nie.745 Statistical Machine Translation based Passage Retrieval for Cross-Lingual Question Answering Tomoyosi Akiba, Kei Shimizu and Atsushi Fujii.751 Poster papers (Poster session 2) Unsupervised All-words Word Sense Disambiguation with Grammatical Dependencies Vivi Nastase757 Syntactic and Semantic Frames in PrepNet Saint-Dizier Patrick763 Automatic Classification of English Verbs Using Rich Syntactic Features Lin Sun, Anna Korhonen and Yuval Krymolowski769 MRD-based Word Sense Disambiguation: Further Extending Lesk Timothy Baldwin, Su Nam Kim, Francis Bond, Sanae Fujita, David Martinez and Takaaki Tanaka.775 Fast Computing Grammar-driven Convolution Tree Kernel for Semantic Role Labeling Wanxiang Che, Min Zhang, AiTi Aw, Chew Lim Tan, Ting Liu and Sheng Li.781 SYNGRAPH: A Flexible Matching Method based on Synonymous Expression Extraction from an Ordinary Dictionary and a Web Corpus Tomohide Shibata, Michitaka Odani, Jun Harashima, Takashi Oonishi and Sadao Kurohashi..787   xx Annotation of Multiword Expressions in the Prague Dependency Treebank Eduard Bejek, Pavel Strak and Pavel Schlesinger..793 Learning Named Entity Hyponyms for Question Answering Paul McNamee, Rion Snow, Patrick Schone and James Mayfield..799 Errgrams -A Way to Improving ASR for Highly Inflected Dravidian Languages Kamadev Bhanuprasad and Mats Svenson805 Noise as a Tool for Spoken Language Identification Sunita Maithani and J.S. Rawat811 Identifying Real or Fake Articles: Towards better Language Modeling Sameer Badaskar, Sachin Agarwal and Shilpa Arora.817 Multi-label Text Categorization with Model Combination based on F1-score Maximization Akinori Fujino, Hideki Isozaki and Jun Suzuki.823 An Experimental Comparison of the Voted Perceptron and Support Vector Machines in Japanese Analysis Tasks Manabu Sassano.829 Learning Decision Lists with Known Rules for Text Mining Venkatesan Chakravarthy, Sachindra Joshi, Ganesh Ramakrishnan, Shantanu Godbole and Sreeram Balakrishnan835 A re-examination of dependency path kernels for relation extraction Mengqiu Wang..841 Mining Chinese-English Parallel Corpora from the Web Bo Li and Juan Liu.847 Fast Duplicated Documents Detection using Multi-level Prefix-filter Kenji Tateishi and Dai Kusui.853 Towards Data And Goal Oriented Analysis: Tool Inter-Operability And Combinatorial Comparison Yoshinobu Kano, Ngan Nguyen, Rune Stre, Kazuhiro Yoshida, Keiichiro Fukamachi, Yusuke Miyao, Yoshimasa Tsuruoka, Sophia Ananiadou and Jun'ichi Tsujii..859   xxi A Co-occurrence Graph-based Approach for Personal Name Alias Extraction from Anchor Texts Danushka Bollegala, Yutaka Matsuo and Mitsuru Ishizuka.865 Towards Automated Semantic Analysis on Biomedical Research Articles Donghui Feng, Gully Burns, Jingbo Zhu and Eduard Hovy871 Large Scale Diagnostic Code Classification for Medical Patient Records Lucian Vlad Lita, Shipeng Yu, Stefan Niculescu and Jinbo Bi877 Hacking Wikipedia for Hyponymy Relation Acquisition Asuka Sumida and Kentaro Torisawa.883 A Discriminative Approach to Japanese Abbreviation Extraction Naoaki Okazaki, Mitsuru Ishizuka and Jun'ichi Tsujii889 Linguistic Interpretation of Emotions for Affect Sensing from Text Mostafa Al Masum Shaikh, Helmut Prendinger and Mitsuru Ishizuka895 How to Take Advantage of the Limitations with Markov Clustering?--The Foundations of Branching Markov Clustering (BMCL) Hiroyuki Akama, Maki Miyake and Jaeyoung Jung..901 Combining Context Features by Canonical Belief Network for Chinese Part-Of-Speech Tagging Hongzhi Xu and Chunping Li907 Language Independent Text Correction using Finite State Automata Ahmed Hassan, Sara Noeman and Hany Hassan.913 Semantic Role Labeling of Chinese Using Transductive SVM and Semantic Heuristics Yaodong Chen, Ting Wang, Huowang Chen and Xishan Xu919 A Comparative Study of Mixture Models for Automatic Topic Segmentation of Multiparty Dialogues Maria Georgescul, Alexander Clark and Susan Armstrong925 Exploiting Unlabeled Text to Extract New Words of Different Semantic Transparency for Chinese Word Segmentation Richard Tzong-Han Tsai and Hsi-Chuan Hung931    xxii Tutorial Social Network Inspired Models of NLP and Language Evolution  Monojit Choudhury, Animesh Mukherjee and Niloy Ganguly937 How to Add a New Language on the NLP Map: Building Resources and Tools for Languages with Scarce Resources Rada Mihalcea and Vivi Nastase..938 Introduction to Text Summarization and Other Information Access Technologies  Horacio Saggion939 Demo A Punjabi Grammar Checker  Mandeep Singh Gill, Gurpreet Singh Lehal, and Shiv Sharma Joshi940 Netgraph  Making Searching in Treebanks Easy  Ji  Mrovsk.945 Global Health Monitor A Web-based System for Detecting and Mapping Infectious Diseases  Son Doan, QuocHung-Ngo, Ai Kawazoe, Nigel Collier951 A Mechanism to Provide Language-Encoding Support and an NLP Friendly Editor  Anil Kumar Singh.957 NLP Applications of Sinhala: TTS & OCR  Ruvan Weerasinghe, Asanka Wasala, Dulip Herath and Viraj Welgama963 POLLy: A Conversational System that uses a Shared Representation to Generate Action and Social Language  Swati Gupta, Marilyn A. Walker, and Daniela M. Romano.967 Cross Lingual Information Access System for Indian Languages  CLIA Consortium.973 AUTHOR INDEX976       xxiii  xxiv   A Lemmatization Method for Modern Mongolian and its Application to Information Retrieval Badam-Osor Khaltar           Atsushi Fujii Graduate School of Library, Information and Media Studies University of Tsukuba 1-2 Kasuga Tsukuba, 305-8550, Japan {khab23, fujii}@slis.tsukuba.ac.jp    Abstract In Modern Mongolian, a content word can be inflected when concatenated with suffixes.
66:328	Identifying the original forms of content words is crucial for natural language processing and information retrieval.
67:328	We propose a lemmatization method for Modern Mongolian and apply our method to indexing for information retrieval.
68:328	We use technical abstracts to show the effectiveness of our method experimentally.
69:328	1 Introduction The Mongolian language is divided into Traditional Mongolian, which uses the Mongolian alphabet, and Modern Mongolian, which uses the Cyrillic alphabet.
70:328	In this paper, we focus solely on the latter and use the word Mongolian to refer to Modern Mongolian.
71:328	In Mongolian, which is an agglutinative language, each sentence is segmented on a phrase-byphrase basis.
72:328	A phrase consists of a content word, such as a noun or a verb, and one or more suffixes, such as postpositional participles.
73:328	A content word can potentially be inflected when concatenated with suffixes.
74:328	Identifying the original forms of content words in Mongolian text is crucial for natural language processing and information retrieval.
75:328	In information retrieval, the process of normalizing index terms is important, and can be divided into lemmatization and stemming.
76:328	Lemmatization identifies the original form of an inflected word, whereas stemming identifies a stem, which is not necessarily a word.
77:328	Existing search engines, such as Google and Yahoo!, do not perform lemmatization or stemming for indexing Web pages in Mongolian.
78:328	Therefore, Web pages that include only inflected forms of a query cannot be retrieved.
79:328	In this paper, we propose a lemmatization method for Mongolian and apply our method to indexing for information retrieval.
80:328	2 Inflection types in Mongolian phrases Nouns, adjectives, numerals, and verbs can be concatenated with suffixes.
81:328	Nouns and adjectives are usually concatenated with a sequence of a plural suffix, case suffix, and reflexive possessive suffix.
82:328	Numerals are concatenated with either a case suffix or a reflexive possessive suffix.
83:328	Verbs are concatenated with various suffixes, such as an aspect suffix, a participle suffix, and a mood suffix.
84:328	Figure 1 shows the inflection types of content words in Mongolian phrases.
85:328	In (a), there is no inflection in the content word   (book), concatenated with the suffix  (the genitive case).
86:328	The content words are inflected in (b)-(e).
87:328	Type Example (a) No inflection  +     book + genitive case (b) Vowel insertion  +      brother + dative case (c) Consonant insertion   +    building + genitive case (d) The letters   or   are eliminated, and the vowel converts to     +     return + ablative case (e) Vowel elimination   +     work + ablative case Figure 1: Inflection types of content words in Mongolian phrases.
88:328	1  Loanwords, which can be nouns, adjectives, or verbs in Mongolian, can also be concatenated with suffixes.
89:328	In this paper, we define a loanword as a word imported from a Western language.
90:328	Because loanwords are linguistically different from conventional Mongolian words, the suffix concatenation is also different from that for conventional Mongolian words.
91:328	Thus, exception rules are required for loanwords.
92:328	For example, if the loanword   (station) is to be concatenated with a genitive case suffix,   should be selected from the five genitive case suffixes (i.e.,  , , ,  , and  ) based on the Mongolian grammar.
93:328	However, because   (station) is a loanword, the genitive case  is selected instead of   , resulting in the noun phrase   (stations).
94:328	Additionally, the inflection (e) in Figure 1 never occurs for noun and adjective loanwords.
95:328	3 Related work Sanduijav et al.96:328	(2005) proposed a lemmatization method for noun and verb phrases in Mongolian.
97:328	They manually produced inflection rules and concatenation rules for nouns and verbs.
98:328	Then, they automatically produced a dictionary by aligning nouns or verbs with suffixes.
99:328	Lemmatization for phrases is performed by consulting this dictionary.
100:328	Ehara et al.101:328	(2004) proposed a morphological analysis method for Mongolian, for which they manually produced rules for inflections and concatenations.
102:328	However, because the lemmatization methods proposed by Sanduijav et al.103:328	(2005) and Ehara et al.104:328	(2004) rely on dictionaries, these methods cannot lemmatize new words that are not in dictionaries, such as loanwords and technical terms.
105:328	Khaltar et al.106:328	(2006) proposed a lemmatization method for Mongolian noun phrases that does not use a noun dictionary.
107:328	Their method can be used for nouns, adjectives, and numerals, because the suffixes that are concatenated with these are almost the same and the inflection types are also the same.
108:328	However, they were not aware of the applicability of their method to adjectives and numerals.
109:328	The method proposed by Khaltar et al.110:328	(2006) mistakenly extracts loanwords with endings that are different from conventional Mongolian words.
111:328	For example, if the phrase  (ecologys) is lemmatized, the resulting content word will be  , which is incorrect.
112:328	The correct word is   (ecology).
113:328	This error occurs because the ending  (-ology) does not appear in conventional Mongolian words.
114:328	In addition, Khaltar et al.115:328	(2006)s method applies (e) in Figure 1 to loanwords, whereas inflection (e) never occurs in noun and adjective loanwords.
116:328	Lemmatization and stemming are arguably effective for indexing in information retrieval (Hull, 1996; Porter, 1980).
117:328	Stemmers have been developed for a number of agglutinative languages, including Malay (Tai et al., 2000), Indonesian (Berlian Vega and Bressan, 2001), Finnish (Korenius et al., 2004), Arabic (Larkey et al., 2002), Swedish (Carlberger et al., 2001), Slovene (Popovi and Willett, 1992) and Turkish (Ekmekioglu et al., 1996).
118:328	Xu and Croft (1998) and Melucci and Orio (2003) independently proposed a languageindependent method for stemming, which analyzes a corpus in a target language and identifies an equivalent class consisting of an original form, inflected forms, and derivations.
119:328	However, their method, which cannot identify the original form in each class, cannot be used for natural language applications where word occurrences must be standardized by their original forms.
120:328	Finite State Transducers (FSTs) have been applied to lemmatization.
121:328	Although Karttunen and Beesley (2003) suggested the applicability of FSTs to various languages, no rule has actually been proposed for Mongolian.
122:328	The rules proposed in this paper can potentially be used for FSTs.
123:328	To the best of our knowledge, no attempt has been made to apply lemmatization or stemming to information retrieval for Mongolian.
124:328	Our research is the first serious effort to address this problem.
125:328	4 Methodology 4.1 Overview In view of the discussion in Section 3, we enhanced the lemmatization method proposed by Khaltar et al.126:328	(2006).
127:328	The strength of this method is that noun dictionaries are not required.
128:328	Figure 2 shows the overview of our lemmatization method for Mongolian.
129:328	Our method consists of two segments, which are identified with dashed lines in Figure 2: lemmatization for verb phrases and lemmatization for noun phrases.
130:328	2    In Figure 2, we enhanced the method proposed by Khaltar et al.131:328	(2006) from three perspectives.
132:328	First, we introduced lemmatization for verb phrases.
133:328	There is a problem to be solved when we target both noun and verb phrases.
134:328	There are a number of suffixes that can concatenate with both verbs and nouns, but the inflection type can be different depending on the part of speech.
135:328	As a result, verb phrases can incorrectly be lemmatized as noun phrases and vice versa.
136:328	Because new verbs are not created as frequently as nouns, we predefine a verb dictionary, but do not use a noun dictionary.
137:328	We first lemmatize an entered phrase as a verb phrase and then check whether the extracted content word is defined in our verb dictionary.
138:328	If the content word is not defined in our verb dictionary, we lemmatize the input phrase as a noun phrase.
139:328	Second, we introduced a loanword identification rule in lemmatization for noun phrases.
140:328	We identify a loanword phrase before applying a noun suffix segmentation rule and vowel insertion rule.
141:328	Because segmentation rules are different for conventional Mongolian words and loanwords, we enhance the noun suffix segmentation rule that was originally proposed by Khaltar et al.142:328	(2006).
143:328	Additionally, we do not use the vowel insertion rule, if the entered phrase is detected as a loanword phrase.
144:328	The reason is that vowel elimination never occurs in noun loanwords.
145:328	Third, unlike Khaltar et al.146:328	(2006), we targeted adjective and numeral phrases.
147:328	Because the suffixes concatenated with nouns, adjectives, and numerals are almost the same, the lemmatization method for noun phrases can also be used for adjective and numeral phrases without any modifications.
148:328	We use lemmatization for noun phrases to refer to the lemmatization for noun, adjective, and numeral phrases.
149:328	We briefly explain our lemmatization process using Figure 2.
150:328	We consult a verb suffix dictionary and perform backward partial matching to determine whether a suffix is concatenated at the end of a phrase.
151:328	If a suffix is detected, we use a verb suffix segmentation rule to remove the suffix and extract the content word.
152:328	This process will be repeated until the residue of the phrase does not match any of the entries in the verb suffix dictionary.
153:328	We use a vowel insertion rule to check whether vowel elimination occurred in the content word and insert the eliminated vowel.
154:328	If the content word is defined in a verb dictionary, we output the content word as a verb and terminate the lemmatization process.
155:328	If not, we use the entered phrase and perform lemmatization for noun phrases.
156:328	We consult a noun suffix dictionary to determine whether one or more suffixes are concatenated at the end of the target phrase.
157:328	Yes No Detect a suffix in the phrase Remove suffixes and extract a content word Check if the content word is a verb Detect a suffix in the phrase Remove suffixes and extract a content word Input a phrase Output the content word Process the inputted phrase as a noun phrase Loanword identification rule Verb dictionary Verb suffix segmentation rule Noun suffix dictionary Noun suffix segmentation rule Verb suffix dictionary Figure 2: Overview of our lemmatization method for Mongolian.
158:328	Lemmatization for noun phrases Vowel insertion rule Insert an eliminated vowel Insert an eliminated vowel Identify loanword Vowel insertion rule Lemmatization for verb phrases 3  We use a loanword identification rule to identify whether the phrase is a loanword phrase.
159:328	We use a noun suffix segmentation rule to remove the suffixes and extract the content word.
160:328	If the phrase is identified as a loanword phrase we use different segmentation rules.
161:328	We use the vowel insertion rule which is also used for verb phrases to check whether vowel elimination occurred in the content word and insert the eliminated vowel.
162:328	However, if the phrase is identified as a loanword phrase, we do not use the vowel insertion rule.
163:328	If the target phrase does not match any of the entries in the noun suffix dictionary, we determine that a suffix is not concatenated and we output the phrase as it is. The inflection types (b)(d) in Figure 1 are processed by the verb suffix segmentation rule and noun suffix segmentation rule.
164:328	The inflection (e) in Figure 1 is processed by the vowel insertion rule.
165:328	We elaborate on the dictionaries and rules in Sections 4.24.8.
166:328	4.2 Verb suffix dictionary We produced a verb suffix dictionary, which consists of 126 suffixes that can concatenate with verbs.
167:328	These suffixes include aspect suffixes, participle suffixes, and mood suffixes.
168:328	Figure 3 shows a fragment of our verb suffix dictionary, in which inflected forms of suffixes are shown in parentheses.
169:328	All suffixes corresponding to the same suffix type represent the same meaning.
170:328	4.3 Verb suffix segmentation rule For the verb suffix segmentation rule, we produced 179 rules.
171:328	There are one or more segmentation rules for each of the 126 verb suffixes mentioned in Section 4.2.
172:328	Figure 4 shows a fragment of the verb suffix segmentation rule for suffix   (past).
173:328	In the column Segmentation rule, the condition of each if sentence is a phrase ending.
174:328	V refers to a vowel and * refers to any strings.
175:328	C9 refers to any of the nine consonants  ,  ,  ,  ,  ,  ,  ,  , or  , and C7 refers to any of the seven consonants  ,  ,  ,  ,  ,  , or  .
176:328	If a condition is satisfied, we remove one or more corresponding characters.
177:328	For example, because the verb phrase  (renew + past) satisfies condition (ii), Suffix type Suffix Appeal Complete Perfect Progressive-perfect ,     ( ),   ( ),  ,   ,  ,  ,  Figure 3: Fragment of verb suffix dictionary.
178:328	Suffix Segmentation rule   Past (i)  If ( *+ V + V +   ) Remove  (ii) If ( * + C9 + C7 + V +   ) Remove V +  Figure 4: Fragment of verb suffix segmentation rule.
179:328	we remove the suffix   and the preceding vowel  to extract   .
180:328	4.4 Verb dictionary We use the verb dictionary produced by Sanduijav et al.181:328	(2005), which includes 1254 verbs.
182:328	4.5 Noun suffix dictionary We use the noun suffix dictionary produced by Khaltar et al.183:328	(2006), which contains 35 suffixes that can be concatenated with nouns.
184:328	These suffixes are postpositional particles.
185:328	Figure 5 shows a fragment of the dictionary, in which inflected forms of suffixes are shown in parentheses.
186:328	4.6 Noun suffix segmentation rule There are 196 noun suffix segmentation rules, of which 173 were proposed by Khaltar et al.187:328	(2006).
188:328	As we explained in Section 3, these 173 rules often incorrectly lemmatize loanwords with different endings from conventional Mongolian words.
189:328	We analyzed the list of English suffixes and found that English suffixes -ation and -ology are incorrectly lemmatized by Khaltar et al.190:328	(2006).
191:328	In Mongolian, -ation is transliterated into   or   and -ology is transliterated into  .
192:328	Thus, we produced 23 rules for loanwords that end with  ,  , or  .
193:328	Figure 6 shows a fragment of our suffix segmentation rule for loanwords.
194:328	For example, for the loanword phrase   (ecology + genitive), we use the segmentation rule for suffix   (genitive) in Figure 6.
195:328	We remove the suffix   (genitive) and add   to the end of the content word.
196:328	As a result, the noun  (ecology) is correctly extracted.
197:328	4   Case Suffix Genitive Accusative Dative Ablative  ,  ,  , ,  ,  ,   ,    ( ),   ( ),  ,  Figure 5: Fragment of noun suffix dictionary.
198:328	Suffix Segmentation rule for loanwords  Genitive If (* + )      Remove () , Add (  )  Accusative If (* +  )      Remove ( ), Add ( ) Figure 6: Fragment of suffix segmentation rules for loanwords.
199:328	4.7 Vowel insertion rule To insert an eliminated vowel and extract the original form of a content word, we check the last two characters of the content word.
200:328	If they are both consonants, we determine that a vowel was eliminated.
201:328	However, a number of Mongolian words end with two consonants inherently and, therefore, Khaltar et al.202:328	(2006) referred to a textbook on the Mongolian grammar (Ts, 2002) to produce 12 rules to determine when to insert a vowel between two consecutive consonants.
203:328	We also use these rules as our vowel insertion rule.
204:328	4.8 Loanword identification rule Khaltar et al.205:328	(2006) proposed rules for extracting loanwords from Mongolian corpora.
206:328	Words that satisfy one of seven conditions are extracted as loanwords.
207:328	Of the seven conditions, we do not use the condition that extracts a word ending with consonants +   as a loanword because it was not effective for lemmatization purposes in preliminary study.
208:328	5 Experiments 5.1 Evaluation method We collected 1102 technical abstracts from the Mongolian IT Park 1  and used them for experiments.
209:328	There were 178,448 phrase tokens and 17,709 phrase types in the 1102 technical abstracts.
210:328	We evaluated the accuracy of our lemmatization method (Section 5.2) and the effectiveness of our method in information retrieval (Section 5.3) experimentally.
211:328	1  http://www.itpark.mn/ (October, 2007) 5.2 Evaluating lemmatization Two Mongolian graduate students served as assessors.
212:328	Neither of the assessors was an author of this paper.
213:328	The assessors provided the correct answers for lemmatization.
214:328	The assessors also tagged each word with its part of speech.
215:328	The two assessors performed the same task independently.
216:328	Differences can occur between two assessors on this task.
217:328	We measured the agreement of the two assessors by the Kappa coefficient, which ranges from 0 to 1.
218:328	The Kappa coefficients for performing lemmatization and tagging of parts of speech were 0.96 and 0.94, respectively, which represents almost perfect agreement (Landis and Koch, 1977).
219:328	However, to enhance the objectivity of the evaluation, we used only the phrases for which the two assessors agreed with respect to the part of speech and lemmatization.
220:328	We were able to use the noun and verb dictionaries of Sanduijav et al.221:328	(2005).
222:328	Therefore, we compared our lemmatization method with Sanduijav et al.223:328	(2005) and Khaltar et al.224:328	(2006) in terms of accuracy.
225:328	Accuracy is the ratio of the number of phrases correctly lemmatized by the method under evaluation to the total number of target phrases.
226:328	Here, the target phrases are noun, verb, adjective, and numeral phrases.
227:328	Table 1 shows the results of lemmatization.
228:328	We targeted 15,478 phrase types in the technical abstracts.
229:328	Our experiment is the largest evaluation for Mongolian lemmatization in the literature.
230:328	In contrast, Sanduijav et al.231:328	(2005) and Khaltar et al.232:328	(2006) used only 680 and 1167 phrase types, respectively, for evaluation purposes.
233:328	In Table 1, the accuracy of our method for nouns, which were targeted in all three methods, was higher than those of Sanduijav et al.234:328	(2005) and Khaltar et al.235:328	(2006).
236:328	Because our method and that of Sanduijav et al.237:328	(2005) used the same verb dictionary, the accuracy for verbs is principally the same for both methods.
238:328	The accuracy for verbs was low, because a number of verbs were not included in the verb dictionary and were mistakenly lemmatized as noun phrases.
239:328	However, this problem will be solved by enhancing the verb dictionary in the future.
240:328	In total, the accuracy of our method was higher than those of Sanduijav et al.241:328	(2005) and Khaltar et al.242:328	(2006).
243:328	5  Table 1: Accuracy of lemmatization (%).
244:328	#Phrase types Sanduijav et al.245:328	(2005) Khaltar et al.246:328	(2006) Our method Noun 13,016 57.6 87.7 92.5 Verb 1,797 24.5 23.8 24.5 Adjective 609 82.6 83.5 83.9 Numeral 56 41.1 80.4 81.2 Total 15,478 63.2 72.3 78.2  We analyzed the errors caused by our method in Figure 7.
247:328	In the column Example, the left side and the right side of an arrow denote an error and the correct answer, respectively.
248:328	The error (a) occurred to nouns, adjectives, and numerals, in which the ending of a content word was mistakenly recognized as a suffix and was removed.
249:328	The error (b) occurred because we did not consider irregular nouns.
250:328	The error (c) occurred to loanword nouns because the loanword identification rule was not sufficient.
251:328	The error (d) occurred because we relied on a verb dictionary.
252:328	The error (e) occurred because a number of nouns were incorrectly lemmatized as verbs.
253:328	For the errors (a)-(c), we have not found solutions.
254:328	The error (d) can be solved by enhancing the verb dictionary in the future.
255:328	If we are able to use part of speech information, we can solve the error (e).
256:328	There are a number of automatic methods for tagging parts of speech (Brill, 1997), which have promise for alleviating the error (e).
257:328	5.3 Evaluating the effectiveness of lemmatization in information retrieval We evaluated the effectiveness of lemmatization methods in indexing for information retrieval.
258:328	No test collection for Mongolian information retrieval is available to the public.
259:328	We used the 1102 technical abstracts to produce our test collection.
260:328	Figure 8 shows an example technical abstract, in which the title is Advanced Albumin Fusion Technology in English.
261:328	Each technical abstract contains one or more keywords.
262:328	In Figure 8, keywords, such as     (blood serum) and   (placenta) are annotated.
263:328	We used two different types of queries for our evaluation.
264:328	First, we used each keyword as a query, which we call keyword query (KQ).
265:328	Second, we used each keyword list as a query, which we call list query (LQ).
266:328	The average number for keywords in the keywords list was 6.1.
267:328	For each query,  Reasons of errors #Errors Example (a) Word ending is the same as a suffix.
268:328	274     sort (b) Noun plural tense is irregular.
269:328	244     animal (c) Noun loanword ends with two consonants.
270:328	94      dinosaur (d) Verb does not exist in our verb dictionary.
271:328	689     to code (e) Word corresponds to multiple part of speech.
272:328	853     country   inter  Figure 7: Errors of our lemmatization method.
273:328	we used as the relevant documents the abstracts that were annotated with the query keyword in the keywords field.
274:328	Thus, we were able to avoid the cost of relevance judgments.
275:328	The target documents are the 1102 technical abstracts, from which we extracted content words in the title, abstract, and result fields as index terms.
276:328	However, we did not use the keywords field for indexing purposes.
277:328	We used Okapi BM25 (Robertson et al., 1995) as the retrieval model.
278:328	We used the lemmatization methods in Table 2 to extract content words and compared the Mean Average Precision (MAP) of each method using KQ and LQ.
279:328	MAP has commonly been used to evaluate the effectiveness of information retrieval.
280:328	Because there were many queries for which the average precision was zero in all methods, we discarded those queries.
281:328	There were 686 remaining KQs and 273 remaining LQs.
282:328	The average number of relevant documents for each query was 2.1.
283:328	Although this number is small, the number of queries is large.
284:328	Therefore, our evaluation result can be stable, as in evaluations for question answering (Voorhees and Tice, 2000).
285:328	We can derive the following points from Table 2.
286:328	First, to clarify the effectiveness of the lemmatization in information retrieval, we compare no lemmatization with the other methods.
287:328	Any lemmatization method improved the MAP for both KQ and LQ.
288:328	Thus, lemmatization was effective for information retrieval in Mongolian.
289:328	Second, we compare the MAP of our method with those of Sanduijav et al.290:328	(2005) and Khaltar et al.291:328	(2006).
292:328	Our method was more effective than the method of Sanduijav et al.293:328	(2005) for both KQ and LQ.
294:328	However, the difference between Khaltar et al.295:328	(2006) and our method was small for KQ and our method 6  Figure 8: Example of technical abstract.
296:328	Table 2: MAP of lemmatization methods.
297:328	Keyword query List query No lemmatization 0.2312 0.2766 Sanduijav et al.298:328	(2005) 0.2882 0.2834 Khaltar et al.299:328	(2006) 0.3134 0.3127 Our method 0.3149 0.3114 Correct lemmatization 0.3268 0.3187  was less effective than Khaltar et al.(2006) for LQ.
300:328	This is because although we enhanced the lemmatization for verbs, adjectives, numerals, and loanwords, the effects were overshadowed by a large number of queries comprising conventional Mongolian nouns.
301:328	Finally, our method did not outperform the method using the correct lemmatization.
302:328	We used the paired t-test for statistical testing, which investigates whether the difference in performance is meaningful or simply because of chance (Keen, 1992).
303:328	Table 3 shows the results, in which < and << indicate that the difference of two results was significant at the 5% and 1% levels, respectively, and   indicates that the difference of two results was not significant.
304:328	Looking at Table 3, the differences between no lemmatization and any lemmatization method, such as Sanduijav et al.305:328	(2005), Khaltar et al.306:328	(2006), our method, and correct lemmatization, were statistically significant in MAP for KQ.
307:328	However, because the MAP value of no lemmatization was improved for LQ, the differences between no lemmatization and the lemmatization methods were less significant than those for KQ.
308:328	The difference between Sanduijav et al.309:328	(2005) and our method was statistically significant in MAP for both KQ and LQ.
310:328	However, the difference between Khaltar et al.311:328	(2006) and our method was not significant in MAP for both KQ and LQ.
312:328	Although, the difference between our method and correct lemmatization was statistically significant in MAP for KQ, the difference was not significant in MAP for LQ.
313:328	Table 3: t-test result of the differences between lemmatization methods.
314:328	Keyword query List query No lemmatization vs. Correct lemmatization << < No lemmatization vs. Sanduijav et al.315:328	(2005) <<  No lemmatization vs. Khaltar et al.316:328	(2006) << < No lemmatization vs. Our method << < Sanduijav et al.317:328	(2005) vs. Our method << < Khaltar et al.318:328	(2006) vs. Our method   Our method vs. Correct lemmatization <  6 Conclusion In Modern Mongolian, a content word can potentially be inflected when concatenated with suffixes.
319:328	Identifying the original forms of content words is crucial for natural language processing and information retrieval.
320:328	In this paper, we proposed a lemmatization method for Modern Mongolian.
321:328	We enhanced the lemmatization method proposed by Khaltar et al.322:328	(2006).
323:328	We targeted nouns, verbs, adjectives, and numerals.
324:328	We also improved the lemmatization for loanwords.
325:328	We evaluated our lemmatization method experimentally.
326:328	The accuracy of our method was higher than those of existing methods.
327:328	We also applied our lemmatization method to information retrieval and improved the retrieval accuracy.
328:328	Future work includes using a part of speech tagger because the part of speech information is effective for lemmatization.

