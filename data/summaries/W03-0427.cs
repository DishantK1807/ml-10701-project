Alternative to using this data to expand or bootstrap seed lists (Cucerzan and Yarowsky, 1999; Buchholz and Van den Bosch, 2000), we use the unannotated corpus to select useful instances to be added directly to the training set.
W99-0612
Additionally we computed the following features with each wordform, largely following those used by the bestperforming submission of the 2002 shared task (Carreras et al., 2002): • Orthographic features represented as binary features: Begin cap, All caps, Internal cap, Contains digit, Contains digit en alpha, Initial, Lower case, First word • The wordform’s first letter and last three letters (as three separate features) • The direct output of the memory-based lemmatizer (Van den Bosch and Daelemans, 1999), providing PoS tag, morphological features, and spelling change information • PoS tag from a slow but accurate version of the memory-based tagger trained on a portion of the British National Corpus, according to the CLAWS-5 tagset (for English data only) For example, for the English word Indian the following feature representation is made: Indian NNP I-NP 1 0 0 0 0 0 0 0 I i a n AJ0-NN1 N-s I-MISC, where NNP is the provided PoS tag, I-NP the chunk tag; the binary features represent the orthographic features (where in this case only Begin cap is positive); AJO-NN1 is the PoS tag of the BNC-trained-tagger; N-s is the lemmatizer output for noun-singular; the last element, I-MISC, is the annotated class label.
W02-2004
and features The CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003) supplied datasets in two languages, English and German, using four named entity categories: persons, organisations, locations, and “miscellany names”.
W03-0419
Not unlike (Yarowsky, 1995) we use confidence of our classifier on unannotated data to enrich itself; that is, by adding confidently-classified instances to the memory.
P95-1026
