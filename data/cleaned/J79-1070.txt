American Journal of Cornput ational Linguistics TEXT UiiDERSTANDING: A SURVEY ROBERT YOUNG Department of Computer Sciences University of Texas us tin, Texas 78712 Copyright 01978 Microfiche 70 Association for Computational Lingu~stics TABLE OF CONTENTS Introducti~n~..~~-~~~~--~~~~,.~.~...,..~1, The Content ofConnected Discourse,.,, .,, .,, .,, . . 1-1 The Nature of Discourse Content .,, .,,, . ., . .,, . 1,1,1 Barclay, Bransford and FrAnks,,, ., .,, .,,,, . 1-1-2 Frederikserl.
. . a ., ., .,, .,,,,, . . . . . . 1.1.3 Kintscll....., .,...,,, ..,.,.
.,,.
1.1.4 Th~mdyke,,.-~*,,~,.-,,,~.,,....1,2 The Structure of Discourse Content, ., . ., .,, . ., 1-21 Bartlett -mm~,~~~..,,,,~.,,,~~,,~ 1-2.2 Crothers .,, . ..
.,, ..., ., .,, .,, ., .,,, 1.2.3 Grimes and Meyer, .,,,,,,,,, ., .,, ., ., 12.4 Kintsch andvanDijk, .,,,, . a . . . ., ., 1-3 Some Considerations Regarding Memory Experiments .,, . ., 1.4 Discussion and Conclusians ., ., . . . ., . . . . . . . 2, The Form bf Connected Discourse,,, ., ., ', . ., .,,, 2.1 Structural Analysis of Text -,, .,, .,, . . ., ., 2.2 KintschandyanDijk -, --.,,, . I -.
. . -, a 2.3 R~rnelhart~.~~,-,.~.,.~,,~-,--.~.,.,.
2.4 Mandlerand
Johnson -,,,,,, -,, . . . ., * ., . . 2.5 Th~rndyke....,-~.~-,.,--,-,,,,~,..,2.6 TextGramrnar .~,~.,-o,.,,,,.,..em,D,., 2.7 Discussion and Conclusions ., ., .,, . . ., ., .,,, 3, Computatiofial Models of Text Understanding . .,, . ., 3.1 The Necessity of World Knowledge rn,, ., ., . . . *,,, 3.11 Charniak ~a.,..,m...o., 3.1.2 Rieger,.,,,.....-.--e,-.-.--.,3-1-3 Schank,.,.m-....,-,...m,,,.m.,e 3-2 The Organization of World Knowledge, . . ., a,, ., .,, a 3.201 SchankandAbelson,,,,,,, . ., . . . . . ., . 3-202 Phillips 0 0-0 ..
-0 -0 o om? 3.3 Otherwork ..-.I.,,.,,--~-~,-~,.,, 3-4 DiscussionandConclusions, . ., ., ., . -, a.
. . . . . 4, Final Observations,,,, .,, ., .,, ., .,, . ., .,, reference^^^...^^,^,,,,,,,,,^,.,^^,, Page 3 INTRODUCTION The goal of this study is to examine work that has something to offer toward the construction of a computable model of text understandhg, and therefore toward cognitive models in genenil.
The reason for the criterion of computability is that this rather strict requirernevt makes vague gcnernlizatiot~s i~nposisible (or at least more difficult), and forces exact specification of proccsscs being hypothesized(However, this criterion is frequently difficult to apply, and in some instances the author s decision was undoubtedly a subject ivc one.
) It should be clearly poirltcd out that no attempt is made here to deal with the semantics of individual sentences.
A familiarity with recent work in semantic representatian in cognitive psychology, linguistics and artificial intelligence is assumed (see Norman and Rumelhart [75], Schank and Colby [73] and Steinberg and Jakbbovifis [ 71 1 ) Although many problems in representing the meaning of individual sentences remain unsolved, this study focuses an those aspects of mcanlng that are conveyed only by groups of connected sentences texts.
Additionally, only work that attempts to deal with the semantics or understanding of texts, as opposed to statistical or syntactic analysis, is considered.
This focus on text has also led to the omission of studies of non-textual mpmory and of computational systems that understand and solve problems stated in English or carry on dialogue.
This omission is not meant.
to imply that work in these areas has no relevance to text understanding, but the dif fcrent focus and additional constraints of these studies make such implications difficult to isolate.
Page 4 The study is divided into three parts, which occasionally overlap, The first section deals with the conterlt of coni~ccted text that is, what exactly does text commtlnicate.
The work in this section is primarily that of experimental psychologi~ts interested in memory and recallThe second section deals with the _strucrurq of text, apart from its specific content, This work has been done mairlly by cultural antl~ropologists and those interested in the theory of literaturc, but is also being investigated by experimental psychologists.
The third section discusses computational models prop-osed by computational linguists, which include attempts to implement in computer programs some of the processes discussed in the other sectionsEach section is concluded with a dlsc~~ssion of the emerging model of text understanding.
Finally, some directions for needed research are suggested.
It is hoped that this kind of interdisciplinary survey will call attention of workers 112 one area to work in other areas addressing the same problems, This type of communication is valuable in two distinct ways.
When similar conclusions are reached in different disciplines frequently using different methods and with somewhat different goals, these conclusians must be given special credence, On the other hand, it is sometimks the case that one discipline completely overlooks a problem or some aspect of it due to their own interests and biases.
Such omissioi~s need to be brought into sharp focus.
Page S 1.0 THE CONTENT OF CONNECTED DISCOURSE This scctfon will present a brief survey of the recent work of some experimental psychologist,^ concerned with thc process of understanding corlncctcd discourse.
Thc details of their cxperi~n~nts will not be presented, but the types of cxperirneals and general conclusions will be discussed, as well as any madcls proposed by the investigators.
Th~~se results seem to cotlve rge toward a single model, in spite of apparent cont radictions, Psychological work on text understanding is relevant to computational models because humans are still the only good tcxt undcrstnndcrs.
Also, although some aspects of psychological research, such as forgetting, are not currently included in any serious way in computational models, it would appear that such models have a very useful role to play in pointing out where significant details of the process of text understanding are being handled intuitively by the theorist, and have not really been defined in the tlleory, 1.1 The Nature Of Discourse Content The nature (general characteristics and features) of the meaning of connected text will be examined first.
The principle focus of these studies is to compare the understanding of a text to the actual text and attempt to charnctefize the types of differences that are found.
1.1.1 Harrl~ly, Brainsford And Franks I\,~rc*l,ty, Bra~~sford and Franks in n large body of work (Bransford, Rarclay irnd l'rrwks [72], l3nrcl~y [73], Bransford and Franks (731, Branrrforrl atld Ptt*('*n 1,-11 1741 nnd Frn~~ke and Rraneford [74]) argue for the cxletence of II t t c rcy~rcscnt nt ions indepcndcnt of the surface input, and propose active 11 1 t'haiCS 011(~11t it18 on thc input.
They describe eontencea as Information whl(\r is ttscld by tlrc undcrstnnder to construct a descript-ion of a situation.
F n t11oy clnim tl\r~t the itrformnt ion used to construct the selnantic dt~*~-lpt [ot~ is not wholly contained in the sentences, but that an underatander lr is ~rrtsvious knowlcdgc.
to a great extent.
They do not make any definite 01 s r r 11 tlrc Form of the setnant ic representat ions.
Typical cxl~l1~tt~~wt:: pcrformtbd to test thcsc hypotheses consist of recognition or r I 1 QP I-ompoi~nci rtrntt\ncea 1 ikc: I.
Tllr~c turt lcs rastcd hoaidc u floating log, and a fish swam beneath t 111-in.
3. 'l'1rrt.c turtlm r~8t~d on a floating log, and a fish swam beneath ttiem.
Thtplryhi c;\ t sittint ion dc~cribod by the accond sentctlcc is essentially the t 1 I f L rot thrm" is rcplaccd uieh "Jt".
This situation differs from t I),\ t (it-st.rl \red i n t lrc f i rs t sent crlct', howcve r.
Whcn sub jc ct s we re p resented wt r 11 .I hcnt c~~ci\ in whicll tllc p ronor11\ substi rut ion had bcrn made, bhosc who had II(*,II tl tlrc* f l rrt scbtrt cl~ccwere able to make thc distinct ion, whf Ic those who I \\vnrtf I r;ccot\d mnctc no di~tinction.
The explanation offered is that r;\~ll jr'ct rz i~r;r\cl thc2 t spntinl kt.rowlcdgc to crclate situatiot~ dcscriprions, and when two different sentences produce the same description, it is difficult to distinguish them.
Similar investigations used a sequence of sentences, each comparing two objects from a set of five according to some dimension (e.g.
positjon, height, speed, weight).
Subjects who knew that a single situation was being described had a better memory for the situation, but were less able to distinguish sentences they had heard from those implied by the described situation.
Once again, the conclusion is that a non-linguistic representation is created when a meaningful text is understood.
A final group of studies involved descriptive texts that were ambiguous or difficult to comprehend without an appropriate context.
The context might be a picture of the described situation or a meaningful title for the text.
In every case the results indicated the understander attempted to build a description of the whole situation, and when this was very difficult or impossible, comp rehension was low.
(Related studies by Anderson, Reynolds, Schallert and Coetz [76] and Scallert [76] utilize texts, each with two totally different meanings.
Evidence is obtained that one or the other alternative is almost always chosen for the entire text.
The effect of subjects backgrounds on interpretations of these ambiguous texts Is also Gtudied, and a correlation between background and chosen interpretation is claimed.
) The principal conclusion of these studies is that the process of understanding text involves constructing a consistent unified meaning, wlli ch is not simply the set of individual sentenee meanings.
It diffcrs in thht Page 8 additional knowledge and orga11ir.n t i 011 i . Int rod~iccd by tire uilderstander.
1 Frcderikscn
Frederikscn [75p, 7Sb1 contin~~cs this line of thought, treating the undcrqtanding of n disccl\irsc as the.
scmarlt i c knowlcdgs that is acquired in listening to the disco\rrsc.
Thi r; knowlc.~l~~,~~ f o r~cqutrcd by processes that utilize prior knowlcdgc, cont cxt, c t c.
nnd includcs inf armat ion which is inferred as well AS that explicitly prcs~b~~tctl.
Fredcuiksen also argues thaf: the processes involved in undcrstnndinp, a discourse are direqtly related to the process limitntior~s of thc PL'OCCSSO~.
The two processes that he discusses are overgcnera1i;cat ion and infert>~~cr.
Ovc.rgcncirnlizetion is the discarding of detail informat ion resulting in n more p,th1'icr~1 concept.
'tie suggests that overgenera1,ization reduccs the amcwnt of infornlotion to be understood, thus reducing the processing Zond on the UII~C ~-stni\de Inferred information is infannation which is assunlcd to hc.
t even if itis not explicitly present.
This process is clhimcd to reduce the pruccssing load by eliminating the necessity of completely andc rst lrndiny, t\vtary sctlteilce.
FredarAksen performed neutral recall cxpcrimcnts nnd roct~ll cxl~rrin~~nts in wh.lch the context the task assigwcd to the subjc.ct prlor to pli-:;c~itntion of the story was changed,.
His conclusfons arc that.
ovc rgcncr;tliz,~r 1011 rind inferences are incorporated into the semantic reprcsi-ntnticrl~ of tl~cb story as it is ut~derstood, and that the context can inf lu~nccl tl~c nii)ou~~t of infc rcnciny, that is done during Page 9 Frederiksen uses a simple, in£ ormally def incd semantic rep resentation in the above studies.
It consists of set Inclusion, identity, and logical implication relationships that hold among the concepts of the text,.
He indicates the need for& detailed model of the sciwntic representation, and in other work, Frederiksen [75cJ begin's to clef ine such a rep resentational scheme.
He propcses the use of two networks: a semantic network and a logical network.
The semantfc network comains the rep resent at ion of individual propositions while the logical network is composed of relations that hold between propositions that exist in the semantic network.
~rederiksen's system is probably the most elaborate yet proposed using the basic ideas of case grammar represented by semantic networks.
He begins with the fundamental ideas of object and action hierarchies, although his are quite large end contain numerous distinctions.
He proposes a system that distinguishes sixteen verb, cases, and a large numhc r of relations specifying states, quantification locati~n, manner, time, order, proximity, tense and aspect.
His logical network consists of relations drawn from propositional logic plus causality, and he proposes several modal operators.
The complexity of this proposal gives the impression of representational power, but it seems that Frederiksen is still primarily oriented toward the repreqentation of 1 indiyidual propositians.
Although he shows the representation of simple time and causally ordered actions sequences, he has not yet demonstrated the adequacy of his system for text, in gerlerdl.
And, he has utilized a number of elements of quantified modal logic without demonstrating their usefulness for modelling human understanding of d'iscoursc.
His discussions do raise a number of interesting questions about representation, and certainly deserve Page 10 consideration in the development of any set of semantic types and relat~ons.
113 Kintsch Kintsch [74] C reviewed by van Di jk [75bJ ) attempts to set forth a fairly complete theory of langudge understanding.
Kintsch's basic rep resentational unit is the proposition, and he includes discus&ion of the usual difficult problems of definiteness (including generic versus specific distinct ions) of noun phrases, quantification, modality, implicetian and presupposition, location, time and tense.
He proposes a text base which underlies discourses, but his revised and elaborated thought on this is discussed in Section 11.2.,Me, describes a model of discourse processing in which he makes a distinction between episodic and semantic memory, argues that the processing operations must be well defined (he suggests pattern matching and completion, abstraction and generation) and argues that recall is essentially a different pmcess from recognition in that recall requires input organization while recognition does not, Kintsch reports a number of experiments undertaken to test aspects of h;i$ theory.
One conclusion that he reaches is that the semantic representation is partially independent of the actual input sentences.
One kind of experiment performed to test this was the performance of a cammsn task by subjects who had read substantially the same material but in forms ot varying comnlexity.
In other experiments he notes that sentences containing multiple propositions are much less likely to be recalled (completnly) than are single propositibn sentences.
This also supports the idea of an undctlying representaticn.
A Page 11 related conclusion is that the agent of a proposition is the most likely case to be recalled.
However, Kintsch did find that in passive sentences, the subject, rather than the agent, was the most likely to be kecalled.
A final conclusion conce ms the presence of inferred in£ ormation in memory.
Kintsch found that immediate recall showed some difference between implicit and explicit propositions, but that after twenty minutes or more the difference had disappeared and the two were indistinguishable to the subjeet.
An interesting side result was the distinct difference in reading and recognition times for argumentative versus descriptive discourse.
The argumentative discourse required significantly more time in both tasks..
Kintsch also includes reaction time experiments to study proposition retrieval, deterruin-ation of the truth or falsity of general propositions and processing of complex lexical items but these will not be discussed.
1.1.4 Thorndyke
Additional investigationb on the role of inference in understanding text have been carried out by Thorndyke [76].
He uses compound sentences asserting a causal connection which is not familiar or obvious.
For example: The hamburger chain owner was a£ raid that his love fox f rench fries would ruin his marriage.
Sentences like these are imbedded in a meaningful text, and are followed later in the teFt by a continuation sentence which references the previously mentioned relationship.
This continuation sentence might be neutral like Page 12 He decided to see a marriage counselor in order to save his marriage.
or it might encourage one particular eqlanatcrry inference like He decided to join weight watchers in order to save his marri ~ge.
which strongly suggests the inference He is fat from eating Erench fries.
Thorndyke uses recognition tests after the presentation of the story to compare inferences that have been reinforced by a continuation sentence with neutral and inapp rop riate inferences.
He found the reinforced inferences much more likely to be recognized as part of She text than the neutral inferences, while recognition of inappropriate inf erenc~s was very unlikely.
Thorndyke suggests that although this evidence indicates that inferences are made and stored as part of the understanding of a text, a more important implicaOion exrsts.
This is that the role of inferencl ng is to aid in the 4ntegretiot.r of new information into tble larger framewi3tk of the understanding o,f a text when no appropriate understanding could be obtained from only the explicitly stated information.
1.2 The
Structure Of Discourse Content Attempts to characterize the content of text necessarily lead to a structuring of that content.
Simple one-dimensional representations in which propositions are connected only by co-reference or by time or causal ordering Page 13 are adequate for only a restricted class of texts.
The following studier all p ropose some type of multi-level representation of content.
It seems appropriate to begin a discussion of memory structure with Bartlett [32] since he is often referenced as the originator of several cu rrently popular hypotheses.
It should be remembered that Bart1 et t was concerned with memory in general and the phenomena associated with recall, and did, not restrict himself to the study of disc~urse.
His pxinciple conclusions were that memories are not stored in isolated, static units, and that exact recall is very rare.
\In fact, he often found cases of gross distortions in the recall of his subjects.
He suggests that instead, memory is composed of a number of active, organized masses of past reactions and experiences, which he designates schemata, and a small amount of outstanding detailRemembering is seen as a constructive process strongly affected by memories other than the one being retrieved.
His ideas of organization beyond the sentence, of storage of something other than actual input sentences, and of active processes that modify text prior to its reproduction in recall are all currently en joying wjde acceptance.
Page 14 li).2.2 Crothers Crotbhers 1721 is concerned with the recall of short, expository paragraphs containin!:.
material not likely to be familiar to his subjects, He presents results obtained wi tll paragraphs about hebulae.
He proposes the existence of a semantic representation underlying any particular discourse which contains the rncal~lng of the discourge, but, does not reflect the details of the surface form of the teyt.
Thus, a single semantic represent~tion might underlie numerbus actual discourses.
His semantic representation assumes a conceptual taxonomy showing the relationship of each known concept to its superordinate concept (i.e.
the familiar semantic hierarchy), but he does not provide details on this.
He also proposes an additkonal set of hierarchies showing the relationships of the concepts in a particular discourse.
For example, the following: means that a nebula is either seen or it is not seen, where all of the concepts are defined on the conceptual graph.
Crothers does not carefully define his notation, so it is ~ot clear exactly what may or may not occur at a node, Primarily, concepts (words) or connectives are used (e.g.
NEBULA. IS AND, OR, WHY).
Since hc deals only with expository, descriptive material he finds no need to represent actions or time, Crothers performed recall experiments on two different versions of the same material, and arrives at three conclusibns.
First, he concludes that the surface paragraph *s not a Page 15 -fieant factor in recall, thus arguing for a surface-independent semantic repnsentation for the paragraphs.
Hislast two conclusions are negative xejecting hypotheses he had previously suggested.
The first of these is that superordinate nodes in the meaning of the paragraph will be recalled more frequently than subordinate nodes.
The second rejected hypothesis is that iaforaation not directly connected to the most superordinate pode of the paragraph I& lese likely to be recalled than information that is connected.
Since his results do not support either of these hypotheses, Crothers suggests tbat other variablea, such as frequency of concepts, are probably also of irportance.
1.2.3 Grimes
And Meyer Grimes [75] has proposed an extended case grammr supplemented with what he calls rhetorical predicates, which are higher-order predicates that take other propositions as their arguments.
He subdivides rhetorical predicates into three groups: paratactic, hypotactic and neutral, Parataet ic predicates always take arguments of equal weight (i.
e. no argument is subordinate to any other argument).
Hypotactic predicates have one dominant argument, to which the others are,subordinate.
Neutral predicates may be used as either paratactic or hypotactic predicates.
The following is a list of some of the rhetorical predicates proposed by Grimes, and their basic meaning: Paratactic predicrtes ALTERNATIVE o RESPONSE Hypotactic predicates ATTRIBUTION o EQUIVALENT SPECIFIC EXPLANATION ANALOGY Neutral predicates COLLECTION Options, or Question and answer, problem and solution Gives qualities of the dominant proposition Gives restatement of the domiriafit proposition Gives more specific infomation about a general dominant proposition Gives an abstract ekplanation for the specific dominant proposition Gives an analogy to support the dominant proposition List of elements related in some unspecified way Causality, an antecedent and consequent Meyer [75] uses Grimes' rhetorical predicates and most of his casegrammar to create analyses of paragraphs she uses in recall experiments.
For example: Page 17 RE SP ON-S E PROBLEM COLLECTION need to gene rate elect ri c power p t~tect envi ronment rational utilization of natural resources SOLUTION breeder reactors would be the essentials of an analysis of a paragraph which stated that the need to generate electric power while protecting the environment and rationally utilizing natural resources is a problem which breeder reactors solves.
Meyer indicates the hierarchical structure through the use of indentation.
Since the rhetorical predicates in the above example were 911 paratactic, nb indentation was used.
However, the following example: finite reserves of natural resources SPECIFIC COLLECTION coal oil gas shows the subordination of the specific set of resources to the generaJ idea.
eyer's analyses of expository paragraphs using this scheme always follow the author's organizational st rvcture and always result in a purely hierarchical structure like those depicted above Meyer also recognizes class of sentences that can occur in expository paragraphs, but do not contribute any Page 18 content to the passage.
She calls these> signalling because their function is.
to explicktly indicate the structure of the passage.
She notes four types of signallins 1.
~~ecificatibn of the structure (e.
g. "Two options exist'').
2. Prematurely revealed information abstracted from the remainder of the passage (em go "The alternatives are solar energy, nuclear energy, geothermal energy aad laser fusion energy.
") 3.
Summary statements t t 4.
Pointer words (e.g.
unfortunately", "an impdrtant point is") Meyer conducted recall experiments varying the position of certain material in the content hierarchy of passages, and including or omitting certain s ~gnalling in£ omat ion.
Her principle conclusion is that material structurally higher in the content hierarchy is remembered substantially better than identical information placed lower in the hierarchy in another passage.
She also notes that passages with identical structure but totally different content exhibit very similar patterns of recall at the higher leve$s.
However, at the lower levels, the pattern of recall varied, indicating content dependence.
In regard to signalling, she concludes that it has very little' effect at the top level, but seems beneficial at the middle levels.
Page 19 In regard to a theoretical explanation of why the highest ideas are recalled best, Meyer suggests three proposals and points out the weaknesses of each.
First, lower propositions might be subsumed by hieher ones with the passage of time.
Immediate recall experiments shw that the phenomenon occurs even without a time lapse, however.
Secondly, at is possible that all propositions are stored but that retrieval is easier at the higher levels.
She criticizes this proposal because even cued recall experiments were unable to retrieve the lower propositions.
Finally, perhaps only higher ideas are ever stored.
But her results show that the lose of lower level propositions begins immediately, but continues with time at a more rapid rate than for the higher level propositions.
Meyer suggests that probably some combination of these processes is occurring, as well as other processes sensitive to the structure of the passage as a whole.
1.24 Kintsch And Van Dijk Kintsch and van Dl jk (van Di jk [74,7Sa,76], van Di jk and Kintsch [forthcoming] and Kintsch and van Di jk [76]) present a model for the organization of discourse as whole, and a number of (sometimes informal) experiments attempting to validate the model.
Beginning at the lowest level, a discourse representation consists of a set of propositions.
A distinction is made between two different types of representation, callCd text bases, as to whether all implied information is made explicit or whether it is left implicit.
The notion of coherence is introduced, which is the property that distinguishes a discourse from a random set of sentences, Referential Page 20 identity has been auggqsted as a major test of coherence, but it ie not an adequate definition (see discuesion of coherence and Bellert's proposals in Section 3).
Kintsch and van Di jk argue that coherence is more accuratelycaptured by the requirement that each proposition of the text base be connected with one or more preceding propositions.
Propositions are connected if one is a condition for the other, with the strength of the connectfon ranging from posaible to necessary.
Thus, an explicit text base is one containing all of the propositions necessary for coherence, while an implicit text base is one with some of these propositinns deleted.
The deleted propositions are those that can be assumed known or which normally would be inf~rred by the unde rs tande r.
Different types of discourse would have different rules governing the deletion of propositions.
For example, casual conve rgation would allow more deletion thari careful argumentation.
The text base is organized hierarchically under macro-s t ructures, which are higher brde r propositions.
Macro-st ructures may be related to their propositional arguments by a number of macro-rules.
Four of these rules are suggested.
=The first, information reduction, is a rule of generalization which would explain the existence of the macro-structure John is ill, which had as its arguments propositions like John has a feve r.
John has the flu.
The second rule, deletion, would explain the relationship between Peter saw a ball.
and its subordinate propositions Peter saw a ball.
The ball wSas blue.
The third rule, integration, combines a central event with its normal pre-conditions, results and component actions.
Thus John went to Paris.
might have as its arguments John took a cab TO the station.
He bought tickets.
He went to Paris.
The fourth rule, construction, explains the relationship between a complex fact and its component parts.
For example, the macro-structure Peter built a house, might have as its arguments the event sequence Peter laid a foundation.
Peter built walls.
Peter built a roof.
In general, two conditions hold fur all macro-structures.
First, the Page 22 macro-structure must be semant lcally implied by its micro-structure (i.e.
its propositional arguments).
The exact meaning of the term implication is not clearly stated by Kintsch and van Dljk, They sometimes refer to it as entailment and treat it as a formal logical relation, but at other times say that it is not logical in the strict sense.
In any case, it is clear that there are semantic rules or structures that allow creation of macro-~tructures such as those above.
Thc second coqdition is that the sequence of macro-st ructures representing a coherent text base must itself be coherent.
Recalling the definition of koherence, this implies that no macro-structure may delete information contained in its micro-structure which fs a c~ndition for another macro-structure An important consequence of this is that the macro-structures 06.
a ttext, taken by themselves, form a coherent summary of that text.
A final component of a tept representation is the specification of the £om or structure of the discourse, but discussion of this proposal will be postponed until Section 2.
Their investigations are primartly with narrative text, and they call the narrative structure a schema.
Kintsch and van4i jk shggcst that the concept of -narrative st-ructure coabined with the idea of macro-structures leads them to the follawing hypotheses regarding co~np rehension and recall of neriativeFfrs t macro-structures are primarily what is stored when a text is understood.
Recall uses macro-structures as a starting point in retrieval, and summaries directly reflect the nlacro-st ructures.
Secondly, since macro-st ructures are essential to comprehension, they must be constructed at the time of reading.
Page 23 Finally, a narrative schema is necessary for the organization of the text representation.
Kintscll and van Dijk have done a number of summary, recall and other experiments to test these hypotheses.
Most use a 1600 word text from The ------..-Decamcrot~.
In recall experiments, the propositions corresponding to the macro-st ructures were found to be recalled most often, and were very unlikely to disappear in delayed recall (nine days later).
Xn contrast, many other propositioi~s recalled immediately were omitted in the delayed recall, The propositions most likely to be recalled have the following functions: 1, Introduce main characters 2, Give major goals of characters 3.
Describe actions leading to these goals 4.
Describe events occurring to these characters leading to or from their goals while propositions having the following functions are likely to be forgotten: 1, Sctting description 2.
Prepnratoq act ions 3.
Mental actions 4.
Comp oncnt act ions Page 24 5.
Probable consequences of an act ion or an event 6.
Meta-narrative statements by the author Summarizing experiments showed thbt summaries of the story *wet.e very much like delayed recall.
When a summary was written after presentation of each successive part of the story, followed immediately by a complete summary, propositions were included Fn the partial summaries that were omitted in the final summary.
A flnal group of recall experiments compared recall of a 70 word paragraph in isolation, to cued recall of the same paragraph imbedded in ran 85O word text.
Surprisingly, the recalls were almost identical But when the entire text was recalled, the reproduction of the particular paragraph wa8 much smaller and less accurate than in the first two cases.
Their conclusions from these results axe that the recall of small amounts of text is a different process from the recall of a long text, that recall of a long text relies . on the macro-structure of the text as a means of organizing the text, that the micro-st ructure is forgotten much more easily and that summarizing is based on the macro-stcructuxe.
Finally, some experiments were done in which incorrect summaries were presented prior to the presentation of the story.
These were found to have practically no influence on the final understanding o'f the story, and the subjects were unable to accurately recall the incorrect summaries.
Page 25 1.3 Some Conside rati on's Regarding Memory Experiments Before attemptiqg to describe an informal madel based upon these hypotheses and experimental resulta, some general criticisms of memory experiments exp ressed by Spiro [ 751 deserve consideration.
spire's principle argument is that recall consists of active reconstruction processes, rather than passive processes which merely reproduce that which was stored st the time of comprehension.
His general position is thus much like that of Bartlett, and he Observes that almo3t all experimentets since Bartlett have failed to replicate his findings of significant errors in recall.
As a result, psychologists have tended to concent rate on the process of understanding, or construction, and have treated recall as somethihg of a simple retrieval process.
Spiro argues that for reconstructive errors to occur, it is necessary that the input be understood in terms of some preexisting schema.
Any text that results in the creation of a new achema would not be subject to the same kind of effects of previous knowledge.
The interference caused by the pre-existence of schemata is even more pronounced if other uses of the schema are made between the time of comprehension and the time of recall.
Spiro also points out that any experimental subject would be unlikely to integrate material read or heard in an experiment into his general knowledge since its truth and source are unknom.
This coupled with the desire to perform well, could easily result id a considerably modified process of understanding text in experimental settings..
Spiro performed a number of recall experiments which support his hypothesis.
He used text about interpersonal relationships and instructed t31e subjects that the experiment was concerned with their reactions to the incidents described, thus maximally Page 26 involving their pre-existing struerurea in the understanding process.
Spiro found substantial errors in the subjects recal,l~, which he explaine as the effect of interaction wi ti1 prc-cxisting structures for interpersonal relationships.
(Kintsch and van Dijk [75] found similar results using stories from the Bible).
Spiro conclr~des that most text recall experiments have not shown these effects because they did not meet the required conditions, but frequently involved the prcscntation of material that was totally new and which was kept isolated by the subject.
These criticisms not only are relevant to the question of construction versus reconstruction, but also to inferring discourse organf zation f rofn recall experiments, and indicate that one must be very cautious in generalizing from the results of text recall.
experiments due to the many intewctions between the subject's knowledge, the experimental setting, the type and content of the text and the extra-experimental effects (or lack of them) in long term experiments.
1.4 Discussion
And Conclusions A great deal of agreement is seen in the preceding studies.
The idea that the meaning of a text differs from the meaning of its individual sentences, in that prior knovledge is used to infer implicit information during comprehension, is generally accepted.
The idea that this meaning must be well structured, or coherent, is also expressed directly or indirectly by most of the researchers.
However, explicit disagreement exists on both the nature of content structure, and its relationship to recall.
Crothers and Meyer disagree as to whether a neutral struccure reflecting pre-existing Page 27 knowledge is built, or the author's structilre used.
Kintsch and . van Dijk essentially use both approaches since the time ordering in narratjve is author defined (although the concept of time is pre-existent), but the macro-st ructures which hierarchically organize the text are pre-existentMeyer, Kintsch and van Dijk all agree that propositions higher in the structure are more likely to be recalled, but Crorhers evidence did not support this conclusion.
Clearly, this hypothesis, if true, could be confirmed only if it is tested against the appropriate content structure.
Spiro's comments regarding the use (pr laah of use) of pre-existing structures are relevant, In the case of unfamiliar expository material, such as that used by Crothers and Meyer, it seems reasonable to suppose that the author s organization would be used to organize the semantic representation due to the lack (or n,on-use) of any appropriate pre-existing content structures.
Thus Meyer's results suppart the importance of propositional level, and Crothera results do notYlowevev, a familiar structure, like an action sequence, is understpod in the.
same way regardless of presentation setting.
Thus, Kintsch and van Di jk found that the role of a proposition in the pre-existing structure (the macro-structures) was primary in determining its importance, It should be noted that even Meyer found variations in the recall of midclevel propositions that she could not explain by reference to the author's organization.
It is plausible to assume that these variations were caused by individual differences in prior knowledge, resulting in differing content structures.
Page 28 In light of thts, it seems plausible to propose a general model that distinguishes the following component processes bf text understaading (realizing that like almost all distinctions, such as syntax versus semanticq, they are really ~nadequate, but useful, oversimplifications).
First there is the process of comprehensioh of the surface structure which builds a representation that is independent of the surface form of the text, This representat$on contains as much inferred information as is necessary to meet some minimal level of understandability, or coherence.
This representation is organized hierarchically by higher level content st ructures ghich summarize or generalize over a larger amount of detailed in£ onnation.
These higherlevel structures would normally be pre-existing (i.
e. known to the understander) although a text could result in the creation of new structures.
Different types of texts could certainly differ in the complexity of each of these tasks, explaining the variation,in di f f iculty of understanding.
The process(es) explaining forgettfng, and the integration of new information into prior knowledge, operates on this text representat-ion.
This process is poorly understood, and there are no well defined hypotheses about its operation.
It appears to operate primarily on the content structure of a text.
So, for example, Spiro's subjects integrated information from the stories they read into their general expectations about love and courtship, and lost the specifics of the tpxt, even recalling it with radical mods f i,ca t ions This pxocess would explain the almost total loss of detail information with time, as well as the interactions and distortions caused by previous knowledge.
Page 29 Finally, recall is a retrieval process which operates on the current form of the rep resentation.
If that form is relatively unchanged since comprehension, recall may be almost distortion-f ree.
But if significant changes have occurred, recall will be distorted.
As suggested by Kintsch and van Dijk, summary is seen as recall to a controlled depth.
Retrieval accesses the higher-level organization first, and uses these structures to access more detailed information.
As retrieved information is generated as output text, a test of coherence would be made.
If something has been forgotten or changed so that a necessqry explanation or link is missing, the retrieval process would supply a probable piece of information from the general pre-existing structures.
This, along with modifications from integration into prior knowledge, accounts for the reconstructive aspect of recallThis general model does not account for the recall of very specific surface details (e.g.
words and constructions used in the input text) but as suggested by Kintsch's work, it seems best to treat this as a process separate from the general understanding of text.
One other inadequacy of the model is that it specifies complete comprehension of all input propositions, including assignment to an appropriate role in a higher level structure.
Frederiksen suggests that overgeneralization is a loss of detail which reduces the processing load.
The idea that partial processing is sometimes done on input information is also suggested by Bobrow and Norman [75].
They describe such processes as resource-limited.
This kind of processing seems to be indicated by facts such as loss of detail in immediate recall and the subjective impression of partial comprehension in a number of situations (such as reading verg rapidly, reading while partially distracted or reading very complex Page 30 material).
Wowever, while the idea of discarding comp rellended in£ ormation* could be described computationally, selective comprehension ia a process that requites further investigation.
One of the principle contributions of computational investigations with this sort of model will be specification of the processes of comprehen~ion, which can only be done by specifying the nature of pre-existing memory structures.
Meyer's work is an example of the use of undefined basic stmctures.
She criticizes Crothera for requiring two graphs to represent a text one of which ia his Eundame~ital hierarchy of kndwn concepts.
She, instead, simply doesn't define any of her predicates first or higher order, apparently taking them as primitive.
Assuming that one attempted to define even the argument roles f~r the rhetorical predicates, enormous difficulty would be encountered.
Advocates of case systems have always had difficulty defining the exact role of cases, or delimiting the class of entities that could fill a case role.
Consider how much more difficult it would be to define what pairs of things could exist in the RESPONSE oF COVARIANCE relations, or exactly what the charactexistics of these arguments are.
Kintsch and van Di jk attempt to set out much more well defined structures, but even they have little to say about the set of structures that must exist, what information they must contain and how the camprehension algorithms use the text and the structures to build higher-level structures.
The section on computational models will consider algorithmic attempts at text understanding, and should clearly indicate the complexity of these issues.
Page 31 2.0 THE FORM OF CONNECTED DISCOURSE The general model of text understanding suggested in the last section describes the structured content of text representation.
This secaan contains work investigating a similar, yet distinct, type of structure the abstract, underlying form of a text.
(Not everyone would accept this distiaction, but it seems analogous to the distinction between the syntactic structure of sentences and the semantic structure of their underlying meaning).
Much of this work has been done by cultural anthxopolopists or by those interested in literary analysis.
Little of the traditional work ha8 been done with cognitive or computational models in mind, and hence tends to rely on intuitive understanding of the terms.
This less computational work will be presented quite briefly, since the presentation is intended to suggest the kinds of results that have been obtained, rather than the details of these conclusions.
It is necessary to define these ideas in a computational way that can be integrated into the models of text understanding, and some recent work has begun this task.
2.1 Structural
Analysis Of Text Most modern work in the structural analysis of texts has roots in the work of the Russian structuralist, Propp [68].
Propp was concerned with the form of Russian folktales.
and developed a method for describing the similarities he found in a corpus of 100 folktales.
The major structural unit that he developed, he designated a function.
These functions act like meta-actions in that they describe major events or event complexes that were Page 32 repeatedly found in the tales.
For example, Absentation is the function that describes the situation in which one ~f the members of the family absents himself from home, and Trickery is the function which describes a villain's attempt to deceive his victim in order to take possession of him or his belongings.
Propp fourid thirty-one such functions to be adequate to describe the events in the tales that he studied.
Importantly, the ordering of the functions was found to be fixed.
Some functicrns are optional, but if they am present their position is fixed with respect to the other ftlnctions.
All of the functions are defined in terns of actors that participate in the situations they describe.
P.ropp did some analysis of the restrictions on the assignment of various characters to these functional roles.
He notes that the aame character is likely to play a fixed set of roles, which he designates a sphere of action.
These spheres of action include such familiar story roles as hero, villain and false hero.
Finally, Propp notes that a single folktale may be composed of a sequence of basic tales.
He designates the basic tale a I1 move".
Thus, a folktale,may be a one-move or a multi-move tale, with each move conforming to the definition of a tale.
These rules capture the similarity of the folktales which could differ widely in the details of characters, setting, specific actions, etc.
It Is clear that Propp's rules could be expressed formally, and that is what Klein et a1 f?4j did by writing a computer program to generate the function sequences of a number of folktales, using Prupp's definitions.
The ideas of Propp have been refined and generalized by Barthes, Bremond, Greimas and Todorov (their work is not generally available in English but is reviewed in van Di jk [72] and Weinolci (72) ).
Their work has been directed Page 33 toward the redefinition of Propp's functions as propositions, and of actor8 as case relations of these propositions.
They have also attempted to generalize the functions by making them less specific, and to apply them to other forms df texts.
However, Hendricks [72] demonst rates the flexibility of Propp's original functions by using them to analyze part of the Bradbury novel Something Wicked This Way Comes.
Chafe [72, 751 discusses the process of "verbalizatiou", by which he means the translation of non-verbal knowledge into verbal output.
One of the proposed component processes of verbalization is breaking the knowledge into smaller chunks according to patterns, which are called "s~hemata'~.
These schemata are grammar like descriptions of possible verbal sequences.
Thus, he notes that a certain class of stories will always be of the form: PLOT + MORAL Chafe also mentions such schemata as TRICK and VISIT as occurring in the stories he has analyzed.
He explicitly states that, at this time, schematic analysis of a story is done by "imagination abd intuition".
He discusses aspects of the schematic analysis of several simple tales, but these are mostly illustrative rather than complete, in any sense.
Colby [73] analyzes Eskimo folktales, identifying "eidons", which are similar to Propp's functions, and producing a grammar capable of generating some of these tales.
Colby observes that most native speakers are probably not very familiar with story grammars of this type (or the knowledge they represent), since only a few individuals are able to generate such tales Nonetheless, it seems reasonable to assume that the same type of structure can Page 34 be found in more conventional stories Although most work in this area has involved analysis of some form of traditional narrative, Labov and Waletzky [67] present analyses of oral vprsions of personal experiences.
Even in this informal type of narrative, they find five regular components: an orientation, a complication, an evaluation, the resolution and a coda or moral, The last two components are optional.
A totally different type of material is examined by Becker [65] who discusses patterns in expository paragraphs.
All of these analyses rely on the intuitive understanding of the analyzer to grasp the meaning of the structures from infomal descriptions and to find these structures in the text being analyzed.
For this reason, the particular structures that have been suggested are of less interest than is the general result that quite regular high level patterns are found in texts of many types, which may be characterized independently of the specific textual content.
2.2 Kintsch
And Van Dijk In addition to the content macro-structures (discussed in section 1.2.4) Kintsch and van Di jk [75] and van Di jk [75a, 761 discuss even higher level "super-structures", used to organize the content of a text according to the type of the text, which are derived from the work in structural analysis of texts.
They limit their work to narratives, which they define as a specific type of action discourse.
Narrative categories such as Episode Setting, Page 35 Complication, etc.
are superstructures under which are organized either more narrative categories or the content macro-structures of the text.
Van Dijk [75aJ presents a fairly complete example.
It includes a 1600 word text from The Decameron, a propositional analysis of the story, the content macro-st ructures of the story and the narrative categories under which the macro-st NCtures are organized.
The following abbreviated fragment should give an indication of the kind of analysis being proposed.
Lllllllllll----lo---*~~ I I STORY MORAL I ----1---11-1 I I I EPISODE1 I O-WIIUIIII-I-I-LI I 1 SETTING HAPPENING I I,--I--------,-I 1 COMPLICATION RESOLUTION I 1 I Landolfo loses his fortune i (detail propositions about this loss) Some expetiments were done to test the role of the understander's notion of narrative structure.
An Apache myth and three Decameron stories, which were of comparable difficulty at the sentence level, were presented.
They differed in that the Apache myth had an organization not familiar to the subjects.
There was much greater variety in the propositions different people Page 36 used in tllc recall' of the myth than in the other three stories.
Another' experiment comparcd recalls of subjects who had read a normal story to those of subjects who had rend scrambled versions of the same story.
The recalls were indistinguishable by judges.
Both of the~e groups of expeiiments indicate the active role of one's expectations about the fom of a discourse in arganizir~g the representation of that discourse, When this is impossible, as in the Apache myth, recall is less organized and more random.
2.3 Rumelhart
Rumelhart (74, 751 proposes a story grammar that is capable of producing structures similar to those described by Kintsch and van Dijk (section 2.2) His grammar contains rules like the following: 1.
STORY -> SETTING + EPISODE 2.
EPISODE -> EVENT + REACTION 3.
REACTlON -> INTERNAL-RESPONSE + OVERT-RESPONSE Using these rules, he describes the syntactic structure of simple stories.
The following fragment illustrstes the types of structures derived (ignoring the parenthc?sizcd predicates for now): STORY I -I------LILICILICIIIIII I I SETTING (AND) EPISODE (INITIATE) I I -I--------------------I I EVENT (CAUSE) REACTION (MOTIVATE) I I (propositions describing ~argie's I balloon being popped ) I I L-1--------------11--------I I XNTERNAL-RESPONSE OVERT-RESPONSE I I Margie is sad Margie cries Associated with most syntacrtc story rules are semantic rules which are used to generate a corresponding semantic structure for the story, The semantic rules for the syntactic rules given above are: 1, ALLOW (SETTING, EPISODE) 2, INITIATE (EVENT, REACTION) where the semantic predicates are intended to mean what is suggested by their names (e.g.
the SETTING ALLOWS the EPISODE to occur).
The figure given above contains the appropriate semantic predicate, in parentheses, at each node in the syntactic structure.
(Rumelhart uses a completely separate semantic structure,) Page 38 Rumelhart digcusses some elementary summarization rules that operate on the semantic structure of a story.
Some illustrative rules are: 1.
MOTIVATE (thought, response) => response 2.
INITIATE (X, Y) => Y 3.
INITIATE (X, Y) => Y (because 1 when 1 after) X These rules could produce the either of the following summaries (for the EPISODE in the story fragment given above): 1.
Margie cried.
2, Margie cried because her balloon had popped, Rume.lhart8s ideas are intended to be primarily illustrative ("a tentative beginning of a theoryu), and deal with very simplified stories.
They do argue clearly for the notion of both a syntactic and a semantic structure for the representation of a story's meaning.
The syntactic structure allows production of the semantic stucture, which is justified by its usefulness in p roducing summaries.
2.4 Mandler
And Johnson Mandler and Johnson [77] discuss an extended form of ~umelhart's story grammar, which they propose as a basis for text recall studies.
The extended Page 39 grammar allows multiple episodes and does not utilize the additional structure containing the semantic interpretation which Rumelhart suggests.
Mandler and Johnson feel that this second structure is unwieldy and frequently redundaat., Conjunction, time-ordering and causality are included as categories in the grammar.
They observe that restrictions imposed on a story by this type of grammar include allowing only a single protagonist per episode, and prohibiting the realization of higher level nodes in the actual text.
They demonstrate the utility of their grammar on several stories, including "The War of the Ghosts".
They also note that a transformational component remains to be developed which would provide for deletions and reorderings of the ideal story structureThey discuss a set of predictions for recall studies, which are suggested by this definition of story.
structure. These include: 1.
Accuracy will be better as the story is complete and ordered as defined by the ideal structure2, Elaborations will be poorly recalled.
3. Optional nodes' realizations will be less well recalledm 4.
Causality will be better recalled than simple time-ordering.
5. Inversions should be fewer as the story is closer to the ideal structure6.
Omissions and violations of the ideal structure will be reflected by additions and distort ions.
Page 40 Unfortunately, the only experimental work reported is a cowrison of recalls of students from first grade, fourth grade and university levels, on a set of stories which are very near the ideal structure.
Hopefully, this is only the beginning stage of validation of the proposed model* An interesting result from this experinlent is the probability of recall of a proposition as a function of its role For university students, Settings (introduction of characters) and Beginnings (initiation of event sequences) were best remembered* Attempts and Outcomes (which together formed Goal Paths) were next best recalled* Reactions (mental events) and Endings (which were usually either very predictable or omitted in the stories used) were least well recalled.
'These results are in harmony with the results reported by Kintsch and van Dijk (which are discussed in Section 1.2.4). 2.5 Thorndyke Thorndyke [771 attempts to validate the basic notion of underlyihg text form as a necessary part of a text understanding.
Re applies a story structure grammar, which is nearly identical to that proposed by Rumelhart, to two stories, "Ci rcle Island" (analyzed by Frederiksen [75b] ) and "The Old Farmer" (given by Rumelhart [74J), each pf which results in a straightforward hierarchical structure.
The initial rule of the grammar is STORY -> SETTING + THEME t PLOT + RESOLUTION Thorndyke wishes to test the effects of violating this rule.
He does so by performing recall, summary and recognition experiments on four vari-ations of Page 41 the stories.
Thesc are a normal Form of the story, a story with the Theme moved to the end, a story with the Theme omitted and a descriptive version which omits causal and temporal continuity.
using only stative or single action sentences.
In comp rehensibili ty judgements and recall tests, the normal form story was best, the Theme-after form next, with the last two cases more dependent on the particular story.
Recalls of the Theme-after passages alao showed a strong tendency to relocate the Theme to its normal position, near the beginning of the story.
There was also a tendency in the more structured passages for higherlevel propositions to have a higher probability of recall.
Summarizations showed that, of the recalled propositions, the higherlevel ones were much more likely to be included as part of the summary.
Summaries of the descriptive presentations yielded a wider selection of proposi,tions.
In recognition tests, the more structured passages produced more recognition errors when the test proposition was consistent with the story, while the less structured passages produced more accurate recognition.
In attempts to separate the effects of content and structure, Thorndyke tested the four stories obtained by using each of the original plots with two character / object sets.
He found that the Farmer plot was always more comprehensible.
He also found that presentation of a second story using the same plot structure improved later recall of the first story.
Thorndyke concludes that text structures are basic to comprehension, although some are inherently more complex than others.
The distinct ion between structure and content is supported by the positive effect of repeated structure prior to recall.
And finally, the structural position of a Page 42 p roposition has significant in£ hence on both recall end summarization.
2.6 Text
Grammar "Text grammar" is the designation used for another currently active line of investigation into the structure of text.
The fundamental ideas of text grammar are discussed by van Dijk [72], Ihwe [72], Kummer [72], Petofi [72] and Petofi and Rieser [73].
(Unfortunately, a great portion of the work is not available in English).
The principle concern is the formulation of generative descriptions of texts, rather than individual sentences, and is usually approached using a model similar to that of the generative semantics school of linguistics.
Van Dijk suggests the following five components of a text grammar: 1.
Semantic formation rules for the meanings of texts, as a whole.
2. Transformations which operate on this text meaning.
3. Transformations which produce a sequence of sentential semantic rep resentations from the text meaning, 4.
Transformations which produce q sequence of sentential syntactic representations (including lexical i terns) from tho sequence of sentential semantic rep resent at ions.
5. Rules pairing syntactic representations with morphonological representations.
Page 43 nccqonenta would operate in the order given to generate a text* He cqhasires this is only the outline of a theory, and that most of the hard dttdls rerain to be specified.
A significant amount of work has been done on ccqoaents 1 and 2, formall,y defining represenmtions of text.
This has in&ded numems examinations of the use of some extended predicate calculus u a basic representation (primarily addressing the meaning of individual satemces and objects) but has also led to psychologically motivated imestiwtioas (as discussed in Section 1.2.4) and to studies in the general stacture of textual types (as discussed in Section 2.2).
Discussions of capmmnts 3 and 4 have been mostly descriptive, indicating phenomena that rst be accounted fo~ without actually defining them.
Many of these phenomena seem best characterized as operatdons operating on two or more underlying propositionsThese phenomena include anaphora (including pronominalization md article selection), sentence stress, contrast, use of clausal caajtanctions, and verb tense determination.
Of course, certain literary styles ma alter the tt normal" rules, choosing repetition over prooariaanzation omission of causal connect ion, repet ition of certain #.tcnce forms, etc.
Operations which occur on a single proposition include: .amtic transfonations, such as personification and the use of metaphor; wmctic traasformations, such as inversions and other stylistic operations; .rd pbaaological transformations, such as those producing rhyme, alliteration .od meter.
The set of realization rules used to produce a particular text fm its generated underlying structure is assumed to be limited by the type of tart that being generated (e.g.
mystery, narrative, etc.), which is Lpdicated by some underlying abstract type marker.
The selected rules will Page 44 also determine the textual characteristics usually referred to as style or literary merit.
It seems that any complete text understanding model must have a set of rules relating the underlying structure of the text individual and groups of propositions together with global aspects of the text to its surface realization.
Although using a generative model, text grammarians are concerned with identifying and characterizing these relationships, and the results of their investigations should be of definite value in describing text understanding, once their research has reached the point of clearly defining the nature of these surface phenomena in terms of the meaning of text.
2.7 Discussion
And Conclusions The principal hypotheses of these investigators is that there is are very high level structures which organize content structures in the representation \of a text.
This section was begun with the warning that the distinction between these two different types of structures might be difficult to define.
It seems clear that although each proposal that has been considered claims to be concerned with this high level structure, some confusion exists.
The interactions between the abstract structures and the content structures are not characterized at all.
Thus, Kintsch and van Dijk do not describe the restrictions on what type of events may realize a CON.PLICATION category.
Similarly, Rumelhart does not explain how the correct semantic rule would be selected when a choice is possible (e.g.
Two sequential EVENTS may be related by either CAUSE or ALLOW).
Mandler and Johnson, and to some extent Thorndyke, create additional confusion by mixing syntactic categories with categories that would usually be considered semantic.
Thus, conjunct ion time ordcdng and causality may appear in the "syntactic" structure of a story.
Although this difficulty in distinguishing between the two types of structure.
suggest that there is no distinction.
the evidence provided by the exirrtenca of describable claesea of texts seems to indioate that some type of high level structures doexist.
It remains to clearly define the nature of thasa struckures, and to explain their relationship with content structures, without repeating the fallacy of creating a multitude of subcategories (e.g.
wny different EVENT subtypes) which are alleged to be purely syntactic categories.
These structures fit neatly into the model discussed in the conclusion of the content section (section 1.4).
They are the highest level of structure, under which content structures are organized.
This is consistent with the hypothesis of Kintsch and van Dijk (discussed in section 1-2*4) that the structural description of a text is one of the important aspects of its representation.
They specifically suggest that these st mctures organize macro-structures, which provide the content organization of the text.
This ia quite ~0nSiSteht with the results of structural analysis which, as Hendrickc [731 points out, ordinarily uses a summary or synopsis, not the actual text.
as a basis for analysis.
(Recall that macro-structures are proposed ae the basis for summary generatfon).
Of course very simple or very navel texta might not have any structure of this type, scnce no appropriate structure would be pre-exis'tent.
Of course, the problem of learning these structure is as difficult to explain (if not more digficult) as the learning of content struct-uree.
Such acquisition is simply not well understood.
The work of the Page 46 text grammarians suggests the complexity and Alversity of linguistic phenomena that nsay be related to underlying textual representnt:ion.
This work also ruggsats that many aspects of a text, other than its literal meaning and general type, may require explicit representation.
Although a eound computational representatian of atyli~tic aspects of text0 may seem a distant goal, it is still important to retain it as part of the goal of understanding text, and to realize that the richness of human use of language will be only partially accounted for without this component Page 47 3.0 COMPUTATIONAL MODELS OF TEXT UNDERSTANDING This section will survey computational work on the process of text understanding.
Computational models will be seen to be of value in at least two ways.
FLrst, many of the features postulated in other models will be found in these computational models, frequently motivated primarily by computational concerns.
This tends to support these hypotheses.
Secondly, many points passed over very quickly by other workers are seen to offer formidable problems when one attempts to set out a full computational description.
The discovery of inadequate description is essential in develeping sound models.
"Computational" will be taken to mean any model that is actually programmable or that is formally defined.
The work selected for discussion in this section is generally treated in more detail than that in previous sectibns.
The reason for this is that if the complexity of rcomputationally specifying certain representations and processes is to be made clear, it is impossible to treat these matters cursorily.
This, in turn, has necessitated greater selectivity on the part of the author in choosing work that seems to best convey certain types of problems.
Bellert 1701 attempts to define the notion of the coherence of a text, and in doing so suggests some of the same conclusions reached by computational linguists in their text understanding work.
Coherence refers to the property of a set of utterances which make it a connected discourse rather than a random collect ion of utterances.
Referential identity has of ten been suggested as an indication of coherence, but it is clearly insufficient.
For example: Page 48 John drinks a lot of coffee.
John married a blonde.
Both sentences refer to John, but do not form a coherent discourse.
Furthermore, referential identity is unnecessary, Consider the two sentences: There has been a drought.
People are starving, These are coherent without any explicit referential identity.
Bellert defihes a coherent text as one in which the semantic interpretation of each sentence is dependent on the semantic interpretation of the preceding sentences.
The semantic interpretation of a sentence ia defined as the set of conclusions that can be inferred from that sentence.
She suggests that there are two types of conclusions that may be drawn: 1.
those drawn only from knowledge of the language 2.
those drawn from knowledge of the world Both types of conclusions are absolutely necessary in understanding text and may be appropriately drawn when the coherence of the text requires.
She concludes that "an utterance has meaning only in the entire context and through our knowledge of the world".
The rest of the work discussed in this section wd 11 strongly reinforce these conclusions.
The discussion is divided into two sections.
The first contains earlier work that supports the claim that world knowledge is essential to the understanding of text.
The closely related problem of making implicitly conveyed information explicit is also a principle concern.
The second section Page 49 describes later work in whlch the or~anization of world knowledge is recognized as a critical question for text understanding.
3.1 The
Necessity Of World Knowledge 3.1.1 Charniak Charniak's work [72, 74, 761 is probably the first attempt to set out in a well defined fashion the dimension of information processing that must be carried on in the understanding of a story.
The tarn "understanding" is necessarily vague, but Charniak suggests an intuitive definition.
Consider the following story fragment: Fred was goipg to the store.
Today was Jack's birthday and Fred was going to get a present.
It should be clear that if a human had read and understood this fragment that he would be able to answer such questions as 1.
Why is Fred going to the store? 2.
Who is Fred buying the present for? 3.
Why is Fred buying a present?
Charniak claims that a semantic representation of this fragment (i.e.
an understanding of it) should explicitly contain the answers to ordinary questions such as these.
Note the important point that this type of Page 50 understanding could be attained only through the use of general knowledge of the world, along with the explicit statements of the text.
Knowledge required to answer the above questions would include such facts as: 1.
A person having a birthday is likely ta receive presents.
2. Presents are of ten bought at stores.
So Charniak's goal becomes outlibing an answer to the question of hw common sense knowledge may be incorporated into the process of understanding natural language.
A closely related goal is the determination of how much knowledge of this type is required by the basic problems of natural language, such as the resolution of pronominal reference, Charniak breaks the problem of processing natural language into two parts.
The fir~lt part is the translation of natural l'anguage into a farm that is convenient for use in making deductions.
This internal representation is like the understanding that a person would be capable of obtaining without cqntext.
The internal representation is a canonical propositional form, Thus, either of the sentences Jack caught a cold.
Jack came down with a cold, might be represented by the proposition (BECOME-SICK-WITH JACK COLD) which represents the explicit meaning of eithcr of the sentences.
The second Page 51 part of the problem is what Charniak calls Deep Semantic Processing (DSP).
This is the processing that makes explicit the implicit information conveyed by the story.
Charniak elects to examine only DSP.
The function of the system that Charniak proposes is to read a story which has already been translated into internal representation and output a data base of propositions that explicitly represent all of the information conveyed by the story.
In order to do this, the system uses commdn sense knowledge to make implicit information explicitThis knowledge is coded into the system initially, and is not learned or modified, Charniak's goal of understanding stories leads directly to the questions of what kind of implicit information is conveyed, what kinds of common sense knowledge are required to explicate that information, how should this common sense knowledge be represented and when and how is it used.
In answering the question about the types of implicit in£ ormation Charni ak discovered that resolution of pronominal reference frequently requi red common sense knowledge.
Consider Charniak's most discussed example [Charniak, 741 : Today was Jack's birthday.
Penny and Janet went to the store.
They were going to get presents.
Janet decided to get a top.
"Don't do that" Penny said.
"Jack has a top.
He will make you take it bock".
The "it" in the last line is normally understood to refer to the top that Penny would buy, but any purely syntactic procedures would probably select the top that Jack already has, on the basis of recency.
The correct choice of referents seems to be based on the common sense knowledge that if a present is purchased and given, it may be returned or exchanged.
The fact that if a person receives a duplicate present he may not wish to keep it is also Page 52 relevant.
This realization led Charniak to concentrate on the problem of pronominal reference.
Instances of reference are clearly recognizable in the input, and the need to utilize common sense knowledge seems fully present.
Charniak decided to represent common sense knowledge as inferences.
That is, implicit knowledge is made e~plicit by having rules which infer the implicit fact upon presentation of the necessary explicit information.
Por example, if one knows that it is raining, the inference that anyone outside will get wet is valid, The presentation of the sentence John went outside.
is sufficient to trigger the common sense inference John got wet, in a situation in which it is known to be raining.
Charniak's chaice of in£ erences as a represent ation was probably strongly influenced by the availability of MICRO-PLANNER.
(For a discugsion of MICRO-PLANNER, see Winograd [74] and Charniak 1761) Before examining his inferences in more detail, one other question must be considered.
Since an inference is drawn at some particular time, the question of when inferences should be made arises.
Three possible answers to the question are suggested: 1.
Make no inferences until the story is accessed (e.g.
to answer a question about it, summarize a part of it, etc,) Page 53 2.
Make inferences as the story is read, but only those that are necessary to solve some particular problem (e.
g. to solve p roblems of ambiguity or reference) 3.
Make non-problem inferences as the story is read, making explicit aa much information as possible Charniak rejects the first possibility because if it is necessary to make dedu.cti0ns from all previous propositions when accessing some proposition, there is no theoretical difference from making them as the story is read, And he argues thqt there is no way to be sure that you have made the correct and necessary inferences without examining all previous propositions.
An argument against both the first and second possibilities is that the meaning of any proposition may be context-sensitive Consider a story in which Janet wants to trade with Jack for his paints.
The sentence "Those paints make your airplane look funny" Janet said.
should probably be understood as part of a bargaining strategy and not an expression' of Janet's true feelings.
Since no explicit problem is presented by this sentence, no inferencing would be done, and hence the correct understanding would be missed.
So Charniak selects the third possib'ili ty, making inferences whenever pos~ible as the story is read.
Charniak implements inferences essentially as MICRO-PLANNER antecedent theorems.
He distjnguishes two types of common sense inferences which he designates base rout ines and demons.
Base routines rep resent knowledge that Page 54 should always be avatlable and does not need to be triggered by a specific context* For example, knowledge about t rsding should always be available ro that any statement about a trade that has occurred will cause the ibfarencer that the ownership relations have been reversed.
Base routincar are implemented as antecedent theorems matched against each input proporition.
Some inferences are not always appropriate, such as the previous example about getting wet in the rain.
The inference would be incorrect if made in r non-raining situation.
This type of inference, called a demon, is implementad as antecedent theorems that are not always active.
Demons are activated by base routines.
Thua, there would be a base routine about raining which could make immediate inferences and activate demons appropriate to the context, rain.
The previous inference rule uould be a demon of this type.
Charniak refers to the set of propositions which match a base routine's pattern as its topic concept.
He notes that a topic concept may occur either before or after a proposition which would match one of the topic concept'^ demons.
Consider the two sequences: 1, It was raining.
Jack was outside.
2. Jack was outside.
It was raining.
In the first sequence, the rain base routine is matched which activates the outside-implies-wet demon.
The demon matches the next proposition causing the inference that Jack is wet.
Charniak calls this looking fomard, and it is handled correctly by antecedent theorems.
In the second sequence, however, the demon is not activated until after the proposition so the inference is Page 55 mirsed.
This is called looking backward.
Charniak proposes an extenaion to antecedent theorems so that when a demon is activated, the data base is marched for matches.
Then, in the second sequence, the inference would be made when the the demon was activated.
A final observation about demons concerns deactivation.
Obviously, if demons are context dependent, they must be deactivated when the context is no longer preeent.
Thi~ is illustrated by It was raining.
When it quit, Jack went outside.
It should not be inferred that Jack got wet.
Although thia simple example could probably be handled by the rain base routine, in general the problem is quite difficult and Charniak offers no real solutions.
He assumes that deactivating demons after some fixed number of intermediate propositions would be a satisfactory first approximation.
Charniak's model includes two other components.
Be suggests a bookkeeping component to keep the data base updated and tonsistent.
When inferences are made, they will frequently replace other assert ions previously true.
For example if Jack ia inside, then goes outside, bookkeeping would mark the original fact as no longer true, but would keep it for historical purposes (such as answering the question, "Was Jack inside?").
The fourth component is made up of fact finders.
These are necessary as a result of Charniak's decision to make all possible in£ erences which are exp resaed as demons as the story is read.
Clearly, many possible inferences should not be made to avoid clogging the system with a huge number of assertions.
To avoid Page 56 this, these unnecessary inferences will not be realized as dcmons.
Inferences such as the facts that John is in his house, his neighbor!~ood, ctc, if he is in his kitchen fall into this category.
Some situations may require the availability of these fact so The sequence Jack was in the house.
Later he was in the kitchen.
should not be interpreted as a change in location, from the house to the kitchen.
Fact finders are implemented as MICRO-PLANNER consctluent theorems, with patterns which are matched against desired goals.
They thus make certain information available through deduction that is not sufficiently important to infer as soon as possible.
Fact finders are always available, not activated and deactivated like demons.
Charniak's complete model is depicted below.
The model shows that the inferences are treated ;Like additional propositions and are thus subject to DSPo Incoming Apply Apply >Base-------Apply Asgertions------Xla t ching--->Bookkeeping CC Demons Routines I I I I v v ------Inferences (new assertions) 3.1.2 Rieger In some ways Rieger's work [74.
751 seems closely related to Charniak's, but it is not clear that this is completely true.
Ricger's system accepts sentences as input which are already analyzed into their semantic representations, and makes explicit additional information that he claims is Page 57 iqlicitly in the input.
Re designates these additional pieces of information inferences, and agrees with Charniak that they should be made whenever possible Rieger discusses the use of in£ erences in handling problems such as reference, but the bulk of his work is specification of the inferences, themselves, and it is here that the main value of his work is found.
Rieger Sdentlfies sixteen classes of inferences which will be discussed in three brod categories (not Rieger's categories).
31.2 Causal Connection Pirst, there are inferences which are concerned with the causal camectiopg between states and acts (Rieger's treatment resembles the use in robotics wo* (e.8.
Fikes and Nilsson [71] ) of preconditions states that be true for an act to occur and postconditions states that result fror m act occurring).
Given that a state or act is true or has occurred, rbrt inferences may be made? 1.
Causative inferences suggest the likely cause input: Mary has the diamond ring.
inference: Someone must have given or sold the ring to Mary.
2. Enablement inferences suggest states that were necessarily t me input: Mary gave John a book, inference: Mary had the book just before she gave it to John.
3. Resultative inferences suggest results that f ollswed input: Mae gave John the book.
inference: John has the book, 4.
Missing enablement inferences explain why something cannot occur input: Mary couldn't see the horses finish.
inference: Something must be blocking her view.
Page 58 5.
Intervention inferences explain how something may be stopped or p revent ed input: Mary was hicting John ljith a bat.
inference: Taking the bat away from Mary would stop her.
3,1.2.2 Missing Information The second category of in£ e rences concerns supplying common knowladgo about familiar objects or actions that is not in the input.
1, Specification inferences fill in missing parts input: John hit Mary.
inference: John used his hand to hit Mary, 2.
Function inferences supply the normal role of objects input: John got a book.
inference: John will read tbe book.
3. Normatiwe inferences supply information about what f s normally true input: Pete is a, human.
inference: Pete probably has a gall bladder.
4, State duration inferences suggest how long some state will persist input: John started eating at 6:00.
inference: fie is probably still eating at 6:15.
5. Feature inferences connect features of objects with the objects input: Fred wagged his tail.
Xnference: Fred is a non-human animal6.
situation inferences supply other likely aspects of a sftuation input: Mary is going to a masquerade.
inference: Mary is probabky wearing a costume* 3.1.2.3 Motivation Atid Rnwledse The third category of lnfarsoces concerns human mrivationr and knowledge, and their relation to one's actions.
1. Motivation inferences suggest reasons for an actor to do eo~vlthing input: John hit Mary.
infetenee John wanted Mary to be hurt.
2. Actioa-pwdiction infbmncao suggert a poseible courae of actian from a pamon's wants input: John wants some naila.
inaereacer John is likely to go to a hardware store.
3. Enablement-p rediction inferences suggest reasons for s pamon bringing about a certain etate input: Mary put on hot glasses.
inferencd: Mary probably wants to look at emthing.
4, Utterance-intent inferences supply information intended, but not actually ~tated input: Mary couldn't jump the fence.
inference: Mary wanted to jump the fence.
5. Knwledge propagation inferences predict whet else a patson would know if given that he knows certain things input: Bill knew that Mary hit.
John with a bat.
inference: Rill knew that John had been hurt.
One point that ehould be clarified is that the use of the tern inference to designate the implicit information a sentence conveys ie partidlly misleedcng.
What is implicit, and thus misht need to be made explicit, is directly a function of the seaant ic representation.
Consider the previous examp le Mary gave John the book.
Page 60 If the fact that John possesses the book after being given it is an inference, It 1s not clear what meaning the representation of the sentence captures.
Surely, the transfer df possessian ia the meaning of the sentence, not just an implicit addition.
At the other extreme, the example John hit Mary.
surely does qot necessarily mean that John wanted to hurt Mary.
This is clearly conveyed implicitly, if at all.
It is very difficult to evaluate the completeness or adequacy of such a large set of inference types, but Rieger certainly suggests how large the class of information is that can be implicitly conveyed by text and, therefore which might need to be made explicit during the processing of that text.
Any proposed scheme for representing and understanding text should be examined to see how each of these types of information is stored and in what way the information is asserted to be part of the meaning of the input.
3.1.3 Schank
Charniak's model of story comprehension primarily discgsses conne~ttot~a between propositions of a story that alter the sequence of events involved in understanding the ston.
Far example, the understanding of some sentence of a story.
may be correct because a demon had been previously activated, thus allowing the correct interpretation of that sentence.
Charniak dges not say much about explicitly rep reseating the connection between the proposition responsible for activating the demon, and the correctly understood Page 61 proposition.
However, since he mainly investigates reference, obtaining the correct referent is an explicit representation of the understanding.
Clearly, many kinds of connections might exist between propositions of a connected discourse.
Schank ( [73b], Schank and Abelson [77] ) investigates causality as one of the primary discourse connectives.
Schank's proposals are discussed in terms of his Conceptual Dependegcy theory [Schank, 73a], but are largely independent of it.
The term conceptualization is used to refer to either a proposition (using one of the small set of primitive predicates or acts) or to a state (i.e.
an object having some value for some attribute).
Schank notes that the sentence John cried because Mary said he was ugly.
asserts a connection between Mary said John was ugly.
and John cried.
But closer consideration reveals that some of the links in this connection are unspecified, John must have found out that Mary had said it and this knowledge must have made him unhappy, which was manifested in his crying.
In order to be able to recognize instances of missing links and to be able to supply them, Schank develops a classification of types of causality and characterizes their form and meaning.
(It should be clear that here, as in all Conceptual Dependency, there is no simple mapping from English to the Page, 62 underlying representation, ) The first type of causation is a result in which an act may bring about a change of state, For example John went to New York, -RESULT-> John is in New York, The second type of causation is enablement This is the situation in which a change of state brings about the conditions necessary for some act to occur, John has a ring, -ENABLE-> John gave it to Mary.
The third causal type, initiation, is the relationship between any conceptualization and the act bf someone thinking about that thing.
John -INITIATE-> I think about Bill.
(John reminds me of Bill.
) The fourth and final type is reason causation, This is the relationship that holds between the act of deciding to do something and actually doing that thing.
John decided to leave town.
-RFASON-> John left town, Schank also suggests the utility of s non-specific caugal connection, which he designates "lead-t 0".
This would be used to rep resent causally connected events in situations where the specific type of causality or the specific chain of causes is unknown, Page 63 Although Schnnk explores the purely syntactic expansion of English causals into his formal causals, he concludes that the syntactic approach is too limited.
Consider the sentence The hurricane caused my depression.
Treating this as an instance of initiation causation (the hurricane initiated depressed thinking) makes it causal-syntact ically correct, but there ie clearly something missing that explains what led to the depressian.
Schank suggests that other knowledge is used to find the connection, and this suggestion seems to indicate a far more general approach to understanding English expressions of causality than any syntactic approach, Schank suggests that a person would, if possible, find a reasonable connection such as that the hurricane probably blew down the speaker's house which caused him to lose money which caused him to become depressed, In order to accomplish this elaboration a person would have to use a great deal of world knowledge.
Schank proposes that a number of different kinds of knowledge are involved here.
First, there are axioms about the way people feel, such as Al.
Bad results can cause depression.
Associated with an axiom would be a number of more idiosyncratic beliefs, such as IB1.
Less money is a bad result.
Finally, general knowledge of the world would also be necessary.
This would necessarily include facts auch as WK1.
Objects can have monetary value.
WK2. Changes in an object's physical state can cause a change in its worth* A person making the above connections would essentially be engaged in problem solving.
Given the final state, depressioo, he would find en axiom which explains it then find an idiosyncratic belief which would meet the exim's preconditions (bad results), then use world knowledge to establish that a negative change of state could be the real culprit, then notice that a hurricane is able to destroy objects.
The real point of this discussion seems to be that much additional knowledge is required to establish conrlections that people are able to (and do) make when understanding connected sentences.
This is an affirmation of Bellert's hypothesis, and con£ irms Charniak's conclusions, but is reached after work on a different text understanding p roblem, Schank [75b] attempts to use these types of causality as a basis for defining the semantic rep resentation of a paragraph.
lie argues that the collected rep resentat ions of the individual sentences of the paragraph do not form a representation of the paragraph as a whole.
Much addttinnal implicit information could be made explicit, but Schank suggests that undirected explication is not plausiblee He offers a solution to the problem of what information should be made explicit by defining a paragraph representation as a causally connected sequence.
Inferences are limited to those items of information required t~ find the causal connections.
Page 65 The etatea that are usually true when an act occurs are called the neceasaty condition8 of that act.
These states would be ~onnectcd to the act by an enabling causation.
Schank divides necessary conditions into two types: absolutely necessary conditions and reasonable necessary conditions (ANCs and RNCs).
The former must always be true when an act occurs.
RNCs, however, tare normally true, but may be violated without creating an anomalous situation.
For example John was working in his yard.
has a8 an ANC (among others) that John has a yard.
An RNC might be that it was nice weather, but this could be violated* It would only indicate something unusual, and perhaps significant.
Schank illustrates the use of neceeeary conditions to establish causal chains by analyzing several stories.
A brief description of one of these should indicate his methods.
He considers the following paragraph: John began to mow his lawn.
Suddenly his toe started bleeding, ...
When he cleaned off his toe, he discovered that he had stepped in tomato sauce.
Mowing the lawn has as ANCs such things as the existence of John, the lawn, a mower, etc.
and as RNCs that it is good weather and the grass needs mowing.
These conditions would be inferred when the first sentence was processed since they were not explicitly stated.
If the first sentence had been preceded by an explicit statement of either or both of these RNC6, they would have been connected as enabling the mowing.
(There is great difficulty in finding a general scheme which allows inferring of normal necessary conditions, but prohibits inferring unusual ones.
In this case, it secms reasanable to infer Page 66 all of them).
The second sentence presents a more difficult problem.
Same sequence of inferences would have to be made which produces the chain: mowing involves turning blades, which could hit a toe, which could cause it to bleed.
The final sentence of the story illustrates the point about normality considerations.
To explain the tomato sauce, one must infer that John got it an his toe, but this seems like an abnoml inference to make with no other explanation.
However, if the paragraph was preceded by the sentences: John was eating pizza outside on his lawn, He noticed that the grass was very long and and he got out his mower.
Then the final sentence seems much more reasonable.
One would infer that pizza has tomato sauce, and John dropped some on the lawn and later stepped in it, In summary, Schank states the following conditions for the representation of a paragraph: 1.
Each input sentence is represented.
2. These rep resentat ions should be conceptually connected, primarily by causal chains, 3.
The necessary condl tfons for every conceptualization must be explicitly represented, and may originate as input sentences or may be inferred either from previous conceptualizations or because they are normal.
4. A story is the joining of causal chains that crilminote in the "point" of the story.
Other paths are of less interest.
3.2 The
Organization Of World Knowledge A characteristic common to all of the preceding work is that a great deal of world knowledge ia required, but there is no clear organization of this knowledge.
It is clear that any system with large amounts of knowledge represented simply as demons or inference rulea would become bogged dawn searching for relevant knowledge and would quite probably draw incorrect in£ erences because knowledge would be applied in inappropriate contexts (recall Charniak's concern about the deactivation of demons).
Charniak [ 75, 76, 771 himself suggests that more organized knowledge would be superior to the demon approach.
These realizations have led to a number of proposals for the organization of knowledge.
Minsky [75] iatroduced the term "frame" for knowledge structures, but Winograd I751 Bobrow and Norman [75] (using tb term "schema") and Rumelhart and Ortbny (771 discuss closely related ideas.
Recently, Bobrow and Norman 1771 have described a language for knowledge representation (Ec2RL) in which the frame concept plays a central role.
These knowledge structures are intended to organize conventional or encyclopedic kncrwledge, rather than def initionsl features or characteristics, This knowledge is described in terms of roles or slots which participate in the situation.
These are the variables of the frame.
Frames must also have the ability to reference other frames.
A detailed discussion ot the nature of Page 58 frames is inappropriate here, primarily because it is outside the scope of this survey, but in part because many of the computational questions regarding frames are not completely answered.
However, recent computational work haa begun the attempt to incorporate such organization of knowledge into text understanding systems.
3.2.1 Schank
And Abelson 3.2.1 1 Scripts Schank ([75bl, Schank et a1 1751 and Cullingford [751) extends his ideas wfth the addition of large, pre-existing knowledge structures that he calls scripts.
He says that it is necessary to have large amounts of specific knowledge about known situations, since otherwise it is difficult or impossible to recognize the causal relationships between events.
A script is a sequence of actions that provide knowledge about the typical occurrence of some situation.
The following is a partial description of the script for going to a restaurant: Script: Restaurant Track: Coffee shop Roles: Custome r, Waitress, Chef, CasKier Props: Tables, Menu, Food, Check, Money Reason: To get food to eat Entry conditions: Customer (is hungry; has money) Results: Customer (is not hungry; has less money; is pleased) Cashier (has more money) Scene 1: Entering Go to restaurant Find an ernp ty table Page 69 Decide where to sit Go to table Sit down [MAINCON] Scene 2r Ordering Receive menu Read menu Decide what to eat Tell Waitress what is wanted [MAINCON] Scene 3: Eating @em Scepe 4: Exiting 1 *.
The scenes are the main episodes of the event'and each is defined in terms of a sequence of specific actions.
Schank suggests that scripts would need to be divided at the top level into different tracks whicih distinguish the sequences for different types of restaurants.
Th& usefulness of a script is seen by considering the sequence Johnwent to a restaurant.
He ordered a hamburger from the waitress.
He paid and left.
Many details of this sequence have been omitted and connections between the actions would be impossible to establish wf thout knowledge of what constitutes going to a restaurant.
Furthermore, the definite reference to the waitress is meaningful only because all participants in a script are automatically introduced by any reference to that script.
The script also contains the conditions that must be true for successful execution of the script, as well as the results of successful execution.
Each scene has one act that is considered the essential act of that part of the script.
These acts are Page 70 called the MAIN CONceptualizations of a scene.
Scripts represent the knowledge about conventional situatiow that any reader would be assumed to know.
But the separate question of how to represent a text which contains script usages must be answered.
If the rcy resentat ion of the restaurant story above wee merely an elaborated causal chain containing many events in£ erred from the restaurant script, the unifying description that these events together constitute going to a restaurant worrld be lost.
Schank. proposes that that the elaborated causal chain is only one level of the story's representation the Conceptual Dependency (CD) level.
There is also a second level of representation the Knowledge Structure (KS) level.
At the KS level the above story would have a representation like: ScriptsRestaurant Custome rcJohn Food=Hambu rge r Additionally, the script representation would be linked to each of the events at the CD level which was part of that script instance.
Schank suggests that the causal chain at the CD level should contain all the events explicitly mentioned plus the MAINCONS of any scene that is mentioned.
If any event is encountered which is not anderstandable in terms of the current script, the event will be represented at the CD level, but will also be placed on a Wierd list.
For example Schank discusses the processing of a story in which John has his pocket picked while riding a subway.
Later, he has no money with which to pay the bill after eating at a restaurantThe first sequence of events is understood in terms of the subway script, but the pocket picking event is placed on the Wierd list.
When applying the restaurant Gcript, the &aability to pay is encountered in the text and is inexplicable from the rotm~rmt script.
The script applier asks the monitoring program to look for cprrs~al occurrences that could result in John having no money.
The dtor finds the pocket picking event, and returns the informati6n to the scrlpt qplier which uses it as the required explanation.
Of course, the problems in general are much more difficult than this riqle example indicates.
For example, an unusual event within a script could imterrupt the script's normal continuation.
Obstacles, such as not being able to get wbat you want at a restaurant, may cause altering or abandoning the restaurant script.
Distractions, sueh as a robbery in a testaurant may lead to suspension of the restaurant script for a sub-story, or to its abandonment, Furthermore, simultaneous,, independent scripts are possible.
The situation of eating in a dining car involves both the train script and the restaurant script.
Finally, the activation and termination of scripts is a very complex p roblem.
For example, consider the sequence: John went to a restaurant, After eating lobster, he bought a watch.
Does this describe a restaurant event followed by a purchasing event, or the more unusual case of buying a watch in a restaurant?
Either is possible, and the story in which this s,equence is found would determine the most probable interpretation.
Page 72 3.2.1 2 Goals And Plans Schank and Abelson (75, 771 (also see Meehan 1761 and Wilensky [76]) have recently suggested that a11 connected event sequences are not apprcrp riatoly represented by scrlpts.
Consider the sequence: Johh wanted to become kingHe went to get some arsenic.
It seems that treating the poisoning-the-king situation as so conventioarl that a script for it exists is unrealistic, The solution lies in realixlag that while scripts handle well known situations, mechanisms rmst exist which are able to handle novel situations using general knowledge.
"Plans" are suggested as the appropriate mechanism.
A plan is a general course of actaon intended to realize some goal(s), A possible hierarchy of high-level goals is shown in Figure 3-l(a).
Motivated actions are always associated with the satisfaction of some high-level goalFrequently, more specific sub-goals exist which are motivated by a high-level goal.
For example, someone may want to go to the train statton (instrumental goal) so he can go to New York (a 1 I specified goal) so he can enjoy pleasure" (high-level goal).
The purpose of clearly defining a goal hierarchy is to enable understanding of situations in which an actor faces goal conflict and elects $0 pursue the highest goal (e.gw "preserve health" rather than "en joy pleasure"), Page 73 Achieve Sex Rest a.
Goal Hierarchy ------------------------------GET (named plan) USE (named plan) INVOKETHINE (planbox) ASK (planbox) D-KNOW (D-goal) C BARGAIN-OBJECT (planbox) 'TELEPHONE-BOOK (script) b.
Associated Knowledge Figure 3-1 Page 74 But general knowledge about Row goals can be achieved must also be available.
The "D-goal" is proposed as the fundamental unit of organization for suhh information.
A D-goal ie a point pf access to planning information for the realization of some goal.
Foe example, D-KNOW is the D-goal for the goal of knowing something, D-CQNT for the goal of physically controZling something, and D-PROX for the goal of being in proximity to something.
The D-goals' associated knowledge is an ordered list of "planboxee", each of which ptovides detail infoption on one method for achieving the goal.
The ordering prwides thb sequence in which the methods are likely to be considered.
For example, D-KNOW has an ASK planbox (as a highly likely method) which specifies the actual act of asking the appropriate question, the intended result (fee.
getting the answer), and the pre-conditions necessary to successfujlly ask.
Some of the pre-conditions are: communication is possi"b1e; the persbn being asked knows the answer; the person being asked is disposed to answer the question, When a planbbx is ext rernely specific, it becomes a script.
Using the telephone book is a method of acquiring certain kinds of knowledge that is so conventional that it is a script, Certain 'recurring sequences of B-goals are called "named plans".
The named plan, USE(x), stands for: D-KNOW(the location of \x) D-PROX (x) D-CONT (x) perform p_reparatlons and do action appropriate to x Figure 3-l(b) sham the relationship of D-goals, planboxes, scripts and named plans to each other and to the goal hierarchy.
The representation of the plans of actors in a text would be at the KS level (with scripts).
The D-goals would be explicitly represented and would be connected to actual acts at the CD level which (attempted to) implement the plan For example, the sentence: John tried to find out who ate the candy.
would be repreaentsd arro: Ks Level CD Level plan D-KNOW(John,?.ate the candy)---implementati-on--> DO I Failure <--------------------result-----------I That is, the plan of trying to know who ate the candy was implemented BS some unspecified act (DO) which failed to achieve the plan's goal.
Acts (at the CD level) which meet pre-conditions of planboxes would be linked to the D-goal they enable.
Additional information is suggested as being appropriate and necessary for the KS level.
This includes, for each character, his goals, the current status of each goal, strategies which could be used to achieve each goal and facts (true information as opposed to actual occurrences) relevant to goal understanding.
This in£ onnation i.s maintained on "Coal Fate Graphs", which also contain associations between characters and any "Themes" (large goal complexes such as BECOMING-RICH) in which he is participating.
Page 76 Schapk and Abeleon appear to be committed to the development of a very complex system for the organization of knarledga, and the representation of such knowledge when it bccurs in stories.
It should be apparent that they rare attempting to model goal related human knowledge and actions, since such knowledge and actions are common in stories.
Since this knowledge pn be required to underatand particular stories it 14 not clear at what point (if any) one ceases t o study text unde rs t anding and begins modelling personality . 3.2.2 Phillips Phillips*[75a,75b] presents probably the most comprehensive computational model of text, in that he is concerned with the representation of all types of knowledge and textual relatiorships.
This breadth is informative, but necessqrily results in a lack of depth in some areas.
He presents a representational scheme which he uses for the vari~us required types of knowledge, which include world knowledge, li%gulstir knowledge and the knowledge conveyed by the text.
Phillips w.orld knowledge, "the encyclopedia", consists of both the static data structures and the dynamic processes which operate upon these structures.
The static data structure is a fairly conventional but very well defined, semantic network (closely related to the suggestions of Hays [73] ) which use nodes for entities and events, and arcs for the relationships between nodes.
The set of hierarchical relationships between entities (the taxonomicstructure) is called' the paradigmatic structure.
The syntagmat ic structure is the see of relationships between events and the event particip ants (case or argument relationships).
Page 77 Phillip8 incroaucea a Modality node attached to every event which is always used to refer to the event and its participants as a whole.
(In many systems this is represented only indirectly).
The discourse relationships of cauoali ty, time ordering and spatial relations are rep resented by arcs between the Modality nodes of events.
Phillips defines another type of relationahip which he designates the Metalingual organization of knowledge.
This allows him to represent a concept as a unit, and yet have a complete subnetwork elqborating the meaning of that concept.
For example, the unitary concept "poison" would have as its composition "someone ingesting something which causes that person to be ill".
This rep resentational technique provides the fundamental capabilities of frames or scripts expansion of something into its parts, and knowledge about those parts.
The processes that operate on the semantic network are divided into two classes, The first, path-t racing, involves only following pathts through the paradigmatic structure.
This type of process would be used to find that "Mary gobbled caviar" was a more specific instance of "People eat food".
The second type of process is pattern-matching, and involves constraints between the components, For example, determining that "John killed himselft'is suicide while "John killed ~111" is not, requires a coreference constraint in the definition of suicide.
Phillips observes that path-tracing is computationally equivalent to finite state automata, while pattern-matching is necessarily more complex.
Page 78 Discourse, or text, is represented using the same representational scheme, but may be characterized by properties not applicable to discontinuous knawlddge.
The first of these properties is connectedness.
Two propositions are paradigmatically connected if each has an argument such that the two arguments have a common paradigmatic superordinate node, or if the first is the immediate superordinate of the the second.
For example, "lions" and 'It igers" both have "animal" as superordinate, so the following are connected paradigmatically: Lions are indigenous co Africa.
Tigers have stripes.
And the two propositions: Man is a hunting animal.
Modern man hunts for sport.
are also connected since the second is a more specific proposition ("modern man" is immediately subordinate to ''man") than the first.
Two propositions are discursively connected when discursive relations (em g.
causality ) exist between them.
The second attribute of discourse is thematicity.
A theme is a prescribed pattern (represented by a Metalingual construction) to which a discourse may conform.
A theme may be ~'contentive" like "accidental drowning" t l which is represented as existing when a person is caused to be in the water and is unable to act, the combination of which causes him to drown".
This is contentive siqce it specifies both the parts (events) of the theme and their interrelationships.
A 'lnon-contentive" theme is one that provides only a structural pattern or the interrelationships between some unspecified entities "clue" is defined to be "an unobserved act that causes the existence of something".
The exact events and results are unspecified.
A discourse is thematic if its propoaitiona can be matched to a theme or hierarchy of themes (i.e.
a theme which matches several propositions in a discourse, such as "accidental drowning", may in turn be a part of another theme, such as "tragedyft).
Phillipa then defines a coherent discourse as one which is both connected (each proposition is connected to at least one other proposition) and thematic.
Phillips points out that although there is no simple one-to-one mapping between his representations and the constructs used in text analyses like those of Grimes (section 1.2.3) and Propp (section 1.
.2), his structures do provide for the representation of most of the proposed relationships, Some of Grimes rhetorical predicates, such as Attribution, Specific and Collection, correspond to paradigmatic connectedness, while others, such as Covariance, correspond to discursive copnectedness.
Still other rhetorical predicates, such as Respqnse and Analogy and Propp's patterns of functions in a move (as well as the functions, themselves) correspond to thematic structure.
Hence, Phillips claIms to have presented computational interpretations for the principle text phenomena.
As a test of his proposed model of text, Phillips presents a model of text understanding embodied in a computer program.
His program inputs a discourse in the form of parse trees of the sentences and builds the knowledge representation of the discourse.
An interesting use of the Metalingual const mcti on is its function in replacing non-cognitive surface words by the Page 80 appropriate cognitive structure.
For example, the preposition "through" is replaced by the cognitive st tucture for "in-contact-wLth" in a sentence like: The Abominable Snwman walked through the snow.
"fhus, the same representational mechanism is used for such divergent types of knowledge as syntact ically-related information and thematic structures.
Once the parse tree has been converted into the knowledge representation of the proposition, the understanding process involves two major steps.
The first fs begun by matching the input proposition (IP) against the encyclopedia to find a corresponding generalized proposition (GP).
Thus, the IP The boat contains Horatio Smith.
is matched to the GP Things contain peaple.
Notice that Phillips uses GPs to capture the same knowledge that features and selectional restrictions capture in many other systems.
So the correct interpretation of a GP is that it is a plausible proposition, not a necessary truth.
Once the IP has been matched to a GP, three additional checks are made starting from the matched GP.
One is to determine if any of the terms of the proposition have Metalingual definitions.
If so, new knowledge correspondin& to the definition is added to the discourse representation.
For example, if the discourse included that "John was poisoned" the elaborated information that "John ingested something that caused him to be ill" would be added.
A second check is to see if the matched GP is discursively connected to any Page 81 other GPs.
If so, new k~lowledge is added to the discourse which corresponds to the related GP and the d$.ecursive connection.
If the rnatche'd GP were "People are injured" and it had a causal link to "People are unable to act", then the IP "John was injured" would result in the addition oE "John was unable to act" with a causal link from the original IP, It is by using these interrelationships of GPs that Phillips accomplishes inference.
The third test is to determine if the matched GP is a part of any 'contentive theme.
(The encyclopedia's GPs have pointers to all contentive themes which contain them).
If so the theme is matched against the discourse as a whole to see if all components are present and all constraints satisfied, If they are, the theme is addtid to the discourse rep resent ation.
"Accidental drowning1' would be added to a discourse representation which had matched the GPs and connections I' ("People contactwater" and "~eople cannot act") cause ("People drown") " with a coreference constraint on "people", After processing Ips and adding the related structure to the discourse representation, the second major step is testing the discourse for coherence.
This involve two tests.
The first: determines if the discourse is connected.
Then, thematicity, is tested by checking to see if a single undominated theme has been found.
It should be noted that non-contenrive themes, since they have no component actions, and thus cannot be pointed to by GPs, must be tested for in a serial fashion.
If the discourse passes both tests, then it is judged coherent.
Page 82 To illustrate the process, a very brief description of the understanding of a atory will be given.
Given the story: (IP1) A boat contains Horatio Smith.
(IP2) The boat overturns.
(IP3) Horatio Smith drowns, the following events would occur: 1, IP1 and IP2 would be matched to GPs which are parts of a complex event that has as a causal result, when instantiated, the added propositions: (AP1) Horatio Smith is in the water.
(caused jointly by IPl and IP2) (AP2) Horatio Smith is injured, (caused jointly by IP1 and IP2) 2.
The GP corresponding to AP2 results in the addition of: (AP3) Horatio Smith cannot act(caused by AP2) 3.
The GPs corresponding to AP1 and AP3 are part of a complex event that has the causal result "People drownt', But this is the GP which matches IP3.
So a causal link is added from AP1 and AP3 to IP3.
4. The discourse is tested for connectedness, and passes the test.
5. The discourse matches the "accidental drowning" theme, which is the only theme it matches, so it is thematic, and thus coherent, Page 83 Phillips principle goal was a computational model of text* His model of text understanding was intended to demonst rate that the proposed representations could actually be built from an input text.
His text model does seem to present a reasonable representation for a number of text phenomena, several of which have not been considered by other computational models, Paradigmatic connectedness and some types of thematic structure seem particularly important.
Iiowever, several object ions must be raised to his model of text underslanding.
The first objection is that his testa for coherence are applied only to the complete discourse, and are not formulated in such a way as to suggest strategies to avoid incorrect interpretation of propositions pnd relationships, If this were done, the sequential processing of input p topositions would continually test for coherence, and incoherence would immediately suggest that some misinterpretation might have been made, or some inference omitted.
A second objection i& that the definitions of connectedness and thematici ty are inadequate.
A common superordinate node is simply not sufficient to explain paradigmatic connectedness.
The example of sentences about lions and tigers would be connected only in some context that explained why these statements were being made (e, g.
"All* I know about lions and tigers is . . .").
Thematicity is defined without respect to how much of the discourse the theme accounts for.
A theme cannot account for all of the propositions in a discourse unless the discourse is very trivial, and yet if a theme matched only the first three propositionS of a one hundred proposition discourse, it could hardly be called the theme of the discourse.
Finally, a number of aspects of the understanding processes are not convincingly shown to be computationally practical.
The problem of avoiding incorrect additions to Page 84 the discourse representation from a rich encyclopedia is ignored.
Each exawle has exactly the right infamation available.
Also, it ie mot clear that: the use of generalized propositions would work when there am ~averrrl .levels of generalization possible.
For example, the g perelized proposition "People contact water" has associated knowledge, but the higher level proposition "People contact thingstt would also need to be present with its associated knowledge.
And finally, the methods of accessing themes by pointers to all occurrences of generalized propositions or by serial search both seem comput at ionally unaccep table.
Propositions like "~eople go" would result in, a combinatoric explosion of possibilities.
For all of these reasons, Phillips' understanding model is useful more in suggesting the kinds of problems involved, than in providing an actual model of text understanding.
3.3 Other
Work Space limitations and the narrowly defined scope of this sunrey have combined to eliminate certain interesting work from detailed consideration.
Wilks [75, 76, 771 has described a text understanding (and translation) system which uses a meaning representation called Preference Semantics.
The system normally opercltes in a basic mode, dealing with sentences individually, but is capable of entering an extended mode when a reference problem occurs.
An example is "it" in John drank the whiskey from the glass and it felt warm in hi3 stoomch.
Several processes are involved in the attempt to determine the correct referent.
"Ext ractionl' is the addition of logically true propositions, only Page 85 wtlicSt in the text, but available from the meanings of the unite.
Thus, both "ltm was in John's stomach, The vhiskey is in a part of Johnroipld ath be extracted.
These two, pqopositions can be identified, thus resolving "it" as "the whiskey".
*I Bwever, had the above example been . and it was good".
the original pruposifions, as vell as relevant extractions, would then be subjected to m ccuncm sense inference rules" such as 1.
<1 drink 2) -> (1 judges 2) 2, (1 is good) <-> (2 wants 1) rt3ich would be used to find the shortest inference chain identifying the referent.
For the example, when "the whiskey'' is tested, the established (John drhk whiskey) -I-> (John judges whiskey) -subset-> (John wants whiskey) <-2(Whiskey is good) where %ant" events are a subset of "judge" events.
A recent addition to Wilks' system is large knowledge structures (like frames) called "pseudo-texts".
They are suggested as containing other knavledge which might be required in solving reference problems (although they have other important use in understanding individual words).
Page 86 At the levei of text, Wilks differs from Rieger and Charniak primarily in his insistence upun entering an extended made only when a problem requires it.
Reference p toblems are the only problems he discusses as triggering thia mode His use of pseudo-text B in establishing textual connections is still too briefly described to critically evaluate.
Rieger ~([75b, 75c, 76a, 76b1, Rieger and Grinberg [771) has described a complex system for the organized representation of cause and effect knwledge, .a& plans utilizing this knowledge.
A set of decision trees ("selection 11 networks") are postulated which.
given a goal, select certain common sense algorithms" capable of realizing that goal.
Rieger asserts that the same knowledge st-ructures used for planning, should be used for understanding the intentional acts of others, To do this in text, he requires knwledge which allows prediction of goals and actions likely to be made in response to the occurrence of some event or state, A subsequent sentence is tested to see if it confirms any prediction by being a step in an expected action or in an algorithm to achieve an expected goal, This testing requires that all algorithms be indexed by step.
Thus, it must b~ possible to find all occurrences of (X GOT0 Y) in some set of algorithms, A confirmation is used to morecoslfidently predict the course of action being followed, Clearly, Rieger is dealing with the same problems as Schank and Abelson (section 3,2.1.2), but ha.s not yet clearly demonstrated the utility or practicality of his approach to this aspect of text understanding.
Page 87 Hobbs 176, 771 has discussed analyses of various texts based on his own system of semantics.
Possible fntersentential relations are described by pattern action pairs which, when matched by input sentences modify the text representation tree apprap riately.
These relations include causality, time ordering, paraphrase, examp 1.2, contrast, parallel const.ruction and vlolated expectation.
These relationship8 indicate that Hobbs does not make a distinction between content and form (author imposed) relations.
Thc complexity of Hobbs' system (in the large number of rules and their interactions) makes evaluation difficult until he has completed his computer implementation.
Other work that should be mentioned includes Schmidt ([761, Schmidt and Sridharan [77]), who discusses the problem of recognitioh of plans from actions, as well as Novak [76] and Bobrow, et a1 [77] who both use frame like knowledge structures in specialized language understandi rag systems.
3.4 Discussion
And Conclusions What have the discrissed computational models added to the previously described model of text understanding?
Charniak, Riegex and Wilks have demonstrated how-it is possible to infer information only implicit in a text.
Schank has especially examined the richness and complexity of causal connections, which are often implicit.
This capability raises many additional questions, however, including when, and how many, inferences should be made.
Whi le Cllarniak and Rieger suggest making many infe rences whencvv r possible, Wilks argues for making them only as required.
Neither approach has yet been Page 88 applied to sufficient ly 1 argc trxt s and knwledge bases to convincingly demonstrate its validity.
Pre-existcnt kn~wledgr structures have been suggested by Schaak and Philips to avoid the extrc:mc8ly difficult problem of making matiy-step inference chains to establish inlpli ci t con~~cct ions.
Although use of these structures has demonstrated their ability to meet this goal, as well as their usefulness in generation of summaries and paraphrases, problems have appeared.
Complex knowledge structures and real texts present many difficult.kea la matching an input proyosltlon with an element in the structure.
When the match is imperfect, orwhen many choices are (computationally) posgible, it is very difficult to perform the required matching correctly, In an attempt to deal with this difficulty (as well as others), and to recognize the fact that novel situations are also unde rstandable, Schank, Abelson, Rieger and Schmidt have been concerned with recognizing the motivations and intentions of actors.
This aspect of understanding is clearly important, for the stated rt3asons, but the approaches described have almost certainly been too simplif icd for the understanding,of actual texts.
It Thus *the requi rcmcnt that an understar~ding of a text contains as much inferred inforniat~o~~ as h~!c~ss~iry to mqet some minimal level of ...
coherence" (section 1.4) is wen to bc a computationally difficult problem.
The orgat-lizing cor~tt~i~t SI 111, tt~rl~~; arc i~sc~ful in dealing with this problem, but create new problems.
Knocll c-dgc) nrltl rr~p resr~nt at ion of plans and intentions is introduced tn hnndalr* sor.\c3 of thcsr problems.
Tt should be noted that the previously dj sc~~r;sotl nrotlc~l tl~~ not spcrl f i c,illy distinguished this type of Page 89 knowledge.
Coherence has been defined in tllcse computational models as connectivity established by inferrencing, matching a knowledge structure or being a step in a plan.
The exact distinctions between these three types of knowledge are still blurred, and it remains to be demonstrated that these distinctions are appropriate and adequate.
Only Phillips and Hobbs have addressed representing the form of texts, bqt these suggestions have not beeh computationally adequate, nor has there been any clear distinction between form and content structures.
A better defined notion of text form should certainly play a role in the ongoing determinatiion of textual coherence that occurs during comp rehension in the text understanding model.
With regard to forgetting, little has been added, although higherlevel knowledge structures could be used to summarile their more detailed components (which could then be "forgotted').
Schank has also suggested that the least connected propositions in a representation are those most likely to be forgotten.
However, these ideas have not been seriously investigated.
In general, computational models understand texts perfectly (if at all), and do not contain any imperfect ret rieval processes.
Permanent learning and integration with prior knowledge has not been investigated in these systems, nor has any explanation been offered for occasional recall of surface text, -These systems generally do not keep the surface text at all, but could easily do sv.
However, it would result in perfect recall of this information.
Page 90 The principal value of computational models has been the demonstration of the great difficulty in actually specifying comprehension algorithms.
It is all too easy, when explaining hw a particular result is achieved, to ignore the problem of avoiding incorrect paths.
The fact that higher-level content st ructures are computationally uaeful, and also psychologically indicated, is an important confirmation.
The investigations of more, actual texts by systems having more knowledge available (not just the relevant knowledge) is an important step in validating the models being proposed.
Page 91 4.0 FINAL OBSERVATIONS The following points are accepted by most researchers concerned with text understanding: 1.
Much information implicit in texts is explicit in an understanding of that text.
2. There is some type of hier; rchical or multi-level organization(s) of the understanding of a text.
3. Organized, pre-exi5tent knowledge is requlred to achieve this type of understanding.
The study of knowledge represcntation,and the nature of knowledge structures is a primary concern.
Many computational problems have not been resolved.
A particularly important question for text understanding concerns the necessity of redundantly copying general knowledge for specific instantiations.
Fahlman (773 discusses this problem in detail, and offers some ways in which to avoid unnecessary redundancy.
The relationship of the content and the form of texts needs additional clarification.
Similarly, the relationship of general content structures to representations for plans and intentions needs study to see how distinct these are.
And of course, the large areas of learning and forgetting are importaht, but missing, components of a text understanding model.
In addition to these open problems, attempts to apply the combined insights of the diverse research perspectives to actual texts is a necessary step in evaluating the adequacy of current text understanding models.
Page 92 REFERENCES Anderson, R.
C., Reynolds, R.
E., Schallert, D.
L. and Goetz, E.
T. 1976.
Frameworks for Comprehending Discourse.
Technical report no.
12. Laboratory for Cognitive Studies in Education, University of Illinois at U rbana-Champ aign.
Anderson R.
C., Spiro, R.
J. and Montague, W.
E. (eds).
1977 (in press).
3chooling -and the Acquisition of Knowledge.
Hillsdale, N.J.: Lawrence Erlbaum Associatesl.
Barclay, J.
R. 1973.
The Role of Compreh'ension in Remembering Sentences.
Cpgnitive Psychology, 4, pp.
2291254. Rartlett F.
C. 1932.
Remembering: A Study in Experimental and Social Psychology, London: Cambridge University Press.
Becber, A.
L. 1965.
A Tagmemic Approach to Paragraph Analysis.
College Composition and Communication, XVI, 5, pp.
237-242. Bellert, I.
1970. On a Condition of the Coherence of Text.
Semiotics, 11, 4, pp.
335-363. Bobrow, D.
G, and Collins, A.
(eds). 1975, Represent ation and Understanding.
New York: Academic Press.
Bobxow, D.
G., Kaplan, R.
M., Kay, Ma, Norman, D.
A@, Thompson.
H. and Winograd, To .1977.
GU~; A Frame-Driven Dialogue System.
Artificial I.ntellip,ence, 8, 2, pp.
155-173. Bobrow, D.
G. and Norman, D.
A. 1975, Some Principles of Memory Schemata.
in Bobrow and Collins [75].
Bobrow, D.
G. and Winograd, T.
1977. An Overview of KRL, A mwledge Representatioxl Language.
_Cognitive Science, 1, 1, pp.
3-46, Bransford, J.
D,, Barclay, J.
R. and Franks, J.
J, 1972.
Sentence Memory: A Constructive versus Interpretive Approach.
Cognitive Psycho'Logy, 3, pp.
193-207. Eransford, Jo D, and Franks, J.
J. 1972, The Ahstraction of Linguistic Ideas: A Review.
_Cognition, . 1, 2, pp.
211-249. Bransford, J.
T). and McCarrel1, No S.
1974. A Sketch of a Cognitive Approach to Comprehension.
in Weimer, W.
B. and Palermo, D.
S, (cds.
), -Co~ition and -the Symbolic Processes.
Hillsdale. N.
J. : Lawrence Erlbaum Associates.
Chafe W.
1972. First Technical Report, Contrastive Linguistics Project.
Department of Linguistics, University of California st Berkeley.
Chafe, Wi 1975.
Some Thoughts on Schemata.
in Schank .,.
and Nash-Webber [75] Charniak, E.
1972. Towards a Model of children's Story Comprehension.
A1 TR-266, Artificial Intelligence Laboratory, Massachusetts Institute of Technology.
Charniak, E.
1974. "~e will make you take it back": A Study in the Pragmatics of Language.
Technical report.
Instituto per gli Studi Semantic1 e Cognitivi, Castagnola, Switzerland.
Charniak, E.
1975. Organization and Inference in a Frame-like System of Common Sense Knowledge.
in Schank an'd Nash-Webber [75].
Charniak, E.
1976. Inference and Know1etlge.a in Charniak and Wilks [76] Charniak, E.
1977. Ms.
Maloprop, A Language Compreh.-nsion Program.
in Proceedings -of the Fifth International Joint Conference on ~rtiflcial Intelligence.
Charniak, E.
and Wilks, Ye (eds.
). 1976.
Computational Semantics.
Amsterdam; North Holland.
Colby, B.
N. 1973.
A Partial Grammar for Eskimo Folktales.
American Anthropologist, 73, pp.
645-662, Crothers, E.
J. 1972.
Memory Structure and the Recall of Discourse.
in Freedle, R.O. and Carrol, JOB.
(eds.). Languafie Comprehension -and the Acquisition of Knowledge.
New York: John Wiley and sons.
Cullingford, R.
1975. An Approach to the Organizatidn of Mundane World Knowledge: The Generation and Management of Scripts.
in Proceedings of the 13th Annual Meetinp, of the Association for Computational ~in~uisticx van Di jk, T.
A. 1972.
Some Aspects -of Text Grammars.
The Hague: Mouton.
van Di jk, T.
A. 1974.
Models of Macro-stmctures.
uapublished mimeograph.
van Dijk, T.
A. 1975a.
Recalling and Summarizing Complex Discourse.
unpublished mimeograph.
van Di jk, T.
A. 1975b.
Discourse Meaning and Memory.
to appear in Journd of Reading Behavior.
van Dijk, T, A.
1976. Macro-structures and Cognition.
contributed to the Twelfth Annual Carnegie Symposium on Cognition.
van Dijk, To A.
and Kintsch, W.
1977 (in press).
Cognitive Psychology and Discourse: Recalling and Summarizing Stories.
in Drcssler, W.U.
(ed). Trends in Text-Linguistics-.
New York: de Gruyter.
Fahlman, S.
1977. A System for Kepresenti~ and -Usinp; kq1,-World Know1edp;q.
unpublished PhD dissertation.
Massachtisetts Institute of Technology.
Fikes, Re Eo and Nilsson, N.
Jo 1971.
STRIPS: A New Approach to the Application of Theorem Proving to Problem Solving.
Artificial Intelligence, 2, pp.
189-208. Franks, J.
J. and Bransford, J.
D. 1974.
Meaning for Syntactic Form as a Function of Semantic Context.
Journal of Psychology, 103, 5, pp.
1037-1039. Frederiksen, C.
Ho 1975a" Acquisition of Semantic Information from Discourse: Effects of Repeated Exposures.
Journal of Verbal Learning and Verbal Behavior, 14, pp.
158-169. Frederiksen, C.
H. 1975b.
Ef fekt s of Context-induced Processing Operations on Semantic Information Acquired from Discourse.
_Cognitive Psychology, I, pp.
139-166. Frederiksen, C.
He 1975~.
Representing Logical and Semantic Structure of Knowledge Acquired from Discourse.
Co~nitive Psychology, 7, PYe 371-458.
Grimes, J.
1975. The Thread -of Discourse.
The Hague: Mouton.
Hays, D.
Go 1973.
Types of Pvrocesses on Cognitive Networks.
in Proceedings of the 1973 International Conference on Computati~nal Linguistics.
Hendricks, W.
0. 1972.
A Structural Study of Nsrrztio-: Sample ~xfalyses.
Poetics, 3, pp.
100-123. Hendricks, W.
0. 1973.
Methodology of Structural Narrative Analysis.
Serniotica, VII, 2 pp.
161-184. Hobbs, Jo 1976.
A Computational Approach to Discourse Analysis.
Research report 76-2, Department of Computer Science, City College, CUNY.
Hobbs, J.
1977. Coherence and Interpretation in English Texts.
in Proceedings of -the Fifth International Joint -Conference on Artificial Int,elligencc.
Ihwe, J.
1972. On the Foundations of a Genera1 Theory of Narrative Structure.
Poetics, 3, pp.
5-14?. Kintsch, W.
1974. -Representation -of Meanini --in Memo Huntsdale, New Jersey: Lawrence Erlbtium.
Kintsch, W.
and van Dijk, T.
A. 1975.
Recalling and Summarizing Stories.
unpublished English translation of "Comment on se' Rappelle et on Re'sume des Histoires".
Langage, 40, pp.
98-116. Klein, S.
1974. Modelling Propp and Levi-Strauss in a Meta-Symbolic Simulation System.
Technical report no.
226, Computer Science Department, Unive~sity of Wisconsin.
Kummer, W.
1972. Outlines of a Model for a Grammar of Discourse.
Poetics, 3, pp.
29-55. Labov, W.
and Waletzky, J.
1967. Narrative Analysis: Oral Versions of Personal Experiences.
in Helm, 3.
(ed. ).
Essays on the Verbal and Visual Arts.
Seattle: University of Washington Press* Handler, J.
M. and Johnson, N.
S. 1977.
Remembrance of Things Parsed: Story Structure and Recall.
Cognitive Psychology, 9, 1, pp.
111-151. Meehan, J.
1976. The Metanovel: -Writing Stories by Computer.
unpublished PhD dissertation, Yale University.
Meyer, B.
J. 1975.
-.The Organization of Prose and Its Effects on Recall, Amsterdam: North Holland.
Minsky, M.
1975. A Framework for Representing Knowledge, in Winston, P.
(ed. ) The Psycholo_sy of Computer Vision, New York: McGraw-Hill.
Norman, D.
A. and Rumelhart, D.
E. 1975Explorations Cognition.
San Francisco: Freeman.
Novak, G.
1976. Computer Understanding of Physics Problems Stated in Natural Language.
American -Journal of Computational Lin~uistics, Microfiche 53.
Petof i, J.
1972. Syntactico-Semantic Okganization of Text Structures.
Poetics, 3, pp.
56-99. Petofi, J.
and Rieser,H.(eds).
1973, Studies -in Text Grammar.
Dordrecht: "Reidel.
Phillips, B.
1975a. Topic Analysis.
unpublished PhD dissertation, State University of New York at Buffalo.
Phillips, B.
1975b. Judging the Coherence of Discourse.
in Pro~eedin~s of the 13th Annual Mectin~ of the Association for Computational Ljnguistics.
Prop~, V.
1968. Morphologycf -theFolktale.
Austin: University of Texas Press.
Rieger, C.
J. 1974.
Conccj tual Memory.
u~~published PhD dissertation, Stanford University.
Rieger, C.
J. 1975a.
Conceptual Memory.
in Schank [75a].
Rieger, C.
J. 197Sb.
Conceptual Overlays: A Mechanism for the Interpretation of Sentence Meaning in Context* in Advance Papers -of the Fourth -International Joint conference -on Artificial Intelligence.
Rieger, C.
J1975~.
The Commonsense Algorithm as a Basis for Computer Models of Human Memory, Inference, Belief and Contextual Language Comprehension.
in Schank and Nash-Webber [75] . Rieger, C.
Jo 1976a.
An Organization of Knowledge for Problem Solving and Language Comp rehension.
Artificial Intelligence 7, 2, pp.
89-127. Rieger, C.
Jo 1976b.
Spontaneous Computation in Cognitive Models.
Technical report no.
459, Department of ~omputer~cience University of Maryland.
Rieger, C.
J. and Grinberg, Me 1977.
The Declarative Representation and P rocedu raf.
Sinlulation a£ Causality in Physical Mechanisms.
in Proceedings-of the Fifth International Joint Conference on Artificial Intelligence, Rumelhart, D.
Em 1974.
Notes on a Schema for Stories.
unpublished manuscript.
Rumelhart. Dm Eo 1975.
Notes on a Schema for StorPes.
in Bobrow and Collins [75].
Rumelhart, D.
Eo and Ortony, A.
1977. The Representation of Knowledge in Memory.
in Anderson, Spiro and Montague [77].
Scallert, Do L.
1976. Improving Memory for Pmse: The Relationship Between Depth of Processing and Context.
Journal of Verbal Learning and Verbal Behavior, 15, 6, pp, 621-632.
Schank R.
1973a. Identification of Conceptualizations Underlying Natural Language.
in Schank and Colby [73].
Schank, Ro 1973b.
Causality and Reasoning.
Technical report no.
1, Instituto per gli Studi Semantici e Cognitivi, Castagnola, Switzerland* Schank, R.
d ) 1975a.
Conceptual Information -ProcessingAmsterdam: North Holland.
Schank, R.
1975b. The Structure of Episodes in Memory.
in Bohrow and Collins [75] . Schank, Ro and Abelson, R, 1975.
Scripts, Plans and Knowledge.
in Advance Papers of the Fourth International --Joint ---Conference on Artificial Intellip,ence.
Schank, R.
and Abclson, R.
1977. Scripts.
Plans, Goals and Understanding.
Hillsdale N1 J.
: 1,awrence' Erlbaum Associates.
Schank, R.
and CoJ by, K.
M. (eds.
) 1973.
Computer Models of Thou~ht Langua~e.
San Francisco: Freeman.
Schank, R.
and ?ash-IJebber, B.
(eds). 1975.
TheoreLical Issues in Natural Lan~ua~e Froc~essin~.
Associ~tion for Cchputational Linguistics.
Schank, Re and the Yale A.
I. Project.
1975. SAM: A Story Understander.
Research reportno43, Department; of Computer Science, Yale 'University.
Schmidt, C.
F, 1976.
Understanding Human Action: Recognizing the Plans and Motives of Other Persons.
in Carrol, J.
and Payne, J.
(eds.). Co~nition 2nd Social Behavior.
Hillsdale, N.
J, : Lawrence Erlbaum Associates.
Schmidt C.
F. and Sridharan, N.
S. 1977, Plan Recognition Using a Hypothesize and Test Paradigm: An Example.
ifi Proceedings of the Fifth International_ -Joint -Conference on Artificial: Intelligence.
Spiro, R.
J. 1975.
Inferential Reconstruction in Memory for Connected Discourse.
Technical report no.
2, Laboratory for Cognitive Studies in Education, Ul~iversi ty of Illinois at Urbana-Champaign.
(to appear 5n Anderson, Spiro and Nontague 1771 ), Steinberg, D.
Dm and Jakobovits, L.
A. (eds.).
1971. Semantics* Cambridge: University Press.
Thorndyke, P.
W. 1976.
The Role of Inference in Discourse Comprehension.
Journal of Verbal Learning -and,, Verbal Behavior, 15, 4, pp.
437-446, Thorndyke, P.
W. 1977.
Cognitive Structures In Comprehension and Memory of Narrative Discourse.
Copnitive PsyChology, 9, 1, pp, 77-110.
Weinold, G.
1972. On Deriving Models of Narrative Analysis f xom Models a£ Discourse Analysis.
Poetics, 3, pp 15-28, Wilensky, R.
1976, Using Plans to Understand Natural Language.
in Proceedings --of the --Annual --ACM Conference.
Wilks, Y.
1975. Semantics for Natural Language Inference, Arttficial Intelligence, 6, 1, pp.
53-74. Wilks, Y.
1976. Parsing English.
in Charniak and Wilks [76].
Wilks, Y.
1977. Knowledge Structures and Language Boundaties.
in Proceedings -of the Fifth Internatienal Joint Conference 3 Artificial Intelligc11ce.
Winograd, T.
1974. Five Lectures 23 Artificial Intelligence.
A1 Memo no.
246, Stanford Universi-ty.
Winograd, T.
1975. Frame Representations and the Declarative / Procedural Controversy.
in Bobrow and Collins [75] .

