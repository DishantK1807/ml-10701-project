<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>J Carletta</author>
<author>S Ashby</author>
<author>S Bourban</author>
<author>M Flynn</author>
<author>M Guillemot</author>
<author>T Hain</author>
<author>J Kadlec</author>
<author>V Karaiskos</author>
<author>W Kraaij</author>
<author>M Kronenthal</author>
<author>G Lathoud</author>
<author>M Lincoln</author>
<author>A Lisowska</author>
<author>I McCowan</author>
<author>W Post</author>
<author>D Reidsma</author>
<author>P Wellner</author>
</authors>
<title>The AMI meeting corpus</title>
<date>2005</date>
<booktitle>In Proceedings of the Measuring Behavior Symposium on “Annotating and Measuring Meeting Behavior</booktitle>
<contexts>
<context>hall we sh well 〈POS-SUBJ SOURCE=SPEAKER TARGET=MEETING we’ll stick to kind of your area for now〉. The meetings that we developed this annotation scheme for are scenario meetings from the AMI corpus (Carletta et al., 2005a). For these meetings, participants play the role of a designteamandholdaseriesofmeetinginaninstrumented meeting room. Occasionally, participants make a subjective comment related to some aspect of t</context>
<context>e + Positive Objective 0.58 83 Negative Subjective + Negative Objective 0.68 93 Subjective Question 0.56 95 Table 4: Interannotator agreement for the AMIDA subjectivity annotations XML Toolkit (NXT) (Carletta et al., 2005b). Although annotations are marked on the meeting transcript, annotators were instructed to listen to the meeting audio and to view the meeting videos as part of the annotation process. When performi</context>
</contexts>
<marker>Carletta, Ashby, Bourban, Flynn, Guillemot, Hain, Kadlec, Karaiskos, Kraaij, Kronenthal, Lathoud, Lincoln, Lisowska, McCowan, Post, Reidsma, Wellner, 2005</marker>
<rawString>J. Carletta, S. Ashby, S. Bourban, M. Flynn, M. Guillemot, T. Hain, J. Kadlec, V. Karaiskos, W. Kraaij, M. Kronenthal, G. Lathoud, M. Lincoln, A. Lisowska, I. McCowan, W. Post, D. Reidsma, and P. Wellner. 2005a. The AMI meeting corpus. In Proceedings of the Measuring Behavior Symposium on “Annotating and Measuring Meeting Behavior”.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carletta</author>
<author>S Evert</author>
<author>U Heid</author>
<author>J Kilgour</author>
</authors>
<date>2005</date>
<journal>The NITE XML Toolkit: Data Model and Query Language. Language Resources and Evaluation Journal</journal>
<volume>39</volume>
<contexts>
<context>hall we sh well 〈POS-SUBJ SOURCE=SPEAKER TARGET=MEETING we’ll stick to kind of your area for now〉. The meetings that we developed this annotation scheme for are scenario meetings from the AMI corpus (Carletta et al., 2005a). For these meetings, participants play the role of a designteamandholdaseriesofmeetinginaninstrumented meeting room. Occasionally, participants make a subjective comment related to some aspect of t</context>
<context>e + Positive Objective 0.58 83 Negative Subjective + Negative Objective 0.68 93 Subjective Question 0.56 95 Table 4: Interannotator agreement for the AMIDA subjectivity annotations XML Toolkit (NXT) (Carletta et al., 2005b). Although annotations are marked on the meeting transcript, annotators were instructed to listen to the meeting audio and to view the meeting videos as part of the annotation process. When performi</context>
</contexts>
<marker>Carletta, Evert, Heid, Kilgour, 2005</marker>
<rawString>J. Carletta, S. Evert, U. Heid, and J. Kilgour. 2005b. The NITE XML Toolkit: Data Model and Query Language. Language Resources and Evaluation Journal, 39(4):313–334.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Cohen</author>
</authors>
<title>A coefficient of agreement for nominal scales</title>
<date>1960</date>
<booktitle>Educational and Psychological Measurement, 20:37–46. Dustin</booktitle>
<contexts>
<context>t segment to contain more than one subjectivity annotation, we measured agreement for each annotation type separately. Table 4 shows the agreement for key annotation types measured in terms of Kappa (Cohen, 1960) and percent agreement. Agreement for whether a segment contains a subjective utterance is 0.56 kappa. The annotators have similar agreement for positive subjective utterances and subjective question</context>
</contexts>
<marker>Cohen, 1960</marker>
<rawString>J. Cohen. 1960. A coefficient of agreement for nominal scales. Educational and Psychological Measurement, 20:37–46. Dustin Hillard, Mari Ostendorf, and Elizabeth Shriberg.</rawString>
</citation>
<citation valid="true">
<title>Detection of agreement vs. disagreement in meetings: Training with unlabeled data</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL</booktitle>
<contexts>
<context>ve content in multiparty conversations, including the annotation of meeting data. However, none of annotation schemes capture the level of detail provided by our annotation scheme. Wrede and Shriberg (2003) have worked on recognizing meeting hotspots, which are places in meetings in which the participants are highly involved in the discussion. For that work, they developed a scheme for annotating spurts</context>
</contexts>
<marker>2003</marker>
<rawString>2003. Detection of agreement vs. disagreement in meetings: Training with unlabeled data. In Proceedings of HLT-NAACL 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pei-Yun Hsueh</author>
<author>Johanna Moore</author>
</authors>
<title>Automatic topic segmentation and lablelling in multiparty dialogue</title>
<date>2006</date>
<booktitle>In Proceedings of IEEE/ACM Workshop on Spoken Language Technology</booktitle>
<contexts>
<context>nd summarise meeting content — information about what happens and what is discussed in meetings. Some meeting content is primarily objective, for example, information about what topics are discussed (Hsueh and Moore, 2006) and who is assigned to work on a given task (Purver et al., 2006). However, another type of meeting content that is important is the subjective content of meetings, that is, the opinions and sentime</context>
</contexts>
<marker>Hsueh, Moore, 2006</marker>
<rawString>Pei-Yun Hsueh and Johanna Moore. 2006. Automatic topic segmentation and lablelling in multiparty dialogue. In Proceedings of IEEE/ACM Workshop on Spoken Language Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pei-Yun Hsueh</author>
<author>Johanna Moore</author>
</authors>
<title>What decisions have you made: Automatic decision detection in conversational speech</title>
<date>2007</date>
<booktitle>In Proceedings of NAACL-HLT</booktitle>
<contexts>
<context>discussion in the meeting. Recognizing subjective content is important because, intuitively, it seems that such information would help with existing meeting-browser tasks, such as decision detection (Hsueh and Moore, 2007). But subjective content in and of itself is also interesting and important to extract and summarise. We would like to know not only what a particular decision was but who supported or opposed the de</context>
</contexts>
<marker>Hsueh, Moore, 2007</marker>
<rawString>Pei-Yun Hsueh and Johanna Moore. 2007. What decisions have you made: Automatic decision detection in conversational speech. In Proceedings of NAACL-HLT 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Laskowski</author>
<author>S Burger</author>
</authors>
<title>Annotation and analysis of emotionally relevant behavior in the ISL meeting corpus</title>
<date>2006</date>
<booktitle>In Proceedings of LREC</booktitle>
<marker>Laskowski, Burger, 2006</marker>
<rawString>K. Laskowski and S. Burger. 2006. Annotation and analysis of emotionally relevant behavior in the ISL meeting corpus. In Proceedings of LREC 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Purver</author>
<author>P Ehlen</author>
<author>J Niekrasz</author>
</authors>
<title>Detecting action items in multi-party meetings: Annotation and initial experiments</title>
<date>2006</date>
<booktitle>In Proceedings of MLMI</booktitle>
<contexts>
<context>at is discussed in meetings. Some meeting content is primarily objective, for example, information about what topics are discussed (Hsueh and Moore, 2006) and who is assigned to work on a given task (Purver et al., 2006). However, another type of meeting content that is important is the subjective content of meetings, that is, the opinions and sentiments that the participants express during discussion in the meeting</context>
</contexts>
<marker>Purver, Ehlen, Niekrasz, 2006</marker>
<rawString>M. Purver, P. Ehlen, and J. Niekrasz. 2006. Detecting action items in multi-party meetings: Annotation and initial experiments. In Proceedings of MLMI 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Randolph Quirk</author>
<author>Sidney Greenbaum</author>
<author>Geoffry Leech</author>
<author>Jan Svartvik</author>
</authors>
<title>A Comprehensive Grammar of the English Language</title>
<date>1985</date>
<publisher>Longman</publisher>
<location>New York. Dennis</location>
<contexts>
<context>gs in the annotated corpus. The paper ends with a discussion of related work and conclusions. 2. Overview of MPQA Annotation Scheme TheMPQAAnnotationSchemeiscenteredaroundtheconcept of private state (Quirk et al., 1985). A private state is any internal mental or emotional state, including opinions, beliefs, sentiments, emotions, evaluations, uncertainties, and speculations, among others. In its most basic represent</context>
</contexts>
<marker>Quirk, Greenbaum, Leech, Svartvik, 1985</marker>
<rawString>Randolph Quirk, Sidney Greenbaum, Geoffry Leech, and Jan Svartvik. 1985. A Comprehensive Grammar of the English Language. Longman, New York. Dennis Reidsma, Dirk Heylen, and Roeland Ordelman.</rawString>
</citation>
<citation valid="true">
<title>Annotating emotion in meetings</title>
<date>2006</date>
<booktitle>In Proceedings of LREC</booktitle>
<contexts>
<context>we feel that our two annotation schemes are complementary. Their annotations capture subjective expressions, which is a level of detail that we do not aim for in our annotations. Laskowski and Burger (2006) propose an annotation scheme for marking emotionally relevant behavior in meetings. Althoughtheirannotationschemeisfairlyrichin the types of subjective content captured, as with the other schemes abo</context>
</contexts>
<marker>2006</marker>
<rawString>2006. Annotating emotion in meetings. In Proceedings of LREC 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Swapna Somasundaran</author>
<author>Josef Ruppenhofer</author>
<author>Janyce Wiebe</author>
</authors>
<title>Detecting arguing and sentiment in meetings</title>
<date>2007</date>
<booktitle>In Proceedings of SIGdial</booktitle>
<marker>Somasundaran, Ruppenhofer, Wiebe, 2007</marker>
<rawString>Swapna Somasundaran, Josef Ruppenhofer, and Janyce Wiebe. 2007. Detecting arguing and sentiment in meetings. In Proceedings of SIGdial 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Theresa Wilson</author>
<author>Claire Cardie</author>
</authors>
<title>Annotating expressions of opinions and emotions in language</title>
<date>2005</date>
<booktitle>Language Resources and Evaluation (formerly Computers and the Humanities</booktitle>
<pages>39--2</pages>
<contexts>
<context>ngs, specifically the opinions and sentiments that participants express as part of their discussion. The scheme adapts concepts from the Multi-perspective Question Answering (MPQA) Annotation Scheme (Wiebe et al., 2005; Wilson, 2008), an annotation scheme for marking opinions and attributions in the news. The adaptations reflect the differences in multiparty conversation as compared to text, as well as the overall </context>
<context>n this paper, we present an annotation scheme for marking subjective content in meetings. The annotation scheme adapts concepts from the Multi-perspective Question Answering (MPQA) Annotation Scheme (Wiebe et al., 2005; Wilson, 2008), an annotation scheme developed for marking opinions and attributions in news articles. The adaptations reflect the differences in multiparty conversation as comparedtotext, aswellasou</context>
<context>ion, a private state can be described based on its functional components: the state of an experiencer holding an attitude optionally toward a target (Wiebe, 1994). The annotation scheme presented in (Wiebe et al., 2005) is a detailed, expression-level representation of private states and attributions that adapts and expands the more basic functional-component representation. The annotations in the scheme are repres</context>
<context>n all the annotation frames is the nested source attribute, which represents a key part of the MPQA annotation scheme. We describe thisattributebelow; detailsontheotherframeattributescan be found in (Wiebe et al., 2005). As previously mentioned, the source of a private state is the experiencer of the private state, and the source of a speech event is its speaker or writer. However, in textual discourse such as the </context>
</contexts>
<marker>Wiebe, Wilson, Cardie, 2005</marker>
<rawString>Janyce Wiebe, Theresa Wilson, and Claire Cardie. 2005. Annotating expressions of opinions and emotions in language. Language Resources and Evaluation (formerly Computers and the Humanities), 39(2/3):164–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
</authors>
<title>Tracking point of view in narrative</title>
<date>1994</date>
<journal>Computational Linguistics</journal>
<volume>20</volume>
<contexts>
<context>tions, among others. In its most basic representation, a private state can be described based on its functional components: the state of an experiencer holding an attitude optionally toward a target (Wiebe, 1994). The annotation scheme presented in (Wiebe et al., 2005) is a detailed, expression-level representation of private states and attributions that adapts and expands the more basic functional-component</context>
</contexts>
<marker>Wiebe, 1994</marker>
<rawString>Janyce Wiebe. 1994. Tracking point of view in narrative. Computational Linguistics, 20(2):233–287.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Wilson</author>
</authors>
<title>Fine-grained Subjectivity and Sentiment Analysis: Recognizing the Intensity, Polarity, and Attitudes of Private States</title>
<date>2008</date>
<tech>Ph.D. thesis</tech>
<institution>University of Pittsburgh</institution>
<contexts>
<context>e opinions and sentiments that participants express as part of their discussion. The scheme adapts concepts from the Multi-perspective Question Answering (MPQA) Annotation Scheme (Wiebe et al., 2005; Wilson, 2008), an annotation scheme for marking opinions and attributions in the news. The adaptations reflect the differences in multiparty conversation as compared to text, as well as the overall goals of our p</context>
<context>sent an annotation scheme for marking subjective content in meetings. The annotation scheme adapts concepts from the Multi-perspective Question Answering (MPQA) Annotation Scheme (Wiebe et al., 2005; Wilson, 2008), an annotation scheme developed for marking opinions and attributions in news articles. The adaptations reflect the differences in multiparty conversation as comparedtotext, aswellasouroverallprojec</context>
<context>ttributes and properties. The initial MPQA scheme contains four annotation frames: direct subjective frames, expressive subjective element frames, objective speech event frames, and agent frames. In (Wilson, 2008), the MPQA scheme is extended to include two new types of annotation frames: attitude frames and target frames. The direct subjective frame and the expressive subjective element frame are both used f</context>
<context>ntence. However, in the newsdomain, itisnotuncommontofindthreeorevenmore levels of attribution. The last two types of annotation frames in the MPQA scheme are the attitude frame and the target frame (Wilson, 2008). The attitude frames are linked to direct subjective frames. The purpose of an attitude frames is to capture the attitude being expressed overall by the private state to which it is linked. Similarl</context>
</contexts>
<marker>Wilson, 2008</marker>
<rawString>T. Wilson. 2008. Fine-grained Subjectivity and Sentiment Analysis: Recognizing the Intensity, Polarity, and Attitudes of Private States. Ph.D. thesis, University of Pittsburgh.</rawString>
</citation>
</citationList>
</algorithm>

