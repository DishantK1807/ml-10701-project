We first briefly describe the supervised system (described in more detail in Kehler et al.(2004)) to which we will compare the self-trained system.
N04-1037
In Kehler et al.(2004) we describe two ways in which our supervised system was augmented to use predicateargument frequencies, one which used them in a postprocessor and another which modeled them with features alongside our morphosyntactic ones.
N04-1037
Examples include the number of sentences between them and the “Hobbs distance”, that is, the number of noun groups that have to be skipped before the potential antecedent is found per the search order used by the Hobbs algorithm (Hobbs, 1978; Ge et al., 1998).
W98-1119
Supervised Algorithm The supervised model was trained using the improved iterative scaling algorithm for Maximum Entropy (MaxEnt) models described by Berger et al.(1996) with binary-valued features.
J96-1002
