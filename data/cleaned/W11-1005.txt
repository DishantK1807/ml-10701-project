Proceedings of SSST-5, Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 41–51,
ACL HLT 2011, Portland, Oregon, USA, June 2011. c©2011 Association for Computational Linguistics
Multi-Word Unit Dependency Forest-based Translation Rule
Extraction
Hwidong Na Jong-Hyeok Lee
Department of Computer Science and Engineering
Pohang University of Science and Technology (POSTECH)
San 31 Hyoja Dong, Pohang, 790-784, Republic of Korea
nullleona,jhleenull@postech.ac.kr
Abstract
Translation requires non-isomorphic
transformation from the source to the
target. However, non-isomorphism can
be reduced by learning multi-word units
(MWUs). We present a novel way of
representating sentence structure based
on MWUs, which are not necessarily
continuous word sequences. Our pro-
posed method builds a simpler structure
of MWUs than words using words
as vertices of a dependency structure.
Unlike previous studies, we collect
many alternative structures in a packed
forest. As an application of our proposed
method, we extract translation rules in
form of a source MWU-forest to the
target string, and verify the rule coverage
empirically. As a consequence, we
improve the rule coverage compare to a
previous work, while retaining the linear
asymptotic complexity.
1 Introduction
Syntax is the hierarchical structure of a natu-
ral language sentence. It is generally repre-
sented with tree structures using phrase struc-
ture grammar (PSG) or dependency grammar
Figure 1: A pair of sentences that require long
distance reordering (dashed line) and discontinuous
translation (thick line)
(DG). Although the state-of-the-art statistical
machine translation (SMT) paradigm is phrase-
based SMT (PBSMT), many researchers have
attempted to utilize syntax in SMT to over-
come the weaknesses of PBSMT. An emerging
paradigm alternative to PBSMT is syntax-based
SMT, which embeds the source and/or target
syntax in its translation model (TM). Utilizing
syntax in TM has two advantages over PBSMT.
The first advantage is that syntax eases global
reordering between the source and the target
language. Figure 1 shows that we need global
reordering in a complex real situation, where
a verbal phrase requires a long distance move-
ment. PBSMT often fails to handle global re-
ordering, for example, from subject-verb-object
(SVO) to SOV transformation where V should
be moved far away from the original position in
41
Table 1: Statistics of the corresponding target words
for the continuous word sequences in the source lan-
guage, or vice versa. C denotes consistent, O over-
lapped, D discontinuous, and N null.
Word Alignment C O D N
Manual 25 60 10 5
Automatic 20 55 15 5
the source language. This is because of the two
distance-based constraints in PBSMT: the dis-
tortion model cost and the distortion size limit.
For the distortion model cost, PBSMT sets zero
cost to the monotone translation and penalizes
the distorted translations as the distortion grows
larger. For the distortion size limit, a phrase can
only be moved from its original position within
a limit. Therefore, PBSMT fails to handle long
distance reordering. Syntax-based SMT man-
ages global reordering as structural transforma-
tion. Because reordering occurs at the sub-
structure level such as constituents or treelets
in syntax-based SMT, the transformation of the
sub-structure eventually yields the reordering of
the whole sentence.
The second advantage of using syntax in TM
is that syntax guides us to discontinuous trans-
lation patterns. Because PBSMT regards only
a continuous sequence of words as a transla-
tion pattern, it often fails to utilize many use-
ful discontinuous translation patterns. For ex-
ample, two discontinuous source words corre-
spond to a target word in Figure 1. In our in-
spection of the training corpus, a continuous
word sequence often corresponds to a set of
discontinuous words in the target language, or
vice versa (Table 1). Discontinuous translation
patterns frequently appear in many languages
(Søgaard and Kuhn, 2009). Syntax-based SMT
overcomes the limitations of PBSMT because it
finds discontinuous patterns along with the hier-
Figure 2: The maximum branching factor (BF) and
depth factor (DF) in a dependency tree in our corpus
archical structure. For example, the two discon-
tinuous source words have a head-dependent re-
lation (Figure 3). Especially with the depen-
dency tree, we can easily identify patterns that
have non-projectivity (Na et al., 2010). How-
ever, syntax-based patterns such as constituents
or treelets do not sufficiently cover various use-
ful patterns, even if we have the correct syn-
tactic analysis (Chiang, 2010). For this reason,
many researchers have proposed supplementary
patterns such as an intra/inter constituent or se-
quence of treelets (Galley et al., 2006; Shen et
al., 2008).
Unlike PSG, DG does not include non-
terminal symbols, which represent constituent
information. This makes DG simpler than PSG.
For instance, it directly associates syntatic role
with the structure, but introduces a difficulty in
syntax-based SMT. The branching factor of a
dependency tree becomes larger when a head
word dominates many dependents. We ob-
serve that the maximum branching factor of
an automatically parsed dependency tree ranges
widely, while most trees have depth under a cer-
tain degree (Figure 2). This indicates that we
have a horizontally flat dependency tree struc-
ture. The translation patterns extracted from the
42
flat dependency tree are also likely to be flat.
Unfortunately, the flat patterns are less appli-
cable at the decoding stage. When one of the
modifiers does not match, for instance, we fail
to apply the translation pattern. Therefore, we
need a more generally applicable representation
for syntax-based SMT using DG.
We propose a novel representation of DG that
regards a set of words as a unit of the depen-
dency relations, similar to (Ding, 2006; Wu et
al., 2009; Na et al., 2010). Unlike their work,
we consider many alternatives without prede-
fined units, and construct a packed forest of the
multi-word units (MWUs) from a dependency
tree. For brevity, we denote the forest based on
MWUs as an MWU-forest. Because all pos-
sible alternatives are exponentially many, we
give an efficient algorithm that enumerates the
k-best alternatives in section 3. As an appli-
cation, we extract translation patterns in form
of a source MWU-forest to the target string in
order to broaden the coverage of the extracted
patterns for syntax-based SMT in section 4. We
also report empirical results related to the use-
fulness of the extracted pattern in section 5. The
experimental results show that the MWU-forest
representation gives more applicable translation
patterns than the original word-based tree.
2 Related
Work
Previous studies have proposed merging alter-
native analyses to deal with analysis errors for
two reasons: 1) the strongest alternative is not
necessarily the correct analysis, and 2) most
alternatives contain similar elements such as
common sub-trees. For segmentation alterna-
tives, Dyer et al. (2008) proposed a word lattice
that represents exponentially large numbers of
segmentations of a source sentence, and inte-
grates reordering information into the lattice as
well. For parsing alternatives, Mi et al. (2008)
suggested a packed forest that encodes alterna-
tive PSG derivations. Futher, Mi et al. (2010)
combined the two approaches in order to bene-
fit from both.
The translation literature also shows that
translation requires non-isomorphic transfor-
mation from the source to the target. This yields
translation divergences such as head-switching
(Dorr, 1994). Ding and Palmer (2005) reported
that the percentage of the head-swapping cases
is 4.7%, and that of broken dependencies is
59.3% between Chinese and English. The large
amount of non-isomorphism, however, will be
reduced by learning MWUs such as elementary
trees (Eisner, 2003).
There are few studies that consider a depen-
dency structure based on MWUs. Ding (2006)
suggested a packed forest which consists of the
elementary trees, and described how to find
the best decomposition of the dependency tree.
However, Ding (2006) did not show how to de-
termine the MWUs and restrict them to form
a subgraph from a head. For opinion mining,
Wu et al. (2009) also utilized a dependency
structure based on MWUs, although they re-
stricted MWUs with predefined relations. Na
et al. (2010) proposed an MWU-based depen-
dency tree-to-string translation rule extraction,
but considered only one decomposition for ef-
ficiency. Our proposed method includes addi-
tional units over Ding’s method, such as a se-
quence of subgraphs within a packed forest. It
is also more general than Wu et al.’s method
because it does not require any predefined re-
lations. We gain much better rule coverage
against Na et al.’s method, while retaining linear
asymptotical computational time.
43
Figure 3: A dependency tree of the source sentence
in Figure 1
3 MWU-based Dependency Forest
There are two advantages when we use the
MWU-forest representaion with DG. First, we
express the discontinuous patterns in a vertex,
so that we can extract more useful translation
patterns beyond continuous ones for syntax-
based SMT. Second, an MWU-forest contains
many alternative structures which may be sim-
pler structures than the original tree in terms of
the branching factor and the maximum depth.
Wu et al. (2009) utilized an MWU-tree to iden-
tify the product features in a sentence easily.
As in previous literature in syntax-based
SMT using DG, we only consider the well-
formed MWUs where an MWU is either a
treelet (a connected sub-graph), or a sequence
of treelets under a common head. In other
words, each vertex in an MWU-forest is either
“fixed on head” or “floating with children”. The
formal definitions can be found in (Shen et al.,
2008).
We propose encoding multiple dependency
structures based on MWUs into a hypergraph.
A hypergraph is a compact representation of
exponetially many variations in a polynomi-
nal space. Unlike PSG, DG does not have
Figure 4: An MWU-forest of Figure 3. The dashed
line indicates the alternative hyperedges.
non-terminals that represent the linguistically
motivated, intermediate structure such as noun
phrases and verb phrases. For this simplicity,
Tu et al. (2010) proposed a dependency forest
as a hypergraph, regarding a word as a vertex
with a span that ranges for all its descendants.
The dependency forest offers tolerence of pars-
ing errors.
Our representation is different from the de-
pendency forest of Tu et al. (2010) since a ver-
tex corresponds to multiple words as well as
words. Note that our representation is also
capable of incorporating multiple parse trees.
Therefore, MWU-forests will also be tolerant
of the parsing error if we provide multiple parse
trees. In this work, we concentrate on the ef-
fectiveness of MWUs, and hence utilize the
best dependency parse tree. Figure 4 shows an
MWU-forest of the dependency tree in Figure
3.
More formally, a hypergraph H = nullV,Enull
consists of the vertices V and hyperedges
E. We assume that a length-J sentence has
a dependency graph which is single-headed,
44
acyclic, and rooted, i.e. hj is the index of the
head word of the j-th word, or 0 if the word is
the root. Each vertex v = nulljnulljnull[1,J]null de-
notes a set of the indices of the words that satis-
fies the well-formed constraint. Each hyperedge
e =nulltails(e),head(e)nulldenotes a set of the de-
pendency relations between head(e) andnullv null
tails(e). We include a special node v0 null V
that denotes the dummy root of an MWU-forest.
Note that v0 does not appear in tails(e) for all
hyperedges. We denotenullenullis the arity of hyper-
edge e, i.e. the number of tail nodes, and the
arity of a hypergraph is the maximum arity over
all hyperedges. Also, let σ(v) be the indices of
the words that the head lays out of the vertex,
i.e. σ(v) = nulljnullhj nullvnulljnullvnull, and τ(v) be
the indices of the direct dependent words of the
vertex, i.e. τ(v) = nulljnullhj nullvnulljnullvnull. Let
OUT(v) and IN(v) be the outgoing and in-
coming hyperedges of a vertex v, respectively.
It is challenging to weight the hyperedges
based on dependency grammar because a de-
pendency relation is a binary relation from a
head to a dependent. Tu et al. (2010) assigned
a probability for each hyperedge based on the
score of the binary relation. We simply prefer
the hyperedges that have lower arity by scoring
as follows:
c(e) =
summationtext
vnulltails(e)nullvnull
nullenull
p(e) = c(e)summationtext
enullnullIN(head(e)) c(enull)
We convert a dependency tree into a hyper-
graph in two steps using the Inside-Outside al-
gorithm. Algorithm 1 shows the pseudo code
of our proposed method. At the first step, we
find the k-best incoming hyperedges for each
vertex (line 3-8), and compute the inside proba-
bility (line 9), in bottom-up order. At the sec-
ond step, we compute the outside probability
Algorithm 1 Build Forest
1: Initialize V
2: for vnullV in bottom-up order do
3: Create a chart C =nullτ(v)null2
4: for chart span [p,q] do
5: Initialize C[p,q] ifnullv s.t. [p,q] = v or
σ(v)
6: Combine C[p,i] and C[i + 1,q]
7: end for
8: Set IN(v) to the k-best in C[TOP]
9: Set β(v) as in Eq. 1
10: end for
11: for vnullV in top-down order do
12: Set α(v) as in Eq. 2
13: end for
14: Prune out e if p(e)nullδ
15: return v0
(line 12) for each vertex in a top-down manner.
Finally we prune out less probable hyperedges
(line 14) similar to (Mi et al., 2008). The inside
and outside probabilities are defined as follows:
β(v) =
summationdisplay
enullIN(v)
p(e)
productdisplay
dnulltails(e)
β(d) (1)
where β(v) = 1.0 if IN(v) =null, and
α(v) =
summationdisplay
hnullOUT(v)
enullIN(head(h))
α(head(e))p(e)
nullOUT(v)null
null
productdisplay
dnulltails(e)nullnullvnull
β(d) (2)
where α(v) = 1.0 if OUT(v) =null.
In practice, we restrict the number of words
in a vertex in the initialization (line 1). We ap-
proximate all possible alternative MWUs that
include each word as follows:
45
Figure 5: A sub-forest of Figure 4 with annotation
of aspan and cspan for each vertex. We omit the
span if it is not consistent.
null A horizontal vertex is a sequence of modi-
fiers for a common head word, and
null A vertical vertex is a path from a word to
one of the ancestors, and
null A combination of the horizontal vertices
and the vertical vertices, and
null A combination of the vertical vertices and
the vertical vertices.
The computational complexity of the initial-
izaion directly affects the complexity of the en-
tire procedure. For each word, generating the
horizontal vertices takes O(b2), and the vertical
vertices take O(bdnull1), where b is the maximum
branching factor and d is the maximum depth
of a dependency tree. The two combinations
take O(bd+1) and O(b2(dnull1)) time to initialize
the vertices. However, it takes O(mm+1) and
O(m2(mnull1)) if we restrict the maximum num-
ber of the words in a vertex to a constant m.
Ding and Palmer (2005) insisted that the
Viterbi decoding of an MWU-forest takes lin-
ear time. In our case, we enumerate the k-best
incoming hyperedeges instead of the best one.
Because each enumeration takes O(k2nullτ(v)null3),
Table 2: The extracted rules in Figure 5. N denotes
the non-lexicalized rules with variables xi for each
vnulltails(e), and L denotes the lexicalized rule.
head(e) tails(e) rhs(γ)
N
null3null null8null: x1 x1
null8null null4null: x1,null5null: x2 when x1 x2
null3,8null null4,5null: x1 when x1
null3,8null null4null: x1,null5null: x2 when x1 x2
null4,5null null6,7null: x1 I’m in x1
null5null null6,7null: x1 in x1
L
null6,7null
N/A
the States
null4null I’m
null5null in
null4,5null I’m in
null5,6null in the State
null3,8null When
the total time complexity also becomes linear
to the length of the sentence n similar to Ding
and Palmer (2005), i.e. O(nullVnullk2nullτ(v)null3), where
nullVnull= O(na2(anull1)) and a = min(m,b,d).
4 MWU-Forest-to-String Translation
Rule Extraction
As an application of our proposed MWU-forest,
we extract translation rules for syntax-based
SMT. Forest-based translation rule extraction
has been suggested by Mi and Huang (2008)
although their forest compacts the k-best PSG
trees. The extraction procedure is essentially
the same as Galley et al. (2004), which iden-
tifies the cutting points (frontiers) and extracts
the sub-structures from a root to frontiers.
The situation changes in DG because DG
does not have intermediate representation. At
the dependency structure, a node corresponds
to two kinds of target spans. We borrow the
definitions of the aligned span (aspan), and the
covered span (cspan) from Na et al. (2010), i.e.
46

