Since the first appearance of “Put-That-There” system (Bolt 1980), a variety of multimodal systems have emerged, from early systems that combine speech, pointing (Neal et al., 1991), and gaze (Koons et al, 1993), to systems that integrate speech with pen inputs (e.g., drawn graphics) (Cohen et al., 1996; Wahlster 1998; Wu et al., 1999), and systems that engage users in intelligent conversation (Cassell et al., 1999; Stent et al., 1999; Gustafson et al., 2000; Chai et al., 2002; Johnston et al., 2002).
P02-1048 P99-1024
These were two major error sources, which were accounted for 55% and 20% of total errors respectively (Chai et al.2004b). In our studies, the majority of user references were simple in that they involved only one referring expression and one gesture as in earlier findings (Kehler 2000).
N04-4011
The details are described in (Chai et al.2004a). 2 Each node from the conversation context is linked to every node corresponding to the first pointing and the second pointing.
N04-4011
The first issue focuses on the fusion aspect, which has been well studied in earlier work, for example, through unificationbased approaches (Johnston 1998) or finite state approaches (Johnston and Bangalore, 2000).
C00-1054 P98-1102
For example, in the unificationbased approach (Johnston 1998), one temporal constraint indicates that speech and gesture can be combined only when the speech either overlaps with gesture or follows the gesture within a certain time frame.
P98-1102
Optimality Theory does not restrict the content of the constraints (Eisner 1997).
P97-1040
