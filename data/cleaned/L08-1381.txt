<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>Shane Bergsma</author>
<author>Dekang Lin</author>
</authors>
<title>Bootstrapping path-based pronoun resolution</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the ACL</booktitle>
<pages>33--40</pages>
<contexts>
<context> contain three data sets), from different perspectives: pronoun types, pronoun gender, and number, the morphological factors proven to be very important in pronoun resolution for the newswire domain (Bergsma and Lin, 2006). However, it can be observed in the graphs that while the distributions of MUC and ACE data sets are similar to each other, GENIA is very different. In GENIA, or bio-texts, a majority of the anaphor</context>
</contexts>
<marker>Bergsma, Lin, 2006</marker>
<rawString>Shane Bergsma and Dekang Lin. 2006. Bootstrapping path-based pronoun resolution. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the ACL, pages 33–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascal Denis</author>
<author>J Baldridge</author>
</authors>
<title>A ranking approach to pronoun resolution</title>
<date>2007</date>
<booktitle>In Proceedings of IJCAI-2007</booktitle>
<contexts>
<context>. 3. Pronoun resolution engine 3.1. Pronoun resolution model We built a machine learning based pronoun resolution engine using a Maximum Entropy ranker model similar with Denis and Baldridge’s model (Denis and Baldridge, 2007). For every anaphoric pronoun …, the ranker selects the most likely antecedent candidate fi, from a set of k candidate markables. Pr(fij|…) = exp( ∑n i=1 ‚ifi(…,fij))∑ k exp( ∑n i=1 ‚ifi(…,fik)) (1) </context>
</contexts>
<marker>Denis, Baldridge, 2007</marker>
<rawString>Pascal Denis and J. Baldridge. 2007. A ranking approach to pronoun resolution. In Proceedings of IJCAI-2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Dan Klein</author>
</authors>
<title>Unsupervised coreference resolution in a nonparametric bayesian model</title>
<date>2007</date>
<booktitle>In In proceedings of ACL</booktitle>
<contexts>
<context>esolution, and for anaphora resolution tasks. Among such, MUC and ACE data sets are very popular for the newswire domain. Many experiments on these corpora produced good results (Yang et al., 2006), (Haghighi and Klein, 2007). Recently, for the biomedical domain, the GENIA corpus has been annotated for coreferences. In this work, we aim to compare these three corpora with respect to corpus-based pronoun resolution tasks.</context>
</contexts>
<marker>Haghighi, Klein, 2007</marker>
<rawString>Aria Haghighi and Dan Klein. 2007. Unsupervised coreference resolution in a nonparametric bayesian model. In In proceedings of ACL 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruslan Mitkov</author>
</authors>
<title>Robust pronoun resolution with limited knowledge</title>
<date>1998</date>
<booktitle>In In Proceedings of ACL ’98</booktitle>
<pages>869--875</pages>
<contexts>
<context>ora resolution and co-reference resolution, the two significant tasks required to be solved when approaching the goal of natural language understanding. The shift from heuristics and knowledge-based (Mitkov, 1998) to machine learning and corpus-based methods (Ng, 2005), (Soon et al., 2001) has made the annotated corpora a vital resource in both training and evaluating resolution models. Because of similar ref</context>
</contexts>
<marker>Mitkov, 1998</marker>
<rawString>Ruslan Mitkov. 1998. Robust pronoun resolution with limited knowledge. In In Proceedings of ACL ’98, pages 869–875.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruslan Mitkov</author>
</authors>
<title>Towards a more consistent and comprehensive evaluation of anaphora resolution algorithms and systems</title>
<date>2001</date>
<journal>Applied Artificial Intelligence</journal>
<volume>15</volume>
<pages>276--24</pages>
<contexts>
<context>of the system trained on the X corpus, and evaluated on the Y corpus. All of the evaluation results are given in success rate 2, a common evaluation scoring in anaphora resolution proposed by Mitkov (Mitkov, 2001). It is calculated as the total successfully resolved anaphoric pronouns divided by the total number of manually annotated anaphoric pronouns. Success rate = Number of successfully resolved anaphorsN</context>
</contexts>
<marker>Mitkov, 2001</marker>
<rawString>Ruslan Mitkov. 2001. Towards a more consistent and comprehensive evaluation of anaphora resolution algorithms and systems. Applied Artificial Intelligence, 15(3):253– 276(24).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
</authors>
<title>Supervised ranking for pronoun resolution: Some recent improvements</title>
<date>2005</date>
<booktitle>In Proceedings of the Twentieth National Conference on Artificial Intelligence (AAAI-05</booktitle>
<contexts>
<context>ant tasks required to be solved when approaching the goal of natural language understanding. The shift from heuristics and knowledge-based (Mitkov, 1998) to machine learning and corpus-based methods (Ng, 2005), (Soon et al., 2001) has made the annotated corpora a vital resource in both training and evaluating resolution models. Because of similar reference characteristics, the same co-reference annotated </context>
</contexts>
<marker>Ng, 2005</marker>
<rawString>Vincent Ng. 2005. Supervised ranking for pronoun resolution: Some recent improvements. In Proceedings of the Twentieth National Conference on Artificial Intelligence (AAAI-05).</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Soon</author>
<author>H Ng</author>
<author>D Lim</author>
</authors>
<title>A machine learning approach to coreference resolution of noun phrases</title>
<date>2001</date>
<journal>Computational Linguistics</journal>
<volume>27</volume>
<contexts>
<context>quired to be solved when approaching the goal of natural language understanding. The shift from heuristics and knowledge-based (Mitkov, 1998) to machine learning and corpus-based methods (Ng, 2005), (Soon et al., 2001) has made the annotated corpora a vital resource in both training and evaluating resolution models. Because of similar reference characteristics, the same co-reference annotated corpora are often emp</context>
<context>n used for this task, and all base noun phrases produced are considered as markables. Some reseachers additionally merge named entities produced by a NER with base NP chunks to form the markable set (Soon et al., 2001). In our system, we built a chunker-based markable detector using the GENIA Tagger (Tsuruoka and Tsujii, 2005). For each input NP chunk, the markable detector creates a markable. If a chunk contains </context>
</contexts>
<marker>Soon, Ng, Lim, 2001</marker>
<rawString>W. Soon, H. Ng, and D. Lim. 2001. A machine learning approach to coreference resolution of noun phrases. Computational Linguistics, 27(4):521–544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoshimasa Tsuruoka</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Bidirectional inference with the easiest-first strategy for tagging sequence data. In</title>
<date>2005</date>
<booktitle>In Proceedings of HLT/EMNLP</booktitle>
<pages>467--474</pages>
<contexts>
<context>additionally merge named entities produced by a NER with base NP chunks to form the markable set (Soon et al., 2001). In our system, we built a chunker-based markable detector using the GENIA Tagger (Tsuruoka and Tsujii, 2005). For each input NP chunk, the markable detector creates a markable. If a chunk contains a possessive pronoun, then that pronoun will form another markable. Every markable is then characterized by ge</context>
</contexts>
<marker>Tsuruoka, Tsujii, 2005</marker>
<rawString>Yoshimasa Tsuruoka and Jun’ichi Tsujii. 2005. Bidirectional inference with the easiest-first strategy for tagging sequence data. In In Proceedings of HLT/EMNLP 2005, pages 467–474.</rawString>
</citation>
</citationList>
</algorithm>

