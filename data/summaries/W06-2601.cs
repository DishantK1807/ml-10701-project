F.J.OchandH.Ney. 2002.
P02-1038
In fact, only recently, log-probability features have been deployed in ME models for statistical machine translation (Och and Ney, 2002).
P02-1038
Estimation From the duality of ME and maximum likelihood (Berger et al., 1996), optimal parameters λ∗ for model (3) can be found by maximizing the log-likelihood function over a training sample {(xt,yt) : t = 1,...,N}, i.e.: λ∗ = argmax λ Nsummationdisplay t=1 logpλ(yt|xt).
J96-1002
Despite ME theory and its related training algorithm (Darroch and Ratcliff, 1972) do not set restrictions on the range of feature functions1, popular NLP text books (Manning and Schutze, 1999) and research papers (Berger et al., 1996) seem to limit them to binary features.
J96-1002
By taking inspiration from the literature (Bender et al., 2003; Borthwick, 1999; Koeling, 2000), a set of standard binary features is introduced.
W00-0729 W03-0420
The Maximum Entropy (ME) statistical framework (Darroch and Ratcliff, 1972; Berger et al., 1996) has been successfully deployed in several NLP tasks.
J96-1002
InMikheev (1998), binary features fortexttagging are classified into two broad classes: atomic and complex.
P98-2140
Moreover, limiting the context to the two previous tags permits to apply dynamic programming (Bender et al., 2003) to efficiently solve the maximization (2).
W03-0420
