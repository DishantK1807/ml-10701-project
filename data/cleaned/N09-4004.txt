Proceedings of NAACL HLT 2009: Tutorials, pages 7–8,
Boulder, Colorado, June 2009. c 2009 Association for Computational Linguistics
ExtractingWorldandLinguisticKnowledgefromWikipedia
SimonePaoloPonzetto
Dept.ofComputationalLinguistics
UniversityofHeidelberg
Heidelberg,Germany
http://www.cl.uni-heidelberg.de/˜ponzetto
MichaelStrube
EMLResearchgGmbH
Schloss-Wolfsbrunnenweg33
Heidelberg,Germany
http://www.eml-research.de/˜strube
Overview
Many research efforts have been devoted to develop robust statistical modeling techniquesfor many NLP
tasks. Our fieldisnowmovingtowardsmorecomplex tasks(e.g.RTE,QA),whichrequireto complement
these methodswitha semanticallyrich representationbasedon world and linguisticknowledge(i.e.anno-
tatedlinguisticdata). InthistutorialweshowseveralapproachestoextractthisknowledgefromWikipedia.
This resource has attracted the attention of much work in the AI community, mainly because it provides
semi-structuredinformationandalargeamountofmanualannotations.Thepurposeofthistutorialistoin-
troduceWikipediaasaresourcetotheNLPcommunityandtoprovideanintroductionforNLPresearchers
bothfromascientific andapractical(i.e.dataacquisitionandprocessingissues)perspective.
Outline
Thetutorialisdividedintothreemainparts:
1. ExtractingworldknowledgefromWikipedia. We review methodsaimingat extractingfullystruc-
turedworldknowledgefromthecontentoftheonlineencyclopedia. Weshow howtotake categories,
hyperlinksand infoboxes as buildingblocksfor a semanticnetwork withunlabeledrelationsbetween
theconcepts. Thetask oftaxonomyinductionthenboilsdownto labelingtherelationsbetweenthese
concepts,e.g. withisa,part-of,instance-of,located-in,etc. relations.
2. LeveraginglinguisticknowledgefromWikipedia. Wikipediaprovides shallow markupannotations
whichcanbeinterpretedas manualannotationsoflinguisticphenomena. These‘annotations’include
word boundaries, word senses, named entities, translations of concepts in many languages. Further-
more,Wikipediacanbeusedasamultilingualcomparablecorpus.
3. Future directions. Knowledge derived from Wikipedia has the potential to become a resource as
important for NLP as WordNet. Also the Wikipedia edit history provides a repository of linguistic
knowledgewhichistobeexploited. Potentialapplicationsoftheknowledgeimplicitlyencodedinthe
edithistoryincludespellingcorrections,naturallanguagegeneration,textsummarization,etc.
Targetaudience
Thistutorialis designedfor studentsand researchersin ComputerScienceand ComputationalLinguistics.
Nopriorknowledgeofinformationextractiontopicsisassumed.
7
Speakers’bios
SimonePaoloPonzettoisanassistantprofessorattheComputationalLinguisticsDepartmentoftheUniver-
sityofHeidelberg,Germany. Hismainresearchinterestslieintheareaofinformationextraction,knowledge
acquisitionandengineering,lexicalsemantics,andtheirapplicationtodiscourse-basedphenomena.
Michael Strube is group leader of the NLP group at EML Research, a privately funded research institute
in Heidelberg, Germany. TheNLPgroupfocuseson the areas of semantics,pragmaticsand discourseand
applicationslikesummarizationandinformationextraction.
8

