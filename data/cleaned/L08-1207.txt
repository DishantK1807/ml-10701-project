<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>P Ahlgren</author>
<author>J Keklinen</author>
</authors>
<title>Swedish full text retrieval: Effectiveness of different combinations of indexing strategies with query terms</title>
<date>2006</date>
<journal>Information Retrieval</journal>
<volume>9</volume>
<marker>Ahlgren, Keklinen, 2006</marker>
<rawString>P. Ahlgren and J. Keklinen. 2006. Swedish full text retrieval: Effectiveness of different combinations of indexing strategies with query terms. Information Retrieval, 9(6):681–697.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M T Cabr´e</author>
<author>R ESTOP</author>
<author>J VIVALDI</author>
</authors>
<title>Automatic term detection: a review of current systems</title>
<date>2000</date>
<journal>Recent Advances in Computational Terminology</journal>
<volume>2</volume>
<marker>Cabr´e, ESTOP, VIVALDI, 2000</marker>
<rawString>M.T. Cabr´e, R. ESTOP, and J. VIVALDI. 2000. Automatic term detection: a review of current systems. Recent Advances in Computational Terminology, 2(1):53–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K W Church</author>
<author>P Hanks</author>
</authors>
<title>Word association norms, mutual information, and lexicography</title>
<date>1990</date>
<booktitle>In Proceedings of the 27th. Annual Meeting of the Association for Computational Linguistics</booktitle>
<pages>76--83</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics</institution>
<location>Vancouver, B.C</location>
<contexts>
<context>cal approaches based on frequency and co-occurrence affinity, b) symbolic approaches using parsers, lexicons and language filters, and c) hybrid approaches combining different methods (Smadja, 1993) (Church and Hanks, 1990) (Daille, 1994) (Sag et al., 2002) (Maynard and Ananiadou, 2000). In practice, most statistical approaches employ linguistic filters to extract candidate MWTs (Church and Hanks, 1990). One of the mai</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>K.W. Church and P. Hanks. 1990. Word association norms, mutual information, and lexicography. In Proceedings of the 27th. Annual Meeting of the Association for Computational Linguistics, pages 76–83, Vancouver, B.C. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
<author>W Gale</author>
<author>P Hanks</author>
<author>D Hindle</author>
</authors>
<title>Using statistics in lexical analysis</title>
<date>1991</date>
<booktitle>In Lexical Acquisition: Exploiting On-Line Resources to Build a Lexicon</booktitle>
<pages>115--164</pages>
<contexts>
<context>nking of MWT-like units by means of statistical techniques, log-likelihood ratio (LLR) (Dunning, 1994), FLR (Nakagawa and Mori, 2003), Mutual Information (MI3) (Kenneth and Hanks, 1989) and t-scores (Church et al., 1991). To filter the MWT-like units, we used their part-of-speech that has been assigned by the diab’s tagger (Diab et al., 2004). The MWT-like string patterns are described through morphosyntactic rules </context>
<context>rely on different concepts. So, we compute several measures: log-likelihood ratio (LLR) (Dunning, 1994), FLR (Nakagawa and Mori, 2003), Mutual Information (MI3) (Kenneth and Hanks, 1989) and tscores (Church et al., 1991). Mutual Information (MI3) MWT Pattern Part of speech pattern N1 N2 NN[P]? j NNs[P]? N1 ADJ NN[P]? j NNs[P]? jJJ N1 PREP N2 NN[P]? j NNs[P]? j IN j NN[P]? j NNs[P]? Table 6: Pattern and Part-of-speec</context>
<context>ucceed N. LN(N) and RN(N) are the frequencies of nouns that directly precede or succeed N. Method Formula LLR (Dunning, 1994) 2(n11log n11m11 + n12log n12m12 + n21log n21m21 + n22log n22m22) T-score (Church et al., 1991) n11¡ n1pnp1npp n112 FLR (Nakagawa and Mori, 2003) FLR(CN) = LR(CN)⁄f(CN) Mutual Information (MI3) (Daille, 1994) log2 n113n12n21 Table 7: Statistical algorithms used to measure the association stren</context>
</contexts>
<marker>Church, Gale, Hanks, Hindle, 1991</marker>
<rawString>K. Church, W. Gale, P. Hanks, and D. Hindle. 1991. Using statistics in lexical analysis. In Lexical Acquisition: Exploiting On-Line Resources to Build a Lexicon, pages 115–164. U. Zernik.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Daille</author>
</authors>
<title>Approche mixte pour l’extraction de terminologie : statistiques lexicales et filtres linguistiques</title>
<date>1994</date>
<booktitle>Ph.D. thesis, Universit de Paris 7</booktitle>
<location>France</location>
<contexts>
<context>requency and co-occurrence affinity, b) symbolic approaches using parsers, lexicons and language filters, and c) hybrid approaches combining different methods (Smadja, 1993) (Church and Hanks, 1990) (Daille, 1994) (Sag et al., 2002) (Maynard and Ananiadou, 2000). In practice, most statistical approaches employ linguistic filters to extract candidate MWTs (Church and Hanks, 1990). One of the main problems conf</context>
<context>1994) 2(n11log n11m11 + n12log n12m12 + n21log n21m21 + n22log n22m22) T-score (Church et al., 1991) n11¡ n1pnp1npp n112 FLR (Nakagawa and Mori, 2003) FLR(CN) = LR(CN)⁄f(CN) Mutual Information (MI3) (Daille, 1994) log2 n113n12n21 Table 7: Statistical algorithms used to measure the association strength of a word pair xy. 5.4. Selecting the best measure We evaluate the statistical algorithms against the environ</context>
<context>d t-score measures, that are based on the significance of association measure, outperform the MI3 measure. Note that LLR outperform other methods. These results are consistent with those reported in (Daille, 1994) (Hong et al., 2001) The results are shown in Table 8. 6. Conclusion In this paper we presented our approach for the extraction of term candidates from Arabic technical texts. We have applied an a hy</context>
</contexts>
<marker>Daille, 1994</marker>
<rawString>B. Daille. 1994. Approche mixte pour l’extraction de terminologie : statistiques lexicales et filtres linguistiques. Ph.D. thesis, Universit de Paris 7, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Daille</author>
</authors>
<title>Variations and application-oriented terminology engineering. International journal of theoretical and applied issues in specialized communication</title>
<date>2005</date>
<pages>11--1</pages>
<contexts>
<context>tem 1 which transliterates Arabic alphabet into Latin alphabet. 3.2. MWT variation The module for automatic term acquisition takes into account term variations. We followed the typology suggested by (Daille, 2005). 1http://www.qamus.org/transliteration.htm Pattern Sub-pattern Arabic MWT English translation N ADJ Altlwv AlkmyAAy chemical pollution N1 N2 tlwv AlmAA water pollution N1 b N2 Altlwv b AlrsAs pollut</context>
</contexts>
<marker>Daille, 2005</marker>
<rawString>B. Daille. 2005. Variations and application-oriented terminology engineering. International journal of theoretical and applied issues in specialized communication, 11(1):181–197.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Diab</author>
<author>K Hacioglu</author>
<author>D Jurafsky</author>
</authors>
<title>Automatic tagging of arabic text: From raw text to base phrase chunks. In</title>
<date>2004</date>
<booktitle>In Proceedings of NAACL-HLT</booktitle>
<pages>149--152</pages>
<location>Boston, USA</location>
<contexts>
<context>c variants 4. Multi-word term extraction The term extraction process is performed in two major steps: the selection of MWT-like units, using part-ofspeech that has been assigned by the diab’s tagger (Diab et al., 2004), and the ranking of MWT-like units by means of statistical techniques, log-likelihood ratio (LLR) (Dunning, 1994), FLR (Nakagawa and Mori, 2003), Mutual Information (MI3) (Kenneth and Hanks, 1989) a</context>
</contexts>
<marker>Diab, Hacioglu, Jurafsky, 2004</marker>
<rawString>M. Diab, K. Hacioglu, and D. Jurafsky. 2004. Automatic tagging of arabic text: From raw text to base phrase chunks. In In Proceedings of NAACL-HLT, pages 149– 152, Boston, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence</title>
<date>1994</date>
<journal>Computational Linguistics</journal>
<volume>19</volume>
<contexts>
<context> MWT-like units, using part-ofspeech that has been assigned by the diab’s tagger (Diab et al., 2004), and the ranking of MWT-like units by means of statistical techniques, log-likelihood ratio (LLR) (Dunning, 1994), FLR (Nakagawa and Mori, 2003), Mutual Information (MI3) (Kenneth and Hanks, 1989) and t-scores (Church et al., 1991). To filter the MWT-like units, we used their part-of-speech that has been assign</context>
<context>order To rank MWT like strings that have been collecting in the first step, The wellknown association measures rely on different concepts. So, we compute several measures: log-likelihood ratio (LLR) (Dunning, 1994), FLR (Nakagawa and Mori, 2003), Mutual Information (MI3) (Kenneth and Hanks, 1989) and tscores (Church et al., 1991). Mutual Information (MI3) MWT Pattern Part of speech pattern N1 N2 NN[P]? j NNs[P</context>
<context>N[P]? j NNs[P]? j IN j NN[P]? j NNs[P]? Table 6: Pattern and Part-of-speech Mapping (Kenneth and Hanks, 1989) was taken from Information Theory. Other measures such as the log-likelihood ratio (LLR) (Dunning, 1994) and t-score (Church et al., 1991) are based on hypothesis testing. FLR (Nakagawa and Mori, 2003) make the hypothesis that MWTs are often built around a limited number of single words and measures ho</context>
<context> and # RDN(N) : These are the number of distinct simple words which directly precede or succeed N. LN(N) and RN(N) are the frequencies of nouns that directly precede or succeed N. Method Formula LLR (Dunning, 1994) 2(n11log n11m11 + n12log n12m12 + n21log n21m21 + n22log n22m22) T-score (Church et al., 1991) n11¡ n1pnp1npp n112 FLR (Nakagawa and Mori, 2003) FLR(CN) = LR(CN)⁄f(CN) Mutual Information (MI3) (Dail</context>
</contexts>
<marker>Dunning, 1994</marker>
<rawString>T. Dunning. 1994. Accurate methods for the statistics of surprise and coincidence. Computational Linguistics, 19(1):61–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Haddad</author>
</authors>
<title>Extraction et impact des connaissances sur les performances des systmes de recherche d’information</title>
<date>2002</date>
<tech>Ph.D. thesis</tech>
<institution>Universit Joseph Fourier</institution>
<location>Grenoble, France</location>
<marker>Haddad, 2002</marker>
<rawString>H. Haddad. 2002. Extraction et impact des connaissances sur les performances des systmes de recherche d’information. Ph.D. thesis, Universit Joseph Fourier, Grenoble, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hong</author>
<author>S Fissaha</author>
<author>J Haller</author>
</authors>
<title>Hybrid filtering for extraction of term candidates from german technical texts</title>
<date>2001</date>
<booktitle>In TIA</booktitle>
<pages>223--232</pages>
<contexts>
<context>res, that are based on the significance of association measure, outperform the MI3 measure. Note that LLR outperform other methods. These results are consistent with those reported in (Daille, 1994) (Hong et al., 2001) The results are shown in Table 8. 6. Conclusion In this paper we presented our approach for the extraction of term candidates from Arabic technical texts. We have applied an a hybrid approach for th</context>
</contexts>
<marker>Hong, Fissaha, Haller, 2001</marker>
<rawString>M. Hong, S. Fissaha, and J. Haller. 2001. Hybrid filtering for extraction of term candidates from german technical texts. In TIA 2001 : terminologie et intelligence artificielle, pages 223–232.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Ibekwe-SanJuan</author>
<author>M T Condamines</author>
</authors>
<title>A.and Cabr Castellv</title>
<date>2007</date>
<journal>special issue of the Terminology Journal</journal>
<pages>2--1</pages>
<contexts>
<context> evaluate this approach in differents domains and applications such as information retrieval or information extraction. Since MWTs have been useful for various applications of terminology processing (Ibekwe-SanJuan and Condamines, 2007) (Marcelline et al., 2003) and in IR (Haddad, 2002) (Ahlgren and Keklinen, 2006), we believe that our Arabic term extraction program will fill a gap in Arabic specialized language processing 7. Refer</context>
</contexts>
<marker>Ibekwe-SanJuan, Condamines, 2007</marker>
<rawString>F. Ibekwe-SanJuan and M. T. Condamines, A.and Cabr Castellv. 2007. Application-driven terminology engineering. special issue of the Terminology Journal, 2:1–17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Jacquemin</author>
</authors>
<title>Spotting and Discovering Terms through Natural Language Processing Techniques</title>
<date>2001</date>
<publisher>MIT Press</publisher>
<location>Cambridge</location>
<contexts>
<context> a given lemma or the ’canonical form’ of a given term can appear in texts is extensive. Inflectional variants include the number inflection of nouns, the number and gender inflections of adjectives (Jacquemin, 2001; Nenadic and Spasic, 2002), and the definite article that is carried out by the prefixed morpheme (Al). Table 3 shows some examples of inflectional variants. Type Arabic MWT Variant English translati</context>
</contexts>
<marker>Jacquemin, 2001</marker>
<rawString>C. Jacquemin. 2001. Spotting and Discovering Terms through Natural Language Processing Techniques. MIT Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W C Kenneth</author>
<author>P Hanks</author>
</authors>
<title>Word association norms, mutual information, and lexicography</title>
<date>1989</date>
<booktitle>In Proceedings of the 27th. Annual Meeting of the Association for Computational Linguistics</booktitle>
<pages>76--83</pages>
<location>Vancouver, B.C</location>
<contexts>
<context> tagger (Diab et al., 2004), and the ranking of MWT-like units by means of statistical techniques, log-likelihood ratio (LLR) (Dunning, 1994), FLR (Nakagawa and Mori, 2003), Mutual Information (MI3) (Kenneth and Hanks, 1989) and t-scores (Church et al., 1991). To filter the MWT-like units, we used their part-of-speech that has been assigned by the diab’s tagger (Diab et al., 2004). The MWT-like string patterns are descr</context>
<context>p, The wellknown association measures rely on different concepts. So, we compute several measures: log-likelihood ratio (LLR) (Dunning, 1994), FLR (Nakagawa and Mori, 2003), Mutual Information (MI3) (Kenneth and Hanks, 1989) and tscores (Church et al., 1991). Mutual Information (MI3) MWT Pattern Part of speech pattern N1 N2 NN[P]? j NNs[P]? N1 ADJ NN[P]? j NNs[P]? jJJ N1 PREP N2 NN[P]? j NNs[P]? j IN j NN[P]? j NNs[P]? </context>
</contexts>
<marker>Kenneth, Hanks, 1989</marker>
<rawString>W. C Kenneth and P. Hanks. 1989. Word association norms, mutual information, and lexicography. In Proceedings of the 27th. Annual Meeting of the Association for Computational Linguistics, pages 76–83, Vancouver, B.C.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R H Marcelline</author>
<author>K S Guergana</author>
<author>M J Thomas</author>
<author>G C Christopher</author>
</authors>
<title>A term extraction tool for expanding content in the domain of functioning, disability, and health: proof of concept</title>
<date>2003</date>
<journal>Journal of Biomedical Informatics</journal>
<pages>36--4</pages>
<marker>Marcelline, Guergana, Thomas, Christopher, 2003</marker>
<rawString>R.H. Marcelline, K.S. Guergana, M.J. Thomas, and Christopher G.C. 2003. A term extraction tool for expanding content in the domain of functioning, disability, and health: proof of concept. Journal of Biomedical Informatics, 36(4/5):250–259.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Maynard</author>
<author>S Ananiadou</author>
</authors>
<title>Identifying terms by their family and friends</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th conference on Computational linguistics</booktitle>
<pages>530--536</pages>
<location>Saarbrcken, Germany</location>
<contexts>
<context>y, b) symbolic approaches using parsers, lexicons and language filters, and c) hybrid approaches combining different methods (Smadja, 1993) (Church and Hanks, 1990) (Daille, 1994) (Sag et al., 2002) (Maynard and Ananiadou, 2000). In practice, most statistical approaches employ linguistic filters to extract candidate MWTs (Church and Hanks, 1990). One of the main problems confronting statistical approaches, however, is that </context>
</contexts>
<marker>Maynard, Ananiadou, 2000</marker>
<rawString>G. Maynard and S. Ananiadou. 2000. Identifying terms by their family and friends. In Proceedings of the 18th conference on Computational linguistics, pages 530 – 536, Saarbrcken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Michiels</author>
<author>N Dufour</author>
</authors>
<title>Defi, a tool for automatic multi-word unit rec-ognition, meaning assignment and translation selection. In</title>
<date>1998</date>
<booktitle>In Proceedings of the First Interna-tional Conference on Language Resources and Evaluation</booktitle>
<pages>1179--1186</pages>
<location>Granada, Spain</location>
<contexts>
<context>part of multiword terms are excluded by statistical approaches. Lexical resources and parsers are used to obtain better coverage of the lexicon in MWT extraction. For example, In their DEFI Project, (Michiels and Dufour, 1998) used dictionaries to identify English and French multiword terms and their translations in the other language. Like pure statistical approaches, purely knowledge based symbolic approaches also face </context>
</contexts>
<marker>Michiels, Dufour, 1998</marker>
<rawString>A. Michiels and N. Dufour. 1998. Defi, a tool for automatic multi-word unit rec-ognition, meaning assignment and translation selection. In In Proceedings of the First Interna-tional Conference on Language Resources and Evaluation, pages 1179–1186, Granada, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Nakagawa</author>
<author>T Mori</author>
</authors>
<title>Nested collocation and compound noun for term recognition. In</title>
<date>2002</date>
<booktitle>In Proceedings of the First Workshop on Computational Terminology COMPTERM’98</booktitle>
<pages>64--70</pages>
<contexts>
<context>develop a multi-word term (MWT) extraction tool for Arabic. The identification of MWT is crucial for terminology extraction because MWTS are less polysemous and more numerous that SWTs. For intance, (Nakagawa and Mori, 2002) show that more than 85% of domain-specific terms are multi-word terms. To extract MWTs from corpora, we adopt the standard approach that combined grammatical patterns and statistical score (Cabr´e e</context>
</contexts>
<marker>Nakagawa, Mori, 2002</marker>
<rawString>H. Nakagawa and T. Mori. 2002. Nested collocation and compound noun for term recognition. In In Proceedings of the First Workshop on Computational Terminology COMPTERM’98,, pages 64–70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Nakagawa</author>
<author>T Mori</author>
</authors>
<title>Automatic term recognition based on statistics of compound nouns and their components</title>
<date>2003</date>
<journal>Terminology</journal>
<volume>9</volume>
<contexts>
<context>g part-ofspeech that has been assigned by the diab’s tagger (Diab et al., 2004), and the ranking of MWT-like units by means of statistical techniques, log-likelihood ratio (LLR) (Dunning, 1994), FLR (Nakagawa and Mori, 2003), Mutual Information (MI3) (Kenneth and Hanks, 1989) and t-scores (Church et al., 1991). To filter the MWT-like units, we used their part-of-speech that has been assigned by the diab’s tagger (Diab e</context>
<context>e strings that have been collecting in the first step, The wellknown association measures rely on different concepts. So, we compute several measures: log-likelihood ratio (LLR) (Dunning, 1994), FLR (Nakagawa and Mori, 2003), Mutual Information (MI3) (Kenneth and Hanks, 1989) and tscores (Church et al., 1991). Mutual Information (MI3) MWT Pattern Part of speech pattern N1 N2 NN[P]? j NNs[P]? N1 ADJ NN[P]? j NNs[P]? jJJ </context>
<context>nneth and Hanks, 1989) was taken from Information Theory. Other measures such as the log-likelihood ratio (LLR) (Dunning, 1994) and t-score (Church et al., 1991) are based on hypothesis testing. FLR (Nakagawa and Mori, 2003) make the hypothesis that MWTs are often built around a limited number of single words and measures how many distinct words are part of MWTs. 5. Experimentation and Evaluation 5.1. Corpora used Docum</context>
<context>of nouns that directly precede or succeed N. Method Formula LLR (Dunning, 1994) 2(n11log n11m11 + n12log n12m12 + n21log n21m21 + n22log n22m22) T-score (Church et al., 1991) n11¡ n1pnp1npp n112 FLR (Nakagawa and Mori, 2003) FLR(CN) = LR(CN)⁄f(CN) Mutual Information (MI3) (Daille, 1994) log2 n113n12n21 Table 7: Statistical algorithms used to measure the association strength of a word pair xy. 5.4. Selecting the best mea</context>
</contexts>
<marker>Nakagawa, Mori, 2003</marker>
<rawString>H. Nakagawa and T. Mori. 2003. Automatic term recognition based on statistics of compound nouns and their components. Terminology, 9(2):201–219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Nenadic</author>
<author>S Spasic</author>
<author>I and Ananiadou</author>
</authors>
<title>Automatic acronym acquisition and term variation management within domain-specific texts. In In</title>
<date>2002</date>
<booktitle>Proceedings of 3rd International Conference on Language, Resources and Evaluation, LREC-3</booktitle>
<pages>2155--2162</pages>
<location>Las Palmas, Spain</location>
<marker>Nenadic, Spasic, Ananiadou, 2002</marker>
<rawString>G. Nenadic and S. Spasic, I.and Ananiadou. 2002. Automatic acronym acquisition and term variation management within domain-specific texts. In In: Proceedings of 3rd International Conference on Language, Resources and Evaluation, LREC-3, pages 2155–2162, Las Palmas, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Roman</author>
</authors>
<title>La Grammaire de l’arabe</title>
<date>1990</date>
<publisher>PUF</publisher>
<location>Paris</location>
<marker>Roman, 1990</marker>
<rawString>A. Roman. 1990. La Grammaire de l’arabe. PUF, Paris.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I A Sag</author>
<author>F Baldwin</author>
<author>T and Bond</author>
<author>A Copestake</author>
<author>D Flickinger</author>
</authors>
<title>Multiword expressions: A pain in the neck for NLP. In CICLing</title>
<date>2002</date>
<pages>1--15</pages>
<contexts>
<context>-occurrence affinity, b) symbolic approaches using parsers, lexicons and language filters, and c) hybrid approaches combining different methods (Smadja, 1993) (Church and Hanks, 1990) (Daille, 1994) (Sag et al., 2002) (Maynard and Ananiadou, 2000). In practice, most statistical approaches employ linguistic filters to extract candidate MWTs (Church and Hanks, 1990). One of the main problems confronting statistical</context>
<context>uage. Like pure statistical approaches, purely knowledge based symbolic approaches also face problems. They are language dependent and not flexible enough to cope with complex structures of MWTs. As (Sag et al., 2002) suggest, it is important to find the right balance between symbolic and statistical approaches. Our main interest in this paper is the development of a hybrid MWT tool for identifying and extracting</context>
<context>nguistic specifications of Arabic multi-word terms Arabic words are formed with root-pattern schemes. Mutiword terms (MWTs) defined as idiosyncratic interpretations cross word boundaries (or spaces) (Sag et al., 2002). The main property of MWTs is the morphosyntactic one : its structure belongs to well-known morphosyntactic structures such as N ADJ, N1 N2, etc. that have been studied by Roman (1990) for Arabic. 3</context>
</contexts>
<marker>Sag, Baldwin, Bond, Copestake, Flickinger, 2002</marker>
<rawString>I.A. Sag, F. Baldwin, T.and Bond, A. Copestake, and D. Flickinger. 2002. Multiword expressions: A pain in the neck for NLP. In CICLing, pages 1–15.</rawString>
</citation>
</citationList>
</algorithm>

