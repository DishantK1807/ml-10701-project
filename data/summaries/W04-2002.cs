Also, Brants and Crocker’s (2000) model imposes memory restrictions on the parser that are inspired by findings from the human sentence processing literature.
C00-1017
This problem is addressed by Brants and Crocker (2000) and Crocker and Brants (2000), who propose a broad-coverage model of human parsing based on PCFGs.
C00-1017
This means that the corresponding processing theories face a scaling problem: it is not clear how they can explain the normal behavior of the human parser, where sentence processing is highly efficient and very robust (see Crocker and Brants 2000 for details on this scalability argument).
C00-1017
A quick search in the Penn Treebank (Marcus et al., 1993) shows that about 17% of all sentences contain parentheticals or other sentence fragments, interjections, or unbracketable constituents.
J93-2004
Models based on n-grams have already been used successfully to model eye-tracking data, both on a word-by-word basis (McDonald and Shillcock, 2003) and for whole sentences (Keller, 2004).
W04-3241
These models include a standard unlexicalized PCFG parser, a head-lexicalized parser (Collins, 1997), and a maximum-entropy inspired parser (Charniak, 2000).
A00-2018 P97-1003
Some initial results on a limited dataset have been obtained by Baldewein and Keller (2004) for head-final constructions in German.
W04-3241
This finding is in line with Charniak’s own analysis, which shows that the high performance of his model is due to the fact that it combines a thirdorder Markov grammar with sophisticated phrasal and lexical features (Charniak, 2000).
A00-2018
Of particular interest are lexicalized parsing models such as the ones developed by Collins (1996, 1997) and Carroll and Rooth (1998).
P96-1025 P97-1003
Current research on human parsing rarely investigates the issues of efficiency, robustness, and broad coverage, as pointed out by Crocker and Brants (2000).
C00-1017
