Work The idea of employing n-gram co-occurrence statistics to score the output of a computer system against one or more desired reference outputs was first successfully implemented in the BLEU metric for machine translation (Papineni et al., 2002).
P02-1040
(Hildebrandt et al., 2004).
N04-1007
Thevital/okaydistinctiononnuggetsisonemajor source of differences in opinion, as has been pointed out previously (Hildebrandt et al., 2004).
N04-1007
Taken another way, definition questions might be viewed as simultaneously asking a whole series of factoid questions about the same entity (e.g., “When was he born?”, “What was his occupation?”, “Where did he live?”, etc.), except that these questions are not known in advance; see Prager et al.(2004) for an implementation based on this view of definition questions.
P04-1073
933 Recently, Soricut and Brill (2004) employed ngram co-occurrences to evaluate question answering in a FAQ domain; unfortunately, the task differs from definition question answering, making their resultsnotdirectlyapplicable.
P04-1078
The basic idea has been extended to evaluating document summarization with ROUGE (Lin and Hovy, 2003).
N03-1020
Since then, the basic method for scoring translation quality has been improved upon by others, e.g., (Babych and Hartley, 2004; Lin and Och, 2004).
C04-1072 P04-1079
Chin-YewLinandEduardHovy. 2003.
N03-1020
