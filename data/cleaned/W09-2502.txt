Proceedings of the 2009 Workshop on Applied Textual Inference, ACL-IJCNLP 2009, pages 10–17,
Suntec, Singapore, 6 August 2009. c 2009 ACL and AFNLP
A Proposal on Evaluation Measures for RTE
Richard Bergmair
recipient of a DOC-fellowship of the Austrian Academy of Sciences
at the University of Cambridge Computer Laboratory;
15 JJ
Thomson Avenue, Cambridge CB3 0FD, UK;
rbergmair@acm.org
Abstract
We outline problems with the interpreta-
tion of accuracy in the presence of bias,
arguing that the issue is a particularly
pressing concern for RTE evaluation. Fur-
thermore, we argue that average precision
scores are unsuitable for RTE, and should
not be reported. We advocate mutual in-
formation as a new evaluation measure
that should be reported in addition to ac-
curacy and confidence-weighted score.
1 Introduction
Weassumethatthereaderisfamiliarwiththeeval-
uation methodology employed in the RTE chal-
lenge.1 We address the following three problems
we currently see with this methodology.
1. The distribution of three-way gold standard
labels is neither balanced nor representative of an
application scenario. Yet, systems are rewarded
for learning this artificial bias from training data,
while there is no indication of whether they could
learn a different bias.
2. The notion of confidence ranking is mislead-
ing in the context of evaluating a ranking by aver-
age precision. The criteria implicitly invoked on
rankings by the current evaluation measures can,
in fact, contradict those invoked on labellings de-
rived by rank-based thresholding.
3. Languageallowsfortheexpressionoflogical
negation, thus imposing a symmetry on the judge-
ments ENTAILED vs. CONTRADICTION. Average
precision does not properly reflect this symmetry.
In this paper, we will first summarize relevant
aspects of the current methodology, and outline
these three problems in greater depth.
1see the reports on RTE-1 (Dagan et al., 2005), RTE-2
(Bar-Haim et al., 2006), RTE-3 (Giampiccolo et al., 2007),
the RTE-3 PILOT (Voorhees, 2008), RTE-4 (Giampicolo et al.,
2008), and RTE-5 (TAC, 2009)
The problem of bias is quite general and widely
known. Artstein and Poesio (2005) discuss it
in the context of Cohen’s kappa (Cohen, 1960),
which is one way of addressing the problem. Yet,
it has not received sufficient attention in the RTE
community, which is why we will show how it ap-
plies to RTE, in particular, and why it is an espe-
cially pressing concern for RTE.
Average precision has been imported into the
RTE evaluation methodology from IR, tacitly as-
suming a great level of analogy between IR and
RTE. However, we will argue that the analogy is
flawed, and that average precision is not suitable
for RTE evaluation.
Then, we will then reframe the problem in in-
formation theoretic terms, advocating mutual in-
formation as a new evaluation measure. We will
show that it addresses all of the issues raised con-
cerning accuracy and average precision and has
advantages over Cohen’s kappa.
2 The
Structure of RTE Data
Let X be the set of all candidate entailments that
can be formed over a natural language of interest,
such as English. An RTE dataset Xa132X is a set of
N candidate entailments Xa16a116x1,x2,...,xNa117.
The RTE task is characterized as a classifica-
tion task. A given candidate entailment xi can
be associated with either a positive class label triangle
(TRUE / YES / ENTAILED) or a negative class la-
bel triangleinv (FALSE / NO / NOT ENTAILED), but never
both. In the three-way subtask, the positive class,
which we will denote as a96, is defined as before,
but the negative classtriangleinvis further subdivided into
a class a97 (NO / CONTRADICTION) and a class ♦
(UNKNOWN). To model this subdivision, we de-
fine equivalence classesa114a4a1153 anda114a4a1152 on the three-
way labels as follows: a114a96a1153 a16 a96, a114♦a1153 a16 ♦,
a114a97a1153 a16a97,a114a96a1152 a16triangle,a114♦a1152 a16triangleinv, anda114a97a1152 a16triangleinv.
The gold standard G for dataset X is then a la-
belling G : X a222a209 a116a96,♦,a97a117. We call a candidate
10
entailment xi atriangle-instance iffa114Ga112xia113a1152 a16triangle, and
analogously for the other class labels.
The outputa112L,a161a113of an RTE system on dataset
X also contains such a labelling L : X a222a209
a116a96,♦,a97a117, in addition to a strict total order a161 on
X representing a ranking of candidate entailments.
2.1 Logical
Preliminaries
The notation chosen here is inspired by modal
logic. Let’s say a candidate entailment xi were
of the logical form ϕa209ψ. The formula “a5a112ϕa209
ψa113” would then assert that ψ necessarily follows
from ϕ (ENTAILMENT), and the formula “a5a112ϕa209
a32ψa113”,whichwouldbeequivalentto“a32♦a112ϕa94ψa113”,
would mean that we can not possibly have ϕa94ψ
(CONTRADICTION). We think of the former as a
positive form of necessity (a96), and of the latter
as a negative form of necessity (a97). The formula
“♦a112ϕa209ψa113” would assert thatψ possibly follows
fromϕ(UNKNOWN).
We will have to assume that this negation oper-
atora32is in fact within the expressive power of the
natural language of interest, i.e. “ϕa209a32ψ” a80X,
whenever “ϕa209ψ” a80X. It imposes a symmetry
on the two labels a96 and a97, with ♦ being neutral.
Forexample: “Socrates is a man and every man
is mortal; Therefore Socrates is mortal.” Thiscan-
didate entailment is a a96-instance. It corresponds
to the following a97-instance: “Socrates is a man
and every man is mortal; Therefore Socrates is
not mortal”. But then, consider the ♦-instance
“Socratesismortal; ThereforeSocratesisaman”.
Here “Socrates is mortal; Therefore Socrates is
not a man” is still a ♦-instance.
It is this modal logic interpretation which
matches most closely the ideas conveyed by the
task definitions (TAC, 2009), and the annota-
tion guidelines (de Marneffe and Manning, 2007).
However, for the two-way task, they allude more
to probabilistic logic or fuzzy logic, where a can-
didate entailment is a triangle-instance iff it holds to a
higher degree or likelihood or probability than its
negation, and atriangleinv-instance otherwise.
We believe that either a three-way modal logic
entailment task or a two-way probabilistic logic
entailment task on its own could make perfect
sense. However, they are qualitatively different
andnottriviallyrelatedbyequatingtrianglewitha96, and
subdividingtriangleinvinto ♦ and a97.
3 Accuracy
& Related Measures
Both the system and the gold standard apply to the
dataset X a total labelling L and G respectively,
i.e. they are forced to assign their best guess la-
bel to every instance. A degree of agreement can
be determined as a percentage agreement either on
the two-way or the three-way distinction:
A3a0L;Ga8a16 1N
Na184
ia161
1a0a114La112xia113a1153 a16a114Ga112xia113a1153a8,
A2a0L;Ga8a16 1N
Na184
ia161
1a0a114La112xia113a1152 a16a114Ga112xia113a1152a8,
where 1 is a counter which takes on a numerical
value of one, when the logical expression in its ar-
gument is true, and zero otherwise.
The RTE-3 PILOT (Voorhees, 2008) reported
someaccuracymeasuresconditionedongoldstan-
dard labels as follows:
Aa493a0L;G, ga8 a16
a176N
ia1611
a0a114La112x
ia113a1153 a16 a114Ga112xia113a1153 a16 g
a8
a176N
ia1611
a0a114Ga112x
ia113a1153 a16 g
a8 ,
Aa492a0L;G, ga8 a16
a176N
ia1611
a0a114La112x
ia113a1152 a16 a114Ga112xia113a1152 a16 g
a8
a176N
ia1611
a0a114Ga112x
ia113a1152 a16 g
a8 .
Assuming the usual analogy with IR, we note
that Aa492a0L;G,trianglea8 is akin to recall. On the other
hand,Aa492a0G;L,trianglea8, whichconditionsaccuracyon
the system-assigned labels rather than the gold
standard labels, is precision.
The conditioned accuracy measures do not pro-
vide a single summary statistic as the others do.
However,suchasummarycouldbedefinedbytak-
ing the mean across the different labels:
Aa493a0L;Ga8a16 13
a184
ga80a116a96,♦,a97a117
Aa493a0L;G;ga8,
Aa492a0L;Ga8a16 12
a184
ga80a116triangle,triangleinva117
Aa492a0L;G;ga8.
It is instructive to consider a number of trivial
baseline systems. Let Sa96, S♦, and Sa97, be the sys-
tems that uniformly assign to everything the la-
bels a96, ♦, and a97, respectively, so that for all i:
La96a112xia113a16a96, L♦a112xia113a16♦, and La97a112xia113a16a97. Also
consider system Sa11, which assigns labels at ran-
dom, according to a uniform distribution.
The performance of these systems depends on
the distribution of gold-standard labels. The pol-
icy at RTE was to sample in such a way that the re-
sulting two-way labels in the gold standard would
11
be balanced. So 50% of all i had a114Ga112xia113a1152 a16 triangle,
while the other 50% hada114Ga112xia113a1152 a16triangleinv.
This means that all trivial baselines have an ac-
curacy of A2 a16Aa492 a16 50%. If the data were bal-
anced on the three-way labels, which they are not,
we would analogously haveA3 a16Aa493 a1633%.
When interpreting a two-way accuracy, one
would thus expect values between 50% and 100%,
where 50% indicates a trivial system and 100%
indicates a perfect system. A value of, for ex-
ample, 70% could be interpreted as-is, mindful of
the above range restriction, or the range restriction
could be factored into the value by using a linear
transformation. One would then say that the accu-
racy of 70% is 40% of the way into the relevant
range of 50%a1100%, and quote the value as a
Cohen’s Kappa ofκa160.4.
3.1 Bias
While the RTE datasets are balanced on two-way
gold standard labels, they are not balanced on the
three-way gold standard labels. Among the candi-
date entailments xi witha114Ga112xia113a1152 a16triangleinv, in RTE-4,
70% of all xi hada114Ga112xia113a1153 a16 ♦, while only 30%
hada114Ga112xia113a1153 a16a97. In the RTE-3 PILOT, the distri-
bution was even more skewed, at 82%/18%.
So, we observe that Sa96 has A3a112La96;Ga113a16.500
and therefore outperforms two thirds of all RTE-3
PILOT participants and one third of all RTE-4 par-
ticipants. On the other hand, only very few par-
ticipants performed worse than the random choice
systemSa11, whichhadA3a112La11;Ga113a16.394on RTE-
4. The other trivial systems have A3a112L♦;Ga113 a16
.350, followed byA3a112La97;Ga113a16.150 on RTE-4.
The conditioned accuracies seem to promise
a way out, since they provide an artificial bal-
ance across the gold standard labels. We have
Aa493a112La96;Ga113 a16 Aa493a112L♦;Ga113 a16 Aa493a112La97;Ga113 a16 .33.
But this measure is then counter-intuitive in that
the random-choice system Sa11 gets Aa493a112La11;Ga113a16
.394 on RTE-4 and would thus be considered
strictly superior to the system Sa96, which, if noth-
ingelse, atleastreproducestherightbias. Another
caveatisthatthiswouldweigherrorsonrarelabels
more heavily than errors on common labels.
In some form or another the problem of bias ap-
plies not only to accuracy itself, but also to related
statistics, such as precision, recall, precision/recall
curves, and confidence weighted score. It is there-
fore quite general, and there are three responses
which are commonly seen:
1. For purposes of intrinsic evaluation, one can
use samples that have been balanced artificially, as
it is being done in the two-way RTE task. Yet, it is
impossible to balance a dataset both on a two-way
and a three-way labelling at the same time.
2. One can use representative samples and ar-
gue that the biased accuracies have an extrinsic in-
terpretation. For example, in IR, precision is the
probabilitythatadocumentchosenrandomlyfrom
the result set will be considered relevant by the
user. Yet, for RTE, one cannot provide a repre-
sentative sample, as the task is an abstraction over
a number of different applications, such as infor-
mation extraction (IE), question answering (QA),
and summarization (SUM), all of which give rise
to potentially very different distributions of labels.
3. On statistical grounds, one can account for
the possibility of random agreement in the pres-
ence of bias using Cohen’s kappa (Artstein and
Poesio, 2005; Di Eugenio and Glass, 2004). We
will outline mutual information as an alternative,
arguing that it has additional advantages.
4 Average
Precision
The purpose of average precision is to evaluate
against the gold standard labelling G the system-
assigned ranking a161, rather than directly compar-
ing the two labellings G and L.
This is done by deriving from the ranking a161 a
series of binary labellings. The i-th labelling in
that series is that which labels all instances up to
rank i as triangle. A precision value can be computed
for each of these labellings, compared to the same
gold standard, and then averaged.
More formally, a161 is the strict total ordering on
the dataset X which has been produced by the sys-
tem. Let xj a169 xi iff xj a161 xi or xj a16 xi. We
can then associate with each instance xi a numeric
rank, according to its position in a161:
#a161a112xia113a16
Na184
ja161
1a112xj a169 xia113.
We can then define the cutoff labelling a161a112ra113 as
a161a112ra113 a112xia113a16
a35
triangle if #a161a112xia113a164r,
triangleinv otherwise;
and average precision as
aPa112G;a161a113a16 1N
Na184
ra161
Aa492
a1
G;a161a112ra113,triangle
a9
.
12
The system-assigned labelling L and the series
of ranking-based labellingsa161a112ra113 are initially inde-
pendent, but, since both accuracy and average pre-
cision refer to the same gold standard G, we get
the following condition on how L must relate to
a161: We call a system output a112L,a161a113 sound if there
exists a cutoff rankr, such that L equalsa161a112ra113, and
self-contradictory otherwise. This is because, for
a self-contradictory system output, there does not
exist a gold standard for which it would be perfect,
in the sense that both accuracy and average preci-
sion would simultaneously yield a value of 100%.
So far, we avoided the common terminology re-
ferring to a161 as a “confidence ranking”, as the no-
tion of confidence would imply that we force the
system to give its best guess labels, but also allow
it to provide a measure of confidence, in this case
by ranking the instances, to serve as a modality for
the interpretation of such a best guess.
This is not what is being evaluated by average
precision. Here, a system can remain entirely ig-
norant as to what is atriangleor atriangleinv-instance. System-
assignedlabelsdonotenterthedefinition, andsys-
tems are not required to choose a cutoffrto derive
a labelling a161a112ra113. This sort of evaluation is ade-
quate for IR purposes, where the system output is
genuinely a ranking, and it is up to the user to set
a cutoff on what is relevant to them. As for RTE, it
is unclear to us whether this applies.
4.1 Thresholding
In the previous section, we have seen that it is
somewhat misleading to see a161 as a confidence-
ranking on the labelling L. Here, we argue that,
even worse than that, the interpretations of a161 and
L may contradict each other. It is impossible for a
system to optimize its output a112L,a161a113 for accuracy
A2a0G;La8 and simultaneously for average preci-
sionaPa112G;a161a113, while maintaining as a side condi-
tionthattheinformationstatea112L,a161a113remainsound
at all times. We show this by indirect argument.
For the sake of contradiction, assume that the
system has come up with an internal information
state consisting of the ranking a161 and the labelling
L, as a best guess. Also assume that this informa-
tion state is sound.
Let’s assume furthermore, again for the sake of
contradiction, that the system is now allowed to
query an oracle with access to the gold standard in
order to revise the internal information state with
thegoalofimprovingitsperformanceasmeasured
by accuracy, and simultaneously also improving
its performance as measured by average precision.
First, the oracle reveals r, the number of triangle-
instances in the gold standard. Let instance xi at
rank #a161a112xia113 a16 r be correctly classified, and the
instance xj at some rank #a161a112xja113a161ra01 be incor-
rectly classified. So we would have a114La112xia113a1152 a16
La112ra113a161 a112xia113 a16 a114Ga112xia113a1152 a16 triangle, and a114La112xja113a1152 a16
La112ra113a161 a112xja113a16triangleinva24a114Ga112xja113a1152.
Next, the oracle reveals the fact that xj had been
misclassified. In response to that new information,
the system could change the classification and set
La112xja113 a208 triangle. This would lead to an increase in
accuracy. Average precision would remain unaf-
fected, as it is a function of a161, not L.
However, the information state a112L,a161a113 is now
self-contradictory. The ranking a161 would have to
be adapted as well to reflect the new information.
Let’s say xj were reranked by inserting it at some
rank ra49 a164 r. This would lead to all intervening in-
stances, including xi, to be ranked down, and thus
to an increase in average precision.
But, since xi has now fallen below the threshold
r, which was, by definition, the correct threshold
chosen by the oracle, the system would reclassify
it as a114La112xja113a1152 a16 triangleinv, which now introduces a la-
belling error. While average precision would not
react to this relabelling, accuracy would now drop.
So there are two rather counterintuitive con-
clusions concerning the simultaneous application
of accuracy, average precision, and thresholding.
First, accuracy may prefer self-contradictory out-
puts to sound outputs. Second, when soundness is
being forced, average precision may prefer lower
accuracy to higher accuracy labellings.
Again, it should be stressed that RTE is the only
prominent evaluation scheme we know of that in-
sists on this combination of accuracy and average
precision. If we had used precision and average
precision, as in IR, the above argument would not
hold. Also, in IR, average precision clearly domi-
nates other measures in its importance.
4.2 Logical
Symmetry
Besides the above arguments on bias, and on the
contradictions between accuracy and average pre-
cision under a thresholding interpretation, there
is a third problem with the current evaluation
methodology. It arises from the symmetry be-
tween the classesa96anda97which we introduced in
section 2.1. This problem is a direct result of the
13
inherent properties of language and logic, and is,
thus, the argument which is most specific to RTE.
Let Xa16a116x1,x2,...,xNa117be a dataset, and let
a32Xa16a116a32x1,a32x2,...,a32xNa117
be the dataset resulting from the application of
negation to each of the candidate entailments.
Similarly, let G : X a222a209a116a96,♦,a97a117be a gold stan-
dard and for allxa80X, let
a32Ga112a32xa113a16
a36
a39a38
a39a37
a97 if Ga112xa113a16a96,
♦ if Ga112xa113a16♦,
a96 if Ga112xa113a16a97,
and analogously for the system-assigned labels L.
Intuitively, we would now expect the following
of an evaluation measure: A system that produces
the labelling L for dataset X is equivalent, in terms
of the evaluation measure, to a system that pro-
duces labellinga32L for dataseta32X. This is indeed
true for three-way accuracy, where A3a0G;La8 a16
A3a0a32G;a32La8, but it is not true for two-way accu-
racy, where the three-way classes are now lumped
together in a different way.
Also, this symmetry is not present in average
precision, which looks only at positive instances.
Since the set oftriangle-instances ofXand the set oftriangle-
instances ofa32X are disjoint, the two average pre-
cisions aPa112G;a161a113and aPa112a32G;a161a49a113, regardless of
how a161 relates to a161a49, need not be functionally re-
lated. – This makes sense in IR, where the set of
irrelevant and non-retrieved documents must not
enter into the evaluation of a retrieval system. But
it makes no sense for the RTE task, where we do
need to evaluate systems on the ability to assign a
single label to all and only the contradictory can-
didate entailments.
5 Mutual
Information
In this section, we define mutual information as a
possible new evaluation measure for RTE. In par-
ticular, we return to the problem of bias and show
that, like Cohen’s kappa, mutual information does
not suffer from bias. We will then introduce a
new problem, which we shall call degradation. We
showthatCohen’skappasuffersfromdegradation,
but mutual information does not. Finally, we will
extend the discussion to account for confidence.
Recall that an RTE dataset is a set of N candi-
date entailments X a16a116x1,x2,...,xNa117, and let X
be a random variable representing the result of a
random draw from this set. Let Pa112X a16 xia113 be
the probability that xi comes up in the draw. This
could represent, for example, the prior probabil-
ity that a particular question is asked in a question
answering scenario. In the absence of any extrin-
sically defined interpretations, one could set ran-
dom variable X to be uniformly distributed, i.e.
Pa112Xa16xia113a16 1N for alli.
This yields a number of further random vari-
ables: Let G and L be the label Ga112xia113 and La112xia113
respectively, assigned to the candidate xi which
has been drawn at random. As usual, we will be
interested in their joint distribution, and the result-
ing marginals and conditionals.
We give the remaining definitions leading to
mutual information in Figure 1, and will discuss
them by considering the particular contingency ta-
ble in Figure 2 as an example. It also spells out the
information theoretic calculations in detail. Fur-
thermore, we will present corresponding values
for Cohen’s kappa, which should be easy for the
reader to retrace, and thus have been omitted from
the Figure for brevity.
The unconditional entropy Ha112Ga113 serves as a
convenient measure of the hardness of the classi-
fication task itself, taking into account the number
oflabelsandtheirdistributioninthegoldstandard.
In the example, this distribution has been chosen
to match that of the RTE-4 dataset almost pre-
cisely, yielding a value for Ha112Ga113 of 1.4277 bits.
This indicates that it is much harder to guess the
three-way gold standard label of an RTE-4 candi-
date entailment than it is to guess the two-way la-
bel, or the outcome of a toss of a fair coin, which
would both have an entropy of exactly 1 bit. On
the other hand, due to the skewness of the distri-
bution, it is easier to guess this outcome than it
would be if the distribution was uniform, in which
case we would have an entropy of 1.5850 bits.
Similarly, we can calculate a conditional en-
tropy Ha112Ga124La16la113over a conditional distribution
of gold standard labels observed, given that the
system has assigned label l to our randomly cho-
sen candidate entailment. In the example, we have
calculatedavalueof1.0746bitsforHa112Ga124La16a96a113.
So, while the hardness of guessing the correct la-
bel without any additional knowledge is 1.4277, it
will be easier to guess this label correctly once the
system-assigned label is known to be a96.
Our best guess would be to always assign label
a96, which would be successful 50% of the time.
14
Pa112Ga16g,La16la113a16
Na184
ia161
Pa112Xa16xia1131
a1
Ga112xia113a16g a94 La112xia113a16l
a9
; (1)
Pa112Ga16ga113a16
a184
l
Pa112Ga16g,La16la113 (2)
Pa112La16la113a16
a184
g
Pa112Ga16g,La16la113 (3)
Pa112Ga16ga124La16la113a16 Pa112Ga16g,La16la113Pa112La16la113 ; (4)
Ha112Ga113a16a1
a184
g
Pa112Ga16ga113 log
a1
Pa112Ga16ga113
a9
; (5)
Ha112Ga124La16la113a16a1
a184
g
Pa112Ga16ga124La16la113 log
a1
Pa112Ga16ga124La16la113
a9
; (6)
Ha112Ga124La113a16
a184
l
Pa112La16la113Ha112Ga124La16la113; (7)
Ia112G;La113a16Ha112Ga113a1Ha112Ga124La113. (8)
Figure 1: definitions for mutual information Ia112G;La113
20 25 5 Pa112Ga16a96a113
(45) (0) a16.5
9 18 9 Pa112Ga16♦a113
(27) (0) a16.36
1 7 6 Pa112Ga16a97a113
(8) (0) a16.14
Pa112La16a96a113 Pa112La16♦a113 Pa112La16a97a113
a16.3 a16.5 a16.2 Na16100
(.8) (0) (.2)
a1Ha112Ga113a16.5 log2a112.5a113
a0.36 log2a112.36a113
a0.14 log2a112.14a113
a16a11.4277
a1Ha112Ga124La16a96a113a16 2030 log2a1122030a113
a0 930 log2a112 930a113
a0 130 log2a112 130a113
a16a11.0746
a1Ha112Ga124La16♦a113a16 2550 log2a1122550a113
a0 1850 log2a1121850a113
a0 750 log2a112 750a113
a16a11.4277
a1Ha112Ga124La16a97a113a16 520 log2a112 520a113
a0 920 log2a112 920a113
a0 620 log2a112 620a113
a16a11.5395
Ha112Ga124La113a16.3a61.0746
a0.5a61.4277
a0.2a61.5395
a161.3441
a1Ha112Ga124La49 a16a96a113a16 4580 log2a1124580a113
a0 2780 log2a1122780a113
a0 880 log2a112 880a113
a16a11.3280
Ha112Ga124La49a113a16.8a61.3280
a0.2a61.5395
a161.3703
Figure 2: example contingency table and entropy calculations
15
But, among the cases where the system in Figure 2
has assigned label a96, this would be an even better
guess. It would now be correct 66% of the time.
We have gained information about the gold stan-
dard by looking at the system-assigned label.
5.1 Bias
The conditional entropy Ha112Ga124La113 is the expected
value of the conditional entropy Ha112Ga124L a16 la113
across all possible labels l, when, as before, we
draw a candidate entailment at random.
Oneverynoteworthypropertyofthismeasureis
that all of the baseline systems we considered, i.e.
systems assigning constant labels, or systems as-
signing labels at random, would have Ha112Ga124La113a16
Ha112Ga113, since the distribution of gold standard la-
bels given the system labels, in all of these cases,
is the same as the prior distribution. Furthermore,
Ha112Ga113 a16 1.4277 is, in fact, an upper bound on
Ha112Ga124La113. All the trivial baseline systems would
perform at this upper bound level.
At the other extreme end of the spectrum, con-
sider a perfect contingency table, where all the
non-diagonal cells are zero. In this case all the
conditional entropies Ha112Ga124L a16 la113 would be en-
tropies over delta distributions concentrating all
probability mass on a single label. This would
yield a value of Ha112Ga124La113 a16 0, which is a lower
bound for any entropy. – For Cohen’s kappa we
would haveκa161.
The system producing our contingency table
performs worse than this ideal but better than the
baselines, at Ha112Ga124La113a161.3441. One can subtract
Ha112Ga124La113 from the upper bound Ha112Ga113 to obtain
the mutual information Ia112G;La113. It is the infor-
mation gained about G once the value of L is re-
vealed. Itisobviouslystillboundedbetween0and
Ha112Ga113, but is somewhat more intuitive as an evalu-
ation measure, as it restores the basic intuition that
larger values indicate higher performance. – Due
to a surprising result of information theory it also
turns out that Ia112G;La113a16Ia112L;Ga113. This symmetry
is another property one would intuitively expect
when comparing two labellings G and L to each
other, and is also present for accuracy and kappa.
We can compare the behaviour of this measure
to that of accuracy. The accuracy of our exam-
ple system is simply the sum of the diagonal con-
tingency counts, so it scores at 44%, compared
to 50% for the baseline that always assigns la-
bel a96. The new bias-aware framework provides a
quite different point of view. We would now note
that the example system does provide Ia112L;Ga113 a16
0.0836 bits worth of information about G, show-
inganagreementofκa160.1277, comparedtozero
information andκa160 agreement for the baseline.
5.2 Degradation
The numbers in the example have been chosen so
as to illustrate a problem we call degradation. The
conditional distribution Pa112G a16 ga124L a16 ♦a113 is the
same as the unconditional distribution Pa112Ga16ga113,
so when it turns out that L a16 ♦, no additional
information has been revealed about G. But in
information theoretic terms, it is considered good
to know when exactly we know nothing.
What happens if we conflate the labels ♦ anda96
in the system output? In Figure, 2, the numbers in
brackets illustrate this. Previously, the system as-
signed label a96 in 30% of all cases. In those cases,
the system’s choice was relatively well-informed,
asa96actuallyturnedouttobethecorrectgoldstan-
dard label 66% of the time. But now, with the la-
bels conflated, the system chooses a96 in 80% of
the cases; a choice which is now much less well-
informed, as it is correct only 45% of the time.
Mutual information shows a drop from 0.0836
bits down to 0.0262. On the other hand, accuracy
increases from 44% to 51%, and Cohen’s kappa
also increases from 0.1277 to 0.1433. But this is
clearly counter-intuitive. Surely, it must be a bad
thing to conflate a well-informed label with a less
well-informed label, thus obscuring the output to
less certainty and more guesswork.
5.3 Confidence
Ranking
One final issue that has still remained unaddressed
is that of confidence ranking. This takes us back
totheveryfirstprobabilisticnotionweintroduced,
that of a probability distribution Pa112X a16 xia113 gov-
erning the choice of the test-instances xi. The uni-
formdistributionwesuggestedearlierresultsinall
instances carrying equal weight in the evaluation.
But for some applications, it makes sense to
give the system some control over which test-
instances it wants to be tested on, independently
of the question of what results it produces for that
test. – So, from a probabilistic point of view, the
most natural take on confidence would be to have
the system itself output the values Pa112X a16 xia113 as
confidence weights.
This would affect Ha112Ga113, which we previously
introducedasameasureofthedifficultyofthetask
16
facedbythesystem. Butnow,thesystemhassome
control over what task it wants to try and solve.
In an extreme scenario, it could concentrate all its
confidence mass in a single instance. Another sys-
tem might force itself to give equal weight to ev-
ery instance. Clearly, these are two very differ-
ent scenarios, so it seems natural that, as soon as
the issue of confidence enters the scene, the eval-
uation has to consider two dimensions. The un-
conditional entropy Ha112Ga113 would have to be re-
ported for every system, together with the mutual
informationIa112L;Ga113. WhileHa112Ga113wouldmeasure
how effective a system was at using its confidence
weighting as a tool to make the task easier on it-
self, Ia112L;Ga113 would measure how successful the
system ultimately was at the task it set for itself.
The example of a system concentrating all of
its confidence mass in a single instance shows that
the ability to freely choose Pa112X a16 xia113 might not
fit with realistic application scenarios. This leads
to the idea of confidence ranking, where a system
could only rank, not weigh, its decisions, and it
would be up to the evaluation framework to then
assign weights according to the ranks.
For example, one could let
Pa112Xa16xia113a16 Na01a1#a161a112xia113a112Na01a113a6a112Na1232a113.
This would assign a weight of N to the highest-
ranked instance, a weight of N a1 1 to the next,
and continue in this manner down to the instance
at rank N, which would get weight 1. The de-
nominator in the above expression then serves to
normalize this weighting to a probability distri-
bution. Note that, in principle, nothing speaks
against using any other series of weights. Perhaps
further investigation into the application scenarios
of RTE systems will provide an extrinsically moti-
vated choice for such a confidence weighting.
6 Final
Recommendations
Ultimately, our proposal boils down to four points,
which we believe are well-supported by the evi-
dence presented throughout this paper:
1. Additional clarification is needed as to the
logical definitions of the two-way and the three-
way distinction of entailment classes.
2. Accuracy and related evaluation measures
suffer from bias, and thus scores of theoretical
baselines must be reported and compared to sys-
tem scores. These include random choice and
choice of a constant label.
3. Average precision scores are misleading and
should not be reported. The confidence-weighted
score that has been dropped after RTE-1 would
be preferable to average precision, but still suffers
from bias.
4. Mutual information should be reported,
in addition to accuracy and possibly confidence-
weighted score, to account for bias and the degra-
dation problem.
Acknowledgments
I would like to thank the anonymous reviewers and my col-
league Ekaterina Shutova for providing many helpful com-
ments and my supervisor Ann Copestake for reading multiple
drafts of this paper and providing a great number of sugges-
tions within a very short timeframe. All errors and omissions
are, of course, entirely my own. I gratefully acknowledge
financial support by the Austrian Academy of Sciences.
References
Ron Artstein and Massimo Poesio. 2005. Kappa3 = alpha
(orbeta). TechnicalReportCSM-437, UniversityofEssex
Department of Computer Science.
RoyBar-Haim, IdoDagan, BillDolan, LisaFerro, DaniloGi-
ampiccolo, Bernardo Magnini, and Idan Szpektor. 2006.
The second pascal recognising textual entailment chal-
lenge. In Proceedings of the Second PASCAL Challenges
Workshop on Recognising Textual Entailment (RTE-2).
Jacob Cohen. 1960. A coefficient of agreement for nomi-
nal scales. Educational and Psychological Measurement,
20:37–46.
Ido Dagan, Oren Glickman, and Bernardo Magnini. 2005.
The pascal recognising textual entailment challenge. In
Ido Dagan, Oren Glickman, and Bernardo Magnini, ed-
itors, Proceedings of the PASCAL Challenges Workshop
on Recognising Textual Entailment (RTE-1).
Marie-Catherine de Marneffe and Christopher Manning.
2007. Contradiction annotation. http:// nlp.stanford.edu/
RTE3-pilot/ contradictions.pdf.
Barbara Di Eugenio and Michael Glass. 2004. The kappa
statistic: A second look. Computational Linguistics,
30(1):95–101.
Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, and Bill
Dolan. 2007. The third pascal recognising textual en-
tailment challenge. In Proceedings of the Workshop on
Textual Entailment and paraphrasing (RTE-3).
Danilo Giampicolo, Hoa Trang Dang, Bernardo Magnini, Ido
Dagan, and Bill Dolan. 2008. The fourth pascal recogniz-
ing textual entailment challenge. In Preproceedings of the
Text Analysis Conference (TAC).
TAC. 2009. Tac2009 rte-5 main task guide-
lines. http:// www.nist.gov/ tac/ 2009/ RTE/
RTE5 Main Guidelines.pdf.
Ellen M. Voorhees. 2008. Contradictions and justifications:
Extensions to the textual entailment task. In Proceedings
of ACL-08: HLT, pages 63–71.
17

