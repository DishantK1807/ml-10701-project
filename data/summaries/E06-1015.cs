On the one hand, SSTs provide learning algorithms with richer information which may be critical to capture syntactic properties of parse trees as shown, for example, in (Zelenko et al., 2003; Moschitti, 2004).
P04-1043
For this purpose, we slightly modified the kernel function proposed in (Collins and Duffy, 2002) by introducing a parameter σ which enables the ST or the SST evaluation.
P02-1034
It should be noted that our results of kernel combinations on FrameNet are in contrast with (Moschitti, 2004), where no improvement was obtained.
P04-1043
1 as presented in (Collins and Duffy, 2002).
P02-1034
We used the default linear (Linear) and polynomial (Poly) kernels for the evaluations with the standard features defined in (Gildea and Jurafsky, 2002).
J02-3001 P02-1031
When σ = 1, ∆(n1,n2) evaluates the number of SSTs common to n1 and n2 as proved in (Collins and Duffy, 2002).
P02-1034
In (Collins and Duffy, 2002), the SST tree kernel was experimented with the Voted Perceptron for the parse-tree reranking task.
P02-1034
In (Gildea and Jurafsky, 2002) seven different features2, which aim to capture the relation between the predicate and its arguments, were proposed.
J02-3001 P02-1031
Set-up We used two different corpora: PropBank (www.cis.upenn.edu/∼ace) along with PennTree bank 2 (Marcus et al., 1993) and FrameNet.
J93-2004
(Gildea and Jurafsky, 2002; Pradhan et al., 2004).
J02-3001 P02-1031
In (Kazama and Torisawa, 2005), an interesting algorithm that speeds up the average running time is presented.
H05-1018
Note that, since the FrameNet data does not include deep syntactic tree annotation, we processed the FrameNet data with Collins’ parser (Collins, 1997), consequently, the experiments on FrameNet relate to automatic syntactic parse trees.
P97-1003
In (Culotta and Sorensen, 2004) such kernels were slightly generalized by providing a matching function for the node pairs.
P04-1054
In (Shen et al., 2003), a tree-kernel based on Lexicalized Tree Adjoining Grammar (LTAG) for the parse-reranking task was proposed.
W03-1012
(Gildea and Palmer, 2002; Pradhan et al., 2004).
J02-3001 P02-1031
Moreover, by combining polynomial and SST kernels, we can improve the classification accuracy (Moschitti, 2004), i.e. tree kernels provide the learning algorithm with many relevant fragments which hardly can be designed by hand.
P04-1043
Regarding the classification properties, we studied the argument labeling accuracy of ST and SST kernels and their combinations with the standard features (Gildea and Jurafsky, 2002).
J02-3001 P02-1031
Third, we point out that the polynomial kernel on flat features is more accurate than tree kernels but the design of such effective features required noticeable knowledge and effort (Gildea and Jurafsky, 2002).
J02-3001 P02-1031
In recent years tree kernels have been shown to be interesting approaches for the modeling of syntactic information in natural language tasks, e.g. syntactic parsing (Collins and Duffy, 2002), relation extraction (Zelenko et al., 2003), Named Entity recognition (Cumby and Roth, 2003; Culotta and Sorensen, 2004) and Semantic Parsing (Moschitti, 2004).
P02-1034 P04-1043 P04-1054
An alternative tree kernel representation, proposed in (Moschitti, 2004), is the selection of the minimal tree subset that includes a predicate with only one of its arguments.
P04-1043
However, as observed in (Collins and Duffy, 2002) this worst case is quite unlikely for the syntactic trees of natural language sentences, thus, we can design algorithms that run in linear time on average.
P02-1034
Unfortunately, the ST set is rather poorer than the one generated by the subset tree (SST) kernel designed in (Collins and Duffy, 2002).
P02-1034
