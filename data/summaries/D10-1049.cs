We use the model of Liang et al. (2009) to im-
P09-1011
A. Koller and K. Striegnitz. 2002. Generation as de-
P02-1003
lection, Barzilay and Lee (2004) use an approach
N04-1015
K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002.
P02-1040
R. Soricut and D. Marcu. 2006. Stochastic language
P06-1139
model of Liang et al. (2009). In the example in Fig-
P09-1011
Aoife Cahill and Josef van Genabith. 2006. Robust pcfg-
P06-1130
Liang et al. (2009) to automatically produce aligned
P09-1011
to that of Liang et al. (2009). On ROBOCUP and
P09-1011
and LFG (Cahill and van Genabith, 2006).
P06-1130
R. Turner, Y. Sripada, and E. Reiter. 2009. Gener-
W09-0607
tion from a PCFG-like grammar. Lu et al. (2009)
D09-1042
parkhi (2002), Wong and Mooney (2007), Chen and
P07-1121
Mooney (2008), Lu et al. (2009), etc.) are typically
D09-1042
P. Liang, M. I. Jordan, and D. Klein. 2009. Learning
P09-1011
Liang et al. (2009) introduces a generative model
P09-1011
W. Lu, H. T. Ng, and W. S. Lee. 2009. Natural lan-
D09-1042
Y. W. Wong and R. J. Mooney. 2007. Learning syn-
P07-1121
R. Barzilay and L. Lee. 2004. Catching the drift: Prob-
N04-1015
over the fields; in contrast, Liang et al. (2009) gen-
P09-1011
tent selection (Barzilay and Lee, 2004) and surface
N04-1015
model of Liang et al. (2009) to automatically induce
P09-1011
and Lee (2004), Foster and White (2004), inter alia)
W04-0601
Belz and Kow (2009) also perform surface realiza-
W09-0603
al. (2003), Green (2006), Turner et al. (2009), Re-
W06-1417 W09-0607
A. Belz and E. Kow. 2009. System building cost vs.
W09-0603
the generative model of Liang et al. (2009)
P09-1011
M. E. Foster and M. White. 2004. Techniques for text
W04-0601
N. Green. 2006. Generation of biomedical arguments for
W06-1417
optimal text. Koller and Striegnitz (2002) perform
P02-1003
(White et al., 2007), HPSG (Nakanishi et al., 2005),
W05-1510
We used the dataset created by Liang et al. (2009).
P09-1011
