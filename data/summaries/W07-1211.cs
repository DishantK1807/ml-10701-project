In addition, Sudo et al.(2003) only generated subtrees which appeared in at least three documents.
P03-1029
Another group of research attempts to classify a particular MWE subtype, such as verb-particle constructions (VPCs) or LVCs, according to some fine-grained semantic criteria (Wanner, 2004; Uchiyama et al., 2005; Cook and Stevenson, 2006).
W06-0202
In previous work (Alishahi and Stevenson, 2005), we have proposed a usage-based computational model of early verb learning that uses Bayesian clustering and prediction to model language acquisition and use.
P05-1047
We take the semantic category of a noun to be the ancestor of its first sense in the hypernym hierarchy of WordNet 2.1, cut at the level of the children 1Our preliminary experiments on development data from Fazly and Stevenson (2006) revealed that the cosine measure and a window size of 5 words resulted in the best performance.
W06-0202
For example the patterns used by Yangarber et al.(2000) are the subject-verb-object tuples from the dependency tree (the remainder of the dependency parse is discarded) while Sudo et al.(2003) allow any subtree within the dependency parse to act as an extraction pattern.
A00-1039 P03-1029
However, Stevenson and Greenwood (2006) also found that the coverage of the chain model was significantly worse than the subtree model, although Sudo et al.83 (2003) found that in some cases their performance could not be distinguished.
P03-1029 W06-0202
In their work on automatically identifying idiom types, Fazly and Stevenson (2006)?henceforth FS06?show that an idiomatic VNC tends to have one (or at most a small number of) canonical form(s), which are its most preferred syntactic patterns.
W06-0202
Stevenson and Greenwood (2006) compared the four pattern models described in Section 2 in terms of their complexity and ability to represent relations found in text.
W06-0202
Approaches evaluated so far make use of dictionaries with semantic annotation (Piao et al., 2006), WordNet (Pearce, 2001), automatically generated thesauri (Lin, 1999; McCarthy et al., 2003; Fazly and Stevenson, 2006), vector-based methods that measure semantic distance (Baldwin et al., 2003; Katz and Giesbrecht, 2006), translations extracted from parallel corpora (Villada Moiron and Tiedemann, 2006) or hybrid methods that use machine learning techniques informed by features coded using some of the above methods (Venkatapathy and Joshi, 2005).
W06-0202
Figure 1 shows an example of the hypernyms for dinner, and its resulting set of semantic properties.1 The following sections review basic properties of the model from Alishahi and Stevenson (2005, 2007), and introduce extensions that give the model its ability to make verb-based predictions.
P05-1047
(Although the set of unfiltered subtree patterns were not generated it is possible to determine the number of patterns which would be generated using a process described by Stevenson and Greenwood (2006).) Model Filtered Unfiltered SVO 9,189 23,128 Chains 16,563 142,019 Linked chains 23,452 493,463 Subtrees 369,453 1.69 1012 Table 1: Number of patterns generated by each model It can be seen that the various pattern models generate vastly different numbers of patterns and that the number of subtrees is significantly greater than the other three models.
W06-0202
Stevenson. 2006.
W06-0202
For example, Kudo et al.(2005) used subtrees for parse ranking but could only generate subtrees which appear at least ten times in a 40,000 sentence corpus.
P05-1024
Predicate-Argument Model (SVO): A simple approach, used by Yangarber et al.(2000), Yangarber (2003) and Stevenson and Greenwood (2005), is to use subject-verb-object tuples from the dependency parse as extraction patterns.
A00-1039 P03-1044 P05-1047
Kudo et al.(2005) and Sudo et al.(2003) both used the rightmost extension algorithm to generate subtrees.
P03-1029 P05-1024
However, this is not necessary since Sudo et al.(2003) showed that adequate knowledge about document relevance could be obtained automatically using an IR system.
P03-1029
Subtrees: The final model to be considered is the subtree model (Sudo et al., 2003).
P03-1029
Chains: A pattern is defined as a path between a verb node and any other node in the dependency tree passing through zero or more intermediate nodes (Sudo et al., 2001).
H01-1009
Sudo et al.(2003) found that it was important to find the appropriate balance between these two factors.
P03-1029
Nonetheless, the mentioned characteristics are useful indicators to distinguish literal and idiomatic expressions (Fazly and Stevenson, 2006).
W06-0202
Many researchers have recently developed methods for the automatic acquisition of various properties of MWEs from corpora (Lin, 1999; Krenn and Evert, 2001; Baldwin et al., 2003; McCarthy et al., 2003; Venkatapathy and Joshi, 2005; Villada Moiron and Tiedemann, 2006; Fazly and Stevenson, 2006).
W06-0202
We then evaluate our model through two tasks of simulating verb-argument plausibility judgment, and analyzing the implicit object alternation, following Resnik (1996).3 4.1 The Training Data In earlier work (Alishahi and Stevenson, 2005, 2007), we used a method to automatically generate training data with the same distributional properties as the input children receive.
P05-1047
Stevenson and Greenwood (2006) also analysed the representational power of each model by measuring how many of the relations found in a standard IE corpus they are expressive enough to represent.
W06-0202
We compared each of the patterns models described in Section 2 using an unsupervised IE experiment similar to one described by Sudo et al.(2003). Let D be a corpus of documents and R a set of documents which are relevant to a particular extraction task.
P03-1029
Fazly and Stevenson (2006) use lexical and syntactic fixedness as partial indicators of noncompositionality.
W06-0202
Stevenson and Greenwood (2006) showed that the choice of pattern model has important implications for IE algorithms including significant differences between the various models in terms of their ability to identify information of interest in text.
W06-0202
Fazly and Stevenson (2006) propose a measure for detecting the syntactic fixedness of English verb phrases of the same variety as us.
W06-0202
The potential MWEs that are extracted with the fully unsupervised method described above and with Fazly and Stevenson?s (2006) method (FS from here onwards) are automatically evaluated by comparing the extracted list to handcrafted MWE databases.
W06-0202
We also make use of this property in an MWE token classification task, but in addition, we draw on other salient characteristics of MWEs which have been previously shown to be useful for their type classification (Evert et al., 2004; Fazly and Stevenson, 2006).
W06-0202
Similar to Lin (1999), McCarthy et al.(2003) and Fazly and Stevenson (2006), our method makes use of automatically generated thesauri; the technique used to compile the thesauri differs from previous work.
W06-0202
Tuning The value of  in equation 1 was set using a separate corpus from which the patterns were generated, a methodology suggested by Sudo et al.(2003). To generate this additional text we used the Reuters Corpus (Rose et al., 2002) which consists of a year?s worth of newswire output.
P03-1029
This model can identify information which is expressed using simple predicate-argument constructions such as the relation between Acme and Smith 1The formalism used for representing dependency patterns is similar to the one introduced by Sudo et al.(2003). Each node in the tree is represented in the format a[b/c] (e.g.
P03-1029
Combining our semantics-based approach with other extraction techniques such as the syntactic fixedness measure proposed by Fazly and Stevenson (2006) might improve the results significantly.
W06-0202
Sudo et al.(2003) compared three models (SVO, chains and subtrees) on two IE scenarios using a entity extraction task.
P03-1029
(Yangarber et al., 2000; Yangarber, 2003; Stevenson and Greenwood, 2005)) and are unlikely to cope with very large sets of candidate patterns.
A00-1039 P03-1044 P05-1047
& Evaluation 4.1 Quantitative evaluation In this section, we quantitatively evaluate our method, and compare it to the lexical and syntactic fixedness measures proposed by Fazly and Stevenson (2006).
W06-0202
More recently researchers have begun to employ deeper syntactic analysis, such as dependency parsing (Yangarber et al., 2000; Stevenson and Greenwood, 2005; Sudo et al., 2001; Sudo et al., 2003; Yangarber, 2003).
A00-1039 H01-1009 P03-1029 P03-1044 P05-1047
The small amount of previous work on the identification of syntactic fixedness (Wermter and Hahn (2004), Fazly and Stevenson (2006)) has either focused on a single variation variety, or has only been evaluated for combinations of a small preselected list of words, presumably due to noise.
W06-0202
Pre41 vious work on the identification of MWE types, however, has found other properties of MWEs, such as their syntactic fixedness, to be relevant to their identification (Evert et al., 2004; Fazly and Stevenson, 2006).
W06-0202
Work Various properties of MWEs have been exploited in developing automatic identification methods for MWE types (Lin, 1999; Krenn and Evert, 2001; Fazly and Stevenson, 2006).
W06-0202
Fixedness To measure fixedness, we use statistical measures of lexical, syntactic, and overall fixedness that we have developed in a previous study (Fazly and Stevenson, 2006), as well as some new measures we introduce here.
W06-0202
Determiners have been shown to be very informative in recognizing the idiomaticity of MWE types, as they are incorporated in the patterns used to automatically determine canonical forms (Fazly and Stevenson, 2006).
W06-0202
