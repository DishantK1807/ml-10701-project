Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 21–24,
Columbus, Ohio, USA, June 2008. c©2008 Association for Computational Linguistics
Dialect Clasification for online podcasts fusing Acoustic and Language 
based Structural and Semantic Information 
 
Rahul Chituri, John. H.L. Hansen
1
 
Center for Robust Speech Systems(CRSS) 
Erik Jonson Schol of Engineering and Computer Science 
University of Texas at Dallas 
Richardson, Texas 75080, U.S.A 
{rahul.ch@student, john.hansen@}utdallas.edu 
Abstract 
The variation in spech due to dialect is a factor 
which significantly impacts spech system per-
formance. In this study, we investigate effective 
methods of combining acoustic and language in-
formation to take advantage of (i) speaker based 
acoustic traits as wel as (ii) content based word 
selection acros the text sequence. For acoustics, 
a GM based system is employed and for text 
based dialect clasification, we proposed n-gram 
language models combined with Latent Seman-
tic Analysis (LSA) based dialect clasifiers. The 
performance of the individual clasifiers is es-
tablished for the three dialect family case (DC 
rates vary from 69.1%-72.4%). The final com-
bined system achieved a DC acuracy of 79.5% 
and significantly outperforms the baseline 
acoustic clasifier with a relative improvement 
of 30%, confirming that an integrated dialect 
clasification system is effective for American, 
British and Australian dialects. 
1 Introduction

Automatic Dialect Clasification has recently gained 
substantial interest in the spech procesing comu-
nity (Gray and Hansen, 205; Hansen et al., 204; 
NIST LRE 205). Dialect clasification systems have 
ben employed to improve the performance for 
Automatic Spech Recognition (ASR) by employing 
dialect dependent acoustic and language models (Di-
akoloukas et al., 197) and for Rich Indexing of Spo-
ken Document Retrieval Systems(Gray and Hansen 
2005). (Huang and Hansen, 205; 206) focused on 
identifying pronunciation diferences for dialect clas-
sification. In this study, unsupervised MFC based 
GMM clasifiers are employed for pronunciation 
modeling. However, English dialects difer in many 
ways other than pronunciation like Word Selection 
and Gramar, which canot be modeled using frame 
based GM acoustic information. For example, 
 
 
1
This project was funded by AFRL under a subcontract to 
RADC Inc. under FA8750-05-C-0029 
 
word selection diferences between UK and US dia-
lects such as “lory” vs. “truck”, “lift”, vs. “eleva-
tor”, etc. Australian English has its own lexical terms 
such as tucker (fod), outback (wildernes), etc (John 
Laver, 194). N-gram language models are employed 
to adres these problems. One aditional factor in 
which dialects difer is in Semantics. For example, 
momentarily which means for a moments duration 
(UK) vs. in a minute or any minute now (US). The 
sentence “This flight wil be leaving momentarily” 
could represent diferent time duration in US vs. UK 
dialects (John Laver, 194). Latent Semantic Analy-
sis is a technique that can distinguish these differ-
ences (Landauer et al.,198). LSA has ben shown to 
be efective for NLP based problems but has yet to be 
aplied for dialect clasification. Therefore, we de-
velop an aproach that uses a combination with n-
gram language modeling and LSA procesing to 
achieve efective language based dialect clasifica-
tion acuracy. Sec 4 explains the baseline acoustic 
clasifier. Language clasifiers are described in Sec 5 
and the results which are presented in Sec 6 afirm 
that combining various sources of information sig-
nificantly outperforms the traditional (or individual) 
techniques used for dialect clasification. 
2 Online
Podcast Database 
The spech comunity has no formal corpus of audio 
and text acros dialects of comon languages that 
could adres the problems discused in Sec.1. It was 
sugested in (Huang and Hansen, 207) that it is 
more probable to observe semantic diferences in the 
spontaneous text and spech rather than formal 
newspapers or prepared speches since they must 
transcend dialects of a language (Hasegawa-Johnson 
and Levinson, 206; Antoine 196). Therefore, we 
colected a database from web based online podcasts 
of interviews where people talk spontaneously. All 
these are already ben transcribed in order to separate 
text and audio structure and to temporarily set aside 
automatic spech recognition (ASR) eror. These 
podcasts are not transcribed with an exact word to 
21
word match but they match the audio to an extent that 
include what the speakers intended to say. The lan-
guage and Acoustic statistics of this database are de-
scribed in Sec 2.1, and 2.2. 
2.1 Language
Statistics 
Huang and Hansen observed that the best dialect 
clasification acuracy for N-gram clasification re-
quires at least 30 text words to obtain reasonable 
performance (Huang and Hansen, 207). So, these 
interviews are segmented into blocks of text with an 
average text of 30 words. Table 1 sumarizes the 
text material for thre family-tre branches of Eng-
lish, containing 474k words and 1325 documents. 
 
No. of Documents Dialect No.of 
words 
Train Test 
US English 200k 383 158 
UK English 154k 288 122 
AU English 120k 233 141 
Table 1: Language Statistics 
2.2 Acoustic
Statistics 
We note that the data colected from online podcasts 
is not wel structured. The audio data is segmented 
into smaler audio segment files since we are inter-
ested in 30 word blocks. Since the colection of dia-
lect podcasts are colected from a wide range of 
online sources, we asume that chanel efects and 
recording conditions are normalized acros these 
thre dialects. We also note that there is no speaker 
overlap between the test and train data. Therefore, 
there are no aditional acoustic clues other than dia-
lect. Table 2 sumarizes the acoustic content of the 
corpus with 231 speakers and 13.5 hrs of audio. 
 
No. of Hours Dialect Males Females 
Train Test 
US English 48 37 3.2 1.7 
UK English 40 32 2.3 1 
AU English 36 38 3.3 2 
Table 2: Acoustic Statistics 
3 System
Architecture 
The system architecture is shown in Fig 1, which 
consists of two main system phases for acoustic and 
language clasifiers. MFC based clasifiers are used 
for acoustic modeling, while for language modeling, 
we use a combination of n-gram language modes and 
LSA clasifiers. In the final phase, we combine the 
acoustic and language clasifiers into our final dialect 
clasifier. To construct the overal system, we first 
train the individual clasifiers, and then set the 
weights of the hybrid clasifiers using a gredy strat-
egy to form the overal decision. 
4 Baseline
Acoustic Dialect Clasification 
GMM based acoustic clasification is a popular 
method for text-independent dialect clasification 
(Huang and Hansen, 206) and therefore it is used as 
a baseline for our system. Fig. 2 shows the block dia-
gram of the baseline gender-independent MFC 
based GM training system with 60 mixtures for 
each dialect. While testing, the incoming audio is 
clasified as a particular dialect based on the maxi-
mum posterior probability measure over al the Gaus-
sian Mixture Models. Mixture and frame selection 
based techniques as wel as SVM-GM hybrid tech-
niques have ben considered for dialect clasification 
(Chituri and Hansen, 207). In order to ases the 
improvement by leveraging audio and text, we did 
not include these audio clasification improvements 
in this study. 
5 Dialect
Clasification using Language 
As shown in Fig 1, the language based dialect clasi-
fication module has two distinct clasifiers. We de-
scribe in detail the n-gram and LSA based clasifiers 
in the sections 5.1 and 5.2 
5.1 N-gram based dialect clasification 
It is asumed that the text document is composed of 
many sentences. Each sentence can be regarded as a 
sequence of words W. The probability of generating 
W is given by . Assum-
ing the probability depends on the previous n words 
is 
 
where m is 
the number of words in W, w
i
 is the word and D 
{UK, US, AU) is the dialect specific language model. 
The n-gram probabilities are calculated from ocur-
rence counting. The final clasification decision is 
given by C= , where ϕ is a set of 
sentences in a document and D  {UK, US, AU}. In this 
study, we use the derivative measure of the cros en-
tropy known as the test set perplexity for dialect clas-
sification. If the word sequence is suficiently long, 
the cros entropy of the word sequence W is ap-
proximated as . The per-
plexity of the test word sequence W as it relates to 
the language model D is  
.The perplexity of the test word se-
quence is the generalization capability of the lan-
guage model. The smaler the perplexity, the beter 
22
the language model generalizes to the test word se-
quence. The final clasification decision is, 
C=  , where  is the set of 
sentences in a document, D   {UK, US, AU}.
 
 
Figure 1: Proposed architecture 
 
 
 
 
 
Figure 2: Baseline GM based dialect clasification 
5.2 Latent
Semantic Analysis for Dialect ID 
One aproach used to adres topic clasification 
problems has ben latent semantic analysis (LSA), 
which was first explored for document indexing in 
(Derwester et al., 190). This adreses the isues of 
synonymy many ways to refer to the same idea and 
polysemy – words having more than one distinct 
meaning. These two isues present problems for dia-
lect clasification as two conversations about a topic 
ned not contain the same words and conversely two 
conversations about diferent topics may contain the 
same words but with diferent intended meanings. In 
order to find a diferent feature space which avoids 
these problems, singular value decomposition (SVD) 
is performed to derive orthogonal vector representa-
tions of the documents. SVD uses eigen-analysis to 
derive linearly independent directions of the original 
term by document matrix A whose columns core-
spond to the number of dialects, while the rows cor-
respond to the words/terms in the entire text database. 
SVD decomposes this original term document matrix 
A, into thre other matrices: A=U*S*V
T, where the 
columns of U are the eigenvectors of AA
T
 (left ei-
genvectors), S is a diagonal matrix, whose diagonal 
elements are the singular values of A, and the col-
umns of V are the eigenvectors of A
T
A(caled right 
eigenvectors). The new dialect vector cordinates in 
this reduced 3 dimensional space are the rows of V. 
The cordinates of the test uterance is given by 
q1=q
T
*U*S
-1
. The test uterance is then clasified as 
a particular dialect based on the scores, given by the 
cosine similarity measure as  , where d
i
 is one of the thre dialects. 
6 Results
and Discusion 
All evaluations presented in this section were con-
ducted on the online podcast database described in 
the section 2. The first row of Table 3 shows the per-
formance of the N-gram LM based dialect clasifica-
tion (69.1% avg. performance). From this we observe 
that this aproach is god for US and UK, but not as 
efective for AU family dialect clasification, with 
AU being confused with UK. The performance of the 
LSA based dialect clasification is shown in the sec-
ond row of Table 3. This clasifier is consistent over 
al the dialects with beter performance than the N-
gram LM aproach. There is more semantic similar-
ity of US with AU than UK (24% vs 5% false posi-
tives), while UK has a balanced semantic eror with 
US and AU. This implies that there is more semantic 
information in these dialects than text sequence struc-
ture. 
 
Next, the N-gram and the LSA clasifiers are com-
bined using optimal weights based on a gredy ap-
proach. Fig. 3 shows the performance of this hybrid 
clasifier with respect to the weights of the individual 
clasifiers (N-gram vs LSA: 0al N-gram, 500.5 
N-gram and 0.5 LSA, 10 al LSA). After seting 
the optimal weights 0.18 to LSA and 0.82 to N-gram 
clasifier, the hybrid clasifier is sen to be consistent 
and beter than the individual clasifiers (Table 3: 
row 3 vs row2/row1). Performance of the hybrid 
clasifier is not as god as the LSA clasifier for AU 
clasification, but significantly beter for clasifica-
tion of US and UK. The hybrid clasifier is beter in 
al cases when compared to the N-gram clasifier, 
with an overal average improvement of 7.3% abso-
lute. The fourth row in Table 3 shows the perform-
ance of acoustic based dialect clasification which is 
as god as the language based dialect clasification, 
but it is noted that performance is por for UK clasi-
fication. It is expected that the type of erors made by 
text (word selection), semantics and acoustic space 
MFCC based 
Acoustic 
GM Clasifier 
Text 
Audio 
N-Gram 
Clasifier 
LSA 
Clasifier 
 
Language 
Clasifier 
Online 
Podcasts 
Final Hybrid Acoustic & 
Language Clasifier 
GM1 
Chose 
Maximum 
Likelihod 
GM2 
 
0 
0 
0 
0 
Silence 
Remover 
Feature 
Extraction 
 
Input 
Audio 
GM n 
23
wil have diferences and therefore we combine these 
acoustical and language clasifiers as shown in Fig1. 
The overal performance of the proposed aproach, 
combining the acoustic and language information, is 
beter than the individual clasifiers (Row 3 and Row 
4 vs. Row 5 of Table 3). Even though the perform-
ance for US is reduced from 87.2% to 86.38%, the 
clasification of UK is improved significantly from 
54% to 74%. This shows that this aproach is more 
consistent with acuracy that outperforms traditional 
acoustic clasifiers with a relative improvement of 
30%. With respect to a language only clasifier, this 
hybrid clasifier is beter in al the cases. 
7 Conclusions

In this study, we have developed a dialect clasifica-
tion (DC) algorithm that adreses family branch DC 
for English (US, UK, AU), by combining GM 
based acoustic, and text based N-gram LM and LSA 
language information. In this paper, we employed 
LSA in combination with N-gram language models 
and GMM acoustic models to improve DC acuracy. 
The performance of the individual clasifiers were 
shown to vary from 69.1%-72.4%. The final com-
bined system achieves a DC acuracy of 79.5% and 
significantly outperformed the baseline acoustic clas-
sifier with a relative improvement of 30%, confirm-
ing that an integrated dialect clasification system 
employing GM based acoustic and N-gram LM, 
LSA based language information is efective for dia-
lect clasification. 
 
Figure 3: Language clasifier 

References 

Diakoloukas, V.; Neumeyer, L.; Kaja, J.; 197. “Develoment of dialect-specific spech recognizers using adaptation methods” IEEICASP 

John Laver; 194. “Principles of Phonetics”. CambridgeUniversity Pres, Cambridge, UK. 

Gray, S.; Hansen, J.H.L; 2005. “An integrated aproach to  the detection and clasification of /dialects for a spoken  document retrieval system” IEEASRU 

Huang R; Hansen J.H.L.; 205. "Dialect/Acent Clasification via Bosted Word Modeling," IEE-ICASP 

Landauer,T.K., Foltz,P.W., & Laham,D; 198. " Introduction to Latent Semantic Analysis " Discourse Proceses,  25, 259-284. 

Huang R; Hansen J.H.L.207 "Dialect Clasification on  Printed Text using Perplexity Measure and Conditional  Random Fields," IEEICASP 

Hasegawa-Johnson M, Levinson S.E, 206 "Extraction of  pragmatic and semantic salience from spontaneous  spoken English " Spech Com. Vol. 48(3-4) 

Antoine, J.-Y 196 " Spontaneous spech and natural language procesing. ALPES: a robust semantic-led parser " ICSLP 

Derwester.S. et al.190." Indexing by latent semantic anlysis " Journal of American Society of Information  Science, 391–407. 

Chituri. R, Hansen J.H.L, 207." Multi stream based Dialect clasification using SV-GM hybrids" IEE-ASRU 

Huang. R, Hansen J.L.H.; 206. “Gausian Mixture Seletion and Data Selection for Unsupervised Spanish Dialect Clasification” ICSLP 

Hansen J.H.L., Yapanel.U, Huang.R., Ikeno.A.; 204. “Dialect Anal'ysis and Modeling for Automatic Clasification” ICSLP NISTLRE 205,” Language Recognition Evaluation”24

