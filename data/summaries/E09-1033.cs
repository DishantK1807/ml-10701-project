investigated in (Atterer and Sch¨utze, 2007) for
J07-4002
Franz J. Och. 2003. Minimum error rate training in
J03-1002 P03-1021
David Yarowsky and Grace Ngai. 2001. Inducing mul-
N01-1026
Mark Hopkins and Jonas Kuhn. 2006. A framework
W06-2002
parses from the BitPar parser (Schmid, 2004) and
C04-1024
Eugene Charniak and Mark Johnson. 2005. Coarse-
P05-1022
Chris Quirk and Simon Corston-Oliver. 2006. The im-
W06-1608
work were published. Burkett and Klein (2008)
D08-1092
inative reranking (see also (Riezler et al., 2002)).
P02-1035
Shailly Goyal and Niladri Chatterjee. 2006. Parsing
P06-2039
Franz J. Och and Hermann Ney. 2003. A systematic
J03-1002 P03-1021
set of all possible analyses (Charniak et al., 1998;
W98-1115
ilar to self-training (McClosky et al., 2006).
N06-1020
(Brown et al., 1993), as implemented in GIZA++
J93-2003
Klein and Manning, 2003). BitPar is particularly
N03-1016
Och (2003) has described an efficient exact one-
J03-1002 P03-1021
Helmut Schmid. 2004. Efficient parsing of highly am-
C04-1024
parse reranking see Charniak and Johnson (2005).
P05-1022
(see (Och, 2003)). In step 9 the algorithm per-
J03-1002 P03-1021
Hopkins and Kuhn (2006) conducted research
W06-2002
the English Penn treebank (Marcus et al., 1993)
J93-2004
Alexander Fraser and Daniel Marcu. 2007. Measuring
J07-3002
Dan Klein and Christopher Manning. 2003. A* pars-
N03-1016
Michaela Atterer and Hinrich Sch¨utze. 2007. Preposi-
J07-4002
Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003.
J03-1002 N03-1017 P03-1021
(Och and Ney, 2003). As is standard practice, we
J03-1002 P03-1021
David Burkett and Dan Klein. 2008. Two lan-
D08-1092
