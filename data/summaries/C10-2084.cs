MERT (Och, 2003) is used to train feature 
P03-1021
ITG formalism (Cherry and Lin, 2007; Haghighi 
W07-0403
Zhang and Gildea (2005) show that Model 1 
P05-1059
(Haghighi, et al., 2009), W-ITG as baselines. 
P09-1104
phrase-based SMT (Chiang, 2007) is proved to 
J07-2003
(Liu et al., 2005; Moore, 2006): 
P05-1057 P06-1065
inherited from Wu (1997). Rules (4) divide the 
J97-3002
like EM. Inspired by Fraser et al. (2006), we 
P06-1097
(Fraser and Marcu, 2006). 
P06-1097
same as that in Haghighi et al. (2009). The 491 
P09-1104
alignment community (Zhang et al., 2005; 
P05-1059
Wu, Dekai. 1997. Stochastic Inversion Transduction 
J97-3002
like Cherry and Lin (2007), Haghighi et al. 
W07-0403
Fraser, Alexander, Daniel Marcu. 2007. Measuring 
J07-3002
phrase-based model (HPBSMT) (Chiang, 2007). 
J07-2003
Chiang (2007),     have    with        与     
J07-2003
Och, Franz Josef. 2003. Minimum error rate training 
P03-1021
and BLEU (Fraser and Marcu, 2007) is itself an 
J07-3002
Marcu, Daniel, William Wong. 2002. A Phrase-Based, 
W02-1018
Och, Franz Josef and Hermann Ney. 2004. The 
J04-4002
Fraser, Alexander, Daniel Marcu. 2006. Semi-
P06-1097
Chiang, David. 2007. Hierarchical Phrase-based 
J07-2003
Liu, Yang, Qun Liu and Shouxun Lin. 2005. Log-
P05-1057
Cherry, Colin and Dekang Lin. 2007. Inversion 
W07-0403
Zhang, Hao and Daniel Gildea. 2005. Stochastic Lex-
P05-1059
fore Cherry et al. (2006) and Haghighi et al. 
P06-2014
Cherry, Colin and Dekang Lin. 2006. Soft Syntactic 
P06-2014
et al., 2009; Zhang et al., 2008). However, there 
P08-1012
in Wu (1997) so as to handle the case of 
J97-3002
pairs can be formulated. Marcu and Wong (2002) 
W02-1018
(Brown et al., 1993) probabilities of the word 
J93-2003
(Chiang, 2007). 
J07-2003
Cherry et al., 2006; Haghighi et al., 2009)1. 
P06-2014 P09-1104
Birch et al. (2006) propose a better and more 
W06-3123
Xiong, Deyi, Qun Liu and Shouxun Lin. 2006. Max-
P06-1066
based distortion model (Xiong, et al., 2006), and 
P06-1066
