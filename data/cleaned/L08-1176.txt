<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>J R Anderson</author>
</authors>
<title>The adaptive nature of human categorization</title>
<date>1991</date>
<journal>Psychological Review</journal>
<volume>98</volume>
<marker>Anderson, 1991</marker>
<rawString>Anderson, J. R. (1991). The adaptive nature of human categorization. Psychological Review, 98(3):409–429.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Baldwin</author>
</authors>
<title>General-Purpose Lexical Acquisition: Procedures, Questions and Results</title>
<date>2005</date>
<booktitle>In Proceedings of the Pacific Association for Computational Linguistics</booktitle>
<location>Tokyo, Japan</location>
<contexts>
<context>d very specific cues ad-hoc for classifying verbs into a number of Levin (1993) based verbal classes. Other authors have tried to use more general features, such as the pos tags of neighboring words (Baldwin, 2005), or general linguistic information as Joanis et al. (2007) who used the frequency of filled syntactic positions or slots, tense and voice of occurring verbs, etc., to describe the whole systems of E</context>
</contexts>
<marker>Baldwin, 2005</marker>
<rawString>Baldwin, T. (2005) General-Purpose Lexical Acquisition: Procedures, Questions and Results, In Proceedings of the Pacific Association for Computational Linguistics 2005, Tokyo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Baldwin</author>
<author>F Bond</author>
</authors>
<title>Learning the Countability of English Nouns from Corpus Data</title>
<date>2003</date>
<booktitle>In Proceedings of the 41 st . Annual Meeting of the Association for Computational Linguistics</booktitle>
<location>Sapporo, Japan</location>
<marker>Baldwin, Bond, 2003</marker>
<rawString>Baldwin, T. and F. Bond. (2003). Learning the Countability of English Nouns from Corpus Data. In Proceedings of the 41 st . Annual Meeting of the Association for Computational Linguistics, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Baldwin</author>
<author>E M Bender</author>
<author>D Flickinger</author>
</authors>
<title>Road-testing the English Resource Grammar over the British National Corpus</title>
<date>2004</date>
<booktitle>In Proceedings of the Fourth International Conference LREC</booktitle>
<location>Lisbon, Portugal</location>
<marker>Baldwin, Bender, Flickinger, 2004</marker>
<rawString>Baldwin, T.; Bender, E.M; Flickinger, D. (2004). Road-testing the English Resource Grammar over the British National Corpus. In Proceedings of the Fourth International Conference LREC, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Bel</author>
<author>S Espeja</author>
<author>M Marimon</author>
</authors>
<title>Automatic Acquisition of Grammatical Types for Nouns</title>
<date>2007</date>
<booktitle>In H LT 2007: The Conference of the North American Chapter of the ACL. Companion Volume, Short Papers</booktitle>
<location>Rochester, New York</location>
<contexts>
<context>have used for evaluation our own work on lexical acquisition with the same materials but using a C4.5 Decision Tree (DT) classifier (Quinlan 1993) in the Weka (Witten and Frank, 2005) implementation (Bel et al. 2007). In that experiment, we trained a DT with the signatures of 289 words, using the encoding available at the SRG lexica for a supervised experiment in a 10-fold cross-validation testing. This test-set</context>
<context>lts for the assignment of the value yes obtained with the test set of 289 nouns both with the DT and with Z. As said before, the results of the DT were obtained in a 10-fold cross-validation testing (Bel et al. 2007). DT Z Prec. Rec. F1 Prec. Rec. F1 trans 0.73 0.45 0.55 0.77 0.37 0.5 intrans 0.84 0.94 0.89 0.48 0.67 0.56 mass 0.4 0.26 0.31 0.62 0.20 0.30 pcomp 0.4 0.08 0.13 0.44 0.33 0.37 count 0.97 0.99 0.98 0</context>
<context> caused because there is a property of linguistic data that some of these features define more than one class. The results of such feature classification based approach were positive when using a DT (Bel et al. 2007) and now using Z, which is our second contribution. The function Z, based on Bayesian methods, is a proposal for tackling the contribution of observed cues and the filtering from noise in different s</context>
</contexts>
<marker>Bel, Espeja, Marimon, 2007</marker>
<rawString>Bel, N.; Espeja, S.; Marimon, M. (2007). Automatic Acquisition of Grammatical Types for Nouns. In H LT 2007: The Conference of the North American Chapter of the ACL. Companion Volume, Short Papers. Rochester, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M R Brent</author>
</authors>
<title>From grammar to lexicon: unsupervised learning of lexical syntax</title>
<date>1993</date>
<journal>Computational Linguistics</journal>
<volume>19</volume>
<pages>243--262</pages>
<marker>Brent, 1993</marker>
<rawString>Brent, M. R. (1993) From grammar to lexicon: unsupervised learning of lexical syntax. Computational Linguistics 19: 243-262.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Briscoe</author>
<author>J Carroll</author>
</authors>
<title>Generalised probabilistic LR parsing for unification-based grammars</title>
<date>1993</date>
<journal>Computational Linguistics</journal>
<marker>Briscoe, Carroll, 1993</marker>
<rawString>Briscoe, E. &amp; Carroll, J. (1993) Generalised probabilistic LR parsing for unification-based grammars. Computational Linguistics 19.1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Briscoe</author>
<author>J Carroll</author>
</authors>
<title>Automatic extraction of subcategorization from corpora</title>
<date>1997</date>
<booktitle>In Proceedings of the Fifth Conference on Applied Natural Processing</booktitle>
<location>Washington</location>
<marker>Briscoe, Carroll, 1997</marker>
<rawString>Briscoe, T. and J. Carroll. (1997)  “Automatic extraction of subcategorization from corpora”. In Proceedings of the Fifth Conference on Applied Natural Processing, Washington.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Chesley</author>
<author>S Salmon-Alt</author>
</authors>
<title>Automatic extraction of subcategorization frames for French</title>
<date>2006</date>
<booktitle>In Proceedings.of the Fifth International Conference LREC</booktitle>
<location>Genoa, Italy</location>
<marker>Chesley, Salmon-Alt, 2006</marker>
<rawString>Chesley, P and S. Salmon-Alt. (2006) Automatic extraction of subcategorization frames for French. In Proceedings.of the Fifth International Conference LREC, Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Copestake</author>
</authors>
<title>Implementing Typed Feature Structure Grammars</title>
<date>2002</date>
<publisher>CSLI Publications</publisher>
<contexts>
<context>erties, those that in several linguistic theories are known as grammatical features. For the research we present here, we have taken the lexicon of a HPSG-based grammar developed in the LKB platform (Copestake, 2002) for Spanish (Marimon et al. 2007a and 2007b), similarly to the work of Baldwin (2005). In the LKB grammatical framework, lexical types are defined as a combination of properties in terms of grammati</context>
</contexts>
<marker>Copestake, 2002</marker>
<rawString>Copestake, A.. (2002). Implementing Typed Feature Structure Grammars. CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Joanis</author>
<author>S Stevenson</author>
<author>D James</author>
</authors>
<title>A General Feature Space for Automatic Verb Classification. Natural Language Engineering</title>
<date>2007</date>
<marker>Joanis, Stevenson, James, 2007</marker>
<rawString>Joanis, E; Stevenson, S; and James, D. (2007). A General Feature Space for Automatic Verb Classification. Natural Language Engineering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Korhonen</author>
</authors>
<title>Subcategorization acquisition. As</title>
<date>2002</date>
<tech>Technical Report UCAM-CL-TR-530</tech>
<institution>University of Cambridge, UK</institution>
<contexts>
<context> ‘with’. Such big differences create real problems to frequency based methods. Most of authors working with frequency criteria have tried to reduce noise using parsed texts (Briscoe and Caroll, 1997; Korhonen, 2002) or using linguistic generalizations that could offer a better distributed evidence (Chelsey and Salmon-Alt, 2006 used constituents and Preiss et al. 2007 used grammatical relations). Although they u</context>
</contexts>
<marker>Korhonen, 2002</marker>
<rawString>Korhonen, A. (2002). Subcategorization acquisition. As Technical Report UCAM-CL-TR-530, University of Cambridge, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Levin</author>
</authors>
<title>English Verb Classes and Alternations: A Preliminary Investigation</title>
<date>1993</date>
<publisher>The University of Chicago Press</publisher>
<marker>Levin, 1993</marker>
<rawString>Levin, B. (1993). English Verb Classes and Alternations: A Preliminary Investigation. The University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marimon</author>
<author>N Bel</author>
<author>S Espeja</author>
<author>N Seghezzi</author>
</authors>
<title>The Spanish Resource Grammar: Pre-processing Strategy and Lexical Acquisition</title>
<date>2007</date>
<booktitle>Proceedings of the ACL2007 Workshop on Deep Linguistic Processing</booktitle>
<editor>In Baldwin, T. et al. (ed</editor>
<location>Prague. CR</location>
<contexts>
<context>linguistic theories are known as grammatical features. For the research we present here, we have taken the lexicon of a HPSG-based grammar developed in the LKB platform (Copestake, 2002) for Spanish (Marimon et al. 2007a and 2007b), similarly to the work of Baldwin (2005). In the LKB grammatical framework, lexical types are defined as a combination of properties in terms of grammatical features. The lexical typology</context>
</contexts>
<marker>Marimon, Bel, Espeja, Seghezzi, 2007</marker>
<rawString>Marimon, M.; Bel, N.; Espeja, S.; and Seghezzi, N. (2007a). The Spanish Resource Grammar: Pre-processing Strategy and Lexical Acquisition. In Baldwin, T. et al. (ed.) Proceedings of the ACL2007 Workshop on Deep Linguistic Processing. Prague. CR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marimon</author>
<author>N Seghezzi</author>
<author>N Bel</author>
</authors>
<title>An Open-source Lexicon for Spanish</title>
<date>2007</date>
<booktitle>in Procesamiento del Lenguaje Natural 39.: Sociedad Española para el Procesamiento del Lenguaje Natural</booktitle>
<contexts>
<context>linguistic theories are known as grammatical features. For the research we present here, we have taken the lexicon of a HPSG-based grammar developed in the LKB platform (Copestake, 2002) for Spanish (Marimon et al. 2007a and 2007b), similarly to the work of Baldwin (2005). In the LKB grammatical framework, lexical types are defined as a combination of properties in terms of grammatical features. The lexical typology</context>
</contexts>
<marker>Marimon, Seghezzi, Bel, 2007</marker>
<rawString>Marimon, M.; Seghezzi, N.; Bel, N. (2007b). An Open-source Lexicon for Spanish in Procesamiento del Lenguaje Natural 39.: Sociedad Española para el Procesamiento del Lenguaje Natural.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Merlo</author>
<author>S Stevenson</author>
</authors>
<title>Automatic Verb Classification based on Statistical Distribution of Argument Structure</title>
<date>2001</date>
<journal>Computational Linguistics</journal>
<pages>27--3</pages>
<marker>Merlo, Stevenson, 2001</marker>
<rawString>Merlo P and S. Stevenson (2001). Automatic Verb Classification based on Statistical Distribution of Argument Structure, Computational Linguistics, 27:3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Mingers</author>
</authors>
<title>An empirical comparison of selection measures for decision tree induction</title>
<date>1989</date>
<booktitle>Machine Learning</booktitle>
<volume>3</volume>
<contexts>
<context>alanced data with respect features and types. This unbalance benefits the DT classifier which takes into account, as we will see, the most frequent items when there is a severe unbalance in the data (Mingers, 1989). For the experiments we present here, we have used a set of 50 nouns that appeared only once in our corpus of one million words. These nouns were chosen at random. The main characteristics of this t</context>
<context>recision (‘prec’), recall (‘rec’) and F1 for the assignment of the value yes for every grammatical feature of the model. As expected, because of the problems of the DT with data with few occurrences (Mingers, 1989), performance is better with Z, especially in what concerns recall, but in the case of the feature intrans. An analysis of errors showed that there were cases where noise was not been detected. The n</context>
</contexts>
<marker>Mingers, 1989</marker>
<rawString>Mingers, J. (1989) “An empirical comparison of selection measures for decision tree induction”. Machine Learning, 3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Preiss</author>
<author>T Briscoe</author>
<author>A Korhonen</author>
</authors>
<title>A System for Large-scale Acquisition of Verbal, Nominal and Adjectival Subcategorization Frames from Corpora</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the ACL</booktitle>
<location>Prague, Czech Republic</location>
<contexts>
<context>se using parsed texts (Briscoe and Caroll, 1997; Korhonen, 2002) or using linguistic generalizations that could offer a better distributed evidence (Chelsey and Salmon-Alt, 2006 used constituents and Preiss et al. 2007 used grammatical relations). Although they used different methods and materials, their results have in common an improvement in precision scores (percentage of properties correctly acquired of all pr</context>
</contexts>
<marker>Preiss, Briscoe, Korhonen, 2007</marker>
<rawString>Preiss, J., Briscoe, T. and  Korhonen, A. (2007). A System for Large-scale Acquisition of Verbal, Nominal and Adjectival Subcategorization Frames from Corpora. In Proceedings of the 45th Annual Meeting of the ACL. Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R J Quinlan</author>
</authors>
<title>C4.5: Programs for Machine Learning</title>
<date>1993</date>
<booktitle>Series in Machine Learning</booktitle>
<publisher>Morgan</publisher>
<location>Kaufman, San Mateo, CA</location>
<contexts>
<context>culties in comparing our approach to other works in the domain, we have used for evaluation our own work on lexical acquisition with the same materials but using a C4.5 Decision Tree (DT) classifier (Quinlan 1993) in the Weka (Witten and Frank, 2005) implementation (Bel et al. 2007). In that experiment, we trained a DT with the signatures of 289 words, using the encoding available at the SRG lexica for a supe</context>
</contexts>
<marker>Quinlan, 1993</marker>
<rawString>Quinlan, R.J. (1993). C4.5: Programs for Machine Learning. Series in Machine Learning. Morgan Kaufman, San Mateo, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I H Witten</author>
<author>F Eibe</author>
</authors>
<title>Data Mining: Practical machine learning tools and techniques. 2nd Edition</title>
<date>2005</date>
<publisher>Morgan Kaufmann</publisher>
<location>San Francisco</location>
<marker>Witten, Eibe, 2005</marker>
<rawString>Witten, I.H. and Eibe F.. (2005). Data Mining: Practical machine learning tools and techniques. 2nd Edition, Morgan Kaufmann, San Francisco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Xu</author>
<author>J B Tenenbaum</author>
</authors>
<title>Word learning as Bayesian inference</title>
<date>2007</date>
<journal>Psychological Review</journal>
<volume>114</volume>
<marker>Xu, Tenenbaum, 2007</marker>
<rawString>Xu, F. and Tenenbaum, J. B. (2007). Word learning as Bayesian inference. Psychological Review 114(2).</rawString>
</citation>
</citationList>
</algorithm>

