<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>Claire Cardie</author>
<author>Cynthia Farina</author>
<author>Adil Aijaz</author>
<author>Matt Rawding</author>
<author>Stephen Purpura</author>
</authors>
<title>A Study in Rule-Specific Issue Categorization for e-Rulemaking</title>
<date>2008</date>
<booktitle>In Proceedings of the Ninth Annual International Conference on Digital Government Research</booktitle>
<note>to appear</note>
<contexts>
<context>blic comments: given the comments submitted for a proposed rule, the automated system determines for each sentence in each comment, which of a set of predefined issues of substance it raises, if any (Cardie et al., 2008). This corpus is the first in a series of sentence-level text categorization corpora to be developed by the Cornell eRulemaking Initiative (CeRI). 2. Related Work In recent years, researchers have be</context>
</contexts>
<marker>Cardie, Farina, Aijaz, Rawding, Purpura, 2008</marker>
<rawString>Claire Cardie, Cynthia Farina, Adil Aijaz, Matt Rawding, and Stephen Purpura. 2008. A Study in Rule-Specific Issue Categorization for e-Rulemaking. In Proceedings of the Ninth Annual International Conference on Digital Government Research. to appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Cohn</author>
<author>L Atlas</author>
<author>R Ladner</author>
</authors>
<title>Improving generalization with active learning</title>
<date>1994</date>
<booktitle>Machine Learning</booktitle>
<volume>15</volume>
<marker>Cohn, Atlas, Ladner, 1994</marker>
<rawString>D. Cohn, L. Atlas, and R. Ladner. 1994. Improving generalization with active learning. Machine Learning, 15(2):201–221.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan Dumais</author>
<author>Hao Chen</author>
</authors>
<title>Hierarchical classification of web content</title>
<date>2000</date>
<booktitle>In SIGIR ’00: Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval</booktitle>
<pages>256--263</pages>
<publisher>ACM</publisher>
<location>New York, NY, USA</location>
<contexts>
<context>is deemed non-NONE, then the level-1 and possibly a level-2 classifier is applied depending on the issue specificity required. This approach is similar in spirit to methods employed in previous work (Dumais and Chen, 2000; Koller and Sahami, 1997) although we do not try to reduce the feature set size. Macro averages across annotators flat categorization 39 issues 0.48 hierarchical categorization 39 issues 0.45 flat ca</context>
</contexts>
<marker>Dumais, Chen, 2000</marker>
<rawString>Susan Dumais and Hao Chen. 2000. Hierarchical classification of web content. In SIGIR ’00: Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256–263, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Freund</author>
<author>H S Seung</author>
<author>E Shamir</author>
<author>N Tishby</author>
</authors>
<title>Selective sampling using the query by committee algorithm</title>
<date>1997</date>
<booktitle>Machine Learning</booktitle>
<pages>28--133</pages>
<marker>Freund, Seung, Shamir, Tishby, 1997</marker>
<rawString>Y. Freund, H. S. Seung, E. Shamir, and N. Tishby. 1997. Selective sampling using the query by committee algorithm. Machine Learning, 28:133–168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Hatzivassiloglou</author>
<author>J Klavans</author>
<author>E Eskin</author>
</authors>
<title>Detecting Text Similarity over Short Passages: Exploring Linguistic Feature Combinations via Machine Learning</title>
<date>1999</date>
<booktitle>In Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (EMNLP/VLC-99</booktitle>
<pages>203--212</pages>
<institution>University of Maryland, College Park, MD. Association for Computational Linguistics</institution>
<contexts>
<context>, and annotated, at the sentence level or below. This is problematic for automated methods because categorization of short texts is known to be quite a bit harder than categorization of longer texts (Hatzivassiloglou et al., 1999; Zelikovitz and Hirsh, 2000; Sahami and Heilman, 2006). Fairly Large, Hierarchical Issue Set. Proposed rules, guidance and other documents that generate a sufficient amount of public comment to warra</context>
</contexts>
<marker>Hatzivassiloglou, Klavans, Eskin, 1999</marker>
<rawString>V. Hatzivassiloglou, J. Klavans, and E. Eskin. 1999. Detecting Text Similarity over Short Passages: Exploring Linguistic Feature Combinations via Machine Learning. In Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (EMNLP/VLC-99), pages 203–212, University of Maryland, College Park, MD. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Kerwin</author>
</authors>
<title>The state of rulemaking in the federal government</title>
<date>2005</date>
<tech>Technical report, Transcript Panel 1</tech>
<contexts>
<context>in a series of related sentence-level text categorization corpora to be developed in the eRulemaking domain. 1. Introduction Each year regulatory agencies in the U.S. issue more than 4,000 new rules (Kerwin, 2005). By law, many of these must be created through a complex process known as notice and comment (N&amp;C) rulemaking: the agency (e.g., the Department of Commerce or Department of Transportation) drafts a </context>
</contexts>
<marker>Kerwin, 2005</marker>
<rawString>C. Kerwin. 2005. The state of rulemaking in the federal government. Technical report, Transcript Panel 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daphne Koller</author>
<author>Mehran Sahami</author>
</authors>
<title>Hierarchically classifying documents using very few words</title>
<date>1997</date>
<booktitle>Proceedings of ICML-97, 14th International Conference on Machine Learning</booktitle>
<pages>170--178</pages>
<editor>In Douglas H. Fisher, editor</editor>
<publisher>Morgan Kaufmann Publishers</publisher>
<location>Nashville, US</location>
<contexts>
<context>n the level-1 and possibly a level-2 classifier is applied depending on the issue specificity required. This approach is similar in spirit to methods employed in previous work (Dumais and Chen, 2000; Koller and Sahami, 1997) although we do not try to reduce the feature set size. Macro averages across annotators flat categorization 39 issues 0.48 hierarchical categorization 39 issues 0.45 flat categorization 17 level-1 i</context>
</contexts>
<marker>Koller, Sahami, 1997</marker>
<rawString>Daphne Koller and Mehran Sahami. 1997. Hierarchically classifying documents using very few words. In Douglas H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 170–178, Nashville, US. Morgan Kaufmann Publishers, San Francisco, US.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Krippendorff</author>
</authors>
<title>Content analysis: An introduction to its methodology (2nd Ed</title>
<date>2004</date>
<publisher>Sage Publications</publisher>
<contexts>
<context>rarchical issues, and the five hierarchical issues plus NONE. Along with the AGR 6In current work, we have moved to the more reliable Cohen’s and Fleiss’ kappa for measuring interannotator agreement (Krippendorff, 2004). Figure 2: Issue-by-Issue Interannotator Agreement Results. scores, we show the coverage of each issue set across all sentences of the corpus. When calculated across the full set of 39 issues (38 is</context>
</contexts>
<marker>Krippendorff, 2004</marker>
<rawString>K. Krippendorff. 2004. Content analysis: An introduction to its methodology (2nd Ed.). Sage Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Namhee Kwon</author>
<author>Eduard Hovy</author>
</authors>
<title>Information acquisition using multiple classifications</title>
<date>2007</date>
<booktitle>In Proceedings of the Fourth International Conference on Knowledge Capture (K-CAP</booktitle>
<marker>Kwon, Hovy, 2007</marker>
<rawString>Namhee Kwon and Eduard Hovy. 2007. Information acquisition using multiple classifications. In Proceedings of the Fourth International Conference on Knowledge Capture (K-CAP 2007).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Namhee Kwon</author>
<author>Eduard Hovy</author>
<author>Stuart Shulman</author>
</authors>
<title>Multidimensional text analysis for erulemaking</title>
<date>2006</date>
<booktitle>In Proceedings of the 7th Annual International Conference on Digital Government Research</booktitle>
<marker>Kwon, Hovy, Shulman, 2006</marker>
<rawString>Namhee Kwon, Eduard Hovy, and Stuart Shulman. 2006. Multidimensional text analysis for erulemaking. In Proceedings of the 7th Annual International Conference on Digital Government Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Purpura</author>
<author>Claire Cardie</author>
<author>Jesse Simons</author>
</authors>
<title>Active Learning for e-Rulemaking: Public Comment Categorization</title>
<date>2008</date>
<booktitle>In Proceedings of the Ninth Annual International Conference on Digital Government Research</booktitle>
<note>to appear</note>
<marker>Purpura, Cardie, Simons, 2008</marker>
<rawString>Stephen Purpura, Claire Cardie, and Jesse Simons. 2008. Active Learning for e-Rulemaking: Public Comment Categorization. In Proceedings of the Ninth Annual International Conference on Digital Government Research. to appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehran Sahami</author>
<author>Timothy D Heilman</author>
</authors>
<title>A webbased kernel function for measuring the similarity of short text snippets</title>
<date>2006</date>
<booktitle>In WWW ’06: Proceedings of the 15th international conference on World Wide Web</booktitle>
<pages>377--386</pages>
<publisher>ACM</publisher>
<location>New York, NY, USA</location>
<contexts>
<context>oblematic for automated methods because categorization of short texts is known to be quite a bit harder than categorization of longer texts (Hatzivassiloglou et al., 1999; Zelikovitz and Hirsh, 2000; Sahami and Heilman, 2006). Fairly Large, Hierarchical Issue Set. Proposed rules, guidance and other documents that generate a sufficient amount of public comment to warrant the help of automatic issue categorization almost i</context>
</contexts>
<marker>Sahami, Heilman, 2006</marker>
<rawString>Mehran Sahami and Timothy D. Heilman. 2006. A webbased kernel function for measuring the similarity of short text snippets. In WWW ’06: Proceedings of the 15th international conference on World Wide Web, pages 377–386, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danny Silver</author>
<author>Goekhan Bakir</author>
<author>Kristin Bennett</author>
<author>Rich Caruana</author>
<author>Massimiliano Pontil</author>
<author>Stuart Russell</author>
<author>Prasad Tadepalli</author>
</authors>
<title>Inductive Transfer : 10 Years Later</title>
<date>2005</date>
<contexts>
<context>and analysts themselves) should be kept to a minimum. For this reason, text categorization methods that allow for inductive transfer across related rulemakings will need to be employed and developed (Silver et al., 2005) so that new rulemakings can benefit from previous rulemakings. We have also left this issue for future work. 5. Interannotator Agreement Results This section present the results of an interannotator</context>
</contexts>
<marker>Silver, Bakir, Bennett, Caruana, Pontil, Russell, Tadepalli, 2005</marker>
<rawString>Danny Silver, Goekhan Bakir, Kristin Bennett, Rich Caruana, Massimiliano Pontil, Stuart Russell, and Prasad Tadepalli. 2005. Inductive Transfer : 10 Years Later.</rawString>
</citation>
<citation valid="true">
<authors>
<author>NIPS</author>
</authors>
<date>2005</date>
<note>Workshop</note>
<marker>NIPS, 2005</marker>
<rawString>NIPS 2005 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Strauss</author>
<author>T Rakoff</author>
<author>C Farina</author>
</authors>
<title>Administrative Law. 10th edition</title>
<date>2003</date>
<contexts>
<context>eceived and, if it chooses to adopt the proposed rule, to issue a statement that responds to significant criticisms made in the comments and explains why it rejected alternative suggested approaches (Strauss et al., 2003). Electronic rulemaking (eRulemaking) refers to the use of information technology to support any step in the rulemaking process. For example, comments on proposed rules can now be submitted electroni</context>
</contexts>
<marker>Strauss, Rakoff, Farina, 2003</marker>
<rawString>P. Strauss, T. Rakoff, and C. Farina. 2003. Administrative Law. 10th edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Yang</author>
<author>J Callan</author>
</authors>
<title>Near-duplicate detection for erulemaking</title>
<date>2005</date>
<booktitle>In Proceedings of the Fifth National Conference on Digital Government Research</booktitle>
<marker>Yang, Callan, 2005</marker>
<rawString>H. Yang and J. Callan. 2005. Near-duplicate detection for erulemaking. In Proceedings of the Fifth National Conference on Digital Government Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Yang</author>
<author>J Callan</author>
</authors>
<title>Near-duplicate detection by instance-level constrained clustering</title>
<date>2006</date>
<booktitle>In Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</booktitle>
<marker>Yang, Callan, 2006</marker>
<rawString>H. Yang and J. Callan. 2006. Near-duplicate detection by instance-level constrained clustering. In Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval.</rawString>
</citation>
</citationList>
</algorithm>

