Instead of estimating the probability of a word with frequency f by its sample relative frequency f (16) pi=, Good suggests the use of the adjusted estimate 1 (1: + 1)E\[V(N,f + 1)1 (17) my(N) = E\[V(N,d)\] A closely related statistic is the probability ~P(N) of sampling a new, unseen type after N word tokens have been sampled: 7~(N ) _ E\[V(N, 1)\] (18) N These estimates are in wide use (see, e.g., Church and Gale \[1991\] for application to bigrams, Bod \[1995\] for application to syntax, and Baayen \[1992\] and Baayen and Sproat \[1996\] for application to morphology).
J96-2001
Baayen, 1996).
J96-2001
For instance, Baayen (1989, 1992) and Baayen and Renouf (1996) exploit the Good-Turing estimate for the probability of sampling unseen types (Good 1953) to develop measures for the degree of productivity of affixes, Baayen and Sproat (to appear) apply this Good-Turing estimate to obtain enhanced estimates of lexical priors for unseen words, and the Good-Turing estimates also play an important role for estimating population probabilities (Church and Gale 1991).
J96-2001
