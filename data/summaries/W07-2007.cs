The organisers themselves have come to similar conclusions in their own experiments (Markert and Nissim, 2002).
W02-1027
Intra-annotator agreement We measured pairwise agreement among annotators usingthekappacoefficient(K)whichiswidelyused in computational linguistics for measuring agreement in category judgments (Carletta, 1996).
J96-2004
In recent years, there has been growing interest in metaphor and metonymy resolution that is either corpus-based or evaluated on larger datasets (Martin, 1994; Nissim and Markert, 2003; Mason, 2004; Peirsman, 2006; Birke and Sarkaar, 2006; Krishnakamuran and Zhu, 2007).
E06-1042 E06-3009 J04-1002 P03-1008
Annotation was highly reliable with a kappa (Carletta, 1996) of 3https://www.cia.gov/cia/publications/ factbook/index.html 4Given that the task is not about standard Named Entity Recognition, we assume that the general semantic class of the name is already known.
J96-2004
Obtained percent agreement of 0.988 and  coefficient (Carletta, 1996) of 0.975 suggest high convergence of both annotations.
J96-2004
The idiomatic/literal token classification methods of Birke and Sarkar (2006) and Katz and Giesbrecht (2006) rely primarily on the local context of a token, and fail to exploit specific linguistic properties of non-literal language.
E06-1042
(2) BMW slipped 4p to 31p (3) His BMW went on to race at Le Mans The importance of resolving metonymies has been shown for a variety of NLP tasks, such as ma36 chine translation (Kamei and Wakao, 1992), question answering (Stallard, 1993), anaphora resolution (Harabagiu, 1998; Markert and Hahn, 2002) and geographical information retrieval (Leveling and Hartrumpf, 2006).
P93-1012 W02-1027 W98-0720
As there is no common framework or corpus for figurative language resolution, previous computational works (Fass, 1997; Hobbs et al., 1993; Barnden et al., 2003, among others) carry out only smallscale evaluations.
E03-1067
For these classications, we calculated a kappa statistic of 0.528 (Carletta, 1996).
J96-2004
Still, apart from (Nissim and Markert, 2003; Peirsman, 2006) who evaluate their work on the same dataset, results are hardly comparable as they all operate within different frameworks.
E06-3009 P03-1008
on measures for inter-rater reliability (Carletta, 1996), on frameworks for evaluating spoken dialogue agents (Walker et al., 1998) and on the use of different corpora in the development of a particular system (The Carnegie-Mellon Communicator, Eskenazi et al.(1999)). The question we are addressing in this paper is how to collect and analyse relevant corpora.
J96-2004
Such techniques either do not use any information regarding the linguistic properties of MWEs (Birke and Sarkar, 2006), or mainly focus on their noncompositionality (Katz and Giesbrecht, 2006).
E06-1042
