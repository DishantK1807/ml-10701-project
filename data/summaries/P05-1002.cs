Comparison with previous best results: KM01 (Kudoh and Matsumoto, 2001), CM03 (Carreras and Marquez, 2003), SP03 (Sha and Pereira, 2003), ZDJ02 (Zhang et al., 2002).
N03-1028
McCallum (2003) describes a technique for greedily adding those feature conjuncts to a CRF which significantly improve the model's log-likelihood.
W03-0430
Note that this decoding is an equivalent formulation to a uniformly weighted logarithmic opinion pool, as described in Smith et al.(2005). Of the three decoding methods, Standalone has the lowest complexity, requiring only a binary Viterbi decoding for each weak learner.
P05-1003
Those results which are significantly better than the corresponding multiclass MLE or regularised model are flagged with a, and those which are significantly worse with a . These results show that error-correcting CRF training achieves quite similar performance to the multiclass CRF on the task (which incidentally exceeds McCallum (2003)'s result of 89.0 using feature induction).
W03-0430
Roark et al.(2004) have also employed feature selection to the huge task of language modelling with a CRF, by partially training a voted perceptron then removing all features that the are ignored by the perceptron.
P04-1007
In recent empirical studies on maximum entropy models and CRFs, limited memory variable metric (LMVM) has proven to be the most efficient method (Malouf, 2002; Wallach, 2002); accordingly, we have used LMVM for CRF estimation.
W02-2018
This result exceeds Lafferty et al.'s accuracy of 95.73% using a CRF but falls short of Toutanova et al.(2003)'s state-of-the-art 97.24%.
N03-1033
Error-correction codes could be applied to other sequence labelling methods, such as the voted perceptron (Roark et al., 2004).
P04-1007
CRFs have been applied with impressive empirical results to the tasks of named entity recognition (McCallum and Li, 2003), simplified part-of-speech (POS) tagging (Lafferty et al., 2001), noun phrase chunking (Sha and Pereira, 2003) and extraction of tabular data (Pinto et al., 2003), among other tasks.
N03-1028 W03-0430
entity recognition CRFs have been used with strong results on the CoNLL 2003 NER task (McCallum, 2003) and thus this task is included here as a benchmark.
W03-0430
Vijay-Shanker. 2003.
N03-1028
