Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pp.
306–314, Prague, June 2007.
c©2007 Association for Computational Linguistics Probabilistic Coordination Disambiguation in a Fully-lexicalized Japanese Parser Daisuke Kawahara National Institute of Information and Communications Technology, 3-5 Hikaridai Seika-cho, Soraku-gun, Kyoto, 619-0289, Japan dk@nict.go.jp Sadao Kurohashi Graduate School of Informatics, Kyoto University, Yoshida-Honmachi, Sakyo-ku, Kyoto, 606-8501, Japan kuro@i.kyoto-u.ac.jp Abstract This paper describes a probabilistic model for coordination disambiguation integrated into syntactic and case structure analysis.
Our model probabilistically assesses the parallelism of a candidate coordinate structure using syntactic/semantic similarities and cooccurrence statistics.
We integrate these probabilities into the framework of fully-lexicalized parsing based on largescale case frames.
This approach simultaneously addresses two tasks of coordination disambiguation: the detection of coordinate conjunctions and the scope disambiguation of coordinate structures.
Experimental resultsonwebsentencesindicatetheeffectiveness of our approach.
1 Introduction
Coordinate structures are a potential source of syntactic ambiguity in natural language.
Since their interpretation directly affects the meaning of the text, their disambiguation is important for natural language understanding.
Coordination disambiguation consists of the following two tasks: • the detection of coordinate conjunctions, • and ﬁnding the scope of coordinate structures.
In English, for example, coordinate structures are triggered by coordinate conjunctions, such as and and or.
In a coordinate structure that consists of more than two conjuncts, commas, which have various usages, also function like coordinate conjunctions.
Recognizing true coordinate conjunctions from such possible coordinate conjunctions is a task of coordination disambiguation (Kurohashi, 1995).
The other is the task of identifying the range of coordinate phrases or clauses.
Previous work on coordination disambiguation has focused on the task of addressing the scope ambiguity (e.g., (Agarwal and Boggess, 1992; Goldberg, 1999; Resnik, 1999; Chantree et al., 2005)).
Kurohashi and Nagao proposed a similarity-based method to resolve both of the two tasks for Japanese (Kurohashi and Nagao, 1994).
Their method, however, heuristically detects coordinate conjunctions by considering only similarities between possible conjuncts, and thus cannot disambiguate the following cases1: (1) a.
kanojo-to she-cmi gakkou-ni school-acc itta went (φ went to school with her) b.
kanojo-to she-cnj watashi-ga I-nom goukaku-shita passed an exam (she and I passed an exam) In sentence (1a), postposition “to” is used as a comitative case marker, but in sentence (1b), postposition “to” is used as a coordinate conjunction.
To resolve this ambiguity, predicative case frames are required.
Case frames describe what kinds of 1In this paper, we use the following abbreviations: nom (nominative), acc (accusative), abl (ablative), cmi (comitative), cnj (conjunction) and TM (topic marker).
306 Table 1: Case frame examples (Examples are written in English.
Numbers following each example represent its frequency.).
CS Examples ga I:18, person:15, craftsman:10, ···yaku (1) wo bread:2484, meat:1521, cake:1283, ···(broil) de oven:1630, frying pan:1311, ··· yaku (2) ga teacher:3, government:3, person:3, ··· (have wo ﬁngers:2950 difﬁculty) ni attack:18, action:15, son:15, ··· ga maker:1, distributor:1yaku (3) wo data:178, ﬁle:107, copy:9, ···(burn) ni R:1583, CD:664, CDR:3, ···...
... ...
ga dolphin:142, student:50, ﬁsh:28, ···oyogu (1) wo sea:1188, underwater:281, ···(swim) de crawl:86, breaststroke:49, stroke:24, ··· ...
... ...
ga I:4, man:4, person:4, ···migaku (1) wo tooth:5959, molar:27, foretooth:12(brush) de brush:38, salt:13, powder:12, ··· ...
... ...
nouns are related to each predicate.
For example, a case frame of “iku” (go) has a “to” case slot ﬁlled with the examples such as “kanojo” (she) or human.
On the other hand, “goukaku-suru” (pass an exam) does not have a “to” case slot but does have a “ga” case slot ﬁlled with “kanojo” (she) and “watashi” (I).
These case frames provide the information for disambiguating the postpositions “to” in sentences (1a) and (1b): (1a) is not coordinate and (1b) is coordinate.
This paper proposes a method for integrating coordination disambiguation into probabilistic syntactic and case structure analysis.
This method simultaneously addresses the two tasks of coordination disambiguation by utilizing syntactic/semantic parallelism in possible coordinate structures and lexical preferences in large-scale case frames.
We use the case frames that were automatically constructed from the web (Table 1).
In addition, cooccurrence statistics of coordinate conjuncts are incorporated into this model.
2 Related
Work Previous work on coordination disambiguation has focused mainly on ﬁnding the scope of coordinate structures.
Agarwal and Boggess proposed a method for identifying coordinate conjuncts (Agarwal and Boggess, 1992).
Their method simply matches parts of speech and hand-crafted semantic tags of the head words of the coordinate conjuncts.
They tested their method using the Merck Veterinary Manual and found their method had an accuracy of 81.6%.
Resnik described a similarity-based approach for coordination disambiguation of nominal compounds (Resnik, 1999).
He proposed a similarity measure based on the notion of shared information content.
He conducted several experiments using the Penn Treebank and reported an F-measure of approximately 70%.
Goldberg applied a cooccurrence-based probabilistic model to determine the attachments of ambiguous coordinate phrases with the form “n1 p n2 cc n3” (Goldberg, 1999).
She collected approximately 120K unambiguous pairs of two coordinate words from a raw newspaper corpus for a one-year period and estimated parameters from these statistics.
Her method achieved an accuracy of 72% using the Penn Treebank.
Chantreeetal. presentedabinaryclassiﬁerforcoordination ambiguity (Chantree et al., 2005).
Their model is based on word distribution information obtained from the British National Corpus.
They achieved an F-measure (β = 0.25) of 47.4% using their own test set.
The previously described methods focused on coordination disambiguation.
Some research has been undertaken that integrated coordination disambiguation into parsing.
Kurohashi and Nagao proposed a Japanese parsing method that included coordinate structure detection (Kurohashi and Nagao, 1994).
Their method ﬁrst detects coordinate structures in a sentence, and then heuristically determines the dependency structure of the sentence under the constraints of the detected coordinate structures.
Their method correctly analyzed 97 Japanese sentences out of 150.
Charniak and Johnson used some features of syntactic parallelism in coordinate structures for their MaxEnt reranking parser (Charniak and Johnson, 2005).
The reranker achieved an F-measure of 91.0%, which is higher than that of their generative parser (89.7%).
However, they used a numerous number of features, and the contribution of the 307 Table 2: Expressions that indicate coordinate structures.
(a) coordinate noun phrase:,(comma) to ya toka katsu oyobi ka aruiwa ...
(b) coordinate predicative clause: -shi ga oyobi ka aruiwa matawa ...
(c) incomplete coordinate structure:,(comma) oyobi narabini aruiwa ...
parallelism features is unknown.
Dubey et al.proposed an unlexicalized PCFG parser that modiﬁed PCFG probabilities to condition the existence of syntactic parallelism (Dubey et al., 2006).
They obtained an F-measure increase of 0.4% over their baseline parser (73.0%).
Experiments with a lexicalized parser were not conducted in their work.
A number of machine learning-based approaches to Japanese parsing have been developed.
Among them, the best parsers are the SVM-based dependency analyzers (Kudo and Matsumoto, 2002; Sassano, 2004).
In particular, Sassano added some features to improve his parser by enabling it to detect coordinate structures (Sassano, 2004).
However, the added features did not contribute to improving the parsing accuracy.
This failure can be attributed to the inability to consider global parallelism.
3 Coordination
Ambiguity in Japanese In Japanese, the bunsetsu is a basic unit of dependencythatconsistsofoneormorecontentwordsand the following zero or more function words.
A bunsetsu corresponds to a base phrase in English and “eojeol” in Korean.
Coordinate structures in Japanese are classiﬁed intothreetypes.
Theﬁrsttypeisthecoordinatenoun phrase.
(2) nagai long enpitsu-to pencil-cnj keshigomu-wo eraser-acc katta bought (bought a long pencil and an eraser) We can ﬁnd these phrases by referring to the words listed in Table 2-a.
The second type is the coordinate predicative clause, in which two or more predicates form a coordinate structure.
bn An:Partial matrix A = (a(i, j)) Coordination key bunsetsu a(n, m) a(pm-n, n+1) a path Similarity betweenb nandbm Figure 1: Method using triangular matrix.
(3) kanojo-to she-cmi kekkon-shi married ie-wo house-acc katta bought (married her and bought a house) We can ﬁnd these clauses by referring to the words and ending forms listed in Table 2-b.
The third type is the incomplete coordinate structure, in which some parts of coordinate predicative clauses are present.
(4) Tom-wa Tom-TM inu-wo, dog-acc Jim-wa Jim-TM neko-wo cat-acc kau buys (Tom (buys) a dog, and Jim buys a cat) We can ﬁnd these structures by referring to the words listed in Table 2-c and also the correspondence of case-marking postpositions.
Forallofthesetypes, wecandetectthepossibility of a coordinate structure by looking for a coordination key bunsetsu that accompanies one of the words listed in Table 2 (in total, we have 52 coordination expressions).
Thatistosay,theleftandrightsidesof a coordination key bunsetsu constitute possible preand post-conjuncts, and the key bunsetsu is located at the end of the pre-conjunct.
The size of the conjuncts corresponds to the scope of the coordination.
4 Calculating
Similarity between Possible Coordinate Conjuncts We assess the parallelism of potential coordinate structures in a probabilistic parsing model.
In this 308 puroguramingugengo-wa2202220 020(prog.
language)mondaikaiketsu-no 202420 020(problem solution) arugorizumu-wo02240 020(algorithm)hyogendekiru 0002 402(can express) kijutsuryoku-to220 020(descriptive power)keisanki-no20 020(computer) kinou-wo0 020(function)jubun-ni 202(sufficiently) kudoudekiru02(can drive)wakugumi-ga0(framework) hitsuyou-dearu.(require) (Programming language requires descriptive power to express an algorithm for solving problems and a framework to sufficiently drive functions of a computer.) post-conjunct pre-conjunct Figure 2: Example of calculating path scores.
section, we describe a method for calculating similarities between potential coordinate conjuncts.
To measure the similarity between potential preand post-conjuncts, a lot of work on the coordination disambiguation used the similarity between conjoined heads.
However, not only the conjoined heads but also other components in conjuncts have some similarity and furthermore structural parallelism.
Therefore, we use a method to calculate the similarity between two whole coordinate conjuncts (KurohashiandNagao, 1994).
Theremainderofthis section contains a brief description of this method.
To calculate similarity between two series of bunsetsus, a triangular matrix, A, is used (illustrated in Figure 1).
A = (a(i,j)) (0 ≤ i ≤ l;i ≤ j ≤ l) (1) where l is the number of bunsetsus in a sentence, diagonal element a(i,j) is the i-th bunsetsu, and elementa(i,j) (i < j) isthesimilarityvaluebetween bunsetsus bi and bj.
A similarity value between two bunsetsus is calculated on the basis of POS matching, exact word matching, and their semantic closeness in a thesaurus tree (Kurohashi and Nagao, 1994).
We use the Bunruigoihyo thesaurus, which contains 96,000 Japanese words (The National Institute for Japanese Language, 2004).
To detect a coordinate structure involving a key bunsetsu, bn, we consider only a partial matrix (denoted An), that is, the upper right part of bn (Figure 1).
An = (a(i,j)) (0 ≤ i ≤ n;n + 1 ≤ j ≤ l) (2) To specify correspondences between bunsetsus in potential preand post-conjuncts, a path is deﬁned as follows: path ::= (a(p1,m), a(p2,m−1), ..., a(pm−n,n + 1)) (3) where n+1 ≤ m ≤ l, a(p1,m) negationslash= 0, p1 = n, pi ≥ pi+1, (1 ≤ i ≤ m−n−1).
That is, a path represents a series of elements from a non-zero element in the lowest row in An to an element in the leftmost column in An.
The path has an only element in each column and extends toward theupperleft.
Theseriesofbunsetsusontheleftside of the path and the series under the path are potential conjuncts for key bn.
Figure 2 shows an example of a path.
Apathscoreisdeﬁnedbasedonthefollowingcriteria: • the sum of each element’s points on the path • penalty points when the path extends nondiagonally (which causes conjuncts of unbalanced lengths) • bonus points on expressions signaling the beginning or ending of a coordinate structure, such as “kaku“ (each) and nado” (and so on) • the total score of the above criteria is divided by the square root of the number of bunsetsus covered by the path for normalization The score of each path is calculated using a dynamic programming method.
We consider each path as a candidate of preand post-conjuncts.
309 5 Integrated Probabilistic Model for Syntactic, Coordinate and Case Structure Analysis This section describes a method of integrating coordination disambiguation into a probabilistic parsing model.
The integrated model is based on a fullylexicalized probabilistic model for Japanese syntactic and case structure analysis (Kawahara and Kurohashi, 2006b).
5.1 Outline
of the Model This model gives a probability to each possible dependency structure, T, and case structure, L, of the input sentence, S, and outputs the syntactic, coordinate and case structure that have the highest probability.
That is to say, the model selects the syntactic structure, Tbest, and the case structure, Lbest, that maximize the probability, P(T,L|S): (Tbest,Lbest) = argmax(T,L)P(T,L|S) = argmax(T,L)P(T,L,S)P(S) = argmax(T,L)P(T,L,S) (4) The last equation is derived because P(S) is constant.
The model considers a clause as a generation unit and generates the input sentence from the end of the sentence in turn.
The probability P(T,L,S) is deﬁned as the product of probabilities for generating clause Ci as follows: P(T,L,S) = ∏ i=1..nP(Ci,relihi|Chi) (5) where n is the number of clauses in S, Chi is Ci’s modifying clause, and relihi is the dependency relation between Ci and Chi.
The main clause, Cn, at the end of a sentence does not have a modifying head, but a virtual clause Chn = EOS (End Of Sentence) is inserted.
Dependency relation relihi is ﬁrst classiﬁed into two types C (coordinate) and D (normal dependency), and C is further divided into ﬁve classes according to the binned similarity (path score) of conjuncts.
Therefore, relihi can be one of the following six classes.
relihi = {D,C0,C1,C2,C3,C4} (6) For instance, C0 represents a coordinate relation with a similarity of less than 1, and C4 represents a coordinate relation with a similarity of 4 or more.
bentou-watabete-te kaet-ta(go home) bentou-watabete-te kaet-ta(go home) EOSEOS )|,( EOSDtakaetP − )|,( EOSDtakaetwabentouP −−)|,( takaetDtetabewabentouP −−− )|,( takaetwabentouDtetabeP −−− (eat) (lunchbox) (eat (lunchbox) )|,( EOSDtakaetP − )|,( EOSDtakaetwabentouP −−)|0,( takaetCtetabewabentouP −−− )|0,( takaetwabentouCtetabeP −−− (1) (3) (4)(2) Dependency structure Dependency structure21,TT 43,TT DT:1 0:2 CT DT:3 0:4 CT Figure 3: Example of probability calculation.
For example, consider the sentence shown in Figure 3.
There are four possible dependency structures in this ﬁgure, and the product of the probabilities for each structure indicated below the tree is calculated.
Finally, the model chooses the structure with the highest probability (in this case T1 is chosen).
Clause Ci is decomposed into its clause type, fi, (including the predicate’s inﬂection and function words) and its remaining content part Ciprime.
Clause Chi is also decomposed into its content part, Chiprime, and its clause type, fhi.
P(Ci,relihi|Chi) = P(Ciprime,fi,relihi|Chiprime,fhi) = P(Ciprime,relihi|fi,Chiprime,fhi)×P(fi|Chiprime,fhi) ≈ P(Ciprime,relihi|fi,Chiprime)×P(fi|fhi) (7) Equation(7)isderivedbecausethecontentpart, Ciprime, is usually independent of its modifying head type, fhi, and in most cases, the type, fi, is independent of the content part of its modifying head, Chi.
We call P(Ciprime,relihi|fi,Chiprime) generative probability of a case and coordinate structure, and P(fi|fhi) generative probability of a clause type.
The latter is the probability of generating function words including topic markers and punctuation marks, and is estimated using a syntactically annotated corpus in the same way as (Kawahara and Kurohashi, 2006b).
The generative probability of a case and coordinate structure can be rewritten as follows: P(Ciprime,relihi|fi,Chiprime) = P(Ciprime|relihi,fi,Chiprime)×P(relihi|fi,Chiprime) ≈ P(Ciprime|relihi,fi,Chiprime)×P(relihi|fi) (8) 310 Equation (8) is derived because dependency relations (coordinate or not) heavily depend on modiﬁer’s types including coordination keys.
We call P(Ciprime|relihi,fi,Chiprime) generative probability of a case structure, and P(relihi|fi) generative probability of a coordinate structure.
The following two subsections describe these probabilities.
5.2 Generative
Probability of Coordinate Structure The most important feature to decide whether two clauses are coordinate is coordination keys.
Therefore, we consider a coordination key, ki, as clause type fi.
The generative probability of a coordinate structure, P(relihi|fi), is deﬁned as follows: P(relihi|fi) = P(relihi|ki) (9) We classiﬁed coordination keys into 52 classes according to the classiﬁcation proposed by (Kurohashi and Nagao, 1994).
If type fi does not contain a coordination key, the relation is always D (normal dependency), that is P(relihi|fi) = P(D|φ) = 1.
The generative probability of a coordinate structure was estimated from a syntactically annotated corpus using maximum likelihood.
We used the Kyoto Text Corpus (Kurohashi and Nagao, 1998), which consists of 40K Japanese newspaper sentences.
5.3 Generative
Probability of Case Structure We consider that a case structure consists of a predicate, vi, a case frame, CFl, and a case assignment, CAk.
Case assignment CAk represents correspondences between the input case components and the case slots shown in Figure 4.
Thus, the generative probability of a case structure is decomposed as follows: P(Ciprime|relihi,fi,Chiprime) = P(vi,CFl,CAk|relihi,fi,Chiprime) = P(vi|relihi,fi,Chiprime) ×P(CFl|relihi,fi,Chiprime,vi) ×P(CAk|relihi,fi,Chiprime,vi,CFl) ≈ P(vi|relihi,fi,whi) ×P(CFl|vi) ×P(CAk|CFl,fi) (10) bentou-wa tabete(lunchbox) (eat) … lunchbox, bread, …wo man, student, …gataberu1 (eat) Case Frame CFl Case AssignmentCA k (no correspondence)Dependency Structure of S Figure 4: Example of case assignment.
The above approximation is given because it is natural to consider that the predicate vi depends on its modifying head whi instead of the whole modifying clause, that the case frame CFl only depends on the predicate vi, and that the case assignment CAk depends on the case frame CFl and the clause type fi.
The generative probabilities of case frames and case assignments are estimated from case frames themselvesinthesamewayas(KawaharaandKurohashi, 2006b).
The remainder of this section describes the generative probability of a predicate, P(vi|relihi,fi,whi).
The generative probability of a predicate captures cooccurrences of coordinate or non-coordinate phrases.
This kind of information is not handled in case frames, which aggregate only predicateargument relations.
The generative probability of a predicate mainly depends on a coordination key in the clause type, fi, as well as the generative probability of a coordinate structure.
We deﬁne this probability as follows: P(vi|relihi,fi,whi) = P(vi|relihi,ki,whi) If Ciprime is a nominal clause and consists of a noun ni, we consider the following probability in stead of equation (10): Pn(Ciprime|relihi,fi,Chiprime) ≈ P(ni|relihi,fi,whi) This is because a noun does not have a case frame and any case components in the current framework.
To estimate these probabilities, we ﬁrst applied a conventional parsing system with coordination disambiguation to a huge corpus, and collected coordinate bunsetsus from the parses.
We used KNP2 (Kurohashi and Nagao, 1994) as the parser and a web corpus consisting of 470M Japanese sentences (Kawahara and Kurohashi, 2006a).
The generative probability of a predicate was estimated from the 2http://nlp.kuee.kyoto-u.ac.jp/nl-resource/knp-e.html 311 collectedcoordinatebunsetsususingmaximumlikelihood.
5.4 Practical
Issue The proposed model considers all the possible dependency structures including coordination ambiguities.
To reduce this high computational cost, we introduced the CKY framework to the search.
Eachparameterinthemodelissmoothedbyusing several back-off levels in the same way as (Collins, 1999).
Smoothing parameters are optimized using a development corpus.
6 Experiments
We evaluated the coordinate structures and dependency structures that were outputted by our model.
The case frames used in this paper were automaticallyconstructedfrom470MJapanesesentencesobtained from the web.
Some examples of the case frames are listed in Table 1 (Kawahara and Kurohashi, 2006a).
In this work, the parameters related to unlexical types are calculated from a small tagged corpus of newspaper articles, and lexical parameters are obtained from a huge web corpus.
To evaluate the effectiveness of our fully-lexicalized model, our experiments are conducted using web sentences.
As the test corpus, we prepared 759 web sentences 3.
The web sentences were manually annotated using the same criteria as the Kyoto Text Corpus.
We also usedtheKyotoTextCorpusasadevelopmentcorpus to optimize the smoothing parameters.
The system input was automatically tagged using the JUMAN morphological analyzer 4.
We used two baseline systems for comparative purposes: the rule-based dependency parser, KNP (Kurohashi and Nagao, 1994), and the probabilistic model of syntactic and case structure analysis (Kawahara and Kurohashi, 2006b), in which coordination disambiguation is the same as that of KNP.
6.1 Evaluation
of Detection of Coordinate Structures First, we evaluated detecting coordinate structures, namelywhetheracoordinationkeybunsetsutriggers 3The test set was not used to construct case frames and estimate probabilities.
4http://nlp.kuee.kyoto-u.ac.jp/nl-resource/juman-e.html Table 3: Experimental results of detection of coordinate structures.
baseline proposed precision 366/460 (79.6%) 361/435 (83.0%) recall 366/447 (81.9%) 361/447 (80.8%) F-measure – (80.7%) – (81.9%) a coordinate structure.
Table 3 lists the experimental results.
The F-measure of our method is slightly higher than that of the baseline method (KNP).
In particular, our method achieved good precision.
6.2 Evaluation
of Dependency Parsing Secondly, we evaluated the dependency structures analyzed by the proposed model.
Evaluating the scope ambiguity of coordinate structures is subsumed within this dependency evaluation.
The dependency structures obtained were evaluated with regard to dependency accuracy — the proportion of correct dependencies out of all dependencies except for the last dependency in the sentence end 5.
Table 4 lists the dependency accuracy.
In this table, “syn” represents the rule-based dependency parser, KNP, “syn+case” represents the probabilistic parser of syntactic and case structure (Kawahara and Kurohashi, 2006b), and “syn+case+coord” represents our proposed model.
The proposed model signiﬁcantly outperformed both of the baseline systems (McNemar’s test; p < 0.01).
In the table, the dependency accuracies are classiﬁed into four types on the basis of the bunsetsu classes (PB: predicate bunsetsu and NB: noun bunsetsu) of a dependent and its head.
“syn+case” outperformed “syn”.
In particular, the accuracy of predicate-argument relations (“NB→PB”) was improved, but the accuracies of “NB→NB” and “PB→PB” decreased.
“syn+case+coord” outperformed the two baselines for all of the types.
Not only the accuracy of predicate-argument relations (“NB→PB”) but also the accuracies of coordinate noun/predicatebunsetsus(relatedto“NB→NB”and “PB→PB”) were improved.
These improvements are conduced by the integration of coordination disambiguation and syntactic/case structure analysis.
5Since Japanese is head-ﬁnal, the second last bunsetsu unambiguously depends on the last bunsetsu, and the last bunsetsu has no dependency.
312 Table 4: Experimental results of dependency parsing.
syn syn+case syn+case+coord all 3,833/4,436 (86.4%) 3,852/4,436 (86.8%) 3,893/4,436 (87.8%) NB→PB 1,637/1,926 (85.0%) 1,664/1,926 (86.4%) 1,684/1,926 (87.4%) NB→NB 1,032/1,136 (90.8%) 1,029/1,136 (90.6%) 1,037/1,136 (91.3%) PB→PB 654/817 (80.0%) 647/817 (79.2%) 659/817 (80.7%) PB→NB 510/557 (91.6%) 512/557 (91.9%) 513/557 (92.1%) To compare our results with a state-of-the-art discriminative dependency parser, we input the same testcorpusintoanSVM-basedJapanesedependency parser, CaboCha6(Kudo and Matsumoto, 2002).
Its dependency accuracy was 86.3% (3,829/4,436), which is equivalent to that of “syn” (KNP).
This low accuracy is attributed to the out-of-domain training corpus.
That is, the parser is trained on a newspaper corpus, whereas the test corpus is obtained from the web, because of the non-availability of a tagged web corpus that is large enough to train a supervised parser.
6.3 Discussion
Figure 5 shows some analysis results, where the dotted lines represent the analysis by the baseline, “syn+case”,andthesolidlinesrepresenttheanalysis by the proposed method, “syn+case+coord”.
These sentences are incorrectly analyzed by the baseline but correctly analyzed by the proposed method.
For instance, in sentence (1), the noun phrase coordination of “apurikeesyon” (application) and “doraiba” (driver) can be correctly analyzed.
This is because the case frame of “insutooru-sareru” (installed) is likely to generate “doraiba”, and “apurikeesyon” and “doraiba” are likely to be coordinated.
One of the causes of errors in dependency parsing is the mismatch between analysis results and annotation criteria.
As per the annotation criteria, each bunsetsuhasonlyonemodifyinghead.
Therefore,in some cases, even if analysis results are semantically correct, they are judged as incorrect from the viewpoint of the annotation.
For example, in sentence (4)inFigure6, thebaselinemethod, “syn”, correctly recognizedtheheadof“iin-wa”(commissioner-TM) as “hirakimasu” (open).
However, the proposed method incorrectly judged it as “oujite-imasuga” (offer).
Both analysis results can be considered to be semantically correct, but from the viewpoint of 6http://chasen.org/˜taku/software/cabocha/ our annotation criteria, the latter is not a syntactic relation (i.e., incorrect), but an ellipsis relation.
This kind of error is caused by the strong lexical preference considered in our method.
To address this problem, it is necessary to simultaneously evaluate not only syntactic relations but alsoindirectrelations,suchasellipsesandanaphora.
This kind of mismatch also occurred for the detection of coordinate structures.
Another errors were caused by an inherent characteristic of generative models.
Generative models have some advantages, such as their application to language models.
However, it is difﬁcult to incorporate various features that seem to be useful for addressing syntactic and coordinate ambiguity.
We plan to apply discriminative reranking to the n-best parsesproducedbyourgenerativemodelinthesame way as (Charniak and Johnson, 2005).
7 Conclusion
This paper has described an integrated probabilistic model for coordination disambiguation and syntactic/case structure analysis.
This model takes advantage of lexical preference of a huge raw corpus and large-scale case frames and performs coordination disambiguation and syntactic/case analysis simultaneously.
The experiments indicated the effectiveness of our model.
Our future work involves incorporating ellipsis resolution to develop an integrated model for syntactic, case, and ellipsis analysis.
Acknowledgment This research is partially supported by special coordination funds for promoting science and technology.
References Rajeev Agarwal and Lois Boggess.
1992. A simple but useful approach to conjunct identiﬁcation.
In Proceedings of ACL1992, pages 15–21.
Francis Chantree, Adam Kilgarriff, Anne de Roeck, and Alistair Wills.
2005. Disambiguating coordinations using word distribution information.
In Proceedings of RANLP2005.
Eugene Charniak and Mark Johnson.
2005. Coarse-to-ﬁne n-best parsing and maxent discriminative reranking.
In Proceedings of ACL2005, pages 173–180.
Michael Collins.
1999. Head-Driven Statistical Models for Natural Language Parsing.
Ph.D. thesis, University of Pennsylvania.
Amit Dubey, Frank Keller, and Patrick Sturt.
2006. Integrating syntactic priming into an incremental probabilistic parser, with an application to psycholinguistic modeling.
In Proceedings of COLING-ACL2006, pages 417–424.
Miriam Goldberg.
1999. An unsupervised model for statistically determining coordinate phrase attachment.
In Proceedings of ACL1999, pages 610–614.
Daisuke Kawahara and Sadao Kurohashi.
2006a. Case frame compilation from the web using high-performance computing.
In Proceedings of LREC2006.
Daisuke Kawahara and Sadao Kurohashi.
2006b. A fully-lexicalized probabilistic model for Japanese syntactic and case structure analysis.
In Proceedings of HLT-NAACL2006, pages 176–183.
Taku Kudo and Yuji Matsumoto.
2002. Japanese dependency analysis using cascaded chunking.
In Proceedings of CoNLL2002, pages 29–35.
Sadao Kurohashi and Makoto Nagao.
1994. A syntactic analysis method of long Japanese sentences based on the detection of conjunctive structures.
Computational Linguistics, 20(4):507–534.
Sadao Kurohashi and Makoto Nagao.
1998. Building a Japanese parsed corpus while improving the parsing system.
In Proceedings of LREC1998, pages 719–724.
Sadao Kurohashi.
1995. Analyzing coordinate structures including punctuation in English.
In Proceedings of IWPT1995, pages 136–147.
Philip Resnik.
1999. Semantic similarity in a taxonomy: An information-based measure and its application to problems of ambiguity in natural language.
Journal of Artiﬁcial Intelligence Research, 11:95–130.
Manabu Sassano.
2004. Linear-time dependency analysis for Japanese.
In Proceedings of COLING2004, pages 8–14.
The National Institute for Japanese Language.
2004. Bunruigoihyo.
Dainippon Tosho, (In Japanese) .

