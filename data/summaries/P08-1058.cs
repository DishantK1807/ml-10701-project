D. Talbot and M. Osborne. 2007b. Smoothed Bloom filter language models: Tera-scale LMs on the cheap. In EMNLP/CoNLL 2007, Prague. 513
D07-1049 P07-1065
Peter F. Brown, Vincent J. Della Pietra, Peter V. deSouza, Jennifer C. Lai, and Robert L. Mercer. 1992. Class based n-gram models of natural language. Computational Linguistics, 18(4):467–479.
J92-4003
Franz J. Och and Hermann Ney. 2004. The alignment template approach to statistical machine translation. Computational Linguistics, 30(4):417–449.
J04-4002
as class-based models (Brown et al., 1992), model
J92-4003
(Church et al., 2007) and distributed language mod-
D07-1021
proposed in (Och and Ney, 2004) where translation
J04-4002
Kenneth Church, Ted Hart, and Jianfeng Gao. 2007. Compressing trigram language models with golomb coding. In Proceedings of EMNLP-CoNLL 2007, Prague, Czech Republic, June.
D07-1021
lowing (Talbot and Osborne, 2007a) we can avoid
D07-1049 P07-1065
(Talbot and Osborne, 2007a). The space required in
D07-1049 P07-1065
Recent work (Talbot and Osborne, 2007b) has used
D07-1049 P07-1065
with stupid backoff smoothing (Brants et al., 2007)
D07-1090
2007), (Brants et al., 2007), (Church et al., 2007).
D07-1021 D07-1090
els that scale more readily (Brants et al., 2007).
D07-1090
Peter Brown, Stephen Della Pietra, Vincent Della Pietra, and Robert Mercer. 1993. The mathematics of machine translation: Parameter estimation. Computational Linguistics, 19(2):263–311.
J93-2003
D.TalbotandM.Osborne. 2007a. Randomisedlanguage modelling for statistical machine translation. In 45th Annual Meeting of the ACL 2007, Prague.
D07-1049 P07-1065
Previous work (Brants et al., 2007) has shown it to
D07-1090
Thorsten Brants, Ashok C. Popat, Peng Xu, Franz J. Och, and Jeffrey Dean. 2007. Large language models in machine translation. In Proceedings of EMNLPCoNLL 2007, Prague.
D07-1090
constructions in (Talbot and Osborne, 2007b) and
D07-1049 P07-1065
in (Brants et al., 2007); and “randomized” uses our
D07-1090
(Church et al., 2007) no errors are possible for n-
D07-1021
