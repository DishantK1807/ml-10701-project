<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>Della Pietra</author>
</authors>
<title>A maximum entropy approach to natural language processing</title>
<date>1996</date>
<journal>Computational Linguistics</journal>
<volume>22</volume>
<institution>Lynn Carlson, Daniel Marcu, and Mary Ellen Okurowski</institution>
<marker>Pietra, 1996</marker>
<rawString>Della Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguistics, 22(1):39–71. Lynn Carlson, Daniel Marcu, and Mary Ellen Okurowski.</rawString>
</citation>
<citation valid="true">
<title>Building a discourse-tagged corpus in the framework of Rhetorical Structure Theory</title>
<date>2003</date>
<booktitle>Current Directions in Discourse and Dialogue</booktitle>
<pages>85--112</pages>
<editor>In Jan van Kuppevelt and Ronnie Smith, editors</editor>
<publisher>Dordrecht: Kluwer Academic</publisher>
<marker>2003</marker>
<rawString>2003. Building a discourse-tagged corpus in the framework of Rhetorical Structure Theory. In Jan van Kuppevelt and Ronnie Smith, editors, Current Directions in Discourse and Dialogue, pages 85–112. Dordrecht: Kluwer Academic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David A Cohn</author>
<author>Zoubin Ghahramani</author>
<author>Michael I Jordan</author>
</authors>
<title>Active Learning with statistical models</title>
<date>1996</date>
<journal>Journal of Artifical Intelligence Research</journal>
<pages>4--129</pages>
<contexts>
<context> the unlabeled examples are closer to the hyperplane than the support vectors. While this approach is restricted to AL for SVMs, Vlachos (2008) presents a stopping criterion for uncertainty-based AL (Cohn et al., 1996) in general. The confidence of the classifier at the current AL iteration is estimated on a large, separate validation set. The author reports that such a confidence curve follows a rise-peak-drop pa</context>
</contexts>
<marker>Cohn, Ghahramani, Jordan, 1996</marker>
<rawString>David A. Cohn, Zoubin Ghahramani, and Michael I. Jordan. 1996. Active Learning with statistical models. Journal of Artifical Intelligence Research, 4:129–145.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sean Engelson</author>
<author>Ido Dagan</author>
</authors>
<title>Minimizing manual annotation cost in supervised training from corpora</title>
<date>1996</date>
<booktitle>In ACL’96 – Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics</booktitle>
<pages>319--326</pages>
<institution>University of California at</institution>
<location>Santa Cruz, CA, USA</location>
<contexts>
<context>cting those examples which are of high utility for the learning process. AL has been successfully applied to speed up the annotation process for many NLP tasks without sacrificing annotation quality (Engelson and Dagan, 1996; Ngai and Yarowsky, 2000; Hwa, 2001; Tomanek et al., 2007a). Once we decide to use AL for meta-data annotation and a reasonable, stable level of annotation quality is reached – after having run throu</context>
<context>red most informative for learning and are thus selected for manual annotation. To calculate the disagreement among the committee members several metrics have been proposed including the vote entropy (Engelson and Dagan, 1996) as possibly the most well-known one. Our approach to approximating the learning curve is based on the disagreement within a committee. However, it is independent of the actual metric used to calcula</context>
<context>on, each classifier is trained on a randomly1 drawn (sampling without replacement) subset L′ ⊂ L with |L′| = 23, L being the set of all examples seen so far. Disagreement is measured by vote entropy (Engelson and Dagan, 1996). In our NER scenario, complete sentences are selected by AL. While we made use of ME classifiers during the selection, we employed a NE tagger based on Conditional Random Fields (CRFs) (Lafferty et </context>
</contexts>
<marker>Engelson, Dagan, 1996</marker>
<rawString>Sean Engelson and Ido Dagan. 1996. Minimizing manual annotation cost in supervised training from corpora. In ACL’96 – Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics, pages 319– 326. University of California at Santa Cruz, CA, USA, 24-27 June 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Udo Hahn</author>
<author>Elena Beisswanger</author>
<author>Ekaterina Buyko</author>
<author>Michael Poprat</author>
<author>Katrin Tomanek</author>
<author>Joachim Wermter</author>
</authors>
<date>2008</date>
<contexts>
<context> random seed set of 20 sentences. Our results are averaged over three independent runs. For the real-world annotation scenario, we considered two sub-corpora from the entity annotations described in (Hahn et al., 2008): The cytokine and growth factor receptors corpus (CYTOREC) is annotated with various entity subclasses of special receptor entities, while the antigens corpus (CDANTIGEN) contains annotations of var</context>
</contexts>
<marker>Hahn, Beisswanger, Buyko, Poprat, Tomanek, Wermter, 2008</marker>
<rawString>Udo Hahn, Elena Beisswanger, Ekaterina Buyko, Michael Poprat, Katrin Tomanek, and Joachim Wermter. 2008.</rawString>
</citation>
<citation valid="true">
<title>Semantic annotations for biology: A corpus development initiative at the Jena University Language &amp; Information Engineering (JULIE) Lab</title>
<date>2008</date>
<booktitle>In LREC 2008 – Proceedings of the 6th International Conference on Language Resources and Evaluation</booktitle>
<location>Marrakech, Morocco</location>
<contexts>
<context>e annotation process when, in the current AL iteration, none of the unlabeled examples are closer to the hyperplane than the support vectors. While this approach is restricted to AL for SVMs, Vlachos (2008) presents a stopping criterion for uncertainty-based AL (Cohn et al., 1996) in general. The confidence of the classifier at the current AL iteration is estimated on a large, separate validation set. T</context>
<context>in in classifier performance is falling below some threshold. For uncertainty-based AL, further stopping criteria employing a confidence estimate of the current classifier were proposed by Zhu et al. (2008). The first one is based on an uncertainty measurement on all unlabeled examples of a pool, the second one uses the prediction accuracy on the selected examples, and the final one builds on the classi</context>
</contexts>
<marker>2008</marker>
<rawString>Semantic annotations for biology: A corpus development initiative at the Jena University Language &amp; Information Engineering (JULIE) Lab. In LREC 2008 – Proceedings of the 6th International Conference on Language Resources and Evaluation. Marrakech, Morocco, June 28-30, 2008. Paris: European Language Resources Association (ELRA). (this volume).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Hwa</author>
</authors>
<title>On minimizing training corpus for parser acquisition</title>
<date>2001</date>
<booktitle>In CoNLL-2001 – Proceedings of the 5th Natural Language Learning Workshop</booktitle>
<pages>84--89</pages>
<contexts>
<context>the learning process. AL has been successfully applied to speed up the annotation process for many NLP tasks without sacrificing annotation quality (Engelson and Dagan, 1996; Ngai and Yarowsky, 2000; Hwa, 2001; Tomanek et al., 2007a). Once we decide to use AL for meta-data annotation and a reasonable, stable level of annotation quality is reached – after having run through only a fraction of the documents </context>
</contexts>
<marker>Hwa, 2001</marker>
<rawString>Rebecca Hwa. 2001. On minimizing training corpus for parser acquisition. In CoNLL-2001 – Proceedings of the 5th Natural Language Learning Workshop, pages 84–89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>France Toulouse</author>
</authors>
<date>2001</date>
<pages>6--7</pages>
<marker>Toulouse, 2001</marker>
<rawString>Toulouse, France, 6-7 July 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seth Kulick</author>
<author>Ann Bies</author>
<author>Mark Liberman</author>
<author>Mark Mandel</author>
<author>Ryan McDonald</author>
<author>Martha Palmer</author>
<author>Andrew Schein</author>
<author>Lyle Ungar</author>
<author>Scott Winters</author>
<author>Pete White</author>
</authors>
<title>Integrated annotation for biomedical information extraction</title>
<date>2004</date>
<booktitle>In BioLink 2004 – Proceedings of the HLT-NAACL</booktitle>
<pages>61--68</pages>
<contexts>
<context>burden on developers of NLP systems to supply comparably sized high-quality annotations. Even inner-domain shifts, such as, e.g., moving from hematology (Ohta et al., 2002) to the genetics of cancer (Kulick et al., 2004) within the field of molecular biology may have drastic consequences in the sense that entirely new meta data sets have to produced by annotation teams. Thus, reducing the human efforts for the creat</context>
<context>andard for plotting the learning curve we used CoNLL’s evaluation corpus which sums up to 3,453 sentences. The PBVAR corpus consists of biomedical abstracts and was derived from the PENNBIOIE corpus (Kulick et al., 2004) by keeping only those annotations related to variation event mentions. We have randomly split this corpus into a pool set and a validation/gold set. In our simulations, 20 sentences were selected in</context>
</contexts>
<marker>Kulick, Bies, Liberman, Mandel, McDonald, Palmer, Schein, Ungar, Winters, White, 2004</marker>
<rawString>Seth Kulick, Ann Bies, Mark Liberman, Mark Mandel, Ryan McDonald, Martha Palmer, Andrew Schein, Lyle Ungar, Scott Winters, and Pete White. 2004. Integrated annotation for biomedical information extraction. In BioLink 2004 – Proceedings of the HLT-NAACL 2004 Workshop ‘Linking Biological Literature, Ontologies and Databases: Tools for Users’, pages 61–68.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John D Lafferty</author>
<author>Andrew McCallum</author>
<author>C N Fernando</author>
</authors>
<date>2004</date>
<location>Boston, MA, USA</location>
<marker>Lafferty, McCallum, Fernando, 2004</marker>
<rawString>Boston, MA, USA, May 2004. John D. Lafferty, Andrew McCallum, and Fernando C. N.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
<date>2001</date>
<booktitle>In ICML-2001 – Proceedings of the 18th International Conference on Machine Learning</booktitle>
<pages>282--289</pages>
<location>Williams College, MA, USA</location>
<marker>Pereira, 2001</marker>
<rawString>Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In ICML-2001 – Proceedings of the 18th International Conference on Machine Learning, pages 282–289. Williams College, MA, USA, June 28 July 1, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: The PENN TREEBANK</title>
<date>1993</date>
<journal>Computational Linguistics</journal>
<volume>19</volume>
<contexts>
<context>P components are increasingly based on supervised machine learning methods. This raises the need for large amounts of training data. While for the general language English newspaper domain syntactic (Marcus et al., 1993), semantic (Palmer et al., 2005; Pustejovsky et al., 2003), and even discourse (Carlson et al., 2003; Miltsakaki et al., 2008) annotations are increasingly made available, any language, domain, or ge</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of English: The PENN TREEBANK. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eleni Miltsakaki</author>
<author>Livio Robaldo</author>
<author>Alan Lee</author>
<author>Aravind Joshi</author>
</authors>
<title>Sense annotation in the Penn Discourse Treebank</title>
<date>2008</date>
<booktitle>CICLing 2008 – Proceedings of the 9th International Conference on Computational Linguistics and Intelligent Text Processing</booktitle>
<pages>275--286</pages>
<editor>In Alexander F. Gelbukh, editor</editor>
<publisher>Springer</publisher>
<location>Haifa, Israel</location>
<contexts>
<context>ning data. While for the general language English newspaper domain syntactic (Marcus et al., 1993), semantic (Palmer et al., 2005; Pustejovsky et al., 2003), and even discourse (Carlson et al., 2003; Miltsakaki et al., 2008) annotations are increasingly made available, any language, domain, or genre shift pushes the severe burden on developers of NLP systems to supply comparably sized high-quality annotations. Even inne</context>
</contexts>
<marker>Miltsakaki, Robaldo, Lee, Joshi, 2008</marker>
<rawString>Eleni Miltsakaki, Livio Robaldo, Alan Lee, and Aravind Joshi. 2008. Sense annotation in the Penn Discourse Treebank. In Alexander F. Gelbukh, editor, CICLing 2008 – Proceedings of the 9th International Conference on Computational Linguistics and Intelligent Text Processing, pages 275–286. Haifa, Israel, February 17-23, 2008. Berlin: Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grace Ngai</author>
<author>David Yarowsky</author>
</authors>
<title>Rule writing or annotation: Cost-efficient resource usage for base noun phrase chunking</title>
<date>2000</date>
<booktitle>In ACL’00 – Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics</booktitle>
<pages>117--125</pages>
<location>Hong Kong, China</location>
<contexts>
<context> are of high utility for the learning process. AL has been successfully applied to speed up the annotation process for many NLP tasks without sacrificing annotation quality (Engelson and Dagan, 1996; Ngai and Yarowsky, 2000; Hwa, 2001; Tomanek et al., 2007a). Once we decide to use AL for meta-data annotation and a reasonable, stable level of annotation quality is reached – after having run through only a fraction of the</context>
</contexts>
<marker>Ngai, Yarowsky, 2000</marker>
<rawString>Grace Ngai and David Yarowsky. 2000. Rule writing or annotation: Cost-efficient resource usage for base noun phrase chunking. In ACL’00 – Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics, pages 117–125. Hong Kong, China, 1-8 August 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomoko Ohta</author>
<author>Yuka Tateisi</author>
<author>Jin-Dong Kim</author>
</authors>
<title>The GENIA corpus: An annotated research abstract corpus in molecular biology domain</title>
<date>2002</date>
<booktitle>In HLT 2002 – Human Language Technology Conference. Proceedings of the 2nd International Conference on Human Language Technology Research</booktitle>
<pages>82--86</pages>
<location>San Diego, CA, USA</location>
<contexts>
<context>age, domain, or genre shift pushes the severe burden on developers of NLP systems to supply comparably sized high-quality annotations. Even inner-domain shifts, such as, e.g., moving from hematology (Ohta et al., 2002) to the genetics of cancer (Kulick et al., 2004) within the field of molecular biology may have drastic consequences in the sense that entirely new meta data sets have to produced by annotation teams</context>
</contexts>
<marker>Ohta, Tateisi, Kim, 2002</marker>
<rawString>Tomoko Ohta, Yuka Tateisi, and Jin-Dong Kim. 2002. The GENIA corpus: An annotated research abstract corpus in molecular biology domain. In HLT 2002 – Human Language Technology Conference. Proceedings of the 2nd International Conference on Human Language Technology Research, pages 82–86. San Diego, CA, USA, March 24-27, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Daniel Gildea</author>
<author>Paul Kingsbury</author>
</authors>
<title>The Proposition Bank: An annotated corpus of semantic roles</title>
<date>2005</date>
<journal>Computational Linguistics</journal>
<volume>31</volume>
<contexts>
<context>sed on supervised machine learning methods. This raises the need for large amounts of training data. While for the general language English newspaper domain syntactic (Marcus et al., 1993), semantic (Palmer et al., 2005; Pustejovsky et al., 2003), and even discourse (Carlson et al., 2003; Miltsakaki et al., 2008) annotations are increasingly made available, any language, domain, or genre shift pushes the severe burd</context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>Martha Palmer, Daniel Gildea, and Paul Kingsbury. 2005. The Proposition Bank: An annotated corpus of semantic roles. Computational Linguistics, 31(1):71–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Patrick Hanks</author>
<author>Roser Saur´ı</author>
<author>Andrew See</author>
<author>Robert Gaizauskas</author>
<author>Andrea Setzer</author>
<author>Dragomir Radev</author>
<author>Beth Sundheim</author>
<author>David Day</author>
<author>Lisa Ferro</author>
<author>Marcia Lazo</author>
</authors>
<title>The TIMEBANK corpus</title>
<date>2003</date>
<booktitle>In Proceedings of the Corpus Linguistics 2003 Conference</booktitle>
<pages>647--656</pages>
<location>Lancaster University, U.K</location>
<marker>Pustejovsky, Hanks, Saur´ı, See, Gaizauskas, Setzer, Radev, Sundheim, Day, Ferro, Lazo, 2003</marker>
<rawString>James Pustejovsky, Patrick Hanks, Roser Saur´ı, Andrew See, Robert Gaizauskas, Andrea Setzer, Dragomir Radev, Beth Sundheim, David Day, Lisa Ferro, and Marcia Lazo. 2003. The TIMEBANK corpus. In Proceedings of the Corpus Linguistics 2003 Conference, pages 647–656. Lancaster University, U.K., 28-31 March 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Greg Schohn</author>
<author>David Cohn</author>
</authors>
<title>Less is more: Active Learning with Support Vector Machines</title>
<date>2000</date>
<booktitle>In ICML 2000 – Proceedings of the 17th International Conference on Machine Learning</booktitle>
<volume>29</volume>
<pages>839--846</pages>
<location>Stanford, CA, USA</location>
<marker>Schohn, Cohn, 2000</marker>
<rawString>Greg Schohn and David Cohn. 2000. Less is more: Active Learning with Support Vector Machines. In ICML 2000 – Proceedings of the 17th International Conference on Machine Learning, pages 839–846. Stanford, CA, USA, June 29 July 2, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Sebastian Seung</author>
<author>Manfred Opper</author>
<author>Haim Sompolinsky</author>
</authors>
<title>Query by committee</title>
<date>1992</date>
<booktitle>In COLT’92 – Proceedings of the 5th Annual Conference on Computational Learning Theory</booktitle>
<pages>287--294</pages>
<publisher>ACM Press</publisher>
<location>Pittsburgh, PA, USA</location>
<contexts>
<context>r performance gain, we here propose an approach to approximate the progression of the learning curve which comes at no extra annotation costs. This approach is designed for use in committee-based AL (Seung et al., 1992). A committee consists of k classifiers of the same type trained on different subsets of the already labeled (training) data. Each committee member then makes its predictions on the pool of unlabeled</context>
</contexts>
<marker>Seung, Opper, Sompolinsky, 1992</marker>
<rawString>H. Sebastian Seung, Manfred Opper, and Haim Sompolinsky. 1992. Query by committee. In COLT’92 – Proceedings of the 5th Annual Conference on Computational Learning Theory, pages 287–294. Pittsburgh, PA, USA, July 27-29, 1992. New York, NY: ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik F Tjong Kim Sang</author>
<author>Fien De Meulder</author>
</authors>
<title>Introduction to the CONLL-2003 shared task: Languageindependent named entity recognition</title>
<date>2003</date>
<booktitle>In CoNLL-2003 – Proceedings of the 7th Conference on Computational Natural Language Learning</booktitle>
<pages>142--147</pages>
<location>Edmonton, Canada</location>
<marker>Sang, De Meulder, 2003</marker>
<rawString>Erik F. Tjong Kim Sang and Fien De Meulder. 2003. Introduction to the CONLL-2003 shared task: Languageindependent named entity recognition. In CoNLL-2003 – Proceedings of the 7th Conference on Computational Natural Language Learning, pages 142–147. Edmonton, Canada, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Tomanek</author>
<author>Joachim Wermter</author>
<author>Udo Hahn</author>
</authors>
<title>An approach to text corpus construction which cuts annotation costs and maintains reusability of annotated data</title>
<date>2007</date>
<booktitle>In EMNLP-CoNLL 2007 -– Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</booktitle>
<pages>486--495</pages>
<location>Prague, Czech Republic</location>
<contexts>
<context>g process. AL has been successfully applied to speed up the annotation process for many NLP tasks without sacrificing annotation quality (Engelson and Dagan, 1996; Ngai and Yarowsky, 2000; Hwa, 2001; Tomanek et al., 2007a). Once we decide to use AL for meta-data annotation and a reasonable, stable level of annotation quality is reached – after having run through only a fraction of the documents compared with the trad</context>
<context> gold standard in the number of sentences) This effect is truly beneficial, especially for real-world annotation projects, due to much lower training times and, by this, shorter annotator idle times (Tomanek et al., 2007a). For the AL simulation, we employed two simulation corpora: The CONLL corpus, based on the English data set of the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003), which consists of ne</context>
</contexts>
<marker>Tomanek, Wermter, Hahn, 2007</marker>
<rawString>Katrin Tomanek, Joachim Wermter, and Udo Hahn. 2007a. An approach to text corpus construction which cuts annotation costs and maintains reusability of annotated data. In EMNLP-CoNLL 2007 -– Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 486–495. Prague, Czech Republic, June 28-30, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Tomanek</author>
<author>Joachim Wermter</author>
<author>Udo Hahn</author>
</authors>
<date>2007</date>
<contexts>
<context>g process. AL has been successfully applied to speed up the annotation process for many NLP tasks without sacrificing annotation quality (Engelson and Dagan, 1996; Ngai and Yarowsky, 2000; Hwa, 2001; Tomanek et al., 2007a). Once we decide to use AL for meta-data annotation and a reasonable, stable level of annotation quality is reached – after having run through only a fraction of the documents compared with the trad</context>
<context> gold standard in the number of sentences) This effect is truly beneficial, especially for real-world annotation projects, due to much lower training times and, by this, shorter annotator idle times (Tomanek et al., 2007a). For the AL simulation, we employed two simulation corpora: The CONLL corpus, based on the English data set of the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003), which consists of ne</context>
</contexts>
<marker>Tomanek, Wermter, Hahn, 2007</marker>
<rawString>Katrin Tomanek, Joachim Wermter, and Udo Hahn. 2007b.</rawString>
</citation>
<citation valid="true">
<title>Efficient annotation with the Jena ANnotation Environment (JANE</title>
<booktitle>In The LAW at ACL 2007 – Proceedings of the Linguistic Annotation Workshop</booktitle>
<pages>9--16</pages>
<marker></marker>
<rawString>Efficient annotation with the Jena ANnotation Environment (JANE). In The LAW at ACL 2007 – Proceedings of the Linguistic Annotation Workshop, pages 9–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Czech Republic Prague</author>
</authors>
<date>2007</date>
<marker>Prague, 2007</marker>
<rawString>Prague, Czech Republic, June 28-29, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Vlachos</author>
</authors>
<title>A stopping criterion for active learning</title>
<date>2008</date>
<journal>Computer Speech and Language</journal>
<pages>22--295</pages>
<marker>Vlachos, 2008</marker>
<rawString>Andreas Vlachos. 2008. A stopping criterion for active learning. Computer Speech and Language, 22:295-312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jingbo Zhu</author>
<author>Huizhen Wang</author>
<author>Eduard Hovy</author>
</authors>
<date>2008</date>
<marker>Zhu, Wang, Hovy, 2008</marker>
<rawString>Jingbo Zhu, Huizhen Wang, and Eduard Hovy. 2008.</rawString>
</citation>
</citationList>
</algorithm>

