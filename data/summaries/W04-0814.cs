Every sentence was part-of-speech tagged using a maximum entropy tagger (Ratnaparkhi, 1996) and parsed using a state-of-the-art wide coverage phrase structure parser (Collins, 1999).
W96-0213
Similarly to (Gildea and Jurafsky, 2002), our own evaluation showed that about 15% of frame elements in FrameNet 1.1 do not correspond to constituents, even when applying some straighforward heuristics (see below) to compensate for this mismatch.
J02-3001
Labeling of Semantic Roles For the SR task, we applied a method very similar to the one used in (Jijkoun and de Rijke, 2004) for recovering syntactic structures and somewhat similar to the first method for automatic semantic role identification described in (Gildea and Jurafsky, 2002).
J02-3001 P04-1040
Processing For both tasks, SR and LF, the core of our systems was the syntactic analysis module described in detail in (Jijkoun and de Rijke, 2004).
P04-1040
We chose TiMBL for this task because we had previously found that it deals successfully with complex feature spaces and data sparseness (in our case, in the presence of many lexical features) (Jijkoun and de Rijke, 2004).
P04-1040
Trained and tested on WSJ, our system achieves state-of-the-art performance for recovery of Penn functional tags and nonlocal dependencies (Jijkoun and de Rijke, 2004).
P04-1040
