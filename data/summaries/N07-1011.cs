This could be incorporated in a ranking scheme, as in Ng (2005).
P05-1020
Although our train-test splits may differ slightly, the best B-Cubed F1 score reported in Ng (2005) is 69.3%, which is considerably lower than the 79.3% obtained with our method.
P05-1020
Luo et al.(2004) do enable features between mention-cluster pairs, but do not perform the error-driven and ranking enhancements proposed in our work.
P04-1018
Any partitioning method is applicable here; however, perhaps most common for coreference is to perform greedy clustering guided by the word order of the document to complement the sampling method described above (Soon et al., 2001).
J01-4004
Collins and Roark (2004) present an incremental perceptron algorithm for parsing that uses “early update” to update the parameters when an error is encountered.
P04-1015
To our knowledge, the best results on this dataset were obtained by the meta-classification scheme of Ng (2005).
P05-1020
There have been a number of machine learning approaches to coreference resolution, traditionally factored into classification decisions over pairs of nouns (Soon et al., 2001; Ng and Cardie, 2002).
J01-4004 P02-1014
Others have attempted to train global scoring functionsusingGibbssampling(Finkeletal., 2005), message propagation, (Bunescu and Mooney, 2004; Sutton and McCallum, 2004), and integer linear programming (Roth and Yih, 2004).
P04-1056 P05-1045 W04-2401
We follow Soon et al.(2001) and Ng and Cardie (2002) to generate most of our features for the Pairwise Model.
J01-4004 P02-1014
Instead, Soon et al.(2001) propose the following sampling method: Scan the document from left to right.
J01-4004
Ng (2005) learns a meta-classifier to choose the best prediction from the output of several coreference systems.
P05-1020
Also note that the Pairwise baseline obtains results similar to those in Ng and Cardie (2002).
P02-1014
