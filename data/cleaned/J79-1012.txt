American Journal of Computational Linguistics THE YoERKISH LANGUAG~E Department of Psychology University of Georgia and Yerkes ~egional Primate Research Center Microfiche $12 Copyright 1975 Association for Computational Linguistics Abstract Yerkish, the language descritr4d in this paper, was devigrred for the purpose of exploring the extent to which non-human organisms (e.g.
great apes) could be t-,rougiit to acquire linguistic skills.
First attempts at teaching a spoken language to non-human primates had failed, app3rently because ol tlle animals' incapacity vocally.
to produce tlle phonemes of a natural language.
Subsequent work (Gardner G Cardner, 1971; I'remack, 1971) demonstrated that colr.munication could be achieved Ey means of visual signs or symbols.
Yerkish is a visual language with a lexicon of gsaplric word symbols (lexigrams), each of whicl;l is a combination of discrete recursive-design elements.
Each lexigram is represented on one of 125 keys of a keyboard, Sentences are formed by pressing keys in successive order.
Sentence length, at present, is limited to seven lexigrams.
Input from the keyboard is monitored and recorded by a computer that, contains in its core the lexicon, A parser, and certain response capabilities.
The grammar is strictly interpretive and was derived fror t1:e 1 correlational' systkm implenlented in the ?Iult is tore parser for 1:n~lisP.
sentences (von Clasersfeld.& Pisani, 197-0).
?he parser works on the basis of essentially non-lingui~tic classifications of items arkd relational concepts (tables of the operational classes are provided in this Faper).
It produces a structural analysis in terms of imr?.ediat,e constituents.
If an input string yields one comprehensive structure, the string is deemed grammat.ica1.
The firstlexigram functions as a sentence marker indicating the mood of the utterance: affirmative, negative, interrogative, and imperative.
In the case of certain requests (imperatives), the conputer activates mechanical devices that fulfil the request (dispensing food, drink, toys, playing music or a movie, etc).
Given this response capability, a 24-hour learning situation is created in which there.is always some 'potential incentive for the animal to use linguistic communication.
Yerkish lexigrams and sentences are easily translated into English, but semantics and sentence structure are somewhat restricted.
Lexigrarns alvays have only one meaning of the corresponding English and the rules for their concatenation \$ere designed to reduce ambiguities to a minimum.
The paper explains deviations from ~nglish grammar by means of structural diagrams and demonstrates that, in spite of the many simpli f ications, Yerkish allows for embedded clau-ses and is, indeed, capable of expansion in many directions.
? Three examples of conversqtions' with the young female chimpanzee that is being taught the use of Yerkish are added as an appendix to the paper.
TABLE OF CONTENTS Ustract .......................... 2 Introduction ........................ 5 Background ......................... 8 The Communication Facility ................. 11 The Yerkish Lexigrams ................... 14 ..........
Interpretive versus Descriptive Grammar 16 ..............
A Restrictxd Universe of Discourse 18 Technical Constraints ................... 19 ...................
The Grammar of Yerkish 22 ..............
Peculiarities of Yerkish Grammar 31 Conclusion ......................... 38 References ......................... 40 TABLES 1 . Design Elements .................... 42 2 . Semantic Color-Coding of Lexigrams ........... 43 3 . Operational Lexigram Classes .............. 44 4 . Operational Correlators ................ 47 5 . Assignation of Correlator Indices to L-igram Cldsses . 51 6 . Assignation of Correlator Indices to Products (Reclassification) ................ 52 APPENDIX .................
'Conversations' with Lana 53 The Yerkish Language for Xon-Human Primate's (1) Introduction There are .several reasons why it would be cumbersome and even somewhat misleading to organize a description of the language used in our communication study with non-human primates, according to the linguist's traditional pattern, in three nore or less idependent sections dealing, respectively, with granunar, lexicon,.
and semantics.
Yerkish is an artificial language that was designed for a specific and peculiar purpose to explorbe to what extent apparentry non-linguistic organisms could acquire linguistic skills if they were placed in an environment in which the use of linguistic communication would be to their advantage.
Being an artificial language, the design of Yerkish was subject to constraints that are rather different from those that may or may not have impinged upon the development of natural languages.
Conputational Research supported by National Ins ti tu tes of Health grants ID-0616 and RR-00165 and., carried out at the Yerkes Regional Primate Research Center, Emory University (Atlanta), by a team of seven specialists from three actively participating institutions: Duane F:.
Rumbaugk, PC initiator and Principal Investigator of the project, Timothy V.
dill and Josephine Brown (Dept . of Psychology, Georgia State Cniversity) are responsible for behavioral design and experimentation.
Harold Warner and Charles Bell (Yef1:es Regional Primate Research Center) are responsible for design and engineering of the interface with the computer and the eledtromechanical devices.
Ernst von Glasersfeld and Pier Paolo Pisani (Dept.
of Psychology and.
Computer Center, University of Georgia) are responsible for the design and computerisation of the Yerkish language, its grammar, and the 'fl~l~istore linguists will, I am sure, agree that natural languages would have different grammars and different interpretive rules if, from the very beginning of their evolution, they had had to be intelligible to a computer.
And that is what Yerkish had to be.
For reasons that will become clear when we discuss the research background of the project, the introduction of a computer as m~nitor of the communication system was one of the salient feature of this research effort (Rumbaugh -et al., 1973a).
Other constraints in the development of the Yerkish language will be discussed at those points in the exposition where their explication seemed most appropriate.
I have tried to concentrate specific aspects under indicative subtitles.
I have no illusions that this has been wholly successful.
lly rmin goal, however, was to give the reader as complete as possihle a picture, not only of what was done, but also of why it was done.
The instrumental aspect of Yerkish as the linguistic vehicle in an experimental communication study must be kept in mind at all times; much of what follows in these pages can make sense only if it is put into that perspective.
Another point that I should like to stress is that.
the artificial language on which this paper reports is only one of several major efforts that made this communication study possible.
Such success as we have had is the result of.
team work in the fullest sense of that term.
The project would never have got off the ground if it had not been for the -continuous patient collaboration 6f seven rather heterogeqeous specialists from three different institutions (see footnote l) and, last but not least, for the perseverance of our f.emale chimpanzee Lana.
(Fig. 1: Figure 1 The chimpanzee Lana worl'ing at her lceyboard Background Yerkish is a visual language of graphic word-sy~tols, designed for research in .communication with non-human primates and, possi.bly, as a substitute vehicle for humans who, for physiological reasons,-could not acquire a spoken language.
Lieberman(l968), on the basis of anatomical investigations, .came to the conclusion that the vocal apparatus of the great apes precludes the production and modulation of many of the phonemes that make up the repertoire of human languages.
Forty years earlier, Robert Yerk-es (1925), the founder of the first primatological research institute, in whose honor we have named our language, had already observed this vocal handicap of the non-human primates.
In the intervening years, the Zailure of several long-term efforts to teach a chimpanzee English, Japanese, or Russian, empirically confirmed his observation '(for a review, cf.
Floog and MelnechuE., 1971).
The fact, however, that the great apeas are barred from speak.-ing a language does not necessarily mean that they could not understand one, nor that they could not learn to use a 1in.guistic co~munication systent that functions in another sensory modality.
There still are, of course, It scholars who, defining language" from a rather anthropocentric point of view, refuse to allow the term for any cornrr.unication system that does not use the vocal-auditory mode of transmission.
Among otl~er tl~ings, this would mean that programming languages and other silent communication systems could never be called "language", no matter lla~ adequately they might be described in terms of lexicon, syntax, and semantics.
Today, It there seems to be a gro~~~ing consensus that this restriction of language" to acoustic systems is not a stientifically necessary or useful one (Ploog and Melnechucli, 1971 : 640; Lyons, 1972 : 64) . Interest, thus, has shifted from the question whether or not other organisms can learn to speak a language, to the question whether or not they can learn to handle a cornmunicati~n system that is linguistic in its structure.
Given that there seems to be no compelling evidence that any nonhuman species on this earth has, in fact, developed a c~~unication 11 system that could legitimately be called language", one might ke inclined to thinlc that attemts t'o teach a Language to a non-human organism are necessarf-fg ci-owmd Bail.
This conclusion, however, would be quite unwarranted.
Animal trainers in circuses and in the laboratory have shown beyond all doubt that many species have a potential for the acquisition of skills t?hich no one, wl~o observed the species in the wild, would suspect.
The fact is that the behaviors an organism manifests in a given environment constitute under all circumstances only a subset of the behaviors which the organism could acquire in different environments (Lorenz, 1974).
In the area of cognitive skills, for instance, ~ohler's investigations (1925) already indicated that the great apes had been drastically underrated.
Since then, and up to the demonstration of "higher mental functions" by Viki (Hayes and Nissen, 1956/1971), especially the cl~impanzee's intellectual reputation has continuously grodn (P.umbaug11, 1970) . Thus it has, indeed, become more and more pertinent to ask just how far a chimpanzee (or other great ape) could be brought in the acquisition of linguistic skills which do not require vocal speecl~.
T.he success of the Gardners (1969, 1971) with +-heir chimpanzee \\'ashoe is so well known that there is no need to rei,terate the description of their pioneering work.
Using American Sign Language (ASL) as a vehicle, they established irrefQtably that an infant chimpanzee can be taught to communicate very effectively; and there would seem to be no reason why, given a conducive environment, Washoe's communicatory skill should not continue to grow as she develops towards intellectual maturity.
It has been repeatedly objected, however, that Washoe's successful communications are as yet no proof that she has acquired "language" (e.g.
Lenneherg, 1971; Brown, 1971).
Piost of the skepticism about washoe's linguistilc accomplishments is based on the argument that the strings of signs she produced do not manifest syntactic competence, When Washoe was introduced to ASL, no rigid rules of sign-order were observed and the relational semantics (which, for instance in English, is taken care of to a large extent by word-order) was left implicit in the communicatory event and had to be intuitively gleaned from the situational context by the observer (Gardner and Gardner, 1971).
Since a language user's compliance with the syntactic rules of the language an important criterion in the evaluation of his linguistic performance, the apparent tack of such rules in ASL made it a priori questionable whether Washoe's or, indeed, any other ASL-user's stringing together of I I signs could be considered syntactic and thus evidence of language" on the theoretical level.
In addition to that, a l'ack of syntactic rules is thevery reason why Washoe's,~~mmunications could not contain many relational indications.
For instance, since the sign system taught to Washoe had no consistent means for designating actor and patient in activity situations (comparable to, say, the subject'-yerb-ob ject sequence in many natural languages), the assignation of these roles was left to the intuition or the common sense of the receiver.
In retrospett it is easy to see t-hat this relative lack of syntactic rigidity would supply critics with arguments that.tend to diminish claims with regard to washoe's linguistic competence.
On the other hand, it is equally clear that the GardnersS when they started on their splendid enterprise., were concerned abov'e all with the formidable task of establishing a viable form of communication with a chimpanzee, and they could not possibly have foreseen all the theoretical reasons why linguists and philosophers of language might doubt that the communication system they chose, and the \\ray.
VJashoe was going to use it, should be called "linguistic".
Hence I should like to emphasize that my attempt to clarify the syntactic problem is in no way intended as a criticism of the work accomplished with Washoe, but solely to throw some light on the several ways in which our project, staxted a few years' l'ater, was able to benefit from the ~ardners' effort.
The Cornmunitation Facility -, The basic idea of our project at the Yerkes Primate Research Center was the introduction of a computer as a thoroughly objective monztor of all linguistic transactions.
This solved sev-era1 problems at once.
In the first -place, it eliminated the proble~ of subjective or intuitive evaluation of the grammatical correctness of the experirental animal's linguistic products.
Incorporating a reduced and suitably adapted Multistore Parser (von Glasersfeld and Pisani, 1970), the computer can t I objectively" judge grammaticality.
An input string either conforms to legitimate syntactic structure, dr it does not.
There cannot be any doubt either way.
Second, the computer has no difficulmty in recording every input and transaction that takes place, be it grammatical or not.
Third, thanks to the computer, the communication facility can be kept in operation twenty-four hours a day, without the forbidding cost of several shifts of techinicians andobservers.
In order to turn the communication facility into a learning environment that could af least to some extent operate without the presence of a.human a system of automatic responses was implemented.
By activating one of a set of machine-commanded dispensers, the computer can satisfy a number of requests, provided these requests are correctly formulated by the experimental animal.
So far, the automatic responses are limited to the dispensing of various foods and drinks, to openivg and shutting 8 window., activating a movie and a slide projector as well as a tape player.
In .the future we hope to add something of a question-answering system in order to enable the computer To respond verbally to some questions and, perhaps, also to give some feedback with regard to errore made in the subject's linguistic input.
A full description of the communication facility, as it is in operati,on at present, has been published elsewhere (Rumbaugh -et al., 1973a), Here we shall be mainly concerned with the Yerkish language.
A quick survey of the main components of the installation will have to suffice.
Input to the system is effected by means of a keyboard of maximally 125 keys, arranged in vertical panels of 25 each.
Four such panels are in use at present, corresponding to a total of 100 E'eys.
Each key represents one lexigram, i.e., a geometrical design which constitutes a word-symbol (lexical item) of the ~erkish language.
Depression of a key activates the correspoqding item in the computerized lexicon which is permanently incorporated in the llultistore parser.
The spatial arrangement of the lexigrams in the keyboard can be easily reshuffled (to prevent the experimental animal from acquiring a fixed motor pattern).
To switch on the system, a horizontal bar, mounted \dell above the keyboard, has to be pulled down.
The bqr has to be held down continuously thfoughout the input of a message.
Lana, the female infant Fhimpanzee with whom we have bees working, does this by hanging on to the bar with one hand while using the other to press keys.
If the system is switched on and several keys are then pressed in successi.on, ending with the I1 period" key (bl~e "end-of-message" signal for the computer), the parser 11 takes this sfring as asentence" and analyzes it in order to establish whether or not is is gramnatikally correct.
If the input string is a grammatically correct request, the machine also determines the object of the request and, if it is within the range of automated responses, satisfies the request by activating the r'elevant dispenser ar mechanism.
Regardless of the outcore of the grmatical analysis, the machine prints out the English=word tor-responding to each lexigram that has been activated and records, at the end of the string, whether or not it was found to be correct.
Directly above the keykoard in the experimental chamber, there is a row of seven! small projectors in which the geometric designs of the lexigrams appear, one by one from left to right, as their keys are being pressed on the keyboard.
This provides Lana with feedback as to the part of the message that has already been typed in, and also with a linear representation of the string she is composing.
P signallight, I1 on the right of the projectors, lights up when the period" key has been pressed and terminates the message.
Above this first row of projectors there is a second similar one which serves to display messagesthat are seqt.
in ta Lana from a second keyboard in the technicianfs station outside &anafs chamber.
ljessages originating fromthe4technicianfs keyboard are also recorded the I I computer, but they are marked by a code symbol as operator's messages" and cannot be confounded with ~ana's linguistic production.
Thue Yerkish Lexigrams The original constraints under which the Yerkish language was to be designed were eskentially three.
1) Drawing on the experience of the Cardners (1969, 1971) and Premack (1971), Yerkish had to be a visual language with a lexicon of unitary word-symbols that could be represented singly on the keys of a keyboard.
2) Both lexical items and sentence structure were to be as univocal as possible, because this, on the one hand, would facilitate the automatic parsing of input and, on the other, it was expected to make acquisition of the lariguage easier for our subjects.
3) The structure of Yerkish was to be close enough to English 'to allow word-by-word translation, in order to make participation in communicationevents, as well as their evaluation, maximally accessiblk to technicians and observers.
For a few weelcs at the very-outset of the enterprise, the author revelled in dreams of an ideal language in which each word was.
to be composed of semantically significant pleremes (Hockett, 1961).
here were to be individual design elements designating the more important recurrent semantic categories, and each concept available in the ~erkish universe of discourse was to be represented by a lexigram (i,e.
the visualfgraphic caunterparts to words in spoken languages) composed of design elements &ich, in their own right, would designate the major semantic categories to which the concept belonged.
Thus, for instance, as the American Indian language Yuehi (Crawford, 1973) has a morpheme that recurs.
in any word that designates a part of the human body, every Yerkish lexigram designating a part of the primate body would have contained a specific design element.
Given that the Yerki,sh lexicon was, in any case,to co.ntain no more than two or three hundred lexigrams, it seemed feasible to cover at least the major semantic categories with a hundred or so design elements.
The reason for doing this was, of course, that such a language would have been an invaluable instrument for testing our subject's c'lassificatory skill and processes of concept formation.
The dream was soon shattered by fiechn.ica1 res tr.ictions.
The feedback projectors above the keyboard had to be such that each one of them could display every lexigsam of the language.
Within our budget, this could be achieved only if all lexigrams were designed in such a way that they could be generated by combining design elements of,a common set limited to twelve.
Vnder these circumstances it was obviously impossible to maintain the individual design elements semantically constant and a drastic compromise had to be made.
By choosing nine graphic elements that could be readi-Ly superimpos-ed, one over the other, and thre6 basic colours, a little additional flexibility was gained (see Table 1.).
By "mixing1' 'the three basic colours we could generate seven discriminable hues.
Together with black (absence of colour), this gave us eight background features, and these could be used to colour-code at least some important conceptual categories (see Table 2).
Interpretive versus Descriptive Grammar I I The grammar of Yarkdsh is a direct derivative of the correlationa.1" 'grammar that was implemented some years ago in the blultistore parser for English sentences (von Gldsersfeld, 1964, 1965, 1970; von Glasersfeld and Pisani, 1968, 1970).
It is, therefore, strictly an interpretive I I I I grammar and lays no claim to ge.nerativeU properties, nor is it transformational" in the Chomskyan sense of that term.
Tn the hope that it might dispel some misunderstandings that have haunted the development of correla.tiona1 gr.ammar since its initial co~~ception by'Silvio Ceccato (Ceccata et al., 1960, 1963), 1 should like to dwell for a moment on a purely theoretical point.
1hile the term I I grammar" is predominantky used to indicate the formalized description 11 of a language (e.g.
Chomsky, 1965; 4 and.140), correlational grammar" is, instead, the description of an interpretive system.
The main difference between the two, though basically simple, has perhaps not been made sufficiently explicit.
An ordinary gfammar is expected to account for all grammatical sentences of the language in a mare or less axiomatic way, i.e. by demonstrating that every possible grammatical sentence is a case under a formally stated rule or set of rules.
An interpretive grammar, on the other hand, is not concerned with demonstrating the grammaticality of any sentence, but with transfoming the contept of a given piece of language into a canonical fbrh composed of pre-established semantic elements or modules, It is a "gr;immarl! in the sense that it consists of rules that govern this transformation, but these rules describe the language only indirectly, since what they actually describe is a model of the language user in the receiving role.
(Mote that by "model", in ---this context, we intend a processor which, given the same input, will yield the same output as the processor to be modelled, regardless of the means it employs to do so.
) An interpretive system of this kind, thus, presupposes the grammaticality of its input.
But since it is designed to interpret all grammatical pieces of language, it can be used to define f f operationally as grammatical" any input that it can interpret, while 11 input that it cannot interpret can be considered ungrammatical".
When designing a correlational grammar for a natural language, it i5 a truly enornous problem to bring the gramarrs interpretive capability anywhere near the interpretive capability of the native user of the language.
In the case of an artificial language, hailever, this problem is altogether eliminated, because the lexicon, the rules of concatenation, and the interpretive grammar can be designed all at the same titre.
Since there is no native user, who has a universe of experiential content and well-established semantic connections (by means of which this content is linked to linguistic expressions), the designer is free to tailor the lexicon, as well as the syntax of his language, to the universe of discourse he envisages.
That is, to a large extent, how Yerkish was designed, expecially with regard to the rules of grammar.
The result of it is that the user of Yerkish can communicate in grammatically correct-lexigram strings no more than the correlational grammar of Yerkish can interpret.
A Restricted Universe of Dis'course Yerkish, as it operates at present, is in fact a compromise In more than one respect.
An effoft was made to create a potential universe of discourse that would allow a non-human primate to formulate as many communications as possible which, given the particular environment, could be used instrumentally for the attainment of goals (von Glasersfeld, 1974a).
Such an attempt is necessarily based on more or less anthropocentric conjecture.
There is, however, a certain amount of evidence that non-human primates organize their perceptual world in a way that does not seem incompatible with ours.
In actual fact, Lana has already demonstrated that all the fterns which we assumed would take on the function of goals for her and would, therefore, act as incentive to communicatory activity, were indeed appropriate.
Where food and drink were concerned, this could almost be taken for granted.
h'ith visual displays such as a movie and slides, with thesounds of music and voices, and with the view through an open window, our anthropocentric hope of analogy was well rewarded.
Above all it is gratifying t~ note that there was never a need to resort to any fom of negative r~inforcement or punishment.
Though there were, especially at the beginning, not very mgny things that Lana could "say'' in Yerkish, she has never tired of saying them.
On the practical side, since the interpretive grarmnar was to be implemented in a functioning parser, the universe of discourse was strictly limited by the size of the computer that could be obtained within the budget of the project.
Becau'se the project is ~I~olly experimental and explorative, it was and is an absolut@ requirerent to leave within the computerized system a certain amount of room for ad hoc modifications and additions that might suddenly prove necessary -in view of our subject's actual performance.
Thus it was essential that the implemented grammar should never occupy all of the available space within the comp'uter.
This is smll the case and we hope to be able to maintain this flexibility for some time to come.
Technical Cons txaints There are four ways in which the Yerkish universe of discourse is restricted.
First, there is the nunber of lexical Items the system can handle.
The present version of the llultistore parser can deal with a maximum of 250 Lexigrams.
The interface that links the con-.puter to the keyboard in the experimental chamber is designed for half that number, i.e. for 125.
The-keyboard, however, is divided into five panels of 25 keys each and these panels are readily exchafigeable.
This means that the subject's vocabulary can, in fact, be extended to 250 items, but only a subset of these, namely 125, will be operative during any one session.
(Since Lana at present uses a total of 100 lexigrams, there is still much room for vocabulary expansion.), The second restriction also concerns the vocabulary of lexigrams, but it springs from the grammar of Yerkish and does not limit the number of individual lexigrarns but rather the number of conceptual classes to which lexigrams have to be assigned.
Because of its interpretive function, correlational grammar requires a classification of lexical items that differs considerably from the word-classification used by txadi tional dcscr iptive gramars.
Lexigrams, in fact, are classified according to certain functional characteristics of the concepts thev designate, i.
e., according to cognitive characteristics.
The lexicon with which a correlational gramnar operates, therefore, is divided, not into a few generic and largely rnorphological~y defined classes such as nouns, verbs, adjectives, eetc., but into a much larger number of classes defined in terms of what the designated items can do, i.e,, by the role or roles they play in the cognitive representation of experiential situations.
In the case of "things1'this is, for instance, the kinds of activity which they can perform as actors and the kinds of activity in which they can play the part of patient; and in the case of "activities" it is, for instance, the kinds of change they bring about.
In the implementation of the interpretive system, i.e. the parser, it id the characterization of the lexical classes that occupies considerable space, not the individual lexical items.
The total number of classes, therefore, has to be decided a priori.
In the present Yerkish parser, the maximum number of lexigram classes is 46.
At the time of rkiting, 35 of these classes have been filled (see Table 3).
The remaining 11 are still empty, but they can be made operative at any moment by the simple insertion of new lexigrams and the definition of the functional properties uf the items they designate, The third restriction concerns the number of lexigrams that can be strung together to form one message.
The amount of data the parser has to take into account during the processing of a given message, obviously, depends to some extent on the number of lexical items of which the message is composed.
This dimension corresponds to sentence length in natural languages.
As it was impossible to foresee with any precision just how much work space the parser might require for the analysis of all types of grammatical input strings, we preferred to be on tile safe side and limited' sentence length to seven lexigrams.
On the basis of the experience gathered since then, we can 13ow say that the computer system could, 'in fact, handle input strings of up to ten lexigrams and, hence, we plan to extend the capacity of the hterface hardware in the near future fr~m seven to ten Lexigrams.
The fourth restriction involves the number of connectives (see Table 4) by means of which phrases and sentences can be put together.
These connectives or correlatoxs are Ear more numerous in a correlational grammar than a?e the traditional syntactic functions.
This proliferation is again the result of the interpretive purpose of the systen.
A parser that is intended to extract the conceptual content from pieces of language must be able to idehtify not only the conceptual items involved, but also the relationalconcepts by means of which they are connected with one another.
Hence, the traditional distinction between syntax and semantics is no longer operative in a correlational grammar, and 11 the few basic grammatical relations" (e.g.
subject-verb, verb-object, etc).
which connect grammatically characterized items, are replaced by a great f r many correlators" which are considered the linguistic expression of the relational concepts that link items on the conceptual level.
While our English grammar operated with some five hundred correlators, (2) the grammar of ~erkish in its present implementation is limited to 46.
Of these, 34 have so far been specified and are functioning (see Table 4).
The remaining 12 will be filled as additions to the grammar became desirable from an experimental point of view.
The Grammar of Yerkish --.
The interpretive purpose of correlational grammars leads to a shifting of focus from dharacteristics of words and sentences, qua linguistic items, to thecharacteristics of concepts and conceptual structures, qua cognitive items.
Ideally, a correlational grammar should be a complete mapping of the semantic connections between the elements and structures of a given language, on the one hand, and the elements and structures of conceptual representation, on the other.
The bulk of vork required to produce such a mapping for a given natural language is so vast as to be almost forbidding.
Nevertheless, work in that direction continues under various headings and significant advances have been made (e.
g. Schank, 1972, 1973) . It will take a good deal more time to map the semantics of an average language user's universe of drscourse, but that is hardly a reason for not going on with it, expecially since much of what has been done encouragesthe hope that the task can, indeed, be completed.
In designing an artificial language with a drastically curtailed universe of discourse, the problem is far more manageable.
The semantic connections can be made as univocal as desired and, consequently, the process of interpretation can be thoroughly systematic.
In the case of Yerkisb, unlvocality was desirable not only with a view to thesize of the automatic parser but also from the point of view of the teaching strategies to be employed with a non-human subject* Hence, Yerkish was (2) cf . Final Scientific Report, Automatic English Sentence Analysis, (December 1969) Grant AFOSR 1319-67, Georgia Institute for Research, Athens, Georgia.
(Obtainable through D.O.D). made as univocal as possible.
Since both on the linguistic and on the c~nceptual level we are dealing with eiement~ and their concaternation in structures, the interpretive grammar has to specify the connections (a) between linguistic and conceptual elements and (b) between linguistic and conceptual structures.
With regard to the elements that are concatenated on the linguistic level, their semantic specification ca2 be given in the lexicon because, here, we are dealing with a fixed set of items, i.e, precisely, lexical items.
With regard to structures phrases and sentences on the linguistic level, and situational repr6sentations on the conceptual level they have to be specified by rules of composition on concatenation, i.e. 11 by a grammar, because language is open" in that direction and allows of a practically infinite numter of individually different vord concatenat ions.
Because Yerkish is based on Lnglish and the output of subjects in the experimental environment will be evaluated by English speakers, the lexical semantics of Yerkish lexigrams c~uld be left implicit to a certain extent.
Thus, for instance, the Yerkish parser does not have to contain an exhaustive semantic analysis of lexigrams such as BALL or RAISIN, because it can be taken for granted that the reader of the parser's output will be quite familiar with the concepts designated by 11 "ball" or by raisin" qua experiential items.
What the parser must contain, however, is a mapping ofthose specific characteristics of the concepts which determine these items' potential for entering into structural relations with other items.
In Yerkish, then, the relational characteristics of conceptual items determine the classification of lexigrams . Thus, having decided, for instance, that there should be items that can be eaten and items that can be drunk, the lexigrams designating thss-e items will be divided into edibles (i.e.
suitable patient/okjects for the activity designated by EAT) and drinkables (i.e.
suitable patientlobjects for the activity designated by DRINK).
Together they constitufethe class of ingestibles which, as it happens, is marked by the red hue of the corresponding lexigrams (see Tables 2 and 3).
In short, Yerkfsh grammar does not require, nor lead to, a complete semantic analysis of lexical items.
What it does require is a lexicon in which classes of lexical items are exhaustively characterized as to the specific relations into which their members can enter with members of other classes.
This exhaustive characterization is supplied, not by listing all the other classes with whose members connections can be potentially formed, bat by a string of indices, each of which specifies a connective relation and the place in it (c-f.
below) 5 member of the class thus characterized can occupy, Finally, we come to the relational concepts or coxrelators which are instrumental in the building up of complex structures, both on the conceptual and on the linguistic level.
Strictly speaking, a correlator is a connective fgnction that links conceptual items on the cognitiverepresentational level.
Languages indicate these connective functions by a variety of means: prepositions; verbs, nouns, and other types of words that incorporate a preposition; conjunctions and other particles; 11 syntactic markers" and, very frequently, merely word-order . Since these linguistic elements indicate correlators, we should call them I I correlator expressions".
Rowever, once it has been made clear that correlators function on the conceptual level and connect concepts with other concepts or combinations thereof, we can in most cases use the term "correlator" for both the relational concepts and the linguistic devices that express them, (3) In designing an artificial language, the classification -of lexical items and the definition or explication of relational concepts must go hand in hand since the first is done in terms of the second, The relational concepts have to be explicitly listed and explicated by some form of paraphrase.
In principle, that is what a "case grammar" does.
Its cases, basically, are relational concepts (e.g.
Tillmore, 1968).
Ho~~ever, because correlational grammar attempts to cover as much relational semantics as possible, its list of correlators will be I I both much longer and wore specific than the lists of cases'' l~hich, to my knowledge, have been suggested.
Yerkish; in its present form operates with some thirty correlators and the Yerkish lexicon is classified with reference to these (see Tables 3 and 5).
Given a basic list of correlators and their linguistic expression, the classification of lexical items can be carried out by listing for each item the correlators by means of which it can be potentially (3) One area where the distinction has to be maintained is the -semantic analysis of natural languages, because correlator expressions such as prepositions rarely have a one-to-one correspondence to relational concepts; instead, they merely mark the preqence of one of a set of relational concepts.
linked to other items.
To give an example, there is a relational, concept (No.
U ) paraphrased as active ingestion of solids involving solid food stuff'; on the linguistic level, this correlator is expressed by the juXtaposition of two lexical items in a certain order.
If we now have a lexigra EAT, that designates active ingestion of solids' and another lexigram RAISIN, that designates a subcategory of 'solid food stuff '., we can form a compound or correlation with the two lexigrms which can be represented as the structure: (a) EAT RAI S IN L,~~~-~,~~~~~-11 -------------A Because the order of succession of the two items in the linear linguistic expression is obligatory and cannot be reversed, it is not enough for the grammar merely to supply the information that the lexigrams EAT and RAISIN can be linked by correlator No.
11, but the grammar must aLss specify that, in this correlation, EAT has to be the left-hand piece (LH) and RAISIN the right-hand + piece (W).
This information is part of the permanent lexicoq of the system.
If It is recorded there by means of correlation indices" (IC1s), which consist of the number of the potential correlator plus the indication whether the items to which this I, is assigned can function as LH-piece or as w-piece.
In many cases there are, of course, several lexical items that can function in the same place (e.g.
NUT, MGM candy, RAISIN, etc., as RH-piece of correlator No.
11). Therefore, 1,'s are assigned to lexigram classes, not to single lexical items.
Thus, while the lexigram EAT, in the present Yerkish lexicon, is the only member of the class VE ('active ingestion of solids'), the lexigrarr RAISIN is one of several in the class EU ('solid food stuff1).
On the one hand, this indexing of classes, rather than individuals, is obviously more economical with regard t~ storage space, on the otKer, it makes it possible to add new lexigrams to the existing classes without in any way disturbing the operative part of the lexicon or the parsing algorithms.
To expand the above example, let us add another correlation.
The 1 relational concept that can be paraphrased as autonomous animate actorf perf ordng 'stationary activity' is correlator No.
01, The paraphrase ! autonomous animate actor' comprises three lexigram classes in the present lexicon, nsmely kP ('familiar primates', i.e., the regular technicians TIN, SHELLEY, BEVERLY, and the experimental animal LANA) ; AV ('visiting primates', i.e., unnamed human or non-human visitors); and A0 ('non-primates', i.e., at present ROACH only).
The paraphrase 1 stationary activity1, i.e, acti.vities that do not involve a change of place on the part of the actor, nor a change of hands on the part of a patient, comprises three lexigram classes, nanely VE (with the single member EAT), VD (with the single member DRINK), and LrA (with several members such as: GROOII, TICKLE,.
HOLD, etc.
) . Given the lexigran sequence LANA EAT, the interpretive grammar finds that LANA, belonging to class AF, bears the.
I,: 01, LH, while EAT, belonging to class VE, bears the I,: 01, RH; and on the strength of this the grammar will allow the correlation: LANA CAT "---------01---------4 I I For the parser, allowing a correlation" means to record it as a possible part-interpretation of the input striqg..
As such it is recorded as a "product" in order to be tested for its potential correlability with other parts of the input.
The information, on the basis of which such first-level correlations (connecting single lexigrams as in a and b) are formed, is contained in 7 the permanent lexic~n and the form in which it is stored can be visualised as a kind of matrix (see Fig.
2 and Table 5).
The correlational data required to form examples (a) and (bj is represented by markers (x) indicating the 1,'s (at head of column) assigned to the lexigxam classes (at beginning of row), In the present implementation of the Yerkish grammar h = 34, m = 35.
Though this information contained in the lexicon covers all correlations involving two single lexigrams, it does not provide 'or cogrelations linking phrases or phrases and lexigrams.
The syscem a correlational grammar uses to cfiscouer higher-level structures in a given input string is again rather different from that of traditional glammar.
It order to be able to handle phrases, i.e., already correlated lexigrams, 1 t or productsf', in exactly the same vay as single lexical items, each 1 product must be assigned a string of I c s that represents its particular potential for functioning as component (LH-piece or CH-piece) of a new and larger correlation that links it with other lexical items or phrases.
The procedure that assigns these IC'S to a given product is what might be called the dynamic part of the grammar, because it is poverned by .an set of operational rul-es tha.t cannot be stated ina siaple formalized way.
(4) The reason for this is that the.
correlruliility of a given phrase often depends on more than one constituent of the phrase.
An example may help to make this clear.
Wit11 regard to.
rorrelator 1'0, 30 that links the two single lexigrarris involved, the phrases and TIIIS CALI, L------30------1 are identical.
Ps potential YH-pieces of a correlation, forlllad by correlator KO, 11, however, they are not equivalent.
EAT TEIS PAISIF 1 &-----------.J 30 would be acceptable and correct, whereas EAT TNI S BA'I t I L ------A i 30 L----,, I1 would not Ee acceptable because BALL does not belong to the lexipr,am class El' clef ined as !.solid food stuff'.
and, therefore.
is not a potential RH-piecc (4) The operational rules are, of course, always conFinations of indivdually simple rules taken from a relatively small set.
This is, indeed the way in which the parsing program compi1.e~ them; although.
this can be called 'f,ormalisatj-on" it.
certainly is not a simple one.
of correlaticln No..
11. In fact, if the string EAT THIS BALL occurs as input to the interpretive grammar, it must he rejected as incorrect.
To implement this dl~criminat ion, the phrase TIIIS MISIP! must be assigned the I,: 11, EH, while the phrase THIS DAI.IA must not.
And in order to do this, the assignation must be based not only on the particular correlator that links THIS with another item, but also on the condition that t'his other item is one that belongs tu the lexigram class solid food stuff'.
In other vords, there has to be an operational assignation rule that makes sure that a first-level correlation produced by correlator KO.
30 is assigned tbe Ic:ll, PiT, so that it can I-e linked in a second-level correlation with the precedirp lexigram FAT, v~hich bears the I 11, 1.1;; but this a'ssignation must.
be made contingent upon the c condition that the product 30 (P.: 30) does, in fac.t, contaic a lexical' itern of class El' as RH-piece; because only if P:30 contains a member of tl~r: t class solid food stuff' can it function as patient of the activity designated by the LH lexigram FAT.
The operational assignation rules, therefore, are of diverse Lypes, I ? sore assigning I, s unconditionally, others assigning I, s only on condition that the same Ic is present, as the case ray Fe, arrong those charaeterising the 1A1' or the 911 of the produet thgt is tieipg classified.
(.See Table 6).
1 In
the implementation of the parser., tile assignation of I, s to products is primarily dete'mined by the particular correlator that is involved in the product to be classified, Tk.e assignation rales a particular correlator calls into action, tliouph functionally of three types only, are specific.
to that correlator and cannot be written in a generalised form; This indeed, is the fundamental reason why a correlational grammar cannot be represented by means of a small numberof relat-ively "powerful" rules.
In a correlational grammar there must be as many sets of specific assignation rules as there are correlators ; and since the.
number of correlators in such an interpretive gram.ar is very much laqger than the number of "syntactic functions" in conventional descriptive grammars, correlational grammars connot be wrj tten in concise and powerful formulas.
As a justification for this lack of Ebrmal elegance, however, it can be said that correlational grammar has no need of the otherwise indispensable and somewhat unwieldy adjunct of "selection rules", because it incorporates that very information in its one basic interpretive algorithm, Peculiarilies -of the Yerkisk Gr.mar The grammar of Yerkish had to be kept as simple as possible for the reasons mentioned above, First, given the small size of the computer, it was mandatory to avoid complex constructians and rules of grammar that might require special spaceand time-consuming subroutines in the parsing pfocedure.
Second, the rules of the language to which the lingpistic behavior of our subject would have ta confo;rm, were to be few and consistent from the learner's point of view; nevertheless they were co be such that Yerkish structures could be translated easily and without major structural transformations into comprehensible English.
As a result of these objectives, Yerkish grammar may seem somewhat unusual.
In the following paragraphs several deviations from English grammar will be discvssed.
Yerkish, at present, bas only one voice.
the active, and three moods, i.
e. indicative, interrogative,,and imperative.
Both :he interrogative and the imperative are formed) not,by specific v,erb-forms or word-order (as in ~lilny natural languages), but by sentential prefixes or markers, i.e. specific lexigrams that are placed at the beginning of the message.
The prefix of the interrogative is the conventional question mark 'I?"', that 11 for imperatives (in Yerkish requests") is an arrow, translated into English as PLEASE.
The keys representing these two lexigrams nust be pressed at the beginning of a string and they can appear only in the first feedback projector on the left.
The lexigram string following them has the same form as an .indicative statement.
In fact, if the string is to he interpreted as an indicative-statement, i.e.. if it is not preceded by !I 711 either . or PLEASE, the first feedl;acl;projector on the left remains blank.
Thus: TIM MOVE INTO RpOM = indicative statement; ? TIIIE YOVE INTO ROOF?
= interrogative; PLEASE TIE1 MQVE INTO ROOM = request.
A third lexigram that fu.nc-tions as a sentential marker is NO, which corresponds to an over-all negation of the statement.
NO TIM MOVE INTO ROOM, therefore, corresponds L-o the English "it is not the case that Tim moves into the room".
However, since Lana has quite spontaneously come to use the lexigram NO to designate what, given the situational context, could be interpreted onLy as "don't", we may adapt the grammar to her usage and turn this NO into a marker for negative imperatives (see Appendix) . Yerkish, as yet, has no tenses but the present.
A simple past and future, however, are foreseen, and they will be designated by particles preceding the activity lexigram.
There are no auxiliaries in Yerkish and the function of the English copula "to be" is taken over by corr,elator No.
10, which is expressed by juxtaposition of a lexigram belonging to one of the classes of items that 1 t are modifiable" and a lexigram designating a specific state.
e.g. BALL RED.
"the ball is red1'; T IEI AWAY, 1 I' Tim is away"; The absence of an explicit copula is noticeable also in conjunction with the "naming functionf1, an important instrument in ~ana's acquisition of new lexical items.
It is used for the ostensive definition of new lexigrams which areplaced at the beginning of a string of the form: XX NME-OF THISi 11 XX is the name of this1'.
(where LY is the new Icx~gram) Two English coQstructions that have a specificatory restrictive function., i.
e. for instance, "the red ball'! and "the ball is red" are one and the same in Yerkish, and the specificatgry relation is designated by a lexigram which can be translated into English as the comp~und 'WHICH-IS (correlator )lo.
31) . e.
BALL ITHICH-IS RED.
"the red ball" or "the bal which -is red1'.
For the sake of greater univocality, Yer,kish spatial prepositions were strictly divided into locatignal and directional ones.
The first -e.g.
IN, ON,OUTSIDE, etc.
-could designate ~nly the locatign of items or activities, the second -e.g.
INTO, OUT-OF, FROM, etc.
-could designate only the direction of activities involving a change of place.
Ho~lever, since Lana has spontaneously used a locational prepositYon to indicate the target of a directional activity, and since this is allowable in many if not all natural lartguages, we are considering the removal of this restriction with regard to spatial prepositions.
So far, there are no conjunctions in Yerkish, but a somewhat restricted form of "and" and "or" has been worked out and will shortly be introduced into the system, There are also some minor pecularities that an English-speaker must keep in mind..
A Yerkish structure involving correlacor No.
IT, for instance, implies that the speaker is the receiver of the item that changes hands, unless another teceiver is explicitly indicated by a prepositional complement.
Thus, if Lana sends the message : PLEASE TIME GIVE IIILK.
it must be understood that the milk is to be given to Lana.
The receiver, however, can be made explicit by adding a prepositional phrase, which yields the correlational structure: PLEASE TIM GIVE MILK TO LANAP -17--1 224 -21Lh0L5 I It English resultative verbs, e.g. to open", "to clean", ete., are, broken up in Yerkish.
The causative element is rendered by EIAKE, the effect by a lexigram designating the resulting state.
Also, in Yerkish the agenr must be specified.
Thus, l lease (Timj open the window1' becomes : PLEASE TIM MAKE WINDOW OPEN.
Translated literally into English, this should be lease, Tim, make window be open", since the correlator that links WlNDOW and OPEN is No.
10, i.e. the gredicative copula equivalent to "to betf.
But in this case, as.
indeed in most occurrences of correlator No.
10, the Yerkish string is easily understood without the explicit copula.
The Yerkish MA~E is not limit-ed to causation of a change of state of specific items, but can be used also to indicate a number of perceptual conditions or events in the environment.
Specific sensory events or changes, such a NOVIE, NUSIC, SLIDE, HEAT, COLD, LIGHT, and DARKNESS, are considered theresult* of activities subsumed by .RAKE.
In Lana1 s wholly technoPogica1 environment.
this is not at all unreasonable.
It obviously makes sense for her to request: PLEASE PLACYINE MAKE MOVIE.
L13 --L L.16 2 L40 It is, indeed, the machine that causes the projector to start running.
S2milarly, however, in Yerkish one cauld correctly say: PLEASE TIM MAKE LESS HEAT.
It Though in Lana's expe~ience Tim can indeed cause less heat' by turning down the thermostat, this would hardly he a reasonable request in the "realIt world outside the Yerkes Lab.
MAKE also opens the way to embedded constructions.
since it can govern a clause.
Though,Lana has not yet come to this, the grammar foresees strings such as : ? TIM NAKE LANA SEE VISITOR or even a double embedding: ? TIM SEE LANA MAKE ROACH MOVE.
and similar structures are, of course, possible with WANT.
Lest these correlational diagrams create the impression that Yerkish structures are invariably right-branching, here are two examples that contain lef t-branchings : ? NO PIECE OF APPLE HERE.
which,in English, would read': "IS there no piece of apple here"?
And STICK WHICH-1s BLUE DIRTY -10 which in English, would be: "?he stick which is blue is dirty", and, as such, roughly equivalent to "The blue stick is dirty.
11 Irr
one particular the grammar of Yerkish deviates from correlational practice.
Prepositions and conjunct ions being "explicitH 'correlator expressions in that they designate relational c.oncepts only, are (in the' correlational approach) n~t items-to be linked, but itenla that do the linking.
Thus, in the original Ffultis tore parser they functioned as cor~elators and not as ordinary lexical items.
In the structure diagrams, therefore, they appeared in a node, not at a terminal.
Given the very smLl computer used for the Yerkish parser; as well as the fact that the lexicon was t'o remain extremely limited (in comparison to English), it was more economical to correlate prepositional phrases in two steps rather than introduce the special routine that had been developed for prepositions and other "explicit" correlator expressions in the English pagser.
Thus a string.
such as "move into room" is not constructed as it would be in a proper correlational systan, i.e.: but rather in twa steps: NOVE INTO ROOM 1 L-4 where P:21 containing P:22 expresses the conceptual relation designated by INTO.
In all other respects the Yerkish system is similar to the Multistofe parser whose characteristic data-compression was, in fact, the feature that made .it possible to contain t.he entire system lexicon, operational interpretive grammar, and automatic response programs in less than 5000 machine words of central core.
Conclusion Though Yerkish is, indeed, an extremely limited linguistic sys tem, the examples of sentence structure I have used above should -be suffi'cient to show that it has a considerable range and flexibility with regard to what can be formulated in it.
The reports on ~ana's progress that we have published so far (Rumbaugh et -* a1 9 1973b, 1974; von Glasersfeld, 1974b-; see also Appendix to this paper) leave little doubt that Lana has already acquired a number of skills that certainly belong to what is usually called linguistic competence.
The grammar of Yerkish as it is at present allows many structures which are still far out of Lana's reach.
She has a long way to go before one might venture to say that she fully exploits the expressive possibilities of Yerkish.
That is precisely how it was intended at the outset of the project.
In any case, the range of expression could easiLy be extended at short notice and without interfering with the existing operational system.
Nor would such additions require an inordinate expansion of the Lexicon.
The introduction of the one lexigrarrl WANT, for instance, has opened the way to a completely new level of expression that may eventually lead to a demonstration of the chimpanzee's capability for conceptual representation.
The addition of a Yerkish "if.
. . then'' would be no nore difficult and could pe,rhaps further clarify the cognitive potential of non-human prinates.
(5) Such additions could also make Yerkish a (5) Premack (1971) reported that his chimpanzee Sara could correctly interpret an "if.
. . then" connection between actual activities or states; the greater range and flexibility of Yerkish would make possible the introduction of much more sophksticated hypothetical statements.
valuable co~unication vehicle for sone of those many unfortunate children wh6, though they are mentally not at all deficient, remain averbal because of some physiological damage.
It is towards this end that we are now exploring the possibility of adapting the Yerkish syst,em, its grammar, and the parser, to a form of simple English.
References Brown, Rog.er (1971$, in Ploog and Melnechuk, 1971.
Ceccato, Silvio, -et al.(1970), Liriguistic Analysis and Progr.amming for Mechanical Translation, Nlan, Italy: Feltrinelli.
Ceccato, Silvib, et al.(1963), Mechanical TranslatLon: The Correlational Solution (Technical ~e~ort), Milan, f taly : Center for Cybef netics, ~nivk'rsity of Milan, Chomsky, Noam (1965), Aspects of the Theory of Syntax, Cambridge, Massachusetts: M.I.T.
Press. Crawford, James (1973), personal comunication.
Fillmore, C.
J. (1968), The case for case, in (E.
Bach and R.
Harms, Eds ).
Universals in Linguistic Theory, New York: Holt, Rinehart, & Winston.
Gardner, R.
A. and B.
T. (196?), Teaching sign language to a chimpanzee, Science, 165, 664-672.
Gardner, B!
T-. and R.
A. (19.71), Two-way communication with an infant chimpanzee, in (A.M.
Scihrier and F.
Stollnitz, ~ds).
~ehavior of Ndnhuman Primates, Vol.
4, New York: Academic Press.
Hayes, Keith J.
and Nissen, C.
H. (1956),, in (A.M.
Schrier and F.
Stollni-tz, Eds).
Behavior of -Nonhuman Primates, New York: Academic Preps, 1971.
Hockett, Charles F.
(1961), Lin-uistiq elevents and their relations, Language 37, 1, 29-53.
Ktlhler, ~olf~ael925), The Mentality of Apes, New York: Harcourt, Brace.
Lenneberg, Eric c1971), in Ploog and Melnechuk, 1971.
Lieberman, P.
(1968), Primate vocalizatbon.
and human linguistic ability, Journal of the Acoustic.
Society of America,'4, 1574-1584.
Lorenz, Konrad (1974), Analogy, as a source of knowledge, Science 185, 229-234.
Lycns, John (1'972.), Human language, in (R.A.
Hinde, Ed.
) Non-Verbal Comunication, Cambridge, England : Cambridge University Press.
Ploog, Detlev, and Melnechuk, Theodore (1971), Are apes capable of language?,.
Neurosciences Research Bulletin, 9,, 5.
Premack, David (1971), On the assessment of language competence in, the chimpanzee, in (A.M.
Schrier and F.
~tollnitz, Eas).
Behavior of Nonhuman Primates, Vol.
4, New York: Academfc Press.
Bumbaugh, Duane PI.
(WO), Learning skills of anthropoids, (in L.
A. Rosenblum, Ed).
Frimate Behavior, Vol.
1, New York: Academic Press.
Bumbaugh, G; I., von Glasersfeld, E., Warner, h., Pisani, P., Gill, T., Brown, J., and Bell,,C.
(1973a), A,computer-controlled la~guage training'system 'for investigating the language skills of young apes, Behavioral Research Ilethods and Instrumentation 5, 5, 385-392.
Bumbaugh, C.
t!., Gill, T.
V., and von Glasarsfe-1d;-T., (l973b), Reading and Sentence completion by a chimpanzee, Science 182, 731-733.
Rumbaugh, D.
M., von Glasersfeld, E., Warner, R., Pisani, P., and Gill,.T.
(1974), Lana (thTmpanzee) learning language: A progress report, Brain, and Language, 1, 205-212.
Schank, Eager (1972), Conceptual dependency: A theory of natural language understanding, Cognitive Psychology, 3, 4, 552-631.
Schank, Roger, (1973), Causality and Reasoning, Technical report ii~.
1, Castagnola, Switzerland: Fondazione nalle 1.iolle. vdn Glasersfeld, Emst '(1964), A project for automatic sentence analysis, Beitrsge.
zur sprachkun4P und Inforrnationsverarbeitung, 4, 38-46.
von Glasersfeld, Ernst (1964); Efultistore a procedure for correlational analysis, Automazione,e Automatismi, 9, 2.
von Glasersfeld, Ernst (1370), The correlational Lapp~oach to language, Pensiero e Linguaggio, 1, 4, 391-398.
von Glasersfeld, '.~rnst (19 74a), Signs, communication, and.
language, Journa'l of IIurnan Evolution, 3, 465-474.
von Glasersfeld, Ernst (1974b), Lana's progress, paper presented at the 12th lleeting of the Association for Computational Linguistics, Amherst l!assachusetts, July, 1974.
von Glasersfeld, Ernst, and Pisani, Pier Paolo (l970), The'?iultistore parser for hierarchical syntactic structures, Cormnu~ications of the Association for ~orn~utin~' Elachinery, 13, 2, 74-82.
von Glasersf eld, ~rnst, and Pisani, Pier Faolo (1968), The hfultis tore Sys tern PIP-2, Scientific Progress report, Athens, Georgia: Georgia Institute for Research.
Yerkes, Robert 11.
(1925), Traits of young chirpanzees, Cn (R.
.?.I. ~erkes afid B.
\J. Learned, Eds,) Chimpanzee Intelligence.
and its Vocal Expressipn, ~altkore : Williams & ~il"1iams. '

