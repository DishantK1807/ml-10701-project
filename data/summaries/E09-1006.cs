In (Agirre and Lopez de Lacalle, 2008) we
C08-1003
the (Koeling et al., 2005) corpus more demanding
H05-1053
Ciprian Chelba and Alex Acero. 2004. Adaptation
W04-3237
Eneko Agirre and Oier Lopez de Lacalle. 2008. On
C08-1003
and Marcu, 2006; Chelba and Acero, 2004). The
W04-3237
Gliozzo et al. (2005) used SVD to reduce the
P05-1050
of training data in WSD (Gliozzo et al., 2005).
P05-1050
(Gliozzo et al., 2005; Zelikovitz and Hirsh, 2001).
P05-1050
Mart´ınez, 2004; Chan and Ng, 2007). This would
P07-1007
optimal performance (Pradhan et al., 2007), we
W07-2016
relatedWSDexperimentsbyKoelingetal.(2005),
H05-1053
closely related to the present paper. Ando (2006)
W06-2911
R. Koeling, D. McCarthy, and J. Carroll. 2005.
H05-1053
Zhi Zhong, Hwee Tou Ng, and Yee Seng Chan. 2008.
D08-1105
Eneko Agirre and Oier Lopez de Lacalle. 2007. Ubc-
W07-2074
In the semi-supervised setting, Blitzer et al.(2006) used Structural Correspondence Learning
W06-1615
target scenario (Escudero et al., 2000; Agirre and
W00-1322
in WSD (Koeling et al., 2005). It comprises 41
H05-1053
in (Agirre and Lopez de Lacalle, 2008) we show
C08-1003
More recently, Chan and Ng (2007) performed
P07-1007
salient bigrams in the context (Pedersen, 2001).
N01-1011
2005; Agirre and Lopez de Lacalle, 2007) takes
W07-2074
Yee Seng Chan and Hwee Tou Ng. 2007. Do-
P07-1007
T. Pedersen. 2001. A Decision Tree of Bigrams is an
N01-1011
Rie Kubota Ando. 2006. Applying alternating struc-
W06-2911
