Present SMT systems use a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney, 2002).
P02-1038
It seems that high precision alignments are better for phrase-based SMT (Chen and Federico, 2006; Ayan and Dorr, 2006), whereas high recall alignments are more suited to N-gram SMT (Mari˜no et al., 2006).
P06-1002
In the first SMT systems (Brown et al., 1993), word alignment was introduced as a hidden variable of the translation model.
J93-2003
This is in agreement with the observation of a poor correlation between word alignment error rate (AER (Och and Ney, 2000)) and automatic translation evaluation metrics (Ittycheriah and Roukos, 2005; Vilar et al., 2006).
C00-2163 H05-1012
We also used the φ2 score (Gale and Church, 1991) as a word association model, and as a POS-tags association model.
H91-1026
85 Recently some alignment evaluation metrics have been proposed which are more informative when the alignments are used to extract translation units (Fraser and Marcu, 2006; Ayan and Dorr, 2006).
P06-1002 P06-1097
Moore. 2005.
H05-1011
Word Aligner For versatility and efficiency requirements, we implemented BIA, a BIlingual word Aligner similar to that of Moore (2005).
H05-1011
In order to improve translation quality, this tuning can be effectively performed by minimizing translation error over a development corpus for which manually translated references are available (Och, 2003).
J03-1002 P03-1021
In contrast, adding new features to some supervised systems (Liu et al., 2005; Moore, 2005; Ittycheriah and Roukos, 2005) is easy, but the need of annotated data is a problem.
H05-1011 H05-1012 P05-1057
Unsupervised systems (Och and Ney, 2003; Liang et al., 2006) are based on generative models trained with the EM algorithm.
J03-1002 N06-1014 P03-1021
