ple approach is well documented; e.g., Turian et al.(2010) show that the baseline model (gazetteer fea-
P10-1040
Wikipedia: Kazama and Torisawa (2007) show that
D07-1073
Massimiliano Ciaramita and Yasemin Altun. 2006.
W06-1670
Atsushi Fujita and Satoshi Sato. 2008. A probabilis-
C08-1029
(i) GATE (Cunningham et al., 2002): countries,
P02-1022
correct parse tree filtering (Yates et al., 2006), and
W06-1604
Jun’ichi Kazama and Kentaro Torisawa. 2007. Exploit-
D07-1073
Michael Collins. 2002. Discriminative training methods
W02-1001
Meliha Yetisgen-Yildiz. 2010. Annotating large email
W10-0728
unsupervised methods (Ando, 2004; Turian et al.,
P04-3013
in-domain NER. Cucerzan (2007) uses Wikipedia
D07-1074
Peter D. Turney. 2002. Thumbs up or thumbs down?
P02-1053
Barr et al. (2008) found that capitalization of NEs in
D08-1107
2010). Turian et al. (2010) show that adapting from
P10-1040
Erik F. Tjong Kim Sang and Fien De Meulder. 2003. In-
W03-0419
rithm (Collins, 2002), a discriminative model with
W02-1001
Silviu Cucerzan. 2007. Large-scale named entity dis-
D07-1074
PoS t, as determined by TnT tagger (Brants, 2000).
A00-1031
Thorsten Brants. 2000. TnT – A statistical part-of-
A00-1031
Rie Kubota Ando. 2004. Exploiting unannotated cor-
P04-3013
Yetisgen-Yildiz et al. (2010) investigate how to best
W10-0728
Cory Barr, Rosie Jones, and Moira Regelson. 2008. The
D08-1107
Dekang Lin and Xiaoyun Wu. 2009. Phrase clustering
P09-1116
Lawson et al. (2010), Finin et al. (2010), and
W10-0712 W10-0713
paraphrase evaluation (Fujita and Sato, 2008). The
C08-1029
analysis (Turney, 2002), for transliteration (Grefen-
P02-1053
ger (Brants, 2000) to avoid using non-plausible PoS
A00-1031
