Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 75–78,
The University of Tokyo, September 24-25, 2010. c©2010 Association for Computational Linguistics
Exploring the Efectivenes of Lexical Ontologies                          
for Modeling Temporal Relations with Markov Logic 
 
 
Eun Y. Ha, Alok Baikadi, Carlyle J. Licata, Bradford W. Mott, James C. Lester 
Department of Computer Science 
North Carolina State University 
Raleigh, NC, USA 
{eha,abaikad,cjlicata,bwmott,lester}@ncsu.edu 
 
  
 
Abstract 
Temporal analysis of events is a central 
problem in computational models of dis-
course. However, corectly recognizing 
temporal aspects of events poses serious 
chalenges. This paper introduces a joint 
modeling framework and feature set for 
temporal analysis of events that utilizes 
Markov Logic. The feature set includes 
novel features derived from lexical on-
tologies. An evaluation sugests that in-
troducing lexical relation features im-
proves the overal acuracy of temporal 
relation models. 
1 Introduction

Reasoning about the temporal aspects of events 
is a critical task in discourse understanding. 
Temporal analysis techniques contribute to a 
broad range of aplications including question 
answering and document sumarization, but 
temporal reasoning is complex. A recent series of 
shared task evaluation chalenges proposed a 
framework with standardized sets of temporal 
analysis tasks, including identifying the temporal 
entities mentioned in text, such as events and 
time expresions, as wel as identifying the tem-
poral relations that hold betwen those temporal 
entities (Pustejovsky and Verhagen, 209).  
Our previous work (Ha et al., 2010) adresed 
modeling temporal relations betwen temporal 
entities and proposed a supervised machine-
learning aproach with Markov Logic (ML) 
(Richardson and Domingos, 206). As novel fea-
tures, we introduced two types of lexical rela-
tions derived from VerbOcean (Chklovski and 
Pantel, 204) and WordNet (Felbaum, 198). A 
preliminary evaluation showed the efectivenes 
of our aproach. In this paper, we extend our 
previous work and conduct a more rigorous 
evaluation, focusing on the impact of joint opti-
mization of the features and the efectivenes of 
the lexical relation features for modeling tempo-
ral relations. 
2 Related
Work 
Recently, data-driven aproaches to modeling 
temporal relations for writen text have ben 
gaining momentum. Boguraev and Ando (205) 
aply a semi-supervised learning technique to 
recognize events and to infer temporal relations 
betwen time expresions and their anchored 
events. Mani et al. (206) model temporal rela-
tions betwen events as wel as betwen events 
and time expresions using maximum entropy 
clasifiers. The participants of TempEval-1 in-
vestigate a variety of techniques for temporal 
analysis of text (Verhagen et al., 207). 
While most data-driven techniques model 
temporal relations as local pairwise clasifiers, 
this aproach has the limitation that there is no 
systematic mechanism to ensure global consis-
tencies among predicted temporal relations (e.g., 
if event A hapens before event B and event B 
hapens before event C, then A should hapen 
before C). To avoid this drawback, a line of re-
search has explored techniques for the global 
optimization of local clasifier decisions. Cham-
bers and Jurafsky (208) ad global constraints 
over local clasifiers using Integer Linear Pro-
graming. Yoshikawa et al. (209) jointly model 
related temporal clasification tasks using ML. 
These aproaches are shown to improve the ac-
curacy of temporal relation models. 
Our work is most closely related to Yoshikawa 
et al. (209) in that ML is used for joint model-
75
ing of temporal relations. We extend their work 
in thre primary respects. First, we introduce 
new lexical relation features. Second, our model 
adreses a new task introduced in TempEval-2. 
Third, we employ phrase-based syntactic features 
(Bethard and Martin 207) rather than depend-
ency-based syntactic features. 
3 Data
and Tasks 
We use the TempEval-2 data for English for both 
training and testing of our temporal relation 
models. The data includes 162 news articles (to-
taling about 53,00 tokens) as the training set 
and another 1 news articles as the test set. The 
corpus is labeled with events, time expresions, 
and temporal relations. Each labeled event and 
time expresion is further anotated with seman-
tic and syntactic atributes. Six types of temporal 
relations are considered: before, after, overlap, 
before-or-overlap, overlap-or-after, and vague. 
Consider the folowing example from the 
TempEval-2 data, marked up with a time expres-
sion t
1
 and thre events e
1, e
2, and e
3, where e
1
 
and e
2
 are the main events of the first and the 
second sentences, respectively, and e
3
 is syntac-
ticaly dominated by e
2
. 
But a [minute and a half]
t1
 
later, a pilot from a nearby 
flight [calls]
e1
 in. Ah, we 
just [saw]
e2
 an [explosion]
e3
 
up ahead of us here about 
sixteen thousand feet or 
something like that. 
In the first sentence, t
1
 and e
1
 are linked by a 
temporal relation overlap. Temporal relation af-
ter holds betwen the two consecutive main 
events: e
1
 ocurs after e
2
. The main event e
2
 of 
the second sentence overlaps with e
3, which is 
syntacticaly dominated by e
2
. 
In this paper, we focus on thre subproblems 
of the temporal relation identification task as de-
fined by TempEval-2: identifying temporal rela-
tions betwen (1) events and time expresions in 
the same sentence (ET); (2) two main events in 
consecutive sentences (MM); and (3) two events 
in the same sentence when one syntacticaly 
dominates another (MS), which is a new task in-
troduced in TempEval-2. 
4 Features

Surface features include the word tokens and 
stems of the words. In the TempEval-2 data, an 
event always consists of a single word token, but 
time expresions often consist of multiple tokens. 
We treat the entire string of words in a given 
time expresion as a single feature. 
Semantic features are the semantic atributes 
of individual events and time expresions de-
scribed in Section 3. In this work, we use the 
gold-standard values for these features that were 
manualy asigned by human anotators in the 
training and the test data. 
Syntactic features include thre features 
adopted from Bethard and Martin (207): gov-
prep, any prepositions governing the event or 
time expresion (e.g., ‘for’ in ‘for ten years’); 
gov-verb, the verb governing the event or time 
expresion; gov-verb-pos, the part-of-spech 
(pos) tag of the governing verb. We also consider 
the pos tag of the word in the event and the time 
expresion. 
Lexical relations are the semantic relations be-
twen two events derived from VerbOcean 
(Chklovski and Pantel, 204) and WordNet 
(Felbaum, 198). VerbOcean contains five types 
of relations (similarity, strength, antonymy, en-
ablement, and hapens-before) that comonly 
ocur betwen pairs of verbs. To overcome data 
sparsenes, we expanded the original VerbOcean 
database by calculating symetric and transitive 
closures of key relations. With WordNet, a se-
mantic distance betwen the asociated tokens of 
each target event pair was computed. 
5 Modeling
Temporal Relations with 
Markov Logic 
ML is a statistical relational learning framework 
that provides a template language for defining 
Markov Logic Networks (MLNs). A MLN is a 
set of weighted first-order clauses constituting a 
Markov network in which each ground formula 
represents a feature (Richardson and Domingos, 
2006). 
Our MLN consists of a set of formulae com-
bining two types of predicates: hiden and ob-
served. Hiden predicates are those that are not 
directly observable during test time. A hiden 
predicate is defined for each task: relEventTimex 
(temporal relation betwen an event and a time 
expresion), relMainEvents (temporal relation 
betwen two main events), and relMainSub 
(temporal relation betwen a main and a domi-
nated event). Observed predicates are those that 
can be fuly observed during test time and repre-
sent each of the features described in Section 4. 
The folowing is an example formula used in 
our MLN: 
76
eventTimex(d, e, t)  eventWord(d, e, w) 
          relEventTimex(d, e, t, r)    (1) 
The predicate eventTimex(d, e, t) represents the 
existence of a candidate pair of event e and time 
expresion t in a document d. Given this candi-
date pair, formula (1) asigns weights to a tem-
poral relation r whenever it observes a word to-
ken w in the given event from the training data. 
This formula is local because it considers only 
one hiden predicate (relEventTimex). 
In adition to local formulae, we also define a 
set of global formulae to ensure consistency be-
twen local decisions: 
relEventTimex(d, e
1, t, r
1
)  relEventTimex(d, 
e
2, t, r
2
)  relMainSub(d, e
1, e
2, r
3
)      (2) 
Formula (2) is global because it jointly concerns 
more than one hiden predicate (relEventTimex 
and relMainSub) at the same time. This formula 
ensures consistency betwen the predicted tem-
poral relations r
1, r
2, and r
3
 given a main event 
e
1, a syntacticaly dominated event e
2, and a time 
expresion t shared by both of these events. Two 
aditional global formulae (3) and (4) are simi-
larly defined to ensure consistency as below. 
relMainSub(d, e
1, e
2, r
3
)  relEventTimex(d, 
e
2, t, r
2
)    relEventTimex(d, e
1, t, r
1
)    (3) 
relMainSub(d, e
1, e
2, r
3
)  relEventTimex(d, 
e
1, t, r
1
)    relEventTimex(d, e
2, t, r
2
)    (4) 
6 Evaluation

To evaluate the proposed aproach, we built and 
compared two models: one model (NoLex) used 
al of the features described in Section 4 except 
for the lexical relation features, and the other 
model (Ful) included the ful set of features. The 
features were generated using the Porter 
Stemer and WordNet Lematizer in NLTK 
(Loper and Bird, 202) and the Charniak Parser 
(Charniak, 200). The semantic distance betwen 
two word tokens was computed using the path-
similarity metric provided by NLTK. Al of the 
models were constructed using Markov TheBeast 
(Riedel, 2008) 
The feature set was optimized for each task on 
a held-out development data set consisting of 
aproximately 10% of the entire training set (Ta-
ble 1). Our previous work (Ha et al., 2010) ob-
served that a local optimization aproach that 
selects for each individual task (i.e., each hiden 
predicate in the given MLN) in isolation from the 
other tasks could harm the overal acuracy of a 
joint model because of resulting inconsistencies 
among individual tasks. In the new experiment 
described in this section, features were selected 
for each task to improve overal acuracy of the 
joint model combining al thre tasks, similar to 
Yoshikawa et al. (209). 
Table 2 reports the resulting performance (F1 
scores) of the models. To isolate the potential 
efects of global constraints, we first compare the 
acuracies of the Ful and the NoLex model, av-
eraged from a ten-fold cros validation on the 
training data before global constraints are aded. 
Ful achieves relative 12% and 3% improve-
ments over NoLex for temporal relation betwen 
events and time expresions (ET) and betwen 
two main events (MM), respectively. The im-
provement for M was statisticaly significant 
(p<0.05) from a two-tailed paired t-test. Note 
that the ET task itself does not use lexical rela-
tion features but stil achieves an improved result 
in Ful over NoLex. This is an efect of joint 
modeling. There is a slight degradation (relative 
2%) in the acuracy for temporal relations be-
twen main and syntacticaly dominated events 
(MS). Overal, Ful achieves relative 5% im-
provement over NoLex. A similar trend of per-
formance improvement in Ful over NoLex was 
observed when the global formulae were aded 
to each model. The second column (Global Con-
straints) of Table 2 compares the two models 
trained on the entire training set and tested on the 
test set after the global formulae were aded. 
However, no statistical significance was found 
on these improvements. Compared to the state-
Task 
Feature 
ET MM MS 
event-word √ √ √ 
event-stem √ √
 
√ 
timex-word √   
Surface 
Features 
timex-stem √   
event-polarity √ √ √ 
event-modal √ √ √ 
event-pos √ √  √* 
event-tense √ √ √ 
event-aspect √ √ √ 
event-clas √ √ √ 
timex-type √   
Semantic 
Atributes 
timex-value √   
pos √ √ √ 
gov-prep √ √ √ 
gov-verb √ √ √ 
Syntactic 
Features 
gov-verb-pos √ √ √ 
verb-rel  √ √ Lexical 
Relations word-dist  √  
 
Table 1: Features used to model each task. *The 
feature is extracted only from the second event in 
the pair being compared. 
77
of-the-art results achieved by the TempEval-2 
participants, Ful achieves the same or beter re-
sults on al thre adresed tasks. 
7 Conclusions

Temporal relations can be modeled with Markov 
Logic using a variety of features including lexi-
cal ontologies. Thre tasks relating to the Tem-
pEval-2 data were adresed: predicting tempo-
ral relations betwen (1) events and time expres-
sions in the same sentence, (2) two main events 
in consecutive sentences, and (3) two events in 
the same sentence when one syntacticaly domi-
nates the other. An evaluation sugests that util-
izing lexical relation features within a joint mod-
eling framework using Markov Logic achieves 
state-of-the-art performance. 
The results sugest a promising direction for 
future work. The proposed aproach asumes 
events and time expresions are already marked 
in the data. To construct a fuly automatic tempo-
ral relation identification system, the aproach 
neds to be extended to include models that rec-
ognize events and time expresions in text as 
wel as their semantic atributes. A data-driven 
aproach similar to the one described in this pa-
per may be feasible for this new modeling task. It 
wil entail exploring a variety of features to fur-
ther understand the complexity underlying the 
problem of temporal analysis of events. 
Acknowledgments 
This research was suported by the National Sci-
ence Foundation under Grant IS-0757535. 
References  
S. Bethard and J. H. Martin. 207. CU-TMP: 
Temporal relation clasification using syntactic and 
semantic features. In Procedings of the 4th Inter-
national Workshop on Semantic Evaluations, pages 
129-132, Prague, Czech Republic. 
B. Boguraev and R. K. Ando. 205. TimeML-
compliant text analysis for temporal reasoning. In 
Procedings of the 19th International Joint 
Conference on Artificial inteligence, pages 97-
103, Edinburgh, Scotland. 
N. Chambers and D. Jurafsky. 208. Jointly combin-
ing implicit constraints improves temporal order-
ing. In Procedings of the Conference on Empiri-
cal Methods in Natural Language Procesing, 
pages 698-706, Honolulu, HI. 
E. Charniak. 200. A maximum-entropy-inspired 
parser. In Procedings of the 1
st
 North American 
Chapter of the Asociation for Computational Lin-
Chapter of the Asociation for Computational Lin-
guistics Conference, pages 132-139, Seatle, WA. 
T. Chklovski and P. Pantel. 204. VerbOcean: Mining 
the web for fine-grained semantic verb relations. In 
Procedings of the Conference on Empirical Meth-
ods in Natural Language Procesing, pages 3-40, 
Barcelona, Spain. 
E. Ha, A. Baikadi, C. Licata, and J. Lester. 2010. 
NCSU: Modeling temporal relations with Markov 
Logic and lexical ontology. In Procedings of the 
5
th
 International Workshop on Semantic Evaluation, 
pages 341-344, Upsala, Sweden. 
E. Loper and S. Bird. 202. NLTK: The natural lan-
guage tolkit. In Procedings of ACL Workshop on 
Efective Tols and Methodologies for Teaching 
Natural Language Procesing and Computational 
Linguistics, pages 62-69, Philadelphia, PA. 
J. Pustejovsky and M. Verhagen. 209. SemEval-
2010 task 13: Evaluating events, time expresions, 
and temporal relations. In Procedings of the 
Workshop on Semantic Evaluations: Recent 
Achievements and Future Directions, pages 12-
16, Boulder, CO. 
S. Riedel. 208. Improving the acuracy and efi-
ciency of MAP inference for Markov Logic. In 
Procedings of the 24th Conference in Uncertainty 
in Artificial Inteligence, pages 468-475, Helsinki, 
Finland. 
M. Richardson and P. Domingos. 206. Markov 
Logic networks. Machine Learning, 62(1):107-
136. 
M. Verhagen, R. Gaizauskas, F. Schilder, M. Heple, 
G. Katz, and J. Pustejovsky. 207. Semeval-2007 
task 15: Tempeval temporal relation identification. 
In Procedings of the 4th International Workshop 
on Semantic Evaluations, pages 75-80, Prague, 
Czech Republic. 
K. Yoshikawa, S. Riedel, M. Asahara, and Y. Matsu-
moto. 209. Jointly identifying temporal relations 
with Markov Logic. In Procedings of the Joint 
Conference of the 47th Anual Meting of the ACL 
and the 4th International Joint Conference on 
Natural Language Procesing of the AFNLP, pages 
405-413, Suntec, Singapore. 
No Global Constraints Global Constraints 
Task 
NoLex Ful NoLex Ful 
State-of-
the-art 
Overal 0.60 0.63 (+5%) 0.59 0.61 (+3%) NA 
ET 0.52 0.58 (+12%) 0.62 0.65 (+5%) 0.63 
MM 0.65 0.67 (+3%)* 0.52 0.56 (+8%) 0.5 
MS 0.6 0.65 (2%) 0.6 0.6 (+0%) 0.6 
Table 2. Performance comparison betwen mod-
els in F1 score. *Statistical significance (p<0.05) 
78

