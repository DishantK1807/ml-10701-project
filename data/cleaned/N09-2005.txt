Proceedings of NAACL HLT 2009: Short Papers, pages 17–20,
Boulder, Colorado, June 2009. c 2009 Association for Computational Linguistics
17
tasks. The triplet lexicon model presented in this
work can also be interpreted as an extension of the
standard IBM model 1 (Brown et al., 1993) with an
additional trigger.
2 Setup
The main focus of this work investigates an extended
lexicon model in search and rescoring. The model
that we consider here and its integration in the de-
coder and setup for rescoring are presented in the
following sections.
2.1 Extended
lexicon model
The triplets of the extended lexicon model p(e|f,fprime)
are composed of two words in the source language
triggering one target word. In order to limit the over-
all number of triplets, we apply a training constraint
that reuses the word alignment information obtained
in the GIZA++ step. For source words f, we only
consider the ones that are aligned to a target word e
given the GIZA++ word alignment. The second trig-
ger fprime is allowed to move over the whole source sen-
tence, thus capturing long-distance effects that can
be observed in the training data:
p(eI1|fJ1 ,{aij}) =
Iproductdisplay
i=1
p(ei|fJ1 ,{aij}) =
Iproductdisplay
i=1
1
Zi
summationdisplay
j∈{ai}
Jsummationdisplay
jprime=1
p(ei|fj,fjprime) (1)
where{aij}denotes the alignment matrix of the sen-
tence pair fJ1 and eI1 and the first sum goes over all
fj that are aligned to the current ei (expressed as
j ∈{ai}). The factor Zi = J ·|{ai}| normalizes
the double summation accordingly. Eq. 1 is used in
the iterative EM training on all sentence pairs of the
training data. Empty words are allowed on the trig-
gering part and low probability triplets are trimmed.
2.2 Decoding
Regarding the search, we can apply this model di-
rectly when scoring bilingual phrase pairs. Given a
trained model for p(e|f,fprime), we compute the feature
score ht of a phrase pair (˜e, ˜f) as
ht(˜e, ˜f,{˜aij},fJ1 ) = (2)
−summationdisplay
i
log summationdisplay
j∈{˜ai}
summationdisplay
jprime
p(˜ei|˜fj,fjprime)+summationdisplay
i
logZi
where i moves over all target words in the phrase ˜e,
the sum over j selects the aligned source words ˜fj
given{˜aij}, the alignment matrix within the phrase
pair, and jprime incorporates the whole source sentence
fJ1 . Analogous to Eq. 1, Zi = J ·|{˜ai}| denotes
the number of overall source words times the num-
ber of aligned source words to each ˜ei. In Eq. 2,
we take negative log-probabilities and normalize to
obtain the final score (representing costs) for the
given phrase pair. Note that in search, we can only
use this direction, p(e|f,fprime), since the whole source
sentence is available for triggering effects whereas
not all target words have been generated so far,
as it would be necessary for the reverse direction,
p(f|e,eprime). Due to data sparseness, we smooth the
model by using a floor value of 10−7 for unseen
events during decoding. Furthermore, an implicit
backoff to IBM1 exists if the second trigger is the
empty word, i.e. for events of the form p(e|f,ε).
2.3 Rescoring
In rescoring, we constrain the scoring of our hy-
potheses to a limited set of n-best translations that
are extracted from the word graph, a pruned com-
pact representation of the search space. The advan-
tage of n-best list rescoring is the full availability of
both source text and target translation, thus allow-
ing for the application of additional (possibly more
complex) models that are hard to implement directly
in search, such as e.g. syntactic models based on
parsers or huge LMs that would not fit in memory
during decoding. Since we are limiting ourselves to
a small extract of translation hypotheses, rescoring
models cannot outperform the same models if ap-
plied directly in search. One advantage though is
that we can apply the introduced trigger model also
in the other direction, i.e. usingp(f|e,eprime), where two
target words trigger one source word. Generally, the
combination of two directions of a model yields fur-
ther improvements, so we investigated how this ad-
ditional direction helps in rescoring (cf. Section 3.1).
In our experiments, we use 10 000-best lists ex-
tracted from the word graphs. An initial setting uses
the baseline system, whereas a comparative setup in-
corporates the (e|f,fprime) direction of the trigger lexi-
con model in search and adds the reversed direction
in rescoring. Additionally, we use n-gram posteri-
ors, a sentence length model and two large language
18
train (ch/en) test08 (NW/WT)
Sent. pairs 9.1M 480 490
Run. words 259M/300M 14.8K 12.3K
Vocabulary 357K/627K 3.6K 3.2K
Table 1: GALE Chinese-English corpus statistics.
models, a 5-gram count LM trained on 2.5G running
words and the Google Web 1T 5-grams. The feature
weights of the log-linear mix are tuned on a separate
development set using the Downhill Simplex algo-
rithm.
3 Experiments
The experiments are carried out with a GALE sys-
tem using the official development and test sets of
the GALE 2008 evaluation. The corpus statistics
are shown in Table 1. The triplet lexicon model was
trained on a subset of the overall data. We used 1.4M
sentence pairs with 32.3M running words on the En-
glish side. The vocabulary sizes were 76.5K for the
source and 241.7K for the target language. The final
lexicon contains roughly 62 million triplets.
The baseline system incorporates the standard
model setup used in phrase-based SMT which com-
bines phrase translation and word lexicon models
in both directions, a 5-gram language model, word
and phrase penalties, and two models for reorder-
ing (a standard distortion model and a discriminative
phrase orientation model). For a fair comparison, we
also added the related IBM model 1 p(e|f) to the
baseline since it can be computed on the sentence-
level for this direction, target given source. This step
achieves +0.5% BLEU on the development set for
newswire but has no effect on test. As will be pre-
sented in the next section, the extension to another
trigger results in improvements over this baseline,
indicating that the extended triplet model is superior
to the standard IBM model 1. The feature weights
were optimized on separate development sets for
both newswire and web text.
We perform the following pipeline of experi-
ments: A first run generates word graphs using the
baseline models. From this word graph, we ex-
tract 10k-best lists and compare the performance to
a reranked version including the additional models.
In a second step, we add one of the trigger lexi-
Chinese-English newswire web text
GALE test08 BLEU TER BLEU TER
baseline 32.5 59.4 25.8 64.0
rescore, no triplets 32.8 59.0 26.6 63.5
resc. triplets fe+ef 33.2 58.6 27.1 63.0
triplets in search ef 33.1 58.8 26.0 63.5
rescore, no triplets 33.2 58.6 26.7 63.5
rescore, triplets fe 33.7 58.1 27.2 62.0
Table 2: Results obtained for the two test sets. For the
triplet models, “fe” means p(f|e,eprime) and “ef” denotes
p(e|f,fprime). BLEU/TER scores are shown in percent.
con models to the search process, regenerate word
graphs, extract updated n-best lists and add the re-
maining models again in a reranking step.
3.1 Results
Table 2 presents results that were obtained on the
test sets. All results are based on lowercase eval-
uations since the system is trained on lowercased
data in order to keep computational resources fea-
sible. For the newswire setting, the baseline is
32.5% BLEU and 59.4% TER. Rescoring with addi-
tional models not including triplets gives only slight
improvements. By adding the path-aligned triplet
model in both directions, we observe an improve-
ment of +0.7% BLEU and -0.8% TER. Using the
triplet model in source to target direction (e,f,fprime)
during the search process, we arrive at a similar
BLEU improvement of +0.6% without any rerank-
ing models. We add the other direction of the triplets
(f,e,eprime) (the one that can not be used directly in
search) and obtain 33.7% BLEU on the newswire
set. The overall cumulative improvements of triplets
in search and reranking are +0.9% BLEU and -0.9%
TER when compared to the rescored baseline not in-
corporating triplet models and +1.2%/-1.3% on the
decoder baseline, respectively.
For the web text setting, the baseline is consid-
erably lower at 25.8% BLEU and 64.0% TER (cf.
right part of Table 2). We observe an improvement
for the baseline reranking models, a large part of
which is due to the Google Web LM. Adding triplets
to search does not help significantly (+0.2%/-0.5%
BLEU/TER). This might be due to training the
triplet lexicon mainly on newswire data. Rerank-
ing without triplets performs similar to the baseline
19
experiment. Mixing in the (f,e,eprime) direction helps
again: The final score comes out at 27.2% BLEU
and 62.0% TER, the latter being significantly better
than the reranked baseline (-1.5% in TER).
3.2 Discussion
The results indicate that it is worth moving models
from rescoring to the search process. This is not
surprising (and probably well known in the com-
munity). Interestingly, the triplet model can im-
prove translation quality in addition to its related
IBM model 1 which was already part of the base-
line. It seems that the extension by a second trigger
helps to capture some language specific properties
for Chinese-English which go beyond local lexical
(word-to-word) dependencies. In Table 3, we show
an example of improved translation quality where a
triggering effect can be observed. Due to the topic of
the sentence, the phrase local employment was cho-
sen over ownjobs. One of the top triplets in this con-
text is p(employment|uni5C31uni4E1A,uni4EBAuni624D), where uni5C31uni4E1A
is “employment” due to the path-aligned constraint
anduni4EBAuni624Dmeans “talent”. Note that the distance be-
tween these two triggers is five tokens.
4 Conclusion
We presented the integration of an extended lexicon
model into the search process and compared it to a
variant which was used in reranking n-best lists. In
order to keep the overall number of triplets feasi-
ble, and thus memory footprints and training times
low, we chose a path-constrained triplet model that
restricts the first source trigger to the aligned target
word, whereas the second trigger can move along
the whole source sentence. The motivation was to
allow for a more fine-grained lexical choice of tar-
get words by looking at sentence-level context. The
overall improvements that can be accounted to the
triplets are up to +0.9% BLEU and -1.5% TER.
In the future, we plan to investigate more triplet
model variants and work on additional language
pairs such as French-English or German-English.
The reverse direction, p(f|e,eprime), is hard to imple-
ment outside of a reranking framework where the
full target hypotheses are already fully generated. It
might be worth looking at cross-lingual trigger mod-
els such as p(f|e,fprime) or constrained variants like
source uni5FB7uni56FDuni4E3Auni4E86uni4FDDuni62A4uni672Cuni56FDuni4EBAuni5C31uni4E1A,uni5BF9uni5F15uni8FDB
uni56FDuni5916uni4EBAuni624Duni8BBEuni4E86uni8F83uni9AD8uni7684uni95E8uni69DB.
baseline germany, in order to protect their own
jobs, the introduction of foreign talent,
a relatively high threshold.
triplets in order to protect local employment,
germany has a relatively high threshold
for the introduction of foreign talent.
reference in order to protect native employment,
germany has set a relatively high thresh-
old for bringing in foreign talents.
Table 3: Translation example on the newswire test set.
p(f|e,eprime) with eprime < e, i.e. the second trigger com-
ing from the left context within a sentence which has
already been generated.
Acknowledgments
This material is partly based upon work supported by the
Defense Advanced Research Projects Agency (DARPA)
under Contract No. HR0011-06-C-0023, and was partly
realized as part of the Quaero Programme, funded by
OSEO, French State agency for innovation.
The authors would like to thank Juri Ganitkevitch for
training the triplet model.
References
P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, and
R. L. Mercer. 1993. The mathematics of statistical
machine translation: Parameter estimation. Computa-
tional Linguistics, 19(2):263–311, June.
M. Carpuat and D. Wu. 2007. Improving statistical ma-
chine translation using word sense disambiguation. In
Proc. EMNLP-CoNLL, Prague, Czech Republic, June.
Y. S. Chan, H. T. Ng, and D. Chiang. 2007. Word sense
disambiguation improves statistical machine transla-
tion. In Proc. ACL, pages 33–40, Prague, Czech Re-
public, June.
I. Garc´ıa-Varea, F. J. Och, H. Ney, and F. Casacuberta.
2001. Refined lexicon models for statistical machine
translation using a maximum entropy approach. In
Proc. ACL Data-Driven Machine Translation Work-
shop, pages 204–211, Toulouse, France, July.
S. Hasan, J. Ganitkevitch, H. Ney, and J. Andr´es-Ferrer.
2008. Triplet lexicon models for statistical machine
translation. In Proc. EMNLP, pages 372–381, Hon-
olulu, Hawaii, October.
D. Vickrey, L. Biewald, M. Teyssier, and D. Koller. 2005.
Word-sense disambiguation for machine translation.
In Proc. HLT-EMNLP, pages 771–778, Morristown,
NJ, USA.
20

