For evaluation we use ROUGE (Lin, 2004) SU4 recall metric1, which was among the official automatic evaluation metrics for DUC.
W04-1013
com/~appelt/ie-tutorial/) 2 Masayuki Asahara, Yuji Matsumoto, Extended models and tools for high-performance part-of-speech tagger, Proceedings of the 18th conference on Computational linguistics, p.21-27, July 31-August 04, 2000, Saarbrcken, Germany 3 Frdric Bchet, Alexis Nasr, Franck Genet, Tagging unknown proper names using decision trees, Proceedings of the 38th Annual Meeting on Association for Computational Linguistics, p.77-84, October 03-06, 2000, Hong Kong 4 Daniel M.
C00-1072
In Proceedings of the First Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL-2000), pages 186193, Seattle, April/May .
C00-1072
First, two estimates of importance on words have been used very successfully both in generic and query-focused summarization: frequency (Luhn, 1958; Nenkova et al., 2006; Vanderwende et al., 2006) and loglikelihood ratio (Lin and Hovy, 2000; Conroy et al., 2006; Lacatusu et al., 2006).
C00-1072 P06-2020
In Conroy et al.(2006) such query sensititivity is achieved by augmenting LLR(C) with all content words from the user query, each assigned a weight of 1 equal to the weight of words defined by LLR(C) as topic words from the input to the summarizer.
P06-2020
Such words are called signature terms in Lin and Hovy (2000) who were the first to introduce the log-likelihood weighting scheme for summarization.
C00-1072
This weighting scheme has been adopted in several recent generic and topic-focused summarizers (Conroy et al., 2006; Lacatusu et al., 2006).
P06-2020
