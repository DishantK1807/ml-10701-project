Teahan et al.(2000) state that interpreting a text as a sequence of words is beneficial for some information retrieval and storage tasks: for example, full-text searches, word-based compression, and key-phrase extraction.
J00-3004
In addition, there is no commonly accepted standard for evaluating the performance of word extraction methods, and it is very hard to decide whether a word is meaningful or not (Sproat et al.1996). We define precision as the number of extracted words that would be meaningful in a Chinese native speaker’s opinion, divided by the total number of extracted compounds.
J96-3004
Weeber, Vos, and Baayen (2000) recently extracted side-effect-related terms in a medical-information extraction system and found that many of the terms had a frequency of less than five.
J00-3001
Yamamoto and Church (2001) experiment with both mutual information and residual inverse document frequency (RIDF) 1 as criteria for deciding Japanese words, and their main contribution is in affording a reduced method for computing term and document frequency.
J01-1001
There are several commonly used segmentation methods such as forward maximum matching and backward maximum matching (Teahan et al.2000; Dai, Loh, and Khoo 1999; Sproat et al.1996). If the dictionary includes the words,, and, then forward maximum matching will extract two words, and, after segmenting the sentence.
J00-3004 J96-3004
Zhang, Gao, and Zhou (2000) propose the application of a statistical method that is based on context dependence and mutual information.
W00-1219
In Chinese text segmentation there are three basic approaches (Sproat et al.1996): pure heuristic, pure statistical, and a hybrid of the two.
J96-3004
According to Guo (1997), words and tokens are the primary building blocks in almost all linguistic theories and language-processing systems, including Japanese (Kobayasi, Tokumaga, and Tanaka 1994), Korean (Yun, Lee, and Rim 1995), German (Pachunke et al.1992), and English (Garside, Leech, and Sampson 1987), in various media, such ∗ School of Computer Science and Technology, Jinan, PRC; Department of Computer Science, Tat Chee Avenue, Kowloon, Hong Kong.
C92-4195 J97-4004
As even human judges differ when facing the task of segmenting a text into words and test corpora differ from system to system (Sproat et al.1996), it is very difficult to compare two methods.
J96-3004
Teahan et al.(2000) propose a compression-based algorithm for Chinese text segmentation.
J00-3004
