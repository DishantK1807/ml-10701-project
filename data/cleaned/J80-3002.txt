Characterizing Indirect Speech Acts 1 Gretchen P.
Brown Computer Corporation of America 575 Technology Square Cambridge, Massachusetts 02139 This paper presents the core of a descriptive theory of indirect speech acts, i.e. utterances in which one speech act form is used to realize another, different, speech act.
The proposed characterization of indirect speech acts is based on principles of goal formation, viewed in the context of a general structural model of action.
The model of action is used to develop rules that characterize a large number of indirect speech act forms.
Computational implications of the theory are discussed.
1. Introduction In recent years, a considerable amount of attention has been devoted to the topic of indirect speech acts, i.e. utterances in which one speech act form is used to realize another, different, speech act.
A simple example of an indirect speech act is the question form 1.1 uttered with the intent to convey a request to close the door.
1.1 Can
you close the door?
Despite the volume of work that has been done on indirect speech acts, fundamental questions remain unanswered.
We still lack a complete answer to even the basic question of what forms can realize a given speech act.
Two properties of the problem have made the search for a complete theory of indirect forms particularly difficult: 1..Sheer numbers: There are a considerable number of different speech acts, and many have a wide selection of possible indirect realizations.
A theory must be quite general to take these into account.
2. Variety: Indirect speech act forms range from highly conventionalized to apparently free forms.
It appears that no single, simple set of generalizations can adequately capture the complexity of indirect speech acts.
1 The
research for this paper was carried out while the author was on the staff of the Laboratory for Computer Science at the Massachusetts Institute of Technology.
The research was supported by the Advanced Research Projects Agency of the Department of Defense and was monitored by the Office of Naval Research under Contract Number N00014-75-C-0661.
It is the claim of this paper that previous inv~estigations of indirect speech acts (abbreviated ISAs 2) have been hampered by inadequate semantic theories.
This study takes as primary the central tenet of speech act theory that language is action (Austin \[2\]) and brings to bear some of the perspectives on the representation of actions developed in the course of Artificial Intelligence research.
Accordingly, principles of goal formation are discussed in the context of a general structural model of action.
The model of action is used to develop rules that characterize a large number of indirect speech act forms.
The focus of this investigation is on the development of a descriptive theory of ISAs.
Accounting for the diversity of ISAs is an important goal, but I see the formulation of a solid and complete descriptive theory as a necessary prerequisite to an explanatory theory.
This is not to say that explanation can be totally decoupled from description, and, in fact, the use of the general model of actions to derive ISA forms has significant explanatory potential.
To fully account for differences in ISA forms, however, we must have a good characterization of what these differences are.
While the claims that will be made in this paper stop at a (partial) descriptive theory of ISAs, the underlying motivations do not.
Computational considerations have played a significant role in the development of the ISA categorization.
The work presented here grew out of the implementation effort reported in 2 It is helpful to pronounce ISA as initials to avoid confusion with IS-A, the name used commonly in the Artificial Intelligence literature for a hierarchical semantic relationship.
Copyright 1980 by the Association for Computational Linguistics.
Permission to copy without fee all or part of this material is granted provided that the copies are not made for direct commercial advantage and the Journal reference and this copyright notice are included on the first page.
To copy otherwise, or to republish, requires a fee and/or specific permission.
0362-613X/80/030150-17501.00 150 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 Gretchen P.
Brown Characterizing Indirect Speech Acts \[3\].
The actual behavior of the system was limited (internal manipulations for a twenty turn sample dialogue), but the process model implemented was relatively sophisticated.
A further expanded and refined version of this model is presented in \[4\].
In viewing the characterization of ISAs as a computational problem, the central premise has been that the phenomenon of ISAs is too complex to admit to a single uniform computational treatment.
The two stumbling blocks to a descriptive theory -the number and variety of ISA forms -are doubly troubling when the theory is to have a computational application.
Some means must be found to divide the class of ISAs into subclasses which have their own specialized representations and processing strategies.
The development of the descriptive theory of ISAs presented has been affected in various ways, subtle and not so subtle, by this computational hypothesis.
The proper level of representation of ISA rules has been of primary concern, as has the identification of classes of ISAs according to the complexity of their derivations.
Section 2 introduces some of the issues that have been raised about ISAs and Section 3 lays the groundwork for the approach taken here.
Section 4 then presents a set of general rules that handle a large number of ISA forms.
The rules in that section are proposed as the core of a descriptive theory of ISAs.
Issues surrounding the application of the rules are addressed in Section 5.
Finally, Section 6 discusses some of the implications of the theory, with comparison to recent computational work.
2. Previous Approaches Two approaches to the characterization of indirect speech acts have been particularly influential for both computational and traditional linguists: the views proposed by Gordon and Lakoff and by Searle.
Since the rules presented in this paper combine properties of each approach, we start with a brief description of each.
We consider first the approach taken by Gordon and Lakoff \[12\].
Concentrating primarily on request, Gordon and Lakoff propose a set of what they call sincerity conditions and then give a single powerful rule to account for the different ways that a request can be framed.
They say that to make a sincere request a speaker must, first, want the action done, second, believe that the hearer can do the action, third, believe that the hearer wants to do the action, and, fourth, believe that the hearer would not do the action unless asked to.
The first of these sincerity conditions is called speaker-based and the remaining three are called hearer-based.
The rule given is: One can convey a request by (a) asserting a speaker-based sincerity condition or (b) questioning a hearer-based sincerity condition.
This formulation is attractive because it is so elegant and simple, but it is also, as the authors are the first to observe, only a preliminary answer.
The conditions associated with request are incomplete, since they lack any mention of obligation relationships; these are discussed below in Section 3.3.
More problematic is the lack of detailed guidelines for extending the theory beyond requests.
A second major approach to ISA regularities is that of Searle.
Searle presents a more complete account of ISAs, proposing generalizations associated with the five major classes of speech act defined in \[26\].
In \[25\] he lists four generalizations for directives and five others for commissives.
The generalizations are differentiated according to the parts of the speech act identified in \[24\], i.e. propositional content conditions, sincerity conditions, and preparatory conditions.
(Gordon and Lakoff's sincerity conditions, in contrast, seem to be an amalgam of Searle's sincerity and preparatory conditions).
Searle's contribution is a valuable one, in that he has succeeded in accounting for a broad range of speech acts.
At the same time, Searle's generalizations can be questioned on the count that they are too specific.
Generalizations are stated in terms of types of preparatory conditions, rather than in terms of preparatory conditions as a whole.
A more serious problem is the relegation of the notion of speakerand hearerbased conditions to an informal role, as opposed to giving it an explicit place in the theory.
The theory proposed in this paper is both a synthesis and a generalization of the two approaches.
Rather than derive ISA forms from a single set of conditions associated with the speech act, as do Gordon aild Lakoff, I follow Searle in looking for important classes of ISA forms based on different parts of the speech act.
The theory presented goes a step further, however, looking beyond the structure of individual speech acts to derive ISA forms from very general principles of goal formation.
3. Preliminaries We first introduce the model of actions on which the ISA rules will be based, and Section 3.2 looks at speech acts from the perspective of this model.
Section 3.3 then discusses the request speech act as a basis for examples used throughout the paper.
3.1. An Outline of the Structure of Actions If we are to follow Austin and Searle in the belief that language is, fundamentally, action, then linguistic models must include a model of the structure of actions.
Such a model of actions can be a unifying force American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 151 Gretchen P.
Brown Characterizing Indirect Speech Acts within the larger model, since structural information can be used in a number of different ways.
This subsection gives a very general treatment of actions, just enough to support the ISA rules proposed.
The account of actions is taken from the OWL-I representation scheme (Szolovits et al.\[27\] and Brown \[3,6\]), 3 and it has counterparts in work by Bruce \[7\], Schank and Abelson \[23\], Grosz \[14\], and Moore, Levin, and Mann \[18,19\].
Some of these approaches differ in the type of action modelled, and all of them differ in the details, but each of the approaches is open to the treatment of action representations as general knowledge.
Thus, action representations are not merely programs for doing something, they are also knowledge structures that may be used by other processes.
We start with the notion of a method, a representation of an action.
Methods have three main parts: a header, argument specifications, and a procedural body.
The header is the method's unique name.
Argument specifications, organized by semantic cases, are used for type checking of inputs to the method (input cases) or to specify the form of results (output cases).
The procedural body is divided into two parts: (optional) prerequisites and procedure steps.
Note that input cases are associated with methods, not surface English verbs.
Input case specifications give constraints on the participants in the method, the materials used, objects manipulated, etc.
(A suggested set of semantic input cases derived by William A.
Martin can be found in \[4\]).
An important type of input case constraint, the precondition, is discussed in the next subsection.
Besides input case specifications, we said that methods may have associated output case specifications, i.e. specifications of results.
One important notion here is that of principal result, which is the main result of the method and, typically, the reason that the method is undertaken.
For example, the action conveyed in "Paint the block red" has as principal result that the block is red.
The paint brush may also end up red, but this is not the principal result.
Turning to the method's procedural body, we need to know that procedure steps may correspond to subactions, i.e. they may be used as calls to other methods.
Beyond this, procedure steps have a good deal of interesting structure, discussion of which is not necessary for the purposes of this paper.
As for prerequisites, the ones that are of interest here are states.
A stative prerequisite of an action is a condition that must obtain before that action is carried out.
If the condition does not hold, then one must 30WL-I was developed by William A.
Martin, Lowell Hawkinson, William Long, Alexander Sunguroff, William Swartout, Peter Szolovits, and the author.
OWL has continued to develop since that time.
bring it about before carrying out the action.
An example of a prerequisite is the requirement that an elementary course of study be completed before a more advanced one is undertaken.
3.2. The Model of Actions Applied to Speech Acts Speech acts, because they are actions, can be represented by methods.
Speech act representations therefore have semantic input cases, which typically include cases for the participants in the conversation and a case for what Searle calls the propositional content condition of the speech act (very roughly, what the speech act is "about") \[24\].
Among the constraints on these input cases are preconditions.
Preconditions are constraints on the beliefs, desires, or other intentions of the agent of the method (the participant responsible for the action) that should be satisfied before the speech act gets underway.
Preconditions differ from prerequisites in that a failure to satisfy preconditions typically means that a method is eliminated from consideration as a possible plan; a prerequisite that is not satisfied merely adds extra steps to be performed.
Preconditions will play an important role in the framing of ISAs; a sample set is given in the next subsection.
A concept that will be useful in talking about ISAs is the intended effect.
The intended effects of speech acts are those effects that P1 (the agent of the speech act) intends to have on P2.
The most important of these effects will be called the principal intended effect.
For request, the principal intended effect is that P2 take responsibility for carrying out some action.
For offer, it is that P2 accept the offer.
"Accept" here includes not only a verbal acceptance, but also that P2 perform some action that complements Pl's offer, e.g., P2 takes food that is offered.
The notion of intended effect comes from Verschueren \[28\], but it has been adapted somewhat.
In particular, for uniformity, intended effects will be restricted to be actions only, not states.
For example, the principal intended effect for state is that P2 come to know (as opposed to just know) that P1 believes something to be a fact.
Intended effects and principal intended effects can be related in a straightforward way to methods.
Intended effects are actions precipitating certain method results (i.e.
intended effects are the direct causes); principal intended effects are actions precipitating certain principal results.
The results and principal results are not necessarily associated with the speech act method but are instead associated with higher level methods that include both the speech act and its prototypical linguistic and nonlinguistic responses.
Once speech acts have been set within the action representation, we can define ISAs more closely to delimit the phenomena of interest.
Speech acts conveyed by ISA forms are derivable from parts of, or 152 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 Gretchen P.
Brown Characl:erizing Indirect Speech Acts conditions associated with, the conveyed speech act(s).
Other implications of an utterance may arise from a particular co-occurrence of steps within larger patterns of dialogue, but these implications will not be considered to be conveyed speech acts.
A very simple example of such an implication comes from a computer console session environment, where some users type "Thank you" in a place where others type "Thank you" followed by "Good-bye".
When "Thank you" occurs alone in such a situation, it will not be considered to be an indirect closing.
Instead, the closing is seen as an optional step, which may be omitted in the presence of utterances that uniquely identify the place in the dialogue.
Utterances that imply omitted steps do so based on relationships at a higher level of dialogue structure than individual speech acts.
3.3. Preconditions for Requests Although the rules presented in the next section are intended to apply to speech acts in general, examples will be drawn primarily from request forms.
Since the ISA rules depend in part on the preconditions of a speech act, the preconditions of the speech act request are discussed here; preconditions for ask, state, offer, and suggest appear in the Appendix.
4 In
these preconditions and throughout the paper, P1 is the originator of the utterance (or written message) and P2 is the receiver.
If subsequent related utterances are discussed, then P1 and P2 continue to refer to the same participants.
Consider, then, the following preconditions for request: I.
P1 wants P2 to take responsibility for carrying out the action.
II. P1 believes that P2 can take responsibility for carrying out the action.
III. P1 believes that P2 is willing to take responsibility for carrying out the action.
IV. P1 believes that P2 is obligated to P1 (and possibly to others) to take responsibility for carrying out the action.
To clarify the terms used in the preconditions, I will outline some of the relationships that should be captured in a semantic network representation of them.
The internal semantic node believe has a superclass relationship to semantic nodes for idea-holding concepts, e.g., thinking, knowing, assuming, and hypothesizing.
The different specializations (i.e.
subclasses) of believe differ according to the strength of commitment to the belief.
In addition, they differ according to 4 In the interests of readability, preconditions and ISA rules are presented in this paper informally.
The model of actions and rules have been represented in OWL-I, which implies a number of commitments, many shared by other representation schemes of the late seventies.
These commitments are discussed further in Sect.
5. whether the belief is open to confirmation against some external reality (i.e., facts), will eventually be open to confirmation (i.e., guesses and predictions), or is generally considered to be a matter of taste (i.e., opinions).
The link between the various specializations of believe is the fact that beliefs can be partially supported by evidence, whether or not complete confirmation of the beliefs is ultimately possible.
This excludes idea-holding actions such as dreaming.
In precondition I, the internal node want has a superclass relationship to semantic nodes for all goalholding concepts, e.g., desiring and hoping.
"Take responsibility" is used in the preconditions to permit subcontracting.
Whether P2 does all the action steps or not, P2 still remains responsible to P1 for the resuits.
In precondition II, "can" is meant to convey the general notion of enablement for actions.
One specialization of the semantic node can is may, enablement through permission.
The internal representation for "can" is discussed further in Section 5.
In the third precondition, the internal node for "be willing" has a superclass in common with want (perhaps called "be inclined") but it differs in that if P2 is willing to do action A1, he or she is not disinclined to do it.
That is to say, P2 does not necessarily have A1 as a goal, but P2 has no conflicting goals which, when weighed against A1, result in a decision against adopting A1 as a goal.
Precondition III is worded "P2 is willing to" rather than "P2 wants to," because P2 will not necessarily already have the action requested as a goal at the time that P1 makes the request.
Finally, we come to the notion of obligation in precondition IV.
The concept of obligation assumed is a more specific version of the generalized obligation that Labov and Fanshel use for requests in \[16\].
Obligation to other people is seen here as coming in three types: role obligation, authority obligation, and the general obligation to be cooperative.
Role obligations are associated with roles, which can be seen as patterns of behavior that can be assumed by individuals for varying periods of time.
An example of a role obligation would be the requirement that a bank teller fulfill a request to make change.
Authority obligations are slightly more difficult to identify, since, especially in contemporary American society, most authority arises from roles.
Authority obligations based on age differences are probably the most prevalent examples.
The third type of obligation, the general obligation to be cooperative, seems to arise simply from a need, often in the form of a temporary inequality between individuals.
The obligation applies in a range of situations.
A typically mundane version of the obligation is that questions should be answered, i.e. that inequalities of knowledge should be corrected.
A more serious American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 153 Gretchen P.
Brown Characterizing Indirect Speech Acts version is the injunction to help someone in an emergency.
Note that this obligation is not absolute (nor are role or authority obligations), and it may be overridden by other obligations.
A point worth mentioning is that my notion of obligation includes the notion of Pl's right to invoke the obligation.
(See \[16\], p.
78). An obligation is seen as a three-place relationship between P1, P2, and the thing that P2 is obliged to do.
Note that the specific persons P1 and P2 need not be named explicitly in the obligation.
For example, the obligation to drive carefully may be an obligation to society in general, and hence to any individual P1 by inclusion in the larger set.
Given this formulation, P1 has the right to invoke the obligation to drive carefully because P1 is one of the parties to the obligation, even if P1 is not named explicitly.5 Philosophical controversy surrounds several of these terms, and a complete and detailed definition for any of them is a research project in itself.
The comments on the terms used in the preconditions are sketchy, but the intent of the comments is to give the reader enough information to evaluate the approach to ISA characterization proposed in this paper.
4. A Set of General Rules for Indirect Speech Acts If one looks carefully at a varied group of indirect speech acts, an outline of a common sense view of rational behavior begins to emerge.
This common sense view can be used as a conceptual organization of ISA forms, an approach taken here in the presentation of a set of general rules for ISAs.
4.1. Some Basic Observations We start with some very basic observations, none of which should seem particularly remarkable since the phenomena involved lie just below the surface, and sometimes right at the surface, of English (and other languages as well).
Strategy 1.
If you believe that a proposition holds, you can tell someone.
Strategy 2.
If you want to know whether a proposition holds, you can ask someone if it holds.
Strategy 3.
If you want to know whether a proposition holds, you can ask someone if it does not hold.
These three communication strategies are extensions of the observations made by Searle and built into Gordon and Lakoff's rule for requests.
"Can" is used above to indicate that other options do, of course, exist; these are merely the options of interest for ISAs.
5 Reminders
are one class of utterance in which P1 does have the right to invoke an obligation without being a party to it.
This is not necessarily a problem for requests, however, because reminders can be treated as separate speech acts.
The three strategies can be augmented by what will be called here the better-knowledge principle: if both you and a conversational partner have a degree of knowledge about a proposition, the decision whether to tell what you know (or think) or ask what the other person knows (or thinks) can be made based on which participant has the better knowledge of the proposition.
Moving from information exchanges to actions in general, we can identify some basic factors in the process of undertaking an action (i.e.
adopting the action as a goal, not necessarily with the intent of being the agent yourself).
1. One should only undertake actions that are necessary.
2. One should only undertake actions for which some desirable result or results can be expected.
3. One should only undertake actions that one expects to be possible.
These three maxims, which will be referred to as the maxims of Necessity, Desirability, and Possibility, summarize factors that should be weighed in goal formation, the process of deciding to adopt some action as a goal.
Necessity, desirability, and possibility of actions are not necessarily, of course, evaluated independently, but the maxims abstract away from the actual weighing procedure.
Interpretation of these maxims is intended to be quite broad.
"Necessity" is assumed here to include obligations, and "possibility" is assumed to include having permission.
Readers familiar with the classic work of Grice on conversational implicature \[13\] will recognize the approach that is being taken.
Grice suggests four categories of maxims that are applicable to linguistic actions but which have analogues in other types of actions.
The maxims given here are applicable to actions in general but apply to speech acts as a special case.
The Maxim of Necessity above has a partial counterpart in Grice's category of Quantity.
The other two maxims have no direct counterparts, and they suggest extensions to Grice's framework.
Given these basic observations about communication and action in general, the question is how they should be incorporated into a theory.
One possible approach is to represent the observations at essentially the level of generality given, then derive ISA forms by a uniform inference process.
Here, in contrast, the observations will be used as a conceptual organization and as a guide to rule specification.
The resulting rules will be more specialized, but they will be at a level closer to the ISA forms that they describe.
The motivation for the choice of this approach can better be described after the rules have been presented.
Accordingly, the rest of this section discusses 154 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 Gretchen P.
Brown Characterizing Indirect Speech Acts rules associated with the maxims of Necessity, Desirability, and Possibility.
4.2. Rules Related to the Maxim of Necessity The Maxim of Necessity says that one should act only when necessary, avoiding extraneous actions.
The following rules account for speech act forms related to this maxim: P1 can convey a speech act indirectly by -Rule NECESSARY-ASSERT -asserting that the intended speech act is necessary e.g., the request "I have to ask you to shut the door".
Rule NECESSARY-ASK -asking whether the intended speech act is necessary e.g., the request "Do I need to ask you to shut the door"?
Rule EQUI-ASK -asking whether an equivalent speech act (i.e., one with the same principal intended effect) has already been performed e.g., the request "Did anyone ask you to take out the garbage"?
Rule FUTURE-EFFECT-ASK -asking whether the principal intended effect can be expected to occur without the speech act e.g., the requests: "Are you planning to take out the garbage"?
"Are you going to take out the garbage"?
Rule PAST-EFFECT-ASK -asking whether the principal intended effect of the speech act has already occurred e.g., the requests: "Did you take out the garbage"?
"Have you taken out the garbage"? and, using additional rules (see Section 5), "Is the garbage out"?
"Assert" is used in these and subsequent rules to inelude the speech acts of stating a fact and giving an opinion, i.e., those speech acts that Searle calls representatives \[26\].
The "necessity" rules exemplify the three communication strategies listed at the beginning of this section.
NECESSARY-ASSERT exemplifies the first strategy, in which P1 tells what he or she knows about the necessity of the speech act.
In NECESSARYASK, P1 asks whether the speech act is necessary (strategy 2), and in the last three rules, P1 asks whether the speech act is unnecessary (strategy 3).
Note that there is no rule for the explicit version of the third strategy, e.g. for the form "Is it unnecessary for me to <speech act>"?
This form is practically incomprehensible as a way to carry out the speech act, even though the reasoning involved is comparable to that for the EQUI-ASK form.
Perhaps this gap refleets a preference for more specialized forms.
The three strategy-3 rules for necessity, which are more specific, supersede the explicit "Is it unnecessary"... form.
Gordon and Lakoff use a condition analogous to the FUTURE-EFFECT-ASK rule to account for the "Will you <action>"? request form.
In this interpretation, the form asks if the request is unnecessary because P2 was going to perform the desired action anyway.
While this approach is plausible on the face of it, some uses of the "will" form are not motivated by questions of the necessity of the action.
Consider, for example, 4.1: 4.1 Will you accept a ride to the airport?
One can view example 4.1 as P1 asking P2 whether the outcome of an offer by P1 will be successful (i.e., acceptance).
This example can therefore be accounted for by the Maxim of Possibility; "will" forms are discussed further in Section 4.4.
Finally, note that P1 is permitted to use an ISA only when P1 can reasonably expect P2 to decipher Pl's intent, i.e., to recognize the indirection.
Neither the "necessity" rules nor any of the other rules to be presented here, however, include this information.
It appears that this constraint is part of a more general constraint that P1 avoid ambiguity.
That is, P1 is obligated -to the best of his or her ability -to frame any utterance (ISA or not) in such a way that P2 can understand the message that P1 intended to convey.
See Grice \[13\] for discussion of an "avoid ambiguity" maxim.
4.3. Rules Related to the Maxim of Desirability Next we come to the Maxim of Desirability, which says that one should initiate actions for which some desirable result or results can be expected and avoid actions for which an undesirable result or results can be expected.
Related to this maxim, we have the following ISA rules: P1 can convey a speech act indirectly by -Rule DESIRABLE-ASSERT -asserting that some desirable result or results can be expected or some undesirable result or results can be avoided for some intended effect of the speech act.
e.g., the request "I'11 be happier when you substantiate those figures".
Here, the desirable result is the happiness of P1, and the intended effect of the request is that P2 substantiate the figures.
American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 155 Gretchen P.
Brown Characterizing Indirect Speech Acts Rule DESIRABLE-ASK -asking whether some desirable result or results can be expected or whether some undesirable result or results can be avoided for some intended effect of the speech act.
e.g., the request "Will more light come in if you move it a little to the right"?
Rule UNDESIRABLE-ASK -asking whether some undesirable result or results can be expected from the intended speech act.
e.g., the request "Will you be offended if I ask you to loan me some money"?
For the first two rules, note that the intended effect need not be an immediate result of the speech act; it may be several times removed in the causal chain.
Similarly, the desirable result need not be an immediate result of the intended effect.
The "desirability" rules exemplify the three linguistic strategies listed at the beginning of this section.
Again, as for the strategy-3 "necessity" rules, DESIRABLE-ASSERT and DESIRABLE-ASK do not include the most general possible forms.
For example, no rule has been given to permit example 4.2 to be interpreted as an indirect request that P2 be quiet.
4.2 I
will be happier if I ask you to be quiet.
Whereas DESIRABLE-ASSERT is framed in terms of an intended effect of the speech act, example 4.2 refers to the speech act explicitly.
The same hypothesis applies for this gap: the more specialized DESIRABLE-ASSERT has displaced the explicit, and more general, form exemplified by 4.2. 4.4.
Rules Related to the Maxim of Possibility The third maxim proposed was the Maxim of Possibility: one should only initiate actions that one expects to be possible.
This means that a speech act should only be initiated when: 1.
P1 has the appropriate authority or permission for the speech act; and 2.
it appears likely that the specific preconditions associated with the action's method can be satisfied.
Only the second case, preconditions, will be considered here.
The ISA forms derived from the first case all seem to belong to a class that Fraser has called hedged performatives, and which are well accounted for in \[11\].
The approach taken for ISAs based on preconditions will be to distinguish three classes of precondition and formulate six rules using the classes distinguished.
The classes will be based on the betterknowledge principle from the beginning of this section, specialized in terms of preconditions.
The classes of precondition are as follows: 1.
Pl-based preconditions Here P1 has inherently better knowledge of whether or not the topic of the precondition holds.
The topic of preconditions that begin here with "P1 believes that P2" is considered to be the direct object of the initial "believe," i.e., the rest of the precondition.
For other preconditions, the topic is the entire pattern.
Preconditions that are Pl-based represent intentional states of P1, i.e., beliefs, intentions, wants, desires, and degrees of willingness.
An example is request I, P1 wants P2 to take responsibility for carrying out the action.
2. P2-based preconditions Here P2 has inherently better knowledge of whether or not the topic of the precondition holds.
Preconditions that fit this category include Pl's beliefs about P2's intentional states.
6 An
example of a P2-based precondition is request III, P1 believes that P2 is willing to take responsibility for carrying out the action.
3. Unmarked preconditions For these preconditions, determination of which participant has better knowledge of the precondition depends on properties of the context or its particular speech act.
Examples are request II and IV.
Using these precondition types, we can construct the following six rules for ISA forms.
P1 can convey a speech act indirectly by -Rule P1-ASSERT: -asserting a Pl-based precondition of the speech act; e.g., "I want you to water the plants".
(request I) "I hope you will use common sense".
(request I) Rule P2-ASK: -an ask of the topic of a P2-based precondition of the speech act.
e.g., "Do you want to shut the door"?
(request III) Rule UNMARKED-ASK: -an ask of the topic of an unmarked precondition of the speech act.
This rule applies in a context where P1 believes P2 has better knowledge of the condition in the precondition topic.
e.g., "Is it your turn to do the dishes"?
(request IV) 6 An exception is the degree of knowledge of facts, which will be classified as an Unmarked condition.
There are cases in which P1 is assumed to have better knowledge about what P2 knows or does not know than P2.
Such an assumption underlies the use of the form "You don't know <fact>" as a way to state the fact.
156 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 Gretchen P.
Brown Characterizing Indirect Speech Acts Rule UNMARKED-ASSERT: -asserting the topic of an unmarked precondition of the speech act.
This rule applies in a context where P1 believes P1 has better knowledge of the condition in the precondition topic.
e.g., "It's your turn to do the dishes".
(request IV) Rule COMPOSITE-REQUEST: -a request form of an action that is a goal of P1.
This rule is applicable only when the speech act has preconditions that are exact matches or specializations of the four preconditions of request.
e.g., "Take a cookie".
(offer IV-VII, in Appendix) Rule COMPOSITE-ASK: -an ask about whether P2 will take responsibility for carrying out an action that is a goal of P1.
This rule is applicable only when the speech act has preconditions that are exact matches or specializations of the four preconditions of request.
e.g., "Will you accept a ride to the airport"?
(offer IV-VII, in Appendix) The rules as written do not account for differences in tense and mood.
That is, the UNMARKED-ASK rule accounts for example 4.3 but not 4.4 and 4.5. 4.3 Are you able to drive Sarah to school? 4.4 Will you be able to drive Sarah to school? 4.5 Would you be able to drive Sarah to school?
Examples 4.4 and 4.5 can be handled as legitimate requests if we extend the rules to account for a wider range of tense and mood behavior.
See \[4\] for suggestions.
The "possibility" rules given also do not derive "not" forms, i.e. strategy-3 rules related to whether an action is impossible.
4.6 Shouldn't you shut the door? 4.7 Can't you shut the door?
Note, however, that the rules given can be used as patterns for producing rules that account for examples 4.6 and 4.7.
Any of the rules above that involve an ask have rule counterparts with not inserted after the ask.
7 In
terms of specific rules, UNMARKED-ASSERT may seem odd when applied to preconditions involving 7 This is a change from \[4\], where the "not" forms were seen as realizations of a different speech act, with different preconditions.
The "not" forms are now seen as requests with a particular set of connotations.
The motive for the change is to make the "possibility" rules consistent with the rules for the maxims of Necessity and Desirability by allowing the strategy of questioning whether a condition does not hold.
capability, producing indirect requests such as example 4.8. 4.8 You can open the door.
Such forms do occur, however, particularly in requests to children where there may be some question of the child's capability to perform the action requested.
COMPOSITE-REQUEST and COMPOSITE-ASK differ most from rules in previous theories because they are based on groups of preconditions.
The COMPOSITE-ASK rule is of special interest.
In Searle's scheme, the very common "Will you <action>"? form is derived from the propositional content condition of directives (the class that includes request).
This approach seems to produce the correct forms, but it is basically a structural account, without strong semantic motivation.
Instead, the approach taken here is to appeal to the Maxim of Possibility.
The appearance of the four request preconditions in a set of preconditions indicates an action that P1 wants done.
We can think of a speech act with this precondition subset as an act with a component request.
By using a "will" form to perform the speech act, e.g. the offer example 4.1, P1 is asking a question about how P2 will respond to the offer, i.e., whether the component request will have a satisfactory response.
When the speech act is itself a request, then the question in the "will" form is whether the speech act as a whole will have a satisfactory response.
The distinction between Pl-based, P2-based, and Unmarked preconditions is probably uncontroversial; the question is whether the categories should be given a primary place in the theory.
The reason that the better-knowledge split has been given a central place is that there is then a distinction between knowledge about a precondition that is independent of context (P1and P2-based) and that which is not (Unmarked).
Instead of deriving the invariant knowledge from first principles each time, it is "precompiled" into the rules.
This choice reflects an approach that will be discussed in Section 6.
4.5. The Scope of the Rules Starting with a general evaluation of the scope of the rules, note that they do not account for such phenomena as sarcasm, jokes, or failure to make standard choices (e.g., P1 makes an utterance and has not decided whether it is a question or a request for a nonverbal action).
Another phenomenon specific to speech acts that complicates theory building is what can be called force shift.
This occurs when one speech act form is used to "masquerade" as another.
For example, one may use a suggestion form such as "How about picking up the blocks now"? in an environment where authority and role relationships make it clear that the utterance is functioning as a command.
In American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 157 Gretchen P.
Brown Characterizing Indirect Speech Acts general, force shift seems to be used to give P1 the appearance of greater benevolence or to save face for P2.
What these phenomena have in common, I think, is their "second order" nature.
All can be seen as presupposing a set of rules and then deviating from them.
I expect these phenomena to be modelled by the mechanisms for rule application, not accounted for by individual rules alone.
Since such mechanisms could be expected to build on, and interact with, the "first order" rule application mechanism, these phenomena have been considered beyond the scope of the current investigation.
The rules in this section are proposed to hold for speech acts in general.
ISAs are not grounded solely in individual speech acts, as for Gordon and Lakoff, or even in types of speech acts as for Searle.
Instead, they are related to a broader view of rational action analogous to that expounded by Grice.
Speech acts, because they are actions, do have structural components that play an important part in the derivation of ISAs.
The driving force behind ISAs, however, is the process of goal formation, i.e. the process of deciding whether to adopt a speech act as a goal.
This process is reflected in the three maxims that were used as a conceptual organization for the presentation.
This emphasis on the goal formation process is closely related to the work of Allen, Cohen, and Perrault \[1,8,21\].
The similarities and differences between the two approaches are discussed in Section 6.
5. Relating Utterances to the General Rules The general ISA rules in the last section were illustrated with English sentences, but nothing has as yet been said about the correspondence between particular utterances and rules.
This section discusses in broad terms the nature of the correspondence, focusing on differences in complexity.
Because the topic is difficult to present in a neutral way, it will be approached from the point of view of language recognition, i.e., matching utterances against rules.
Much of what is said, however, is relevant for generation as well.
Note that discussion in this section is restricted to the issue of proposing correct matches; issues related to choosing between alternative interpretations of an utterance (i.e., alternative matches) are deliberately avoided.
(See, however, \[4\]).
5.1. Levels of Matching Complexity Any discussion of matching rests on a set of assumptions about the representations involved.
We briefly outline some of the assumptions made here, starting with a distinction between two levels of representation: surface and internal.
Each utterance is expected to have (at least) a surface representation and an internal representation.
Internal representations are also used for action structures, including preconditions, and for ISA rules and patterns.
Internal representations are organized in a knowledge base according to a semantic network formalism.
Surface representations closely reflect the surface form of an utterance, and only those distinctions forced by the parsing process are made.
Thus, noun group references not needed by the parser may remain unresolved (e.g., "I saw him").
Choices among systematically ambiguous relationships of constituents and choices among ambiguous word senses also need not be made unless they are forced.
ISA forms are preserved; e.g., "Can you close the door"? would have a surface representation that records its interrogative nature and that contains a surface item corresponding to "can".
An important implication of these attributes is that surface representation draws from a different vocabulary of semantic items than internal representation.
For example, the surface item "believe" used in representing "I believe you're fight" is related to, but is not the same as, the internal item "believe" that corresponds to the general idea-holding concept from Section 3.3.
Surface items do, however, have associated internal level definitions which specify the ways that they can be translated into internal level representations.
These definitions include various potential translations; context is typically called on in each individual case to choose among alternatives and to specify details.
The problem for ISA matching, then, is to relate the definitions of items in the surface representation of an ISA to ISA patterns.
The ISA patterns are produced by applying the general rules from the last section to the method representations of particular speech acts.
Matching will be discussed using as an example the pattern produced by applying rule UNMARKEDASK to request precondition II: P1 asks whether P2 can take responsibility for carrying out action A.
Consider, then, the following examples interpreted as indirect requests.
5.1 Can
you close the door? 5.2 Are you able to close the door? 5.3 Are you permitted to close the door? 5.4 Can you please close the door? 5.5 Will you be home in time to walk the dog? 5.6 Have you got a hammer to put up that hook? 5.7 Must you smoke? 5.8 Can you reach the salt? 5.9 It's cold in here.
158 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 Gretchen P.
Brown Characterizing Indirect Speech Acts Examples 5.1 to 5.3 can be handled by a set of general purpose matching rules that reflect hierarchical relationships in the knowledge base.
The "can" in example 5.1 matches can in the above ISA pattern, since we can expect surface "can" to have internal can as a major part of its associated definition.
(Other components in the definition might include the connotations of the lexical item).
Similarly, "are you able" in example 5.2 is an exact match, since we can also expect its associated definition to contain can as a component.
In example 5.3, "permitted" has may as a component in its definition, and in the knowledge base may is a specialization (i.e., subclass) of can.
The important point in these matches is that elements of internal level definitions of surface items are related to elements of ISA patterns via the hierarchical relationships of the knowledge base, i.e., via predefined classification links.
Thus, proposing the request interpretation for examples 5.1 to 5.3 involves relatively well understood knowledge base manipulations.
Example 5.4 is a typical utterance that is not accounted for by the ISA patterns given.
The problem is that example 5.4, a question according to its interrogative form, contains "please", a construct reserved for request and related speech acts.
Utterances of this form have been much-discussed in the literature (e.g.
Sadock \[22\], Searle \[25\], and Morgan \[20\]).
The question is whether this form has evolved to the point that it is "really" a request only, no longer also a question.
The interest is fueled by questions of the nature of meaning that are involved.
Because I am interested in focusing on generalizations possible about ISAs, these issues will be omitted from discussion here.
It is worth noting, however, that, whatever the ultimate theoretical disposition of these forms may be, they will probably have to be handled in a computational system by specialized patterns, to represent their unique properties.
One such representation scheme, closely related to Morgan's notion of short-circuited entailment, is given in \[4\].
The rest of the examples above, 5.5 through 5.9, can be related to the "can" request pattern in a regular fashion, but they require a richer set of matching relationships.
Example 5.5 is typical of examples for which proposing a match may turn out to involve arbitrarily complex inference.
To begin to account for example 5.5, we can posit some link between can in the ISA pattern and a representation for being in the appropriate spatial proximity to do an action.
This link may be hierarchical, or part of a definition related to the internal node can, or both.
This treatment does not, however, fully solve the problem exemplified by example 5.5.
There is still a good distance between the relationship of being at home with a dog and the idea of being in the fight range to perform the action of taking it for a walk.
The level of detail in the utterance is so much more specific than the level of detail in the pattern that we cannot expect a match by merely traversing precomputed links in a knowledge base.
Another difference between 5.5 and the previous examples is that the knowledge needed to propose the match may go beyond information conveyed by the utterance to information from the surrounding context.
Either of these two factors has the potential to turn the process of proposing interpretations for utterances such as example 5.5 into a full-blown inference process, with all the attendant difficulties in controlling the inference.
The rest of the examples can be expected to be more tractable, because we can take advantage of specialized links in the model of actions introduced in Section 3.
Example 5.6 makes a "can you" request by asking whether P2 has an assignment (the hammer) for the instrument semantic case of the action (putting up a hook).
Several different types of semantic cases can be queried in this way (see \[4\]); the structural model of actions supplies links between actions and their cases that can be traversed in this match.
For examples 5.7 to 5.9, we can again exploit the model of actions to propose matches.
The three examples may have request interpretations where the actions intended are, respectively, that P2 stop smoking, pass the salt, and close the window.
Note that none of the three examples describes these actions explicitly, and for that reason I have called utterances of this class implicit-action ISAs.
These three examples represent three classes of implicit-action ISAs, which differ in the complexity of the search needed to propose a match.
For example 5.7 there is essentially no search; the implicit action is merely that P2 stop or avoid the action named.
Example 5.8 names a prerequisite of the implicit salt passing action.
Recall from Section 3.1 that prerequisites are among the basic parts of methods.
Other components of actions, including semantic input cases, steps, and principal resuits, may also be used in implicit-action ISAs.
All of these are related to the action by the explicit links of the method representation.
Finally, example 5.9 alludes to the intended action by stating a basis for the action, i.e., a condition seen as sufficient to warrant the action.
"Basis for action" can be related to the structural links of methods (see \[4\]), but the relationship between the condition named in the utterance and the implicit action is relatively complex.
Implicitaction ISAs are discussed in more detail in \[5\].
We have, then, classes of utterances that obey relatively constrained matching relationships and classes that could involve an arbitrary inference process to propose interpretations.
In between is a set of utterances for which proposal of interpretations can utilize structural links within action representations.
Difficult problems of search and knowledge structuring remain American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 159 Gretchen P.
Brown Characterizing Indirect Speech Acts unsolved, but the links identified at least specify the types of paths that we can expect to see in matches of ISA patterns.
5.2. Embedded ISAs In the discussion of matching, the initial assumption was that matching of surface representations occurred against patterns produced by single applications of rules to speech act methods.
This assumption makes no provision for embedded forms.
Some evidence does exist for this approach.
For example, Sadock \[22\], in another context, observes that 5.10 is not a request for the hearer to move over, even though the similar form 5.11 is.
5.10 Tell me if you can move over.
5.11 Can you move over?
In terms of the rules presented in Section 4, a request interpretation for 5.10 could only come from an embedded rule application: the UNMARKED-ASK rule applied to request II, resulting in ask, then the COMPOSITE-REQUEST rule applied to four of the preconditions of ask (see the Appendix).
Forbidding such a double application effectively blocks a request interpretation, leaving only the information-seeking alternative.
This straightforward solution, augmented by various classes of exceptions, was adopted in \[4\].
The embedded examples that have accumulated since, however, are too numerous to be accounted for simply as exceptions.
Consider the following indirect requests: 5.12 I wonder if you can move over.
5.13 I believe it's your turn to do the dishes.
For 5.12, the internal level definition of wonder would include the following information: P1 wonder if <action or state> 1.
P1 wants to know if <action or state> 2.
P1 is speculating if <action or state> Example 5.12 is eharacterizable by applying rule P1ASSERT to ask I (P1 wants to know the answer to the question) after applying rule UNMARKED-ASK to request II.
Example 5.13 is eharacterizable by applying rule P1-ASSERT to state I (P1 believes X is a fact) after applying rule UNMARKED-ASSERT to request IV.
These examples, and others like them, seem to be best accounted for by politeness conditions.
8 In
particular, I suggest the following hypothesis: embedding of general ISA rules is permitted when it furthers the politeness intentions of P1, either to heighten polite8 "Politeness" is used here quite broadly to include not only observation of the conventions of etiquette, but also the expression of respect for the other participant and the expression only of emotions harmonious with the social expectations associated with the conversational environment.
ness or to lessen it.
These processes are referred to here as mitigation and aggravation, respectively.
(The terms are borrowed from Labov and Fanshel \[16\] but apply to a somewhat broader range of phenomena here).
Embeddings within rules that are unmarked for politeness are forbidden, as are embeddings where the rules involved have conflicting politeness markings.
Evidence for this hypothesis is found in comparing example 5.12 to 5.14: 5.14 I want to know if you can move over.
Example 5.14 is derivable from the same set of rules as 5.12, but 5.12 conveys a request force while 5.14 does not.
The reason for this, I suggest, is that the UNMARKED-ASK rule is a mitigator: questions, in general, promote politeness by giving P2 an opportunity to answer, allowing P2 to refuse to accept Pl's goals in uttering the speech act.
"I wonder" is similarly undemanding: the emphasis is more on the speculation process P1 is involved in than the "wanting to know" aspect.
In contrast, the "I want to know" in 5.14 works in the direction of aggravation.
A goal stated explicitly leaves P2 very little room to refuse P1 without doing so explicitly.
In narrowing P2's options, P1 has lowered the level of politeness.
Example 5.12, then, with both rule applications working in the direction of mitigation, is a permitted embedding.
Example 5.14, with one rule application producing mitigation and one aggravation, is blocked as an indirect request.
This approach can also be used to explain the block on embedding in example 5.10.
The COMPOSITEREQUEST rule realized with an imperative is not a mitigator, while the UNMARKED-ASK rule realized with a question is.
Thus, the indirect request interpretation is blocked.
The examples presented make a case for the use of politeness conditions to govern ISA rule embedding, but it must be emphasized that more work is needed.
Despite the work on politeness conditions, much of this area is not well understood.
(For three different perspectives on the implications of ISA choices, see Lakoff \[17\], Davison \[9\], and Ervin-Tripp \[10\]).
Conelusive proof or disproof of the hypothesis awaits an analysis of the implications of ISA choices at a level of detail and completeness that is not yet available.
6. Computational Implications This paper has characterized a significant number of ISA forms, with attention to representational issues.
As noted in the introduction, these are the only claims made, although the ultimate motivation of the work was not only computational but was directed by a particular computational philosophy of language recognition.
This philosophy will be described briefly here, with emphasis on the way that the theory presented fits into it.
Due to the number of issues involved, I 160 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 Gretchen P.
Brown Characterizing Indirect Speech Acts will again consider only ISA pattern identification, i.e. proposing the candidate matches for a particular utterance form.
Issues related to choosing between alternatives are discussed in \[4\], along with a framework for using dialogue context to aid in this choice.
The approach to ISA pattern identification suggested will be contrasted with two other computational approaches, that of Moore, Levin, and Mann \[18,19\] and Allen, Cohen, and Perrault \[1,8,21\].
We start with a summary of each approach.
The central structure in the process model of dialogue developed by Moore, Levin, and Mann is called the dialogue game.
Dialogue games are procedures that include steps for speech acts and their standard range of responses.
Indirect speech act forms are related to these larger structures according to the general principle that any utterance that can establish the parameters of a dialogue game can serve as an ISA.
For recognition, the correspondence between particular ISAs and parameters is done by applying rule-like transformations using partial match and plausible inference techniques.
Representations of utterances are placed in a pool of facts about the dialogue where correspondences are drawn by highly parallel "anarchic" control structures.
The second computational approach to ISAs, that of Allen et al., focuses on the speech act planning process.
Allen's work is most relevant here, because it deals in detail with ISA recognition.
Alien introduces the notion of an obstacle, a type of condition in the speech act planning process that provides the subject matter for many varieties of ISAs.
This approach appears to generate a more constrained set of possible ISA forms than the approach of Moore et al.and gives more basis for an explanation of the variety of forms.
To draw the correspondence between ISAs and speech act plans, Allen et al.propose a general inference process guided by heuristics such as the principle that inference stops when a non-obvious condition is proposed as the topic of the ISA.
These approaches and the one advocated here have in common the reliance on representation of actions to characteihze indirect speech acts.
Allen, Cohen, and Perrault view the speech act as an independent unit; Moore, Levin and Mann relate ISAs to larger units of activity that have speech act components and that are defined according to the goals achieved by the speech acts.
This difference between the approaches of Allen et al.and Moore et al.is, I think, primarily one of presentation rather than substance.
The approach advocated here is a combination of the two perspectives.
A complete system would need both the ability to handle the prototype speech act plus response sequences (called core dialogue methods in \[4\]) and the ability to treat speech acts as basic building blocks within other sequences.
By focusing on independent speech acts in this paper, I do not intend to rule out their incorporation within larger actions.
A more substantive difference among the approaches is the mechanism envisioned for drawing correspondences between individual ISAs and ISA patterns.
Both of the approaches summarized above are theoretical in a traditional sense, in that they posit one mechanism powerful enough to account for any utterance, i.e., a mechanism powerful enough to handle the most difficult case.
Coupled with the interest in maximizing power is the interest in maximizing simplicity; redundancy in the representation structure is not expected or exploited.
In contrast, the proposals in this paper are motivated by an "appropriate technology" view of ISA pattern identification.
From this perspective, ISA patterns are assumed to be particularly adapted to communication, so that identifying candidate ISA patterns is not typically a general problem solving process.
(I emphasize here pattern identification; choosing between the alternative candidates identified appears to be a more open-ended process).
Given these assumptions, the search is for a way to identify the most frequently used ISA forms simply, short of full-blown problem solving.
The solution could include a hierarchy of processing strategies, differentiated to handle different levels of complexity.
The descriptive model presented in the preceding sections relates to this philosophy on two counts: matching processes and the choice of levels of representation.
Each is considered in turn.
Section 5 described several different types of match between particular ISA representations and patterns: first, those matches using only predefined classification links in the knowledge base; second, those requiring evaluation of representations, possibly augmented by contextual information, to establish classification links; and, third, those using definition and method component links, again with or without the use of additional contextual information.
While these distinctions can be used to guide a general inference mechanism, they could also be used in the development of specialized matching strategies, to take advantage of properties of the representations and links involved.
Along with the use of specialized processors for ISA pattern identification can come the use of specialized, and to an extent redundant, representations.
This is most evident in the preceding pages in the distinction between using the goal formation process as a conceptual organization of ISAs (and, hence, to an extent as an explanation) versus its use as a direct basis for drawing correspondences with individual ISAs.
The ISA patterns assumed are at least three levels removed from any actual goal formation procedure: the use of maxims is an abstraction of the proceAmerican Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 161 Gretchen P.
Brown Characterizing Indirect Speech Acts dure; generalized rules are based on maxims; and then ISA patterns are produced by applying rules to individual speech acts.
This is in contrast to plan deduction of Allen et al., which uses only very general rules coupled with the representations of the plan deduction process.
Similarly, what was called the betterknowledge principle was "precompiled" into rules, rather than combined with more general rules by inference.
The thrust of the effort is to push ISA patterns to a level as close as possible to the representations of particular ISAs; in fact, in many cases this paper has not gone as far as possible, and I think, as ultimately desirable, in producing highly specific ISA patterns.
This representational style is expected to have three effects.
First, for many cases, it avoids problems inherent in general inference processes of controlling the direction of inference toward the "interesting" cases.
Second, the more specialized the patterns, the simpler the individual match processes, and the more forms can be handled by cheaper processes.
Third, the various ISA patterns give a natural place to associate information about idiomaticity and specialized information about implications of ISA choice.
Note that these various mechanisms and representations cannot be introduced arbitrarily.
To be effective, they must be chosen based on an understanding of the structure of indirect speech act classes, i.e. on an appropriate descriptive theory.
This brings us back to the original claims of the paper; it is hoped that the proposals made are a step toward such a theory.
Finally, it should be emphasized that the computational apparatus sketched here complements, rather than seeks to replace, a generalized problem solving mechanism for ISA pattern identification.
The hypothesis is that only a relatively small proportion of ISAs require the more general (and more expensive) mechanism.
It is possible that the use of redundant mechanisms and representations can lead to good computational solutions to the problem of modelling a large body of indirect speech acts.
Appendix. Indirect Forms for Sample Speech Acts • ask propositional content: some question performative: I ask you...
other direct form: <interrogative> e.g., Where's the mustard? principal intended effect: that P2 tell P1 the answer to the question in the propositional content Rule NECESSARY-ASSERT: I have to ask you where the mustard is.
Rule NECESSARY-ASK: Do I need to ask you where the mustard is?
Rule EQUI-ASK: Did I ask you where the mustard is?
Rule FUTURE-EFFECT-ASK: Do you intend to tell me where the mustard is?
Rule PAST-EFFECT-ASK: Did you tell me where the mustard is?
Rule DESIRABLE-ASSERT: I'll be able to finish these sandwiches if you tell me where the mustard is.
Rule DESIRABLE-ASK: Will you feel better if you tell me where the mustard is?
Rule UNDESIRABLE-ASK: Will you be angry if I ask you where the mustard is?
Precondition-Based Examples I.
P1 wants to know the answer to the question.
(Want here and in IV implies that P1 does not already know the answer.
The case where P1 does know and merely wants to know if P2 knows -and where P2 knows that P1 knows -is classed as another speech act.
Know is considered to be a restricted form of believe; while anything can be believed, only facts can be known.
For ask, the "fact" is that some proposition is the answer to the question).
Rule P1-ASSERT: I want to know where the mustard is.
II. P1 believes that P2 can tell the answer to the question.
(Tell is used here and below to mean "utter a representative"; see Searle \[26\]).
Rule UNMARKED-ASK: Can you tell me where the mustard is?
Rule UNMARKED-ASSERT: You can tell me where the mustard is.
III. P1 believes that P2 is willing to tell the answer to the question.
Rule P2-ASK: Would you be willing to tell me where the mustard is?
IV. P1 wants P2 to tell P1 the answer to the question.
Rule P1-ASSERT: I'd like you to tell me where the mustard is.
V. P1 believes that P2 has some obligation (a role obligation, authority obligation, or general obligation to be cooperative) to P1 to tell P1 the answer to the question.
Rule UNMARKED-ASK: ? Should you tell me where the mustard is?
(Although it is possible to construct contexts in which this form can be used, it seems to be only marginal.
Forms such as "Shouldn't you 162 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 Gretchen P.
Brown Characterizing Indirect Speech Acts tell me "...? and "Don't you think you should tell me"...? are far more common.
Perhaps this is because the "should" form is too neutral with respect to the obligation.
To the extent that the obligation is motivated by Pl's wants or needs, then P1 defines the obligation.
Even for other obligations, situations are scarce in which P1 can reasonably be presented as neutral about the existence of the obligation.
In most cases, to successfully carry out the speech act, P1 must use a form that conveys Pl's belief that the obligation exists).
Rule UNMARKED-ASSERT: You ought to tell me where the mustard is.
II-V together: Rule COMPOSITE-REQUEST: Tell me where the mustard is.
Rule COMPOSITE-ASK: Will you tell me where the mustard is? • state propositional content: some proposition that P1 believes to be open to confirmation against what P1 believes is commonly held to be reality (This is contrasted with opinions, e.g., judgments about tastes, which are assumed to be conveyed by a different type of speech act).
performative: I state that ...
other direct form: <declarative> e.g., Your candidate is a convicted felon.
principal intended effect: that P2 come to know the proposition at the same level of detail and certainty as P1 Rule NECESSARY-ASSERT: I have to tell you that your candidate is a convicted felon.
Rule NECESSARY-ASK: Do I need to tell you that your candidate is a convicted felon?
Rule EQUI-ASK: Has anybody told you that your candidate is a convicted felon?
Rule FUTURE-EFFECT-ASK: GAP (Once a fact is mentioned, inquiry about future knowledge of that fact is irrelevant.
This rules out forms such as "Will you hear that"...? and "Will you know that ")...?
Rule PAST-EFFECT-ASK: Did you hear that your candidate is a convicted felon?
Rule DESIRABLE-ASSERT: It's important that you hear that your candidate is a convicted felon.
Rule DESIRABLE-ASK: ? Is it helpful for you to hear that your candidate is a convicted felon?
(The stative form "Is it helpful for you to know that"...? is much more acceptable.
This form would be derived using DESIRABLE-ASK and an implicit-action rule.
See Section 5 for general discussion).
Rule UNDESIRABLE-ASK: Will you be angry if I tell you that your candidate is a convicted felon?
Precondition-Based Examples I.
P1 believes that some proposition is a fact.
Rule P1-ASSERT: I think that your candidate is a convicted felon.
II. P1 believes that P2 does not know the proposition at the same level of detail and certainty that P 1 does.
(The mention of "level of detail" here is motivated by an interest in including statements which could otherwise be mistakenly classed as redundant.
For example, if P2 knows that it is raining, then the statement "It's raining" should be a violation of precondition II; a statement such as "It's pouring," however, should not).
Rule UNMARKED-ASK: Are you unaware that your candidate is a convicted felon?
Rule UNMARKED-ASSERT: You don't know that your candidate is a convicted felon.
III. P1 wants P2 to know the proposition at the same level of detail and certainty that P1 does.
Rule P1-ASSERT: I want you to know that your candidate is a convicted felon.
IV. P1 believes that it is in Pl's, P2's, or someone else's interest that P2 know the proposition at the same level of detail and certainty that P1 does.
Rule UNMARKED-ASK: Should you know that your candidate is a convicted felon?
Rule UNMARKED-ASSERT: You should know that your candidate is a convicted felon.
American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 163 Gretchen P.
Brown Characterizing Indirect Speech Acts • offer propositional content: some action that P1 believes will be of benefit to P2 performative: I offer you ...
other direct form: none principal intended effect: that P2 accept Pl's commitment to take responsibility for the action in the propositional content Rule NECESSARY-ASSERT: ? I must offer you a ride to the airport.
(In general, necessity alone is not considered to be enough to motivate an offer, although in practice, of course, it may be the sole motivation.
The propositional content specification of offer includes the notion of benefit to P2, so P1 is expected to have the well-being of P2 in mind.
The statement of necessity alone clashes with this expected benevolence.
The only way that this example form could be used for a sincere offer is if must is used in the same way as in the polite offer cited by R.Lakoff, "You must have some cake").
Rule NECESSARY-ASK: ?Do I need to offer you a ride to the airport?
(Beyond the considerations noted for the NECESSARY-ASSERT example, this form seems to be marginal due to the conflict between its angry connotations and the level of politeness involved in an offer).
Rule EQUI-ASK: Has anybody offered you a ride to the airport?
Rule FUTURE-EFFECT-ASK: GAP (This gap is explained by the fact that the principal intended effect for offer can be brought about only by the speech act; there is no independent means of achieving it).
Rule PAST-EFFECT-ASK: Have you already accepted a ride to the airport?
Rule DESIRABLE-ASSERT: I'd feel a lot better if you'd accept a ride to the airport.
Rule DESIRABLE-ASK: ? Will you stop worrying if you accept a ride to the airport?
(An elaboration of this rule may be warranted, since a form that explicitly names the speech act is much more acceptable, e.g., "Will you stop worrying if I offer you a ride to the airport"?
It is not clear, however, exactly how to proceed, since comparable "explicit speech act" forms for request and suggest do not seem to exist).
Rule UNDESIRABLE-ASK: Will you be offended if I offer to loan you some money?
Precondition-Based Examples I.
P1 wants to take responsibility for the action.
Rule P1-ASSERT: I want to drive you to the airport.
II. P1 believes that P1 can take responsibility for Pl's part of the action.
Rule UNMARKED-ASK: Can I drive you to the airport?
Rule UNMARKED-ASSERT: I can drive you to the airport.
III. P1 is willing to take responsibility for Pl's part of the action.
Rule P1-ASSERT: I'm more than willing to drive you to the airport.
IV. P1 wants P2 to perform some action that complements Pl's part of the action.
(Examples of complementary actions would be physically taking food offered by a hostess or getting into a car and sitting in response to an offer of a ride from a friend.
A general way to refer to P2's performance of a complementary action in response to an offered action is to say that P2 accepted, e.g., "Jane thanked Paula and accepted the gift").
Rule P1-ASSERT: I want you to accept a ride to the airport.
V. P1 believes P2 can perform some action that complements Pl's part of the action.
Rule UNMARKED-ASK: Can you accept a ride to the airport?
Rule UNMARKED-ASSERT: You can accept a ride to the airport.
VI. P1 believes that P2 would be willing to perform some action that complements Pl's part of the action.
Rule P2-ASK: Would you be willing to accept a ride to the airport?
VII. P1 believes that P2 has an obligation (to "be cooperative") to P1 to perform some action that complements Pl's part of the action.
(It is generally in P2's interest to accept an offer, and so one of the obligations involved in accepting an offer is P2's obligation to further his or her own self interest.
Beyond, this, however, P2 has an obligation to help further P1 's goals by virtue of a general social obligation to be cooperative.
In accepting an offer, P2 is enhancing Pl's image as a benevolent person, Pl's satisfaction in giving, etc.
By accepting, then, P2 is furthering Pl's goals and being "cooperative").
Rule UNMARKED-ASK: ? Should you accept a ride to the airport?
(See discussion for ask V).
Rule UNMARKED-ASSERT: You must accept a ride to the airport.
164 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 Gretchen P.
Brown Characterizing Indirect Speech Acts VIII.
P1 believes that P2 has an obligation to P2 (by virtue of P2's own self-interest) to perform some action that complements Pl's part of the action.
Rule UNMARKED-ASK: ? That suitcase is heavy.
Should you let me drive you to the airport?
(See discussion for ask V).
Rule UNMARKED-ASSERT: That suitcase is heavy.
You should let me drive you to the airport.
IV-VII together: Rule COMPOSITE-REQUEST: Please accept a ride to the airport.
Rule COMPOSITE-ASK: Will you accept a ride to the airport? • suggest propositional content: an action except for: actions in which P1 and P2 share common agency (In excluding actions where P1 and P2 share common agency, I am merely arguing for a separate type of speech act, e.g., suggest-common-action, to cover such cases).
performative: I suggest ...
other direct forms: 1.
What about <action>? e.g., What about joining the Marines? 2.
How about <action>? e.g., How about joining the Marines? principal intended effect: that P2 consider taking responsibility for the action in the propositional content.
Rule NECESSARY-ASSERT: I must suggest that you join the Marines.
Rule NECESSARY-ASK: Need I suggest that you join the Marines?
Rule EQUI-ASK: Has anyone suggested that you join the Marines?
Rule FUTURE-EFFECT-ASK: Are you thinking about joining the Marines?
Rule PAST-EFFECT-ASK: Have you considered joining the Marines?
Rule DESIRABLE-ASSERT: I'd be pleased if you'd consider joining the Marines.
Rule DESIRABLE-ASK: Would your parents be happy if you considered joining the Marines?
Rule UNDESIRABLE-ASK: Would you be offended if I suggested that you join the Marines?
Precondition-Based Examples I.
P1 wants P2 to consider taking responsibility for the action.
Rule P1-ASSERT: I want you to think about joining the Marines.
II. P1 believes that P2 can consider taking responsibility for the action.
Rule UNMARKED-ASK: Could you think about joining the Marines?
Rule UNMARKED-ASSERT: You could think about joining the Marines.
III. P1 believes that P2 is willing to consider taking responsibility for the action.
Rule P2-ASK: Are you willing to consider joining the Marines?
IV. P1 believes that P2 has an obligation (to "be cooperative") to P1 to consider the action.
(The "be cooperative" obligation is similar to that for offer VII.
The obligation arises from the fact that a goal of P1 is involved in a suggest, via precondition I).
Rule UNMARKED-ASK: ? Should you think about joining the Marines?
(See discussion for ask V).
Rule UNMARKED-ASSERT: You must think about joining the Marines.
V. P1 believes that P2 can take responsibility for the action.
Rule UNMARKED-ASK: Can you join the Marines?
Rule UNMARKED-ASSERT: You can join the Marines.
VI. P1 believes that P2 is willing to take responsibility for the action.
Rule P2-ASK: Are you willing to join the Marines?
VII. P1 believes that there are some reasons why the action is desirable.
Rule UNMARKED-ASK: Would it be good for you to join the Marines?
Rule UNMARKED-ASSERT: You'd be a credit to your sorority if you joined the Marines.
American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 165 Gretchen P.
Brown Characterizing Indirect Speech Acts VIII.
P1 believes that P2 has an obligation to P2 (by virtue of P2's own self-interest) to consider taking responsibility for the action.
Rule UNMARKED-ASK: You need a new experience.
Should you join the Marines?
Rule UNMARKED-ASSERT: You need a new experience.
You should join the Marines.
I-IV together: Rule COMPOSITE-REQUEST: Think about joining the Marines.
Rule COMPOSITE-ASK: Will you consider joining the Marines?
Acknowledgements This paper builds on work in knowledge representation done by William A.
Martin and members of the Knowledge Based Systems Group at the M.I.T.
Laboratory for Computer Science.
I am also grateful to William Mark, Candace Sidner, Peter Szolovits, James Weiner, and the referees for many helpful comments.
Special thanks to Michael McCord and George Heidorn for substantial contributions to the presentation.
References 1.
Allen, J.
"A Plan-Based Approach to Speech Act Recognition," Technical Report No.
131/79 (February 1979), Department of Computer Science, University of Toronto, Toronto, Canada.
2. Austin, J.L.
How to Do Things with Words, Oxford University Press, New York, 1962.
3. Brown, G.P.
"A Framework for Processing Dialogue," LCS TR-182 (June 1977), Laboratory for Computer Science, M.I.T., Cambridge, MA.
4. Brown, G.P.
"Toward a Computational Theory of Indirect Speech Acts," LCS TR-223 (September 1979), Laboratory for Computer Science, M.I.T.
Cambridge, MA.
5. Brown, G.P.
"Action Descriptions in Indirect Speech Acts," Cognition and Brain Theory, Vol.
3, No.
3, Spring 1980.
6. Brown, G.P.
"Linguistic and Situational Context in a Model of Task-Oriented Dialogue," to appear in Vaina and Hintikka (eds.): Cognitive Constraints on Communication Representations and Processes, D.
Reidel, Dortrecht, Holland.
7. Bruce, B.C.
"Belief Systems and Language Understanding," BBN Report No.
2973 (January 1975), Bolt, Beranek and Newman, Inc., Cambridge, MA.
8. Cohen, P.R.
"On Knowing What to Say: Planning Speech Acts," Technical Report No.
118 (January 1978), Department of Computer Science, University of Toronto, Toronto, Canada.
9. Davison A.
"Indirect Speech Acts and What to Do With Them," in: Cole and Morgan (eds).
Syntax and Semantics, vol.
3, Academic Press, New York, 1975.
10. Ervin-Tripp, S.
"Wait for Me, Roller Skate," in: Ervin-Tripp and Mitchell-Kernan (eds).
Child Discourse, Academic Press, New York, 1977.
11. Fraser, B.
"Hedged Performatives," in: Cole and Morgan (eds).
Syntax and Semantics, vol.
3, Academic Press, New York, 1975.
12. Gordon, D.
and Lakoff, G.
"Conversational Postulates," in: Cole and Morgan (eds).
Syntax and Semantics, vol.
3, Academic Press, New York, 1975.
13. Grice, H.P.
"Logic and Conversation," in: Cole and Morgan (eds).
Syntax and Semantics, vol.
3, Academic Press, New York, 1975.
14. Grosz, B.
"The Representation and Use of Focus in a System for Understanding Dialogs," Proceedings of the Fifth International Joint Conference on Artificial Intelligence, Cambridge, Mass.
(August 1977).
15. Hawkinson, L.
"The Representation of Concepts in OWL," Advance Papers of the Fourth International Joint Conference on Artificial Intelligence, Tbilisi, Georgia, USSR (September 1975).
16. Labov, W.
and Fanshel, D.
Therapeutic Discourse, Academic Press, New York, 1977.
17. Lakoff, R.
"The Logic of Politeness; of, Minding Your p's and q's," Papers from the Ninth Regional Meeting of the Chicago Linguistic Society, Department of Linguistics, University of Chicago, Chicago IL.
18. Levin, J.A. and Moore, J.A.
"Dialogue Games: Metacommunication Structures for Natural Language Interaction," Cognitive Science, Vol.
1, No.
4, October 1977.
19. Moore, J.A., Levin, J.A, and Mann, W.C.
"A Goal-Oriented Model of Human Dialogue," American Journal of Computational Linguistics, Microfiche 67 (1977).
20. Morgan, J.L.
"Two Types of Convention in Indirect Speech Acts," in: Cole (ed).
Syntax and Semantics, vol.
9, Academic Press, New York, 1978.
21. Perrault, C.R., Allen, J.F., and Cohen P.R.
"Speech Acts as a Basis for Understanding Dialogue Coherence," Theoretical Issues in Natural Language Processing-2, University of Illinois at Urbana-Champaign, (July 1978).
22. Sadock, J.M.
Toward a Linguistic Theory of Speech Acts, Academic Press, New York, 1974.
23. Schank, R.
and Abelson, R.
Scripts, Plans, Goals, and Understanding, Lawrence Erlbaum Associates, Hillsdale, NJ 1977.
24. Searle, J.R.
Speech Acts, University Press, Cambridge, 1969.
25. Searle, J.R.
"Indirect Speech Acts," in: Cole and Morgan (eds).
Syntax and Semantics, vol.
3, Academic Press, New York, 1975.
26. Searle, J.R.
"A Taxonomy of Illocutionary Acts," in: Gunderson (ed.), Language, Mind, and Knowledge, University of Min• nesota Press, 1976.
27. Szolovits, P., Hawkinson, L., and Martin, W.A.
"An Overview of OWL, a Language for Knowledge Representation," Proceedings of the Workshop on Natural Language for Interaction with Data Bases, International Institute for Applied Systems Analysis, Laxenburg, Austria; also available as LCS-TM-86, (June 1977), Laboratory for Computer Science, M.I.T., Cambridge, MA.
28. Verschueren, J.
"The Analysis of Speech Act Verbs: Theoretical Preliminaries," (August 1977) Indiana University Linguistics Club, Bloomington, IN .

