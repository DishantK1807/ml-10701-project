Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 769–776
Manchester, August 2008
A Fully-Lexicalized Probabilistic Model
for Japanese Zero Anaphora Resolution
Ryohei Sasano∗
Graduate School of Information Science
and Technology, University of Tokyo
ryohei@nlp.kuee.kyoto-u.ac.jp
Daisuke Kawahara
National Institute of Information
and Communication Technology
dk@nict.go.jp
Sadao Kurohashi
Graduate School of Infomatics,
Kyoto University
kuro@i.kyoto-u.ac.jp
Abstract
This paper presents a probabilistic model
for Japanese zero anaphora resolution.
First, this model recognizes discourse en-
tities and links all mentions to them. Zero
pronouns are then detected by case struc-
ture analysis based on automatically con-
structed case frames. Their appropriate
antecedents are selected from the entities
with high salience scores, based on the
case frames and several preferences on
the relation between a zero pronoun and
an antecedent. Case structure and zero
anaphora relation are simultaneously de-
termined based on probabilistic evaluation
metrics.
1 Introduction
Anaphora resolution is one of the most important
techniques in discourse analysis. In English, def-
inite noun phrases such as the company and overt
pronouns such as he are anaphors that refer to pre-
ceding entities (antecedents). On the other hand,
in Japanese, anaphors are often omitted and these
omissions are called zero pronouns. We focus
on zero anaphora resolution of Japanese web cor-
pus, in which anaphors are often omitted and zero
anaphora resolution plays an important role in dis-
course analysis.
Zero anaphora resolution can be divided into
two phases. The ﬁrst phase is zero pronoun detec-
tion and the second phase is zero pronoun resolu-
tion. Zero pronoun resolution is similar to coref-
c©2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
* Research Fellow of the Japan Society for the Promotion of
Science (JSPS)
erence resolution and pronoun resolution, which
have been studied for many years (e.g. Soon et
al.(2001); Mitkov(2002); Ng(2005)). Isozakiand
Hirao (2003) and Iida et al. (2006) focused on zero
pronoun resolution assuming perfect pre-detection
of zero pronouns. However, we consider that zero
pronoun detection and resolution have a tight rela-
tion and should not be handled independently. Our
proposed model aims not only to resolve zero pro-
nouns but to detect zero pronouns.
Zero pronouns are not expressed in a text and
have to be detected prior to identifying their an-
tecedents. Seki et al. (2002) proposed a proba-
bilistic model for zero pronoun detection and res-
olution that uses hand-crafted case frames. In
order to alleviate the sparseness of hand-crafted
case frames, Kawahara and Kurohashi (2004) in-
troduced wide-coverage case frames to zero pro-
noun detection that are automatically constructed
from a large corpus. They use the case frames as
selectional restriction for zero pronoun resolution,
but do not utilize the frequency of each example of
case slots. However, since the frequency is shown
to be a good clue for syntactic and case structure
analysis(KawaharaandKurohashi,2006),wecon-
sider the frequency also can beneﬁt zero pronoun
detection. Therefore we propose a probabilistic
model for zero anaphora resolution that fully uti-
lizes case frames. This model directly consid-
ers the frequency and estimates case assignments
for overt case components and antecedents of zero
pronoun simultaneously.
In addition, our model directly links each zero
pronoun to an entity, while most existing mod-
els link it to a certain mention of an entity. In
our model, mentions and zero pronouns are treated
similarly and all of them are linked to correspond-
ing entities. In this point, our model is similar to
769
Table 1: Examples of Constructed Case Frames.
case slot examples generalized examples with rate
ga (subjective) he, driver, friend, ··· [CT:PERSON]:0.45, [NE:PERSON]:0.08, · · ·tsumu (1)
wo (objective) baggage, luggage, hay, ··· [CT:ARTIFACT]:0.31, · · ·(load)
ni (dative) car, truck, vessel, seat, ··· [CT:VEHICLE]:0.32, · · ·
tsumu (2) ga (subjective) player, children, party, ··· [CT:PERSON]:0.40, [NE:PERSON]:0.12, · · ·
(accumulate) wo (objective) experience, knowledge, ··· [CT:ABSTRACT]:0.47, · · ·
...
...
...
ga (subjective) company, Microsoft, ﬁrm, ··· [NE:ORGANIZATION]:0.16, [CT:ORGANIZATION]:0.13, · · ·
hanbai (1) wo (objective) goods, product, ticket, ··· [CT:ARTIFACT]:0.40, [CT:FOOD]:0.07, · · ·
(sell) ni (dative) customer, company, user, ··· [CT:PERSON]:0.28, · · ·
de (locative) shop, bookstore, site ··· [CT:FACILITY]:0.40, [CT:LOCATION]:0.39, · · ·
...
...
...
thecoreferencemodelproposedbyLuo(2007)and
that proposed by Yang et al. (2008). Due to this
characteristic, our model can utilize information
beyond a mention and easily consider salience (the
importance of an entity).
2 Construction
of Case Frames
Case frames describe what kinds of cases each
predicate has and what kinds of nouns can ﬁll
these case slots. We construct case frames from
a large raw corpus by using the method proposed
by Kawahara and Kurohashi (2002), and use them
for case structure analysis and zero anaphora res-
olution. This section shows how to construct the
case frames.
2.1 Basic
Method
After a large corpus is parsed by a Japanese parser,
case frames are constructed from modiﬁer-head
examples in the resulting parses. The problems of
case frame construction are syntactic and seman-
tic ambiguities. That is to say, the parsing results
inevitably contain errors and predicate senses are
intrinsically ambiguous. To cope with these prob-
lems, case frames are gradually constructed from
reliable modiﬁer-head examples.
First, modiﬁer-head examples that have no syn-
tactic ambiguity are extracted, and they are disam-
biguated by coupling a predicate and its closest
case component. Such couples are explicitly ex-
pressed on the surface of text, and can be consid-
ered to play an important role in sentence mean-
ings. For instance, examples are distinguished not
by predicates (e.g., “tsumu (load/accumulate))”,
but by couples (e.g., “nimotsu-wo tsumu (load bag-
gage)” and “keiken-wo tsumu (accumulate experi-
ence))”. Modiﬁer-headexamplesareaggregatedin
this way, and yield basic case frames.
Thereafter, the basic case frames are clustered
to merge similar case frames. For example, since
“nimotsu-wo tsumu (load baggage)” and “busshi-
wo tsumu (load supplies)” are similar, they are
clustered. The similarity is measured using a
thesaurus (The National Language Institute for
JapaneseLanguage, 2004). Usingthisgradualpro-
cedure, we constructed case frames from approx-
imately 1.6 billion sentences extracted from the
web. In Table 1, some examples of the resulting
case frames are shown.
2.2 Generalization
of Examples
By using case frames that are automatically con-
structed from a large corpus, sparseness problem
is alleviated to some extent, but still remains. For
instance, there are thousands of named entities
(NEs), which cannot be covered intrinsically. To
deal with this sparseness problem, we general-
ize the examples of case slots. Kawahara and
Kurohashi also give generalized examples such
as “agent” but only a few types. We generalize
case slot examples based on categories of common
nouns and NE classes.
First, we use the categories that Japanese mor-
phological analyzer JUMAN1 adds to common
nouns. InJUMAN,abouttwentycategoriesarede-
ﬁned and tagged to common nouns. For example,
“ringo (apple),” “inu (dog)” and “byoin (hospi-
tal)” are tagged as “FOOD,” “ANIMAL” and “FA-
CILITY,” respectively. For each category, we cal-
culate the rate of categorized example among all
case slot examples, and add it to the case slot as
“[CT:FOOD]:0.07.”
We also generalize NEs. We use a common
standard NE deﬁnition for Japanese provided by
IREX workshop (1999). IREX deﬁned eight NE
classes as shown in Table 2. We ﬁrst recognize
NEs in the source corpus by using an NE recog-
nizer (Sasano and Kurohashi, 2008), and then con-
struct case frames from the NE-recognized corpus.
1http://nlp.kuee.kyoto-u.ac.jp/nl-resource/juman.html
770
Table 2: Deﬁnition of NE in IREX.
NE class Examples
ORGANIZATION NHK Symphony Orchestra
PERSON Kawasaki Kenjiro
LOCATION Rome, Sinuiju
ARTIFACT Nobel Prize
DATE July 17, April this year
TIME twelve o’clock noon
MONEY sixty thousand dollars
PERCENT 20%, thirty percents
As well as categories, for each NE class, we calcu-
late the NE rate among all case slot examples, and
add it to the case slot as “[NE:PERSON]:0.12.”
The generalized examples are also included in
Table1. Thisinformationisutilizedtoestimatethe
case assignment probability, which will be men-
tioned in Section 3.2.3.
3 Zero
Anaphora Resolution Model
In this section, we propose a probabilistic model
for Japanese zero anaphora resolution.
3.1 Overview
The outline of our model is as follows:
1. Parse an input text using the Japanese parser
KNP2 and recognize NEs.
2. Conduct coreference resolution and link each
mention to an entity or create new entity.
3. For each sentence, from the end of the sen-
tence, analyze each predicate by the follow-
ing steps:
(a) Select a case frame temporarily.
(b) Consider all possible correspondence
between each input case component and
an case slot of the selected case frame.
(c) Regard case slots that have no corre-
spondence as zero pronoun candidates.
(d) Consider all possible correspondence
between each zero pronoun candidate
and an existing entity.
(e) For each possible case frame, estimate
each correspondence probabilistically,
and select the most likely case frame and
correspondence.
In this paper, we concentrate on three case slots
for zero anaphora resolution: “ga (subjective),”
“wo (objective)” and “ni (dative),” which cover
about 90% of zero anaphora.
2http://nlp.kuee.kyoto-u.ac.jp/nl-resource/knp.html
Morphological analysis, NE recognition, syn-
tactic analysis and coreference resolution are con-
ducted as pre-processes for zero anaphora resolu-
tion. Therefore, the model has already recognized
existing entities before zero anaphora resolution.
For example, let us consider the following text:
(i) Toyota-wa 1997-nen hybrid car Prius-wo
hatsubai(launch). 2000-nen-karaha kaigai
(overseas)-demo hanbai(sell)-shiteiru.
(Toyota launched the hybrid car Prius in 1997. φ1
started selling φ2 overseas in 2000.)
Figure 1 shows the analysis process for this text.
There are three mentions3 in the ﬁrst sentence, and
the two mentions, hybrid car and Prius, appear in
apposition. Thus, after the pre-processes, two enti-
ties, {Toyota}and{hybrid-car, Prius}, are created.
Then, case structure analysis for the predicate
hatsubai (launch) is conducted. First, one of the
case frames of hatsubai (launch) is temporarily se-
lected and each input case component is assigned
to an appropriate case slot. For instance, case com-
ponent Toyota is assigned to ga case slot and Prius
is assigned to wo case slot4. In this case, though
there is a mention hybrid-car that is not a case
component of hatsubai (launch) by itself, it refers
to the same entity as Prius refers. Thus, there is no
entity that is not linked to hatsubai (launch), and
no further analysis is conducted.
Now, let us consider the second sentence. A
mention kaigai (overseas)appearsandanewentity
{kaigai} is created. Then, case structure analysis
for the predicate hanbai (sell) is conducted. There
is only one overt case component kaigai (over-
seas), and it is assigned to a case slot of the se-
lected case frame of hanbai (sell). For instance,
the case frame hanbai(1) in Table 1 is selected and
kaigai (overseas) is assigned to de (locative) case
slot. In this case, the remaining case slots ga, wo
and ni are considered as zero pronouns, and all
possible correspondences between zero pronouns
and remaining entities are considered. As a result
of probabilistic estimation, the entity {Toyota} is
assigned to ga case, the entity {hybrid-car, Prius}
is assigned to wo case and no entity is assigned to
ni case.
Now, we show how to estimate the correspon-
dence probabilistically in the next subsection.
3In this paper, we do not consider time expressions, such
as 1997, as mentions.
4Notethatsincetherearesomenoncase-makingpostposi-
tions in Japanese, such as “wa” and “mo,” several correspon-
dences can be considered.
771
Toyota-wa
Prius-wo
hybrid car
hatsubai.
kaigai-demo
hanbai-shiteiru.
1997-nen
2000-nen-karawa
{Toyota, Φg17137}
{hybrid car, 
Prius, Φ2 }
{kaigai}
Entities
(overseas)
(launch)
(sell)
hatsubai(launch)
ga
subjective
company, SONY, firm, … 
[NE:ORGANIZATION] 0.15, …
wo
objective
product, CD, model, car,  …
[CT:ARTIFACT] 0.40, …
de      
locative
area, shop, world, Japan, …
[CT:FACILITY] 0.13, …
hanbai(sell)
ga
subjective
company, Microsoft, … 
[NE:ORGANIZATION] 0.16, …
wo     
objective
goods, product, ticket, … 
[CT:ARTIFACT] 0.40, …
ni
dative
customer, company, user, … 
[CT:PERSON] 0.28, …
de      
locative
shop, bookstore, site, … 
[CT:FACILITY] 0.40, …
:direct case assignment
:indirect case assignment (zero anaphora)
Case framesInput sentences
Toyota launched the hybrid car Prius in 1997. Φg17137started selling Φ2overseas in 2000.
Figure 1: An Example of Case Assignment CAk.
3.2 Probabilistic
Model
The proposed model gives a probability to each
possible case frame CF and case assignment CA
when target predicate v, input case components
ICC and existing entities ENT are given. It also
outputs the case frame and case assignment that
have the highest probability. That is to say, our
model selects the case frame CFbest and the case
assignment CAbest that maximize the probability
P(CF,CA|v,ICC,ENT):
(CFbest,CAbest)
=argmax
CF,CA
P(CF,CA|v,ICC,ENT) (1)
Though case assignment CA usually represents
correspondences between input case components
and case slots, in our model it also represents
correspondences between antecedents of zero pro-
nouns and case slots. Hereafter, we call the former
direct case assignment (DCA) and the latter indi-
rect case assignment (ICA). Then, we transform
P(CFl,CAk|v,ICC,ENT) as follows:
P(CFl,CAk|v,ICC,ENT)
=P(CFl|v,ICC,ENT)
× P(DCAk|v,ICC,ENT,CFl)
× P(ICAk|v,ICC,ENT,CFl,DCAk)
≈P(CFl|v,ICC) × P(DCAk|ICC,CFl)
× P(ICAk|ENT,CFl,DCAk) (2)
=P(CFl|v)×P(DCAk,ICC|CFl)/P(ICC|v)
× P(ICAk|ENT,CFl,DCAk) (3)
parenleftBig
∵ P(CFl|v,ICC) = P(CFl,ICC|v)P(ICC|v)
=P(ICC|CFl,v) · P(CFl|v)P(ICC|v)
=P(ICC|CFl) · P(CFl|v)P(ICC|v) ,
(∵ CFl contains the information about v.)
P(DCAk|ICC,CFl)
=P(DCAk,ICC|CFl)P(ICC|CF
l)
parenrightBig
Equation (2) is derived because we assume that
the case frame CFl and direct case assignment
DCAk are independent of existing entities ENT,
and indirect case assignment ICAk is independent
of input case components ICC.
Because P(ICC|v) is constant, we can say that
our model selects the case frame CFbest and the
direct case assignment DCAbest and indirect case
assignment ICAbest that maximize the probability
P(CF,DCA,ICA|v,ICC,ENT):
(CFbest,DCAbest,ICAbest) =
argmax
CF,DCA,ICA
parenleftBig
P(CF|v) × P(DCA,ICC|CF)
×P(ICA|ENT,CF,DCA)
parenrightBig
(4)
The probability P(CFl|v), called generative
probability of a case frame, is estimated from
case structure analysis of a large raw corpus. The
following subsections illustrate how to calculate
P(DCAk,ICC|CFl) and P(ICAk|ENT,CFl,
DCAk).
772
3.2.1 Generative
Probability of Direct Case
Assignment
For estimation of generative probability of di-
rect case assignment P(DCAk,ICC|CFl), we
follow Kawahara and Kurohashi’s (2006) method.
They decompose P(DCAk, ICC|CFl) into the
following product depending on whether a case
slot sj is ﬁlled with an input case component or
vacant:
P(DCAk,ICC|CFl) =∏
sj:A(sj)=1
P(A(sj) = 1,nj,cj|CFl,sj)
×
∏
sj:A(sj)=0
P(A(sj) = 0|CFl,sj)
=
∏
sj:A(sj)=1
{
P(A(sj) = 1|CFl,sj)
× P(nj,cj|CFl,sj,A(sj) = 1)
}
×
∏
sj:A(sj)=0
P(A(sj) = 0|CFl,sj) (5)
where the function A(sj) returns 1 if a case slot sj
is ﬁlled with an input case component; otherwise
0, nj denotes the content part of the case compo-
nent, and cj denotes the surface case of the case
component.
The probabilities P(A(sj) = 1|CFl,sj) and
P(A(sj) = 0|CFl,sj) are called generative prob-
ability of a case slot, and estimated from case
structure analysis of a large raw corpus as well as
generative probability of a case frame.
The probability P(nj,cj|CFl,sj,A(sj) = 1) is
called generative probability of a case component
and estimated as follows:
P(nj,cj|CFl,sj,A(sj) = 1)
≈P(nj|CFl,sj,A(sj)=1)×P(cj|sj,A(sj)=1) (6)
P(nj|CFl,sj,A(sj) = 1) means the gener-
ative probability of a content part nj from a
case slot sj in a case frame CFl, and esti-
mated by using the frequency of a case slot
example in the automatically constructed case
frames. P(cj|sj,A(sj) = 1) is approximated by
P(cj|case type of(sj),A(sj)=1) and estimated
from the web corpus in which the relationship be-
tween a surface case marker and a case slot is an-
notated by hand.
3.2.2 Probability
of Indirect Case Assignment
To estimate probability of indirect case assign-
ment P(ICAk|ENT,CFl,DCAk) we also de-
compose it into the following product depending
Table 3: Location Classes of Antecedents.
intra-sentence: case components of
L1 : parent predicate of Vz
L2 : parent predicate of Vz” (parallel)
L3 : child predicate of Vz
L4 : child predicate of Vz (parallel)
L5 : parent predicate of parent noun phrase of Vz
L6 : parent predicate of parent predicate of Vz (parallel)
L7 : other noun phrases following Vz
L8 : other noun phrases preceding Vz
inter-sentence: noun phrases in
L9 : 1 sentence before
L10: 2 sentences before
L11: 3 sentences before
L12: more than 3 sentences before
on whether a case slot sj is ﬁlled with an entity
entj or vacant:
P(ICAk|ENT,CFl,DCAk) =
∏
sj:Aprime(sj)=1
P(Aprime(sj) = 1,entj|ENT,CFl,sj)
×
∏
sj:Aprime(sj)=0
P(Aprime(sj) = 0|ENT,CFl,sj) (7)
where the function Aprime(sj) returns 1 if a case slot
sj is ﬁlled with an entity entj; otherwise 0. Note
that we only consider case slots ga, wo and ni that
is not ﬁlled with an input case component. We
approximate P(Aprime(sj) = 1,entj|ENT,CFl,sj)
and P(Aprime(sj) = 0|ENT,CFl,sj) as follows:
P(Aprime(sj) = 1,entj|ENT,CFl,sj)
≈ P(Aprime(sj) = 1,entj|entj,CFl,sj)
= P(Aprime(sj) = 1|entj,CFl,sj) (8)
P(Aprime(sj) = 0|ENT,CFl,sj)
≈ P(Aprime(sj) = 0|case type of(sj)) (9)
Equation (8) is derived because we assume
P(Aprime(sj) = 1|CFl,sj) is independent of exist-
ing entities that are not assigned to sj. Equation
(9) is derived because we assume P(Aprime(sj) = 0)
is independent of ENT and CFl, and only de-
pends on the case type of sj, such as ga, wo and ni.
P(Aprime(sj)=0|case type of(sj)) is the probability
that a case slot has no correspondence after zero
anaphora resolution and estimated from anaphoric
relation tagged corpus.
Let us consider the probability P(Aprime(sj) =
1|entj,CFl,sj). We decompose entj into content
part njm, surface case cjn and location class ljn.
Here, location classes denote the locational rela-
tionsbetweenzeropronounsandtheirantecedents.
We deﬁned twelve location classes as described in
Table 3. In Table 3, Vz means a predicate that has
a zero pronoun. Note that we also consider the
773
locations of zero pronouns that are linked to the
target entity as location class candidates. Now we
roughly approximate P(Aprime(sj)=1|entj, CFl,sj)
as follows:
P(Aprime = 1|entj,CFl,sj)
=P(Aprime = 1|njm,cjn,ljn,CFl,sj)
=P(njm,cjn,ljn|CFl,sj,A
prime=1)·P(Aprime=1|CFl,sj)
P(njm,cjn,ljn|CFl,sj)
≈P(njm|CFl,sj,A
prime=1)
P(njm|CFl,sj) ·
P(cjn|CFl,sj,Aprime=1)
P(cjn|CFl,sj)
·P(ljn|CFl,sj,A
prime=1)
P(ljn|CFl,sj) ·P(A
prime=1|CFl,sj) (10)
≈P(njm|CFl,sj,A
prime=1)
P(njm)
× P(cjn|case type of(sj),A
prime=1)
P(cjn)
× P(Aprime=1|ljn,case type of(sj)) (11)
parenleftBig
∵ P(ljn|CFl,sj,A
prime=1)
P(ljn|CFl,sj) ·P(A
prime=1|CFl,sj)
= P(A
prime=1,lj
n|CFl,sj)
P(ljn|CFl,sj) =P(A
prime=1|CFl,lj
n,sj)
parenrightBig
Note that because entj is often mentioned more
than one time, there are several combinations of
content part njm, surface case cjn and location
class ljn candidates. We select the pair of m and n
with the highest probability.
Equation (10) is derived because we as-
sume njm, cjn and ljn are independent of each
other. Equation (11) is derived because we ap-
proximate P(Aprime = 1|CFl,ljn,sj) as P(Aprime =
1|ljn,case type of(sj)), and assume P(njm) and
P(cjn) are independent of CFl and sj. Since these
approximation is too rough, speciﬁcally, P(njm)
and P(cjn) tend to be somewhat smaller than
P(njm|CFl,sj) and P(cjn|CFl,sj) and equation
(11) often becomes too large, we introduce a
parameter α(≤1) and use the α-times value as
P(Aprime = 1|entj,CFl,sj).
The ﬁrst term of equation (11) represents how
likely an entity that contains njm as a content part
is considered to be an antecedent, the second term
represents how likely an entity that contains cjn as
a surface case is considered to be an antecedent,
and the third term gives the probability that an
entity that appears in location class ljn is an an-
tecedent.
The probabilities P(njm) and P(cjn) are esti-
mated from a large raw corpus. The probabili-
ties P(cjn|case type of(sj)) and P(Aprime = 1|ljn,
case type of(sj)) are estimated from the web
corpus in which the relationship between an an-
tecedent of a zero pronoun and a case slot, and the
relationship between its surface case marker and a
case slot are annotated by hand. Then, let us con-
sider the probability P(njm|CFl,sj,Aprime(sj) = 1)
in the next subsection.
3.2.3 Probability
of Component Part of Zero
Pronoun
P(njm|CFl,sj,Aprime=1) is similar to P(nj|CFl,
sj,A=1)andcanbeestimatedapproximatelyfrom
case frames using the frequencies of case slot ex-
amples. However, while Aprime(sj) = 1 means sj is
not ﬁlled with input case component but ﬁlled with
an entity as the result of zero anaphora resolution,
case frames are constructed by extracting only the
input case component. Therefore, the content part
of a zero anaphora antecedent njm is often not in-
cluded in the case slot examples. To cope with this
problem, we utilize generalized examples.
When one mention of an entity is tagged any
category or recognized as an NE, we also use the
category or the NE class as the content part of the
entity. For examples, if an entity {Prius} is recog-
nized as an artifact name and assigned to wo case
of the case frame hanbai(1) in Table 1, the system
also calculates:
P(NE:ARTIFACT|hanbai(1),wo,Aprime(wo)=1)
P(NE:ARTIFACT)
besides:
P(Prius|hanbai(1),wo,Aprime(wo) = 1)
P(Prius)
and uses the higher value.
3.3 Salience
Score
Previous works reported the usefulness of salience
for anaphora resolution (Lappin and Leass, 1994;
Mitkov et al., 2002). In order to consider salience
of an entity, we introduce salience score, which is
calculated by the following set of simple rules:
• +2 : mentioned with topical marker “wa”.
• +1 : mentioned without topical marker “wa”.
• +0.5 : assigned to a zero pronoun.
• ×0.7 : beginning of each sentence.
For examples, we consider the salience score of
the entity {Toyota} in (i) in Section 3.1. In the
ﬁrst sentence, since {Toyota} is mentioned with
topical marker “wa”, the salience score is 2. At the
beginning of the second sentence it becomes 1.4,
774
Table 4: Data for Parameter Estimation.
probability data
P(nj) raw corpus
P(cj) raw corpus
P(cj|case type of(sj),A(sj)=1) tagged corpus
P(cj|case type of(sj),Aprime(sj)=1) tagged corpus
P(nj|CFl,sj,A(sj)=1) case frames
P(nj|CFl,sj,Aprime(sj)=1) case frames
P(CFl|vi) case structure analysis
P(A(sj)={0,1}|CFl,sj) case structure analysis
P(Aprime(sj)=0|case type of(sj)) tagged corpus
P(Aprime(sj)=1|lj,case type of(sj)) tagged corpus
Table 5: Experimental Results.
R P F
Kawahara & Kurohashi .230 (28/122) .173 (28/162) .197
Proposed (α = 1) .426 (52/122) .271 (52/192) .331
(α = 1/2) .410 (50/122) .373 (50/134) .391
(α = 1/4) .295 (36/122) .419 (36/86) .346
and after assigned to the zero pronoun of “hanbai”
it becomes 1.9. Note that we use the salience score
not as a probabilistic clue but as a ﬁlter to consider
thetargetentityasapossibleantecedent. Whenwe
usethesaliencescore,weonlyconsidertheentities
that have the salience score no less than 1.
4 Experiments
4.1 Setting
We created an anaphoric relation-tagged corpus
consisting of 186 web documents (979 sentences).
We selected 20 documents for test and used the
other 166 documents for calculating several proba-
bilities. Since the anaphoric relations in some web
documents were not so clear and too difﬁcult to
recognize, we did not select such documents for
test. In the 20 test documents, 122 zero anaphora
relations were tagged between one of the mentions
of the antecedent and the target predicate that had
the zero pronoun.
Each parameter for proposed model was esti-
mated using maximum likelihood from the data
described in Table 4. The case frames were auto-
maticallyconstructedfromwebcorpuscomprising
1.6 billion sentences. The case structure analysis
was conducted on 80 million sentences in the web
corpus, andP(nj)andP(cj)werecalculatedfrom
the same 80 million sentences.
In order to concentrate on zero anaphora resolu-
tion, we used the correct morphemes, named enti-
ties, syntactic structures and coreferential relations
thatwereannotatedbyhand. Sincecorrectcorefer-
ential relations were given, the number of created
entities was same between the gold standard and
the system output because zero anaphora resolu-
tion did not create new entities.
4.2 Experimental
Results
We conducted experiments of zero anaphora reso-
lution. As the parameter α introduced in Section
3.2.2., we tested 3 values 1, 1/2, and 1/4. For
comparison, we also tested Kawahara and Kuro-
hashi’s (2004) model. The experimental results are
shown in Table 5, in which recall R, precision P
and F-measure F were calculated by:
R = # of correctly recognized zero anaphora# of zero anaphora tagged in corpus ,
P = # of correctly recognized zero anaphora# of system outputted zero anaphora ,
F = 21/R + 1/P .
Kawahara and Kurohashi’s model achieved al-
most 50% as F-measure against newspaper arti-
cles. However, as a result of our experiment
against web documents, it achieved only about
20%asF-measure. Thismaybebecauseanaphoric
relations in web documents were not so clear as
those in newspaper articles and more difﬁcult to
recognize. As to the parameter α, the larger α
tended to output more zero anaphora, and the high-
est F-measure was achieved against α = 1/2.
When using α = 1/2, there were 72 (=122−50)
zero pronouns that were tagged in the corpus and
not resolved correctly. Only 12 of them were cor-
rectly detected and assigned to a wrong entity, that
is, 60 of them were not even detected. Therefore,
we can say our recall errors were mainly caused by
the low recall of zero pronoun detection.
In order to conﬁrm the effectiveness of gener-
alized examples of case slots and salience score,
we also conducted experiments under several con-
ditions. We set α = 1/2 in these experiments. The
results are shown in Table 6, in which CT means
generalizedcategories, NEmeansgeneralizedNEs
and SS means salience score.
Without using any generalized examples, the F-
measure is less than Kawahara and Kurohashi’s
method, which use similarity to deal with sparse-
ness of case slot examples, and we can con-
ﬁrm the effectiveness of the generalized examples.
While generalized categories much improved the
F-measure, generalized NEs contribute little. This
may be because the NE rate is smaller than com-
mon noun rate, and so the effect is limited.
We also conﬁrmed that the salience score ﬁlter
improved F-measure. Moreover, by using salience
score ﬁlter, the zero anaphora resolution becomes
about ten times faster. This is because the system
775
Table 6: Experiments under Several Conditions.
CT NE SS R P F√
.131 (16/122) .205 (16/78) .160√ √
.164 (20/122) .247 (20/81) .197√ √
.402 (49/122) .368 (49/133) .384√ √
.385 (47/122) .196 (47/240) .260√ √ √
.410 (50/122) .373 (50/134) .391
can avoid checking entities with low salience as
antecedent candidates.
4.3 Comparison
with Previous Works
We compare our accuracies with (Seki et al.,
2002). They achieved 48.9% in precision, 88.2%
in recall, and 62.9% in F-measure for zero pro-
noundetection, and54.0%accuracyforantecedent
estimation on 30 newspaper articles, that is, they
achieved about 34% in F-measure for whole zero
pronoun resolution. It is difﬁcult to directly com-
pare their results with ours due to the difference
of the corpus, but our method achieved 39% in
F-measure and we can conﬁrm that our model
achieves reasonable performance considering the
task difﬁculty.
5 Conclusion
In this paper, we proposed a probabilistic model
for Japanese zero anaphora resolution. By us-
ing automatically constructed wide-coverage case
frames that include generalized examples and in-
troducing salience score ﬁlter, our model achieves
reasonable performance against web corpus. As
future work, we plan to conduct large-scale ex-
periments and integrate this model to a fully-
lexicalized probabilistic model for Japanese syn-
tactic and case structure analysis (Kawahara and
Kurohashi, 2006).
References
Iida, Ryu, Kentaro Inui, and Yuji Matsumoto. 2006.
Exploiting syntactic patterns as clues in zero-
anaphora resolution. In Proceedings of COL-
ING/ACL 2006, pages 625–632.
IREX Committee, editor. 1999. Proc. of the IREX
Workshop.
Isozaki, Hideki and Tsutomu Hirao. 2003. Japanese
zero pronoun resolution based on ranking rules and
machine learning. In Proceedings of the Conference
on Empirical Methods in Natural Language Process-
ing (EMNLP), pages 184–191.
Kawahara, Daisuke and Sadao Kurohashi. 2002.
Fertilization of Case Frame Dictionary for Robust
Japanese Case Analysis. In Proceedings of the 19th
InternationalConferenceonComputationalLinguis-
tics, pages 425–431.
Kawahara, Daisuke and Sadao Kurohashi. 2004.
Zeropronounresolutionbasedonautomaticallycon-
structed case frames and structural preference of an-
tecedents. In Proceedings of the 1st International
Joint Conference on Natural Language Processing
(IJCNLP-04), pages 334–341.
Kawahara, Daisuke and Sadao Kurohashi. 2006. A
fully-lexicalized probabilistic model for japanese
syntactic and case structure analysis. In Proceedings
of the Human Language Technology Conference of
the NAACL, Main Conference, pages 176–183.
Lappin, Shalom and Herbert J. Leass. 1994. An algo-
rithm for pronominal anaphora resolution. Compu-
tational Linguistics, 20(4):535–562.
Luo, Xiaoqiang. 2007. Coreference or not: A
twin model for coreference resolution. In Human
Language Technologies 2007: The Conference of
the North American Chapter of the Association for
Computational Linguistics; Proceedings of the Main
Conference, pages 73–80.
Mitkov, Ruslan, RichardEvans, andConstantinOr˘asan.
2002. A new, fully automatic version of mitkov’s
knowledge-poor pronoun resolution method. In Pro-
ceedings of the Third International Conference on
Intelligent Text Processing and Computational Lin-
guistics (CICLing-2002).
Ng, Vincent. 2005. Machine learning for coreference
resolution: From local classiﬁcation to global rank-
ing. In Proceedings of the 43rd Annual Meeting
of the Asssociation for Computational Linguistics,
pages 157–164.
Sasano, Ryohei and Sadao Kurohashi. 2008. Japanese
namedentityrecognitionusingstructuralnaturallan-
guage processing. In Proceedings of the 3rd Interna-
tional Joint Conference on Natural Language Pro-
cessing (IJCNLP-08), pages 607–612.
Seki, Kazuhiro, Atsushi Fujii, and Tetsuya Ishikawa.
2002. AprobabilisticmethodforanalyzingJapanese
anaphora integrating zero pronoun detection and res-
olution. In Proceedings of the 19th International
Conference on Computational Linguistics, pages
911–917.
Soon, Wee Meng, Hwee Tou Ng, and Daniel
Chung Yong Lim. 2001. A machine learning ap-
proach to coreference resolution of noun phrases.
Computational Linguistics, 27(4):521–544.
The National Language Institute for Japanese Lan-
guage. 2004. Bunruigoihyo. Dainippon Tosho, (In
Japanese).
Yang, Xiaofeng, Jian Su, Jun Lang, Ghew Lim Tan,
Ting Liu, and Sheng Li. 2008. An entity-mention
modelforcoreferenceresolutionwithinductivelogic
programming. In Proceedings of ACL-08: HLT,
pages 843–851.
776

