Search As in our previous parser (Johansson and Nugues, 2006), we used a beam-search extension to Nivre’s original algorithm (which is greedy in its original formulation).
W06-2930
Method 2.1 Nivre’s Parser We used Nivre’s algorithm (Nivre et al., 2006), which is a variant of the shift–reduce parser.
W06-2933
The projectivization algorithm (Nivre and Nilsson, 2005) iteratively moves each nonprojective arc upward in the tree until the whole tree is projective.
P05-1013
To make better use of the training set, we applied the algorithm in both directions as Johansson and Nugues (2006) and Sagae and Lavie (2006) for all languages except Catalan and Hungarian.
N06-2033 W06-2930
The two best-performing systems in the CoNLL-X shared task (Buchholz and Marsi, 2006) can be classified along two lines depending on the method they used to train the parsing models.
W06-2920
The online methods on the other hand, although less theoretically appealing, can handle realistically sized data sets and have successfully been applied in dependency parsing (McDonald et al., 2006).
W06-2932
The approach of the top system (McDonald et al., 2006) was to fit the model to minimize cost over sentences, while the secondbest system (Nivre et al., 2006) trained the model to maximize performance over individual decisions in an incremental algorithm.
W06-2932 W06-2933
to SVM-based Local Classifiers We compared the performance of the parser with a parser based on local SVM classifiers (Johansson and Nugues, 2006).
W06-2930
