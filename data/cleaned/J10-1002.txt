AGraph-TheoreticFrameworkfor
SemanticDistance
VivianTsang
∗
UniversityofToronto
SuzanneStevenson
∗∗
UniversityofToronto
Many NLP applications entail that texts are classiﬁed based on their semantic distance (how
similar or different the texts are). For example, comparing the text of a new document to that of
documents of known topics can help identify the topic of the new text. Typically, a distributional
distance is used to capture the implicit semantic distance between two pieces of text. However,
suchapproachesdonottakeintoaccountthesemanticrelationsbetweenwords.Inthisarticle,we
introduceanalternativemethodofmeasuringthesemanticdistancebetweentextsthatintegrates
distributional information and ontological knowledge within a network ﬂow formalism. We ﬁrst
represent each text as a collection of frequency-weighted concepts within an ontology. We then
make use of a network ﬂow method which provides an efﬁcient way of explicitly measuring the
frequency-weighted ontological distance between the concepts across two texts. We evaluate our
methodinavarietyofNLPtasks,andﬁndthatitperformswellontwoofthreetasks.Wedevelop
a new measure of semantic coherence that enables us to account for the performance difference
across the three data sets, shedding light on the properties of a data set that lends itself well to
our method.
1.Introduction
Many natural language tasks can be cast as a problem of comparing texts in terms of
theirsemanticdistance.Forexample,givenasuitabletextdistancemeasure,document
classiﬁcationcanbeperformedbycomparingthetextofanewdocumenttothetextof
various documents whose topics are known. The new document is then labelled with
the topic of the document whose text is most similar to it. In general, the texts to be
comparedmaybefulldocuments,asinthisexample,ormaybeportionsofdocuments,
or even collections of documents. Using text comparison to perform semantic classiﬁ-
cationhasbeenadoptedinavarietyofnaturallanguageprocessing(NLP)tasks,from
document classiﬁcation (Scott and Matwin 1998; Rennie 2001; Al-Mubaid and Umair
2006), to prepositional phrase attachment (Pantel and Lin 2000), to spelling correction
(BudanitskyandHirst2001).
∗ DepartmentofComputerScience,UniversityofToronto,6King’sCollegeRoad,Toronto,OntarioM5S
3G4,Canada.E-mail:vyctsang@cs.toronto.edu.
∗∗ DepartmentofComputerScience,UniversityofToronto,6King’sCollegeRoad,Toronto,OntarioM5S
3G4,Canada.E-mail:suzanne@cs.toronto.edu.
Submissionreceived:16December2007;revisedsubmissionreceived:18June2008;acceptedforpublication:
20August2008.
©2010AssociationforComputationalLinguistics
ComputationalLinguistics Volume36,Number1
Distributionalmethodsforsemanticdistancearewidelyusedandhighlysuccessful
in comparing texts that are represented as bags of words with associated frequencies
of occurrence (Lee 2001; Weeds, Weir, and McCarthy 2004; Pedersen, Banerjee, and
Patwardhan2005).Indocumentclassiﬁcation,forexample,thetextofadocumentmay
be represented as a word frequency vector, which is compared using a distributional
distance measure to each of the word frequency vectors of the texts of the documents
ofknowntopics.Inthisway,distributionaldistancebetweenwordvectorscapturesthe
semanticdistancebetweentwotextsthatisimplicitlyencodedinthesetofwordsused
ineach.
Semantic distance can also be measured more explicitly, by using the relations in
anontologyasthedirectencodingofsemanticassociation.However,suchapproaches
have generally been limited to calculating the distance between two individual con-
cepts, rather than capturing the distance between two sets of concepts corresponding
to two texts. Numerous measures have been proposed, for example, for capturing
the distance between two concepts in WordNet, typically relying on the synonymy
(synset) and hyponymy (is-a) relations (Wu and Palmer 1994; Resnik 1995; Jiang and
Conrath1997,amongothers).Usingsuchanontologicalmeasuretocomparetwotexts
(collections of words instead of single words) might involve mapping each word of a
text to its appropriate concept(s) in the ontology, and then calculating the aggregate
distance between the two resulting sets of concepts across the ontological relations.
For example, one might calculate the semantic distance between the two texts as the
average,minimum,maximum,orsummedontologicaldistancebetweentheindividual
elementsofthetwosetsofconcepts(CorleyandMihalcea2005).
Observe that each of these approaches to text comparison—distributional and
ontological—encodes information not contained in the other. Distributional distance
capturesimportantinformationaboutfrequencyofoccurrenceofthewordsthatconsti-
tutethetargettext,whereasontologicaldistancecapturesessentialsemanticknowledge
that has been encoded in the relations of an ontology. In response, previous work has
attemptedtocombinedistributionalandontologicalinformationincomputingseman-
tic distance. For example, researchers have developed measures of semantic distance
betweentextsthatapplydistributionaldistancestoconceptvectorsoffrequenciesrather
thantowordvectors(McCarthy2000;MohammadandHirst2006).However,theseap-
proachesonlymakepairwisecomparisionsbetweentheelementsoftheconceptvectors,
anddonottakeintoaccounttheimportantontologicalrelationsamongtheconcepts.In
order to capture such relations, other methods have instead integrated distributional
information into an ontological method. However, such approaches have heretofore
been limited to measuring distance between two individual concepts. For example,
some ontological measures use corpus frequencies of words to yield concept weights
that are taken into account in measuring the distance between two concepts (Resnik
1995; Jiang and Conrath 1997). What has been missing is an approach to semantic
distancebetweentwotexts—twosetsofwords—thatcantrulyintegratedistributional
and ontological (relational) information, drawing more fully on their complementary
advantagesfortextcomparison.
In this article, we describe a new graph-based distance measure that achieves the
desired integration of distributional and ontological factors in measuring semantic
distancebetweentwosetsofconcepts(mappedfromtwotexts).Anontologyistreated
as a graph in the usual manner, in which the concepts are nodes and the relations are
edges. A text is represented as a subgraph of the ontology, by mapping the words in
the text into their corresponding concepts, which are weighted according to the word
frequencies.Wecalltheresultingsetoffrequency-weightedconceptsa semantic proﬁle.
32
TsangandStevenson AGraph-TheoreticFrameworkforSemanticDistance
By exploiting the relational structure of the ontology, we can explicitly measure the
ontologicaldistanceoverthepathsbetweentwoproﬁles.Usingthefrequenciesonthe
conceptnodes,weweightthesepathsaccordingtothefrequencydistributionofwords
in the two texts. The resulting calculation yields a frequency-weighted ontological
distancebetweenthetwosetsofconcepts.Thus,weviewatextnotasasetofitemsto
becomparedindividuallytothoseinanotherset(withthoseindividualdistancesthen
somehowcombined,e.g.,asinCorleyandMihalcea[2005]),butratherasadistribution
of “mass” within a graph that encodes the semantic relations across the two sets, and
useaweightedgraph-basedapproachthatcapturestheaggregatedistancebetweenthe
twofrequencymasses.
Toourknowledge,thisistheﬁrstmethodtointegrateontologicalanddistributional
information in the graphical calculation of text distance. This article describes the use
ofthenewmeasureinseveraldifferenttypesofNLPtextcomparisontasks,inorderto
explore the situations in which such an approach can be effective. Given the novelty
of the approach, the task-based evaluation is not intended as the last word on the
usefulnessofthemethod,butratherasaﬁrstsuiteofexperimentsacrossdifferenttypes
of text comparison tasks to illuminate some of the strengths and weaknesses of such
an approach to text distance. We thus analyze the results in detail to identify future
directionsforfurtherilluminatingwhenandtowhatextentthemethodmightbeuseful.
The analysis reveals that our method is not consistently successful across our
sample tasks. We hypothesize that, because ontological relations play an integral role
in our semantic distance measure, the measure is less effective when the semantic
proﬁle for a text (the set of corresponding concepts) lacks semantic coherence. Other
work has explored ways to measure the semantic coherence of a set of concepts in
terms of their connectedness within an ontology (Gurevych et al. 2003). Because a
semantic proﬁle in our work includes both ontological (relational) and distributional
(frequency) knowledge, we require a measure of semantic coherence that takes both
into account. We develop a novel measure of semantic coherence called proﬁle density
that captures both the ontological and distributional coherence of a set of frequency-
weighted concepts, and apply it to the data sets used in the different tasks to better
understandtheperformanceofoursemanticdistancemeasure.
Ourdistancemeasureiscastasagraphicaltextcomparisontaskwithinanetwork
ﬂow framework as described in Section 2. In Section 3, we give an overview of our
exploration of the method on three types of text comparison problems. The following
threesectionspresentexperimentalresultsandanalysisofapplyingourmethodtothe
various tasks: verb alternation detection (Section 4), name disambiguation (Section 5),
and document classiﬁcation (Section 6). In Section 7, we describe our proﬁle density
measureanduseittoanalyzethepropertiesofthedatasetsthatleadtotheperformance
differentialacrossthetasks.Weconcludethepaperwithadescriptionofrelatedwork
intextcomparisonandgraph-theoreticNLPapproaches(Section8)andadiscussionof
somefuturedirectionsforourresearch(Section9).
2.TheNetworkFlowMethod
Asnotedpreviously,wetreatanontologyasagraphandrepresentatextasasemantic
proﬁle—a collection of nodes in the graph (concepts in the ontology), each having a
weight (its frequency). For example, in Figure 1, a small text consisting of the words
{cheese, wheat}, with frequencies of 4 and 10, respectively, is represented as a small
weighted subgraph in an ontology by uniformly distributing the word frequencies
among the associated concepts. In this way, a text is a weighted subgraph within a
33
ComputationalLinguistics Volume36,Number1
Figure1
AsmalltextrepresentedasacollectionofweightednodesinafragmentofWordNet.
largergraph(withthethicknessoftheboxesintheﬁgureindicatingweight),andtwo
suchweightedsubgraphsareconnectedviaasetofpathsinthegraph.
Our goal is to measure the distance between two subgraphs (representing two
texts to be compared), taking into account both the ontological distance between the
componentconceptsandtheirfrequencydistributions.Toachievethis,wemeasurethe
amount of “effort” required to transform one proﬁle to match the other graphically:
Themoresimilartheyare,thelesseffortittakestotransformoneintotheother.(This
view is similar to that motivating the use of “earth mover’s distance” in computer
vision [Levina and Bickel 2001].) In Section 2.1, we ﬁrst give the intuitive motivation
for the approach in terms of the properties of semantic distance that we want to cap-
ture by considering transport effort. We then present the mathematical formulation of
our graph-based method as a minimum cost ﬂow (MCF) problem in Section 2.2, and
describetheformulationofourtaskwithinthisnetworkﬂowframeworkinSection2.3.
InSection2.4,wereturntothepropertiesweidentifyinSection2.1toexplainhowthey
arereﬂectedintheMCFformulation.
2.1AnIntuitiveOverview
InFigure 2(a),weshow adiagrammatic representation ofan ontology(thelarge open
triangle) with two proﬁles, one indicated with ﬁlled squares and the other with ﬁlled
triangles.Thelocationofaﬁlledshapeindicatesthelocationofaproﬁleconceptinthe
ontology,anditssizeindicatesitsfrequencywithintheproﬁle.Weomitedgesbetween
thenodestosimplifythediagram,butnotethatweassumewehaveahierarchical,con-
nected ontology; hyponymy links are sufﬁcient. Our goal is to calculate the similarity
betweenthetwoproﬁlesbydetermininghowmucheffortisrequiredtotransport,along
the ontological links, the frequency mass from all of the squares to “ﬁll” the available
spaceinthetriangles.Theamountofmasstomoveandtheamountofspaceavailable
areindicatedbythesizesofthesquaresandtriangles,respectively.Thedegreeofeffort
requiredtotransportonetotheotherindicatesthedegreeofsemanticdistance.
34
TsangandStevenson AGraph-TheoreticFrameworkforSemanticDistance
Figure2
Twosubgraphs(onerepresentedbysquares,theother,triangles)withvaryingdegreesof
overlapand,therefore,similaritywithinanontology.Figure(b)differsfromFigure(a)interms
oftheontologicaldistancebetweenthesquareandthetriangleclusters.Figure(c)differsfrom
Figure(a)intermsofthesizeoftheindividualsquares.
The transport effort is determined by both the amount of mass to move and the
graphical distance over which it must travel. First consider graphical (ontological)
distancebetweentheproﬁles.Assumethecalculateddistancebetweenthetwoproﬁles
in Figure 2(a) is d. In Figure 2(b), the triangle proﬁle is exactly the same. By contrast,
althoughthesquareproﬁlehasthesameinternalproperties(samefrequencydistribu-
tionandgraphicalstructure),itslocationisfurtherfromthetriangles.Becausethetwo
proﬁlesoccupymoredistantportionsoftheontologicalspace,theyarelesssemantically
similar than in Figure 2(a). As desired, the extra ontological distance over which the
square frequency mass must be transported to the triangles will cause the calculated
distanceinFigure2(b)tobelargerthand.
Nextconsidertheeffectofvaryingthefrequencydistributionovertheproﬁlenodes.
Again,inFigure2(c),thetriangleproﬁleisexactlythesameasinFigure2(a).However,
whereas the nodes of the square proﬁle in Figure 2(c) are in the same locations as in
Figure2(a),theirdistributionalpropertiesaredifferent.Thebulkofthefrequencydistri-
butionisnowshiftedclosertothenodesofthetriangleproﬁle.Becausethetwoproﬁles
have more distributional weight located closer within the ontology, this indicates that
the semantic space they occupy is more similar than in Figure 2(a). Correspondingly,
becausemuchofthemassofthesquareproﬁleneedstotravellessfartoﬁllthespaceof
thetrianglenodes,thecalculateddistanceinFigure2(c)willbelessthand.
35
ComputationalLinguistics Volume36,Number1
Itisworthnotingexplicitlythatthisnotionofsemanticdistanceastransporteffort
ofconceptfrequencyovertherelations(edges)ofanontologydifferssigniﬁcantlyfrom
anapproachtosemanticdistancethatutilizesconceptvectorsoffrequency.Bycrucially
utilizingtherelationsbetweenconceptsincalculatingsemanticdistance,ourapproach
candeterminethedistancebetweentextsthatuserelatedbutnon-equivalentconcepts.
For example, our measure will ﬁnd greater similarity between a text that discusses
milk and one that discusses cheese than between one that discusses milk and one that
discusses bread.Avectordistancewouldﬁndeachoftheseequallydissimilar,because
therearenoconceptsincommon,andthereisnowaytorelatemilktocheese.
1
The intuitive examples in Figure 2 show that calculating semantic distance as
transporteffortcapturesinawell-motivatedwayboththeontologicaldistancebetween
theproﬁlesandtheirweightingbythedistributionalamountsoftheconceptnodes.In
thenextsubsection,wedescribeamathematicalformulationthatcapturestherelevant
properties of our problem in a network ﬂow framework. Network ﬂow methods are
often used in computer science for modelling such transport effort, for example, in
communicationortransportationnetworks.
2.2MinimumCostFlow
Our intuitive transport effort examples above can be viewed as a supply–demand
problem,inwhichweﬁndtheminimumcostﬂow(MCF)fromthesupplyproﬁletothe
demandproﬁletomeettherequirementsofthelatter.Mathematically,letG =(N,E)be
a connected graph representing an ontology, where N is the set of nodes representing
the individual concepts, and E is the set of edges representing the relations between
the concepts. (Most ontologies are connected; in the case of a forest, adding an arbi-
trary root node yields a connected graph.) Each edge has a cost c : E → R, which is
the ontological distance of the edge. Each node i ∈ N is associated with a value b(i)
such that b : N → R indicates its available supply (b(i) > 0), its demand (b(i) < 0), or
neither (b(i)=0). The goal is to ﬁnd a ﬂow from supply nodes to demand nodes that
satisﬁesthesupply/demandconstraintsofeachnodeandminimizestheoverall“trans-
portcost.”
First, we have to deﬁne a function to describe the ﬂow entering i via an incoming
edge (h,i) and exiting i via an outgoing edge (i,j). Let IN
i
be the set of edges (h,i)
with a ﬂow entering node i; similarly, let OUT
i
be the set of edges (i,j)withaﬂow
exitingnodei.Then,theﬂowenteringandexitingnodeiiscapturedbyx : E → Rsuch
that we can observe the combined incoming ﬂow,
summationtext
(h,i)∈IN
i
x(h,i), from the entering
edgesIN
i,aswellasthecombinedoutgoingﬂow,
summationtext
(i,j)∈OUT
i
x(i,j),viatheexitingedges
OUT
i
(see Figure 3). A valid ﬂow, x, must be found such that the net ﬂow at each
node—thedifferencebetweenitsexitingﬂowanditsenteringﬂow—equalsitsspeciﬁed
supply or demand constraints. For example, in Figure 2 where the squares represent
thesupplyandthetrianglesrepresentthedemand,asolutionfor x wouldallowusto
transportalltheweightatthesquarestoﬁllthetriangles,viaasetofroutesconnecting
them.
1 TechniquessuchasSVDorLSAcouldbeappliedtotheconceptvectors,aswithwordvectors,yielding
potentialrelationsthroughunnamedconcepts(e.g.,LandauerandDumias1997).Note,however,that
suchmethodsaredependentontheusagesoftheconceptsimplicitlyencodingsuchconnections,
whereasanontology-basedmethoddrawsonaknowledgebasethatexplicitlyencodestherelations
regardlessoftheparticularusagesoftheconcepts.
36
TsangandStevenson AGraph-TheoreticFrameworkforSemanticDistance
Figure3
Anillustrationofﬂowenteringandexitingnodei.
Formally,theMCFproblemcanbestatedasfollows(fromChv´atal1983):
Minimize z(vectorx)=
summationdisplay
(i,j)∈E
c(i,j)·x(i,j)(1)
subjectto
summationdisplay
(i,j)∈OUT
i
x(i,j)−
summationdisplay
(h,i)∈IN
i
x(h,i)= b(i),∀i ∈ N (2)
and x(i,j)≥0,∀(i,j)∈ E (3)
The constraint speciﬁed by Equation (2) ensures that the difference between the ﬂow
entering and exiting each node i matches its supply or demand b(i) exactly. The next
constraint, Equation (3), ensures that the ﬂow is transported from the supply to the
demandbutnotintheoppositedirection.ThecalculationofzinEquation(1)(whichis
subject to these constraints) multiplies the amount of ﬂow travelling along each edge,
x(i,j),bythetransportationcostofusingthatedge,c(i,j).Takingthesummationoverall
edgesoftheproduct c(i,j)·x(i,j)yieldsthedesiredtransporteffortofusingthesupply
toﬁllthedemand.
2
2.3SemanticDistanceasMCF
To cast our text comparison task into this framework, we ﬁrst represent each text as a
semanticproﬁleinanontology.Theproﬁleofonetextischosenasthesupply(S)andthe
otherasthedemand(D);ourdistancemeasureissymmetric,sothischoiceisarbitrary.
InourexamplesinSection2.1,thesquareproﬁlewasseenasthesupplyandthetriangle
2 Wecastourtextcomparisonproblemasanuncapacitatedminimum-costﬂowproblem,i.e.,thereisno
upperboundconstraintplacedontheamountofﬂowalongeachedge(seeEquation(3)).Unlikea
capacitatedversionofMCF,whichisNP-complete(GareyandJohnson1979),ourproblemistractable
andcanbesolvedinpolynomialtime.
37
ComputationalLinguistics Volume36,Number1
proﬁle as the demand. The concept frequencies of the proﬁles are normalized, so that
thetotalsupplyequalsthetotaldemand.
Thecostoftheroutesbetweennodesisdeterminedbyasemanticdistancemeasure
deﬁned over the nodes in the ontology—that is, a measure of individual concept-
to-concept distance. A relation (such as hyponymy) between two concepts i and j is
represented by an edge (i,j), and the cost c on the edge (i,j) can be deﬁned as the
concept-to-conceptdistancebetween i and j.Forsimplicityinthisarticle,weuseedge
distanceasourconcept-to-conceptdistancemeasurec;thatis,eachedge(i,j)hasacost
of 1, and the distance between any two concepts is the number of edges separating
them.
3
Next, we must determine the value of b(i) at each concept node i.Inthesimple
case, i occursinonlyoneproﬁleortheother.If i ∈ S, b(i)issettothenormalizedsup-
ply frequency, f
S
(i). If i ∈ D, b(i) is set to the negative of the normalized demand
frequency,−f
D
(i),sincedemandisindicatedbyavaluelessthanzero.However, i may
be part of both the supply and demand proﬁles, and then b(i) must be set to the net
supply/demandatnodei.Thuswehave:
b(i)= f
S
(i)−f
D
(i)(4)
For example, if the supply proﬁle contains a node car with frequency of 0.25, and the
same node in the demand proﬁle has a frequency of 0.7, then b(car)is−0.45. In other
words,thenodecarhasanetdemandof0.45.
Recall that our goal is to transport all the supply to meet the demand; the key
step is to determine the optimal routes between S and D such that the constraints in
Equation(2)andEquation(3)aresatisﬁed.Thetotaldistanceoftheroutes,ortheMCF—
z(vectorx)inEquation(1)—isthedistancebetweenthetwosemanticproﬁles.
2.4OntologicalandDistributionalFactorsinMCF
To see how the factors of ontological distance and frequency distribution play out in
theMCFformulation,let’sreturntooursquareandtriangleproﬁleexample.Consider
ahypotheticalzoomed-inareaoftheearlierdiagraminFigure2(a),showninFigure4.
Here we assume that the square nodes have a net supply (b(i) > 0) and the triangle
nodes have a net demand (b(i) < 0).
4
The size of the square and triangle nodes in
the ﬁgure indicates |b(i)|—i.e., the relative supply/demand, respectively. The circles
indicate nodes with neither supply nor demand constraints—i.e., b(i)=0. Each arrow
fromnode i tonode j indicatesthesourceanddestinationfortransportedﬂowfroma
square node to a triangle. The length of an arrow represents the ontological distance,
c(i,j), and the width indicates the amount of ﬂow, x(i,j). Note that the mass at the
rightmost square in the ﬁgure has to be distributed over the two triangles, and the
mass at the leftmost square is transported over a path with one edge (as indicated by
3 Somesemanticdistances,suchasthoseofLin(1998)andResnik(1995),donotdirectlyusethe
underlyinggraphstructureoftheontologyincalculatingthedistancebetweentwoconcepts.Usingthis
typeofdistanceinourMCFframeworkrequiresanextragraphtransformationstep;seeTsangand
Stevenson(2006)formoredetails.
4 Earlierwemadethesimplifyingassumptionthatsquarenodeswerethesupplyproﬁleandtriangle
nodesthedemandproﬁle.Wehavenowseenthatanodecanbelongtobothproﬁles,andits
characterizationmoreaccuratelyisstatedintermsofnetsupply/demand.Thus,forexample,asquare
nodemaybelongtojustthesupplyproﬁleortoboththesupplyanddemandproﬁle;thedeﬁningfactor
isthatithasanetsupply.
38
TsangandStevenson AGraph-TheoreticFrameworkforSemanticDistance
Figure4
Anexampleoftransportingtheweightsatthesquarenodes(supplynodes)tothetrianglenodes
(demandnodes).Thecirclenodeshavezerosupply/demandrequirement.
thearrownearby)insteadofapathwiththreeedges(withtwocirclenodesonthepath).
Theaggregatedlengthandwidthofthethreearrowscorrespondstotheminimumcost
ﬂow, i.e., the semantic distance between the proﬁles represented by the squares and
triangles.
Both the ontological distance between nodes and the node weights are important
indeterminingtheminimumcostﬂow.TheroleofontologicalinformationintheMCF
formulationisclear.Ifthesquareswerefurtherawayfromthetrianglesintheontology
inFigure4—thatis,ifmoreedgesseparatedthesquaresandthetriangles—thesetsof
concepts they represent would be less semantically similar. The length of the arrows
(representingc(i,j))wouldbegreater,andtheresultingMCFwouldbelarger,reﬂecting
the greater semantic distance between the proﬁles. Distributional information in this
methodisequallycriticaltothedistancecalculation,becauseitdeterminestheamount
ofsupply/demandateachnode.IfthesquaresinFigure4weremoreuniformlysized,
the two proﬁles would be more semantically similar because the weight would be
distributed more similarly across the ontological space. In this case, less ﬂow would
havetotravelfromtherightmostsquaretotheleftmosttriangle(i.e.,thecorresponding
arrowwouldbethinner,representingx(i,j)),andtheresultingMCFwouldthereforebe
smaller.Inshort,ourMCFmethodcapturesthedesiredpropertythatbothontological
distancebetweenproﬁlenodesandtheirfrequencydistributionsdeterminetheoverall
semanticdistancebetweentwoproﬁles.
3.Evaluation:ExperimentalTasksandMethodology
WeselectthreedifferentNLPtasksthatcanbeformulatedastextclassiﬁcationproblems
based on semantic distance between the texts. In each case, the texts to be compared
aretreatedasbagsofwordswithassociatedfrequencies.Thetasksarechosentoreﬂect
differenttypesofrelationsusedtoextracttherelevantwords,toseeifavaryingamount
ofconstraintonthewordscomprisingatextinﬂuencestheperformanceofourmethod.
In verb alternation detection (Section 4), we identify which verbs, out of a set of
target and ﬁller verbs, allow a certain variation in the syntactic expression of their
39
ComputationalLinguistics Volume36,Number1
underlying argument structure. The task is achieved by comparing the set of head
wordsthatoccurwiththeverbineachoftwodifferentsyntacticpositions(e.g.,subject
of intransitive and object of transitive). In this task, the words that make up the texts
tobecomparedhaveaparticularsyntacticrelationtotheverbunderconsideration.In
proper name disambiguation (Section 5), we classify the sense of an ambiguous name
accordingtoitslocalcontext.Thistaskissimilartowordsensedisambiguation(WSD),
inpickingtheintendedsenseofaterm,butalsohassimilaritiestotopicidentiﬁcation,
since the proper name delineates a particular domain of discourse. In this task, we
comparethetextconstitutingtheambiguousinstancetotextsrepresentingeachofthe
known referents of the name. Here, the words of a text are extracted from a small
windowofoccurrencearoundthetargetnametoken(25wordsoneachside),regardless
of the syntactic relations among the words. For the known referents, the words from
these windows are aggregated across a small set of labelled instances. In document
classiﬁcation (Section 6), a text is classiﬁed into one of a restricted number of topic
categories. The text to be classiﬁed consists of all the words in a document; for each
topic,itiscomparedtoasetofwordscorrespondingtoasmallsetofknowndocuments
forthattopic.Theextractedwordsarenotconstrainedbysyntacticrelation(asinverb
alternation)orevenbydistancetoatargetelement(asinnamedisambiguation).
Ineachcase,theresultingbagofwordsforatextmustbemappedintoasemantic
proﬁle—a frequency-weighted set of concepts in an ontology. Because all three of our
tasksinvolvegeneraldomaintext,weuseWordNetasourontology(Fellbaum1998).
5
(A domain-restricted task may motivate the use of a domain-speciﬁc ontology, such
as UMLS for comparing medical texts as in Bodenreider [2004].) Because the noun
hierarchyoftheWordNetontologyismostdeveloped,werestrictoursemanticproﬁles
to use only the nouns from the bag of words corresponding to a text: Any word in
the text that appears in the noun hierarchy of WordNet is included in the bag of
nouns.
Thebagofnounswiththeirassociatedfrequenciesmustbemappedtotheappro-
priate concepts in WordNet. Given the current state of unsupervised WSD, there is
generally no attempt to disambiguate the words of a text when performing this kind
of mapping—that is, there is no selection of the most appropriate concept or set of
concepts to map the words to, given the context of their use. The simplest method
is to distribute the frequency of each word uniformly to its corresponding concepts.
Forexample,Ribas(1995)mapsthewordfrequencytothemostspeciﬁcconcept(s)for
the word, including all of the possible synsets for the word, but not their hypernyms.
Resnik(1993)alsodistributesthewordfrequencyuniformly,butdoessoacrossthemost
speciﬁcconcept(s)andalloftheirhypernyms.Otherapproaches,althoughstillavoiding
thedifﬁcultiesofWSD,dotrytocapturetheoverallsemantic“tendencies”ofthesetof
words. Such methods estimate the appropriate probability distribution over a set of
conceptstorepresentagivenbagofnounsasawhole(LiandAbe1998;ClarkandWeir
2002). However, such techniques still start with a mapping of each word to all of its
immediateconcepts.
5 ThereisdisagreementoverthesuitabilityoftreatingWordNetasanontology,ratherthanasalexical
network(Gangemi,Guarino,andOltramari2001;Hirst2009).However,theintentionofthecreatorsof
WordNetisapparentlythatitssynsetscorrespondtoconcepts,andtherelationsbetweentheminclude
both“conceptual-semanticandlexicalrelations”(http://wordnet.princeton.edu/),qualifyingit,under
someviews,asageneraldomainontology.Althoughrecognizingthelimitationsanddifﬁcultiesofusing
aprimarilylexicalresourceasanontology,wenotethatWordNetisstandardlyusedassuchin
computationallinguistics,andsoweadoptthisusehere.
40
TsangandStevenson AGraph-TheoreticFrameworkforSemanticDistance
For all three of our tasks, we take the simple approach of mapping each noun
individually to its most speciﬁc concepts (not their hypernyms), uniformly dividing
the word frequency among them. In verb alternation, we also experiment with the
possibility of ﬁnding the best set of frequency-weighted concepts for the full bag of
nouns(usingthetechniquesofLiandAbe[1998]andClarkandWeir[2002]),toseeif
thisaffectstheperformanceofourmethod.
The precise classiﬁcation experiment performed using these semantic proﬁles is
describedindetailsubsequentlyinthesectionforeachtask.Ineachcase,wecompare
the performance of our MCF method on the semantic proﬁles to one or more purely
distributionalmethodsusingtheoriginalwordfrequencyvectors.
4.Task1:VerbAlternationDetection
Verbalternationreferstovariationsinthesyntacticexpressionofverbalarguments.Ifa
verbparticipatesinanalternation,thesameunderlyingsemanticargumentmayappear
in varying positions (slots) of the verb’s subcategorization frames. For example, the
followingsentencesshowthattheargumentundergoingthemeltingactioncanappear
asthesubjectofanintransitiveuseofmelt(1a)orastheobjectofatransitiveuse(1b).
1a. Thechocolatemelted.
1b. Thecookmeltedthechocolate.
Thistypeofintranstive/transitivepairingisknownasthecausativealternationbecause
oftheexplicitexpressionofthecauser(the cook)inthetransitivealternant.
It has long been hypothesized that the semantics of a verb and its relations to its
argumentsatleastpartiallydeterminethesyntacticexpressionofthosearguments(see
Pinker [1989], among others). Inﬂuential work by Levin (1993) showed that this rela-
tionship could be exploited “in reverse” by using alternation behavior as an indicator
oftheunderlyingsemanticsofaverb—speciﬁcally,thatverbsundergoingthesamesets
ofalternationsformclasseswithsimilarsemantics.Computationallinguistshavebuilt
onthisworkbydemonstratingthatstatisticalcuestoalternationbehaviorcanbeused
to automatically place verbs into semantic classes (Merlo and Stevenson 2001; Schulte
imWalde2006).
Detection of verb alternation behavior can be cast as a text comparison problem
(McCarthy 2000; Merlo and Stevenson 2001). Consider an alternation such as the
causative illustrated in Example (1). The set of nouns appearing as the subject of the
intransitive (such as chocolate) have the same relation to the verb as the set of nouns
appearing as the object of the transitive. Because the verb places constraints on what
kinds of entities can be in that relation (here, things that are meltable), the two sets of
nouns should be similar. Hence, to identify a particular alternation for a verb, the set
of nouns in a certain slot of one of its subcategorization frames is compared to the set
ofnounsinthealternatingslotforthatsemanticargumentinanothersubcategorization
frame.
For example, Merlo and Stevenson (2001) devise a simple lemma overlap score
that counts the number of tokens appearing in both of the relevant syntactic slots.
McCarthy (2000) instead compares two semantic proﬁles in WordNet that contain the
conceptscorrespondingtothenounsfromthetwoargumentpositions.InMcCarthy’s
method,theproﬁlesareﬁrstgeneralizedtoasetofhigherlevelnodesinthehierarchy
(startingwiththemethodofLiandAbe[1998]);next,skewdivergenceisusedtoﬁnd
41
ComputationalLinguistics Volume36,Number1
thedistance between theresulting vectorsofconcepts. Hereweuse our networkﬂow
methodtodirectlycomparethesemanticproﬁlescorrespondingtothenounsets.Our
method allows us to compare sets of weighted concepts as in McCarthy’s, but using
a distance method that applies within the ontology graph, rather than simply using a
distributionaldistancemeasureoverconceptvectors.
4.1ExperimentalSet-up
We adopt the data set from an investigation of a semantic distance measure that was
a precursor to our network ﬂow method (Tsang and Stevenson 2004). The selection
of these verbs and extraction of their arguments are discussed in the following two
sections;wethendescribeourevaluationmethodology.
4.1.1 Experimental
Verbs.Weevaluateourmethodonthecausativealternation.Asnoted
previously, in this alternation the target syntactic slots for comparison are the subject
oftheintransitive(Subj-Intrans)andtheobjectofthetransitive(Obj-Trans).(Theseare
the positions of the chocolate in Examples (1a) and (1b), respectively.) To identify verbs
undergoingthisalternation,werandomlyselectedverbsfromamongLevinclassesthat
are indicated to allow the causative alternation. This allows us to test the ability of a
distancemeasuretodetectalternationbehavioramongverbsfromarangeofsemantic
classeswhichmaydifferinotherrespects.
We refer to the verbs that are expected to undergo the causative alternation as
causativeverbs.Forcomparison,werandomlyselectedanequalnumberofﬁllerverbs,
subject to the constraint that their Levin classes do not allow a causative alternation.
(Speciﬁcally,noneoftheclassescontainingaﬁllerverballowsanalternationinwhich
thesameunderlyingargumentappearsintheSubj-IntransslotaswellastheObj-Trans
slot.)Thefullsetofpotentialcausativeandﬁllerverbswereﬁlteredaccordingtocorpus
counts,asdescribednext.
4.1.2 Corpus
Data and Argument Extraction. We used a randomly selected 35M-word
portionoftheBritishNationalCorpus(BNC;Burnard2000).Thetextwasparsedusing
the RASP parser of Briscoe and Carroll (2002), and subcategorization frames were
extractedusingthesystemofBriscoeandCarroll(1997).Eachsubcategorizationframe
entryforaverbincludesalistoftheobservedargumentheadsperslotalongwiththeir
frequencies.Foreachverb/slotpair,wethusextractedthesetofnounsusedinthatslot
alongwiththeirfrequencyofoccurrence.
Verbs were ﬁltered from the potential list of experimental items if they occurred
lessthan10timesinourcorpusineitherthetransitiveorintransitiveframe.Theverbs
werethendividedintomultiplefrequencybands:high(atleast450instances),medium
(between 150 and 400 instances), and low (between 10 and 100 instances). An equal
numberofverbsofeachtype(causativeandﬁller)wererandomlyselectedwithineach
band, yielding a total of 120 experimental verbs in balanced data sets of 60 items for
development and 60 items for testing. The development data was used in our earlier
worktoselectaproﬁle-generationmethodforthetestdata(TsangandStevenson2004).
Inourcurrentwork,wedidnotmakeanyadjustmentstoourmethodbasedonresults
onthedevelopmentset(i.e.,itwasnotusedtosetanyparametersorselectaparticular
implementationapproach).Hence,wereporttheevaluationofourmethodonthefull
set of 60 verbs in each of the data sets, as well as individually on the three frequency
bandsof20verbseach.Wereferheretotheoriginal“development”and“test”datasets
as“dataset1”and“dataset2”.
42
TsangandStevenson AGraph-TheoreticFrameworkforSemanticDistance
4.1.3 Evaluation
Methodology. For each verb, we create a semantic proﬁle for each of
the Subj-Intrans and Obj-Trans slots. We ﬁrst take the argument heads with their fre-
quencies from the appropriate slots in the extracted subcategorization frame for the
verb. We then map these words with their frequencies to the corresponding nodes in
WordNet,asdescribedinSection3.(Wealsoconsiderheredifferentproﬁlegeneration
methods,discussedlaterinSection4.2.2.)Wethencalculatethenetworkﬂowdistance
between the two semantic proﬁles for each verb, yielding a distance calculation for
that verb. Recall that we expect verbs that participate in the alternation to have more
similar semantic proﬁles corresponding to the Subj-Intrans and Obj-Trans nouns. For
example, a causative verb like melt, as in Examples (1a) and (1b), may have words
likechocolate,sherbet,andglacierintheSubj-Intransslot,andwordslikechocolate,butter,
and bronze intheObj-Transslot.Incontrast,anon-causativeverblike fry willtypically
have more dissimilar sets of words that contribute to the two proﬁles (e.g., cook, wife,
and chef in the Subj-Intrans slot, and egg, noodle,andonion in the Obj-Trans slot). We
thus rank all the verbs by the distance calculation, and (as in McCarthy 2000) set a
thresholdtodividetheverbsintocausative(smallerdistancevalues)andnon-causative
(largerdistancevalues).FollowingMcCarthy,weexperimentedwithboththemeanand
medianvaluesasthethreshold,butfoundlittledifference.Wereporttheresultsusing
themediandistanceasthethreshold,becausethisprovidedmoreconsistentresultswith
ourmethod.
Becausewelabelallverbsinourexperimentsascausativeornon-causative,weuse
accuracy as the performance measure. Since we have balanced data sets, the random
baselineis50%.Wecompareourresultsaswelltoanumberofdistributionalmethods
(as enumerated in the next section). Given the small size of our data sets, a simple
statistical test on the resulting accuracies is not powerful enough to reveal differences
when the accuracies are close. However, because the difference in methods is due to
variation in how they rank the experimental items, we perform a Wilcoxon signed
rank test (Wilcoxon 1945) to determine when the rankings between two methods are
signiﬁcantlydifferent,usingapvalueof.05.
4.2ResultsandAnalysis
Asnotedherein,wepresentresultsontwosetsofdata,andalsoexaminetheeffectofus-
ingalternativeproﬁlegenerationmethods.Wecompareournetworkﬂowdistance(NF)
to a number of other distance measures including probability distributional distances
given by Jensen-Shannon divergence (JS) and skew divergence (skew div) (Lee 2001),
as well as the general vector distances of cosine, Manhattan distance, and Euclidean
distance.
4.2.1 Experimental
Results. Ondataset1,ournetworkﬂowdistanceperformsbetterthan
oraswellasallothermeasuresontheindividualfrequencybands,asshowninTable1.
On all verbs combined (the “All” column) the performance of our method is not the
best, although the Wilcoxon test shows no signiﬁcant difference between the rankings
ofNFandthebestmeasure(Manhattan).(ThedifferenceinrankingsbetweenNFand
allothermeasuresissigniﬁcant.)
Interestingly, we ﬁnd that the ”All Verbs” performance of NF (and that of several
other methods) is indeed worse than the performance on the individual frequency
bands. We examined the distance values across the frequency bands to determine the
causeforthispattern.Wefoundthatlowfrequencyverbstendtohavesmallerdistances
43
ComputationalLinguistics Volume36,Number1
Table1
Accuraciesondataset1bythenetworkﬂowmethod(NF),cosine,Manhattandistance,Euclidean
distance,skewdivergence(skewdiv),andJensen-Shannondivergence(JS).Bestaccuraciesin
eachconditionareshowninboldface.
All FrequencyBands Avgof
Verbs High Medium Low Bands
NF 0.60 0.70 0.70 0.70 0.70
cosine 0.57 0.60 0.60 0.60 0.60
Manhattan 0.63 0.70 0.70 0.70 0.70
Euclidean 0.47 0.40 0.50 0.40 0.43
skewdiv 0.57 0.60 0.60 0.50 0.57
JS 0.60 0.70 0.60 0.70 0.67
Table2
Accuraciesondataset2bythenetworkﬂowmethod(NF),cosine,Manhattandistance,Euclidean
distance,skewdivergence(skewdiv),andJensen-Shannondivergence(JS).Bestaccuraciesin
eachconditionareshowninboldface.
All FrequencyBands Avgof
Verbs High Medium Low Bands
NF 0.67 0.60 0.80 0.60 0.67
cosine 0.50 0.60 0.50 0.50 0.53
Manhattan 0.63 0.60 0.80 0.60 0.67
Euclidean 0.60 0.50 0.70 0.50 0.57
skewdiv 0.63 0.60 0.80 0.60 0.67
JS 0.70 0.60 0.80 0.60 0.67
between the two slots and high frequency verbs tend to have larger distances. This is
duetothefactthathigherfrequencyverbstypicallyoccurwithawiderrangeofnouns,
leading to a more dispersed semantic proﬁle (i.e., a larger number of concepts). As a
result,thebestthresholdforseparatingthealternatingandnon-alternatingverbsdiffers
across the frequency bands, and the threshold for all verbs together lies in between
the thresholds for the high and low frequency bands. When classifying all verbs, the
frequencyeffectmayresultinmorefalsepositivesforlowfrequencyverbs(whichhave
generally smaller distance values), and more false negatives for high frequency verbs
(which have generally larger distance values). The column labelled “Avg” in Table 1
shows the performance when averaging the results across the individual frequency
bands.Formostmethods,includingours,the“Avg”resultsaremuchbetterthanwhen
consideringallverbstogether(the“All”column).
Table 2 reports the performance on dataset2, which is similar to that on dataset1.
Again, we ﬁnd that our method is tied for the best performance in every condition
except for all verbs combined. (Here we ﬁnd that all four methods over .60 accuracy
inthe“All”conditionhavestatisticallyindistinguishablerankingsoftheexperimental
items.) On this data set, taking the average of the frequency bands does not help
performance of our method compared to “All,” but neither does it hurt (and for most
methods“Avg”doesbetterorthesameas“All”).Weconcludethatseparatingitemsby
frequencymayberequiredtoachieverobustresultsinthistypeoftask.
Although our method is tied for best in every condition except “All,” neither
is our method distinguished from several of the other distance measures. Given the
44
TsangandStevenson AGraph-TheoreticFrameworkforSemanticDistance
Table3
Averageaccuraciesbythenetworkﬂowmethod(NF),Manhattandistance(Man),skew
divergence(skewdiv),andJensen-Shannondivergence(JS)ondifferentproﬁles:original
(“raw”),LiandAbe,andClarkandWeirproﬁles.Bestaccuraciesineachconditionareshownin
boldface.
raw LiandAbe ClarkandWeir
Dataset1 Dataset2 Dataset1 Dataset2 Dataset1 Dataset2
NF 0.70 0.67 0.50 0.67 0.73 0.70
Manhattan 0.70 0.67 0.57 0.67 0.60 0.57
skewdiv 0.57 0.67 0.53 0.67 0.68 0.60
JS 0.67 0.67 0.63 0.67 0.63 0.53
relatively small amounts of data per verb (with proﬁles averaging about 900 nodes
in size), it is possible that the raw proﬁles suffer from a sparse data problem and are
notsufﬁcientlycapturingtheconceptualsimilaritiesamongalternatingslots.McCarthy
(2000)addressedthisissuebyusingatechniqueforgeneralizingconceptnodespriorto
comparingproﬁles.Weexplorethisissuenext.
4.2.2 Comparing
Different Proﬁle Generation Methods. Ourexperimentsusesemanticpro-
ﬁlescreateddirectlyfromthewordfrequencies,asdescribedearlier.However,research
hasexploredthepossibilityofgeneralizingthiskindof“raw”datatoasemanticproﬁle
that more appropriately reﬂects the coherent concepts expressed in the original set of
weightedconceptnodes.Thiscanbeespeciallyusefulwhencreatingsemanticproﬁles
from small amounts of data, given the noise introduced in the mapping of words to
concepts.
6
Toexploretheeffectofdifferentproﬁlegenerationmethodsonthistask,we
consider here two approaches, that of Li and Abe (1998) and Clark and Weir (2002).
Both these methods start with a semantic proﬁle generated as described in Section 3
and attempt to ﬁnd the set of nodes in the ontology that appropriately generalize the
conceptsinthe“raw”proﬁle.
Table3comparestheperformanceofthenetworkﬂowdistancewiththatofseveral
othermeasuresontheoriginal(“raw”)proﬁles,theLiandAbeproﬁles,andtheClark
and Weir proﬁles. Results are reported for the average of the individual frequency
bands,sincethatproducedthebestresultsoverallinourearlierexperiments.Theresults
forcosineandEuclideandistanceareomitted,becausetheyperformworseoverallthan
theothermeasures.
7
Thebestresultsacrossbothdatasetsareachievedbyournetworkﬂowmethodon
theClarkandWeirproﬁles.Consideringtheresultsacrossallproﬁletypes,thenetwork
ﬂow approach is most consistent, achieving the best (or tied for best) performance
in but one condition (dataset1 with Li and Abe proﬁles). The distributional methods
6 Becausewedividethefrequencyofaworduniformlyamongalltheword’sconcepts,withnoattemptat
disambiguationorinformedweighting,muchnoiseisintroduced.Giventhesmallamountsofdata,the
noisemaybesufﬁcienttomisleadournetworkﬂowmethod.
7 Becausetheseresultsusetheapproachofaveragingresultsacrossthefrequencybands,wecannotapply
theWilcoxonsignedranktesttotherankings.(Theindividualfrequencybandshavetoofewitemsfor
thetesttodetectdifferences.)OnAllVerbscombined(resultsnotreportedinthistable),therankingsof
NFaredifferentfromallothermethodsoneachcombinationofdatasetandproﬁlegenerationapproach,
exceptinthesinglecaseofManhattanandJSondataset2usingLiandAbetocreatetheproﬁles.
45
ComputationalLinguistics Volume36,Number1
(Manhattan,skewdiv,JS)inalmostallcasesperformworseonthegeneralizedproﬁles
than on the “raw” proﬁles. (The one exception is that skew divergence does better on
dataset1ontheClarkandWeirproﬁles.)
Overall,then,itseemsthatrawdataislikelybestforapurelydistributionalmethod,
buttheClarkandWeirproﬁlesenablethenetworkﬂowmethodtooutperformthemby
exploiting the graph structure of the ontology. Indeed, when comparing our method
to the others on the Clark and Weir proﬁles for the individual frequency bands (not
shown in the table), we ﬁnd that much of our performance advantage comes on the
lowfrequencyverbs.Thisindicatesthatthecombinationofourmethodwithasuitable
generalizationtechniqueisespeciallyimportantwhendealingwithsparsedata.
WeexaminethedatafurthertodiscoverwhytheLiandAbeproﬁlesyieldpoorer
performanceinmostcasesondataset1.WeﬁndthatLiandAbe’s(1998)methodtendsto
generateproﬁleswithmoregeneralconcepts.Forexample,whengivenanoriginalset
ofconceptssuchas Edam, Brie, Sockeye,andChinook,themethodmayproduceasingle
generalconceptsuchas food insteadofthetwoconcepts cheese and salmon thatcapture
the two kinds of food that are indicated. The loss of semantic information from using
overlygeneralconceptsmayproducethedecreaseinperformance.
For comparison, we also apply McCarthy’s (2000) method to our dataset2, and
ﬁnd that it achieves only 0.60 on all verbs and 0.53 averaged over the three frequency
bands. Her method is especially poor on low frequency verbs (below chance at 0.40).
We hypothesize that her method is less robust to low frequency counts because it
may overgeneralize the data by ﬁrst applying Li and Abe’s (1998) method, and then
generalizingthenodesevenfurther.
We see that although some amount of generalization of the semantic proﬁles is
useful in this task, overgeneralization may be harmful. We leave it to future work
to explore the interaction of our network ﬂow method with different types of proﬁle
generation across various tasks. Because the next two tasks we consider use larger
amountsofdata,weonlyexperimentwithrawproﬁlesinthesecases.
5.Task2:NameDisambiguation
Interest in the NLP problem of name disambiguation has increased as the growth of
the World Wide Web has led to large numbers of ambiguous name references in on-
linetext.Forexample,Websitesordocumentscontainingthename John Edwards may
refertotheU.S.presidentialcandidatefor2008,anNBAbasketballplayer,oraBritish
medicalgeneticist.Anambiguousnamemayberesolvedbycomparingitslocaltextual
context—thesetofwordsitco-occurswith—withthelocaltextualcontextsofthename
whenitsreferenceisknown.Forexample,thetextsurroundingthename John Edwards
initsvarioususesareverylikelytoincludedistinguishingwordssuchas politician vs.
game vs. research.Manyapproacheshavebeenproposedforresolvingnameambiguity
byusingdistributionalmethodsovercontextualinformation(Xu,Liu,andGong2003;
Han,Zha,andGiles2005;Pedersen,Purandare,andKulkarni2005).
Inthissection,wepresenttheapplicationofournetworkﬂowdistancemeasuretoa
namedisambiguationtask,anddemonstratethebeneﬁtsofcombiningontologicaland
distributionalknowledgeinthistask.Theparticulartaskweexamineisoneof“pseudo
name disambiguation,” in which the textscontaining matched pairs of different names
areextracted,andthenthetwodifferentnamesarereplacedbyasinglesymbol,leading
toanambiguous“name”acrossthetwosetsoftexts.Thegoalistorecoverthecorrect
target name in each instance. For example, the names of two soccer players (Ronaldo
andDavidBeckham)formonedisambiguationtask,andthenamesofanethnicgroup
46
TsangandStevenson AGraph-TheoreticFrameworkforSemanticDistance
and a diplomat (Tajik and Rolf Ekeus) form another. This task was established by
Pedersen, Purandare, and Kulkarni (2005) to provide “annotated” experimental data
(with each text indicating the correct name) without the need for expensive manual
annotation.
In Pedersen, Purandare, and Kulkarni (2005), an unsupervised method of name
discrimination through text clustering was used to address this task. This isinfeasible
foramethodlikeours,inwhicheachdistancecalculationrequiresaccesstoanontology.
(Theworst-casecomplexityofclusteringwithourmethodisquadraticinthesizeofthe
ontology used; a detailed discussion can be found in Tsang and Stevenson [2006].) In-
stead,weuseasupervisedmethodology,butexperimentwithvaryingsmallamountsof
datainaminimallysupervisedapproach.Althoughourmethodrequiresextramanual
effortintheformofdataannotationfortraining,weﬁndthattheamountofannotated
datarequiredismodest.
5.1ExperimentalMethodology
5.1.1 Corpus
Data. We use Pedersen, Purandare, and Kulkarni’s (2005) data set, which
was taken from the Agence France-Press English Service portion of the GigaWord
EnglishcorpusdistributedbytheLinguisticDataConsortium.Theyextractedthelocal
context of six pairs of names of varying confusability, including: the names of two
soccer players (Ronaldo and David Beckham); an ethnic group and a diplomat (Tajik
and Rolf Ekeus); two companies (Microsoft and IBM); two politicians (Shimon Peres
and Slobodan Miloˇsevi´c); a nation and a nationality (Jordan and Egyptian); and two
countries (France and Japan). For each name instance, the extracted text consists of
50 words (25 words to the left and to the right of the target name), with the target
nameobfuscated.Forexample,forthetaskofdistinguishingDavidBeckhamandRonaldo,
thetargetnameineachinstancebecomes David BeckhamRonaldo.Theoriginalnamein
each instance is retained only for evaluating the results (and for training, in the case
of our method, as described subsequently). (Note that this approach to data creation
avoidstheuse ofmanually annotated dataforthisexperimental task,butin anactual
application, manual annotation of truly ambiguous names would be necessary.) Each
pair of names thus serves as one of six name disambiguation tasks. Table 4 shows the
number of instances per task (name pair). The “Majority” column also indicates the
relative frequency of the majority name in each pair, which we adopt as the baseline
accuracy.
5.1.2 Classiﬁcation Using the NetworkFlow Method. As mentioned previously, we take a
supervised approach, in which name instances are classiﬁed with the use of training
Table4
Thepairstobeidentiﬁed,therawfrequencies,andtherelativefrequencyofthemajorityname.
Name1 Count Name2 Count Total Majority
Ronaldo 1,700 DavidBeckham 752 2,452 0.69
Tajik 3,002 RolfEkeus 1,071 4,073 0.74
Microsoft 3,401 IBM 2,406 5,807 0.59
ShimonPeres 7,686 SlobodanMiloˇsevi´c 6,048 13,734 0.56
Jordan 25,039 Egyptian 21,392 46,431 0.54
Japan 116,379 France 110,435 226,814 0.51
47
ComputationalLinguistics Volume36,Number1
dataannotatedbytheoriginalnameintheinstance.Togenerateourtrainingdata,we
randomly select a portion of the instances for each of the 12 names. All the training
instancesforanameareusedtoformasingleaggregatesemanticproﬁle,whichserves
as the gold-standard for that name. The remaining instances serve as test data; for
each of these, we build an individual semantic proﬁle. All proﬁles are generated as
describedinSection3,namely,eachfrequencycountforawordisdistributeduniformly
amongthecorrespondingconceptsinWordNet.Agold-standardproﬁleisconstructed
inexactlythesamewayexceptthatitswordfrequencyvectoriscreatedbyaggregating
the word counts from all the relevant training instances. Note that there is nothing
special about such a proﬁle or how it is formed; it simply aggregates counts from
multiplecontexts.
8
To classify a name instance, we measure the network-ﬂow distance between the
individualproﬁleoftheambiguousinstanceandeachofthetwogold-standardproﬁles
for that task. The name whose gold-standard proﬁle has the shortest distance to the
instanceproﬁleisthenameassignedtotheambiguousinstance.Forexample,assume
wehavea“David BeckhamRonaldo”instancetobeclassiﬁed.Wecompareitsproﬁleto
eachofthegoldstandardproﬁlesfor“DavidBeckham”and“Ronaldo”bymeasuring
the distance between each of the two pairs of proﬁles. If the instance proﬁle has a
shorter distance to the proﬁle for “David Beckham” than to that of “Ronaldo,” then
itisclassiﬁedas“DavidBeckham,”otherwiseas“Ronaldo.”
5.1.3 Evaluation
Methodology. Weusetheaccuracyoflabellingallinstancesasoureval-
uation measure. To compare to prior results using F-measure, we report that in some
tables. Because we label all instances, accuracy and F-measure are equivalent in our
method,using2rp/(r+p)asthedeﬁnitionofF-measure.
Therandombaselineforourtaskistheaccuracyoflabellingallinstanceswiththe
predominantname,asshowninthe“Majority”columnofTable4.Becauseweusethe
datasetofPedersen,Purandare,andKulkarni(2005),wecompareourperformanceto
theirdistributionalmethod(reportingtheirbestresultsbothwithandwithoutsingular
valuedecomposition).Becausetheirmethodisanunsupervisedone,wealsotrainand
testasupervisedlearnerusingdistributionaldata(LIBSVMbyChangandLin[2001]).
Foreachsetoftrainingdata,weremovestopwordsandusetheremainingwords(with
theirfrequencies)asinputfeaturesfortheSVM.Wethenobtaintheoptimalparameters
(i.e.,optimalvaluesforcostandgammainLIBSVM)byusing10-foldcross-validation
over the training data. Finally, we perform classiﬁcation on the test data using those
parameters. This enables us to compare our results to a purely distributional method
withaccesstothesametrainingdata.
Because our method is supervised, it is important to minimize the amount of
annotateddatarequiredtobuildthegold-standardproﬁles.(Lengthytrainingtimecan
also be an issue for a supervised method, but here “training” is the straightforward
task of building an aggregate semantic proﬁle.) Because it is unclear a priori what
amountoftrainingdataissufﬁcient,weexperimentwithseveralquantities.Weinitially
select 200 random instances per pair of names, respecting the relative proportions of
the two names overall. (Two hundred instances constitute about 0.1–10% of the data
perpairofnames.)Subsequently,wedecreasethequantityfurther,toone-halfandone-
quarter the original amount (100 and 50 instances, respectively) to observe how the
8 Inourlaterexperimentindocumentclassiﬁcation,onasubsetofourdata,wetriedanearestneighbor
approachtoalltraininginstancesratherthanaggregatingthem,butthisdidnotperformaswell.
48
TsangandStevenson AGraph-TheoreticFrameworkforSemanticDistance
Table5
Networkﬂowresultsusing200traininginstancesontherandomsamplesandtheiraverage
performance.
NamePair RandomSamples Averageof
12345 Samples
Ronaldo/Beckham 0.78 0.83 0.76 0.79 0.84 0.80
Tajik/Ekeus 0.98 0.98 0.97 0.96 0.98 0.97
Microsoft/IBM 0.73 0.72 0.73 0.74 0.73 0.73
Peres/Miloˇsevi´c 0.96 0.96 0.97 0.96 0.97 0.96
Jordan/Egyptian 0.79 0.78 0.78 0.77 0.76 0.77
Japan/France 0.79 0.73 0.77 0.70 0.73 0.75
Table6
Averageresultsforthenetworkﬂow(NF)resultsusing200instancespergold-standardproﬁle,
SVMusing200trainingvectors,andPed05andPed05
SVD
(thebestresultswithoutandwith
SVD,respectively).AllresultsareF-measure(thesameasaccuracyforourmethodandSVM).
Theweightedaverageiscalculatedbasedonthenumberofinstancesineachpairofnames.The
bestresultforeachnamepairisindicatedinboldface.
NamePair Majority Ped05 Ped05
SVD
SVM
200
NF
200
Ronaldo/Beckham 0.69 0.73 0.65 0.85 0.80
Tajik/Ekeus 0.74 0.96 0.89 0.90 0.97
Microsoft/IBM 0.59 0.51 0.59 0.62 0.73
Peres/Miloˇsevi´c0.560.97 0.94 0.90 0.96
Jordan/Egyptian 0.54 0.59 0.62 0.72 0.77
Japan/France 0.51 0.51 0.50 0.48 0.75
UnweightedAverage 0.61 0.71 0.70 0.75 0.84
WeightedAverage 0.53 0.55 0.55 0.55 0.77
performance is inﬂuenced by the amount of data used to construct the gold standard
proﬁles.
9
Toreducetheimpactofpossibleskewedsamplingoftrainingdata,werepeat
the random sampling ﬁve times, with no overlap between the random samples. We
reporttheperformanceofeachsamplesetaswellastheaverageovertheﬁvesamples.
5.2ResultsandAnalysis
5.2.1InitialExperiments.Table5showstheperformanceofourmethodoverﬁverandom
samplesof200traininginstancespertask.Observethattheperformanceovertheﬁve
rounds varies very little (a maximum difference of 0.08, and most are much closer).
Thisshowstherobustnessofourmethodtodifferentmake-upsoftrainingdata.Table6
showstheaverageperformanceofourmethod,incomparisontothechance(majority)
baseline, as well as the results produced by the unsupervised method of Pedersen,
Purandare,andKulkarni(2005)(withsingularvaluedecomposition[SVD]reportedas
9 Wealsoexperimentwith400traininginstancestoseewhetherincreasingtheamountoftrainingdata
helps.Theperformancebeneﬁtisminimal:twotaskshavethesameaverageperformance,threeimprove
by1%,andoneby2%,withanimprovementintheaverageoverallthetasksof1.25%.Apairedt-test
betweentheresultson400and200traininginstancesyieldsahighpvalue(p=0.73),indicatingthatthe
differencesbetweenthetwoarestatisticallyinsigniﬁcant.
49
ComputationalLinguistics Volume36,Number1
Ped05
SVD, and without SVD as Ped05), and the supervised SVM on the same training
data as our method. Observe that our method not only signiﬁcantly outperforms the
random baseline, it is moreover the best performer among all the methods (paired
t-test,p < 0.05).
There are cases for which Pedersen, Purandare, and Kulkarni’s (2005) methods
haveatbestchanceperformance(Microsoft/IBMandJapan/France).Theauthorssuggest
thatthesepairsofnamesariseinthecontextofnewstextinwhichthereare“noconsis-
tentlystrongdiscriminatingfeatures”usefulintheclusteringalgorithm.(Interestingly,
this is the case even with SVD, where words are grouped into a small number of un-
namedconcepts.)EventheSVMhasdifﬁcultywiththesepairs,alsoperformingatjust
aroundchance.Yetourmethodperformswellabovechanceforthesepairs.Ingeneral,
SVMproducesresultsthatarelittlebetteronaveragethantheunsupervisedresultsin
Pedersen,Purandare,andKulkarni(2005)(withsometasksperformingbetter,andsome
worse).Thisshowsthattheperformanceimprovementfromthenetworkﬂowmethod
does not depend solely on access to training data. Instead, it seems that the use of
ontologicalrelationsincalculatingdistancecansigniﬁcantlyenhancethediscriminatory
poweroversimplyusingwords.
NotethatthereisonedifferencebetweenthedatausedintheSVMandthenetwork
ﬂowexperiments:TheSVMistrainedusingallwordsasfeatures,whileonlyWordNet
noun concepts are used in the network ﬂow experiments. It is possible that using just
nounsoramappingofnounstoWordNetconceptscouldbringtheperformanceofthe
SVMintolinewithournetworkﬂowmeasure.Wethusperformtworeplicationsofthe
SVM experiments, one using only nouns as features and one using noun concepts as
features (with the relevant frequencies as the feature values in both cases). However,
both of these approaches produce little to no improvement over the all-words results
reported in Table 6. We conclude that our network ﬂow method is superior to, and
more consistent than, the purely distributional methods, and that this difference is
attributabletotheintegrationofdistributionalandontological(relational)information
inourmeasure.
5.2.2 Reducing
the Amount of Training Data. Because,incontrasttoPedersen,Purandare,
andKulkarni(2005),weuseasupervisedapproach,wewanttodeterminewhetherwe
can reduce our dependence on training data. Here, we report experiments using one-
half(100instances)andone-quarter(50instances)ofthetrainingdatausedearlier.As
before,werepeattherandomsamplingofthetraininginstancesﬁvetimesineachcase,
andreporttheaverageperformancehere.
Table7showsthenetworkﬂowperformancefor200,100,and50traininginstances.
Numerically,theresultsdonotdifferbymuchwhenthetrainingdataisreducedfrom
200 to 100 instances, and a paired t-test ﬁnds the difference to be non-signiﬁcant. The
performancedropismorepronouncedinthe50-instanceexperiment,whereeverypair
of names shows some drop in performance compared to 100 instances. Here, a paired
t-test shows that the performance drop in the 50-instance experiment is statistically
signiﬁcant (p=0.04). Despite this, we still outperform the other methods: Our results
using 50 training instances are much better than those of Pedersen, Purandare, and
Kulkarni(2005)inallbutonetask,andevenbetteroverallthantheSVMin200training
instances(comparetheSVMcolumnofTable6).
Forcomparison,wealsotraintheSVMin100traininginstances,andﬁndadecrease
of 3% on average from using 200 training instances. We conclude that our method is
morerobusttominimaltrainingconditions.Toexploretheleastamountoftrainingdata
needed for our measure, we further reduce the amount for producing gold-standard
50
TsangandStevenson AGraph-TheoreticFrameworkforSemanticDistance
Table7
Averageclassiﬁcationresultsofthenetworkﬂowmethodusing200,100,and50trainingdata
perclassiﬁcationtask.Theweightedaverageiscalculatedbasedonthenumberoftestinstances
pertask.
NamePair NumberofTrainingInstances
200 100 50
Ronaldo/Beckham 0.80 0.79 0.76
Tajik/Ekeus 0.97 0.98 0.96
Microsoft/IBM 0.73 0.73 0.72
Peres/Miloˇsevi´c 0.96 0.97 0.94
Jordan/Egyptian 0.77 0.74 0.70
Japan/France 0.75 0.75 0.70
UnweightedAverage 0.83 0.83 0.80
WeightedAverage 0.77 0.76 0.72
proﬁlesto20and5instancespertask,andobserveacontinualdropinperformance.The
performanceofonetask(Ronaldo/David Beckham)dropsbelowchancewith20training
instancesandanother(Microsoft/IBM)dropsbelowchancewith5.Forthissetofdata,
we conclude that 50 instances per task are required to provide enough discriminatory
powerforourmethod.
Althoughunsupervisedmethodshavetheadvantageofrequiringnotrainingdata,
in our case, 50 to 100 training instances constitute only a very small portion of the
data, as well as a small amount of annotation effort in absolute terms. We conclude
thatthe(small)labellingeffortisjustiﬁedbytheperformancegainachievedusingour
minimallysupervisedapproach.
6.Task3:DocumentClassiﬁcation
DocumentclassiﬁcationisanNLPtaskinwhichapreviouslyunseendocumentisgiven
atopiclabel(orasetofsuchlabels)basedonitssubjectmatter.Forexample,aﬁnancial
documentdiscussingtheﬂuctuationofcrudeoilpricesmaybelabelled“commerce”or
“crude oil” in the Reuters Corpus (Lewis et al. 2004). In our version of the task, each
document has a single topic label. Document classiﬁcation is typically performed by
comparing the text of an unlabelled document to the text of documents whose topics
(labels)areknown,andassigningthelabeloftheclosestsuchdocument(Joachims2002;
Iwayamaetal.2003;Esuli,Fagni,andSebastiani2006;Nigam,McCallum,andMitchell
2006).Thistaskisthussimilartothenamedisambiguationtaskintheprevioussection,
andourapproachissimilaraswell:Hereagain,weformgold-standardproﬁlesfroma
smallcollectionoftextsofknownclasses,andthencompareeachtestinstancetoeach
ofthegold-standardproﬁles.Asinnamedisambiguation,weexperimentwithdifferent
amountsoftrainingdataforcreatingthegold-standardproﬁles.
There are two differences of note in comparison to name disambiguation. First, in
document classiﬁcation we use the entire set of words constituting the document to
createasemanticproﬁle,ratherthanasmallerwindowaroundatargetword.Second,
whereas each ambiguous name instance in the earlier task had exactly two potential
labels(andthusthereweretwogold-standardproﬁlesforcomparison),thenumberof
labelsinthedocumentclassiﬁcationtaskismuchlarger,leadingtomoreambiguityin
thetask.
51
ComputationalLinguistics Volume36,Number1
6.1ExperimentalSet-up
6.1.1 Corpus
Data. Ourdataisacorpusofarticlesfrom20differentUsenetnewsgroups
releasedbyMitchell(1999).Becauseeachnewsgroupcorrespondstoatopic,thearticles
canbeclassiﬁedusingthe(single)newsgrouplabel.Weusethecollectionmaintainedby
Rennie(2001),inwhichalltheduplicates(cross-posts)areremoved,resultingin18,828
articles. The articles are approximately evenly distributed among the 20 newsgroups.
Stopwordsandarticleheadersareremovedbeforeprocessingeachtext.
Work that relies on word frequency vectors to represent the texts in document
classiﬁcationhasrevealedtheimportanceofpreprocessingthewordfrequencydatato
emphasize those terms that are likely to be most meaningful. For example, word fre-
quencies have typically been weighted by inverse document frequencies (tf ·idf)to
lessen the impact of very common but less distinguishing words. According to
Rennie(2001),theirbestsystemonthesamecorpususesthe
logtf+1
logidf
weightingscheme.
In order to compare our system to theirs, we use this same word weighting scheme
in the creation of the word vectors that are used to produce our semantic proﬁles.
(We have experimented with using raw word frequencies as well as tf ·idf to pro-
duce proﬁles. Both methods yield approximately the same results as the
logtf+1
logidf
frequencyweightingscheme.)
6.1.2 Training
and Evaluation. Asmentionedbefore,wetreattheclassiﬁcationtasksimi-
larlytonamedisambiguation,takingaminimallysupervisedapproach.Werandomly
select a small number of documents as training data for creating the gold-standard
semantic proﬁles. We use 10 or 30 documents per newsgroup, or approximately 1–3%
of the documents. The remaining documents are used as testing data. Again, we use
a random sample of documents for each gold-standard proﬁle, repeated ﬁve times to
minimize the impact of a possible skewed sampling. We report the average accuracy
overtheﬁvesamples.
Because there are 20 possible topic labels, the random baseline is very low, at 5%.
(Usingthe predominant label raises thisonlyslightly.) Amore informative evaluation
ofourmethodistocomparetoastate-of-the-artapproachthatispurelydistributional.
A comparison to Rennie (2001) is natural, since we use the same data set. However,
they trained an SVM on 30 documents per class and tested on 10% of the documents,
repeated 10 times. Because our training approach differs somewhat (training on 10 or
30 documents per class, testing on all remaining documents, repeated 5 times), we
also replicate their SVM experiment using our training and test sets. As in the name
disambiguationtask,weusetheLIBSVMsoftwarepackage(ChangandLin2001)and
tunetheclassiﬁerinthetrainingphaseforthebestSVMparameterspriortothetesting.
Also as in our name disambiguation task, we additionally train and test the SVM on
just the nouns in a document (rather than all words), and also on the nouns mapped
toconcepts(withtherelevantfrequenciesasthefeaturevaluesinbothcases).Thuswe
reportresultsoftheSVMonthreedifferenttypesofinputfrequencyvectors:allwords,
nouns,andconcepts.
6.2ResultsandAnalysis
6.2.1 Initial
Results. Table 8 presents the classiﬁcation results using 10 and 30 training
documentsperclassforournetworkﬂowandSVMmethods.Ournetworkﬂowmethod
performs well above the random baseline, but is far from achieving state-of-the-art
results. The SVM experiments using all words in the document perform much better
thanournetworkﬂowmethod,andareconsistentwiththeaccuracyof68.7%achieved
52
TsangandStevenson AGraph-TheoreticFrameworkforSemanticDistance
Table8
Averageclassiﬁcationresultsusing10and30trainingdocumentspernewsgroup.
TrainingSize/Class SVM SVM SVM NF
Allwords Nouns(Words) NounConcepts
10 47.1 47.8 42.7 31.2
30 66.2 66.4 61.4 32.0
by Rennie (2001) using an SVM. One possible reason is that the SVM is trained on
all words (minus stopwords and article headers), whereas our network ﬂow method
applies to noun concepts only. The SVM performance on noun-only data is similar to
that of all words. Although there is a marked decrease in performance on the concept
frequencyvectors,SVMstilloutperformsourmethod.
The poorer SVM performance on concept frequencies suggests that concept fre-
quency vectors are less easily distinguishable than word frequency vectors. Recall,
however,thatwefoundnodifferencewiththesevarioustrainingapproachesforSVM
in name disambiguation. It is possible that the mapping from words to concepts is a
problemherebecausethefulltextisused,ratherthanarelativelysmallwindowaround
atargetword.Becauseeachwordcanmaptomultiple(potentiallyunrelated)concepts,
theuseofalarger,unconstrainedbagofwordsmayleadtoahighdegreeofambiguity,
introducingmorenoiseinthesemanticproﬁlethanourmethodcanhandle.Thismay
alsoexplainwhythenetworkﬂowmethoddoesnotimprovewithadditionaltraining
data, showing virtually no improvement between 10 and 30 training instances (0.8%
difference). We speculate that the amount of noise in a semantic proﬁle based on the
largeramountoftextmayincreasealongwiththeincreaseinthetrainingsize,offsetting
anypotentialgainfromhavingadditionaldata.
Ifthishypothesisiscorrect,itisnaturaltoaskwhytheSVMresultusingconcepts
showsasubstantialincreaseinaccuracyfrom10to30trainingdocuments.Iflargertexts
yieldnosiersemanticproﬁles,whydoesthisnotnegativelyaffecttheSVMaswell?This
highlights a fundamental distinction of our approach: our method is novel because it
ﬁndsthedistancebetweenconceptsasembeddedinagraph(theontology),notjustbetween
conceptvectors.Generally,ourthesisisthatthisisanadvantageofourmodel:Itentails
that all concepts generated from a text play a role in determining the distance of that
text from another. As we noted earlier, this allows us to ﬁnd similarity between texts
thatuserelatedbutnotequivalentconcepts.However,theperformanceofourmethod
inthisdocumentclassiﬁcationtaskrevealsapotentialdrawbackofthispropertyofour
method. Because it takes all concepts into account in determining distance, it is more
susceptibletonoise.Figure5illustratestheproblem.Weseethatthesquareandtriangle
proﬁlesarenoisy—thatis,theyeachhaveanumberofnodesthatarenotpartoftheir
coherent semantic content. These noisy aspects of the two proﬁles are less separated
in ontological space, making the two proﬁles more similar according to our measure
than their “true” semantic content would indicate. Because a vector representation of
concepts does not form connections between differing concepts, it is not led astray in
thewayourmethodis.
6.2.2 Removing
Noise from the Proﬁles.Ourconjectureisthatthepoorperformanceofour
networkﬂowmethodisduetonoisecausedbyambiguityinthemappingofeachword
toallofitsconcepts(i.e.,notjusttherelevantonestothetopic).Thiseffectcouldalsobe
53
ComputationalLinguistics Volume36,Number1
Figure5
Twonoisyproﬁles,onerepresentedbysquares,theotherbytriangles.
exacerbatedbythefactthat,inusingthefulldocument,wemayhaveahighernumber
of less relevant words than when a proﬁle is formed from a more constrained set of
words (as in verb alternation detection and name disambiguation). If this hypothesis
is true, then the noisy (irrelevant) concepts should be distributed within each proﬁle
accordingtosomepriorprobabilitydistribution.Ifweknewthatdistribution,thenwe
could“subtractout”thenoiseandformmoresemanticallycoherentproﬁles.Referring
toFigure5,theideaisthatwewouldliketoremovethesmall,dispersedsquaresand
triangles,leavingonlythelargeronesthatformasemanticallymorecoherentset.
We test this idea, experimenting with two possible noise distributions. The ﬁrst is
simply the uniform distribution, and the second is a distribution determined empiri-
callyusingfrequencycountsfromadomain-generalcorpus.Forthelatter,wedetermine
a distribution over concepts based on the nouns in the BNC. Because the BNC is a
balancedcorpus,thedistributionofitsnounscanbeconsideredapriorthatistreatable
as noise compared to the distribution in a newsgroup posting that is speciﬁc to a
particular topic. In each case, we create a semantic proﬁle representing the expected
noise, and then “subtract” the resulting noise proﬁle from each of our gold-standard
semantic proﬁles in the document classiﬁcation task. The “subtraction” is actually a
process of setting to zero all of the semantic proﬁle frequencies that are less than the
noise value for that concept. Any node with a value higher than the noise value for
thatnodeisexpectedtobeapotentiallyrelevantconcept.Weleavesuchnodesattheir
originalvaluesothattheyaremoredistinguishedfromtheremainingvalues(nowset
to zero). Figure 6 illustrates the result of applying this kind of noise reduction to the
proﬁlesinFigure5.Wecanseethatlow-frequencyconceptnodesarezeroedout,with
higherfrequencynodesmaintainingtheirconceptweight.
Table 9 presents the network ﬂow results on the noise-subtracted data, showing a
3–5% increase in the performance using 30 training documents per class. The perfor-
mancedecreaseswithnoise-subtractionwhenwehaveonly10trainingdocumentsper
class, suggesting that there may not be enough data in this case to use this simplistic
subtractivemethod.
Interestingly,subtractingtheuniformnoisedistributionfromtheproﬁleshasamore
favorable effect than subtracting the BNC noise distribution. The BNC distribution is
perhaps inappropriate for our data. Newsgroup data includes a variety of subjects
54
TsangandStevenson AGraph-TheoreticFrameworkforSemanticDistance
Figure6
ThesametwoproﬁlesinFigure5.Theproﬁlemassesthatare“subtracted”areshadedingray.
which may make it more similar to a balanced corpus than we have originally antic-
ipated,thuswhatwearetreatingasa“noise”distributioninthiscasemaynotactually
represent noise. That said, there is a small but notable increase even using the BNC
noise distribution when we have sufﬁcient training data. The idea of subtracting out
noise seems promising, but we leave the appropriate representation of noise, and the
mechanismforremovingiteffectively,asanareaoffutureresearch.
7.ProﬁleDensity:AMeasureofCoherenceofSemanticProﬁles
We have seen a performance difference across the three tasks we used in evaluation:
thenetworkﬂowmethodoutperformspurelydistributionalmeasuresonverbalterna-
tion detection and name disambiguation, but does poorly on document classiﬁcation
comparedtoadistributionalapproach.(SeeTable10forasummaryoftheresults.)We
usethesameontology(WordNet)andthesameconceptdistance(numberofedges)in
our network ﬂow measure across all three tasks, hence there must be some difference
in the three data sets themselves that impacts the ability of our method to distinguish
the semantic proﬁles corresponding to one class of data (one usage of an ambiguous
name,forexample)fromtheproﬁlesofadifferentclassofdata(theotherusageofthe
name).Inthissection,wedevelopameasurethatcancapturethispropertyandexplain
theperformancedifferentialwehaveobservedforourmethod.
Table9
Averageclassiﬁcationresultsusing30and10trainingdocumentspernewsgroup,usingthe
originalproﬁles(NF),andusingproﬁlesafterthe“noisesubtraction”processdescribedinthe
text(“NF−Uniform”and“NF−BNC”areresultssubtractingtheuniformdistributionand
theBNCnounfrequencydistribution,respectively).
TrainingSize/Class NF NF−Uniform NF−BNC
10 31.2 28.2 27.4
30 32.0 37.2 35.6
55
ComputationalLinguistics Volume36,Number1
Table10
Summaryoftask-basedresults.Thenumbersinparenthesesindicatethenumberoftraining
instancesused.Thebestresultforeachtaskisshowninbold.
VerbAlternationDetection random Manhattan skewdiv JS NF
Dataset1Avg 0.50 0.70 0.57 0.67 0.70
Dataset2Avg 0.50 0.67 0.67 0.67 0.67
NameDisambiguation random SVM(100) SVM(200) NF(100) NF(200)
UnweightedAvg 0.61 0.72 0.75 0.83 0.83
WeightedAvg 0.53 0.52 0.55 0.76 0.77
DocumentClassiﬁcation random SVM(10) SVM(30) NF(10) NF(30)
20newsgroups 0.05 0.43 0.61 0.31 0.32
7.1ProﬁleCoherence
Ourgoalistoﬁndapropertyofindividualsemanticproﬁlesthat,whenaveragedacross
the proﬁles in a data set, indicates whether our method will be able to distinguish
proﬁles of different classes in that data set. That is, we aim to learn about the overall
separability of the classes in a data set by investigating the properties of individual
proﬁlesthatconstitutethedataset.Ourhypothesisisthattheimportantfactorforour
method is what we refer to as proﬁle coherence: the degree to which proﬁle mass is
concentratedwithinaconstrainedspace(orsetofconstrainedspaces)oftheontology.
Themorespatiallycoherentthesetsofweightedconceptsarefortheproﬁlesinadata
set,themorelikelyitisthatourmethodwillbeabletodistinguishcontrastingproﬁles.
Conversely, less coherent proﬁles, whose frequency mass is more distributed across a
wider area of the ontology, will be more difﬁcult to separate into classes. (Note that
proﬁlecoherenceisnotasufﬁcientconditionfordataseparability,butwehypothesize
thatitcanbeausefulindicator.)
Forexample,considerthesquareandtriangleproﬁlesinFigure7.Coherentproﬁles
have their proﬁle mass (the concept weights) focused within small, distinct regions of
theontology,asinFigure7(a).Thesetypesofproﬁlestendtobehighlydistinguishable
fromeachother.Lesscoherentproﬁles,whosemassismoredispersedthroughtheon-
tology,suchasthoseinFigure7(b),arelikelytobelessdistinguishable.Note,however,
thatitisnotsimplyoccupyinggreaterorfewernodesinthehierarchythatdetermines
proﬁle coherence (and distinguishability). The proﬁles in Figure 7(c) are “spread out”
asin(b),butaremorecoherent(anddistinguishable)duetohavingareasofhighmass.
TheconsiderationsillustratedinFigure7suggestthatbothdistributionalandonto-
logicalfactorscontributetothecoherenceofasemanticproﬁle,andthatwemustdeter-
mineasuitablemeasureofcoherencethatcapturesbothfactors.Asimpler,alternative
hypothesis is that either purely distributional or purely ontological factors may sufﬁ-
cientlycapturethecoherenceofasemanticproﬁle.Toexploretheseideas,weexamine
differentwaystoassessthecoherenceofthesemanticproﬁlesinourexampledatasets.
We develop various measures of coherence, and then evaluate whether the degree of
coherence as determined by each measure indeed corresponds to the performance of
56
TsangandStevenson AGraph-TheoreticFrameworkforSemanticDistance
Figure7
Examplesoftwoproﬁles(indicatedbysquaresandtriangles)ofvaryingcoherence.Theproﬁles
in(a)aremoredistinguishablethanthosein(b)and(c);theproﬁlein(c)isinturnmore
distinguishablethanthatin(b).Thedegreeofdistinguishabilityoftheseproﬁlesisreﬂectedin
theirdegreeofcoherence.
ournetworkﬂowmethodonthedatasetsinourthreetasks.Weexpectausefulmeasure
of proﬁle coherence to have a high average value across the data sets on which we
perform well (verb alternation and name disambiguation), and a low average value
acrossthedatasetonwhichweperformpoorly(documentclassiﬁcation).
In Section 7.2, we brieﬂy review several measures intended to separately capture
the distributional or ontological coherence of a semantic proﬁle. We show that such
measuresareinsufﬁcientforaccountingfortheperformancedifferencesofourmethod
acrossthedatasets.InSection7.3,wedevelopanovelmeasuretocapturethecoherence
ofourproﬁlesintermsofbothdistributionalandontologicalinformation.Thismeasure,
calledproﬁledensity,expressesthedegreetowhichasemanticproﬁleformsacoherent
clusteringofweightedconceptsinanontology.Wedemonstratethatourproﬁledensity
measurecanaccountfortheperformancedifferentialacrossourdatasets.
7.2SeparateDistributionalandOntologicalApproaches
Weexploredseveral(unsuccessful)meansforcapturingproﬁlecoherencewithapurely
distributional or purely ontological measure. Although we could not exhaustively
investigate all possible measures of this kind, the underlying reasons for the lack of
successofthesemeasuresinexplainingthedifferingperformanceofourmethodacross
57
ComputationalLinguistics Volume36,Number1
thedatasetsconvincedusoftheneedforameasurethatintegratesdistributionaland
ontologicalfactors(whichwepresentinthefollowingsection).Wementionthesingle-
factormeasureshereforcompleteness.
7.2.1 Potential
Distributional Coherence. Recall that Section 6.2.2 shows that removing
the “noise” distribution from each proﬁle improves the document classiﬁcation per-
formance of our method. In other words, subtracting the noise distribution from a
proﬁle can make it distributionally more distinct from other proﬁles. Based on this
observation, we hypothesize that the less a proﬁle resembles a noise distribution over
the ontology, the more coherent it is—that is, the more likely the frequency mass is
situated in meaningful clusters of concepts. To test this hypothesis, we calculate the
average distance (using KL-divergence [Kullback and Leibler 1951]) of the proﬁles in
a data set from a proﬁle created from a noise distribution (the uniform distribution
of words, or their distribution in the BNC, as in Section 6.2.2). Higher values of this
measureindicatefurtherdistancefromthenoisedistribution.
7.2.2 Potential
Ontological Coherence. Here we consider two observations. First, we
hypothesize that proﬁles with fewer concepts are more coherent, because a smaller
number of concepts is more likely to be less dispersed in the ontology. We simply
use average proﬁle size to capture this property (here, smaller values of proﬁle size
indicategreatercoherence).Second,wehypothesizethatproﬁleswhoseconceptshave
greaterspeciﬁcityaremorecoherent,becauseuseoflessspeciﬁcconceptsisindicative
of vagueness and potential lack of coherence. Because speciﬁcity corresponds well to
depth in WordNet, we use a simple measure of average proﬁle depth to indicate the
speciﬁcityofthesetofconceptsinaproﬁle(here,greatervaluesofdepthshouldindicate
greatercoherence).
7.2.3 Analysis
of the Single-Factor Measures. For each task, we calculate the average of
each of the hypothesized distributional and ontological coherence measures over the
proﬁles in the data set, and ﬁnd that there is no consistent correspondence with the
performance of our network ﬂow method across the tasks. Despite the intuitions and
observationspresentedherein,theseresultsarenotsurprising.Forexample,theproﬁles
of a data set may all be distributionally very similar overall to the noise proﬁle, sup-
posedlyindicatinglowcoherence,buttheymaybequitecoherentintheactualontolog-
icalspacetheyoccupy.Similarly,theproﬁlesinadatasetmayallhaveasmallaverage
depth in the ontology or large size (again supposedly indicating low coherence), but
theirdistributionalproperties(theweightsontheconceptsthatareoccupied)mayyield
coherentclustersofmassintheproﬁle.Thisanalysisthenconﬁrmsourhypothesisthat,
becausedistributionalandontologicalinformationareintertwinedintherepresentation
of a semantic proﬁle, a useful measure of proﬁle coherence must take into account an
integrationofthesetwoinformationsources.
7.3IntegratingDistributionalandOntologicalFactorsinaCoherenceMeasure
As noted earlier, and tentatively conﬁrmed by the results herein, we assume that the
interaction of distributional and ontological factors determines the coherence of pro-
ﬁles (i.e., a coherent proﬁle has its frequency mass concentrated within a reasonably
constrained space [or set of constrained spaces] of the ontology). We observe that this
is similar to the geographical notion of population density, which is determined by
the population mass divided by the area occupied. Here we extend the geographical
58
TsangandStevenson AGraph-TheoreticFrameworkforSemanticDistance
Figure8
Twoexamplesofproﬁledensitywithinanontology.Thehollowtrianglesarethecommon
ancestorsoftheﬁlledtriangles,whichareconceptnodesintheproﬁle.Theproﬁlein(a)isfairly
dispersed,requiringasinglebutdistantancestornode.Theproﬁlein(b)ismoreclustered;two
ancestornodesarerequiredbuteachisclosetoitsdescendants.
deﬁnition of density within our network framework by relating population mass to
distributional weights on concepts, and occupied area to the spread of the weighted
concepts in the ontology. We call the resulting measure of proﬁle coherence proﬁle
density.
7.3.1 The
Proﬁle Density Measure. Toadaptthedeﬁnitionofgeographicaldensitytoour
problem,weﬁrstneedtodeterminetheanalogsofpopulationmassandoccupiedarea
in a semantic proﬁle. The proﬁle mass at each concept node is directly analogous to
thepopulationmass.Deﬁningtheoccupiedareawithinanontologyisnotasstraight-
forward,asthereisnosimpledeﬁnitionofareawithinagraph.Forexample,Agirreand
Rigau(1996)usethenumberofnodeswithinasubgraphasitsarea,butthisfailstotake
intoaccounthowdispersedthenodesarethroughouttheontology.Weinsteaddevelop
a deﬁnition of area that captures the actual spatial spread of the proﬁle mass through
theontology.
To begin, we note that any subgraph of the WordNet hypernym hierarchy is hi-
erarchical itself. Thus, any region of the ontology that contains some proﬁle mass is
a hierarchy rooted at some common ancestor of those proﬁle nodes.
10
As shown in
Figure8,themoredispersed(lesscloselyclusteredtogether)asetofnodesis,thefurther
awaytheircommonancestoris.Thatis,ahighlyrelated(andspatiallyconstrained)set
of concept nodes can be generalized to a more speciﬁc ancestor concept (i.e., near the
descendants, as in Figure 8(b)), whereas a semantically distant set of concepts will be
generalized to a semantically general ancestor concept (i.e., far from the descendants,
as in Figure 8(a)). The ontological distance between a set of nodes and their common
ancestorthusindicateshowcloselyclusteredthedescendantnodesare.
Next note that any semantic proﬁle can be represented by aset of ancestor nodes,
andtheseancestornodescapturethespatialclusteringsoftheproﬁlemass.Forexample,
10 AlthoughWordNetcontainsinstancesofmultipleinheritance,therateislow.Asaresult,thelikelihood
ofasetofproﬁlenodessharingmultipleancestorsislowaswell.
59
ComputationalLinguistics Volume36,Number1
Figure9
Thesetwoproﬁleshaveequaldensityvaluegivenouroriginalproﬁle densityformulain
Equation(5),butaresuitabledistinguished(withtheproﬁlein(b)havinghigherdensitythan
thatin(a))bythenorm densityformulainEquation(6).Seethetextfordiscussion.
theproﬁleinFigure8(a)isrepresentedbyoneancestornode,andthatinFigure8(b)by
twosuchnodes.Combiningtheseobservations,weseethatgivenasuitablemannerfor
identifyingancestornodestorepresentaproﬁle,wecanusethecombinedontological
distance between each of those nodes and their descendants as an indication of how
closely clustered the concepts of the proﬁle are. We can now complete our deﬁnition
of proﬁle density by using the total distance between each identiﬁed ancestor and its
descendantsasanindicationoftheoccupiedareaoftheontology.
Formally, let P be a proﬁle and A be a set of ancestor concept nodes such that
each proﬁle node d ∈ P is guaranteed to have an ancestor a ∈ A. (We will explain in
Section7.3.2howtoﬁndthesetA.)TheproﬁledensityofPisthendeﬁnedasfollows:
proﬁle density(P)=
summationdisplay
a∈A
summationdisplay
d∈P,
d∈descendant(a)
mass(d)
distance(d,a)
(5)
where mass(d)istheproﬁlemass(conceptfrequency)atnode d,anddistance(d,a)isthe
distanceintheontologybetweennode d andnode a,asgivenbyasuitableconcept-to-
conceptdistancemeasure(suchastheedgedistancethatwehaveusedinourtask-based
evaluations).
There is one more subtle detail we must address. Consider the two examples in
Figure9,wherethedistancebetweeneachancestorandallitsdescendantsisthesame
(here, say, a distance of 1), but the distribution of the proﬁle mass differs. The ﬁrst
diagram hasten equally weightedproﬁle nodes, andthe second hastwo. Our current
formulationinEquation(5)yieldsadensityof1forbothdiagrams(i.e.,(0.1/1)×10=
1=(0.5/1)×2). However, the proﬁle mass in diagram (a) is distributed among more
nodesthanthatindiagram(b).Intuitively,thesecondproﬁleismoredenselyclustered
andshouldhaveahigherdensityvalue.
Looking more closely at our density formula in Equation (5), observe that the
number of proﬁle nodes has an impact on the calculation—that is, density increases
asthenumberofproﬁlenodesincreasesduetotheinnersummationintheformula.To
60
TsangandStevenson AGraph-TheoreticFrameworkforSemanticDistance
achieveanappropriatedensitymeasure,then,wenormalizetheoriginaldensityvalue
bythenumberofproﬁlenodes,resultinginanormalizeddensityforaproﬁle:
norm density(P)=
density(P)
sizeof(P)
=
1
sizeof(P)
summationdisplay
a∈A
summationdisplay
d∈P,
d∈descendant(a)
mass(d)
distance(d,a)
(6)
ReturningtoourexampleinFigure9,Equation(6)assignstheﬁrstproﬁleanormalized
densityof0.1,andthesecondproﬁleanormalizeddensityof0.5.Themodiﬁedmeasure
nowappropriatelydistinguishesthetwoproﬁledensities,indicatingthattheproﬁlein
Figure9(a)islesstightlyclusteredthantheproﬁleinFigure9(b).
7.3.2 Finding
the Ancestor Set for Proﬁle Density.Asnotedearlier,ourdeﬁnitionofproﬁle
density depends on identifying a suitable set of ancestor nodes of the concept nodes
in the proﬁle: the aggregate distance of the ancestors to the proﬁle nodes indirectly
indicates the degree to which the proﬁle nodes are spatially clustered close together.
Thus, given a proﬁle P, we need to ﬁnd A, the set of nodes that are ancestors of the
proﬁle nodes d ∈ P. (The nodes a ∈ A correspond to the hollow triangles indicated in
Figure 8 and Figure 9.) Recall that these ancestor nodes are intended to be a set of
concepts that serve as an appropriate generalization of the nodes in the proﬁle—each
ancestor inasense represents acoherent cluster ofproﬁlenodes. However, wedonot
knowaprioriwhattheappropriatelevelofgeneralizationis—wesimplywantalevel
thatgivesausefulassessmentofhowclusteredtogethertheproﬁlenodesare.
Forthispurpose,wemakeuseofClarkandWeir’s(2002)methodforgeneralizing
a set of weighted concept nodes in an ontology. As we noted in Section 4, given a
frequencydistributionoverallconceptnodes,ClarkandWeiruseastatisticalmethodto
searchforthesetofnodes(i.e.,ournodesetA)thatbestgeneralizetheoriginalweighted
concepts.Thismethodisparticularlyappropriateforourpurposesbecauseitincludesa
parameter,α ∈ (0,1),thatcontrolsthelevelofgeneralization.Wevaryαoverﬁvevalues
(0.05, 0.25, 0.5, 0.75, and 0.95) to obtain ﬁve different (more toless generalized) sets of
ancestors. In our analysis, we calculate the density using each ancestor set in order to
evaluatetheimpactoftheprecisechoiceofancestornodesonourmeasure.
7.3.3ResultsandAnalysis.Foreachofthethreetasksinourearliertask-basedevaluation,
we calculate the proﬁle density of the corresponding data set. We deﬁne the proﬁle
densityofadatasettobetheaverageofthenormalizeddensityvaluesoveritsproﬁles.
Fortheverbalternationdetectiontask,weperformtheanalysisonall240proﬁlesused
inthetask(120verbs,with2proﬁlesperverb,oneforthesubjectslot,onefortheobject
slot). In the remaining two tasks, because each instance proﬁle is compared to a gold-
standardproﬁle,webelievethattheperformancedependsprimarilyonthecoherenceof
thegold-standardproﬁles.Wethusperformouranalysisonthegold-standardproﬁles
only.Fornamedisambiguation,wehave60proﬁles(5samplingswith12gold-standard
proﬁles each); for document classiﬁcation, we have 100 proﬁles (5 samplings with 20
gold-standardproﬁleseach).Foreachproﬁle,wecalculatethenormalizeddensityusing
each of ﬁve ancestor sets (based on the α value, as noted above). For the concept-to-
conceptdistancemeasure,distance(d,a)inEquation(6),weuseedgedistance,thesame
measureusedinthetasksinearliersectionsofthepaper.
61
ComputationalLinguistics Volume36,Number1
Table11
Theproﬁledensityscoresforeachdatasetatﬁvedifferentvaluesofα,aswellastheaverage
scoresacrosstheαvalues.
αvalue 0.05 0.25 0.5 0.75 0.95 Avg
VerbAlternation 5.59e-4 5.90e-4 6.32e-4 7.14e-4 8.87e-4 6.76e-4
NameDisambiguation(200) 8.93e-5 9.89e-5 1.08e-4 1.18e-4 1.35e-4 1.10e-4
NameDisambiguation(100) 1.11e-4 1.26e-4 1.38e-4 1.52e-4 1.78e-4 1.41e-4
DocClassiﬁcation(30) 5.25e-5 5.94e-5 6.59e-5 7.43e-5 8.78e-5 6.80e-5
DocClassiﬁcation(10) 8.03e-5 8.85e-5 9.87e-5 1.11e-5 1.33e-5 5.84e-5
We expect that, if our proﬁle density measure does indeed reﬂect the coherence
of a data set, then we will see a correspondence between the density values and the
performance of our network ﬂow method. Higher density values indicate a proﬁle
whose weighted concepts form more coherent clusters in the ontology. Speciﬁcally,
then, we expect higher density values for the data sets from our verb alternation de-
tectionandnamedisambiguationtasks(onwhichourmethodhadbetterperformance
thandistributionalmethods),andlowerdensityvaluesforthedocumentclassiﬁcation
data set (on which our method had worse performance than a purely distributional
method).
11
Table 11 shows the proﬁle densities of each data set. First note that the density
values are relatively stable across all values of α, indicating that the precise level of
generalization is not critical to the usefulness of our density measure. Next, observe
that, as predicted, the document classiﬁcation data set is shown to have the lowest
density for both training set sizes. This observation is in accord with our hypothesis
thattheproﬁledensitymeasureindicatesthecoherenceoftheproﬁlesinadatasetand
isthereforeinformativeaboutthenetworkﬂowperformanceonthatdataset.
Interestingly,wealsoobservethat,acrossallvaluesof α andtrainingsetsizes,the
verbalternationdatasethasthelargestdensities,followedbythenamedisambiguation
dataset,thenthedocumentclassiﬁcationdata.(Thedifferencesbetweenallthreedata
sets are statistically signiﬁcant, plessmuch0.05.) This result might stem from the fact that
there are varying degrees of constraint placed upon the data in the three tasks. In
verb alternation, the nouns used to generate a proﬁle appear either all in the subject
or all in the object position of the target verb. In name disambiguation, we loosen the
restrictiontoincludeallnounsinasmallwindowsurroundingthetargetword.Lastly,
indocumentclassiﬁcation,theonlyrestrictiononthenounsusedtogenerateaproﬁle
isthattheyappearinthesamedocument.Thissuggeststhatthesyntacticandsemantic
constraintsplaceduponasetofnounscanhaveanimpactonthecoherenceoftheproﬁle
createdfromthem.
This latter observation suggests that our proﬁle density measure may be useful
not only in indicating the ability of our network ﬂow method to distinguish relevant
proﬁles.Moregenerally,itmayalsoreﬂectthevaryingdegreesofsyntacticandsemantic
11 Notethatbecauseourmethodineachtaskiscomparedtodifferentkindsofalternativedistributional
methods,wedonotexpecttoﬁndamathematicalcorrelationbetweentheperformanceimprovement
andthedensityvalues;rather,goodperformanceshouldbereﬂectedinhigherdensityvaluesandpoor
performanceinlowerdensityvalues.
62
TsangandStevenson AGraph-TheoreticFrameworkforSemanticDistance
constraints placed upon the set of words that generate a proﬁle. Our proﬁle density
measuremayindeedbegenerallyusefulasameasureofthesemanticcoherenceofaset
ofconceptsinanontology(Gurevychetal.2003),amatterweplantoexploreinfuture
work.
In summary, our analysis in this section has shown that both distributional and
ontological properties contribute to the coherence of a proﬁle, but neither alone is
indicative of the network ﬂow performance in a particular task. Our new measure of
proﬁledensityservesasatoolforanalyzingproﬁlesthatintegratestheirdistributional
and ontological coherence, and provides a post hoc means for explaining the perfor-
mance differential of our method across the different tasks we performed here. The
resultsalsopointtothepossibilityofdevisingadiagnostictoolforthesuitabilityofthe
networkﬂowmethodonnoveldata.Ananalysisofthedataandresultsacrossalarger
setoftaskswillallowustoinvestigatethepossibilityofdeterminingadensitythreshold
thatwouldbeindicativeofexpectedpositiveresultswithourmethod.
8.RelatedWork
Tothebestofourknowledge,ourmethodistheonlyworkthatmeasurestextdistance
by combining ontological knowledge and distributional information together via a
graph-based algorithm. Although there are existing methods that use either or both
typesofinformationinmeasuringthesemanticdistanceoftexts(CorleyandMihalcea
2005;MohammadandHirst2006),ourworkisuniqueinthatitintegratestheontolog-
ical distance between individual words across two texts as well as the distributional
differences between the texts. Here we review existing work on both text comparison
and graph-based approaches in CL, given the relevance of these two areas to our
research.
8.1TextComparison
Our work stems from the studies on measuring the semantic distance between two
words or concepts using an ontological resource (which is extensively covered in
Pedersen,Banerjee,andPatwardhan[2005]andBudanitskyandHirst[2006]).Toextend
these methods for the comparison of two texts, we incorporate ontological distance
betweenconceptsanddistributionalinformationinasystematicandefﬁcientmanner.
Other research that attempts to include the two takes a more modular approach. For
example, Corley and Mihalcea (2005) consider the ontological distance between the
conceptsrepresentingthetextsbutignoretheirdistributionalinformation.Ontheother
hand,ScottandMatwin(1998),McCarthy(2000),andMohammadandHirst(2006)take
the distributional distance between concept vectors representing the texts but do not
considertheontologicalrelationsamongtheconcepts.
Most recent work on text comparison tends to be word-based and distributional
(Lee 2001; Weeds, Weir, and McCarthy 2004; Pedersen, Purandare, and Kulkarni 2005;
Al-Mubaid and Umair 2006). In the case of high dimensionality and data sparseness,
words are grouped into a smaller number of (unnamed) concepts using some matrix
factorization technique (e.g., SVD) or some clustering method (Pereira, Tishby, and
Lee 1993). In other words, words are grouped together based on their distributional
propertiesinsteadoftheirexplicitsemantic/ontologicalproperties.Furthermore,unlike
in our method, once the words are collapsed into unnamed concepts, the individual
elements(i.e.,theunnamedconcepts)acrossdatapointscannotbecompared.Asshown
63
ComputationalLinguistics Volume36,Number1
inourexperiments,takingintoaccountthisextrapieceofinformationisbeneﬁcialfor
someapplications.
8.2GraphApproaches
Inrecentyears,wehaveseenanincreasinguseofgraph-basedmethodsinNLP(Pang
andLee2004;Mihalcea2005;NavigliandVelardi2005).Thegraph-theoreticapproach
is popular due to the elegance of representing appropriate NLP problems and the
availability of a number of efﬁcient algorithms. One of the most straightforward NLP
examplesistheuseofWordNet.Besidesourworkhere,muchpriorresearchhastaken
advantage of the graphical structure of WordNet. For example, Agirre and Rigau’s
(1996) conceptual density uses WordNet as a graph and calculates the density within
asubgraph (thenumber ofrelevant conceptswithinasubgraph), whichwasfoundto
beusefulforWSD.
Graphsingeneralaretheobviousmathematicalformalismtoencodetherelation-
ships(representedasedges)betweeneitherwordsorlongerunitsoftext(represented
as nodes). (The reverse is possible, using nodes to represent relations and edges for
semanticentities.ThechoiceofrepresentationclearlydependsontheNLPtaskitself.)
Onceweformulateaproblemintoastandardgraphproblem,thereareexistingefﬁcient
graph-based algorithms that we can use to ﬁnd an optimal or near-optimal solution.
Forexample,bothPangandLee(2004)andBarzilayandLapata(2005)useaminimum-
cutalgorithmfortwovastlydifferentapplications,documentpolarityclassiﬁcationand
content selection, respectively. In these approaches, the sentences are represented as
nodes in a graph, and the edge connecting each pair of nodes is weighted with an
association score between the sentences, reﬂecting, for example, the distance (number
of sentences) between a pair of sentences. The minimum-cut method allows them to
classifythenodes,andthusthesentences,intodifferentcategories.
Anotherpopulargraphmethodistherandomwalkalgorithm,whichissuccessfully
employed by the PageRank approach for ranking Web pages (Brin and Page 1998).
Similar to the minimum-cut algorithm, here, nodes represent semantic entities (e.g.,
words),andedgesrepresentassociationsbetweenthenodes(e.g.,wordco-occurrence).
The random walk algorithm allows for the classiﬁcation of each node based on the
relevance of its neighbors. For example, Mihalcea (2006) uses random walk for WSD
byconstructingagraphinthefollowingway.Eachnoderepresentsanambiguous(test)
word,ora(training)wordlabelledwithoneofitssenses.Eachedgeindicatesthatthe
corresponding two words co-occur in some context. The sense of an ambiguous word
is determined by the sense of its most relevant neighbor(s), by randomly traversing
the graph until an equilibrium state has been reached. Hughes and Ramage (2007)
also use a random walk method, with the goal of determining semantic relatedness
betweenindividualwords(notsetsofwords,asinourwork).Intheirwork,therandom
walkmethodcomputesaprobabilitydistributionoverWordNetconcepts.Notethatthe
probability distributions resulting from random walks centered at different concepts
in WordNet are distinct. One can then measure the semantic relatedness between two
concepts by calculating the divergence between their probability distributions over
WordNetconceptsasaresultofthetworandomwalkscenteredatthem.
In comparison to other graph approaches to NLP, we choose to use a minimum-
cost ﬂow algorithm based on our graph formulation. Because a proﬁle is a collection
of frequency-weighted concepts, some concept nodes are weighted more heavily than
others, therefore the routes between such nodes across the two proﬁles are also
weightedmoreheavily.Analgorithmsolvingaminimum-costﬂowproblemprovides
64
TsangandStevenson AGraph-TheoreticFrameworkforSemanticDistance
an efﬁcient mechanism to ﬁnd these weighted routes as our solution, making MCF,
rather than the shortest paths or maximum-ﬂow-minimum-cut, the best choice for
formalizingtheconstraintswedeﬁneinthetextcomparisonproblem.
9.Conclusion
Wehavepresentedagraph-theoreticapproachtocalculatingsemanticdistancebetween
twotexts,whichencompassesbothontologicalknowledgeanddistributionalinforma-
tion.Wehavedevelopedanetworkﬂowmethodthattakesadvantageofthegraphical
structureofanontology.Givenasuitableontology,awordfrequencyvectorforatext
can be transformed into a frequency distribution over concept nodes. Hence, we treat
textsasweightedsubgraphswithinalargergraph(theontology).Byincorporatingthe
semantic distance between individual concepts, the graphical structure representing
the ontology becomes a metric space in which we can measure the distance between
subgraphs,weightedbytheirfrequencies.
Inthisarticle,weuseedgedistanceexclusivelyfortheindividualdistancebetween
concepts. Given that the distance between concepts is an integral part of our for-
mulation, and that other sophisticated concept-to-concept distances have been shown
to outperform edge distance for comparing concepts (Jarmasz and Szpakowicz 2003;
Weeds 2003), we also investigate the use of such distances. However, incorporating
them can lead to a quadratic growth in complexity. To remedy this, a pre-processing
stepisrequiredtoreducethecomplexitytoreasonablecomputationtime.InTsangand
Stevenson(2006),weintroduceonesuchmethodbyperformingagraphtransformation
ontheoriginalnetworkpriortothenetworkﬂowcalculation.Thetransformednetwork
ismoreefﬁcienttoprocesswithoutcompromisingtheperformanceaccuracy.Werefer
thereadertothatpaperforfurtherinformation.
Inthetask-basedevaluationpresentedhere,ourmethodhasbeenshowntoprovide
superiorperformanceonverbalternationdetectionandnamedisambiguation,incom-
parison to alternative distributional approaches—even in cases where the alternative
methods have attempted to incorporate additional semantic knowledge (McCarthy
2000;Pedersen,Purandare,andKulkarni2005).Unlikeexistingdistributionaldistances
and clustering techniques, the use of our text representation as well as the integration
of ontological distance allows a systematic way of capturing appropriate semantic
distinctionsbetweenthetextsinthesetasks.
In contrast, our method does not perform as well on document classiﬁcation as a
state-of-the-art machine learning algorithm using a purely distributional approach. In
ordertoexaminetheperformancediscrepancyacrosstasks,weexploremeasuresofthe
coherence of the proﬁles in a data set, as potential indicators of how easily semantic
proﬁles of different classes can be distinguished. The purely distributional and purely
ontologicalindicatorsweconsiderarenotusefulinexplainingtherelativelypoorper-
formanceofourmethodondocumentclassiﬁcation.Inresponse,wedevelopameasure
ofproﬁlecoherence,calledproﬁledensity,thatintegratesthesefactorsbydetermining
thedegreetowhichaproﬁleformsdistributionallyandontologicallycoherentclusters
of concepts. As a result, we are able to explain the performance of our method on the
datasetsintermsoftheirdensityvalues.
Recall also that we saw a performance difference in the verb alternation task de-
pendingonthedifferentmethodusedtogeneratethesemanticproﬁlesfromthebagof
wordsofthetext(i.e.,using“raw”data,versusamethodtogeneralizetothebestsetof
conceptsforthebagofwords).Givenalsothatwefoundthattheproﬁlesindocument
classiﬁcationhavealowdensity(i.e.,theirconceptsareoverlydispersed),onefocusfor
65
ComputationalLinguistics Volume36,Number1
futureworkwillbetoexplorefurthermeansforgeneratingproﬁlesthatbestcapturethe
intendedsensesofthewordswithinthetext.OneoptionmaybetouseMohammad’s
(2008) unsupervised method for building concept vectors from word frequency data,
which focuses the frequencies onto the most likely senses of the words according to
coarseontologicalcategories.
Another strand of future work relates to our proﬁle density measure. We suggest
thatnotonlyisourproﬁledensityusefulinpredictingtheperformanceofournetwork
ﬂowmethodonunseendata,itmayalsobeusefulformeasuringthesemanticcoherence
of a text. Note that a text that is semantically coherent tends to form proﬁles with
highly frequent and highly related concepts within an ontology. Coincidentally, our
proﬁle density formulation measures the overall relatedness, and thus coherence, of a
collectionofconceptsbytakingintoaccountthedistancebetweentheconceptsaswell
as the frequency distribution. For example, if we relax the notion of a text to include
verbal arguments, semantic coherence of a text can be thought of as the selectional
preference strength a verb imposes on its arguments. As future work, we intend to
investigateproﬁledensityasanindicatorofselectionalpreferencestrength.Generally,
webelieveproﬁledensitymayofferaquantitativemeasureforsemanticcoherenceand
otherrelatedNLPapplications.
Acknowledgments
Wewouldliketothankourcolleaguesin
Toronto,inparticularAfsanehFazlyand
theCLresearchgroupattheUniversityof
Toronto,forhelpfuldiscussions.Wewould
alsothanktheanonymousreviewersfor
theirdetailedcomments.Wegratefully
acknowledgetheﬁnancialsupportprovided
bytheNaturalSciencesandEngineering
ResearchCouncilofCanada(NSERC),
OntarioGraduateScholarship(OGS),
andtheUniversityofToronto.
References
Agirre,EnekoandGermanRigau.1996.
Wordsensedisambiguationusing
conceptualdensity.InProceedings of the
12th International Conference of
Computational Linguistics (COLING-1996),
pages16–22,Copenhagen.
Al-Mubaid,HishamandSyedA.Umair.
2006.Anewtextcategorizationtechnique
usingdistributionalclusteringand
learninglogic.IEEE Transaction on
Knowledge and Data Engineering,
18(9):1156–1165.
Barzilay,ReginaandMirellaLapata.2005.
Collectivecontentselectionfor
concept-to-textgeneration.InProceedings
of the Joint Conference on Human Language
Technology / Empirial Methods in Natural
Language Processing (HLT/EMNLP),
pages331–338,Vancouver,Canada.
Bodenreider,Olivier.2004.Theuniﬁed
medicallanguagesystem(UMLS):
Integratingbiomedicalterminology.
Nucleic Acids Research,32:D267–D270.
Brin,SergeyandLawrencePage.1998.
Theanatomyofalarge-scale
hypertextualWebsearchengine.
Computer Networks and ISDN Systems,
30(1–7):107–117.
Briscoe,TedandJohnCarroll.1997.
Automaticextractionofsubcategorization
fromcorpora.InProceedings of the 5th
Applied Natural Language Processing
Conference (ANLP),pages356–363,
Washington,DC,USA.
Briscoe,TedandJohnCarroll.2002.Robust
accuratestatisticalannotationofgeneral
text.InProceedings of the Third International
Conference on Language Resources and
Evaluation (LREC 2002),pages1499–1504,
LasPalmas,Spain.
Budanitsky,AlexandGraemeHirst.2001.
SemanticdistanceinWordnet:An
experimental,application-oriented
evaluationofﬁvemeasures.InProceedings
of the Workshop on WordNet and Other
Lexical Resources, in the North American
Chapter of the Association for Computational
Linguistics (NAACL-2001),pages29–34,
Pittsburgh,PA,USA.
Budanitsky,AlexandGraemeHirst.2006.
EvaluatingWordNet-basedmeasuresof
semanticdistance.Computational
Linguistics,32(1):13–47.
Burnard,Lou.2000.The British National
Corpus Users Reference Guide.Oxford
UniversityComputingServices,
Oxford,UK.
66
TsangandStevenson AGraph-TheoreticFrameworkforSemanticDistance
Chang,Chih-ChungandChih-JenLin,2001.
LIBSVM: a library for support vector
machines.Softwareavailableat
www.csie.ntu.edu.tw/∼cjlin/libsvm.
Chv´atal,Vaˇsek.1983.Linear Programming.
W.H.FreemanandCompany,NewYork.
Clark,StephenandDavidWeir.2002.
Class-basedprobabilityestimationusinga
semantichierarchy.Computational
Linguistics,28(2):187–206.
Corley,CourtneyandRadaMihalcea.2005.
Measuringthesemanticsimilarityoftexts.
InProceedings of the ACL Workshop on
Empirical Modeling of Semantic Equivalence
and Entailment,pages13–18,AnnArbor,
Michigan,USA.
Esuli,Andrea,TizianoFagni,andFabrizio
Sebastiani.2006.TreeBoost.MH:A
boostingalgorithmformulti-label
hierarchicaltextcategorization.In
Proceedings of the 13th International
Symposium on String Processing and
Information Retrieval (SPIRE’06),
pages13–24,Glasgow.
Fellbaum,Christiane,editor.1998.WordNet:
An Electronic Lexical Database.MITPress,
Cambridge,MA.
Gangemi,Aldo,NicolaGuarino,and
AlessandroOltramari.2001.Conceptual
analysisoflexicaltaxonomies:Thecaseof
WordNettop-level.InChrisWeltyand
BarrySmith,editors,Formal Ontology in
Information Systems: Collected papers from
the Second International Conference.ACM
Press,pages285–296,NewYork,USA.
Garey,MichaelR.andDavidS.Johnson.
1979.Computers and Intractability: A Guide
to the Theory of NP-Completeness.W.H.
FreemanandCo.,NewYork.
Gurevych,Iryna,RainerMalaka,Robert
Porzel,andHans-PeterZorn.2003.
Semanticcoherencescoringusingan
ontology.InProceedings of the Joint Human
Language Technology and Northern Chapter of
the Association for Computational Linguistics
Conference (HLT-NAACL),pages88–95,
Edmonton.
Han,Hui,HongyuanZha,andC.LeeGiles.
2005.Namedisambiguationinauthor
citationsusingaK-wayspectralclustering
method.InJoint Conference on Digital
Libraries (JCDL’05),pages334–343,Denver,
CO,USA.
Hirst,Graeme.2009.Ontologyandthe
lexicon.InSteffenStaabandRudiStuder,
editors,Handbookon Ontologies.
InternationalHandbooksonInformation
Systems.Springer,NewYork,
pages269–292.
Hughes,ThadandDanielRamage.2007.
Lexicalsemanticrelatednesswith
randomgraphwalks.InProceedings of
the Conference on Empirical Methods in
Natural Language Processing (EMNLP),
pages581–589,Prague.
Iwayama,Makoto,AtsushiFujii,Noriko
Kando,andYuzoMarukawa.2003.An
empiricalstudyonretrievalmodelsfor
differentdocumentgenres:Patentsand
newspaperarticles.InProceedings of the
26th ACM SIGIR International Conference on
Research and Development in Information
Retrieval,pages251–258,Toronto,Canada.
Jarmasz,MarioandStanSzpakowicz.2003.
Roget’sthesaurusandsemanticsimilarity.
InProceedings of Conference on Recent
Advances in Natural Language Processing
(RANLP 2003),pages212–219,Borovets.
Jiang,JayandDavidConrath.1997.Semantic
similaritybasedoncorpusstatisticsand
lexicaltaxonomy.InProceedings on the
International Conference on Research in
Computational Linguistics,pages19–33,
Taipei,Taiwan.
Joachims,T.2002.Learning to Classify Text
Using Support Vector Machines—Methods,
Theory, and Algorithms.Kluwer/Springer,
NewYork.
Kullback,S.andR.A.Leibler.1951.On
informationandsufﬁciency.Annals of
Mathematical Statistics,22:79–86.
Landauer,ThomasK.andSusanT.Dumais.
1997.AsolutiontoPlato’sproblem:The
LatentSemanticAnalysistheoryofthe
acquisition,induction,andrepresentation
ofknowledge.Psychological Review,
(104):211–240.
Lee,Lillian.2001.Ontheeffectivenessofthe
skewdivergenceforstatisticallanguage
analysis.InArtiﬁcial Intelligence and
Statistics,pages65–72.
Levin,Beth.1993.English Verb Classes and
Alternations: A Preliminary Investigation.
UniversityofChicagoPress,Chicago.
Levina,ElizavetaandPeterBickel.2001.
Theearthmover’sdistanceisthe
mallowsdistance:Someinsightsfrom
statistics.InProceedings of the Eighth
IEEE International Conference on Computer
Vision,volume2,pages251–256,
Vancouver,Canada.
Lewis,DavidD.,YimingYang,TonyG.Rose,
andFanLi.2004.RCV1:Anewbenchmark
collectionfortextcategorizationresearch.
Journal of Machine Learning Research,
(5):361–397.
Li,HangandNaokiAbe.1998.Word
clusteringanddisambiguationbasedon
67
ComputationalLinguistics Volume36,Number1
co-occurrencedata.InProceedings of
COLING-ACL 1998,pages749–755,
Montreal,Canada.
Lin,Dekang.1998.Aninformation-theoretic
deﬁnitionofsimilarity.InProceedings of
International Conference on Machine
Learning,pages296–304,Madison,
Wisconsin,USA.
McCarthy,Diana.2000.Usingsemantic
preferencestoidentifyverbal
participationinroleswitchingalternations.
InProceedings of Applied Natural Language
Processing and North American Chapter of the
Association for Computational Linguistics
(ANLP-NAACL 2000),pages256–263,
Seattle,Washington,USA.
Merlo,PaolaandSuzanneStevenson.2001.
Automaticverbclassiﬁcationbasedon
statisticaldistributionsofargument
structure.Computational Linguistics,
27(3):393–408.
Mihalcea,Rada.2005.Unsupervised
large-vocabularywordsense
disambiguationwithgraph-based
algorithmsforsequencedatalabeling.
InProceedings of the Joint Conference on
Human Language Technology / Empirial
Methods in Natural Language Processing
(HLT/EMNLP),pages411–418,Vancouver,
Canada.
Mihalcea,Rada.2006.Randomwalksontext
structures.InProceedings of Computational
Linguistics and Intelligent Text Processing
(CICLing) 2006,pages249–262,Mexico
City,Mexico.
Mitchell,Tom.1999.20newsgroupsusenet
articles.http://kdd.ics.uci.edu/
/databases/20newsgroups/
20newsgroups.data.html.
Mohammad,Saif.2008.Measuring Semantic
Distance using Distributional Proﬁles of
Concepts.Ph.D.thesis,Universityof
Toronto,Canada.
Mohammad,SaifandGraemeHirst.2006.
Distributionalmeasuresof
concept-distance:Atask-oriented
evaluation.InProceedings of the 2006
Conference on Empirical Methods in Natural
Language Processing (EMNLP 2006),
pages35–43,Sydney.
Navigli,RobertoandPaolaVelardi.2005.
Structuralsemanticinterconnections:A
knowledge-basedapproachtowordsense
disambiguation.IEEE Transactions on
Pattern Analysis and Machine Intelligence,
27(7),pages1075–1086.
Nigam,Kamal,AndrewMcCallum,andTom
Mitchell.2006.Semi-Supervisedtext
classiﬁcationusingEM.InOlivier
Chapelle,BernhardSch¨olkopf,and
AlexanderZien,editors,Semi-Supervised
Learning.MITPress,Cambridge,MA,
pages33–56.
Pang,BoandLillianLee.2004.A
sentimentaleducation:Sentiment
analysisusingsubjectivitysummarization
basedonminimumcuts.InProceedings of
the 42nd ACL,pages271–278,Barcelona,
Spain.
Pantel,PatrickandDekangLin.2000.An
unsupervisedapproachtoprepositional
phraseattachmentusingcontextually
similarwords.InProceedings of Association
for Computational Linguistics (ACL-00),
pages101–108,HongKong.
Pedersen,Ted,SatanjeevBanerjee,and
SiddharthPatwardhan.2005.Maximizing
semanticrelatednesstoperformword
sensedisambiguation.TechnicalReport
UMSI2005/25,UniversityofMinnesota,
Duluth.
Pedersen,Ted,AmrutaPurandare,and
AnaghaKulkarni.2005.Name
discriminationbyclusteringsimilar
context.InProceedings of the Sixth
International Conference on Intelligent Text
Processing and Computational Linguistics,
pages226–237,MexicoCity,Mexico.
Pereira,Fernando,NaftaliTishby,and
LillianLee.1993.Distributional
clusteringofEnglishwords.In
Proceedings of the 31st Annual Meeting
of the Association for Computational
Linguistics,pages183–190,Columbus,
Ohio,USA.
Pinker,Steven.1989.Learnability and
Cognition: The Acquisition of Argument
Structure.MITPress,Cambridge,MA.
Rennie,Jason.2001.Improving Multi-class
Text Classiﬁcation with Naive Bayes.
Master’sthesis,MassachusettsInstituteof
Technology,Cambridge,MA.
Resnik,Philip.1993.Selection and Information:
A Class-Based Approach to Lexical
Relationships.Ph.D.thesis,Universityof
Pennsylvania,Philadelphia,PA.
Resnik,Philip.1995.Usinginformation
contenttoevaluatesemanticsimilarityina
taxonomy.InProceedings of the 14th
International Joint Conference on Artiﬁcial
Intelligence,pages448–453,Montreal,
Canada.
Ribas,Francesc.1995.Onlearningmore
appropriateselectionalrestrictions.In
Proceedings of the Seventh Conference of the
European Chapter of the Association for
Computational Linguistics,pages112–118,
Dublin.
68
TsangandStevenson AGraph-TheoreticFrameworkforSemanticDistance
SchulteimWalde,Sabine.2006.Experiments
ontheautomaticinductionofGerman
semanticverbclasses.Computational
Linguistics,32(2):159–194.
Scott,SamandStanMatwin.1998.Text
classiﬁcationusingWordNethypernyms.
InProceedings of the COLING-ACL
Workshop on Usage of WordNet in Natural
Language Processing Systems,pages45–51,
Montreal,Canada.
Tsang,VivianandSuzanneStevenson.2004.
Calculatingsemanticdistancebetween
wordsenseprobabilitydistributions.In
Proceedings of the Eighth Conference on
Computational Natural Language Learning
(CoNLL-2004),pages81–88,Boston,
MA,USA.
Tsang,VivianandSuzanneStevenson.
2006.Contextcomparisonasaminimum
costﬂowproblem.InProceedings of
HLT-NAACL 2006 Workshop on
Textgraphs: Graph-based Algorithms for
Natural Language Processing,pages97–104,
NewYork,NY.
Weeds,Julie.2003.Measures and Applications
of Lexical Distributional Similarity.Ph.D.
thesis,UniversityofSussex,Sussex,UK.
Weeds,Julie,DavidWeir,andDiana
McCarthy.2004.Characterisingmeasures
oflexicaldistributionalsimilarity.In
Proceedings of the 20th International
Conference of Computational Linguistics
(COLING-2004),pages1015–1021,Geneva,
Switzerland.
Wilcoxon,Frank.1945.Individual
comparisonsbyrankingmethods.
Biometrics,1:80–83.
Wu,ZhibiaoandMarthaPalmer.1994.Verb
semanticsandlexicalselection.In
Proceedings of the 32nd Annual Meeting of the
Association for Computational Linguistics,
pages133–138,LasCruces,NewMexico,
USA.
Xu,Wei,XinLiu,andYihongGong.2003.
Documentclusteringbasedon
non-negativematrixfactorization.In
Proceedings of the 26th ACM SIGIR
International Conference on Research and
Development in Information Retrieval,
pages267–273,Toronto,Canada.
69


