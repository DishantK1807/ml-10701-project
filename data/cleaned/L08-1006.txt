<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>L Ballesteros</author>
<author>W B Croft</author>
</authors>
<title>Resolving ambiguity for cross-language retrieval</title>
<date>1998</date>
<booktitle>In Proceedings of 21th ACM SIGIR</booktitle>
<pages>64--71</pages>
<contexts>
<context>arch on equivalent selection by using statistical translation techniques, including example-based approaches, IBM translation models, N-gram models, and machine learning [e.g., (Fung and Yee, 1998), (Ballesteros and Croft, 1998), (Uchimoto et al., 2003), (Yamamoto and Matsumoto, 2001), (Fujii and Ishikawa, 2000)]. Examplebased approaches, IBM models, and machine learning, however, require large comparable or parallel corpor</context>
</contexts>
<marker>Ballesteros, Croft, 1998</marker>
<rawString>L. Ballesteros and W. B. Croft. 1998. Resolving ambiguity for cross-language retrieval. In Proceedings of 21th ACM SIGIR, pages 64 71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Fujii</author>
<author>T Ishikawa</author>
</authors>
<title>Translating compound words in the cross-language information retrieval of technical documents (in Japanese</title>
<date>2000</date>
<booktitle>In Journal of Information Processing Society of Japan</booktitle>
<pages>1038--1045</pages>
<contexts>
<context>ple-based approaches, IBM translation models, N-gram models, and machine learning [e.g., (Fung and Yee, 1998), (Ballesteros and Croft, 1998), (Uchimoto et al., 2003), (Yamamoto and Matsumoto, 2001), (Fujii and Ishikawa, 2000)]. Examplebased approaches, IBM models, and machine learning, however, require large comparable or parallel corpora, which are high-cost. On the other hand, N-gram models do not always require compar</context>
</contexts>
<marker>Fujii, Ishikawa, 2000</marker>
<rawString>K. Fujii and T. Ishikawa. 2000. Translating compound words in the cross-language information retrieval of technical documents (in Japanese). In Journal of Information Processing Society of Japan, pages 1038 1045.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Fung</author>
<author>L Y Yee</author>
</authors>
<title>An IR approach for translating new words from nonparallel, comparable texts</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL98</booktitle>
<pages>414--419</pages>
<contexts>
<context>ories. The rst is research on equivalent selection by using statistical translation techniques, including example-based approaches, IBM translation models, N-gram models, and machine learning [e.g., (Fung and Yee, 1998), (Ballesteros and Croft, 1998), (Uchimoto et al., 2003), (Yamamoto and Matsumoto, 2001), (Fujii and Ishikawa, 2000)]. Examplebased approaches, IBM models, and machine learning, however, require larg</context>
</contexts>
<marker>Fung, Yee, 1998</marker>
<rawString>P. Fung and L. Y. Yee. 1998. An IR approach for translating new words from nonparallel, comparable texts. In Proceedings of COLING-ACL98, pages 414 419.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Ichihara</author>
<author>S Tada</author>
<author>S Mizobuti</author>
<author>K Ando</author>
</authors>
<title>English veri cation and example retrieval tool for English writing(in Japanese</title>
<date>2005</date>
<booktitle>In The 11th Annual Meeting of the Association for Natural Language Processing (NLP2005</booktitle>
<pages>4--9</pages>
<contexts>
<context>nd category of related work is research on developing various kinds of English writing support systems, e.g., systems that can present examples of English sentences including keywords given by users (Ichihara et al., 2005), and systems that can detect certain types of English errors related to the mass-count distinction (Nagata et al., 2006). The early studies most related to our work were done by (Oshika et al., 2005</context>
</contexts>
<marker>Ichihara, Tada, Mizobuti, Ando, 2005</marker>
<rawString>K. Ichihara, S. Tada, S. Mizobuti, and K. Ando. 2005. English veri cation and example retrieval tool for English writing(in Japanese). In The 11th Annual Meeting of the Association for Natural Language Processing (NLP2005), pages 4 9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Matsumoto</author>
<author>A Kitauchi</author>
<author>T Yamashita</author>
<author>Y Hirano</author>
<author>H Matsuda</author>
<author>K Takaoka</author>
<author>M Asahara</author>
</authors>
<title>Japanese morphological analysis system chasen version 2.2.1</title>
<date>2000</date>
<contexts>
<context>used as the Japanese-English dictionary. The SS Tagger (Tsuruoka and Tsujii, 2005a) was used for tagging English POSs. The SS Parser (Tsuruoka and Tsujii, 2005b) was used for parsing English. Chasen (Matsumoto et al., 2000) was used for segmenting Japanese words and tagging POSs. The testing problems were generated as follows. Onehundredfty English sentences were randomly selected from the NICT Japanese-English paral</context>
</contexts>
<marker>Matsumoto, Kitauchi, Yamashita, Hirano, Matsuda, Takaoka, Asahara, 2000</marker>
<rawString>Y. Matsumoto, A. Kitauchi, T. Yamashita, Y. Hirano, H. Matsuda, K. Takaoka, and M. Asahara. 2000. Japanese morphological analysis system chasen version 2.2.1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Nagata</author>
<author>T Wakana</author>
<author>A Kawai</author>
<author>K Morihiro</author>
<author>F Masui</author>
<author>N Isu</author>
</authors>
<title>Recognition errors in English writing based on the mass count distinction (in Japanese</title>
<date>2006</date>
<booktitle>In IEICE Transaction on Information and Systems</booktitle>
<volume>Vol.</volume>
<contexts>
<context>can present examples of English sentences including keywords given by users (Ichihara et al., 2005), and systems that can detect certain types of English errors related to the mass-count distinction (Nagata et al., 2006). The early studies most related to our work were done by (Oshika et al., 2005) and (Sato et al., 2006). Their methods, however, used only raw Web data (i.e., they simply checked numbers of hits on t</context>
</contexts>
<marker>Nagata, Wakana, Kawai, Morihiro, Masui, Isu, 2006</marker>
<rawString>R. Nagata, T. Wakana, A. Kawai, K. Morihiro, F. Masui, and N. Isu. 2006. Recognition errors in English writing based on the mass count distinction (in Japanese). In IEICE Transaction on Information and Systems, Vol.</rawString>
</citation>
<citation valid="false">
<authors>
<author>No J89-D</author>
</authors>
<volume>8</volume>
<pages>1777--1790</pages>
<marker>J89-D, </marker>
<rawString>J89-D, No. 8, pages 1777 1790.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Oshika</author>
<author>M Sato</author>
<author>S Ando</author>
<author>H Yamana</author>
</authors>
<title>An English composition support system using Google (in Japanese</title>
<date>2005</date>
<booktitle>In DEWS2005 4-B-08</booktitle>
<contexts>
<context>hihara et al., 2005), and systems that can detect certain types of English errors related to the mass-count distinction (Nagata et al., 2006). The early studies most related to our work were done by (Oshika et al., 2005) and (Sato et al., 2006). Their methods, however, used only raw Web data (i.e., they simply checked numbers of hits on the Web). The reliability was thus extremely low because of huge numbers of docu</context>
</contexts>
<marker>Oshika, Sato, Ando, Yamana, 2005</marker>
<rawString>H. Oshika, M. Sato, S. Ando, and H. Yamana. 2005. An English composition support system using Google (in Japanese). In DEWS2005 4-B-08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Sato</author>
<author>S Ando</author>
<author>H Yamana</author>
</authors>
<title>Constuction of English composition support systems using search engin (in Japanese</title>
<date>2006</date>
<booktitle>In The 12th Annual Meeting of the Association for Natural Language Processing (NLP2006</booktitle>
<pages>664--667</pages>
<contexts>
<context>systems that can detect certain types of English errors related to the mass-count distinction (Nagata et al., 2006). The early studies most related to our work were done by (Oshika et al., 2005) and (Sato et al., 2006). Their methods, however, used only raw Web data (i.e., they simply checked numbers of hits on the Web). The reliability was thus extremely low because of huge numbers of documents written by non-nat</context>
</contexts>
<marker>Sato, Ando, Yamana, 2006</marker>
<rawString>M. Sato, S. Ando, and H. Yamana. 2006. Constuction of English composition support systems using search engin (in Japanese). In The 12th Annual Meeting of the Association for Natural Language Processing (NLP2006), pages 664 667.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Sumita</author>
<author>F Sugaya</author>
<author>S Yamamoto</author>
</authors>
<title>Automatic generation method of a ll-in-the-blank question for measuring English pro ciency (in Japanese</title>
<date>2004</date>
<booktitle>In ICICE TL2004-22/WIT2004-56</booktitle>
<pages>17--22</pages>
<contexts>
<context>c. 4.1.2. but replaces the words with their POSs; however, it can only be used when using high-quality corpora for searches. 4.1.4. Use of contentive-bounded word sequences In the method proposed by (Sumita et al., 2004), all queries are constructed using the shortest word sequence centered on the candidate word and containing contextual words wedged between contentives (i.e., nouns, verbs, and adjectives). Since th</context>
</contexts>
<marker>Sumita, Sugaya, Yamamoto, 2004</marker>
<rawString>E. Sumita, F. Sugaya, and S. Yamamoto. 2004. Automatic generation method of a  ll-in-the-blank question for measuring English pro ciency (in Japanese). In ICICE TL2004-22/WIT2004-56, pages 17 22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Tsuruoka</author>
<author>J Tsujii</author>
</authors>
<title>Bidirectional inference with the easiestrst strategy for tagging sequence data</title>
<date>2005</date>
<contexts>
<context> the Web data were not gathered beforehand but used to check hits on the Web using Google Web APIs4. Eijiro5 with 1,760,000 lexical entries was used as the Japanese-English dictionary. The SS Tagger (Tsuruoka and Tsujii, 2005a) was used for tagging English POSs. The SS Parser (Tsuruoka and Tsujii, 2005b) was used for parsing English. Chasen (Matsumoto et al., 2000) was used for segmenting Japanese words and tagging POSs. </context>
</contexts>
<marker>Tsuruoka, Tsujii, 2005</marker>
<rawString>Y. Tsuruoka and J. Tsujii. 2005a. Bidirectional inference with the easiestrst strategy for tagging sequence data.</rawString>
</citation>
<citation valid="true">
<authors>
<author>In HLTEMNLP</author>
</authors>
<date>2005</date>
<pages>467--474</pages>
<marker>HLTEMNLP, 2005</marker>
<rawString>In HLT/EMNLP 2005, pages 467 474.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Tsuruoka</author>
<author>J Tsujii</author>
</authors>
<date>2005</date>
<note>Chunk parsing revisited</note>
<contexts>
<context> the Web data were not gathered beforehand but used to check hits on the Web using Google Web APIs4. Eijiro5 with 1,760,000 lexical entries was used as the Japanese-English dictionary. The SS Tagger (Tsuruoka and Tsujii, 2005a) was used for tagging English POSs. The SS Parser (Tsuruoka and Tsujii, 2005b) was used for parsing English. Chasen (Matsumoto et al., 2000) was used for segmenting Japanese words and tagging POSs. </context>
</contexts>
<marker>Tsuruoka, Tsujii, 2005</marker>
<rawString>Y. Tsuruoka and J. Tsujii. 2005b. Chunk parsing revisited.</rawString>
</citation>
<citation valid="true">
<date>2005</date>
<booktitle>In the 9th International Workshop on Parsing Technologies (IWPT</booktitle>
<pages>133--140</pages>
<marker>2005</marker>
<rawString>In the 9th International Workshop on Parsing Technologies (IWPT 2005), pages 133 140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Uchimoto</author>
<author>S Sekine</author>
<author>M Murata</author>
<author>H Isahara</author>
</authors>
<title>Word translation by combining and example-based method and machine learning models (in Japanses</title>
<date>2003</date>
<booktitle>In Natural Language Processing</booktitle>
<volume>10</volume>
<pages>87--114</pages>
<contexts>
<context> using statistical translation techniques, including example-based approaches, IBM translation models, N-gram models, and machine learning [e.g., (Fung and Yee, 1998), (Ballesteros and Croft, 1998), (Uchimoto et al., 2003), (Yamamoto and Matsumoto, 2001), (Fujii and Ishikawa, 2000)]. Examplebased approaches, IBM models, and machine learning, however, require large comparable or parallel corpora, which are high-cost. O</context>
</contexts>
<marker>Uchimoto, Sekine, Murata, Isahara, 2003</marker>
<rawString>K. Uchimoto, S. Sekine, M. Murata, and H. Isahara. 2003. Word translation by combining and example-based method and machine learning models (in Japanses). In Natural Language Processing, Vol. 10, No.3, pages 87 114.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Uchimoto</author>
<author>Y Zhang</author>
<author>K Sudo</author>
<author>M Murata</author>
<author>S Sekine</author>
<author>H Isahara</author>
</authors>
<title>Multilingual Aligned Parallel Treebank Corpus Re ecting Contextual Information and Its Applications</title>
<date>2004</date>
<booktitle>In Proceedings of the MLR2004: PostCOLING Workshop on Multilingual Linguistic Resources</booktitle>
<pages>63--70</pages>
<contexts>
<context>lected from the NICT Japanese-English parallel corpus in which the original Japanese sentences were Japaneses newspaper articles and the English sentences were translated by professional translators (Uchimoto et al., 2004). One word was randomly selected for each of these sentences and replaced with its Japanese equivalent appearing in the original Japanese sentence, so that in total there were 60 Japanese words whose</context>
</contexts>
<marker>Uchimoto, Zhang, Sudo, Murata, Sekine, Isahara, 2004</marker>
<rawString>K. Uchimoto, Y. Zhang, K. Sudo, M. Murata, S. Sekine, and H. Isahara. 2004. Multilingual Aligned Parallel Treebank Corpus Re ecting Contextual Information and Its Applications. In Proceedings of the MLR2004: PostCOLING Workshop on Multilingual Linguistic Resources, pages 63 70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Utiyama</author>
<author>H Isahara</author>
</authors>
<title>Reliable measures for aligning Japanese-English news articles and sentences</title>
<date>2003</date>
<contexts>
<context> National Corpus (BNC) including 6,050,000 sentences, and others including the three years (2003-2005) of The Daily Yomiuri English newspaper and the automatically aligned Japanese-English sentences (Utiyama and Isahara, 2003). On the other hand, the Web data were not gathered beforehand but used to check hits on the Web using Google Web APIs4. Eijiro5 with 1,760,000 lexical entries was used as the Japanese-English dictio</context>
</contexts>
<marker>Utiyama, Isahara, 2003</marker>
<rawString>M. Utiyama and H. Isahara. 2003. Reliable measures for aligning Japanese-English news articles and sentences.</rawString>
</citation>
<citation valid="false">
<booktitle>In ACL-2003</booktitle>
<pages>72--79</pages>
<marker></marker>
<rawString>In ACL-2003, pages 72 79.</rawString>
</citation>
</citationList>
</algorithm>

