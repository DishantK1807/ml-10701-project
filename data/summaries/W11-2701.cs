ror rate training approach (Och, 2003). The objec-
P03-1021
C. Bannard and C. Callison-Burch. 2005. Paraphras-
P05-1074
Cohn and Lapata, 2007; Clarke and Lapata, 2008;
C08-1018 D07-1008
been reported by Clarke and Lapata (2006b).
P06-1048 P06-2019
H. Jing. 2000. Sentence reduction for automatic text
A00-1043
sions (Cohn and Lapata, 2008); hence, abstractive
C08-1018
T. Cohn and M. Lapata. 2007. Large margin syn-
D07-1008
More recently, Zhao et al. (2009a) presented a
P09-1094
The dataset that Cohn and Lapata (2008) used
C08-1018
L. Zhou, C.-Y. Lin, and Eduard Hovy. 2006. Re-
W06-1610
D. Kauchak and R. Barzilay. 2006. Paraphrasing for
N06-1058
2000; Knight and Marcu, 2002; McDonald, 2006;
E06-1038
Burch, 2008; Kok and Brockett, 2010). Zhao et
N10-1017
J. Clarke and M. Lapata. 2006b. Models for sentence
P06-1048 P06-2019
S. Zhao, H. Wang, X. Lan, and T. Liu. 2010. Leverag-
C10-1149
extraction measure; and Newman et al. (2010) found it to be the
N10-1012
then applied the paraphrasing rules of Zhao et al.(2009b) to the resulting extractive compressions; we
P09-1094
example BLEU (Papineni et al., 2002), to compare
P02-1040
Cohn and Lapata, 2009; Nomoto, 2009; Galanis
D09-1041
for sentence paraphrasing (Zhao et al., 2010).
C10-1149
K. Papineni, S. Roukos, T. Ward, and W. J. Zhu. 2002.
P02-1040
ing paraphrasing rules (Zhao et al., 2009b) to the
P09-1094
T. Nomoto. 2009. A comparison of model free versus
D09-1041
S. Kok and C. Brockett. 2010. Hitting the right para-
N10-1017
D. Newman, J.H. Lau, K. Grieser, and T. Baldwin. 2010.
N10-1012
the ‘Model 1’ score; see Zhao et al. (2009b) for details.
P09-1094
E. Yamangil and S. M. Shieber. 2010. Bayesian syn-
P10-1096
We note that Zhao et al.’s method (2009a) is in-
P09-1094
S. Zhao, H. Wang, T. Liu, and S. Li. 2009b. Extract-
P09-1094
eij. Zhao et al. (2009b) associate each paraphrasing
P09-1094
R. McDonald. 2006. Discriminative sentence compres-
E06-1038
S. Zhao, X. Lan, T. Liu, and S. Li. 2009a. Application-
P09-1094
posed by Cohn and Lapata (2008). It learns a set of
C08-1018
J. Clarke and M. Lapata. 2006a. Constraint-based
P06-1048 P06-2019
(Riezler et al., 2003; Clarke and Lapata, 2006a).
N03-1026 P06-1048 P06-2019
D. Galanis and I. Androutsopoulos. 2010. An extrac-
N10-1131
Pecina (2005), however, found PMI to be the best collocation
P05-2003
language (Zhao et al., 2010). Using methods of this
C10-1149
the rule has a high score. Szpektor et al. (2008) point
P08-1078
parallel and comparable corpora (Zhao et al., 2008).
P08-1116
We then applied Zhao et al.’s (2009b) paraphrasing
P09-1094
of the source (Jing, 2000). Sentence compression is
A00-1043
S. Zhao, C. Niu, M. Zhou, T. Liu, and S. Li. 2008. Com-
P08-1116
C. Callison-Burch. 2008. Syntactic constraints on para-
D08-1021
T. Cohn and M. Lapata. 2008. Sentence compression
C08-1018
J. F. Och. 2003. Minimum error rate training in statistical
P03-1021
phrases have been proposed (Zhou et al., 2006; Kauchak and
W06-1610
P. Pecina. 2005. An extensive empirical study of colloca-
P05-2003
extraction methods (Riezler et al., 2007; Callison-
P07-1059
sentence compression (Zhao et al., 2009a).1
P09-1094
N. Madnani and B.J. Dorr. 2010. Generating phrasal and
J10-3003
