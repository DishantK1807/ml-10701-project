1:207	Coling 2008 22nd International Conference on Computational Linguistics Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation Workshop chairs: Johan Bos, Edward Briscoe, Aoife Cahill, John Carroll, Stephen Clark, Ann Copestake, Dan Flickinger, Josef van Genabith, Julia Hockenmaier, Aravind Joshi, Ronald Kaplan, Tracy Holloway King, Sandra Kubler, Dekang Lin, Jan Tore Lnning, Christopher Manning, Yusuke Miyao, Joakim Nivre, Stephan Oepen, Kenji Sagae, Nianwen Xue, and Yi Zhang 23 August 2008 Manchester, UK c2008 The Coling 2008 Organizing Committee Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Nonported license http://creativecommons.org/licenses/by-nc-sa/3.0/ Some rights reserved Order copies of this and other Coling proceedings from: Association for Computational Linguistics (ACL) 209 N. Eighth Street Stroudsburg, PA 18360 USA Tel: +1-570-476-8006 Fax: +1-570-476-0860 acl@aclweb.org ISBN 978-1-905593-50-7 Design by Chimney Design, Brighton, UK Production and manufacture by One Digital, Brighton, UK ii Introduction Broad-coverage parsing has come to a point where distinct approaches can offer (seemingly) comparable performance: statistical parsers acquired from the Penn Treebank (PTB); data-driven dependency parsers; deep parsers trained off enriched treebanks (in linguistic frameworks like CCG, HPSG, or LFG); and hybrid deep parsers, employing hand-built grammars in, for example, HPSG, LFG, or LTAG.
2:207	Evaluation against trees in the Wall Street Journal (WSJ) section of the PTB has helped advance parsing research over the course of the past decade.
3:207	Despite some scepticism, the crisp and, over time, stable task of maximizing ParsEval metrics (i.e. constituent labeling precision and recall) over PTB trees has served as a dominating benchmark.
4:207	However, modern treebank parsers still restrict themselves to only a subset of PTB annotation; there is reason to worry about the idiosyncrasies of this particular corpus; it remains unknown how much the ParsEval metric (or any intrinsic evaluation) can inform NLP application developers; and PTB-style analyses leave a lot to be desired in terms of linguistic information.
5:207	The Grammatical Relations (GR) scheme, inspired by Dependency Grammar, offers a level of abstraction over specific syntactic analyses.
6:207	It aims to capture the gist of grammatical relations in a fashion that avoids reference to a token linguistic theory.
7:207	GR has recently been applied successfully in a series of cross-framework parser evaluation studies.
8:207	At the same time, rather little GR gold standard data is available, and the GR scheme has been questioned for some of its design decisions.
9:207	More specifically, GR builds on a combination of syntactic and, albeit very limited, some semantic information.
10:207	Existing studies suggest that the GR gold standard can be both overly rich and overly shallow in some respects.
11:207	Furthermore, the mapping of native parser outputs into GR introduces noise, and it raises a number of theoretical and practical questions.
12:207	Gold standard representations at the level of propositional semantics have at times been proposed for cross-framework parser evaluation, specifically where the parsing task is broadly construed as a tool towards text understanding, i.e. where the parser is to provide all information that is grammaticalized and contributing to interpretation.
13:207	PropBank would seem a candidate gold standard, but to date very few studies exist that report on the use of PropBank for parser evaluation.
14:207	The reasons might be that (at least some) parser developers believe that PropBank goes too far beyond the grammatical level to serve for parser evaluation, and that starting from PTB structures may have led to some questionable annotation decisions.
15:207	Finally, a complementary topic to cross-framework evaluation is the increasing demand for crossdomain parser evaluation.
16:207	At conferences in 2007, concerns were expressed about results that might rely on particular properties of the WSJ PTB, and over idiosyncrasies of this specific sample of natural language.
17:207	For example, it remains a largely open question to what degree progress made in PTB parsing can carry over to other genres and domains; a related question is on the fitness of some specific approach (when measured in parser evaluation metrics) for actual NLP applications.
18:207	In summary, it may be necessary that the WSJand PTB-derived parser benchmarks be complemented by other gold standards, bothintermsoftheselectionoftextsandtargetrepresentations.
19:207	Andtofurthertheadaptation of parser evaluation to more languages, it will be important to carefully distill community experience from ParsEval and GR evaluations.
20:207	iii This workshop aims to bring together developers of broad-coverage parsers who are interested in questions of target representations and cross-framework and cross-domain evaluation and benchmarking.
21:207	From informal discussions that the co-organizers had among themselves and with colleagues, it seems evident that there is comparatively broad awareness of current issues in parser evaluation, and a lively interest in detailed exchange of experience (and beliefs).
22:207	Specifically, the organizers have tried to attract representatives from diverse parsing approaches and frameworks, ranging from traditional treebank parsing, over data-driven dependency parsing, to parsing in specific linguistic frameworks.
23:207	For the latter class of parsers, in many frameworks there is a further sub-division into groups pursuing classic grammar engineering vs. ones who rely on grammar acquisition from annotated corpora.
24:207	Quite likely for the first time in the history of these approaches, there now exist large, broad-coverage parsing systems representing diverse traditions that can be applied to running text, often producing comparable representations.
25:207	In our view, these recent developments present a new opportunity for re-energizing parser evaluation research.
26:207	We sincerely wish this workshop will provide participants with the opportunity for in-depth and cross-framework exchange of expertise and discussion of future directions in parser evaluation.
27:207	A specific sub-goal of the workshop is to establish an improved shared knowledge among participants of the strengths and weaknesses of extant annotation and evaluation schemes.
28:207	In order to create a joint focus for detailed discussion, the workshop preparation included a lightweight shared task.
29:207	For a selection of 50 sentences (of which ten were considered obligatory, the rest optional) for which PTB, GR, and PropBank (and other) annotations are available, contributors were invited to scrutinize existing gold-standard representations contrastively, identify perceived deficiencies, and sketch what can be done to address these.
30:207	As an optional component, participants in the shared task were welcome to include native, framework-specific output representations and actual results for a parsing system of their choice (be it their own or not) in the contrastive study.
31:207	In either case, submissions to the shared taskreflectonthenatureofdifferentrepresentations, highlightwhichadditionaldistinctionsaremadein either scheme, and argue why these are useful (for some task) or unmotivated (in general).
32:207	Of the eight papers selected for presentation at the workshop, the following three were submissions to the shared task, viz.
33:207	those by Flickinger (page 17), Tateisi (page 24), and McConville and Dzikovska (page 51).
34:207	For further information on the workshop as a whole, its shared task, and some specific datasets used, please see: a11 a10 a8 a9 http://lingo.stanford.edu/events/08/pe/ iv Organizers: Johan Bos, University of Rome La Sapienza (Italy) Edward Briscoe, University of Cambridge (UK) Aoife Cahill, University of Stuttgart (Germany) John Carroll, University of Sussex (UK) Stephen Clark, Oxford University (UK) Ann Copestake, University of Cambridge (UK) Dan Flickinger, Stanford University (USA) Josef van Genabith, Dublin City University (Ireland) Julia Hockenmaier, University of Illinois at Urbana-Champaign (USA) Aravind Joshi, University of Pennsylvania (USA) Ronald Kaplan, Powerset, Inc.
35:207	(USA) Tracy Holloway King, PARC (USA) Sandra Kubler, Indiana University (USA) Dekang Lin, Google Inc.
36:207	(USA) Jan Tore Lnning, University of Oslo (Norway) Christopher Manning, Stanford University (USA) Yusuke Miyao, University of Tokyo (Japan) Joakim Nivre, Vaxjo and Uppsala Universities (Sweden) Stephan Oepen, University of Oslo (Norway) and CSLI Stanford (USA) Kenji Sagae, University of Southern California (USA) Nianwen Xue, University of Colorado (USA) Yi Zhang, DFKI GmbH and Saarland University (Germany) v  Table of Contents The Stanford Typed Dependencies Representation Marie-Catherine de Marneffe and Christopher D. Manning1 Exploring an Auxiliary Distribution Based Approach to Domain Adaptation of a Syntactic Disambiguation Model Barbara Plank and Gertjan van Noord9 Toward an Underspecifiable Corpus Annotation Scheme Yuka Tateisi17 Toward a Cross-Framework Parser Annotation Standard Dan Flickinger  24 Parser Evaluation Across Frameworks without Format Conversion Wai Lok Tam, Yo Sato, Yusuke Miyao, and Junichi Tsujii29 Large Scale Production of Syntactic Annotations to Move Forward Anne Vilnat, Gil Francopoulo, Olivier Hamon, Sylvain Loiseau, Patrick Paroubek, and Eric Villemonte de la Clergerie36 Constructing a Parser Evaluation Scheme Laura Rimell and Stephen Clark44 Deep Grammatical Relations for Semantic Interpretation Mark McConville and Myroslava O. Dzikovska51 vii  Conference Programme Saturday, August 23, 2008 9:009:30 Workshop Motivation and Overview (Cahill, Oepen, et al.) 9:3010:00 The Stanford Typed Dependencies Representation Marie-Catherine de Marneffe and Christopher D. Manning 10:0010:30 Exploring an Auxiliary Distribution Based Approach to Domain Adaptation of a Syntactic Disambiguation Model Barbara Plank and Gertjan van Noord 10:3011:00 Coffee Break 11:0011:30 Toward an Underspecifiable Corpus Annotation Scheme Yuka Tateisi 11:3012:00 Toward a Cross-Framework Parser Annotation Standard Dan Flickinger 12:0012:30 Discussion 12:3014:00 Lunch Break 14:0014:30 Summary of CoNLL 2008 Shared Task (Nivre) 14:3015:00 Parser Evaluation Across Frameworks without Format Conversion Wai Lok Tam, Yo Sato, Yusuke Miyao and Junichi Tsujii 15:0015:30 Large Scale Production of Syntactic Annotations to Move Forward Anne Vilnat, Gil Francopoulo, Olivier Hamon, Sylvain Loiseau, Patrick Paroubek, and Eric Villemonte de la Clergerie 15:3016:00 Coffee Break 16:0016:30 Constructing a Parser Evaluation Scheme Laura Rimell and Stephen Clark 16:3017:00 Deep Grammatical Relations for Semantic Interpretation Mark McConville and Myroslava O. Dzikovska 17:0017:30 Discussion ix  Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation, pages 18 Manchester, August 2008 The Stanford typed dependencies representation Marie-Catherine de Marneffe Linguistics Department Stanford University Stanford, CA 94305 mcdm@stanford.edu Christopher D. Manning Computer Science Department Stanford University Stanford, CA 94305 manning@stanford.edu Abstract This paper examines the Stanford typed dependencies representation, which was designed to provide a straightforward description of grammatical relations for any user who could benefit from automatic text understanding.
37:207	For such purposes, we argue that dependency schemes must follow a simple design and provide semantically contentful information, as well as offer an automatic procedure to extract the relations.
38:207	We consider the underlying design principles of the Stanford scheme from this perspective, and compare it to the GR and PARC representations.
39:207	Finally, we address the question of the suitability of the Stanford scheme for parser evaluation.
40:207	1 Introduction The Stanford typed dependencies representation was designed to provide a simple description of the grammatical relationships in a sentence that could easily be understood and effectively used by people without linguistic expertise who wanted to extract textual relations.
41:207	The representation was not designed for the purpose of parser evaluation.
42:207	Nevertheless, we agree with the widespread sentiment that dependency-based evaluation of parsers avoids many of the problems of the traditional Parseval measures (Black et al., 1991), and to the extent that the Stanford dependency representation is an effective representation for the tasks envisioned, it is perhaps closer to an appropriate taskbased evaluation than some of the alternative dependency representations available.
43:207	In this paper c2008.
44:207	Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
45:207	Some rights reserved.
46:207	we examine the representation and its underlying design principles, look at how this representation compares with other dependency representations in ways that reflect the design principles, and consider its suitability for parser evaluation.
47:207	A major problem for the natural language processing (NLP) community is how to make the very impressive and practical technology which has been developed over the last two decades approachable to and usable by everyone who has text understanding needs.
48:207	That is, usable not only by computational linguists, but also by the computer science community more generally and by all sorts of information professionals including biologists, medical researchers, political scientists, law firms, business and market analysts, etc. Thinking about this issue, we were struck by two facts.
49:207	First, we noted how frequently WordNet (Fellbaum, 1998) gets used compared to other resources, such as FrameNet (Fillmore et al., 2003) or the Penn Treebank (Marcus et al., 1993).
50:207	We believe that much of the explanation for this fact lies in the difference of complexity of the representation used by the resources.
51:207	It is easy for users not necessarily versed in linguistics to see how to use and to get value from the straightforward structure of WordNet.
52:207	Second, we noted the widespread use of MiniPar (Lin, 1998) and the Link Parser (Sleator and Temperley, 1993).
53:207	This clearly shows that (i) it is very easy for a non-linguist thinking in relation extraction terms to see how to make use of a dependency representation (whereas a phrase structure representation seems much more foreign and forbidding), and (ii) the availability of high quality, easy-to-use (and preferably free) tools is essential for driving broader use of NLP tools.1 1On the other hand, evaluation seems less important; to the best of our knowledge there has never been a convincing and thorough evaluation of either MiniPar or the Link Grammar 1 This paper advocates for the Stanford typed dependencies representation (henceforth SD) being a promising vehicle for bringing the breakthroughs of the last 15 years of parsing research to this broad potential user community.
54:207	The representation aims to provide a simple, habitable design.
55:207	All information is represented as binary relations.
56:207	This maps straightforwardly on to common representations of potential users, including the logic forms of Moldovan and Rus (Moldovan and Rus, 2001),2 semantic web Resource Description Framework (RDF) triples (http://www.w3.org/RDF/), and graph representations (with labeled edges and nodes).
57:207	Unlike many linguistic formalisms, excessive detail is viewed as a defect: information that users do not understand or wish to process detracts from uptake and usability.
58:207	The user-centered design process saw the key goal as representing semantically contentful relations suitable for relation extraction and more general information extraction uses.
59:207	The design supports this use by favoring relations between content words, by maintaining semantically useful closed class word information while ignoring linguistic decisions less relevant to users, and by not representing less used material about linguistic features such as tense and agreement.
60:207	The SD scheme thus provides a semantic representation simple and natural enough for people who are not (computational) linguists but can benefit from NLP tools.
61:207	2 Design choices and their implications 2.1 Design principles The style of the SD representation bears a strong intellectual debt to the framework of LexicalFunctional Grammar (Bresnan, 2001), and, more directly, it owes a debt to both the sets of grammatical relations and the naming defined in two representations that follow an LFG style: the GR (Carroll et al., 1999) and PARC (King et al., 2003) schemes.
62:207	These were used as a starting point for developing the Stanford dependencies (de Marneffe et al., 2006).
63:207	But where the SD scheme deviates from GR, PARC, and its LFG roots is that it has been designed to be a practical model of sentence representation, particularly in the context of relation extraction tasks.
64:207	parser.
65:207	2The logic forms of Moldovan and Rus are in the form of a predicate calculus representation, although not one that represents such things as operator scope in a way that most would expect of a predicate calculus representation.
66:207	SD makes available two options, suited to different use cases: in one, every word of the original sentence is present as a node with relations between it and other nodes, whereas in the latter, certain words are collapsed out of the representation, making such changes as turning prepositions into relations.
67:207	The former is useful when a close parallelism to the source text words must be maintained, whereas the latter is intended to be more useful for relation extraction and shallow language understanding tasks.
68:207	Here, we discuss only the latter representation; see (de Marneffe et al., 2006) for a discussion of both options and the precise relationship between them.
69:207	The intended use cases of usability by people who are not (computational) linguists and suitability for relation extraction applications led SD to try to adhere to the following design principles (DPs): 1.
70:207	Everything is represented uniformly as some binary relation between two sentence words.
71:207	2.
72:207	Relations should be semantically contentful and useful to applications.
73:207	3.
74:207	Where possible, relations should use notions of traditional grammar for easier comprehension by users.
75:207	4.
76:207	Underspecified relations should be available to deal with the complexities of real text.
77:207	5.
78:207	Where possible, relations should be between content words, not indirectly mediated via function words.
79:207	6.
80:207	The representation should be spartan rather than overwhelming with linguistic details.
81:207	We illustrate many of them in the rest of this section, using example sentences which were made available for the Parser Evaluation Shared Task.
82:207	The grammatical relations of SD are arranged in a hierarchy, rooted with the most generic relation, dependent.
83:207	The hierarchy contains 56 grammatical relations.
84:207	When the relation between a head and its dependent can be identified more precisely, relations further down in the hierarchy are used, but when it is unclear, more generic dependencies are possible (DP1, DP4).
85:207	For example, the dependent relation can be specialized to aux (auxiliary), arg (argument), or mod (modifier).
86:207	The arg relation is further divided into the subj (subject) relation and the comp (complement) relation, and so on.
87:207	The backbone of this hierarchy is quite similar to that in GR, but there are some crucial differences.
88:207	2 2.2 Comparison with GR and PARC The SD scheme is not concerned with the argument/adjunct distinction which is largely useless in practice.
89:207	In contrast, NP-internal relations are an inherent part of corpus texts and are critical in realworld applications.
90:207	The SD scheme therefore includes many relations of this kind: appos (appositive modifier), nn (noun compound), num (numeric modifier), number (element of compound number) and abbrev (abbreviation), etc.
91:207	(DP2).
92:207	For instance, in the sentence I feel like a little kid, says a gleeful Alex de Castro, a car salesman, who has stopped by a workout of the Suns to slip six Campaneris cards to the Great Man Himself to be autographed (WSJ-R), we obtain the following relations under the SD representation: SD appos(Castro, salesman) num(cards, six) nn(cards, Campaneris) The numeric modifier relation between cards and six is also standard in the PARC and GR schemes.
93:207	PARC provides an apposition relation between salesman and Alex de Castro, whereas GR only identifies salesman as a text adjunct of Castro.
94:207	But on the whole, SD makes more fine-grained distinctions in the relations, which are needed in practice.
95:207	The adjunct dependency of the PARC scheme lumps together different relations.
96:207	For example, the adjectival modifier gleeful in the sentence above will not be marked distinctively from the preposition modifying workout, nor from the relation between the verbs stop and slip: PARC adjunct(Alex de Castro, gleeful) adjunct(kid, little) adjunct(stop, slip) adjunct(workout, of) The SD output for the relations between these words looks as follows: SD amod(Castro, gleeful) amod(kid, little) xcomp(stop, slip) prep of(workout, Suns) The comparison between the two outputs shows that SD proposes a larger set of dependencies, capturing relation differences which can play a role in applications (DP2), while sticking to notions of traditional grammar (DP3).
97:207	The SD scheme also chooses content words as heads of the dependencies (DP5).
98:207	Auxiliaries, complementizers, and so on, are dependents of them.
99:207	This choice in design is driven by the kind of information that is useful for applications.
100:207	For instance, in the sentence Considered as a whole, Mr. Lane said, the filings required under the proposed rules will be at least as effective, if not more so, for investors following transactions (WSJ-R), effective is chosen as the head of the quoted phrase.
101:207	This enables the representation to have a direct dependency (nsubj for nominal subject) between the key content words effective and filings.
102:207	Such a link is more difficult to infer from the GR scheme, where be is chosen as the head.
103:207	However the relation between effective and filings is key to extracting the gist of the sentence semantics, and it is therefore important for applications to be able to retrieve it easily.
104:207	Also, in the case of structures involving copular verbs, a direct link between the subject and the complement enables equivalent representations across languages (in Chinese, for example, copulas are not explicitly expressed).
105:207	Such parallel representations should presumably help machine translation, and this was a further motivation for choosing content words as heads.
106:207	Another instance where direct links between content words is useful is the case of prepositional complements.
107:207	The SD scheme offers the option of collapsing dependencies involving a preposition (DP5).
108:207	In the example above, instead of having two relations adjunct(workout, of) and obj(of, Suns) as in PARC or ncmod(workout, of) and dobj(of, Suns) as in GR, SD provides a direct relation between the content words: prep of (workout, Suns).
109:207	Prepositions often work as role markers, and this type of link facilitates the extraction of how the two content words are related; and thus these links are often used by downstream applications (Lin and Pantel, 2001; Snow et al., 2005).
110:207	The usefulness of the representation is exemplified in the sentence A similar technique is almost impossible to apply to other crops, such as cotton, soybeans and rice (WSJ-R) for which SD gives direct links between the entities joined through the preposition such as: SD prep such as(crops, cotton) prep such as(crops, soybeans) prep such as(crops, rice) A similar collapsing treatment takes place for conjuncts (DP5).
111:207	Consider the following sentence: Bell, based in Los Angeles, makes and distributes 3 SD nsubj(makes-8, Bell-1) nsubj(distributes-10, Bell-1) partmod(Bell-1, based-3) nn(Angeles-6, Los-5) prep in(based-3, Angeles-6) conj and(makes-8, distributes-10) amod(products-16, electronic-11) conj and(electronic-11, computer-13) amod(products-16, computer-13) conj and(electronic-11, building-15) amod(products-16, building-15) dobj(makes-8, products-16) Figure 1: SD representation for Bell, based in Los Angeles, makes and distributes electronic, computer and building products.
112:207	electronic, computer and building products (WSJR).
113:207	Figures 1 and 2 give the full dependency output from SD and GR, respectively.
114:207	The numbers after the words in the SD representation indicate the word position in the sentence.3 From the SD representation, one can easily see that the sentence talks about electronic products and computer products as well as building products.
115:207	By collapsing the dependencies involving conjuncts, the output produced is closer to the semantics of the sentence, and this facilitates information extraction (DP2).
116:207	This information is not straightforwardly apparent in the GR scheme (see figure 2), nor in the PARC scheme which follows a similar treatment of conjuncts.
117:207	Another choice in the design has been to consistently have binary relations (DP1).
118:207	All the dependencies form a triple: a grammatical relation holding between two words (head and dependent).
119:207	This gives uniformity to the representation and renders it very readable, critical features for a usercentered design.
120:207	Furthermore, all the information can be represented by a directed graph, enabling the creation of both a limpid visual representation for humans and a canonical data structure for software.
121:207	Moreover, it maps straightforwardly on to semantic web representations such as OWL and RDF triples, as exploited in (Zouaq et al., 2006; Zouaq et al., 2007).
122:207	This design choice limits the kind of information offered by the SD scheme.
123:207	For instance, the PARC scheme contains much more information 3Without word position, the representation is deficient if the same word occurs more than once in a sentence.
124:207	GR (passive based) (ncsubj based Bell obj) (ta bal Bell based) (iobj based in) (dobj in Angeles) (ncmod Angeles Los) (conj and makes) (conj and distributes) (conj and electronic) (conj and computer) (conj and building) (ncsubj and Bell ) (dobj and products) (ncmod products and) Figure 2: GR representation for Bell, based in Los Angeles, makes and distributes electronic, computer and building products.
125:207	about individual words, such as verb tense and aspect, noun number and person, type of NE for proper nouns, pronoun form, adjective degree, etc. For the sentence in figures 1 and 2, the following information is available for the word Los Angeles in the PARC scheme: PARC num(Los Angeles5, sg) pers(Los Angeles5, 3) proper(Los Angeles5, location) This kind of information is indubitably valuable, but is often less used in practice, and does not per se pertain to dependency data.
126:207	Adding it lengthens an output already complex enough, and impedes readability and convenience.
127:207	Thus, SD does not provide such overwhelming detail (DP6).
128:207	2.3 Trading off linguistic fidelity and usability We feel that turning prepositions into relations is useful for 98% of users 98% of the time.
129:207	Nevertheless opting for usability in this way causes the SD scheme to sacrifice some linguistic fidelity.
130:207	One instance is that modifiers of prepositions are dependent on the verb (or more precisely, on the head of the clause in which they appear) and not on the preposition itself.
131:207	In Bill went over the river and right through the woods, right will be an adverbial modifier of went.
132:207	In He had laughed, simultaneously mocking the stupidity of government by cosmetics and confessing that he was also a part of it, just as he was part of government by voice coach and acting coach (BNC), just which modifies as will be a dependent of the head of the adverbial 4 clause, i.e., part.
133:207	This induces some distortion in the exact semantics of the sentence.
134:207	The interaction between preposition collapsing and PP conjunction is another instance in which the SD treatment slightly alters the semantics of the sentence.
135:207	Consider again the sentence Bill went over the river and right through the woods.
136:207	Both prepositions, over and through, are governed by the verb went.
137:207	To avoid disjoint subgraphs when collapsing the relations, examples like this are transformed into VP coordination, which requires making a copy of the word went.
138:207	This gives the following representation, which corresponds to a sentence like Bill went over the river and went right through the woods: SD prep over(went-2, river-5) prep through(went-2, woods-10) conj and(went-2, went-2) Not collapsing the relations in such a case would prevent the alteration of the semantics, but would lead to a non-uniform treatment of prepositions.
139:207	Uniformity is key for readability and user convenience.
140:207	It seems therefore reasonable to use a representation which sacrifices the exact semantics of the original sentence by producing a sentence roughly equivalent, but which ensures uniformity across relations.
141:207	3 The formalism and the tool Two vital conditions for the success of a dependency scheme are to provide a suitable representation for users as well as a tool that is easy to use.
142:207	Sagae et al.143:207	(2008) note that the availability of an automatic procedure to convert phrase structure parses to SD is the reason for its use in evaluations of parsers in the biomedical domain.
144:207	The primary focus of the SD scheme, however, has been to offer grammatical relations appropriate for end-users.
145:207	The Stanford parser4 comes with a tool, described in (de Marneffe et al., 2006), which provides for the rapid extraction of the grammatical relations from phrase structure parses.
146:207	Structural configurations are used to define grammatical roles: the semantic head of each constituent of the parse is identified, using rules akin to the Collins head rules, but modified to retrieve the semantic head of the constituent rather than the syntactic head.
147:207	As mentioned, content words are chosen as heads, and all the other words in the constituent 4http://nlp.stanford.edu/software/lex-parser.shtml depend on this head.
148:207	To retrieve adequate heads from a semantic point of view, heuristics are used to inject more structure when the Penn Treebank gives only flat constituents, as is often the case for conjuncts, e.g., (NP the new phone book and tour guide), and QP constituents, e.g., (QP more than 300).
149:207	Then for each grammatical relation, patterns are defined over the phrase structure parse tree using the tree-expression syntax defined by tregex (Levy and Andrew, 2006).
150:207	Conceptually, each pattern is matched against every tree node, and the matching pattern with the most specific grammatical relation is taken as the type of the dependency.
151:207	The automatic extraction of the relations is not infallible.
152:207	For instance, in the sentence Behind their perimeter walls lie freshly laundered flowers, verdant grass still sparkling from the last shower, yew hedges in an ecstasy of precision clipping (BNC), the system will erroneously retrieve apposition relations between flowers and grass, as well as between flowers and hedges whereas these should be conj and relations.
153:207	The system is clueless when there is no overt maker of conjunction.
154:207	Another limitation of the tool is the treatment of long-distance dependencies, such as whmovement and control/raising: the system cannot handle long-distance dependencies that cross clauses.
155:207	In a sentence like What does he think?, the system will correctly find that what is a direct object of think: SD dobj(think-4, What-1) aux(think-4, does-2) nsubj(think-4, he-3) However in a sentence such as Who the hell does he think hes kidding?
156:207	(BNC), the automatic extraction will fail to find that who is the direct object of kidding.
157:207	Here, it is vital to distinguish between SD as a representation versus the extant conversion tool.
158:207	Long-distance dependencies are not absent from the formalism, but the tool does not accurately deal with them.5 4 Stanford dependencies in practice SD has been successfully used by researchers in different domains.
159:207	In the PASCAL Recognizing 5As possible future work, we have thought of using a tool such as the one of Levy and Manning (2004) to correctly determine long distance dependencies, as input to the current dependency conversion system.
160:207	This would presumably be effective, but would make the conversion process much heavier weight.
161:207	5 Textual Entailment (RTE) challenges (Dagan et al., 2006; Giampiccolo et al., 2007), the increase in the use of SD is clearly apparent.
162:207	The goal in these challenges consists of identifying whether one sentence follows from a piece of text and general background knowledge, according to the intuitions of an intelligent human reader.
163:207	In 2007, out of the 21 systems which participated in the challenge, 5 used the SD representation, whereas the year before only the Stanford entry was using it.
164:207	SD is also widely present in the bioinformatic world where it is used with success (Erkan et al., 2007; Greenwood and Stevenson, 2007; Urbain et al., 2007; Clegg, 2008).
165:207	Fundel et al.166:207	(2007) found that, in extraction of relations between genes and proteins, a system based on the SD scheme greatly outperformed the previous best system on the LLL challenge dataset (by an 18% absolute improvement in F-measure).
167:207	Airola et al.168:207	(2008) provide more systematic results on a number of proteinprotein interaction datasets.
169:207	Their graph kernel approach uses an all-dependency-paths kernel which allows their system to consider full dependency graphs.
170:207	Their system is based on the SD scheme, and they demonstrate state-of-the-art performance for this approach.
171:207	In the biomedical domain, SD has recently been used in evaluations of parsers (Clegg and Shepherd, 2007; Pyysalo et al., 2007a).
172:207	Pyysalo et al.173:207	(2007a) assessed the suitability of the SD scheme over the Link Grammar dependency scheme in an application-oriented evaluation.
174:207	The Link Parser indeed uses a very fine-grained set of relations, which often makes distinctions of a structural rather than a semantic nature.
175:207	One example is the MX relation which connects modifying phrases with commas to preceding nouns (The DOG, a POODLE, was black; JOHN, IN a black suit, looked great). The Link Parser uses a different set of dependency types for dependencies appearing in questions and relative clauses.
176:207	Another example is the prepositional phrase where alternative attachment structures are indicated by different relations.
177:207	Many of these distinctions are too fine and non-semantic to be of practical value.
178:207	The SD scheme, by aiming for an intermediate level of granularity, and targeting semantic dependencies, provides a more adequate representation for applications.
179:207	Therefore, to increase the usability of the BioInfer corpus (Pyysalo et al., 2007b), which provides manually annotated data for information extraction in the biomedical domain and originally followed the Link Grammar scheme, Pyysalo et al.180:207	(2007a) developed a version of the corpus annotated with the SD scheme.
181:207	They also made available a program and conversion rules that they used to transform Link Grammar relations into SD graphs, which were then hand-corrected (Pyysalo et al., 2007b).
182:207	While a limited amount of gold standard annotated data was prepared for the Parser Evaluation Shared Task, this is the main source of gold-standard SD data which is currently available.
183:207	In other domains, Zhuang et al.184:207	(2006) uses the representation to extract opinions about features in reviews and Meena and Prabhakar (2007) uses it to improve the quality of sentence-level sentiment analysis.
185:207	The open information extraction system TEXTRUNNER (Banko et al., 2007) also makes use of the SD graph representation: its first module uses the Stanford parser and the dependency tool to automatically identify and label trustworthy and untrustworthy extractions.
186:207	Even in theoretical linguistic work, SD has proven very useful: it has hugely facilitated data extraction from corpora, in the context of the NSF-funded project Dynamics of probabilistic grammar carried out at the Stanford Linguistics department.
187:207	5 Suitability for parser evaluation When seeking a gold-standard dependency scheme for parser evaluation, the ultimate goal of such an evaluation is an important question.
188:207	It is necessary to contrast the two different forms that evaluation can take: extrinsic task-based evaluation and intrinsic evaluation.
189:207	We tend to agree with Molla and Hutchinson (2003) that intrinsic evaluations have limited value and that task-based evaluation is the correct approach.
190:207	Some of the results of the previous section at least broadly support the utility of the SD scheme for practical use in higherlevel tasks.
191:207	Nevertheless, given the current trend in the NLP community as well as in other fields such as bioinformatics, where the advantage of dependency representations for shallow text understanding tasks has become salient, we would argue, following Clegg and Shepherd (2007), that dependency-based evaluation is close to typical user tasks.
192:207	Moreover, it avoids some of the known deficiencies of other parser evaluation measures such as Parseval (Carroll et al., 1999).
193:207	Recent work on parser evaluation using dependency graphs in the biomedical domain confirms 6 that researchers regard dependency-based evaluation as a more useful surrogate for extrinsic task-based evaluation (Clegg and Shepherd, 2007; Pyysalo et al., 2007a).
194:207	In their evaluation, Clegg and Shepherd (2007) aimed at analyzing the capabilities of syntactic parsers with respect to semantically important tasks crucial to biological information extraction systems.
195:207	To do so, they used the SD scheme, which provides a de facto standard for comparing a variety of constituent parsers and treebanks at the dependency level, and they assessed its suitability for evaluation.
196:207	They found that the SD scheme better illuminates the performance differences between higher ranked parsers (e.g., Charniak-Lease parser (Lease and Charniak, 2005)), and lower ranked parsers (e.g., the Stanford parser (Klein and Manning, 2003)).
197:207	Their parser evaluation accommodates user needs: they used the collapsed version of the dependency graphs offered by the SD scheme, arguing that this is the kind of graph one would find most useful in an information extraction project.
198:207	Although Clegg and Shepherd (2007) also favor dependency graph representations for parser evaluation, they advocate retention of parse trees so information lost in the dependency structures can be accessed.
199:207	In essence, any existing dependency scheme could be adopted as the gold-standard for evaluation.
200:207	However if one believes in ultimately valuing extrinsic task-based evaluation, a dependency representation which proposes a suitable design for users and user tasks is probably the best surrogate for intrinsic evaluation.
201:207	Moreover, the existence of tools for automatically generating and converting dependency representations has aided greatly in making parser comparison possible across different formalisms.
202:207	We believe that the SD scheme approaches these goals.
203:207	If one accepts the goals set here, in order to enforce uniformity between application and evaluation, it seems sensible to have a unique scheme for both purposes.
204:207	Some of the positive results from use of the SD representation, as well as the evaluations carried out in the biomedical field, point to the usability of the SD scheme for both purposes.
205:207	Acknowledgments We wish to thank Andrew Brian Clegg and Sampo Pyysalo for their useful feedback on the dependency extraction tool.
206:207	Their comments enabled us to improve the tool.
207:207	We also thank the workshop reviewers for their helpful comments.

