Marcu (1999) uses a decision-tree learner and shallow syntactic features 96 to create classi ers for discourse segmentation and for identifying rhetorical relations.
P99-1047
However, the results are trees of Rhetorical Structure Theory (RST) (Mann and Thompson, 1986), and the classi ers rely on well-formedness constraints on RST trees which are too restrictive (Moore and Pollack, 1992).
J92-4007
Weights for the levels are determined as in Collins (2003).
J03-4003
One exception is Marcu’s work (Marcu, 1997, 1999) (see also Soricut and Marcu (2003) for constructing discourse structures for individual sentences).
N03-1030 P97-1013 P99-1047
Another main approach to robust dialogue processing has been statistical models for identifying dialogue acts (e.g., Stolcke et al.(2000)). However, dialogue acts are properties of utterances rather than hierarchically arranged relations between them, so they do not provide a basis for resolving semantic underspeci cation generated by the grammar (Asher and Lascarides, 2003).
J00-3003
Even so, it is interesting that the scores reported in Marcu (1999) for labelled and unlabelled relations are similar to our scores for Model 4.
P99-1047
It is hard to compare these models with Marcu’s (1999) rhetorical parsing model.
P99-1047
We use dialogues from Redwoods’ appointment scheduling domain and adapt head-driven generative parsing strategies from sentential parsing (e.g., Collins (2003)) for discourse parsing.
J03-4003
For the rst, the labelled/unlabelled relations fscores are 50.3%/73.0% and for the latter, they are 75.3%/84.0% this is similar to the performance on other discourse annotation projects, e.g., Carlson et al.(2001). On the same ten dialogues, Model 4 achieves 42.3%/64.9%.
W01-1605
One of the most important developments in this work is that of Collins (2003).
J03-4003
