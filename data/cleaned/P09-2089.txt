Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 353–356,
Suntec, Singapore, 4 August 2009. c 2009 ACL and AFNLP
Updating a Name Tagger Using Contemporary Unlabeled Data
Cristina Mota
L2F(INESC-ID)&IST&NYU
RuaAlvesRedol9
1000-029LisboaPortugal
cmota@ist.utl.pt
Ralph Grishman
NewYorkUniversity
ComputerScienceDepartment
NewYorkNY10003USA
grishman@cs.nyu.edu
Abstract
FormanyNLPtasks,including nameden-
tity tagging, semi-supervised learning has
been proposed as a reasonable alternative
to methods that require annotating large
amounts of training data. In this paper,
we address the problem of analyzing new
data given a semi-supervised NE tagger
trained on data from an earlier time pe-
riod. Wewillshowthatupdating theunla-
beled data issufficient to maintain quality
over time, and outperforms updating the
labeled data. Furthermore, we will also
show that augmenting the unlabeled data
with older data in most cases does not re-
sult in better performance than simply us-
ing a smaller amount of current unlabeled
data.
1 Introduction
Brill (2003) observed large gains in performance
for different NLP tasks solely by increasing the
size of unlabeled data, but stressed that for other
NLP tasks, such as named entity recognition
(NER),westill need to focus on developing tools
thathelptoincreasethesizeofannotated data.
This problem is particularly crucial when pro-
cessing languages, such as Portuguese, for which
thelabeled dataisscarce. Forinstance, inthefirst
NER evaluation for Portuguese, HAREM (San-
tos and Cardoso, 2007), only two out of the nine
participants presented systems based on machine
learning, and they both argued they could have
achieved significantly better results if they had
largertraining sets.
Semi-supervised methods are commonly cho-
sen as an alternative to overcome the lack of an-
notated resources, because they present a good
trade-off between amount of labeled data needed
and performance achieved. Co-training is one of
thosemethods,andhasbeenextensivelystudiedin
NLP(NigamandGhani,2000; PierceandCardie,
2001; Ng and Cardie, 2003; Mota and Grishman,
2008). In particular, we showed that the perfor-
mance of a name tagger based on co-training de-
cays as the time gap between training data (seeds
and unlabeled data) and test data increases (Mota
and Grishman, 2008). Compared to the original
classifier of Collins and Singer (1999) that uses
sevenseeds,weusedsubstantially largerseedsets
(more than 1000), which raises the question of
which ofthe parameters (seeds or unlabeled data)
arecausing theperformance deterioration.
In the present study, we investigated two main
questions, from the point of view of a developer
whowantstoanalyze anewdataset,givenanNE
tagger trained with older data. First, we studied
whether it was better to update the seeds or the
unlabeled data; then, we analyzed whether using
a smaller amount of current unlabeled data could
be better than increasing the amount of unlabeled
data drawn from older sources. The experiments
show that using contemporary unlabeled data is
the best choice, outperforming most experiments
with larger amounts of older unlabeled data and
allexperiments withcontemporary seeds.
2 Contemporary
labeled data in NLP
The speech community has been defending for
some time now the idea of having similar tem-
poral data for training and testing automatic
speech recognition systems for broadcast news.
Mostworksfocusonimprovingout-of-vocabulary
(OOV) rates, to which new names contribute
significantly. For instance, Palmer and Osten-
dorf (2005) aiming at reducing the error rate due
to OOV names propose to generate offline name
lists from diverse sources, including temporally
relevantnewstexts;FedericoandBertoldi(2004),
and Martins et al. (2006) propose to daily adapt
the statistical language model of a broadcast
353
news transcription system, exploiting contempo-
rarynewswiretextsavailableontheweb;Auzanne
et al. (2000) proposed a time-adaptive language
model, studying its impact over a period of five
months on the reduction of OOV rate, word error
rate and retrieval accuracy on a spoken document
retrievalsystem.
Concerning variations over longer periods of
time,weobservedthattheperformance ofasemi-
supervised name tagger decays over a period of
eight years, which seems to be directly related
withthefactthatthetextsusedtotrainandtestthe
tagger also show a tendency to become less simi-
lar over time (Mota and Grishman, 2008); Batista
etal.(2008)alsoobserved adecaying tendency in
the performance of a system for recovering capi-
talization over a period of six years, proposing to
retrain a MaxEnt model using additional contem-
porarywrittentexts.
3 Name
tagger overview
We assessed the name tagger described in Mota
and Grishman (2008) to recognize names of peo-
ple, organizations and locations. The tagger is
based on the co-training NE classifier proposed
by Collins and Singer (1999), and is comprised
of several components organized sequentially (cf.
Figure1).
g15g21g31g32g1g32g21g35g32
g13g17g25g30g31g1g2g12g8g5g19g28g27g32g21g35g32g3
g11g17g18g21g26g21g20g1g13g17g25g30g31
g1g15g21g35g32g1g34g25g32g24g1g19g26g17g31g31g25g36g21g20g1g12g8
g15g21g35g32g1g34g25g32g24g1g33g27g19g26g17g31g31g25g36g21g20g1g12g8g10g20g21g27g32g25g36g19g17g32g25g28g27
g7g26g17g31g31g25g36g19g17g32g25g28g27
g13g30g28g29g17g23g17g32g25g28g27
g9g21g17g32g33g30g21g1g21g35g32g30g17g19g32g25g28g27
g13g17g25g30g31g1g2g31g29g21g26g26g25g27g23g1g22g21g17g32g33g30g21g31g5g1
g19g28g27g32g21g35g32g33g17g26g1g22g21g17g32g33g30g21g31g3
g7g28g6g32g30g17g25g27g25g27g23
g14g29g21g26g26g25g27g23g1g4g1
g19g28g27g32g21g35g32g33g17g26g1g30g33g26g21g31
g14g21g21g20g31g1
g16g27g26g17g18g21g26g21g20g1g32g21g35g32
g1g3g8g9g5g6g4g1g7g2g5g6g5g6g4
Figure1: NEtaggerarchitecture
4 Data
sets
CETEMP´ublico (Rocha and Santos, 2000) is a
Portuguese journalistic corpus with 180 million
words that spans eight years of news, from 1991
to 1998. The minimum size of epoch (time span
of data set) available for analysis is a six-month
period,corresponding eithertothefirsthalfofthe
yearorthesecond.
The data sets were created using the first 8256
extracts1 withineach six-month period ofthepol-
iticssectionofthecorpus: thefirst192areusedto
collectseeds,thenext208extractsareusedastest
setsandtheremaining7856areusedtocollectthe
unlabeled examples. The seeds correspond to the
first1150namesoccurringinthoseextracts. From
the list of unlabeled examples obtained after the
NEidentificationstage,onlythefirst41226exam-
ples of each epoch were used to bootstrap in the
classification stage.
5 Experiments
We denote by S, U and T, respectively, the seed,
unlabeled and test texts, and by (Si, Uj, Tk) a
training-test configuration, where 91a ≤ i,j,k ≤
98b, i.e., epochs i, j and k vary between the first
half of 1991 (91a) and the second half of 1998
(98b). Forinstance,thetraining-test configuration
(Si=91a...98b, Ui=91a...98b, Tj=98b) represents the
training-test configuration where the test set was
drawnfromepoch98b,andthetaggerwastrained
in turn with seeds and unlabeled data drawn from
thesameepoch i thatvariedfrom91ato98b.
5.1 Do
we need contemporary labeled data?
Inorder tounderstand whether itisbetter to label
examples falling within the epoch of the test set
or to keep using old labeled data while bootstrap-
ping with contemporary unlabeled data, we fixed
thetestsettobewithinthelastepochoftheinter-
val (98b), and performed backward experiments,
i.e.,wevaried the epoch of either the seeds orthe
unlabeled data backwards. The choice of fixing
the test within the last epoch of the interval is the
one that mostapproximates areal situation where
onehasataggertrainedwitholddataandwantsto
processamorerecenttext.
Figure2showstheresultsforbothexperiments,
where(Sj=98b,Ui=91a...98b,Tj=98b)representsthe
experiment where the test was within the same
epoch as the seeds and the unlabeled data were
drawn from a single, variable, epoch in turn, and
(Si=91a...98b,Uj=98b,Tj=98b)representstheexper-
iment where the test was within the epoch of the
1Extractsaretypicallytwoparagraphs.
354
unlabeled data and the seeds were drawn in turn
from each of the epochs; the graphic also shows
thebaseline backward training (varying theepoch
ofboththeseedsandtheunlabeled datatogether).
0.74
0.76
0.78
0.80
0.82
Training epoch
F−measure
(i,i,98b)
(98b,i,98b)
(i,98b,98b)
91a 91b 92a 92b 93a 93b 94a 94b 95a 95b 96a 96b 97a 97b 98a 98b
Figure2: F-measureovertimefortestset98bwith
configurations: (Si=91a...98b, Ui=91a...98b, Tj=98b),
(Sj=98b, Ui=91a...98b, Tj=98b), and (Si=91a...98b,
Uj=98b, Tj=98b)
As can be seen, there is a small gain in perfor-
mance by using seeds within the epoch of the test
set,butthedecayisstillobservableasweincrease
the time gap between the unlabeled data and the
test set. On the contrary, if weuse unlabeled data
within the epoch of the test set, we hardly see
a degradation trend as the time gap between the
epochsofseedsandtestsetisincreased.
An examination of the results shows that, for
instance, Sendero Luminoso received the correct
classification of organization when the tagger is
trained with unlabeled data drawn from the same
epoch, but is incorretly classified as person when
trainedwithdatathatisnotcontemporarywiththe
testset. Eventhoughthatnameisnotaseedinany
of the cases, it occurs twice in good contexts for
organization in unlabeled data contemporary with
the test set (l´ıder do Sendero Luminoso/leader of
the Shining Path and acc¸ ˜oes do Sendero Lumi-
noso/actions of the Shining Path), while it does
notoccurintheunlabeled datathatisnotcontem-
porary. Given that both the name spelling and the
context in the test set, o messianismo do peruano
Sendero Luminoso/the messianism of the Peruvian
Shining Path,areinsufficienttoassignacorrectla-
bel, the occurrence of the name in the contempo-
rary unlabeled data contributes to its correct clas-
sificationinthetestset.
5.2 Is
more older unlabeled data better?
The second question we addressed was whether
having more older unlabeled data could result in
better performance than less data but within the
epoch of the test set. In this case, we conducted
two backward experiments, augmenting the un-
labeled data backwards with older data than the
testset(98b),startinginthepreviousepoch(98a):
in the first experiment, the seeds were within the
same epoch as the test set, and in the second ex-
perimenttheseedswerewithinthesameepoch as
theunlabeledsetbeingadded. Thiscorrespondsto
configurations (Sj=98b, Uprimei=91a...98a, Tj=98b) and
(Si=91a...98a, Uprimei=91a...98a, Tj=98b), respectively,
where Uprimei = uniontext98ak=i Uk.
In Figure 3, we show the result of these con-
figurations together with the result of the back-
ward experiment corresponding to configuration
(Si=91a...98b, Uj=98b, Tj=98b), also represented in
Figure 2. We note that, in the case of the former
experiments,thesizeoftheunlabeled examplesis
increasing inthedirection 98ato91a.
0.77
0.78
0.79
0.80
0.81
0.82
0.83
Training epoch
F−measure
(i,98b,98b)
(i,u[i,...,98a],98b)
(98b,u[i,...,98a],98b)
91a 91b 92a 92b 93a 93b 94a 94b 95a 95b 96a 96b 97a 97b 98a 98b
Figure 3: F-measure for test set 98b with
configurations (Si=91a...98b, Uj=98b, Tj=98b),
(Sj=98b, Uprimei=91a...98a, Tj=98b) and (Si=91a...98a,
Uprimei=91a...98a, Tj=98b),where Uprimei = uniontext98ak=i Uk
As can be observed, increasing the size of the
unlabeled data does not necessarily result in bet-
terperformance: forbothchoicesofseeds,perfor-
mance sometimes improves, sometimes worsens,
as the unlabeled data grows (following the curves
355
fromrighttoleft).
Furthermore,thetaggertrainedwithmoreunla-
beled data in most cases did not outperform the
tagger trained with less unlabeled data selected
fromtheepochofthetestset.
6 Discussion
and future directions
We conducted experiments varying the epoch of
seeds andunlabeled data ofanamedentity tagger
based on co-training. We observed that the per-
formancedecayresultingfromincreasingthetime
gapbetweentrainingdata(seedsandunlabeledex-
amples) and the test set can be slightly attenuated
byusing theseeds contemporary withthetest set.
Thegainislarger ifoneusesolderseedsandcon-
temporary unlabeled data, a strategy that, in most
of the experiments, results in better performance
thanusingincreasingsizesofolderunlabeleddata.
These results suggest that we may not need to
labelnewdatanortrainourtaggerwithincreasing
sizesofdata,aslongasweareabletotrainitwith
unlabeled datatimecompatiblewiththetestset.
Inthefuture,oneissuethatneedsclarificationis
whybootstraping fromcontemporary labeleddata
had so little influence on the performance of co-
training, and if other semi-supervised approches
arealsosensitivetothisquestion.
Acknowledgment
The first author’s research work was funded by
Fundac¸˜aoparaaCiˆenciaeaTecnologia through a
doctoral scholarship (ref.: SFRH/BD/3237/2000).
References
C´edricAuzanne,JohnS.Garofolo,JonathanG.Fiscus,
and William M. Fisher. 2000. Automatic language
modeladaptationforspokendocumentretrieval. In
Proceedings of RIAO 2000 Conference on Content-
Based Multimedia Information Access.
FernandoBatista,NunoMamede,andIsabelTrancoso.
2008. Language dynamics and capitalization using
maximumentropy. InProceedings of ACL-08: HLT,
Short Papers,pages1–4,Columbus,Ohio,June.As-
sociationforComputationalLinguistics.
Eric Brill. 2003. Processing natural language with-
outnaturallanguageprocessing. In CICLing,pages
360–369.
Michael Collins and Yoram Singer. 1999. Unsuper-
vised models for named entity classification. In
Proceedings of the Joint SIGDAT Conference on
EMNLP.
MarcelloFederico and Nicola Bertoldi. 2004. Broad-
cast news lm adaptation over time. Computer
Speech & Language,18(4):417–435.
Ciro Martins, Ant´onioTeixeira, and Jo˜ao Neto. 2006.
Dynamic vocabulary adaptation for a daily and
real-time broadcast news transcription system. In
IEEE/ACL Workshop on Spoken Language Technol-
ogy,Aruba.
Cristina Mota and Ralph Grishman. 2008. Is this NE
tagger getting old? In Proceedings of the Sixth
International Language Resources and Evaluation
(LREC’08),Marrakech,Morocco,may.
Vincente Ng and Claire Cardie. 2003. Weakly super-
vised natural language learning without redundant
views. In NAACL’03: Proceedings of the 2003 Con-
ference of the North American Chapter of the As-
sociation for Computational Linguistics on Human
Language Technology, pages 94–101, Morristown,
NJ,USA.ACL.
Kamal Nigam and Rayid Ghani. 2000. Analyzing
theeffectivenessandapplicabilityofco-training. In
Proceedings of CIKM,pages86–93.
David D. Palmer and Mari Ostendorf. 2005. Improv-
ing out-of-vocabulary name resolution. Computer
Speech & Language,19(1):107–128.
David Pierce and Claire Cardie. 2001. Limitationsof
co-trainingfornaturallanguagelearningfromlarge
datasets. In Proceedings of the 2001 Conference on
Empirical Methods in Natural Language Processing
(EMNLP-2001).
Paulo Rocha and Diana Santos. 2000. Cetemp´ublico:
Um corpus de grandes dimens˜oes de linguagem
jornal´ıstica portuguesa. In Maria das Grac¸as
Volpe Nunes, editor, Actas do V Encontro para o
processamento computacional da l´ıngua portuguesa
escrita e falada PROPOR 2000,pages131–140,At-
ibaia,S˜aoPaulo,Brasil.
Diana Santos and Nuno Cardoso, editors. 2007. Re-
conhecimento de entidades mencionadas em por-
tuguˆes: Documentac¸˜ao e actas do HAREM, a
primeira avaliac¸˜ao conjunta na ´area. Linguateca,
12deNovembro.
356

