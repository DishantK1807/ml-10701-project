1:215	Coling 2008 22nd International Conference on Computational Linguistics Proceedings of the workshop on Grammar Engineering Across Frameworks Workshop chairs: Stephen Clark and Tracy Holloway King 24 August 2008 Manchester, UK c2008 The Coling 2008 Organizing Committee Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Nonported license http://creativecommons.org/licenses/by-nc-sa/3.0/ Some rights reserved Order copies of this and other Coling proceedings from: Association for Computational Linguistics (ACL) 209 N. Eighth Street Stroudsburg, PA 18360 USA Tel: +1-570-476-8006 Fax: +1-570-476-0860 acl@aclweb.org ISBN 978-1-905593-54-5 Design by Chimney Design, Brighton, UK Production and manufacture by One Digital, Brighton, UK ii Introduction The GEAF workshop aims to bring together grammar engineers from different frameworks to compare research and methodologies, particularly around the themes of evaluation, modularity, maintainability, relevance to theoretical and computational linguistics, and applications of deep grammars to realworld domains and NLP tasks.
2:215	Recent years have seen the development of techniques and resources to support robust, deep grammatical analysis of natural language in real-world domains and applications.
3:215	The demands of these types of tasks have resulted in significant advances in areas such as parser efficiency, hybrid statistical/symbolic approaches to disambiguation, and the acquisition of large-scale lexicons.
4:215	The effective acquisition, development, maintenance and enhancement of grammars is a central issue in suchefforts,andthesizeandcomplexityofrealisticgrammarsmakesthesetasksextremelychallenging; indeed,thesetasksareoftentackledinwaysthathavemuchincommonwithsoftwareengineering.
5:215	This workshop aims to bring together grammar engineers from different frameworks  for example LFG, HPSG, TAG, CCG, dependency grammar  to compare their research and methodologies.
6:215	We would like to thank the program committee Jason Baldridge, Emily Bender, Miriam Butt, Aoife Cahill, John Carroll, Ann Copestake, Berthold Crysmann, Mary Dalrymple, Stefanie Dipper, Dan Flickinger, Josef van Genabith, Ron Kaplan, Montserrat Marimon, Yusuke Miyao, Owen Rambow, and Jesse Tseng for their detailed reviews of all of the submitted papers, and Prof. Junichi Tsujii for agreeing to give the invited talk.
7:215	In addition, we would like to thank Mark Stevenson for helping with general COLING workshop organization and Roger Evans for helping create these proceedings.
8:215	iii  Organizers: Stephen Clark, Oxford University Tracy Holloway King, Palo Alto Research Center Programme Committee: Jason Baldridge, University of Texas at Austin Emily Bender, University of Washington Miriam Butt, Universitat Konstanz Aoife Cahill, Universitat Stuttgart John Carroll, University of Sussex Ann Copestake, Cambridge University Berthold Crysmann, Bonn Mary Dalrymple, Oxford University Stefanie Dipper, Ruhr-Universitat Bochum Dan Flickinger, Stanford University Josef van Genabith, Dublin City University Ron Kaplan, Powerset Montserrat Marimon, Universitat Pompeu Fabra Yusuke Miyao, University of Tokyo Owen Rambow, Columbia University Jesse Tseng, CNRS Invited Speaker: Junichi Tsujii, Univerity of Tokyo and University of Manchester v  Table of Contents TuLiPA: Towards a Multi-Formalism Parsing Environment for Grammar Engineering Laura Kallmeyer, Timm Lichte, Wolfgang Maier, Yannick Parmentier, Johannes Dellert and Kilian Evang . . .
9:215	1 Making Speech Look Like Text in the Regulus Development Environment Elisabeth Kron, Manny Rayner, Marianne Santaholma, Pierrette Bouillon and Agnes Lisowska . . 9 A More Precise Analysis of Punctuation for Broad-Coverage Surface Realization with CCG Michael White and Rajakrishnan Rajkumar.
10:215	.17 Multilingual Grammar Resources in Multilingual Application Development Marianne Santaholma . . .
11:215	25 Speeding up LFG Parsing Using C-Structure Pruning Aoife Cahill, John T. Maxwell III, Paul Meurer, Christian Rohrer and Victoria Rosen . . .
12:215	33 From Grammar-Independent Construction Enumeration to Lexical Types in Computational Grammars Lars Hellan . . .
13:215	41 Designing Testsuites for Grammar-based Systems in Applications Valeria de Paiva and Tracy Holloway King . . .
14:215	49 Towards Domain-Independent Deep Linguistic Processing: Ensuring Portability and Re-Usability of Lexicalised Grammars Kostadin Cholakov, Valia Kordoni and Yi Zhang . . .
15:215	57 vii  Conference Programme Sunday, August 24, 2008 9:009:15 Opening Remarks 9:1510:30 Invited Talk by Junichi Tsujii 10:3011:00 Break 11:0011:30 TuLiPA:TowardsaMulti-FormalismParsingEnvironmentforGrammarEngineering Laura Kallmeyer, Timm Lichte, Wolfgang Maier, Yannick Parmentier, Johannes Dellert and Kilian Evang 11:3012:00 Making Speech Look Like Text in the Regulus Development Environment Elisabeth Kron, Manny Rayner, Marianne Santaholma, Pierrette Bouillon and Agnes Lisowska 12:0012:30 A More Precise Analysis of Punctuation for Broad-Coverage Surface Realization with CCG Michael White and Rajakrishnan Rajkumar 12:30-14:00 Lunch 14:0014:30 Multilingual Grammar Resources in Multilingual Application Development Marianne Santaholma 14:3015:00 Speeding up LFG Parsing Using C-Structure Pruning Aoife Cahill, John T. Maxwell III, Paul Meurer, Christian Rohrer and Victoria Rosen 15:0015:30 From Grammar-Independent Construction Enumeration to Lexical Types in Computational Grammars Lars Hellan 15:3016:30 Demo Session with break TuLiPA: Towards a Multi-Formalism Parsing Environment for Grammar Engineering (Laura Kallmeyer, Timm Lichte, Wolfgang Maier, Yannick Parmentier, Johannes Dellert and Kilian Evang) Natural Language Entailment Using Implicit Information: An XLE Implementation (Daniel G. Bobrow, Bob Cheslow, Cleo Condoravdi, Lauri Karttunen, Tracy Holloway King, Charlotte Price and Annie Zaenen) The Regulus Development Environment (Elisabeth Kron, Manny Rayner, Pierrette Bouillon, Marianne Santaholma and Agnes Lisowska) ix Sunday, August 24, 2008 (continued) MedSLT: Rule-based Medical Speech Translation System (Pierrette Bouillon, Manny Rayner, Sonia Halimi, Beth Ann Hockey, Hitoshi Isahara, Kyoko Kanzaki, Yukie Nakao, Marianne Santaholma, Marianne Starlander and Nikos Tsourakis) Grammar and Output Representations in the C&C CCG Parser (Laura Rimell and Stephen Clark) Developing a Modular Parsing System for Semantic Analysis of Japanese: the Verb Phrase Module (Yukiko Sasaki Alam) The Checkpoint System: Hybrid Processing for Grammar and Style Checking (Tina Kluwer, Peter Adolphs and Berthold Crysmann) Cognitive Grammar-based Linguistic Processor for Knowledge Extraction from Russian and English Texts (Igor Kuznetsov and Elena Kozerenko) Defining and Viewing a Cross-linguistic Ontology of Verb Constructions (Lars Helan) 16:3017:00 Designing Testsuites for Grammar-based Systems in Applications Valeria de Paiva and Tracy Holloway King 17:0017:30 Towards Domain-Independent Deep Linguistic Processing: Ensuring Portability and Re-Usability of Lexicalised Grammars Kostadin Cholakov, Valia Kordoni and Yi Zhang x Coling 2008: Proceedings of the workshop on Grammar Engineering Across Frameworks, pages 18 Manchester, August 2008 TuLiPA: Towards a Multi-Formalism Parsing Environment for Grammar Engineering Laura Kallmeyer SFB 441 Universitat Tubingen D-72074, Tubingen, Germany lk@sfs.uni-tuebingen.de Yannick Parmentier CNRS LORIA Nancy Universite F-54506, Vanduvre, France parmenti@loria.fr Timm Lichte SFB 441 Universitat Tubingen D-72074, Tubingen, Germany timm.lichte@uni-tuebingen.de Johannes Dellert SFB 441 SfS Universitat Tubingen D-72074, Tubingen, Germany {jdellert,kevang}@sfs.uni-tuebingen.de Wolfgang Maier SFB 441 Universitat Tubingen D-72074, Tubingen, Germany wo.maier@uni-tuebingen.de Kilian Evang SFB 441 SfS Universitat Tubingen D-72074, Tubingen, Germany Abstract In this paper, we present an open-source parsing environment (Tubingen Linguistic Parsing Architecture, TuLiPA) which uses Range Concatenation Grammar (RCG) as a pivot formalism, thus opening the way to the parsing of several mildly context-sensitive formalisms.
16:215	This environment currently supports tree-based grammars (namely Tree-Adjoining Grammars (TAG) and Multi-Component TreeAdjoining Grammars with Tree Tuples (TT-MCTAG)) and allows computation not only of syntactic structures, but also of the corresponding semantic representations.
17:215	It is used for the development of a tree-based grammar for German.
18:215	1 Introduction Grammars and lexicons represent important linguistic resources for many NLP applications, among which one may cite dialog systems, automatic summarization or machine translation.
19:215	Developing such resources is known to be a complex task that needs useful tools such as parsers and generators (Erbach, 1992).
20:215	Furthermore, there is a lack of a common framework allowing for multi-formalism grammar engineering.
21:215	Thus, many formalisms have been proposed to model natural language, each coming with specific implementations.
22:215	Having a common framework would facilitate the comparison c2008.
23:215	Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
24:215	Some rights reserved.
25:215	between formalisms (e.g., in terms of parsing complexity in practice), and would allow for a better sharing of resources (e.g., having a common lexicon, from which different features would be extracted depending on the target formalism).
26:215	In this context, we present a parsing environment relying on a general architecture that can be used for parsing with mildly context-sensitive (MCS) formalisms1 (Joshi, 1987).
27:215	Its underlying idea is to use Range Concatenation Grammar (RCG) as a pivot formalism, for RCG has been shown to strictly include MCS languages while being parsable in polynomial time (Boullier, 2000).
28:215	Currently, this architecture supports tree-based grammars (Tree-Adjoining Grammars and MultiComponent Tree-Adjoining Grammars with Tree Tuples (Lichte, 2007)).
29:215	More precisely, treebased grammars are first converted into equivalent RCGs, which are then used for parsing.
30:215	The result of RCG parsing is finally interpreted to extract a derivation structure for the input grammar, as well as to perform additional processings (e.g., semantic calculus, extraction of dependency views).
31:215	The paper is structured as follows.
32:215	In section 2, we present the architecture of the TuLiPA parsing environment and show how the use of RCG as a pivot formalism makes it easier to design a modular system that can be extended to support several dimensions (syntax, semantics) and/or formalisms.
33:215	In section 3, we give some desiderata for grammar engineering and present TuLiPAs current state 1A formalism is said to be mildly context sensitive (MCS) iff (i) it generates limited cross-serial dependencies, (ii) it is polynomially parsable, and (iii) the string languages generated by the formalism have the constant growth property (e.g., {a2n|n  0} does not have this property).
34:215	Examples of MCS formalisms include Tree-Adjoining Grammars, Combinatory Categorial Grammars and Linear Indexed Grammars.
35:215	1 with respect to these.
36:215	In section 4, we compare this system with existing approaches for parsing and more generally for grammar engineering.
37:215	Finally, in section 5, we conclude by presenting future work.
38:215	2 Range Concatenation Grammar as a pivot formalism The main idea underlying TuLiPA is to use RCG as a pivot formalism for RCG has appealing formal properties (e.g., a generative capacity lying beyond Linear Context Free Rewriting Systems and a polynomial parsing complexity) and there exist efficient algorithms, for RCG parsing (Boullier, 2000) and for grammar transformation into RCG (Boullier, 1998; Boullier, 1999).
39:215	Parsing with TuLiPA is thus a 3-step process: 1.
40:215	The input tree-based grammar is converted into an RCG (using the algorithm of Kallmeyer and Parmentier (2008) when dealing with TT-MCTAG).
41:215	2.
42:215	The resulting RCG is used for parsing the input string using an extension of the parsing algorithm of Boullier (2000).
43:215	3.
44:215	The RCG derivation structure is interpreted to extract the derivation and derived trees with respect to the input grammar.
45:215	The use of RCG as a pivot formalism, and thus of an RCG parser as a core component of the system, leads to a modular architecture.
46:215	In turns, this makes TuLiPA more easily extensible, either in terms of functionalities, or in terms of formalisms.
47:215	2.1 Adding functionalities to the parsing environment As an illustration of TuLiPAs extensibility, one may consider two extensions applied to the system recently.
48:215	First, a semantic calculus using the syntax/semantics interface for TAG proposed by Gardent and Kallmeyer (2003) has been added.
49:215	This interface associates each tree with flat semantic formulas.
50:215	The arguments of these formulas are unification variables, which are co-indexed with features labelling the nodes of the syntactic tree.
51:215	During classical TAG derivation, trees are combined, triggering unifications of the feature structures labelling nodes.
52:215	As a result of these unifications, the arguments of the semantic formulas are unified (see Fig.
53:215	1).
54:215	S NPx VP NPj V NPy NPm John loves Mary name(j,john) love(x,y) name(m,mary) a59 love(j,m),name(j,john),name(m,mary) Figure 1: Semantic calculus in Feature-Based TAG.
55:215	In our system, the semantic support has been integrated by (i) extending the internal tree objects to include semantic formulas (the RCG-conversion is kept unchanged), and (ii) extending the construction of the derived tree (step 3) so that during the interpretation of the RCG derivation in terms of tree combinations, the semantic formulas are carried and updated with respect to the feature unifications performed.
56:215	Secondly, let us consider lexical disambiguation.
57:215	Because of the high redundancy lying within lexicalized formalisms such as lexicalized TAG, it is common to consider tree schemata having a frontier node marked for anchoring (i.e., lexicalization).
58:215	At parsing time, the tree schemata are anchored according to the input string.
59:215	This anchoring selects a subgrammar supposed to cover the input string.
60:215	Unfortunately, this subgrammar may contain many trees that either do not lead to a parse or for which we know a priori that they cannot be combined within the same derivation (so we should not predict a derivation from one of these trees to another during parsing).
61:215	As a result, the parser could have poor performance because of the many derivation paths that have to be explored.
62:215	Bonfante et al.63:215	(2004) proposed to polarize the structures of the grammar, and to apply an automaton-based filtering of the compatible structures.
64:215	The idea is the following.
65:215	One compute polarities representing the needs/resources brought by a given tree (or tree tuple for TT-MCTAG).
66:215	A substitution or foot node with category NP reflects a need for an NP (written NP-).
67:215	In the same way, an NP root node reflects a resource of type NP (written NP+).
68:215	Then you build an automaton whose edges correspond to trees, and states to polarities brought by trees along the path.
69:215	The automaton is then traversed to extract all paths leading to a final state with a neutral polarity for each category and +1 for the axiom (see Fig.
70:215	2, the state 2 7 is the only valid state and {proper., trans., det., noun.}
71:215	the only compatible set of trees).
72:215	0 John 1 1 eats 2 2 a 3 3 cake 4 0 1 NP+ 2 S+ 3 S+ NP4 S+ 5 S+ NP6 S+ NP+ 7 S+ proper.
73:215	intrans.
74:215	trans.
75:215	det. det. noun.
76:215	noun.
77:215	Figure 2: Polarity-based lexical disambiguation.
78:215	In our context, this polarity filtering has been added before step 1, leaving untouched the core RCG conversion and parsing steps.
79:215	The idea is to compute the sets of compatible trees (or tree tuples for TT-MCTAG) and to convert these sets separately.
80:215	Indeed the RCG has to encode only valid adjunctions/substitutions.
81:215	Thanks to this automaton-based clustering of the compatible tree (or tree tuples), we avoid predicting incompatible derivations.
82:215	Note that the time saved by using a polarity-based filter is not negligible, especially when parsing long sentences.2 2.2 Adding formalisms to the parsing environment Of course, the two extensions introduced in the previous section may have been added to other modular architectures as well.
83:215	The main gain brought by RCG is the possibility to parse not only tree-based grammars, but other formalisms provided they can be encoded into RCG.
84:215	In our system, only TAG and TT-MCTAG have been considered so far.
85:215	Nonetheless, Boullier (1998) and Sgaard (2007) have defined transformations into RCG for other mildly context-sensitive formalisms.3 To sum up, the idea would be to keep the core RCG parser, and to extend TuLiPA with a specific conversion module for each targeted formalism.
86:215	On top of these conversion modules, one should also provide interpretation modules allowing to decode the RCG derivation forest in terms of the input formalism (see Fig.
87:215	3).
88:215	2An evaluation of the gain brought by this technique when using Interaction Grammar is given by Bonfante et al.89:215	(2004).
90:215	3These include Multi-Component Tree-Adjoining Grammar, Linear Indexed Grammar, Head Grammar, Coupled Context Free Grammar, Right Linear Unification Grammar and Synchronous Unification Grammar.
91:215	Figure 3: Towards a multi-formalism parsing environment.
92:215	An important point remains to be discussed.
93:215	It concerns the role of lexicalization with respect to the formalism used.
94:215	Indeed, the tree-based grammar formalisms currently supported (TAG and TTMCTAG) both share the same lexicalization process (i.e., tree anchoring).
95:215	Thus the lexicon format is common to these formalisms.
96:215	As we will see below, it corresponds to a 2-layer lexicon made of inflected forms and lemma respectively, the latter selecting specific grammatical structures.
97:215	When parsing other formalisms, it is still unclear whether one can use the same lexicon format, and if not what kind of general lexicon management module should be added to the parser (in particular to deal with morphology).
98:215	3 Towards a complete grammar engineering environment So far, we have seen how to use a generic parsing architecture relying on RCG to parse different formalisms.
99:215	In this section, we adopt a broader view and enumerate some requirements for a linguistic resource development environment.
100:215	We also see to what extent these requirements are fulfilled (or partially fulfilled) within the TuLiPA system.
101:215	3.1 Grammar engineering with TuLiPA As advocated by Erbach (1992), grammar engineering needs tools for testing the grammar with respect to consistency, coverage, overgeneration and accuracy.
102:215	These characteristics may be taken into account by different interacting software.
103:215	Thus, consistency can be checked by a semiautomatic grammar production device, such as the XMG system of Duchier et al.104:215	(2004).
105:215	Overgeneration is mainly checked by a generator (or by a parser with adequate test suites), and coverage and accuracy by a parser.
106:215	In our case, the TuLiPA system provides an entry point for using a grammar production system (and a lexicon conversion 3 tool introduced below), while including a parser.
107:215	Note that TuLiPA does not include any generator, nonetheless it uses the same lexicon format as the GenI surface realizer for TAG4.
108:215	TuLiPAs input grammar is designed using XMG, which is a metagrammar compiler for treebased formalisms.
109:215	In other terms, the linguist defines a factorized description of the grammar (the so-called metagrammar) in the XMG language.
110:215	Briefly, an XMG metagrammar consists of (i) elementary tree fragments represented as tree description logic formulas, and (ii) conjunctive and disjunctive combinations of these tree fragments to describe actual TAG tree schemata.5 This metagrammar is then compiled by the XMG system to produce a tree grammar in an XML format.
111:215	Note that the resulting grammar contains tree schemata (i.e., unlexicalized trees).
112:215	To lexicalize these, the linguist defines a lexicon mapping words with corresponding sets of trees.
113:215	Following XTAG (2001), this lexicon is a 2-layer lexicon made of morphological and lemma specifications.
114:215	The motivation of this 2-layer format is (i) to express linguistic generalizations at the lexicon level, and (ii) to allow the parser to only select a subgrammar according to a given sentence, thus reducing parsing complexity.
115:215	TuLiPA comes with a lexicon conversion tool (namely lexConverter) allowing to write a lexicon in a user-friendly text format and to convert it into XML.
116:215	An example of an entry of such a lexicon is given in Fig.
117:215	4.
118:215	The morphological specification consists of a word, the corresponding lemma and morphological features.
119:215	The main pieces of information contained in the lemma specification are the ENTRY field, which refers to the lemma, the CAT field referring to the syntactic category of the anchor node, the SEM field containing some semantic information allowing for semantic instantiation, the FAM field, which contains the name of the tree family to be anchored, the FILTERS field which consists of a feature structure constraining by unification the trees of a given family that can be anchored by the given lemma (used for instance for non-passivable verbs), the EQUATIONS field allowing for the definition of equations targeting named nodes of the trees, and the COANCHORS field, which allows for the specification of coanchors (such as by in the verb to come by).
120:215	4http://trac.loria.fr/geni 5See (Crabbe, 2005) for a presentation on how to use the XMG formalism for describing a core TAG for French.
121:215	Morphological specification: vergisst vergessen [pos=v,num=sg,per=3] Lemma specification: ENTRY: vergessen CAT: v SEM: BinaryRel[pred=vergessen] ACC: 1 FAM: Vnp2 FILTERS: [] EX: EQUATIONS: NParg1  cas = nom NParg2  cas = acc COANCHORS: Figure 4: Morphological and lemma specification of vergisst.
122:215	From these XML resources, TuLiPA parses a string, corresponding either to a sentence or a constituent (noun phrase, prepositional phrase, etc.), and computes several output pieces of information, namely (for TAG and TT-MCTAG): derivation/derived trees, semantic representations (computed from underspecified representations using the utool software6, or dependency views of the derivation trees (using the DTool software7).
123:215	3.2 Grammar debugging The engineering process introduced in the preceding section belongs to a development cycle, where one first designs a grammar and corresponding lexicons using XMG, then checks these with the parser, fixes them, parses again, and so on.
124:215	To facilitate grammar debugging, TuLiPA includes both a verbose and a robust mode allowing respectively to (i) produce a log of the RCGconversion, RCG-parsing and RCG-derivation interpretation, and (ii) display mismatching features leading to incomplete derivations.
125:215	More precisely, in robust mode, the parser displays derivations step by step, highlighting feature unification failures.
126:215	TuLiPAs options can be activated via an intuitive Graphical User Interface (see Fig.
127:215	5).
128:215	6See http://www.coli.uni-saarland.de/ projects/chorus/utool/, with courtesy of Alexander Koller.
129:215	7With courtesy of Marco Kuhlmann.
130:215	4 Figure 5: TuLiPAs Graphical User Interface.
131:215	3.3 Towards a functional common interface Unfortunately, as mentioned above, the linguist has to move back-and-forth from the grammar/lexicon descriptions to the parser, i.e., each time the parser reports grammar errors, the linguist fixes these and then recomputes the XML files and then parses again.
132:215	To avoid this tedious task of resources re-compilation, we started developing an Eclipse8 plug-in for the TuLiPA system.
133:215	Thus, the linguist will be able to manage all these resources, and to call the parser, the metagrammar compiler, and the lexConverter from a common interface (see Fig.
134:215	6).
135:215	Figure 6: TuLiPAs eclipse plug-in.
136:215	The motivation for this plug-in comes from the observation that designing electronic grammars is a task comparable to designing source 8See http://www.eclipse.org code.
137:215	A powerful grammar engineering environment should thus come with development facilities such as precise debugging information, syntax highlighting, etc. Using the Eclipse open-source development platform allows for reusing several components inherited from the software development community, such as plug-ins for version control, editors coupled with explorers, etc. Eventually, one point worth considering in the context of grammar development concerns data encoding.
138:215	To our knowledge, only few environments provide support for UTF-8 encoding, thus guarantying the coverage of a wide set of charsets and languages.
139:215	In TuLiPA, we added an UTF-8 support (in the lexConverter), thus allowing to design a TAG for Korean (work in progress).
140:215	3.4 Usability of the TuLiPA system As mentioned above, the TuLiPA system is made of several interacting components, that one currently has to install separately.
141:215	Nonetheless, much attention has been paid to make this installation process as easy as possible and compatible with all major platforms.9 XMG and lexConverter can be installed by compiling their sources (using a make command).
142:215	TuLiPA is developed in Java and released as an executable jar.
143:215	No compilation is needed for it, the only requirement is the Gecode/GecodeJ library10 (available as a binary package for many platforms).
144:215	Finally, the TuLiPA eclipse plug-in can be installed easily from eclipse itself.
145:215	All these tools are released under Free software licenses (either GNU GPL or Eclipse Public License).
146:215	This environment is being used (i) at the University of Tubingen, in the context of the development of a TT-MCTAG for German describing both syntax and semantics, and (ii) at LORIA Nancy, in the development of an XTAG-based metagrammar for English.
147:215	The German grammar, called GerTT (for German Tree Tuples), is released under a LGPL license for Linguistic Resources11 and is presented in (Kallmeyer et al., 2008).
148:215	The test-suite currently used to check the grammar is hand-crafted.
149:215	A more systematic evaluation of the grammar is in preparation, using the Test Suite for Natural Language Processing (Lehmann et al., 1996).
150:215	9See http://sourcesup.cru.fr/tulipa.
151:215	10See http://www.gecode.org/gecodej.
152:215	11See http://infolingu.univ-mlv.
153:215	fr/DonneesLinguistiques/ Lexiques-Grammaires/lgpllr.html 5 4 Comparison with existing approaches 4.1 Engineering environments for tree-based grammar formalisms To our knowledge, there is currently no available parsing environment for multi-component TAG.
154:215	Existing grammar engineering environments for TAG include the DyALog system12 described in Villemonte de la Clergerie (2005).
155:215	DyALog is a compiler for a logic programming language using tabulation and dynamic programming techniques.
156:215	This compiler has been used to implement efficient parsing algorithms for several formalisms, including TAG and RCG.
157:215	Unfortunately, it does not include any built-in GUI and requires a good knowledge of the GNU build tools to compile parsers.
158:215	This makes it relatively difficult to use.
159:215	DyALogs main quality lies in its efficiency in terms of parsing time and its capacity to handle very large resources.
160:215	Unlike TuLiPA, it does not compute semantic representations.
161:215	The closest approach to TuLiPA corresponds to the SemTAG system13, which extends TAG parsers compiled with DyALog with a semantic calculus module (Gardent and Parmentier, 2007).
162:215	Unlike TuLiPA, this system only supports TAG, and does not provide any graphical output allowing to easily check the result of parsing.
163:215	Note that, for grammar designers mainly interested in TAG, SemTAG and TuLiPA can be seen as complementary tools.
164:215	Indeed, one may use TuLiPA to develop the grammar and check specific syntactic structures thanks to its intuitive parsing environment.
165:215	Once the grammar is stable, one may use SemTAG in batch processing to parse corpuses and build semantic representations using large grammars.
166:215	This combination of these 2 systems is made easier by the fact that both use the same input formats (a metagrammar in the XMG language and a text-based lexicon).
167:215	This approach is the one being adopted for the development of a French TAG equipped with semantics.
168:215	For Interaction Grammar (Perrier, 2000), there exists an engineering environment gathering the XMG metagrammar compiler and an eLEtrOstatic PARser (LEOPAR).14 This environment is being used to develop an Interaction Grammar for French.
169:215	TuLiPAs lexical disambiguation module 12See http://dyalog.gforge.inria.fr 13See http://trac.loria.fr/semconst 14See http://www.loria.fr/equipes/ calligramme/leopar/ reuses techniques introduced by LEOPAR.
170:215	Unlike TuLiPA, LEOPAR does not currently support semantic information.
171:215	4.2 Engineering environments for other grammar formalisms For other formalisms, there exist state-of-the-art grammar engineering environments that have been used for many years to design large deep grammars for several languages.
172:215	For Lexical Functional Grammar, one may cite the Xerox Linguistic Environment (XLE).15 For Head-driven Phrase Structure Grammar, the main available systems are the Linguistic Knowledge Base (LKB)16 and the TRALE system.17 For Combinatory Categorial Grammar, one may cite the OpenCCG library18 and the C&C parser.19 These environments have been used to develop broad-coverage resources equipped with semantics and include both a generator and a parser.
173:215	Unlike TuLiPA, they represent advanced projects, that have been used for dialog and machine translation applications.
174:215	They are mainly tailored for a specific formalism.20 5 Future work In this section, we give some prospective views concerning engineering environments in general, and TuLiPA in particular.
175:215	We first distinguish between 2 main usages of grammar engineering environments, namely a pedagogical usage and an application-oriented usage, and finally give some comments about multi-formalism.
176:215	5.1 Pedagogical usage Developing grammars in a pedagogical context needs facilities allowing for inspection of the structures of the grammar, step-by-step parsing (or generation), along with an intuitive interface.
177:215	The idea is to abstract away from technical aspects related to implementation (intermediate data structures, optimizations, etc.).
178:215	15See http://www2.parc.com/isl/groups/ nltt/xle/ 16See http://wiki.delph-in.net/moin 17See http://milca.sfs.uni-tuebingen.de/ A4/Course/trale/ 18See http://openccg.sourceforge.net/ 19See http://svn.ask.it.usyd.edu.au/trac/ candc/wiki 20Nonetheless, Beavers (2002) encoded a CCG in the LKBs Type Description Language.
179:215	6 The question whether to provide graphical or text-based editors can be discussed.
180:215	As advocated by Baldridge et al.181:215	(2007), a low-level textbased specification can offer more flexibility and bring less frustration to the grammar designer, especially when such a specification can be graphically interpreted.
182:215	This is the approach chosen by XMG, where the grammar is defined via an (advanced or not) editor such as gedit or emacs.
183:215	Within TuLiPA, we chose to go further by using the Eclipse platform.
184:215	Currently, it allows for displaying a summary of the content of a metagrammar or lexicon on a side panel, while editing these on a middle panel.
185:215	These two panels are linked via a jump functionality.
186:215	The next steps concern (i) the plugging of a graphical viewer to display the (meta)grammar structures independently from a given parse, and (ii) the extension of the eclipse plug-in so that one can easily consistently modify entries of the metagrammar or lexicon (especially when these are split over several files).
187:215	5.2 Application-oriented usage When dealing with applications, one may demand more from the grammar engineering environment, especially in terms of efficiency and robustness (support for larger resources, partial parsing, etc.).
188:215	Efficiency needs optimizations in the parsing engine making it possible to support grammars containing several thousands of structures.
189:215	One interesting question concerns the compilation of a grammar either off-line or on-line.
190:215	In DyALogs approach, the grammar is compiled off-line into a logical automaton encoding all possible derivations.
191:215	This off-line compilation can take some minutes with a TAG having 6000 trees, but the resulting parser can parse sentences within a second.
192:215	In TuLiPAs approach, the grammar is compiled into an RCG on-line.
193:215	While giving satisfactory results on reduced resources21, it may lead to troubles when scaling up.
194:215	This is especially true for TAG (the TT-MCTAG formalism is by definition a factorized formalism compared with TAG).
195:215	In the future, it would be useful to look for a way to precompile a TAG into an RCG off-line, thus saving the conversion time.
196:215	Another important feature of grammar engineering environments consists of its debugging func21For a TT-MCTAG counting about 300 sets of trees and an and-crafted lexicon made of about 300 of words, a 10-word sentence is parsed (and a semantic representation computed) within seconds.
197:215	tionalities.
198:215	Among these, one may cite unit and integration testing.
199:215	It would be useful to extend the TuLiPA system to provide a module for generating test-suites for a given grammar.
200:215	The idea would be to record the coverage and analyses of a grammar at a given time.
201:215	Once the grammar is further developed, these snapshots would allow for regression testing.
202:215	5.3 About multi-formalism We already mentioned that TuLiPA was opening a way towards multi-formalism by relying on an RCG core.
203:215	It is worth noticing that the XMG system was also designed to be further extensible.
204:215	Indeed, a metagrammar in XMG corresponds to the combination of elementary structures.
205:215	One may think of designing a library of such structures, these would be dependent on the target grammar formalism.
206:215	The combinations may represent general linguistic concepts and would be shared by different grammar implementations, following ideas presented by Bender et al.207:215	(2005).
208:215	6 Conclusion In this paper, we have presented a multi-formalism parsing architecture using RCG as a pivot formalism to parse mildly context-sensitive formalisms (currently TAG and TT-MCTAG).
209:215	This system has been designed to facilitate grammar development by providing user-friendly interfaces, along with several functionalities (e.g., dependency extraction, derivation/derived tree display and semantic calculus).
210:215	It is currently used for developing a core grammar for German.
211:215	At the moment, we are working on the extension of this architecture to include a fully functional Eclipse plug-in.
212:215	Other current tasks concern optimizations to support large scale parsing and the extension of the syntactic and semantic coverage of the German grammar under development.
213:215	In a near future, we plan to evaluate the parser and the German grammar (parsing time, correction of syntactic and semantic outputs) with respect to a standard test-suite such as the TSNLP (Lehmann et al., 1996).
214:215	Acknowledgments This work has been supported by the Deutsche Forschungsgemeinschaft (DFG) and the Deutscher Akademischer Austausch Dienst (DAAD, grant 7 A/06/71039).
215:215	We are grateful to three anonymous reviewers for valuable comments on this work.

