Metric epsilon1 ψtrain/test R P F1 T 0 76.7 90.5 83.1 228 OR 1 70.4/83.9 78.2 88.1 82.8 74 2.5 83.6/95.6 76.4 62.6 68.8 33 5 90.5/97.2 75.3 66.5 70.7 14 Florian et al.(2003) 88.5 89.0 88.8 baseline 50.9 71.9 59.6 Table 7: Filtering Rate, Micro-averaged Recall, Precision, F1 and total computation time for CoNLL-2003 (English).
W03-0425
CoNLL 2002 & 2003 Shared Tasks These shared tasks (Tjong Kim Sang, 2002; Tjong Kim Sang and De Meulder, 2003)7 concern language-independent named entity recognition.
W02-2024 W03-0419
8http://timex2.mitre.org/tern.html. 13 Metric epsilon1 ψtrain/test R P F1 T 0 66.4 67.0 66.7 615 CC 1 64.1/62.3 67.5 67.3 67.4 420 2.5 80.1/78.0 66.6 69.1 67.8 226 5 88.9/86.4 64.8 68.1 66.4 109 OR 1 70.7/68.9 68.3 67.3 67.8 308 2.5 81.0/79.1 67.5 68.3 67.9 193 5 87.8/85.6 65.4 68.2 66.8 114 IC 1 37.3/36.9 58.5 65.7 61.9 570 2.5 38.4/38.0 56.9 65.4 60.9 558 5 39.5/38.9 55.6 65.5 60.1 552 Zhou and Su (2004) 76.0 69.4 72.6 baseline 52.6 43.6 47.7 Table 5: Filtering Rate, Micro-averaged Recall, Precision,F1 and Time for JNLPBA.
W04-1219
gazetteers (Carreras et al., 2002) and lexical resources (Zhou and Su, 2004)) while SIE adopts exactly the same feature set and does not use any external or task dependent knowledge source.
W02-2004 W04-1219
Metric epsilon1 ψtrain/test R P F1 T 0 73.6 78.7 76.1 134 CC 1 64.4/64.4 71.6 79.9 75.5 70 2.5 75.1/73.3 72.8 80.3 76.4 50 5 88.6/84.2 66.6 64.7 65.6 24 OR 1 71.5/71.6 72.0 78.3 75.0 61 2.5 82.1/80.7 73.6 78.9 76.2 39 5 90.5/86.1 66.8 64.5 65.6 19 IC 1 47.3/47.5 67.0 79.2 72.6 101 2.5 51.3/51.5 65.9 79.3 72.0 95 5 55.7/56.0 63.8 78.9 70.5 89 Carreras et al.(2002) 76.3 77.8 77.1 baseline 45.4 81.3 58.3 Table 6: Filtering Rate, Micro-averaged Recall, Precision, F1 and total computation time for CoNLL-2002 (Dutch).
W02-2004
