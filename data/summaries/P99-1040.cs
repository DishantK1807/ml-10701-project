While we are not aware of any other work that has applied machine learning to detecting patterns suggesting that the user is having problems over the course of a dialogue, (Levow, 1998) has applied machine learning to identifying single misrecognitions.
P98-1122
Corpus: Our corpus consists of a set of 544 dialogues (over 40 hours of speech) between humans and one of three dialogue systems: ANNIE (Kamm et al., 1998), an agent for voice dialing and messaging; ELVIS (Walker et al., 1998b), an agent for accessing email; and TOOT (Litman and Pan, 1999), an agent for accessing online train schedules.
P98-2219
Litman. 1998.
P98-2129
Previous work correlating misrecognition rate with acoustic information, as well as our own 2These utterance labelings were produced during a previous set of experiments investigating the performance evaluation of spoken dialogue systems (Walker et al., 1997; Walker et al., 1998a; Walker et al., 1998b; Kamm et al., 1998; Litman et al., 1998; Litman and Pan, 1999).
P98-2129 P98-2219
Previous research suggests that this acoustic feature predicts misrecognitions because users modify their pronunciation in response to system rejection messages in such a way as to lead to further misunderstandings (Shriberg et al., 1992; Levow, 1998).
H92-1009 P98-1122
3This threshold is consistent with a threshold inferred from human judgements (Litman, 1998).
P98-2129
Previous work has shown that speech recognition performance is an important predictor of user satisfaction, and that changes in dialogue behavior impact speech recognition performance (Walker et al., 1998b; Litman et al., 1998; Kamm et al., 1998).
P98-2129 P98-2219
For example, the user satisfaction measures we collected in a series of experiments using the PARADISE evaluation framework (Walker et al., 1998c) could serve as the basis for such an alternative classification scheme.
P98-2219
Walker. 1998.
P98-2219 P98-2219
This work differs from previous work in focusing on behavior at the (sub)dialogue level, rather than on identifying single misrecognitions at the utterance level (Smith, 1998; Levow, 1998; van Zanten, 1998).
P98-1122
