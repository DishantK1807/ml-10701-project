Proceedings of the EACL 2009 Workshop on Language Technology and Resources for Cultural Heritage,
Social Sciences, Humanities, and Education –LaTeCH – SHELT&R 2009, pages 18–25,
Athens, Greece, 30 March 2009. c©2009 Association for Computational Linguistics
Multiplesequencealignmentsin linguistics
JelenaProki´c
Universityof Groningen
TheNetherlands
j.prokic@rug.nl
MartijnWieling
Universityof Groningen
TheNetherlands
m.b.wieling@rug.nl
JohnNerbonne
Universityof Groningen
TheNetherlands
j.nerbonne@rug.nl
Abstract
In this study we apply and evaluate an
iterative pairwise alignment program for
producing multiple sequence alignments,
ALPHAMALIG(Alonsoet al., 2004),us-
ing as materialthe phonetictranscriptions
of wordsusedin Bulgariandialectological
research. To evaluate the quality of the
multiple alignment, we propose two new
methodsbasedoncomparingeachcolumn
in the obtained alignments with the cor-
responding column in a set of gold stan-
dardalignments.Ourresultsshow thatthe
alignments produced by ALPHAMALIG
correspond well with the gold standard
alignments,makingthisalgorithmsuitable
for the automatic generation of multiple
string alignments. Multiple string align-
ment is particularly interestingfor histor-
ical reconstructionbased on sound corre-
spondences.
1 Introduction
Our cultural heritage is studied today not only in
museums,libraries,archives and their digitalpor-
tals, but also throughthe genetic and culturallin-
eamentsof living populations. Linguists,popula-
tion geneticists, archaeologists,and physical and
culturalanthropologistsare all active in research-
ing cultural heritage on the basis of material that
mayormaynotbepartofofficialculturalheritage
archives. The commontask is that of understand-
ing the histories of the peoplesof the world,espe-
cially their migrations and contacts. To research
and understandlinguisticcultural heritage we re-
quireinstrumentswhicharesensitivetoitssignals,
and, in particular sensitive to signals of common
provenance.Thepresentpaperfocusesonpronun-
ciationhabitswhichhave beenrecognizedto bear
signals of commonprovenance for over two hun-
dred years (since the work of Sir William Jones).
We presentwork in a researchline whichseeksto
submit pronunciationdata to phylogeneticanaly-
sis (Grayand Atkinson,2003)and whichrequires
an alignment of the (phonological) segments of
cognate words. We focus in this paper on evalu-
atingthe qualityof multi-alignedpronunciations.
In bioinformatics,sequencealignmentis a way
of arranging DNA, RNA or protein sequences in
order to identify regions of similarity and deter-
mine evolutionary, functional or structural simi-
laritybetweenthe sequences. Thereare two main
types of string alignment: pairwise and multiple
stringalignment. Pairwisestringalignmentmeth-
ods compare two strings at a time and cannot di-
rectly be used to obtain multiplestring alignment
methods (Gusfield, 1997, 343-344). In multiple
string alignment all strings are aligned and com-
paredatthesametime,makingitagoodtechnique
for discovering patterns, especiallythose that are
weakly preserved and cannot be detected easily
from sets of pairwisealignments. Multiplestring
comparison is considered to be the holy grail of
molecularbiology(Gusfield,1997,332):
It is the most critical cutting-edge tool for ex-
tractingandrepresentingbiologicallyimportant,
yet faint or widely dispersed, commonalities
froma set of strings.
Multiple string comparison is not new in lin-
guistic research. In the late 19th century the
Neogrammariansproposed the hypothesis of the
regularity of sound change. According to THE
NEOGRAMMARIAN HYPOTHESIS sound change
occurs regularly and uniformly whenever the ap-
propriate phonetic environment is encountered
(Campbell, 2004). Ever since, the understand-
ing of sound change has played a major role in
the comparative methodthat is itself based on the
simultaneous comparison of different languages,
i.e. lists of cognate terms from the related lan-
guages. The correct analysis of sound changes
18
requires the simultaneous examination of corre-
sponding sounds in order to compare hypotheses
about their evolution. Alignmentidentifieswhich
sounds correspond. Historical linguists align the
sequences manually, while we seek to automate
thisprocess.
In recent years there has been a strong fo-
cus in historical linguistics on the introduction
of quantitative methods in order to develop tools
for the comparison and classification of lan-
guages. For example, in his PhD thesis, Kondrak
(2002) presents algorithmsfor the reconstruction
of proto-languagesfrom cognates. Warnow et al.(2006) applied methods taken from phylogenet-
ics on Indo-European phonetic data in order to
model language evolution. Heeringa and Joseph
(2007) applied the Levensthein algorithm to the
Dutch pronunciationdata taken from Reeks Ned-
erlandseDialectatlassenandtriedto reconstructa
‘proto-language’of Dutch dialectsusing the pair-
wisealignments.
Studiesin historicallinguisticsand dialectome-
try where string comparisonis used as a basis for
calculating the distances between language vari-
eties will profit from tools to multi-align strings
automatically and to calculate the distances be-
tween them. Good multiple alignment is of ben-
efit to all those methods in diachroniclinguistics
such as the comparative reconstruction method
or the so-called CHARACTER-BASED METHODS
taken from phylogenetics, which have also been
successfullyapplied in linguistics(Gray and Jor-
dan, 2000; Gray and Atkinson, 2003; Atkinson
et al., 2005; Warnow et al., 2006). The multi-
alignment systems can help historical linguistics
by reducingthe humanlabor neededto detect the
regular sound correspondencesand cognate pairs
of words. They also systematize the linguistic
knowledge in intuitive alignments, and provide a
basis for the applicationof the quantitative meth-
odsthatleadto a betterunderstandingoflanguage
variationandlanguagechange.
In this study we apply an iterative pairwise
alignment program for linguistics, ALPHAMA-
LIG, on phonetic transcriptionsof words used in
dialectologicalresearch. We automaticallymulti-
align all transcriptionsand compare these gener-
ated alignmentswith manuallyaligned gold stan-
dard alignments. At the same time we propose
two methodsfor the evaluationof the multiplese-
quencealignments(MSA).
The structure of this paper is as follows. An
example of a multiple alignment and a discus-
sion of the advantages over pairwise alignment
is given in the next section, after which we dis-
cuss our data set in section 3. Section 4 explains
the iterative pairwisealignmentalgorithmand the
programALPHAMALIG.Section5 discussesthe
gold standard and two baselines, while section 6
discussesthenovel evaluationprocedures.There-
sults are given in section 7 and we end this paper
witha discussionin section8.
2 Exampleof
MultipleSequence
Alignment
In this sectionwe will give an exampleof the au-
tomaticallymulti-alignedstringsfromourdataset
and point out some important features of the si-
multaneouscomparisonof morethantwo strings.
village1 j "A -
village2 j "A z e -
village3 "A s -
village4 j "A s -
village5 j "A z e k a
village6 j "E -
village7 "6 s -
Figure1: Exampleof multiplestringalignment
In Figure 1 we have multi-aligned pronuncia-
tions of the word az ’I’ automatically generated
by ALPHAMALIG.The advantages of this kind
of alignmentover pairwisealignmentaretwofold:
• First, it is easier to detect and processcorre-
sponding phones in words and their alterna-
tions (like ["A] and ["E] and ["6] in the second
columnin Figure1).
• Second, the distances/similarities between
strings can be different in pairwisecompari-
son as opposedto multiplecomparison.This
is so because multi-aligned strings, unlike
pairwisealignedstrings,containinformation
on the positionswhere phones were inserted
or deleted in both strings. For example,
in Figure 1 the pairwise alignment of the
pronunciationsfrom village 1 and village 3
wouldbe:
village1 j "A -
village3 "A s
19
Thesetwo alignmentshave one matchingel-
ement out of three in total, which means
that the similarity between them is 1/3 =
0.33. At the same time the similarity be-
tween these two strings calculated based on
the multi-aligned strings in Figure 1 would
be 4/6 = 0.66. The measurementbased on
multi-alignment takes the common missing
materialintoaccountas well.
3 Dataset
The data set used in this paper consists of pho-
netic transcriptions of 152 words collected from
197 sites evenly distributed all over Bulgaria. It
is part of the project Buldialect—Measuringlin-
guistic unity and diversity in Europe.1 Pronun-
ciations of almost all words were collected from
all the sites and for some words there are mul-
tiple pronunciationsper site. Phonetic transcrip-
tions include various diacriticsand suprasegmen-
tals,makingthe totalnumberof uniquecharacters
(types)in the dataset 98.2
4 Iterative
pairwisealignment
Multiple alignment algorithms iteratively merge
two multiplealignmentsof two subsets of strings
into a single multiple alignment that is union of
those subsets (Gusfield, 1997). The simplest ap-
proach is to align the two strings that have the
minimumdistanceover all pairs of strings and it-
erativelyalignstringshavingthesmallestdistance
to the already aligned strings in order to generate
a new multiple alignment. Other algorithms use
differentinitializationsand differentcriteriain se-
lectingthe new alignmentsto merge. Somebegin
with the longest (low cost) alignment instead of
theleastcostabsolutely. Astringwiththesmallest
edit distanceto any of the already merged strings
is chosento be addedto the stringsin the multiple
alignment. In choosingthe pair with the minimal
distance,all algorithmsare greedy, and risk miss-
ing optimalalignments.
ALPHAMALIGis an iterative pairwise align-
mentprogramfor bilingualtext alignment.It uses
the strategy of merging multiple alignments of
subsetsofstrings,insteadofaddingjustonestring
1The project is sponsored by Volkswagen Stiftung.
More information can be found at http://sfs.uni-
tuebingen.de/dialectometry.
2The data is publicly available and can be found at
http://www.bultreebank.org/BulDialects/index.html.
at the time to the already aligned strings.3 It was
originallydevelopedtoaligncorrespondingwords
inbilingualtexts,i.e.withtextualdata,butitfunc-
tions with any data that can be represented as a
sequenceof symbolsof a finite alphabet. In addi-
tion to the input sequences,the programneeds to
know thealphabetandthe distancesbetweeneach
token pair and each pair consistingof a token and
a gap.
In order to perform multiple sequence align-
mentsofX-SAMPAwordtranscriptionswemodi-
fiedALPHAMALIGslightlysoitcouldworkwith
the tokens that consist of more than one symbol,
such as ["e], ["e:] and [t_S]. The distances be-
tweenthetokenswerespecifiedin sucha waythat
vowels can be aligned only with vowels and con-
sonants only with consonants. The same tokens
are treated as identical and the distance between
them is set to 0. The distancebetweenany token
in the data set to a gap symbol has the same cost
as replacinga vowel with a vowel or a consonant
witha consonant.Exceptfor thisverygenerallin-
guisticknowledge,nootherdata-specificinforma-
tionwas given to the program.In thisresearchwe
do not use any phoneticfeaturesin orderto define
the segments more precisely and to calculate the
distances between them in a more sensitive way
thanjustmakinga binary’match/does-not-match-
distinction’,sincewewanttokeepthesystemlan-
guage independentand robust to the highest pos-
sibledegree.
5 Goldstandardandbaseline
In order to evaluate the performance of AL-
PHAMALIG, we compared the alignments ob-
tainedusingthis programto the manuallyaligned
strings, our gold standard, and to the alignments
obtained using two very simple techniques that
are describednext: simple baseline and advanced
baseline.
5.1 Simplebaseline
Thesimplestwayofaligningtwostringswouldbe
to align the first elementfrom one string with the
first element from the other string, the second el-
ement with the second and so on. If two strings
are not of equal length, the remaining unaligned
tokensarealignedwiththegapsymbolwhichrep-
3More information on ALPHAMALIG can be found
at http://alggen.lsi.upc.es/recerca/align/alphamalig/intro-
alphamalig.html.
20
resentsaninsertionoradeletion.Thisisthealign-
mentimplicitinHammingdistance,whichignores
insertionsanddeletions.
By applying this simple method, we obtained
multiplesequencealignmentsfor all words in our
data set. An example of such a multiplesequence
alignment is shown in Figure 2. These align-
ments were used to check how difficult the mul-
tiple sequence alignment task is for our data and
how much improvement is obtained using more
advancedtechniquesto multi-alignstrings.
j "A -
j "A z e
"A S -
Figure2: Simplebaseline
5.2 Advancedbaseline
Our second baseline is more advanced than the
first and was created using the following proce-
dure:
1. for each word the longest string among all
pronunciationsis located
2. all strings are pairwise aligned against the
longest string using the Levensthein algo-
rithm (Heeringa, 2004). We refer to both se-
quences in a pairwise alignment as ALIGN-
MENT LINES. Note that alignment lines in-
clude hyphensindicatingthe places of inser-
tionsanddeletions.
3. thealignmentlines—allof equallength—are
extracted
4. allextractedalignmentlinesareplacedbelow
eachotherto formthe multiplealignment
An example of combiningpairwisealignments
against the longest string (in this case [j"aze]) is
shown in Figure3.
5.3 Goldstandard
Our gold standard was created by manually cor-
recting the advanced baseline alignments de-
scribed in the previous section. The gold stan-
dard results and both baseline results consist of
152 files with multi-alignedstrings, one for each
word. The pronunciationsare ordered alphabeti-
cally accordingto the village they come from. If
therearemorepronunciationspersite,they areall
present,oneunderthe other.
j "A z e
j "A -
j "A z e
"A S -
j "A -
j "A z e
"A S -
Figure 3: Advanced baseline. The top two align-
ments each contain two alignment lines, and the
bottomonecontainsthree.
6 Evaluation
Although multiple sequence alignments are
broadlyusedin molecularbiology, thereis stillno
widely acceptedobjective function for evaluating
the goodness of the multiple aligned strings
(Gusfield, 1997). The quality of the existing
methods used to produce multiple sequence
alignments is judged by the ’biological meaning
of the alignments they produce’. Since strings
in linguistics cannot be judged by the biological
criteria used in string evaluation in biology, we
were forced to propose evaluation methods that
would be suitablefor the stringsin question. One
of the advantages we had was the existence of
the gold standard alignments, which made our
task easier and more straightforward—inorder to
determinethe qualityof the multi-alignedstrings,
we compareoutputsof the differentalgorithmsto
the gold standard. Since there is no off-the-shelf
methodthat can be used for comparisonof multi-
aligned strings to a gold standard, we propose
two novel methods—onesensitive to the order of
columnsin two alignmentsand anotherthat takes
intoaccountonlythe contentof eachcolumn.
6.1 Columndependentmethod
The first methodwe developedcomparesthe con-
tentsof thecolumnsandalsotakes thecolumnse-
quenceinto account. The columndependenteval-
uation(CDE)procedureis as follows:
• Each gold standard column is compared to
the most similar column out of two neigh-
boringcolumnsofacandidatemultiplealign-
ment. The two neighboringcolumnsdepend
on the previous matched column j and have
indicesj +1 andj +2 (at thestartj = 0). It
is possiblethat there are columnsin the can-
didate multiple alignment which remain un-
matched,as well as columnsat theendof the
goldstandardwhichremainunmatched.
21
• The similarity of a candidate column with a
gold standardcolumnis calculatedby divid-
ing the number of correctly placed elements
in every candidatecolumn by the total num-
ber of elements in the column. A score of
1 indicates perfect overlap, while a score of
0 indicatesthe columnshave no elementsin
common.
• The similarity score of the whole multiple
alignment(fora singleword)iscalculatedby
summing the similarity score of each candi-
datecolumnanddividingit by thetotalnum-
ber of matched columns plus the total num-
ber of unmatched columns in both multiple
alignments.
• The final similarityscore between the set of
goldstandardalignmentswiththe set of can-
didate multiple alignments is calculated by
averaging the multiple alignment similarity
scoresfor all strings.
Asanexampleconsiderthemultiplealignments
inFigure4,withthegoldstandardalignment(GS)
on the left and the generated alignment (GA) on
the right.
w rj "E m e
v r "e m i
u rj "e m i
v rj "e m i
w rj "E m e
v r "e m i
u rj "e m i
v rj "e m i
Figure4: GS and ALPHAMALIGmultiple string
alignments, the gold standard alignment left, the
ALPHAMALIGoutputright.
The evaluation starts by comparing the first col-
umn of the GS with the first and second column
of the GA. The first columnof the GA is the best
match, since the similarityscore betweenthe first
columns is 0.75 (3 out of 4 elements match). In
similar fashion, the second column of the GS is
comparedwiththesecondandthethirdcolumnof
the GA and matchedwiththe thirdcolumnof GA
with a similarity score of 1 (all elements match).
The third GS column is matched with the fourth
GA column, the fourth GS column with the fifth
GAcolumnandthefifthGScolumnwiththesixth
GA column(all three having a similarityscore of
1). As a consequence,the second column of the
GA remainsunmatched.In total,five columnsare
matchedandonecolumnremainsunmatched.The
totalscoreof the GAequals:
(0.75+1+1+1+1)
(5+1) = 0.792
It is clear that this methodpunishesunmatched
columnsby increasingthe value of the denomina-
tor in the similarityscorecalculation.As a conse-
quence, swapped columns are punished severely,
whichis illustratedin Figure5.
"o rj @ j -
"o rj @ u
"o rj @ f -
"o rj @ j
"o rj @ u -
"o rj @ f
Figure5: Two alignmentswithswappedcolumns
In the alignments in Figure 5, the first three
columns of GS would be matched with the first
three columnsof GA with a score of 1, the fourth
wouldbe matchedwiththefifth,andtwo columns
wouldbe leftunmatched:thefifthGScolumnand
the fourth GA column yielding a total similarity
scoreof 4/6 = 0.66. Especiallyin thiscasethisis
undesirable, as both sequences of these columns
represent equally reasonable multiple alignment
and should have a total similarity score of 1.
We thereforeneed a less strict evaluation method
which does not insist on the exact ordering. An
alternative method is introducedand discussedin
the followingsection.
6.2 ModifiedRandIndex
In developing an alternative evaluation we pro-
ceededfromtheinsightthatthecolumnsofa mul-
tiple alignmentare a sort of PARTITION of the el-
ements of the alignmentstrings, i.e., they consti-
tute a set of disjointmulti-setswhoseunionis the
entire multi-setof segmentsin the multiplealign-
ment. Each column effectively assigns its seg-
mentsto a partition,whichclearlycannotoverlap
with the elements of another column (partition).
Since every segment must fall within some col-
umn,the assignmentis alsoexhaustive.
Our second evaluation method is therefore
based on the modified Rand index (Hubert and
Arabie, 1985). The modified Rand index is used
in classificationfor comparingtwo differentparti-
tions of a finite set of objects. It is based on the
Randindex (Rand,1971),oneof themostpopular
measuresforcomparingthedegreetowhichparti-
tionsagree(in classification).
Given a set of n elementsS = o1,...on andtwo
partitionsof S, U and V , the Randindex R is de-
finedas:
22
R = a+ba+b+c+d
where:
• a: the numberof pairs of elementsin S that
are in the same set (column) in U and in the
sameset in V
• b: the number of pairs of elementsin S that
areindifferentsets(columns)inU andindif-
ferentsetsin V
• c: the number of pairs of elementsin S that
are in the same set in U and in different sets
in V
• d: the numberof pairs of elementsin S that
are in different sets in U and in the same set
in V
Consequently, a and b are the number of pairs of
elementsonwhichtwoclassificationsagree,while
c and d are the number of pairs of elements on
which they disagree. In our case classifications
agree about concrete segment tokens only in the
cases where they appear in the same columns in
the alignments.
The value of Rand index rangesbetween0 and
1, with 0 indicating that the two partitions(multi-
alignments)do notagreeon any pairof pointsand
1 indicatingthat the datapartitionsare exactlythe
same.4 A problem with the Rand index is that it
does not return a constantvalue (zero)if two par-
titions are picked at random. Hubert and Arabie
(1985) suggested a modification of the Rand in-
dex (MRI) that corrects this property. It can be
expressedin the generalformas:
MRI = Randindex−ExpectedindexMaximumindex−Expectedindex
The expected index is the expected number of
pairs which would be placedin the same set in U
andinthesamesetinV bychance.Themaximum
index representsthe maximumnumberof objects
that can be put in the same set in U and in the
samesetin V . TheMRIvaluerangesbetween−1
and 1, with perfect overlap being indicated by 1
and values≤ 0 indicatingno overlap. For a more
detailed explanationof the modified Rand index,
pleasereferto HubertandArabie(1985).
4In dialectometry, this index was used by Heeringa et al.(2002)to validatedialectclusteringmethods.
We would like to emphasizethat it is clear that
thesetofcolumnsofa multi-alignmenthave more
structurethana partitionsec, in particularbecause
thecolumns(subpartitions)areordered,unlike the
subpartitionsin a partition. But we shall compen-
sateforthisdifferencebyexplicitlymarkingorder.
"o [1] rj [2] @ [3] j [4] -
"o [5] rj [6] @ [7] u [8]
"o [9] rj [10] @ [11] f [12] -
Figure6: Annotatedalignment
In our study, each segment token in each tran-
scriptionwastreatedasa differentobject(seeFig-
ure 6), and every column was taken to be a sub-
partition to which segment tokens are assigned.
Both alignmentsin Figure 5 have 12 phones that
areputinto5groups.We“tag”eachtokensequen-
tiallyinordertodistinguishthedifferenttokensof
a singlesegmentfromeachother, but notethatthe
waywedothisalsointroducesanordersensitivity
in the measure.Thetwo partitionsobtainedare:
GS1= {1,5,9}
GS2= {2,6,10}
GS3= {3,7,11}
GS4= {4,12}
GS5= {8}
GA1= {1,5,9}
GA2= {2,6,10}
GA3= {3,7,11}
GA4= {8}
GA5= {4,12}
Using the modified Rand index the quality of
eachcolumnis checked, regardless of whetherthe
columnsare in order. The MRIfor the alignments
in Figure 5 will be 1, because both alignments
group segment tokens in the same way. Even
thoughcolumnsfourandfiveareswapped,inboth
classificationsphones [j] and [f] are grouped to-
gether, whilesound[u] formsa separategroup.
The MRI itself only takes into account the
quality of each column separately since it sim-
plycheckswhetherthesameelementsaretogether
in the candidatealignmentas in the gold-standard
alignment. It is thereforeinsensitive to the order-
ing of columns. While it may have seemedcoun-
terintuitivelinguisticallytoproceedfromanorder-
insensitivemeasure,thecomparisonof“taggedto-
kens”describedabove effectively reintroducesor-
der sensitivity.
Inthenextsectionwedescribetheresultsofap-
plying both evaluation methods on the automati-
callygeneratedmultiplealignments.
23
7 Results
After comparing all files of the baseline algo-
rithmsand ALPHAMALIGagainst the gold stan-
dardfilesaccordingtothecolumndependenteval-
uation method and the modified Rand index, the
average score is calculated by summing up all
scores and dividing them by the number of word
files(152).
The results are given in Table 1 and also in-
clude the number of words with perfect multi-
alignments (i.e. identical to the gold standard).
Using CDE, ALPHAMALIGscored 0.932 out of
1.0 with 103 perfectly aligned files. The result
for the simple baseline was 0.710 with 44 per-
fectly aligned files. As expected, the result for
the advanced baseline was in between these two
results—0.869 with 72 files that were completely
identical to the GS files. Using MRI to eval-
uate the alignments generated we obtained gen-
erally higher scores for all three algorithms, but
with the same ordering. ALPHAMALIGscored
0.982, with 104 perfectly aligned files. The ad-
vanced baseline had a lower score of 0.937 and
74 perfect alignments. The simple baseline per-
formed worse, scoring 0.848 and having 44 per-
fectlyalignedfiles.
The scores of the CDE evaluation method are
lowerthantheMRIscores,whichisduetothefirst
method’s problematicsensitivity to columnorder-
inginthealignments.It is clearthatinbothevalu-
ation methods ALPHAMALIGoutperformsboth
baselinealignmentsby a widemargin.
It is important to notice that the scores for the
simple baseline are reasonably high, which can
be explained by the structure of our data set.
The variationof word pronunciationsis relatively
small, making string alignment easier. However,
ALPHAMALIGobtainedmuch higher scores us-
ing bothevaluationmethods.
Additionalqualitativeerroranalysisrevealsthat
theerrorsofALPHAMALIGaremostlycausedby
the vowel-vowel consonant-consonantalignment
restriction. In the data set there are 21 files that
containmetathesis. Since vowel-consonantalign-
mentswerenotallowedinALPHAMALIG,align-
ments produced by this algorithm were different
fromthe goldstandard,as illustratedin Figure7.
The vowel-consonantrestrictionis also respon-
sible for wrong alignmentsin some words where
metathesis is not present, but where the vowel-
consonant alignment is still preferred over align-
v l "7 k
v "7 l k
v l "7 k
v "7 l k
Figure7: Two alignmentswithmetathesis
ing vowels and/or consonantswith a gap (see for
exampleFigure4).
The other type of error present in the AL-
PHAMALIG alignments is caused by the fact
thatallvowel-vowelandconsonant-consonantdis-
tances receive the same weight. In Figure 8
the alignment of word bjahme ’were’ produced
by ALPHAMALIGis wrong because instead of
aligning [mj] with [m] and [m] it is wrongly
alignedwith [x] and [x], while [x] is alignedwith
[S] insteadof aligningit with[x] and[x].
b "E S u x m e -
bj "A x m i -
b "e x mj 7 -
Figure 8: Alignment error produced by AL-
PHAMALIG
8 Discussionandfuture
work
In this study we presenteda first attempt to auto-
maticallymulti-alignphonetictranscriptions.The
algorithmweusedtogeneratealignmentshasbeen
shown to be very reliable, produce alignments of
good quality, with less than 2% error at the seg-
ment level. In this study we used only very sim-
ple linguisticknowledge in order to align strings.
The only restrictionwe imposedwas that a vowel
should only be aligned with a vowel and a con-
sonant only with a consonant. The system has
showntobeveryrobustandtoproducegoodqual-
ity alignmentswith a very limitedinformationon
the distancesbetweenthe tokens. However, in the
futurewe wouldlike to applythisalgorithmusing
more detailed segment distances, so that we can
workwithoutvowel-consonantrestrictions.Using
moredetailedlanguagespecificfeaturesystemfor
eachphone,webelievewemaybeabletoimprove
the produced alignments further. This especially
holds for the type of errors illustratedin Figure 8
whereit is clear that [mj] is phoneticallycloserto
[m] thanto [x] sound.
As our data set was relatively simple(indicated
bythereasonableperformanceofoursimplebase-
line algorithm),we would very muchlike to eval-
uateALPHAMALIGagainstamorecomplexdata
24
CDE CDEperfectcolumns MRI MRIperfectcolumns
Simplebaseline 0.710 44 0.848 44
Advancedbaseline 0.869 72 0.937 74
ALPHAMALIG 0.932 103 0.982 104
Table1: Resultsof evaluatingoutputsof the differentalgorithmsagainstthe GS
set and try to replicate the good results we ob-
tained here. On one hand, high performance of
both baseline algorithms show that our task was
relatively easy. On the other hand, achieving per-
fectalignmentswillbeverydifficult,if possible at
all.
Additionally, weproposedtwomethodstoeval-
uatemultiplealignedstringsinlinguisticresearch.
Although these systems could be improved, both
of them are giving a good estimationof the qual-
ity of the generatedalignments.For the examined
data, we find MRI to be better evaluation tech-
nique since it overcomesthe problemof swapped
columns.
In this research we tested and evaluated AL-
PHAMALIGon the dialect phonetic data. How-
ever, multiple sequence alignments can be also
applied on the sequences of sentences and para-
graphs. This makes multiple sequencealignment
algorithma powerful tool for mining text data in
socialsciences,humanitiesandeducation.
Acknowledgements
We are thankfulto Xavier Messeguerof the Tech-
nical University of Catalonia who kindly sup-
plied us with the sourcecode of ALPHAMALIG.
We also thank Therese Leinonen and Sebastian
Kürschnerof the Universityof GroningenandEs-
teve Valls i Alechaof the Universityof Barcelona
for theirusefulfeedbackon our ideas.
References
LauraAlonso,IreneCastellon,JordiEscribano,Xavier
Messeguer, and Lluis Padro. 2004. Multiple
Sequence Alignment for characterizing the linear
structure of revision. In Proceedingsof the 4th In-
ternationalConferenceon Language Resources and
Evaluation.
Quentin Atkinson, Geoff Nicholls, David Welch, and
Russell Gray. 2005. From words to dates: water
into wine, mathemagic or phylogenetic inference.
TranscriptionsofthePhilologicalSociety, 103:193–
219.
Lyle Campbell. 2004. Historical Linguistics: An In-
troduction. Edinburgh UniversityPress,secondedi-
tion.
Russel D. Gray and Quentin D. Atkinson. 2003.
Language-tree divergence times support the Ana-
tolian theory of Indo-European origin. Nature,
426:435–339.
Russel D. Gray and Fiona M. Jordan. 2000. Lan-
guage trees support the express-train sequence of
Austronesianexpansion. Nature, 405:1052–1055.
Dan Gusfield. 1997. Algorithmson Strings,Trees and
Sequences: Computer Science and Computational
Biology. CambridgeUniversityPress.
Wilbert Heeringa and Brian Joseph. 2007. The rela-
tivedivergenceofDutchdialectpronunciationsfrom
theircommonsource:Anexploratorystudy. InJohn
Nerbonne,T. Mark Ellison,and Grzegorz Kondrak,
editors,ProceedingsoftheNinthMeetingoftheACL
Special Interest Group in ComputationalMorphol-
ogy and Phonology.
Wilbert Heeringa, John Nerbonne,and Peter Kleiweg.
2002. Validating dialect comparison methods. In
Wolfgang Gaul and Gunter Ritter, editors, Classifi-
cation,Automation,andNew Media.Proceedingsof
the 24th Annual Conference of the Gesellschaft für
Klassifikatione. V., Universityof Passau,March 15-
17, 2000, pages 445–452.Springer, Berlin, Heidel-
berg andNew York.
WilbertHeeringa. 2004. MeasuringDialectPronunci-
ationDifferencesusingLevenshteinDistance. Ph.D.
thesis,RijksuniversiteitGroningen.
Lawrence Hubert and Phipps Arabie. 1985. Compar-
ing partitions. Journalof Classification, 2:193–218.
Grzegorz Kondrak. 2002. Algorithms for Language
Reconstruction. PhDThesis,Universityof Toronto.
William M. Rand. 1971. Objective criteria for the
evaluationof clusteringmethods. Journal of Amer-
ican Statistical Association, 66(336):846–850,De-
cember.
Tandy Warnow, Steven N. Evans, Donald Ringe, and
Luay Nakhleh. 2006. A stochastic model of lan-
guage evolution that incorporates homoplasy and
borrowing. In Peter Forster and Colin Renfrew, ed-
itors, Phylogenetic Methods and the Prehistory of
Languages. MacDonaldInstituteforArchaeological
Research,Cambridge.
25

