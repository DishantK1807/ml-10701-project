In (Chen et al., 2003) we investigated normalizing abbreviations and transforming spelled-out numbers into numerals, “enhanced preprocessing”, and then compared this approach with using an “ASR stoplist”.
N03-2005
Our approach was to identify a parallel corpus of manually and automatically transcribed documents, the TDT2 corpus, and then use a statistical approach (Dunning, 1993) to identify tokens with significantly Table 5: Impact of recall and precision enhancing devices.
J93-1003
Dunning. 1993.
J93-1003
We have developed systems based on cosine similarity (Chen et al., 2003).
N03-2005
