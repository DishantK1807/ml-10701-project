nore punctuation (Nakov and Hearst, 2005b)).
H05-1105 W05-0603
Lauer (1995), for example, would be to take an am-
P95-1007
(Ratnaparkhi, 1996) trained on the full training data
W96-0213
cussed in Nakov and Hearst (2005a), Nakov and
H05-1105 W05-0603
tion (Nakov and Hearst, 2005b) and noun-sequence
H05-1105 W05-0603
of Charniak and Johnson (2005) and Collins (2000)
P05-1022
2008). Lapata and Keller (2004) uses the number
N04-1016
uses only affinity-based web features. Yates et al.(2006) use Web counts to filter out certain â€˜seman-
W06-1604
addition to POS tags (also see Finkel et al. (2008)).
P08-1109
David Vadas and James R. Curran. 2007. Adding noun
P07-1031
far back as Lauer (1995) for noun-compound brack-
P95-1007
7Work such as Smith and Eisner (2008), Martins et al.(2009), Koo and Collins (2010) has been exploring more non-
D08-1016 P09-1039 P10-1001
syntactic features used in Huang (2008). Our web-
P08-1067
(2007)). Nakov and Hearst (2008) post-processes
P08-1052
work (Nakov and Hearst, 2005b) but also add nu-
H05-1105 W05-0603
bracketing (Nakov and Hearst, 2005a; Pitler et al.,
H05-1105 W05-0603
Ryan McDonald and Fernando Pereira. 2006. On-
E06-1011
David A. Smith and Jason Eisner. 2008. Dependency
D08-1016
non-local) from Huang (2008), a simplified merge
P08-1067
intuition from Nakov and Hearst (2005b), namely
H05-1105 W05-0603
models of McDonald et al. (2005) and McDonald
P05-1012
Eugene Charniak and Mark Johnson. 2005. Coarse-to-
P05-1022
Michael Collins. 2002. Discriminative training meth-
W02-1001
Liang Huang. 2008. Forest reranking: Discriminative
P08-1067
greater score is chosen. More recently, Pitler et al.(2010) use web-scale n-grams to compute similar
C10-1100
Berkeley parser (Petrov et al., 2006), about 20%
P06-1055
Koo et al. (2008), we used the MXPOST tagger
P08-1068
top parses. In an important contrast, Koo et al.(2008) smooth the sparseness of lexical features in a
P08-1068
Berkeley parser (Petrov et al., 2006), an unlexical-
P06-1055
Preslav Nakov and Marti Hearst. 2005b. Using the web
H05-1105 W05-0603
M. Lauer. 1995. Corpus statistics meet the noun com-
P95-1007
M. Atterer and H. Schutze. 2007. Prepositional phrase
J07-4002
ley parser (Petrov et al., 2006). Third, past systems
P06-1055
Nakov and Hearst (2005b) suggested that the attes-
H05-1105 W05-0603
Adwait Ratnaparkhi. 1996. A maximum entropy model
W96-0213
Mirella Lapata and Frank Keller. 2004. The Web as a
N04-1016
2001; Lapata and Keller, 2004). For example, the
N04-1016
ity (Nakov and Hearst, 2005b). The approach of
H05-1105 W05-0603
2005; Collins and Koo, 2005; Collins, 2000) and
J05-1003
Terry Koo and Michael Collins. 2010. Efficient third-
P10-1001
Vadas and Curran (2007).
P07-1031
the results of McDonald and Pereira (2006).6 Ta-
E06-1011
Terry Koo, Xavier Carreras, and Michael Collins. 2008.
P08-1068
2004; Nakov and Hearst, 2005b; Nakov and Hearst,
H05-1105 W05-0603
Preslav Nakov and Marti Hearst. 2005a. Search en-
H05-1105 W05-0603
used the averaged perceptron (Collins, 2002; Huang,
W02-1001
2005; McDonald and Pereira, 2006). Our first-order
E06-1011
dency parser of McDonald and Pereira (2006),
E06-1011
parser of McDonald and Pereira (2006). For con-
E06-1011
Michael Collins and Terry Koo. 2005. Discrimina-
J05-1003
Preslav Nakov and Marti Hearst. 2008. Solving rela-
P08-1052
