PROCESSING WORD ORDER VARIATION WITHIN A MODIFIED ID/LP FRAMEWORK Pradip Dey University of Alabama at Birmingham Birmingham~ AL 35294~ U.S.A.
ABSTRACT From a well represented sample of world languages Steele (1978) shows that about 70% of languages exhibit significant word order variation.
Only recently has this wlde-spread phenomenon been drawing appropriate attention.
Perhaps ID/LP (Immediate Dominance and Linear Precedence) framework is the most debated theories in this area.
We point out some difficulties in processing standard ID/LP grammar and present a modified version of the grammar.
In the modified version, the right hand side of phrase structure rules is treated as a set or partially ordered set.
An instance of the framework is implemented.
1. Introduction From a well represented sample of world languages Steele (1978) ~,~hows that about 76~ of the languages exhibit significant word order variation |. Until recently thls widespread phenomenon was not given proper attention in natural language processing.
The primary goal of tbis study is to develop eomputatlonally efficient and linguistically adequate strategles for parsing word order variation.
The strategies are implemented in a network based parser.
At first we characterize the basic problem at an abstract level without going into details of the problem in any specific language (in Section-2).
Then~ in Sectlon-3, the details of the problems in a specific language~ namely~ Iilndi~ are presented.
The Immediate dominance and linear precedence (ID/LP) framework~ developed by Gazdar and Pullum~ is one of the most debated theories in the study of word order variation (Pullum 1982~ Uszkorelt 1082, Shieber 1983, Barton 1985).
The basic idea behind ID/LP framework is to separate immediate dominance from linear precedence in rewrite rules.
Pullum (1982) expresses this via a metagrammar.
The modified version presented in this paper expresses this directly in the object grammar eliminating the need for a metagrammar.
It treats the right hand side of a PS (Phrase Structure) rule as a set or partially ordered set.
Parsing with this type of rule can proceed by checking set membership.
2. The Word Order Problem in General The word order problem is the problem of processing the whole range of word order variation occurring in natural languages.
Some Australian languages such as Warlpiri show extreme word order variation (Hale 1983).
Hindi, Japanese and German also allow considerable word order variation.
In this section we develop descriptive formalisms and parsing mechanisms that are adequate for the whole range of word order variation.
Consider a grammar thdt allows a node labeled S to have daughters labeled $, O, and ¥ in any linear order~ and nothing else.
Such a grammar can be presented with a set of rules such as that given in (2.1).
(2.1) S --> $ OV, S --> $VO, S --> 0 SV, S--> OV$, S--> V$O, S--> VO$ The problem with a grammar such as that given in (2.1) is that i~ needs too many rules to capture word order variation (in this case free word order).
For 5 'words' such a grammar will need 5!
= 120 rules.
With the increase in the number of words, such a gralnmar will grow factorially.
That is, for a number of words it will need n/ rules.
There is a convYnient way of 'collapsing' rules in GPSG (Generalized Phrase Structure Grammar) of Gazder (1981).
It uses metarules that operate on basic rules to generate derived rules which then function as basic rules in derivations.
Thus, (2.1) can be abbreviated as (2.2).
(2.2) Basic rule: \[_~ $ O V\] Metarule: \[5....X...Y...\] =:> \[S....y...X...\] where X and Y range over $, O, V.
Within GPSG Pullmn (1982) suggests another solution which also involves a metagrammar, tie suggests that a grammar such as (2.1) can be expressed via a metagrammar that treats immediate dominance and linear precedence separately.
Pullum's theory is known as ID/LP analysis 2 According to this theory grammar (2.1) "would be specified by means of the metagrammar" given in (2.3).
Similarlyj the metagrammar given in (2.4) "determines" the grammar shown in (2.5).
In (2.3) and (2.4) i ..... diate doml .... e star .... ts are given under a~ and linear precedence statements are given~ under b.
In the case of (2.3) however the set of linear precedence statements is empty.
In the case of (2.4) $ ( O means 'it" any rule introduces $ and O, $ linearly precedes O'.
(2.3)a. {S--> $,O,V} b.
{$} (2.4)a.
{S--> $,O,V} h.
(*<O} (2.5) (s->.*ov, s->$vo, s->v$o} An important advantage of ID/LP analysis is that it can account for word order variation in a general way, capturing "analytical intultion~ often hinted at in the literature, that fixing constituent order "costs" in the same way that having special NP case-marking rules or verb agreement rules does" (Pnllum 1982: 211).
The main disadvantage of the standard ID/LP framework is th~:t it is difficult to process (Shieber 1983, Barton 1985).
The alternative solution proposed in this study treats the rigbt hand side of a rule as a set3 . Thus~ the grammar in (2.1) can be p ..... ted in this format, eith ....
(2.6a) or as (2.6b).
The latter rule is to be understood under the node admissibility condition.
(2.a)a. S->($,o,v} b.
(5 $'°'v} Since the right hand side of the rule is a se G the order of $~ O and V does not matter.
In parsing, this solution has definite advantages.
Firstly~ the factorial growth of rules is eliminated.
Secondly~ parsing can proceed by checking set membership or set difference.
That is, instead of 'ordered match' the parser has to do 'unordered match'.
The precise way of doing it will vary from parser to parser.
We describe one way of implementing it in the ATN (Augmented Transition Network (Woods 1970, Finln and Hadden 1977)) formalism.
Consider the ATN fragment presented below in (2.7) for the grammar given in (2.6).
Conditions on are are given in . LISP like structures within parenthesis.
Thus (null $) means 'if 65 S-reglster is empty'.
By the arc WRD $ (null $), the 'word' $ will be accepted if no $ has previously been found.
(In natural language, one can assume $ ~ Subject, O ~ Object, V = Verb, and use PUSH arc in place of WRD in the following diagram).
(2.7) WRD, (N~LL ~ :23 WRDO(NULL_ O) / / WRD V (NULL V) J ~ 4 POP (NOTNULL $)(NOTNULL O)(NOTNULL V)~ (2.7) parses any strings generated by (2.1) by scanning the input from left to right and checking the set membership.
Thus, in recognition and parsing, (2.7) correctly reflects (2.0).
Suppose, the input string is VO$.
One way to see how a sentence is parsed is to trace through the analysis of the sentence as are sequence.
This string is accepted by the arc sequence (3, 2, 1, 4).
The ATN given in (2.7) can be said to have conditioned multiple loops.
For convenience of reference, we shall refer to ATN structures such as (2.7) as 'set-loops'.
Further restrictions on set-loops (such as (2.7)) can be imposed and all constituent order variations can be parsed simply by imposing additional conditions on arcs.
Thus, an ATN parser such as (2.8b) can parse the language generated by the grammar given in (2.5).
Formally, (2.5) is presented with a partially ordered set such as (2.8a) in the proposed framework.
The partial ordering is specified as a constrain after "/"~ as in a context-sensitlve rule contexts are specified after "/''.
(2.8)a. ( *,O,V}/$<O (2.8)b.
( WRD $ _(NUL____~L ~D O (NULL O)(NOTNULL $) WRD V (NULL V) POP (NOTNULL $)(NOTNULL O)(NOTNULL V~ Suppose that $, O, and V are nontermlnals which are further expanded by appropriate rewrite rules.
Right hand side of such expansions can also show word order variations as shown in (2.9).
(2.9) $ --:> {a,b,c}, O --> (d,e}, V --~> {f,g,h} So far, we have described parsing strategies for constituent order variations.
However, in natural language we often find a discontinuous constituent.
That is, an element can be moved out of its constituent (toplcalization in English would be a good example if VP is a constituent) which can be described by categories with holes (eg.
VP/NP). In cases such as this, VIR arcs in combination with hold lists arc used in ATN (Bates 1978).
Alternatively, temporary registers can be used to parse discontinuous constituents.
Temporary 66 registers are particularly suitable to handle large number of 'misplaced' words that cannot be handled by usual HOLD lists in combination with VIR arcs.
We would llke to apply the general strategies described above to the case of Hindi which shows considerable word order variation.
3. Word Order in Hindi In Hindl, the order of the major constituents such as $ (Subject), O (direct Object), I (Indirect object), and V (Verb (+aux)) is free.
For example, out of the four constituents present in (3.11.1), we can make twenty four variants of the same senteneep all of which are perfectly good in Hindi as is obvious from (3.11.1-24).
(3.11/1. mohan ne raam ko sev dlaa thaa.
($IOV / Mohan ag Ram to apple gave was "Mohan gave the apple to Ram".
2. mohan ne raam ko dlaa thaa sev.
($IVO) 3.
mohan ne diaa than raam ko sev.
($VIO) 4.
mohan ne diaa than sev raam ko.
($VOI) 24.
diaa thaa sev mohan ne raam ko.
(VO$I) To capture the freedom of order of $, I, O~ and V in sentences such as (3.11) We can have a rule such as (3.12) in the grammar of Hindl.
The V alone can stand as a sentence in Hindi since it is highly inflected (see Kachru 1980).
Hence (3.13) is more appropriate for Hindi where $~ I, and O are given within paratheses to show their optional occurrence.
(3.12) (S ~'I'O'V } (3.13) ( ~ (,), (I), (o), v } We have been referring to rules such as (3.13 / as set rules.
An ATN fragment, such as (3.14) would be appropriate for (3.13 / . IC PUSH CNULL,I _j / / 5 POP (NOTNULL V) f (Assume appropriate subnets for $, I, O, V) Suppose we are parsing (3.11.1) mohaa nc raam ko sev diaa than "Mohan gave the apple to Ram".
It is accepted by the arc seq .....
(1, 2, 3, 4, 5).
The sentence given in (3.11.24) is accepted by the arc sequence (3, 1, 4, 2, 51 . (3.14) captures constituent order variation in Hindl in a general way.
However, it is to be noted that sentences such as (3.11.1) have bl-transltive (or double transitive) V.
We have to impose more conditions on arc 5, POP, to parse intransitive and transitive sentences.
Informally, the conditions are: (1 / If the V is intransitive then the I and O must be empty.
(2) If the V is transitive then the I must be empty.
We have implemented a large parser of Hindl wlth wide coverage of construction types including relative clauses, interrogatives, passives, dative subjects, compound verbs and gapping which interact with word order variation (see Dey 1982, 1984).
Word order variation in Hindl is fairly restrictive.
Thus, in the sentences of (3.11) the main verb must precede the AUX.
(3.15) is unacceptable because it violates this restriction.
(3.15) * thaa dlaa sev mohan ne raam ko.
was gave apple Mohan ag Ram to Similarly, (3.16) violates the restrictlon that the case elements must follow the noun (Verma 1970).
(3.18) * m~ mohan ram ko sev diaa thaa.
ag Mohan Ram to apple gave was As obvious frmn (3.15-16), all rules of tIindi are not 'set.rules'.
Thus, the subject"NP, $, cannot be expanded by (3.17a); rat\] .... w .... th ...... 1 (3.17b).
(3.17)a. {-*e NP, K } b.
\[ $ NP K \] (Assume \[NP mohan\], \[K ne\]) In the modified ID/LP fl'amework we allow strict order rules such as (3.17b), fr .... d .....
I ...... h as (3.14) and partial order rules such as (2.8a).
We also allow notions llke subject and object.
That means the grammar is an annotated PS grammar.
The parsing strategy suggested above for this grammar has an important consequence.
It does not recognize VP (thab dominates V, O, I) as a constituent.
It advocates a 'flat' structure for sentences as shown in (3.1.8).
(3.18) S ( 1 o v mohan ne raam ko sev dl aa "Mohan gave tbe apple to Ram".
It should be noted that actual structural representations should be given with mort details.
Some parse trees given by the parser are presented below: (3.19) (p .....
(inoh ....... aln k .... dlaa thaa)) (S (NP-subj (NP (DEW nil) (ADJ) (N mohan)) (K-ag he)) (NP-ind (NP (DET nil) (ADJ) (N ......
)) (K-dat ko)) (NP-obj (NP (DET nil) (ADJ) (N sev))) (VX (ADV) (V dlaa (AUX thaa))))t (3.20) (parse (diaa thaa sev raam ko mohan ne)) (S (NP-sul,j (NP (DET nil) (ADJ) (i mohan)) (K-ag ne)) (NP-ind (NP (DET nil) (hDJ) (i raam)) (K-dat ko)) (iP-obj (il' (DET nil) (ADJ) (N sev))) (VX (ADV) (V diaa (AUX thaa))))t It is t~o be noted that though case words llke ne and ko often help to identify subjects, objects etc.
the parser must use semantic information in order to identify them in sentences mlch as the ones given in (3.21-22) (see Dey 1984).
(3.21). (parse (mohan anDaa khaataa hat)) Mohan egg eats is "Mohan eats an egg" (S (NP-subj (NP (DET nil) (ADJ) (N mohan)) (K-ag nil)) (NP-Ind nil (K-dat nil)) (NP-obj (NP (DET nil) (ADJ) (i anDaa))) (VX: (ADV) (V khaataa (AUX hal))))t (3.22) (p ....
(anDaa mohan khaataa hal)) "Mohan eats an egg" (S (NP-subj (NP (DET nil) (ADJ) (N mohan)) (K-ag nil)) (NP-ind nll (K-dat nil)) (NP-obj (NP (DET nil) (ADJ) (N anDaa))) (VX (ADV) (V khaataa (AUX hai))))t 4.
Concluding Remarks Processing word order variation with new techniques within the modified ID/LP framework seems to be revealing.
But, it is not eontext"fl'ee nnlike other ID/LP based parsers.
Detailed comparison of II)/LP based parsers is a subject of further research.
Footnotes: 1.
I am grateful to A.
K. Joshi, A.
Kroch, T.
Finln, D.
Itindle, S.
Gambhlr, K.
Reilly, D.
Kaemmerer, K.
Ryan, II.
Bullock and the anonymous COLING-86 referees for thelr helpful suggestions and comments.
2. See Uszkoreit (1982) for an implementation of ID/LP framework.
3. The right hand side of a rule should be treated as a restricted set rather than as a pure set.
The restriction can bc stated as follows: a membvr of a set can occur only once in the set unless specified otherwise.
Thus, though formally the following two sets are equal, under the restrictions imposed they are notequah { $, O, V } =#= { $, O,V, $,V } References Barton, G.
\]5. Jr.
1985. "On the Complexity of ID/LP Parsing" Computational Linguistics, 11, 205-218 Bates, M.
1978. "The Theory and Practice of Augmented Transition Network gramnlars".
In L.
Bole (ed).
Natural Language Communication with Computers.
Spring Verlag, \]\]erlin: 191-259.
Dey, P.
\]982. "A Parser for Hindi".
Presented to 4th South Asian Languages Round Table, Syracuse, 1982.
...... 1984.
Computatlonally Efficient and Linguistically Adequate Parsing of Some Natural Language Structures.
Ph.D. diss., University of Pennsylvania.
Finin, T.
and G.
IIadden \].977.
"Augmenting ATNs".
In the Proceedings of the 5th IJCAI.
Gambhlr, V.
1980. Syntactic Restrictions and Discourse Functions of Word Order of Standard tIindl.
Ph.D. diss., University of Pennsylvania.
Gazdar, G.
1981. "Unbounded Dependencies and Coordinatc Stmlcture", Linguistic Inquiry 12, 155-184.
Hale, K.
1983. "Warlpiri and the Grammar of Nonconfigurational Languages," Natural Language and Linguistic Theory, 1.5-48.
Kachru, Y.
1980. Aspects of Hindl Syntax.
Delhi: Monohar.
Pullum, G.
K. 1982.
"Free Word Order and Phrase Structure Rules," NELS, 12, 209-222.
Pullum, G.
K. 1983.
"Context-freeness and the Computer Processing of Human Languages," Prec.
of the 21st ACL Conference.
Shleber, S.
1fl83. "Direct Parsing of ID/LP Grammars," Lingnlstlcs and Philosophy 7:2.
Steele, S.
1981. "Word Order Variation: A Typological Study," in J.
Greenberg (ed).
Universals of Language, Vol.
4. Stanford, CA: Stanford University Press.
Uszkorelt, H.
1982. "A Framework for Parsing Partially Free Word Worder," Proceedings of the 21st ACL Conference.
Verma, M.
K. 1971.
The Structure of Noun Phrase in English and Hindi.
Delhi: Motilal Banarsldas.
Woods, W.A. 1970.
"Transition Network Grammars for Natural Language Analysis," Comm.
of ACM \]3, 591-605 .

