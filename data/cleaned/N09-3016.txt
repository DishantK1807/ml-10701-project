Proceedings of the NAACL HLT Student Research Workshop and Doctoral Consortium, pages 90–95,
Boulder, Colorado, June 2009. c 2009 Association for Computational Linguistics
ModelingLetter-to-PhonemeConversionasaPhraseBasedStatistical
MachineTranslationProblemwithMinimumErrorRateTraining
TarakaRama,AnilKumarSingh,SudheerKolachina
Language Technologies ResearchCentre,
IIIT, Hyderabad,India.
{taraka@students,anil@research,sudheer.kpg08@research}.iiit.ac.in
Abstract
Letter-to-phonemeconversionplaysanimpor-
tantroleinseveralapplications. Itcanbeadif-
ﬁculttaskbecausethemappingfromlettersto
phonemescanbemany-to-many. Wepresenta
language independent letter-to-phoneme con-
version approach which is based on the pop-
ular phrase based Statistical Machine Trans-
lation techniques. The results of our ex-
periments clearly demonstrate that such tech-
niques can be used effectively for letter-to-
phoneme conversion. Our results show an
overall improvement of 5.8% over the base-
line and are comparable to the state of the art.
Wealsoproposeameasuretoestimatethedif-
ﬁculty level of L2P taskforalanguage.
1 Introduction
Letter-to-phoneme (L2P) conversion can be deﬁned
as the task of predicting the pronunciation of a
word given its orthographic form (Bartlett et al.,
2008).The pronunciation is usually represented as
a sequence of phonemes. Letter-to-phoneme con-
version systems play a very important role in spell
checkers(ToutanovaandMoore,2002),speechsyn-
thesis systems (Schroeter et al., 2002) and translit-
eration (Sherif and Kondrak, 2007). Letter-to-
phoneme conversion systems may also be effec-
tivelyusedforcognateidentiﬁcationandtranslitera-
tion. Theexistingcognateidentiﬁcationsystemsuse
theorthographicformofawordastheinput. Butwe
know that the correspondence between written and
spoken forms of words can be quite irregular as is
the case in English. Even in other languages with
supposedly regular spellings, this irregularity exists
owing to linguistic phenomena like borrowing and
language variation. Letter-to-phoneme conversion
systems can facilitate the task of cognate identiﬁca-
tion by providing a language independent transcrip-
tionforany word.
Until a few years ago, letter-to-phoneme conver-
sion was performed considering only one-one cor-
respondences (Black et al., 1998; Damper et al.,
2004). Recent work uses many-to-many correspon-
dences (Jiampojamarn et al., 2007) and reports sig-
niﬁcantly higher accuracy for Dutch, German and
French. The current state of the art systems give as
much as 90% (Jiampojamarn et al., 2008) accuracy
forlanguageslikeDutch,GermanandFrench. How-
ever, accuracy of this level is yet to be achieved for
English.
Rule-based approaches to the problem of letter-
to-phoneme conversion although appealing, are im-
practical as the number of rules for a particular lan-
guagecanbeveryhigh(KominekandBlack,2006).
Alternative approaches to this problem are based on
machinelearningandmakeuseofresourcessuchas
pronunciationdictionaries. Inthispaper,wepresent
one such machine learning based approach wherein
we envisage this problem as a Statistical Machine
Translation(SMT)problem.
The outline of the paper is as follows. Section 2
presents a brief summary of the related work done
in L2P conversion. Section 3 describes our model
and the techniques devised for optimizing the per-
formance. Section4describestheletter-to-phoneme
alignment. The description of the results and exper-
iments and a new technique for estimating the difﬁ-
90
cultylevelofL2PtaskhavebeengiveninSection5.
Error analysis is presented in Section 6. Finally we
concludewithasummaryandsuggestdirectionsfor
futurework.
2 RelatedWork
In the letter-to-phoneme conversion task, a single
letter can map to multiple phonemes [x → ks] and
multiple letters can generate a single phoneme. A
letter can also map to a null phoneme [e → ϕ] and
vice-versa. These examples give a glimpse of why
thetaskissocomplexandasinglemachinelearning
technique may not be enough to solve the problem.
Aoverviewof theliteraturesupportsthis claim.
In older approaches, the alignment between the
letters and phonemes was taken to be one-to-
one (Black et al., 1998) and the phoneme was
predicted for every single letter. But recent
work (Bisani and Ney, 2002; Jiampojamarn et al.,
2007) shows that multiple letter-to-phoneme align-
ments perform better than single letter to phoneme
alignments. The problem can be either viewed as a
multi-class classiﬁer problem or a structure predic-
tion problem. In structure prediction, the algorithm
takes the previous decisions as the features which
inﬂuence thecurrentdecision.
In the classiﬁer approach, only the letter and its
contextaretakenasfeatures. Then,eithermulticlass
decisiontrees(DaelemansandvandenBosch,1997)
or instance based learning as in (van den Bosch and
Daelemans,1998)isusedtopredicttheclass,which
in this case is a phoneme. Some of these meth-
ods(Blacketal.,1998)arenotcompletelyautomatic
and need an initial handcrafted seeding to begin the
classiﬁcation.
Structure prediction is like a tagging problem
where HMMs (Taylor, 2005) are used to model
the problem. Taylor claims that except for a pre-
processing step, it is completely automatic. The
whole process is performed in a single step. The
resultsarepoor,asreasonedin(Jiampojamarnetal.,
2008)duetotheemissionprobabilitiesnotbeingin-
formed by the previous letter’s emission probabil-
ities. Pronunciation by Analogy (PbA) is a data-
driven method (Marchand and Damper, 2000) for
letter-to-phoneme conversion which is used again
by Damper et al (2004). They simply use an
Expectation-Maximisation (EM) like algorithm for
aligning the letter-phoneme pairs in a speech dictio-
nary. They claim that by integrating the alignments
induced by the algorithm into the PbA system, they
were able to improve the accuracy of the pronunci-
ation signiﬁcantly. We also use the many-to-many
alignment approach but in a different way and ob-
tainedfromadifferentsource.
The recent work of Jiampojamarn et al (2007)
combinesbothoftheaboveapproachesinaveryin-
teresting manner. It uses an EM like algorithm for
aligningthelettersandphonemes. Thealgorithmal-
lows many-to-many alignments between letters and
phonemes. Then there is a letter chunking module
which uses instance-based training to train on the
alignments which have been obtained in the previ-
ous step. This module is used to guess the possible
letter chunks in every word. Then a local phoneme
predictor is used to guess the phonemes for every
letter in a word. The size of the letter chunk could
be either one or two. Only one candidate for every
word is allowed. The best phoneme sequence is ob-
tainedby usingViterbisearch.
An online model MIRA (Crammer and Singer,
2003) which updates parameters is used for the L2P
task by Jiampojamarn et al (2008). The authors
unifythestepsoflettersegmentation,phonemepre-
diction and sequence modeling into a single mod-
ule. The phoneme prediction and sequence model-
ing are considered as tagging problems and a Per-
ceptron HMM (Collins, 2002) is used to model
it. The letter segmenter module is replaced by a
monotone phrasal decoder (Zens and Ney, 2004) to
searchforthepossiblesubstringsinawordandout-
put the n-best list for updating MIRA. Bisani and
Ney (2002) take the joint multigrams of graphemes
and phonemes as features for alignment and lan-
guagemodelingforphonetictranscriptionprobabili-
ties. Ahybridapproachsimilartothisisby(vanden
Boschand Canisius,2006).
InthenextsectionwemodeltheproblemasaSta-
tisticalMachineTranslation(SMT)task.
3 ModelingtheProblem
Assume that given a word, represented as a se-
quenceoflettersl=l
J
1
=l
1
...l
j
...l
J,needstobetran-
scribed as a sequence of phonemes, represented asf
91
= f
I
1
= f
1
...f
i
...f
I
. The problem of ﬁnding the best
phonemesequenceamongthecandidatetranslations
canbe representedas:
f
best
= argmax
f
{Pr(f|l)} (1)
We model the problem of letter to phoneme con-
version based on the noisy channel model. Refor-
mulatingtheabove equationusingBayes Rule:
f
best
= argmax
f
p(l|f)p(f) (2)
This formulation allows for a phoneme n-gram
modelp(f)andatranscriptionmodelp(l|f). Given
a sequence of letters l, the argmax function is a
search function to output the best phonemic se-
quence. During the decoding phase, the letter se-
quence l is segmented into a sequence of K letter
segments
¯
l
K
1
. Each segment
¯
l
k
in
¯
l
K
1
is transcribed
into a phoneme segment
¯
f
k
. Thus the best phoneme
sequence is generated from left to right in the form
of partial translations. By using an n-gram model
p
LM
as thelanguage model,wehave theequations:
f
best
= argmax
f
p(l|f)p
LM
(3)
with p(l|f) writtenas
p(
¯
l
K
1
|
¯
f
K
1
) =
K
�
k=1
Φ(
¯
l
k
|
¯
f
k
) (4)
From the above equation, the best phoneme se-
quenceisobtainedbasedontheproductoftheprob-
abilities of transcription model and the probabilities
of a language model and their respective weights.
Themethodforobtainingthetranscriptionprobabil-
ities is described brieﬂy in the next section. Deter-
mining the best weights is necessary for obtaining
the right phoneme sequence. The estimation of the
models’ weights can be done in the following man-
ner.
The posterior probability Pr(f|l) can also be
directly modeled using a log-linear model. In
this model, we have a set of M feature functions
h
m
(f,l),m = 1...M . For each feature function
there exists a weight or model parameter λ
m,m =
1...M. Thusthe posteriorprobabilitybecomes:
Pr(f|l) = p
λ
M
1
(f|l) (5)
=
exp
�
Σ
M
m=1
λ
m
h
m
(f,l)
�
�
´
f
I
1
exp
�
Σ
M
m=1
λ
m
h
m
(
´
f
I
1,l)
� (6)
with the denominator, a normalization factor that
canbe ignoredinthemaximization process.
The above modeling entails ﬁnding the suitable
modelparametersorweightswhichreﬂecttheprop-
erties of our task. We adopt the criterion followed
in (Och, 2003) for optimising the parameters of the
model. The details of the solution and proof for the
convergence are given in Och (2003). The models’
weights, used for the L2P task, are obtained from
thistraining.
4 Letter-to-PhonemeAlignment
We used GIZA++ (Och and Ney, 2003), an open
source toolkit, for aligning the letters with the
phonemes in the training data sets. In the context
of SMT, say English-Spanish, the parallel corpus is
alignedbidirectionallytoobtainthetwoalignments.
The IBM models give only one-to-one alignments
between words in a sentence pair. So,GIZA++ uses
some heuristics to reﬁne the alignments (Och and
Ney,2003).
In our input data, the source side consists of
grapheme (or letter) sequences and the target side
consists of phoneme sequences. Every letter or
grapheme is treated as a single ‘word’ for the
GIZA++ input. The transcription probabilities can
then be easily learnt from the alignments induced
by GIZA++, using a scoring function (Koehn et al.,
2003). Figure 1 shows the alignments induced by
GIZA++ for the example words which are men-
tioned by Jiampojamarn et al (2007). In this ﬁg-
ure, we only show the alignments from graphemes
tophonemes.
Figure 1: Example Alignments fromGIZA++
92
5 Evaluation
We evaluated our models on the English CMUDict,
French Brulex, German Celex and Dutch Celex
speech dictionaries. Thesedictionaries are available
for download on the website of PROANALSYL
1
Letter-to-Phoneme Conversion Challenge. Table 1
shows the number of words for each language. The
datasets available at the website were divided into
10folds. Intheprocessofpreparingthedatasetswe
took one set for test, another for developing our pa-
rameters and the remaining 8 sets for training. We
report our results in word accuracy rate, based on
10-foldcrossvalidation,withmeanandstandardde-
viation.
Language Datasets Number of Words
English CMUDict 112241
French Brulex 27473
German Celex 49421
Dutch Celex 116252
Table 1: Number ofwords ineach Dataset
We removed the one-to-one alignments from
the corpora and induced our own alignments us-
ing GIZA++. We used minimum error rate train-
ing (Och, 2003) and the A* beam search de-
coder implemented by Koehn (Koehn et al., 2003).
All the above tools are available as parts of the
MOSES(Koehnetal.,2007) toolkit.
5.1 ExploringtheParameters
Theparameterswhichhaveamajorinﬂuenceonthe
performance of a phrase-based SMT model are the
alignment heuristics, the maximum phrase length
(MPR) and the order of the language model (Koehn
et al., 2003). In the context of letter to phoneme
conversion, phrase means a sequence of letters or
phonemes mapped to each other with some prob-
ability (i.e., the hypothesis) and stored in a phrase
table. The maximumphraselength corresponds to
the maximum number of letters or phonemes that a
hypothesis can contain. Higher phrase length corre-
spondsalarger phrasetableduringdecoding.
We have conducted experiments to see which
combination gives the best output. We initially
trained the model with various parameters on the
1
http://www.pascal-network.org/Challenges/PRONALSYL/
training data and tested for various values of the
above parameters. We varied the maximum phrase
length from 2 to 7. The language model was trained
usingSRILMtoolkit(Stolcke,2002). Wevariedthe
order of language model from 2 to 8. We also tra-
versed the alignment heuristics spectrum, from the
parsimonious intersect at one end of the spectrum
through grow, grow-diag, grow-diag-ﬁnal, grow-
diag-ﬁnal-andandsrctotgttothemostlenientunion
attheotherend. Ourintuitiveguesswasthatthebest
alignmentheuristicwouldbeunion.
We observed that the best results were obtained
whenthelanguagemodelwastrainedon6-gramand
the alignment heuristic was union. No signiﬁcant
improvement was observed in the results when the
value of MPR was greater than 5. We have taken
caresuchthatthealignmentsarealwaysmonotonic.
Note that the average length of the phoneme se-
quencewasalso6. Weadoptedtheaboveparameter
settingsfor performingtrainingontheinputdata.
5.2 SystemComparison
Weadopttheresultsgivenin(2007)asourbaseline.
We also compare our results with some other recent
techniques mentioned in the Related Work section.
Table 2 shows the results. As this table shows, our
approach yields the best results in the case of Ger-
man and Dutch. The word accuracy obtained for
the German Celex and Dutch Celex dataset using
our approach is higher than that of all the previous
approaches listed in the table. In the case of En-
glish and French, although the baseline is achieved
through our approach, the word accuracy falls short
of being the best. However, it must also be noted
that the dataset that we used for English is slightly
larger than those of the other systems shown in the
table.
We also observe that for an average phoneme
accuracy of 91.4%, the average word accuracy is
63.81%, which corroborates the claim by Black et
al(Blacketal.,1998)thata90%phonemeaccuracy
correspondsto60% wordaccuracy.
5.3 DifﬁcultyLevelandAccuracy
We also propose a new language-independent mea-
sure that we call ‘Weighted Symmetric Cross En-
tropy’(WSCE)toestimatethedifﬁcultylevelofthe
L2P task for a particular language. The weighted
93
Language Dataset Baseline CART 1-1Align 1-1+ CSIF 1-1+ HMM M-M Align M-M +HMM MeR+ A*
English CMUDict 58.3±0.49 57.8 60.3±0.53 62.9±0.45 62.1±0.53 65.1±0.60 65.6±0.72 63.81±0.47
German Celex 86.0±0.40 89.38 86.6±0.54 87.6±0.47 87.6±0.59 89.3±0.53 89.8±0.59 90.20±0.25
French Brulex 86.3±0.67 87.0±0.38 86.5±0.68 88.2±0.39 90.6±0.57 90.9±0.45 86.71±0.52
Dutch Celex 84.3±0.34 86.6±0.36 87.5±0.32 87.6±0.34 91.1±0.27 91.4±0.24 91.63±0.24
Table2: SystemComparisonintermsofwordaccuracies.Baseline:ResultsfromPRONALSYSwebsite.CART:CARTDecision
Tree System (Black et al., 1998). 1-1Align,M-Malign,HMM:one-one alignments, many-many alignments, HMM with local
prediction (Jiampojamarn et al., 2007). CSIF:Constraint Satisfaction Inference(CSIF) of(van den Bosch and Canisius, 2006).
MeR+A*:Our approach withminimum errorrate trainingand A*search decoder. “-” referstono reportedresults.
SCE is deﬁnedas follows:
d
sce
wt
=
�
r
t
(p
l
log (q
f
) + q
f
log (p
l
)) (7)
where p and q are the probabilities of occurrence
of letter (l) and phoneme (f) sequences, respec-
tively. Also, r
t
corresponds to the conditional prob-
ability p(f | l). This transcription probability can
be obtained from the phrase tables generated during
training. The weighted entropy measure d
sce
wt,for
each language, was normalised with the total num-
ber of such n-gram pairs being considered for com-
parison with other languages. We have ﬁxed the
maximum order of l and f n-grams to be 6. Ta-
ble 3 shows the difﬁculty levels as calculated using
WSCE along with the accuracy for the languages
that we tested on. As is evident from this table,
there is a rough correlation between the difﬁculty
level and the accuracy obtained, which also seems
intuitivelyvalid,giventhenatureoftheselanguages
andtheir orthographies.
Language Datasets d
sce
wt
Accuracy
English CMUDict 0.30 63.81±0.47
French Brulex 0.41 86.71±0.52
Dutch Celex 0.45 91.63±0.24
German Celex 0.49 90.20±0.25
Table 3: d
sce
wt
values predict the accuracy rates.
6 ErrorAnalysis
In this section we present a summary of the error
analysis for the output generated. We tried to ob-
serve if there exist any patterns in the words that
weretranscribedincorrectly.
The majority of errors occurred in the case of
vowel transcription, and diphthong transcription in
particular. In the case of English, this can be at-
tributed to the phenomenon of lexical borrowing
from a variety of sources as a result of which the
number of sparse alignments is very high. The sys-
tem is also unable to learn allophonic variation of
certain kinds of consonantal phonemes, most no-
tably fricatives like /s/ and /z/. This problem is ex-
acerbated by the irregularity of allophonic variation
inthelanguage itself.
7 ConclusionandFutureWork
In this paper we have tried to address the problem
of letter-to-phoneme conversion by modeling it as
an SMT problem and we have used minimum error
rate training to obtain the suitable model parame-
ters, which according to our knowledge, is a novel
approachtoL2Ptask. Theresultsobtainedarecom-
parable to the state of the art system and our error
analysisshowsthatalotofimprovementisstillpos-
sible.
Intuitively, the performance of the system can be
improvedinatleasttwoareas. FirstistheMinimum
Error Rate Training (MERT) and the second is the
decoding phase. Using phonetic feature based edit
distance or string similarity as the loss function in
the MERT implementation can improve results sig-
niﬁcantly. In addition, incorporating more model
parameters and extensive testing of these parame-
ters might improve the results of the system. We
also plan to introduce a decoding scheme similar to
the substring based transducer (Sherif and Kondrak,
2007) to improve the usage of lower order language
models.
Acknowledgements
This work was supported by ILMT grant
11(10)/2006-HCC(TDIL).
94
References
Susan Bartlett, Grzegorz Kondrak, and Colin Cherry.
2008. AutomaticsyllabiﬁcationwithstructuredSVMs
for letter-to-phoneme conversion. In Proceedings of
ACL-08:HLT,pages568–576,Columbus,Ohio,June.
ACL.
Max Bisani and Hermann Ney. 2002. Investigations
on joint-multigram models for grapheme-to-phoneme
conversion. In International Conference on Spoken
Language Processing, pages 105–108, Denver, CO,
USA, September.
A.W. Black, K. Lenzo, and V. Pagel. 1998. Issues in
Building General Letter to Sound Rules. InTheThird
ESCA/COCOSDAWorkshop(ETRW)onSpeechSyn-
thesis.ISCA.
M. Collins. 2002. Discriminative training methods for
hidden Markov models: theory and experiments with
perceptron algorithms. InProceedingsoftheACL-02
conference on EMNLP-Volume 10, pages 1–8. ACL,
Morristown, NJ,USA.
K. Crammer and Y. Singer. 2003. Ultraconservative on-
line algorithms for multiclass problems. TheJournal
ofMachineLearningResearch, 3:951–991.
Walter M. P. Daelemans and Antal P. J. van den
Bosch. 1997. Language-Independent Data-0riented
Grapheme-to-Phoneme Conversion. Progress in
SpeechSynthesis.
R.I.Damper,Y.Marchand,J.D.Marseters,andA.Bazin.
2004. AligningLettersandPhonemesforSpeechSyn-
thesis. In FifthISCAWorkshoponSpeechSynthesis.
ISCA.
Sittichai Jiampojamarn, Grzegorz Kondrak, and Tarek
Sherif. 2007. Applying many-to-many alignments
and hidden markov models to letter-to-phoneme con-
version. InHLT2007:TheConferenceoftheNAACL;
ProceedingsoftheMainConference, pages 372–379,
Rochester, New York, April.ACL.
Sittichai Jiampojamarn, Colin Cherry, and Grzegorz
Kondrak. 2008. Joint processing and discrimina-
tivetrainingforletter-to-phonemeconversion. InPro-
ceedingsofACL-08:HLT,pages905–913,Columbus,
Ohio, June. ACL.
P. Koehn, F.J. Och, and D. Marcu. 2003. Statistical
phrase-based translation. In Proceedingsofthe2003
ConferenceoftheNAACL:HLT-Volume1, pages 48–
54. ACLMorristown, NJ,USA.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, et al. 2007. Moses: Open Source
Toolkit for Statistical Machine Translation. In ACL,
volume 45, page 2.
J. Kominek and A.W. Black. 2006. Learning pronuncia-
tiondictionaries: languagecomplexityandwordselec-
tion strategies. InHLT-NAACL, pages 232–239. ACL,
Morristown, NJ,USA.
Y. Marchand and R.I. Damper. 2000. A Multistrat-
egy Approach to Improving Pronunciation by Anal-
ogy. ComputationalLinguistics, 26(2):195–219.
F.J.OchandH.Ney. 2003. ASystematicComparisonof
Various Statistical Alignment Models. Computational
Linguistics, 29(1):19–51.
F.J.Och. 2003. Minimumerrorratetraininginstatistical
machine translation. In Proceedings of the 41st An-
nualMeetingonACL-Volume1,pages160–167.ACL,
Morristown, NJ,USA.
J. Schroeter, A. Conkie, A. Syrdal, M. Beutnagel,
M.Jilka,V.Strom,Y.J.Kim,H.G.Kang,andD.Kapi-
low. 2002. A Perspective on the Next Challenges for
TTS Research. In IEEE 2002 Workshop on Speech
Synthesis.
Tarek Sherif and Grzegorz Kondrak. 2007. Substring-
based transliteration. In Proceedingsofthe45thAn-
nual Meeting of the Association of Computational
Linguistics, pages 944–951, Prague, Czech Republic,
June. Associationfor Computational Linguistics.
A.Stolcke. 2002. Srilm–anextensiblelanguagemodel-
ing toolkit.
P. Taylor. 2005. Hidden Markov Models for Grapheme
to Phoneme Conversion. In Ninth European Con-
ference on Speech Communication and Technology.
ISCA.
K. Toutanova and R.C. Moore. 2002. Pronunciation
modeling for improved spelling correction. In Pro-
ceedings of the 40th annual meeting of ACL, pages
144–151.
A. van den Bosch and S. Canisius. 2006. Improved
morpho-phonological sequence processing with con-
straint satisfaction inference. In Proceedings of the
EighthMeetingoftheACL-SIGPHONatHLT-NAACL,
pages 41–49.
A. van den Bosch and W. Daelemans. 1998. Do not for-
get: Full memory in memory-based learning of word
pronunciation. proceedings of NeMLap3/CoNLL98,
pages 195–204.
R. Zens and H. Ney. 2004. Improvements in phrase-
based statistical machine translation. In HLTConf./
NAACL, pages 257–264, Boston, MA, May.
95

