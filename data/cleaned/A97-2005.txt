Dependency parser demo Timo J~irvinen and Pasi Tapanainen University of Helsinki, Department of General Linguistics Research Unit for Multilingual Language Technology P.O.
Box 4, FIN-00014 University of Helsinki, Finland {Pasi.
Tapanainen, Timo.
Jarvinen}©ling. Helsinki.
fi 1 Introduction We are concerned with surface-syntactic parsing of running text.
Our main goal is to describe a syntactic analysis of sentences using dependency links that show the head-dependent relations between words.
The new dependency parser 1 (Tapanainen and J~irvinen, 1997; J~rvinen and Tapanainen, 1997) belongs to a continuous effort to apply rule-based methods to natural languages.
It can been seen as a relative of the Constraint Grammar framework (Karlsson et al., 1995), for many features of the system have been derived from it.
The syntactic description in the English Constraint Grammar (ENGCG) is implicitly dependency oriented; it contains tags for heads and modifiers but not explicit links between them (see Figure 2).
Although, the new syntactic formalism differs much from the Constraint Grammar's formalisms, the basic rule types of the older formalism have been preserved among the new ones.
Also, the rules are independent, and they describe syntax in a piecemeal fashion.
The new dependency parser creates explicit links between the elements of the sentence (in Figure 1) while still retaining the shallower representation similar to ENGCG (in Figure 2).
The parser applies the ENGTWOL lexicon designed originally by Juha Heikkil£ and Atro Voutilainen.
Also, the reliable parts of the ENGCG's morphological disambiguator by Atro Voutilainen are applied.
The parser has been tested in Sun workstation and in PCs under Linux.
The syntactic analysis is modest in time and space requirements: the size of the process (the syntactic analysis only) is less than 2 MB and it runs in a Pentium 90 MHz machine at the speed of 200 words per second.
We have tested the parser on bigger texts to test its usability in corpus linguistic and lexicographic work.
By now, some 30 million words have been pparsed., http://www.ling.helsinki.fi/~tapanain/dg/ 2 The dependency model Our syntactic description can be seen as a formalisation of Tesni~re's (1959) original dependency theory.
The dependency model adopted to our description differs in various respects from the post-Tesni~rean development of dependency theory, though many of the features are recognised elsewhere.
The main features of the parsing system and the adopted dependency theory are: • The basic syntactic element is not a word, but a nucleus.
This is related to the internM organisation of the grammar, though the default output shows the dependency links between surface words.
• Every element has one and only one head (uniqueness).
• The result is a tree.
• Functional dependencies are expressed by link names.
• The links may cross (non-projective constructions are allowed).
• Modifiers are not obligatory; valency defines possibility rather than obligatoriness to have arguments.
• The grammar is not generative.
This means that the parser accepts every input sentence, and returns an analysis even for ungrammatical sentences to the extent the structure is recoverable.
• The dependency description is monostratal, i.e. there is one level of syntactic description, the surface-syntactic description, and no transformations.
9 <LIKE> ~-~.~ ---.._2b j: <WOULD> <DO> ubj: obj: : ~t: <WHAT> <YOU> <ME~)(:TO> <$.9> Figure 1: Dependency tree <What> "what" <**CLB> PRON WH SG/PL @OBJ <would> "would" V AUXMOD VFIN @+FAUXV <you> "you" PRON PERS NOM SG2/PL2 @SUBJ <like> "like" V INF @-FMAINV <me> "i" PRON PERS ACC SG1 @OBJ <to> "to" INFMAIZK> @INFMARK> <do> "do" V INF @-FMAINV <?> Figure 2: ENGCG-style output A An example The following sentence is excerpted from Jane Smiley's Barn Blind (HarperCollins, 1994, p.
8). The dependency links are enumerated and named, e.g. subj:>2 marks the subject of the head #2.

