Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 1–8
Manchester, August 2008
Two-Phased Event Relation Acquisition:
Coupling the Relation-Oriented and Argument-Oriented Approaches
Shuya Abe Kentaro Inui Yuji Matsumoto
Graduate School of Information Science,
Nara Institute of Science and Technology
{shuya-a,inui,matsu}@is.naist.jp
Abstract
Addressing the task of acquiring semantic
relations between events from a large corpus,
we first argue the complementarity between
the pattern-based relation-oriented
approach and the anchor-based argumentoriented
approach. We then propose a twophased
approach, which first uses lexicosyntactic
patterns to acquire predicate pairs
and then uses two types of anchors to identify
shared arguments. The present results
of our empirical evaluation on a large-scale
Japanese Web corpus have shown that (a)
the anchor-based filtering extensively improves
the accuracy of predicate pair acquisition,
(b) the two types of anchors are
almost equally contributive and combining
them improves recall without losing accuracy,
and (c) the anchor-based method also
achieves high accuracy in shared argument
identification.
1 Introduction
The growing interest in practical NLP applications
such as question answering, information extraction
and multi-document summarization places increasing
demands on the processing of relations
between textual fragments such as entailment and
causal relations. Such applications often need to
rely on a large amount of lexical semantic knowledge.
For example, a causal (and entailment) relation
holds between the verb phrases wash something
and something is clean, which reflects the
commonsense notion that if someone has washed
c©2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported license
(http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
something, this object is clean as a result of the
washing event. A crucial issue is how to obtain
and maintain a potentially huge collection of
such event relation instances. This paper addresses
the issue of how to automatically acquire such instances
of relations between events (henceforth,
event relation instances) from a large-scale text
collection.
Motivated by this issue, several research groups
have reported their experiments on automatic acquisition
of causal, temporal and entailment relations
between event expressions (typically verbs
or verb phrases) (Lin and Pantel, 2001; Inui et
al., 2003; Chklovski and Pantel, 2005; Torisawa,
2006; Pekar, 2006; Zanzotto et al., 2006; Abe et
al., 2008, etc.). As we explain below, however,
none of these studies fully achieves the goal we
pursue in this paper.
An important aspect to consider in event relation
acquisition is that each event has arguments. For
example, the causal relation between wash something
and something is clean can be represented
naturally as:
(1) wash(obj:X) →
cause
is clean(subj:X),
where X is a logical variable denoting that the
filler of the object slot of the wash event should be
shared (i.e. identical) with the filler of the subject
slot of the is clean event.
To be more general, an instance of a given relation
R can be represented as:
(2) pred
1
(arg
1
:X) →
R
pred
2
(arg
2
:X),
where pred
i
is a natural language predicate, typically
a verb or adjective, and X is a logical variable
denoting which argument of one predicate and
which argument of the other are shared. The goal
we pursue in this paper is therefore not only (a)
to find predicate pairs that are of a given relation
1
type, but also (b) to identify the arguments shared
between the predicates if any. We call the former
subtask predicate pair acquisition and the latter
shared argument identification. Aswereview
in the next section, however, existing state-of-theart
methods for event relation acquisition are designed
to achieve only either of these two subtasks
but not both. In this paper, we propose a twophased
method, which first uses lexico-syntactic
patterns to acquire predicate pairs for a given relation
type and then uses two kinds of anchors to
identify shared arguments.
2 Previous
work
Existing methods for event relation acquisition can
be classified into two approaches, which we call
the pattern-based approach and anchor-based approach
in this paper.
The common idea behind the pattern-based approach
is to use a small number of manually selected
generic lexico-syntactic co-occurrence patterns
(LSPs or simply patterns). Perhaps the simplest
way of using LSPs for event relation acquisition
can be seen in the method Chklovski and
Pantel (2005) employ to develop their knowledge
resource called VerbOcean. Their method uses a
small number of manually selected generic LSPs
such as to 〈Verb-X〉 and then 〈Verb-Y〉
1
to obtain
six types of semantic relations including strength
(e.g. taint – poison) and happens-before (e.g.
marry – divorce). The use of such generic patterns,
however, tends to be high recall but low precision.
Chklovski and Pantel (2005), for example, report
that their method obtains about 29,000 verb pairs
with 65.5% precision.
This low-precision problem requires an additional
component for pruning extracted relations.
This issue has been addressed from a variety of
angles. For example, some devise heuristic statistical
scores and report their impact on precision
(Chklovski and Pantel, 2005; Torisawa, 2006;
Zanzotto et al., 2006). Another way is to incorporate
a classifier trained with supervision. Inui
et al. (2003), for example, use a Japanese generic
causal connective marker tame (because) and a
supervised classifier learner to separately obtain
four types of causal relations: cause, precondition,
effect and means. More recently, Abe et
al. (2008) propose to extend Pantel and Pennac1
1
A 〈〉 included in an LSP denotes, throughout this paper,
a variable slot to be filled with an event expression. The filler
of 〈〉 denotes either the lexical or syntactic constraints on the
slot or an example that is to fill the slot.
chiotti (2006)’s Espresso algorithm, which induces
specific reliable LSPs in a bootstrapping manner
for entity-entity relation extraction, so that
the extended algorithm can apply to event relations.
Their method learns a large number of relatively
specific patterns such as cannot 〈find out
(something)〉 due to the lack of 〈investigation〉 in a
boot-strapping fashion, which produces a remarkable
improvement on precision.
The anchor-based approach, on the other hand,
has emerged mainly in the context of paraphrase
and entailment acquisition. This approach uses information
of argument fillers (i.e. anchors) of each
event expression as a useful clue for identifying
event relations. A popular way of using such argument
information relies on the distributional hypothesis
(Harris, 1968) and identifies synonymous
event expressions by seeking a set of event expressions
whose argument fillers have a similar distribution.
Such algorithms as DIRT (Lin and Pantel,
2001) and TE/ASE (Szpektor et al., 2004) represent
this line of research.
Another way of using argument information is
proposed by Pekar (2006), which identifies candidate
verb pairs for the entailment relation by imposing
criteria: (a) the two verbs must appear in
the same local discourse-related context and (b)
their arguments need to refer to the same participant,
i.e. anchor. For example, if a pair of
clauses Mary bought a house. and The house belongs
to Mary. appear in a single local discourserelated
context, two pairs of verbs, buy(obj:X)–
belong(subj:X) and buy(subj:X)–belong(to:X) are
identified as candidate entailment pairs.
It is by now clear that the above two approaches,
which apparently have emerged somewhat independently,
could play a complementary role with
each other. Pattern-based methods, on the one
hand, are designed to be capable of discriminating
relatively fine-grained relation types. For example,
the patterns used by Chklovski and Pantel
(2005) identify six relation types, while Abe
et al. (2008) identify two of the four causal relation
types defined by Inui et al. (2003). However,
these methods are severely limited for the purpose
of shared argument identification because lexicosyntactic
patterns are not a good indication of
argument-shared structure in general. The anchorbased
approach, on the other hand, works well for
identifying shared arguments simply because it relies
on argument information in identifying synonymous
or entailment verb pairs. However, it has
no direct means to discriminate more fine-grained
2
specific relations such as causality and backward
presupposition. To sum up, the pattern-based approach
tends to be rather relation-oriented while
the anchor-based approach tends to be argumentoriented.
oriented.
In spite of this complementarity, however, to our
best knowledge, the issue of how to benefit from
both approaches has never been paid enough attention.
An interesting exception could be found
in Torisawa (2006)’s method of combining verb
pairs extracted with a highly generic connective
pattern 〈Verb-X〉 and 〈Verb-Y〉 together with the
co-occurrence statistics between verbs and their arguments.
While the reported results for inference
rules with temporal ordering look promising, it is
not clear yet, however, whether the method applies
to other types of relations because it relies
on relation-specific heuristics.
3 Two-phased event relation acquisition
3.1 The
basic idea
The complementarity between the pattern-based
relation-oriented approach and the anchor-based
argument-oriented approach as discussed above
naturally leads us to consider combining them.
The method we explore in this paper is illustrated
in Figure 1. The overall process has two phrases:
predicate pair acquisition followed by shared argument
identification. Given a relation type for acquisition,
we first acquire candidate predicate pairs
that are likely to be of the given relation exploiting
a state-of-the-art pattern-based method. We then,
in the second phase, seek anchors indicative of the
shared argument for each acquired predicate pair.
We consider two kinds of anchors: instance-based
anchors and type-based anchors. If anchors are
found, the predicate pair is verified and the associated
argument pair is identified as the shared argument;
otherwise, the predicate pair is discarded.
As we demonstrate in the section for empirical
evaluation, this verification process boosts the accuracy
as well as identifying shared arguments.
3.2 Predicate
pair acquisition
For predicate pair acquisition, we can choose
one from a range of state-of-the-art pattern-based
methods. Among others, in our experiments, we
adopted Abe et al. (2008)’s method because it had
an advantage in that it was capable of learning patterns
as well as relation instances.
Abe et al. (2008)’s method is based on Pantel
and Pennacchiotti (2006)’s Espresso algorithm,
which is originally designed to acquire relations
between entities. Espresso takes as input a small
number of seed instances of a given target relation
and iteratively learns co-occurrence patterns
and relation instances in a bootstrapping manner.
Abe et al. have made several extensions to it so
that it can be applied to event relations. Since the
details of this phase are not the focus of this paper,
we refer the reader to (Abe et al., 2008) for further
information.
3.3 Shared
argument identification
For each of the predicate pairs acquired in the previous
phase, in shared argument identification, we
use anchors to identify which argument is shared
between the predicate pair. To find anchors indicative
of shared arguments, we have so far examined
two methods. We detail each below.
3.3.1 Instance-based anchors
Inspired by Pekar (2006)’s way of using anchors
for verb entailment acquisition, we assume
that if two related predicates have a shared argument,
they must tend to appear in the same local
discourse-related context with the shared argument
filled with the same noun phrase (i.e. anchor).
As an example, let us consider discourse (2a) in
Figure 1. In this local discourse context, the noun
bread appears twice, and one bread fills the subject
slot of burn while the other fills the object slot of
bake. In such a case, we assume the two breads refer
to the same object, namely anchor, and the subject
of burn and the object of bake are shared with
each other. We call such anchors instance-based
anchors for the sake of contrast with type-based
anchors, which we describe in 3.3.2.
We implement this assumption in the following
way. Given a pair of predicates Pred
1
and Pred
2,
we search a corpus for tuples 〈Pred
1
-Arg
1
; Pred
2,
Arg
2
; Anc〉 satisfying the following conditions:
(a) Anchor word Anc is the head of a noun phrase
filling argument Arg
1
of Pred
1
appearing in a
Web page.
(b) Anc also fills argument Arg
2
of Pred
2
appearing
in the same Web page as above.
(c) Anc must not be any of those in the stop list.
(d) pmi(Pred
i, Arg
i
) ≥−1.0 for i ∈{1, 2}
For our experiments, we manually created the stop
list, which contained 219 words including pronouns,
numerals and highly generic nouns such as
3
Figure 1: Two-phased event relation acquisition
4
“\q(thing)”, “�w(thing)” and “qV(time)”.
pmi(Pred
i, Arg
i
) in condition (d) is the point-wise
mutual information between Pred
i
and Arg
i
. This
condition is imposed for pruning wrong anchors
misidentified due to parsing errors.
While Pekar carefully defines boundaries of local
discourse-related context, we simply assume
that every pair of predicates sharing an anchor in
a Web page is somewhat related — unlike Pekar,
we do not impose such constraints as paragraph
boundaries. Nevertheless, as we show later in
the evaluation section, our assumption works precisely
enough because the looseness of our discourse
boundary constraint is compensated by the
constraints imposed by lexico-syntactic patterns.
We finally calculate an anchor set for each argument
pair Pred
1
-Arg
1
and Pred
2
-Arg
2
by accumulating
the obtained tuples:
AnchorSet(Pred
1
-Arg
1, Pred
2
-Arg
2
)
= {Arg|〈Pred
1
-Arg
1
; Pred
2
-Arg
2
; Anc〉}.
3.3.2 Type-based anchors
Let us consider sentences (3a) and (3b) in
Figure 1. These two sentences both contain predicates
bake and burn. In (3a), the noun bread fills
the object slot of bake, while in (3b) the same noun
bread fills the subject slot of burn. In such a case,
we assume the noun bread to be an anchor indicating
that the object of bake and the subject of
burn are shared with each other. We call such anchors
type-based anchors because bread in (3a)
and bread in (3b) do not refer to the same object
but are identical just as type.
Given a pair of predicates Pred
1
and Pred
2,we
search a corpus for sentences where Pred
1
and
Pred
2
co-occur, and calculate the frequency counts
of their argument fillers appearing in those sentences:
tences:
• If argument Arg
1
of Pred
1
is filled by noun
Anc, increment the count of 〈Pred
1
-Arg
1
;
Pred
2
; Anc〉.
• If argument Arg
2
of Pred
2
is filled by noun
Anc, increment the count of 〈Pred
1
; Pred
2
Arg
Arg
2
; Anc〉.
We then identify the intersection between the filler
sets of Pred
1
-Arg
1
and Pred
2
-Arg
2
as the anchor
set of that argument pair. Namely,
AnchSet(Pred
1
-Arg
1, Pred
2
-Arg
2
)=S
1
∩ S
2,
where
S
1
= {Arg|〈Pred
1
-Arg
1
; Pred
2
; Anc〉},
S
2
= {Arg|〈Pred
1
; Pred
2
-Arg
2
; Anc〉}.
3.3.3 Application
of anchor sets
We say an argument pair covered by anchors
only if any anchor is found for it. Analogously,
we say a predicate pair covered by anchors only if
any argument pair associated with it is covered by
anchors. In the phase of shared argument identification,
for each given predicate pair, we carry out
the following procedure:
1. Discard the predicate pair if it is not covered
by anchors.
2. Choose maximally k-most frequent argument
pairs associated with the predicate pair (k =3
in our experiments).
3. Choose maximally l-most frequent anchors
for each chosen argument pair (l =3).
4 Experiments
4.1 Settings
For an empirical evaluation, we used a sample
of approximately 500M sentences taken from the
Web corpus collected by Kawahara and Kurohashi
(2006). The sentences were dependencyparsed
with CaboCha (Kudo and Matsumoto,
2002), and co-occurrence samples of event mentions
were extracted. Event mentions with patterns
whose frequency was less than 20 were discarded
in order to reduce computational costs.
In our experiments, we considered two of Inui et
al. (2003)’s four types of causal relations: actioneffect
relations (Effect in Inui et al.’s terminology)
and action-means relations (Means). An actioneffect
relation holds between events x and y if and
only if non-volitional event y is likely to happen as
either a direct or indirect effect of volitional action
x. For example, the action X-ga undou-suru (X exercises)
and the event X-ga ase-o-kaku (X sweats)
are considered to be in this type of relation. We
did not require the necessity for an effect. For example,
while nomu (drink) does not necessarily result
in futsukayoi-ni naru (have a hangover), the
assessors judged this pair correct because one can
at least say that the latter sometimes happens as a
result of the former. An action-means relation, on
the other hand, holds between events x and y if and
only if volitional action y is likely to be done as a
part/means of volitional action x. For example, if
5
case a event-pair is X-ga hashiru (X runs) is considered
as a typical action that is often done as a
part of the action X-ga undou-suru (X exercises).
For our experiments, we manually built a lexicon
of over 12,000 verbs with volitionality labels,
obtaining 8,968 volitional verbs, 3,597 nonvolitional
and 547 ambiguous. Volitional verbs
include taberu (eat) and kenkyu-suru (research),
while non-volitional verbs include atatamaru (get
warm), kowareru (to break-vi) and kanashimu (be
sad). Volitionality information was used as a feature
of predicate slots in pattern-based predicate
pair acquisition.
4.2 Results
and discussion
4.2.1 Predicate
pair acquisition
We ran the extended Espresso algorithm starting
with 25 positive and 4 negative seed relation
instances for the action-effect relation and 174
positive and 131 negative seed relations for the
action-means relation. As a result, we obtained
9,511 patterns with 22,489 relation instances for
action-effect and 14,119 co-occurrence patterns
with 13,121 relation instances for action-means
after 40 iterations of pattern and instance ranking/selection.
The threshold parameters for selecting
patterns and instances were decided in a preliminary
trial. Some of the acquired instances are
shown in Table 1.
We next randomly sampled 100 predicate pairs
from each of four sections (1–500, 501–1500,
1501–3500 and 3500–7500) of the ranks of the acquired
pairs for each relation class. Two annotators
were asked to judge the correctness of each predicate
pair (i.e. 800 pairs in total). They judged a
predicate pair to be correct if they could produce
an appropriate relation instance from that pair by
adding some shared argument. For example, the
pairTZ�(hang/put/call) andmsU�(connect)
was judged correct because it could constitute such
a relation instance as:
(3)TZ�(�:X) →
effect
msU�(U:X)
(X ∈{?�})
make(obj:X) →
effect
go-through(subj:X)
(X ∈{phone-call})
Unfortunately, the two annotators did not agree
with each other very much. out of the 400 samples,
they agreed only on 294 for action-effect and
297 for action-means. However, a closer look at
the results revealed that the judgements of the one
annotator were considerably but very consistently
Table 2: Accuracy and recall of relation classification
tion
LSPs covered by anchors
all top-N instance type combined
action-effect 400 254 175 169 254
269 185 144 143 206
(accuracy) (0.67) (0.72) (0.82) (0.84) (0.81)
(recall) (1.00) (0.68) (0.53) (0.53) (0.76)
action-means 400 254 178 176 254
280 193 143 140 200
(accuracy) (0.70) (0.75) (0.80) (0.79) (0.78)
(recall) (1.00) (0.68) (0.51) (0.50) (0.71)
more tolerant than the other. Assuming that the
judgements of the latter correct, the precision and
recall of those of the former would be 0.71 and
0.97 for action-effect, and 0.75 and 0.99 for actionmeans.
These figures indicate that the two annotators
agreed quite well with respect to the “goodness”
of a sample, while having different criteria
for strictness. For our evaluation, we decided to
lean to the strict side and considered a sample correct
only if it was judged correct by both annotators.
The accuracy and recall achieved by the
pattern-based model is shown in the column “all”
under “LSPs” in Table 2.
We then applied the anchor-based methods described
in Section 3.3 to the above 800 sampled
predicate pairs. The results are shown in the column
“covered by anchors” of Table 2. Since the
tendency for both relation classes is more or less
the same, let us focus only on the results for actioneffect.
effect.
As shown in the column “all” under “LSPs” in
the table, the pattern-based method covered 269
out of the 400 predicate pairs sampled above. The
instance-based anchors (“instance”) covered 175
out of the 400 predicate pairs sampled above, and
144 of them were correct with respect to relation
type. We calculate its accuracy by dividing 144
by 175 and recall by dividing 144 by 269. These
figures indicate that the instance-based anchors
chose correct predicate pairs at a very high accuracy
while sacrificing recall. The recall, however,
can be extensively improved without losing accuracy
by combining the instance-based and typebased
anchors, where we considered a predicate
pair covered if it was covered by either of the
instance-based and type-based anchors. The results
are shown in the column “combined” under
“covered by anchors” in the same table. While the
type-based anchors exhibited the same tendency as
the instance-based anchors (namely, high accuracy
6
Table 1: Examples
Pred1 Arg1 Pred2 Arg2 Anc
action-effect begin(��b�) obj(�) finish( 4�b�) subj(�) installation(������),
transaction(��������)
action-effect design(����b�) obj(�) be pretty(T�MM) subj(�) logotype(��)
action-effect sleep( ��) in(�) be sleep(���) in(�) bed(���), futon(��)
action-means cure(��b�) by(�) prescribe( rMb�) obj(�) medicine( )
action-means cure(��b�) obj(�) prescribe( rMb�) for(�) patient(�  )
action-means go home(<Pb�) by(�) drive(�8b�) obj(�) car( ), car(�� )
action-means use(b;b�) obj(�) copy(���b�) obj(�) file(����), data(���)
and low recall), their coverage reasonably differed
from each other, which contributed to the improvement
of recall.
To summarize so far, the pattern-based method
we adopted in the experiment generated a substantial
number of predicate pairs with a accuracy
comparative to the state of the art. The accuracy
was, however, further boosted by applying both
instance-based and type-based anchors. This effect
is particularly important because, to our best
knowledge, very few pattern-based relation acquisition
models have been reported to achieve as high
a accuracy as what we achieved. In the case of our
pattern-based model, for reference, the 254 highly
ranked pairs of the 400 samples included only 185
correct pairs, which is worse than the 206 pairs
covered by anchors for both accuracy and recall
(see the “top-N” column under “LSPs” in Table 2.
This difference also leads us to consider incorporating
our anchor-based filtering into the bootstrapping
cycles of pattern-based predicate pair acquisition.
quisition.
4.2.2 Shared
argument identification
We next investigated the accuracy of shared argument
identification. For each of the aforementioned
predicate pairs covered by anchors (the 254
pairs for action-effect and 254 for action-means),
we asked the same two annotators as above to
judge the correctness of the shared argument information.
The results of combination are shown
in Table 3.
“arg-strict” shows the results of the strict judgments
where the shared argument was considered
to be correctly identified only when the most frequent
argument pair was judged correct, while
“arg-lenient” shows the results of the lenient judgments
where the shared argument was considered
to be correctly identified when either of the three
most frequent argument pairs was judged correct.
For judging the correctness of an argument pair,
we had three degrees of strictness. In the most
strict criterion (“anc-strict”), an argument pair was
judged correct only when its maximally three anchor
words were all correct, while in “anc-lenient”,
an argument pair was judged correct when any of
the three most frequent anchor words was correct.
In “anc-any”, an argument pair was judged correct
as far as an annotator could think of any appropriate
anchor word for it. While the inter-annotator
agreement was not very high, with the kappa coefficient
in the “arg-strict” and “anc-any” setting
0.47 for action-effect and 0.42 for action-effect),
one was again consistently more tolerant than the
other. For the same reason as argued in 4.2.1, we
considered an acquired relation correct only if both
annotators judged it correct.
In this experiment, predicate pairs that had been
judged wrong with respect to relation types were
all considered wrong in all the settings. The upper
bounds of accuracy, therefore, are given by those
in Table 2. For “arg-∗” with the “combined” anchors,
for example, the upper bound of accuracy
is 0.81. Since “arg-lenient” with “combined” and
“anc-lenient” achieved 0.76 accuracy, our method
turned out to be reasonably precise in identifying
argument pairs and their fillers. Paying attention
to “arg-strict” and “anc-strict”, on the other hand,
one can see a considerable drop from the lenient
case, which needs to be further investigated.
5 Conclusion
and future work
Motivated by the complementarity between the
pattern-based relation-oriented approach and the
anchor-based argument-oriented approach to event
relation acquisition, we have explored a twophased
approach, which first uses patterns to acquire
predicate pairs and then uses two types of
anchors to identify shared arguments, reporting on
the present results of our empirical evaluation. The
results have shown that (a) the anchor-based filtering
extensively improves the accuracy of predicate
pair acquisition, (b) the instance-based and
type-based anchors are almost equally contributive
and combining them improves recall without los7
7
Table 3: Accuracy of shared argument identification
action-effect action-means
anc-strict anc-lenient anc-any anc-strict anc-lenient anc-any
instance 0.64 0.71 0.71 0.61 0.66 0.66
arg-strict type 0.60 0.63 0.65 0.61 0.65 0.67
combined 0.60 0.65 0.66 0.58 0.62 0.64
instance 0.78 0.80 0.80 0.73 0.75 0.76
arg-lenient type 0.68 0.71 0.72 0.67 0.69 0.71
combined 0.74 0.76 0.77 0.71 0.73 0.74
ing accuracy, and (c) the anchor-based method also
achieves high accuracy in shared argument identification.
fication.
Our future direction will be two-fold. One is
evaluation. Clearly, more comprehensive evaluation
needs to be done. For example, the acquired
relation instances should be evaluated in
some task-oriented manner. The other intriguing
issue is how our anchor-based method for shared
argument identification can benefit from recent advances
in coreference and zero-anaphora resolution
tion (Iida et al., 2006; Komachi et al., 2007, etc.).

