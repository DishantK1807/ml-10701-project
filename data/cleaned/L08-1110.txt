<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>R Brown</author>
<author>D McNeill</author>
</authors>
<title>The tip of the tongue phenomenon. Journal of verbal learning and verbal behaviour</title>
<date>1966</date>
<pages>5--325</pages>
<contexts>
<context>caused by ageing or by various pathologies such as dyslexia. A known effect is the tip of the tongue : a word cannot be directly accessed but it can be recognized when presented into a list of words (Brown and McNeill, 1966). According to current connexionist models of language production (Dell et al., 1999), verbal information is organised in mind into layers of units : semantic features, words and phonemes. We hypothe</context>
</contexts>
<marker>Brown, McNeill, 1966</marker>
<rawString>R. Brown and D. McNeill. 1966. The tip of the tongue phenomenon. Journal of verbal learning and verbal behaviour, 5:325–337.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D M Burke</author>
<author>D G MacKay</author>
<author>J S Worthley</author>
<author>E Wade</author>
</authors>
<title>On the tip of the tongue : what causes word finding failures in young and older adults</title>
<date>1991</date>
<journal>Journal of Memory and Language</journal>
<pages>30--542</pages>
<contexts>
<context>d. It is made of 20 target words (TW) each associated with 5 other words (associations) by 50 users. We assume that words targeted in tip of the tongue phenomenon are low frequency words as shown by (Burke et al., 1991). The target words were selected so that they belong to every evaluated resource. Table 2 contains the 20 chosen target words and their associated english translations and their frequencies in a fren</context>
</contexts>
<marker>Burke, MacKay, Worthley, Wade, 1991</marker>
<rawString>D. M. Burke, D. G. MacKay, J. S. Worthley, and E. Wade. 1991. On the tip of the tongue : what causes word finding failures in young and older adults ? Journal of Memory and Language, 30:542–579.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Church</author>
<author>Patrick Hanks</author>
</authors>
<title>Word association norms, mutual information , and lexicography</title>
<date>1990</date>
<journal>Computational Linguistics</journal>
<volume>16</volume>
<contexts>
<context>s approaches of statistical collocation. A collocation network has been built by computing mutual information of terms in a 20-words window on a corpus made of Le Monde journal extracts according to (Church and Hanks, 1990) approach (coocc). It has been used by (Ferret and Zock, 2006) for similar experiments. We have built another collocation network with Infomap tool applied on Corpatext2 literature corpus (lsa). Info</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Kenneth Church and Patrick Hanks. 1990. Word association norms, mutual information , and lexicography. Computational Linguistics, 16(1):177–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Deerwester</author>
<author>S T Dumais</author>
<author>G W Furnas</author>
<author>T K Landauer</author>
<author>R Harshman</author>
</authors>
<title>Indexing by latent semantic analysis</title>
<date>1990</date>
<journal>Journal of the American Society for Information Science</journal>
<volume>41</volume>
<contexts>
<context>corpus (lsa). Infomap3 uses a vector space model approach on a term-document matrix to provide semantic associations. The vector space model is combined with latent semantic analysis (LSA) principle (Deerwester et al., 1990) in order to reduce the lexical space into a concept space based on word cooccurrences. (Landauer et al., 1998) demonstrates that LSA leads to a good representativity of the mental lexicon. The third</context>
</contexts>
<marker>Deerwester, Dumais, Furnas, Landauer, Harshman, 1990</marker>
<rawString>S. Deerwester, S. T. Dumais, G. W. Furnas, T. K. Landauer, and R. Harshman. 1990. Indexing by latent semantic analysis. Journal of the American Society for Information Science, 41(6):391–407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Dell</author>
<author>F Chang</author>
<author>Z Griffin</author>
</authors>
<title>Connectionist models of language production : lexical access and grammatical encoding. Cognitive Science</title>
<date>1999</date>
<pages>23--517</pages>
<contexts>
<context>he tongue : a word cannot be directly accessed but it can be recognized when presented into a list of words (Brown and McNeill, 1966). According to current connexionist models of language production (Dell et al., 1999), verbal information is organised in mind into layers of units : semantic features, words and phonemes. We hypothesized that existing semantic networks can help to model the mental lexicon when a wid</context>
</contexts>
<marker>Dell, Chang, Griffin, 1999</marker>
<rawString>G. Dell, F. Chang, and Z. Griffin. 1999. Connectionist models of language production : lexical access and grammatical encoding. Cognitive Science, 23:517–542.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olivier Ferret</author>
<author>Michael Zock</author>
</authors>
<title>Enhancing electronic dictionaries with an index based on associations</title>
<date>2006</date>
<booktitle>In Coling/ACL joint conference</booktitle>
<pages>281--288</pages>
<location>Sydney, Australia</location>
<contexts>
<context>has been built by computing mutual information of terms in a 20-words window on a corpus made of Le Monde journal extracts according to (Church and Hanks, 1990) approach (coocc). It has been used by (Ferret and Zock, 2006) for similar experiments. We have built another collocation network with Infomap tool applied on Corpatext2 literature corpus (lsa). Infomap3 uses a vector space model approach on a term-document mat</context>
</contexts>
<marker>Ferret, Zock, 2006</marker>
<rawString>Olivier Ferret and Michael Zock. 2006. Enhancing electronic dictionaries with an index based on associations. In Coling/ACL joint conference, pages 281–288, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hyungsuk Ji</author>
<author>Sabine Ploux</author>
<author>Eric Wehrli</author>
</authors>
<title>Lexical knowledge representation with contextonyms</title>
<date>2003</date>
<booktitle>In MT Summit IX</booktitle>
<location>New Orleans, USA</location>
<contexts>
<context>uld evaluate the efficiency of collocation algorithms when they are based on similar training corpus. The main disadvantage of collocation approaches evaluated here is to discard secondary meanings. (Ji et al., 2003) propose an approach based on contextonyms that distinguishes different senses of a word by creating classes of associated terms. We will experiment such approaches in a future work. Future work will</context>
</contexts>
<marker>Ji, Ploux, Wehrli, 2003</marker>
<rawString>Hyungsuk Ji, Sabine Ploux, and Eric Wehrli. 2003. Lexical knowledge representation with contextonyms. In MT Summit IX, New Orleans, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Landauer</author>
<author>P W Foltz</author>
<author>D Laham</author>
</authors>
<title>Introduction to latent semantic analysis</title>
<date>1998</date>
<booktitle>Discourse Processes</booktitle>
<pages>25--259</pages>
<contexts>
<context>ons. The vector space model is combined with latent semantic analysis (LSA) principle (Deerwester et al., 1990) in order to reduce the lexical space into a concept space based on word cooccurrences. (Landauer et al., 1998) demonstrates that LSA leads to a good representativity of the mental lexicon. The third collocation associations are dynamically extracted for each word by computing the keywords of the 10 first doc</context>
</contexts>
<marker>Landauer, Foltz, Laham, 1998</marker>
<rawString>Thomas Landauer, P. W. Foltz, and D. Laham. 1998. Introduction to latent semantic analysis. Discourse Processes, 25:259–284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veit Reuer</author>
</authors>
<title>Language resources for a network-based dictionary</title>
<date>2004</date>
<booktitle>In Workshop on Enhancing and Using Electronic Dictionaries ; following COLING</booktitle>
<pages>81--84</pages>
<contexts>
<context>o model the mental lexicon when a wide variety of semantic links are employed together. Previous works suggested the use of phonological distance (Zock, 2002) combined with several lexical resources (Reuer, 2004). The aim of the work presented here is to validate this hypothesis in a context more general than the tip of the tongue while focusing on similar situations.We propose a feasibility study of a syste</context>
</contexts>
<marker>Reuer, 2004</marker>
<rawString>Veit Reuer. 2004. Language resources for a network-based dictionary. In Workshop on Enhancing and Using Electronic Dictionaries ; following COLING 2004, pages 81– 84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Snowling</author>
</authors>
<date>2000</date>
<publisher>Dyslexia. Blackwell</publisher>
<contexts>
<context> production. Several cognitive processes and resources drive language production. A lack of phonological awareness may involve a reduction of the connections between phonological and mental lexicons (Snowling, 2000). This can be caused by ageing or by various pathologies such as dyslexia. A known effect is the tip of the tongue : a word cannot be directly accessed but it can be recognized when presented into a </context>
</contexts>
<marker>Snowling, 2000</marker>
<rawString>M. J. Snowling. 2000. Dyslexia. Blackwell.</rawString>
</citation>
</citationList>
</algorithm>

