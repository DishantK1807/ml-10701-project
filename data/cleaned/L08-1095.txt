<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>2007a</author>
</authors>
<title>Apache commons codec</title>
<note>http://commons.apache.org/codec/userguide.html</note>
<marker>2007a, </marker>
<rawString>AA.VV. 2007a. Apache commons codec. http://commons.apache.org/codec/userguide.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>2007b</author>
</authors>
<title>The soundex indexing system</title>
<note>http://www.archives.gov/genealogy/census/soundex.html</note>
<marker>2007b, </marker>
<rawString>AA.VV. 2007b. The soundex indexing system. http://www.archives.gov/genealogy/census/soundex.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>2008a</author>
</authors>
<title>The Project Gutenberg</title>
<note>website. http://www.gutenberg.org</note>
<marker>2008a, </marker>
<rawString>AA.VV. 2008a. The Project Gutenberg website. http://www.gutenberg.org/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>2008b</author>
</authors>
<title>The United States Conference of Catholic Bishops</title>
<note>website. http://www.usccb.org</note>
<marker>2008b, </marker>
<rawString>AA.VV. 2008b. The United States Conference of Catholic Bishops website. http://www.usccb.org/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Berlinsky-Schine</author>
</authors>
<title>Context-based detection of ‘real word’ typographical errors using markov models</title>
<date>2004</date>
<tech>Technical report</tech>
<institution>Cornell University</institution>
<location>Ithaca, NY. http://adam.politikia.com/documents/typofinal.doc</location>
<contexts>
<context>o detect errors by parsing each sentence and checking for grammatical anomalies. More recently, some statistical methods have been tried, including the usage of word n-gram models (Mays et al., 1991; Berlinsky-Schine, 2004; Wilcox-O’Hearn et al., 2008), POS tagging (Marshall, 1983; Garside et al., 1987; Golding and Schabes, 1996), Bayesian classifiers (Gale et al., 1993), decision lists (Yarowsky, 1994), Bayesian hybri</context>
<context>nitial, independent evaluation of that system can be found in (Hirst, 2008). The main problem with word n-grams is data sparseness, even with a fairly large amount of training data. In fact, a study (Berlinsky-Schine, 2004) reported better performance using word bigrams rather than word trigrams, most likely because of the data sparseness problem. POS based methods suffer much less from the sparse data problem, but suc</context>
<context>the various results published in the literature, because of substantial differences in the data sets and evaluation metrics adopted by different researchers. For example, the experiments reported in (Berlinsky-Schine, 2004) scored a maximum of 92% detection hit rate and 30% false positive rate with a word bigrams model; 55% detection hit rate and 18% false positive rate with a word trigrams model. The results published</context>
</contexts>
<marker>Berlinsky-Schine, 2004</marker>
<rawString>Adam Berlinsky-Schine. 2004. Context-based detection of ‘real word’ typographical errors using markov models. Technical report, Cornell University, Ithaca, NY. http://adam.politikia.com/documents/typofinal.doc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Budanitsky</author>
<author>Graeme Hirst</author>
</authors>
<title>Evaluating wordnet-based measures of lexical semantic relatedness</title>
<date>2006</date>
<journal>Computational Linguistics</journal>
<volume>32</volume>
<contexts>
<context>methods (Golding and Schabes, 1996), and Latent Semantic Analysis (Jones and Martin, 1997). Methods that exploit semantic similarity between words have also been proposed (Hirst and Budanitsky, 2005; Budanitsky and Hirst, 2006). The spell checker of the recently released Microsoft Word 2007 is able to detect and correct some real-word mistakes (Microsoft Corporation, 2006). The proprietary, closedsourcenatureofthissoftware</context>
<context>red a maximum of 92% detection hit rate and 30% false positive rate with a word bigrams model; 55% detection hit rate and 18% false positive rate with a word trigrams model. The results published in (Budanitsky and Hirst, 2006) report a maximum f-score of 0.14 for what the authors call “suspicion,” and a maximum f-score of 0.25 for what they call “detection.” 6. Conclusions and future work This work showed that a more empi</context>
</contexts>
<marker>Budanitsky, Hirst, 2006</marker>
<rawString>Alexander Budanitsky and Graeme Hirst. 2006. Evaluating wordnet-based measures of lexical semantic relatedness. Computational Linguistics, 32(1):13–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew J Carlson</author>
<author>Jeffrey Rosen</author>
<author>Dan Roth</author>
</authors>
<title>Scaling up context-sensitive text correction</title>
<date>2001</date>
<booktitle>In AAAI</booktitle>
<pages>45--50</pages>
<contexts>
<context>ing and Schabes, 1996). A significant issue with many proposed systems is coverage. For example, the sophisticated machine learning method proposed in (Golding and Roth, 1996; Golding and Roth, 1999; Carlson et al., 2001) has been “scaled up” to cover approximately 500 words in the latter work. Although this is a significant improvement over the 20-40 words covered by previous research, the method is still far from c</context>
</contexts>
<marker>Carlson, Rosen, Roth, 2001</marker>
<rawString>Andrew J. Carlson, Jeffrey Rosen, and Dan Roth. 2001. Scaling up context-sensitive text correction. In AAAI, pages 45–50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Davide Fossati</author>
<author>Barbara Di Eugenio</author>
</authors>
<title>A mixed trigrams approach for context sensitive spell checking</title>
<date>2007</date>
<marker>Fossati, Di Eugenio, 2007</marker>
<rawString>Davide Fossati and Barbara Di Eugenio. 2007. A mixed trigrams approach for context sensitive spell checking.</rawString>
</citation>
<citation valid="true">
<date></date>
<booktitle>In CICLing-2007, Eighth International Conference on Intelligent Text Processing and Computational Linguistics</booktitle>
<location>Mexico City, Mexico</location>
<marker></marker>
<rawString>In CICLing-2007, Eighth International Conference on Intelligent Text Processing and Computational Linguistics, Mexico City, Mexico, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Gale</author>
<author>Kenneth W Church</author>
<author>David Yarowsky</author>
</authors>
<title>A method for disambiguating word senses in a large corpus. Computers and the Humanities</title>
<date>1993</date>
<pages>26--415</pages>
<contexts>
<context>ge of word n-gram models (Mays et al., 1991; Berlinsky-Schine, 2004; Wilcox-O’Hearn et al., 2008), POS tagging (Marshall, 1983; Garside et al., 1987; Golding and Schabes, 1996), Bayesian classifiers (Gale et al., 1993), decision lists (Yarowsky, 1994), Bayesian hybrid methods (Golding, 1995), a combination of POS and Bayesian methods (Golding and Schabes, 1996), and Latent Semantic Analysis (Jones and Martin, 1997</context>
</contexts>
<marker>Gale, Church, Yarowsky, 1993</marker>
<rawString>William A. Gale, Kenneth W. Church, and David Yarowsky. 1993. A method for disambiguating word senses in a large corpus. Computers and the Humanities, 26:415–439. Roger Garside, Geoffrey Leech, and Geoffrey Sampson.</rawString>
</citation>
<citation valid="true">
<title>The Computational Analysis of English: a corpusbased approach</title>
<date>1987</date>
<publisher>Longman</publisher>
<marker>1987</marker>
<rawString>1987. The Computational Analysis of English: a corpusbased approach. Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Golding</author>
<author>Dan Roth</author>
</authors>
<title>Applying winnow to context-sensitive spelling correction</title>
<date>1996</date>
<booktitle>In International Conference on Machine Learning</booktitle>
<pages>182--190</pages>
<contexts>
<context>give better results when combined together (Golding and Schabes, 1996). A significant issue with many proposed systems is coverage. For example, the sophisticated machine learning method proposed in (Golding and Roth, 1996; Golding and Roth, 1999; Carlson et al., 2001) has been “scaled up” to cover approximately 500 words in the latter work. Although this is a significant improvement over the 20-40 words covered by pre</context>
</contexts>
<marker>Golding, Roth, 1996</marker>
<rawString>Andrew Golding and Dan Roth. 1996. Applying winnow to context-sensitive spelling correction. In International Conference on Machine Learning, pages 182–190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>AndrewGoldingandDanRoth</author>
</authors>
<title>Awinnowbasedapproach to context-sensitive spelling correction</title>
<date>1999</date>
<booktitle>Machine Learning, 34(1-3):107–130. Special Issue on Machine Learning and Natural Language</booktitle>
<marker>AndrewGoldingandDanRoth, 1999</marker>
<rawString>AndrewGoldingandDanRoth. 1999. Awinnowbasedapproach to context-sensitive spelling correction. Machine Learning, 34(1-3):107–130. Special Issue on Machine Learning and Natural Language.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Golding</author>
<author>Yves Schabes</author>
</authors>
<title>Combining trigram-based and feature-based methods for contextsensitive spelling correction</title>
<date>1996</date>
<booktitle>In 34th Annual Meeting of the Association for Computational Linguistics</booktitle>
<contexts>
<context>istical methods have been tried, including the usage of word n-gram models (Mays et al., 1991; Berlinsky-Schine, 2004; Wilcox-O’Hearn et al., 2008), POS tagging (Marshall, 1983; Garside et al., 1987; Golding and Schabes, 1996), Bayesian classifiers (Gale et al., 1993), decision lists (Yarowsky, 1994), Bayesian hybrid methods (Golding, 1995), a combination of POS and Bayesian methods (Golding and Schabes, 1996), and Latent</context>
<context>same part of speech. Bayesian methods, on the other hand, are better able to detect these cases, but have worse general performance. These last two methods give better results when combined together (Golding and Schabes, 1996). A significant issue with many proposed systems is coverage. For example, the sophisticated machine learning method proposed in (Golding and Roth, 1996; Golding and Roth, 1999; Carlson et al., 2001)</context>
</contexts>
<marker>Golding, Schabes, 1996</marker>
<rawString>Andrew Golding and Yves Schabes. 1996. Combining trigram-based and feature-based methods for contextsensitive spelling correction. In 34th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Golding</author>
</authors>
<title>A bayesian hybrid method for context-sensitive spelling correction</title>
<date>1995</date>
<booktitle>In The Third Workshop on Very Large Corpora</booktitle>
<pages>39--53</pages>
<contexts>
<context>Hearn et al., 2008), POS tagging (Marshall, 1983; Garside et al., 1987; Golding and Schabes, 1996), Bayesian classifiers (Gale et al., 1993), decision lists (Yarowsky, 1994), Bayesian hybrid methods (Golding, 1995), a combination of POS and Bayesian methods (Golding and Schabes, 1996), and Latent Semantic Analysis (Jones and Martin, 1997). Methods that exploit semantic similarity between words have also been p</context>
</contexts>
<marker>Golding, 1995</marker>
<rawString>Andrew Golding. 1995. A bayesian hybrid method for context-sensitive spelling correction. In The Third Workshop on Very Large Corpora, pages 39–53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G E Heidorn</author>
<author>K Jensen</author>
<author>L A Miller</author>
<author>R J Byrd</author>
<author>M S Chodorow</author>
</authors>
<title>The EPISTLE text-critiquing system</title>
<date>1986</date>
<journal>IBM Systems Journal</journal>
<volume>21</volume>
<contexts>
<context>pressive, providing further motivation for new research on spell checkers. Different approaches to tackle the issue of real-word spell checking have been tried in the literature. Symbolic approaches (Heidorn et al., 1986) try to detect errors by parsing each sentence and checking for grammatical anomalies. More recently, some statistical methods have been tried, including the usage of word n-gram models (Mays et al.,</context>
</contexts>
<marker>Heidorn, Jensen, Miller, Byrd, Chodorow, 1986</marker>
<rawString>G. E. Heidorn, K. Jensen, L. A. Miller, R. J Byrd, and M. S. Chodorow. 1986. The EPISTLE text-critiquing system. IBM Systems Journal, 21(3):305–326.</rawString>
</citation>
<citation valid="true">
<authors>
<author>GraemeHirstandAlexanderBudanitsky</author>
</authors>
<title>Correcting real-word spelling errors by restoring lexical cohesion</title>
<date>2005</date>
<journal>Natural Language Engineering</journal>
<pages>11--87</pages>
<marker>GraemeHirstandAlexanderBudanitsky, 2005</marker>
<rawString>GraemeHirstandAlexanderBudanitsky. 2005. Correcting real-word spelling errors by restoring lexical cohesion. Natural Language Engineering, 11:87–111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graeme Hirst</author>
</authors>
<title>An evaluation of the contextual spelling checker of microsoft office word</title>
<date>2008</date>
<contexts>
<context> Corporation, 2006). The proprietary, closedsourcenatureofthissoftwaremakesitdifficulttoassessthe technology and methods used in it. An initial, independent evaluation of that system can be found in (Hirst, 2008). The main problem with word n-grams is data sparseness, even with a fairly large amount of training data. In fact, a study (Berlinsky-Schine, 2004) reported better performance using word bigrams rat</context>
</contexts>
<marker>Hirst, 2008</marker>
<rawString>Graeme Hirst. 2008. An evaluation of the contextual spelling checker of microsoft office word 2007, January. http://ftp.cs.toronto.edu/pub/gh/Hirst-2008-Word.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael P Jones</author>
<author>James H Martin</author>
</authors>
<title>Contextualspellingcorrectionusinglatentsemanticanalysis</title>
<date>1997</date>
<booktitle>In Fifth Conference on Applied Natural Language Processing</booktitle>
<contexts>
<context>ers (Gale et al., 1993), decision lists (Yarowsky, 1994), Bayesian hybrid methods (Golding, 1995), a combination of POS and Bayesian methods (Golding and Schabes, 1996), and Latent Semantic Analysis (Jones and Martin, 1997). Methods that exploit semantic similarity between words have also been proposed (Hirst and Budanitsky, 2005; Budanitsky and Hirst, 2006). The spell checker of the recently released Microsoft Word 20</context>
</contexts>
<marker>Jones, Martin, 1997</marker>
<rawString>Michael P. Jones and James H. Martin. 1997. Contextualspellingcorrectionusinglatentsemanticanalysis. In Fifth Conference on Applied Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karen Kukich</author>
</authors>
<title>Techniques for automatically correcting words in text</title>
<date>1992</date>
<journal>ACM Computing Surveys</journal>
<volume>24</volume>
<contexts>
<context>ors occur often in practice. Indeed, empirical studies have estimated that errors resulting in valid words account from 25% to more than 50% of the errors, depending on the application (Mitton, 1987; Kukich, 1992). Thus, it appears that this challenging problem has not received the attention it deserves. Recently, extensive work has been done on the characterization of spelling mistakes in web documents (Ring</context>
</contexts>
<marker>Kukich, 1992</marker>
<rawString>Karen Kukich. 1992. Techniques for automatically correcting words in text. ACM Computing Surveys, 24(4):377–439.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of english: The penn treebank</title>
<date>1993</date>
<journal>Computational Linguistics</journal>
<volume>19</volume>
<contexts>
<context>raining data: a collection of misspelled pairs, already described in section 2.1, and a corpus of correct sentences annotated for parts of speech. In our previous work, we used the WSJ Penn Treebank (Marcus et al., 1993) to train the mixed trigram model. Experiments with three different sizes of the training data showed that the accuracy of the model’s predictions did not increase significantly using more training d</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of english: The penn treebank. Computational Linguistics, 19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian Marshall</author>
</authors>
<title>Choice of grammatical word-class without global syntactic analysis: tagging words in the LOB corpus. Computers and the Humanities</title>
<date>1983</date>
<pages>17--139</pages>
<contexts>
<context>al anomalies. More recently, some statistical methods have been tried, including the usage of word n-gram models (Mays et al., 1991; Berlinsky-Schine, 2004; Wilcox-O’Hearn et al., 2008), POS tagging (Marshall, 1983; Garside et al., 1987; Golding and Schabes, 1996), Bayesian classifiers (Gale et al., 1993), decision lists (Yarowsky, 1994), Bayesian hybrid methods (Golding, 1995), a combination of POS and Bayesia</context>
</contexts>
<marker>Marshall, 1983</marker>
<rawString>Ian Marshall. 1983. Choice of grammatical word-class without global syntactic analysis: tagging words in the LOB corpus. Computers and the Humanities, 17:139– 150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Mays</author>
<author>Fred J Damerau</author>
<author>Robert L Mercer</author>
</authors>
<title>Context based spelling correction</title>
<date>1991</date>
<booktitle>Information Processing and Management</booktitle>
<pages>27--5</pages>
<contexts>
<context>et al., 1986) try to detect errors by parsing each sentence and checking for grammatical anomalies. More recently, some statistical methods have been tried, including the usage of word n-gram models (Mays et al., 1991; Berlinsky-Schine, 2004; Wilcox-O’Hearn et al., 2008), POS tagging (Marshall, 1983; Garside et al., 1987; Golding and Schabes, 1996), Bayesian classifiers (Gale et al., 1993), decision lists (Yarowsk</context>
</contexts>
<marker>Mays, Damerau, Mercer, 1991</marker>
<rawString>Eric Mays, Fred J. Damerau, and Robert L. Mercer. 1991. Context based spelling correction. Information Processing and Management, 27(5):517–522.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Microsoft Corporation</author>
</authors>
<title>Microsoft office word 2007 product guide</title>
<date>2006</date>
<note>http://office.microsoft.com/enus/word/HA101680221033.aspx</note>
<contexts>
<context>been proposed (Hirst and Budanitsky, 2005; Budanitsky and Hirst, 2006). The spell checker of the recently released Microsoft Word 2007 is able to detect and correct some real-word mistakes (Microsoft Corporation, 2006). The proprietary, closedsourcenatureofthissoftwaremakesitdifficulttoassessthe technology and methods used in it. An initial, independent evaluation of that system can be found in (Hirst, 2008). The </context>
</contexts>
<marker>Corporation, 2006</marker>
<rawString>Microsoft Corporation. 2006. Microsoft office word 2007 product guide. http://office.microsoft.com/enus/word/HA101680221033.aspx.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Mitton</author>
</authors>
<title>A collection of computer-readable corpora of English spelling errors</title>
<date>1986</date>
<booktitle>Available online at the Oxford Text Archive website</booktitle>
<tech>Technical report</tech>
<location>Birkbeck College, London, UK</location>
<contexts>
<context>bability P(wk|ek) on a more empirically grounded basis. Unfortunately, lexical resources that can be used for such estimation are scarce. One of these resources is the Birkbeck spelling error corpus (Mitton, 1986), a collection of corpora of English spelling mistakes. Unfortunately, it is not possible to use this corpus to make direct estimations of misspelling frequencies, because frequency information is av</context>
</contexts>
<marker>Mitton, 1986</marker>
<rawString>Roger Mitton. 1986. A collection of computer-readable corpora of English spelling errors. Technical report, Birkbeck College, London, UK. Available online at the Oxford Text Archive website.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Mitton</author>
</authors>
<title>Spelling checkers, spelling correctors and the misspellings of poor spellers. Information processing and management</title>
<date>1987</date>
<pages>23--5</pages>
<contexts>
<context>r if these errors occur often in practice. Indeed, empirical studies have estimated that errors resulting in valid words account from 25% to more than 50% of the errors, depending on the application (Mitton, 1987; Kukich, 1992). Thus, it appears that this challenging problem has not received the attention it deserves. Recently, extensive work has been done on the characterization of spelling mistakes in web d</context>
</contexts>
<marker>Mitton, 1987</marker>
<rawString>Roger Mitton. 1987. Spelling checkers, spelling correctors and the misspellings of poor spellers. Information processing and management, 23(5):495–505.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Phillips</author>
</authors>
<title>The double metaphone search algorithm</title>
<date>2000</date>
<journal>C/C++ Users Journal</journal>
<contexts>
<context>veral algorithms that can convert a string of characters into an approximate phonetic representation. Three of them are soundex (AA.VV., 2007b), refined soundex (AA.VV., 2007a), and double metaphone (Phillips, 2000). Double metaphone looks like the most interesting one for two reasons: first, it isthemostrecentone,andithasbeendesignedtoovercome some of the limitations of the previous ones. Second, the correlati</context>
</contexts>
<marker>Phillips, 2000</marker>
<rawString>Lawrence Phillips. 2000. The double metaphone search algorithm. C/C++ Users Journal, June. http://www.ddj.com/cpp/184401251.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christoph Ringlstetter</author>
<author>Klaus U Schulz</author>
<author>Stoyan Mihov</author>
</authors>
<title>Orthographic errors in web pages: Toward cleaner web corpora</title>
<date>2006</date>
<journal>Computational Linguistics</journal>
<volume>32</volume>
<contexts>
<context>1992). Thus, it appears that this challenging problem has not received the attention it deserves. Recently, extensive work has been done on the characterization of spelling mistakes in web documents (Ringlstetter et al., 2006). This work shows that the amount of spelling mistakes in the web is impressive, providing further motivation for new research on spell checkers. Different approaches to tackle the issue of real-word</context>
</contexts>
<marker>Ringlstetter, Schulz, Mihov, 2006</marker>
<rawString>Christoph Ringlstetter, Klaus U. Schulz, and Stoyan Mihov. 2006. Orthographic errors in web pages: Toward cleaner web corpora. Computational Linguistics, 32(3):295–340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiang Tong</author>
<author>David A Evans</author>
</authors>
<title>A statistical approach to automatic ocr error correction in context</title>
<date>1996</date>
<booktitle>In Fourth Workshop on Very Large Corpora</booktitle>
<contexts>
<context>sticalcontextual spell checking has been studied is Optical Character Recognition (OCR). For this application, Markov Models approaches based on letter n-grams have been shown to be quite successful (Tong and Evans, 1996). To tackle the problem of data sparseness of word trigrams models, and overcome the lack of information provided by POS trigrams models, a mixed trigram model has been proposed (Fossati and Di Eugen</context>
</contexts>
<marker>Tong, Evans, 1996</marker>
<rawString>Xiang Tong and David A. Evans. 1996. A statistical approach to automatic ocr error correction in context. In Fourth Workshop on Very Large Corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Dan Klein</author>
<author>Christopher Manning</author>
<author>Yoram Singer</author>
</authors>
<title>Feature-rich part-of-speech tagging with a cyclic dependency network</title>
<date>2003</date>
<booktitle>In HLT-NAACL</booktitle>
<pages>252--259</pages>
<contexts>
<context>ot increase significantly using more training data, but the overall coverage of the model was larger. Thus, in addition to the WSJ Penn Treebank, thecurrentversionofthesystemusestheStanfordPOStagger (Toutanova et al., 2003) to automatically tag plain text and use it as additional training data. The idea is that, under the assumption that the accuracy of the system does not decrease too much because of the mistakes of t</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Kristina Toutanova, Dan Klein, Christopher Manning, and Yoram Singer. 2003. Feature-rich part-of-speech tagging with a cyclic dependency network. In HLT-NAACL 2003, pages 252–259.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Amber Wilcox-O’Hearn</author>
<author>Graeme Hirst</author>
<author>Alexander Budanitsky</author>
</authors>
<title>Real-word spelling correction with trigrams: A reconsideration of the Mays, Damerau, and Mercer model</title>
<date>2008</date>
<booktitle>In CICLing-2008, 9th International Conference on Intelligent Text Processing and Computational Linguistics</booktitle>
<pages>605--616</pages>
<location>Haifa, Israel</location>
<marker>Wilcox-O’Hearn, Hirst, Budanitsky, 2008</marker>
<rawString>L. Amber Wilcox-O’Hearn, Graeme Hirst, and Alexander Budanitsky. 2008. Real-word spelling correction with trigrams: A reconsideration of the Mays, Damerau, and Mercer model. In CICLing-2008, 9th International Conference on Intelligent Text Processing and Computational Linguistics, pages 605–616, Haifa, Israel.</rawString>
</citation>
</citationList>
</algorithm>

