<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>A Andreevskaia</author>
<author>S Bergler</author>
</authors>
<title>Semantic Tag Extraction from WordNet Glosses</title>
<date>2006</date>
<booktitle>In Proceedings of LREC-2006</booktitle>
<contexts>
<context> text and classifying phrases, sentences, or documents as objective, positive, or negative (Hatzivassiloglou and McKeown, 1997; Riloff and Wiebe, 2003; Pang and Lee, 2004; Esuli and Sebastiani, 2006; Andreevskaia and Bergler, 2006; Takamura et al., 2007). Other efforts focus on applications like movie and product review mining (e.g. Turney, 2002; Hu &amp; Liu, 2004). Here we want to contribute towards progress on the subtasks of r</context>
</contexts>
<marker>Andreevskaia, Bergler, 2006</marker>
<rawString>A. Andreevskaia and S. Bergler. 2006. Semantic Tag Extraction from WordNet Glosses. In Proceedings of LREC-2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Baker</author>
<author>C Fillmore</author>
<author>J Lowe</author>
</authors>
<title>The Berkeley FrameNet Project</title>
<date>1998</date>
<booktitle>In Proceedings of the 17th international conference on Computational linguistics</booktitle>
<contexts>
<context>ar syntactic frame, maps to the verb’s Arg0 and the target to its Arg1. For please in (9), source and target correspond to Arg1 and Arg0, respectively. Comparable mappings are available for FrameNet (Baker et al., 1998). The source of fear maps to the Experiencer frame element, and the target to the Content frame element. For please, the source maps to the Experiencer frame element and the target to the Stimulus fr</context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>C. Baker, C. Fillmore, and J. Lowe. 1998. The Berkeley FrameNet Project. In Proceedings of the 17th international conference on Computational linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bethard</author>
<author>H Yu</author>
<author>A Thornton</author>
<author>V Hatzivassiloglou</author>
<author>D Jurafsky</author>
</authors>
<title>Automatic Extraction of Opinion Propositions and their Holders</title>
<date>2004</date>
<booktitle>In Proceedings of AAAI Spring Symposium on Exploring Attitude and Affect in Text: Theories and Applications</booktitle>
<marker>Bethard, Yu, Thornton, Hatzivassiloglou, Jurafsky, 2004</marker>
<rawString>S. Bethard, H. Yu, A. Thornton, V. Hatzivassiloglou, and D. Jurafsky. 2004. Automatic Extraction of Opinion Propositions and their Holders. In Proceedings of AAAI Spring Symposium on Exploring Attitude and Affect in Text: Theories and Applications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Bloom</author>
<author>N Garg</author>
<author>S Argamon</author>
</authors>
<title>Extracting Appraisal Expressions</title>
<date>2007</date>
<booktitle>In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference</booktitle>
<contexts>
<context>alue of role labeling for target recognition. Other research tackles source and target recognition as part of building complete review mining systems (Popescu and Etzioni, 2005; Yi and Niblack, 2005; Bloom et al., 2007). Yi &amp; Niblack’s sentiment pattern database and Bloom et al.’s linkage specifications provide mappings of argument to opinion roles similar to the mappings in Kim &amp; Hovy’s work. However, when linking</context>
</contexts>
<marker>Bloom, Garg, Argamon, 2007</marker>
<rawString>K. Bloom, N. Garg, and S. Argamon. 2007. Extracting Appraisal Expressions. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Choi</author>
<author>E Breck</author>
<author>C Cardie</author>
</authors>
<title>Joint Extraction of Entities and Relations for Opinion Recognition</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing</booktitle>
<marker>Choi, Breck, Cardie, 2006</marker>
<rawString>Y. Choi, E. Breck, and C. Cardie. 2006. Joint Extraction of Entities and Relations for Opinion Recognition. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Esuli</author>
<author>F Sebastiani</author>
</authors>
<title>Determining Term Subjectivity and Term Orientation for Opinion Mining</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Lingusitics (EACL</booktitle>
<contexts>
<context>ognizing such expressions in text and classifying phrases, sentences, or documents as objective, positive, or negative (Hatzivassiloglou and McKeown, 1997; Riloff and Wiebe, 2003; Pang and Lee, 2004; Esuli and Sebastiani, 2006; Andreevskaia and Bergler, 2006; Takamura et al., 2007). Other efforts focus on applications like movie and product review mining (e.g. Turney, 2002; Hu &amp; Liu, 2004). Here we want to contribute towar</context>
</contexts>
<marker>Esuli, Sebastiani, 2006</marker>
<rawString>A. Esuli and F. Sebastiani. 2006. Determining Term Subjectivity and Term Orientation for Opinion Mining. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Lingusitics (EACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Hatzivassiloglou</author>
<author>K McKeown</author>
</authors>
<title>Predicting the Semantic Orientation of Adjectives</title>
<date>1997</date>
<booktitle>In Proceedings of the Thirty-Fifth Annual Meeting of the Association for Computational Linguistics and Eighth Conference of the European Chapter of the Association for Computational Linguistics</booktitle>
<contexts>
<context> research area encompassing work on acquiring lexica of opinion expressions, recognizing such expressions in text and classifying phrases, sentences, or documents as objective, positive, or negative (Hatzivassiloglou and McKeown, 1997; Riloff and Wiebe, 2003; Pang and Lee, 2004; Esuli and Sebastiani, 2006; Andreevskaia and Bergler, 2006; Takamura et al., 2007). Other efforts focus on applications like movie and product review mini</context>
</contexts>
<marker>Hatzivassiloglou, McKeown, 1997</marker>
<rawString>V. Hatzivassiloglou and K. McKeown. 1997. Predicting the Semantic Orientation of Adjectives. In Proceedings of the Thirty-Fifth Annual Meeting of the Association for Computational Linguistics and Eighth Conference of the European Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hu</author>
<author>B Liu</author>
</authors>
<title>Mining Opinion Features in Customer Reviews</title>
<date>2004</date>
<booktitle>In Proceedings of the Nineteeth National Conference on Artificial Intellgience (AAAI-2004</booktitle>
<contexts>
<context>3; Pang and Lee, 2004; Esuli and Sebastiani, 2006; Andreevskaia and Bergler, 2006; Takamura et al., 2007). Other efforts focus on applications like movie and product review mining (e.g. Turney, 2002; Hu &amp; Liu, 2004). Here we want to contribute towards progress on the subtasks of recognizing opinion sources (holders) and targets (topics). As research turns to new genres, these tasks become more important. For in</context>
<context>ocal and global targets given that reviews focus on one product and its features, and given that sets of reviews can be used to identify via statistical analysis what the important features are (e.g. Hu &amp; Liu, 2004) . In other genres such as movie reviews and task-oriented meetings, the distinction is harder to make. In movie reviews, evaluations and arguments inside the world of the movie have to be distinguis</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>M. Hu and B. Liu. 2004. Mining Opinion Features in Customer Reviews. In Proceedings of the Nineteeth National Conference on Artificial Intellgience (AAAI-2004).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kim</author>
<author>E Hovy</author>
</authors>
<title>Extracting Opinions, Opinion Holders, and Topics Expressed in Online News Media Text</title>
<date>2006</date>
<booktitle>In ACL Workshop on Sentiment and Subjectivity in Text</booktitle>
<marker>Kim, Hovy, 2006</marker>
<rawString>S. Kim and E. Hovy. 2006. Extracting Opinions, Opinion Holders, and Topics Expressed in Online News Media Text. In ACL Workshop on Sentiment and Subjectivity in Text.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Lambrecht</author>
</authors>
<title>Information structure and sentence form</title>
<date>1994</date>
<publisher>Cambridge University Press</publisher>
<location>New York, N.Y</location>
<contexts>
<context> liable to receive blame or credit for events. A second factor that appears relevant is information structure. Referents that are prominent as pragmatic foci or topics (in the pragmatic sense of e.g. Lambrecht, 1994) are easy to perceive as targets. For instance, if in a discourse an open proposition is set up where only the filler of one particular semantic role is contested, then the candidate entities strongl</context>
</contexts>
<marker>Lambrecht, 1994</marker>
<rawString>K. Lambrecht. 1994. Information structure and sentence form. Cambridge University Press, New York, N.Y.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
<author>P Kingsbury</author>
<author>D Gildea</author>
</authors>
<title>The Proposition Bank: An Annotated Corpus of Semantic Roles</title>
<date>2005</date>
<journal>Computational Linguistics</journal>
<volume>31</volume>
<contexts>
<context>e verbs fear and please in (8) and (9). (8) WE fear [an early death] much more. (9) [This] pleased THE MAINLY FEMALE AUDIENCE. These verbs realize source and target differently. Relative to PropBank (Palmer et al., 2005), the source for fear, in that particular syntactic frame, maps to the verb’s Arg0 and the target to its Arg1. For please in (9), source and target correspond to Arg1 and Arg0, respectively. Comparab</context>
</contexts>
<marker>Palmer, Kingsbury, Gildea, 2005</marker>
<rawString>M. Palmer, P. Kingsbury, and D. Gildea. 2005. The Proposition Bank: An Annotated Corpus of Semantic Roles. Computational Linguistics, 31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
</authors>
<title>A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts</title>
<date>2004</date>
<booktitle>In Proceedings of the ACL 2004</booktitle>
<location>Barcelona, Spain, Main Volume</location>
<contexts>
<context>ion expressions, recognizing such expressions in text and classifying phrases, sentences, or documents as objective, positive, or negative (Hatzivassiloglou and McKeown, 1997; Riloff and Wiebe, 2003; Pang and Lee, 2004; Esuli and Sebastiani, 2006; Andreevskaia and Bergler, 2006; Takamura et al., 2007). Other efforts focus on applications like movie and product review mining (e.g. Turney, 2002; Hu &amp; Liu, 2004). Here</context>
</contexts>
<marker>Pang, Lee, 2004</marker>
<rawString>B. Pang and L. Lee. 2004. A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts. In Proceedings of the ACL 2004, Barcelona, Spain, Main Volume.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Popescu</author>
<author>O Etzioni</author>
</authors>
<title>Extracting Product Features and Opinions from Reviews</title>
<date>2005</date>
<booktitle>In HLT/EMNLP</booktitle>
<contexts>
<context>i et al. for sources and newly demonstrates the value of role labeling for target recognition. Other research tackles source and target recognition as part of building complete review mining systems (Popescu and Etzioni, 2005; Yi and Niblack, 2005; Bloom et al., 2007). Yi &amp; Niblack’s sentiment pattern database and Bloom et al.’s linkage specifications provide mappings of argument to opinion roles similar to the mappings i</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>A. Popescu and O. Etzioni. 2005. Extracting Product Features and Opinions from Reviews. In HLT/EMNLP 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Prasad</author>
<author>N Dinesh</author>
<author>A Lee</author>
<author>A Joshi</author>
<author>B Webber</author>
</authors>
<title>Annotating Attribution in the Penn Discourse TreeBank</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL Workshop on Sentiment and Subjectivity in Text</booktitle>
<contexts>
<context> (cf. 4). However, identifying the right source in the presence of multiple possible sources in the text can be difficult. A valuable resource for studying attribution is the Penn Discourse Treebank (Prasad et al., 2006). Its annotations show that attribution is realized in many different ways and that parts of the same sentence may be attributed to different sources. We now consider some specific cases in which the</context>
</contexts>
<marker>Prasad, Dinesh, Lee, Joshi, Webber, 2006</marker>
<rawString>R. Prasad, N. Dinesh, A. Lee, A. Joshi, and B. Webber. 2006. Annotating Attribution in the Penn Discourse TreeBank. In Proceedings of the COLING/ACL Workshop on Sentiment and Subjectivity in Text.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W V Quine</author>
</authors>
<title>Quantifiers and propositional attitudes</title>
<date>1956</date>
<journal>Journal of Philosophy</journal>
<volume>53</volume>
<marker>Quine, 1956</marker>
<rawString>W.V. Quine. 1956. Quantifiers and propositional attitudes. Journal of Philosophy, 53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Quirk</author>
<author>S Greenbaum</author>
<author>G Leech</author>
<author>J Svartvik</author>
</authors>
<title>A Comprehensive Grammar of the English Language</title>
<date>1985</date>
<publisher>Longman</publisher>
<location>New York</location>
<marker>Quirk, Greenbaum, Leech, Svartvik, 1985</marker>
<rawString>R. Quirk, S. Greenbaum, G. Leech, and J. Svartvik. 1985. A Comprehensive Grammar of the English Language. Longman, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Riloff</author>
<author>J Wiebe</author>
</authors>
<title>Learning Extraction Patterns for Subjective Expressions</title>
<date>2003</date>
<booktitle>In EMNLP</booktitle>
<contexts>
<context>acquiring lexica of opinion expressions, recognizing such expressions in text and classifying phrases, sentences, or documents as objective, positive, or negative (Hatzivassiloglou and McKeown, 1997; Riloff and Wiebe, 2003; Pang and Lee, 2004; Esuli and Sebastiani, 2006; Andreevskaia and Bergler, 2006; Takamura et al., 2007). Other efforts focus on applications like movie and product review mining (e.g. Turney, 2002; H</context>
</contexts>
<marker>Riloff, Wiebe, 2003</marker>
<rawString>E. Riloff and J. Wiebe. 2003. Learning Extraction Patterns for Subjective Expressions. In EMNLP 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Takamura</author>
<author>T Inui</author>
<author>M Okumura</author>
</authors>
<title>Extracting Semantic Orientations of Phrases from Dictionary</title>
<date>2007</date>
<contexts>
<context>entences, or documents as objective, positive, or negative (Hatzivassiloglou and McKeown, 1997; Riloff and Wiebe, 2003; Pang and Lee, 2004; Esuli and Sebastiani, 2006; Andreevskaia and Bergler, 2006; Takamura et al., 2007). Other efforts focus on applications like movie and product review mining (e.g. Turney, 2002; Hu &amp; Liu, 2004). Here we want to contribute towards progress on the subtasks of recognizing opinion sour</context>
</contexts>
<marker>Takamura, Inui, Okumura, 2007</marker>
<rawString>H. Takamura, T. Inui, and M. Okumura. 2007. Extracting Semantic Orientations of Phrases from Dictionary.</rawString>
</citation>
<citation valid="true">
<date>2007</date>
<booktitle>In Proceedings of NAACL/HLT</booktitle>
<contexts>
<context>nation-activities that do not relate to the the task at hand. One possible approach to the problem of distinguishing but relating local and global targets correctly is to use taxonomies. Bloom et al. (2007) use hand-built domaindependent taxonomies for movie and product reviews. They point out, however, that the precision of the target classification is the area of most concern to them. A second challen</context>
</contexts>
<marker>2007</marker>
<rawString>In Proceedings of NAACL/HLT 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Turney</author>
</authors>
<title>Thumbs up or thumbs down? Semantic orientation applied to unsupervised lassification of reviews</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</booktitle>
<pages>417--424</pages>
<location>Philadelphia, Pennsylvania</location>
<contexts>
<context>and Wiebe, 2003; Pang and Lee, 2004; Esuli and Sebastiani, 2006; Andreevskaia and Bergler, 2006; Takamura et al., 2007). Other efforts focus on applications like movie and product review mining (e.g. Turney, 2002; Hu &amp; Liu, 2004). Here we want to contribute towards progress on the subtasks of recognizing opinion sources (holders) and targets (topics). As research turns to new genres, these tasks become more i</context>
<context> and arguments inside the world of the movie have to be distinguished from those that are about the movie and they do not combine: an evil character may make for a positive movie watching experience (Turney, 2002). In meetings, agenda items are not always neatly separated and even if they are, speakers may still engage in side conversations, jokes, or coordination-activities that do not relate to the the task</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>P. Turney. 2002. Thumbs up or thumbs down? Semantic orientation applied to unsupervised lassification of reviews. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 417– 424, Philadelphia, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Wiebe</author>
<author>T Wilson</author>
<author>C Cardie</author>
</authors>
<date>2005</date>
<booktitle>Annotating Expressions of Opinions and Emotions in Language. Language Resources and Evaluation</booktitle>
<volume>39</volume>
<contexts>
<context>the opinion roles. In section 6, we situate our work in the research context. We present ideas for further research in section 7 and conclude in section 8. 2. Annotation scheme The basic MPQA scheme (Wiebe et al., 2005) concerns words and phrases that are used in particular contexts to express private states such as emotions, evaluations, speculations, etc. Following Quirk et al. (1985), private states are defined </context>
</contexts>
<marker>Wiebe, Wilson, Cardie, 2005</marker>
<rawString>J. Wiebe, T. Wilson, and C. Cardie. 2005. Annotating Expressions of Opinions and Emotions in Language. Language Resources and Evaluation, 39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Wilson</author>
<author>J Wiebe</author>
</authors>
<title>Annotating attributions and private states</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Frontiers in Corpus Annotation II: Pie in the Sky</booktitle>
<location>Ann Arbor, Michigan</location>
<contexts>
<context>ates of their sources. They are therefore assigned to a separate category of objective speaking events. In an extension to the basic scheme, attitudes and targets were added to the annotation scheme (Wilson and Wiebe, 2005; Wilson, 2008). The attitude types that Wilson (2008) defines include Arguing, Sentiment, Agreement, Speculation, Intention, and an Other category. In this paper, we will mainly refer to the first tw</context>
</contexts>
<marker>Wilson, Wiebe, 2005</marker>
<rawString>T. Wilson and J. Wiebe. 2005. Annotating attributions and private states. In Proceedings of the ACL Workshop on Frontiers in Corpus Annotation II: Pie in the Sky, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Wilson</author>
</authors>
<title>Fine-Grained Subjectivity And Sentiment Analysis: Recognizing The Intensity, Polarity, And Attitudes Of Private States</title>
<date>2008</date>
<tech>Ph.D. thesis</tech>
<institution>University of Pittsburgh</institution>
<contexts>
<context>hey are therefore assigned to a separate category of objective speaking events. In an extension to the basic scheme, attitudes and targets were added to the annotation scheme (Wilson and Wiebe, 2005; Wilson, 2008). The attitude types that Wilson (2008) defines include Arguing, Sentiment, Agreement, Speculation, Intention, and an Other category. In this paper, we will mainly refer to the first two types, which</context>
</contexts>
<marker>Wilson, 2008</marker>
<rawString>T. Wilson. 2008. Fine-Grained Subjectivity And Sentiment Analysis: Recognizing The Intensity, Polarity, And Attitudes Of Private States. Ph.D. thesis, University of Pittsburgh.</rawString>
</citation>
</citationList>
</algorithm>

