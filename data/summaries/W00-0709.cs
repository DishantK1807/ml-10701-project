The grammar used was a manually written broad coverage DCG style grammar (Briscoe and Carroll, 1997).
A97-1052
Abney. 1997.
J97-4005
Most or all of these factors are considered in some form or another by current state-of-the-art statistical parsers such as those of Charniak (1997), Magerman (1995) and Collins (1996).
P95-1037 P96-1025
If the information contributed by the features is too specific to the training data, overfitting becomes a problem (Chen and Rosenfeld, 1999; Osborne, 2000).
C00-1085
This structure for statistical features might be compared with the Data-Oriented Parsing (DOP) of Bod (1998) in that it considers subtrees of parses as the structural units from which statistical information is taken.
P98-1022
The merging procedure seeks to address overfitting at the level of the features themselves and remain true to the spirit of the maximum entropy approach, which seeks to represent what is unknown about the data with uniformity of the distribution, rather than by making adjustments on the model distribution itself, such as the Gaussian prior of Osborne (2000).
C00-1085
The maximum entropy technique of statistical modeling using random fields has proved to be an effective way of dealing with a variety of linguistic phenomena, in particular where modeling of attribute-valued grammars (AVG's) is concerned (Abney, 1997).
J97-4005
Magerman. 1995.
P95-1037
The experiments described here were conducted using the Wall Street Journal Penn Treebank corpus (Marcus et al., 1993).
J93-2004
