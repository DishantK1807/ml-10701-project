Some of the kinds of word level post-processing include the use of dictionary lookup, probabilistic relaxation, character and word n-gram frequency analysis (Hong, 1995), and morphological analysis (Oflazer, 1996).
J96-1003
Subsequently, the characters in the aligned words can aligned in two different ways, namely: 1:1 (one-to-one) character alignment, where each character is mapped to no more than one character (Church and Gale, 1991); or using m:n alignment, where a character segment of length m is aligned to a character segment of length n (Brill and Moore, 2000).
P00-1037
DeRoeck introduced a clustering technique tolerant of Arabicâ€™s complex morphology (De Roeck and Al-Fares, 2000).
P00-1026
Similar work was done for Turkish in which an error tolerant finite state 409 recognizer was employed (Oflazer, 1996).
J96-1003
In the first, a 6-gram language model was trained on the same web-mined collection after each of the words in the collection was segmented into its constituent prefix, stem, and suffix (in this order) using language model based stemmer (Lee et al., 2003).
P03-1051
This path was pursued to examine the effect of correction on applications where stems are more useful than words such as Arabic information retrieval (Darwish et al., 2005; Larkey et al., 2002).
W05-0704
In a system described by Agirre (1998), an English grammar was used to parse sentences with spelling mistakes.
P98-1003
In the second, a trigram language model was trained on the same collection after the language modeling based stemming was used on all the tokens in the collection (Lee et al., 2003).
P03-1051
