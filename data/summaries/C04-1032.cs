5.1 Evaluation Criterion We use the same evaluation criterion as described in (Och and Ney, 2000).
P00-1056
Tables 3 and 4 show the performance of the one-sided MWEC algorithm in comparison with the experiment reported by (Och and Ney, 2003).
J03-1002
A detailed description of the popular translation/alignment models IBM-1 to IBM-5 (Brown et al., 1993), as well as the Hidden-Markov alignment model (HMM) (Vogel et al., 1996) can be found in (Och and Ney, 2003).
C96-2141 J03-1002 J93-2003
Using the IBM translation models IBM-1 to IBM-5 (Brown et al., 1993), as well as the Hidden-Markov alignment model (Vogel et al., 1996), we can produce alignments of good quality.
C96-2141 J93-2003
We will show statistically significant improvements compared to state-ofthe-art results in (Och and Ney, 2003).
J03-1002
Additional linguistic knowledge sources such as dependeny trees or parse trees were used in (Cherry and Lin, 2003; Gildea, 2003).
P03-1011 P03-1012
Therefore, this sum is approximated using a subset of promising alignments (Och and Ney, 2000).
P00-1056
On the Verbmobil task, we obtain a further improvement of 19% relative over the baseline result reported in (Och and Ney, 2003), reaching an AER as low as 3.8%.
J03-1002
As in (Och and Ney, 2003), the first 100 sentences of the test corpus are used as a development corpus to optimize model parameters that are not trained via the EM algorithm, e.g. the interpolation weights.
J03-1002
They are based on the sourcechannel approach to statistical machine translation (Brown et al., 1993).
J93-2003
Work A description of the IBM models for statistical machine translation can be found in (Brown et al., 1993).
J93-2003
Word alignment models were first introduced in statistical machine translation (Brown et al., 1993).
J93-2003
The solutions of these problems depend heavily on the quality of the word alignment (Och and Ney, 2000).
P00-1056
The HMM-based alignment model was introduced in (Vogel et al., 1996).
C96-2141
For the Verbmobil task, the refined method of (Och and Ney, 2003) is used.
J03-1002
Bilingual bracketing methods were used to produce a word alignment in (Wu, 1997).
J97-3002
On the Verbmobil task, we achieve an improvement of more than 1% absolute over the baseline error rate of 4.7%. 1 Introduction Word-aligned bilingual corpora provide important knowledge for many natural language processing tasks, such as the extraction of bilingual word or phrase lexica (Melamed, 2000; Och and Ney, 2000).
J00-2004 P00-1056
An overview of these models is given in (Och and Ney, 2003).
J03-1002
We use the same training schemes (model sequences) as presented in (Och and Ney, 2003): 15H5334363 for the Verbmobil Task, i.e. 5 iteration of IBM-1, 5 iterations of the HMM, 3 iteration of IBM-3, etc.
J03-1002
(Melamed, 2000) uses an alignment model that enforces one-to-one alignments for nonempty words.
J00-2004
Because we use the same training and testing conditions as (Och and Ney, 2003), we will refer to the results presented in that article as the baseline results.
J03-1002
