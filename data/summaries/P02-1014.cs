Results are shown in Table 2 (Duplicated Soon Baseline) where performance is reported in terms of recall, precision, and F-measure using the modeltheoretic MUC scoring program (Vilain et al., 1995).
M95-1005
Grishman (1995), Lin (1995)), most previous work treats linguistic constraints as broadly and unconditionally applicable hard constraints.
M95-1010 M95-1014
Baseline Coreference System Our baseline coreference system attempts to duplicate both the approach and the knowledge sources employed in Soon et al.(2001). More specifically, it employs the standard combination of classification and clustering described above.
J01-4004
ate the training data: we rely on coreference chains from the MUC answer keys to create (1) a positive instance for each anaphoric noun phrase, NPa3, and its closest preceding antecedent, NPa2 ; and (2) a negative instance for NPa3 paired with each of the intervening NPs, NPa2a5a4a7a6, NPa2a5a4a9a8,a10a11a10a12a10, NPa3a14a13a7a6. This method of negative instance selection is further described in Soon et al.(2001); it is designed to operate in conjunction with their method for creating coreference chains, which is explained next.
J01-4004
We follow the procedure employed in Soon et al.to cre1Results presented in Harabagiu et al.(2001) are higher than those reported here, but assume that all and only the noun phrases involved in coreference relationships are provided for analysis by the coreference resolution system.
J01-4004 N01-1008
Soon et al.(2001), for example, apply an NP coreference system based on decision tree induction to two standard coreference resolution data sets (MUC-6, 1995; MUC7, 1998), achieving performance comparable to the best-performing knowledge-based coreference engines.
J01-4004
Improving Machine Learning Approaches to Coreference Resolution Vincent Ng and Claire Cardie Department of Computer Science Cornell University Ithaca, NY 14853-7501 a0 yung,cardie a1 @cs.cornell.edu Abstract We present a noun phrase coreference system that extends the work of Soon et al.(2001) and, to our knowledge, produces the best results to date on the MUC6 and MUC-7 coreference resolution data sets â€” F-measures of 70.4 and 63.4, respectively.
J01-4004
We investigate two methods to improve existing machine learning approaches to the problem of 8Soon et al.(2001) present only the tree learned for the MUC-6 data set.
J01-4004
Lappin and Leass (1994)) and NP coreference resolution (e.g.
J94-4002
Aone and Bennett (1995), McCarthy and Lehnert (1995)).
P95-1017
Sidner (1979), Harabagiu et al.(2001)) as a means of improving common noun phrase resolution, which remains a challenge for state-of-the-art coreference resolution systems.
N01-1008
(See the indented Learning Framework results in Table 2.) Our results provide direct evidence for the claim (Mitkov, 1997) that the extra-linguistic strategies employed to combine the available linguistic knowledge sources play an important role in computational approaches to coreference resolution.
W97-1303
