Spoken-Language Translation Method Using Examples Hitoshi IIDA, Eiichiro SUMITA and Osamu FURUSE ATR Interpreting Telecommunications Research Laboratories 2-2 Hikaridai Seika-cho, Kyoto 619-02, JAPAN {iida, sumita, furuse}@itl.atr.co.jp 1 Introduction Conventional approaches to machine translation are mostly concerned with written text, such as technical documents.
This paper addresses the problem of spoken-language translation and explains the method and its capability to handle spoken language.
2 Seven
requirements for spoken-language translation The following new design features are critical for success in spoken-language translation: 1.
Incremental processing Incremental processing is required so as to handle fragmental phrases or incomplete utterances and to realize a real-time response.
This has a very close relation with item 5 below.
2. Handling spoken language Fragmental phrases, isolated phrases, a gradient of case role changing, complex topicalization, metonymical phrases, idiomatic expressions for etiquette, and inconsistent expressions in one utterance are main characteristics of spoken language.
They strongly depend on dialogue situations.
3. Handling euphemistic expressions Under the influence of social position or situation, euphemistic expressions appear in various scenes in various forms.
4. Deterministic processing Neither pre-editing nor post-editing can be relied on in a speech translation system.
Interactive disambiguation by speakers does not necessarily converge a correct interpretation.
5. Sufficient speed to avoid to break communication As an interpreter intervenes between speakers, real-time response is required to keep smooth turn taking.
.. High-quality translation This is necessary in order to ensure correct information exchange between speakers.
Recovering from speech recognition errors There are various aspects to recovering from speech recognition errors, for example in correcting phoneme sequences, syllable sequences, word sequences (including compound words and collocations).
3 Meeting
the seven requirements 3.1 Incremental processing This is an essential technology if one is to build an incremental translation system like a simultaneous interpreter, and the proper way to grasp a chunk of a translation unit corresponding to some chunk in a target language is to extend 'constituent boundary parsing' to bottom-up-type parsing \[Furuse96\].
3.2 Recovering
from errors A certain recovery method is now under consideration: a re-entrizing model for phoneme candidates by means of searching the correct phonemes using modification depending on recognition error characteristics in an example-based framewbrk \[Wakita95\].
This approach provides a recovery effect in handling phoneme or syllable sequences, and the effect depends on the particular speakers because of individual error characteristics.
3.3 Requirements
covered by EBMT/TDMT The remaining requirements are handled effectively by an example-based approach as explained here.
In NLP systems, especially for spoken language, many possibile syntactic structures are produced.
It is an important and difficult process to choose the most plausibile structure.
Conventional approachs, such as knowledge-based one, cannot easily handle continuous phenomena: gradation of case role changing; derivation of a metonymical 1074 relation; and relationship between a topicalized word and the main predicate.
We have proposed Example-Based Machine 3¥anslation (EBMT) to deal with these difliculties\[Sumita92-a\].
The EBMT method prepares a large number of translation examples; the translation example that most closely matches the input expression is retrieved; and tile example is nfimicked.
When applying F, BM'F to sentence translation, the sentence must be analyzed by matching transaltion patterns of phrases \[Furuse94\].
This model is in a sense "driven by transfer", and we call it Transfer-Driven Machine %anslation (TDMT).
3.3.1 Handling
spoken language Spoken language includes many phenomena; here, howew'.r, we concentrate on the following ones: (1) "wa" is a Japanese topic marker and, in general, this marker can t)e replaced by other case particles.
But some usages cannot be identified as to case role because of gradation of case role changing.
Moreover, if there are double topic markers in a sentence, they cannot I)e replaced by other particles 1.
The first sentence in our Japanese-to-English (JE) translation "snapshot" (Figure 1), for exam-.
ple, is properly translated in our TI)MT prototype system.
(i) "Chikatetsu-wa ichiban-chikai eki-wa doko desu-ka".
('subway-topiealized,' 'the nearest,' 'station-topicalized,' 'where,' 'bequestion') (2) Two sentences are mixed in one utterance.
The tirst is pended, then inunedaitely the second sentence starts without conjunction.
(ii) "Shiharai-wa ginkou-fllrikomi-o o-machishite-oriInasu".
('payment-topicalized,' 'bank-transferobjective,' 'wait-for-polite-modest') a.a.= Handling euphemistic expressions (1) There are various types of expressions for politeness, modesty, and euphemism.
Such expressions are used depending on social roles.
The fourth sentence in our Japaneseto-Korean (JK) translation snapshot (Figure 2) is a sample of this type, which is properly dealt with by TI)MT.
(iii) "Yoyaku-wo kakunin-sasete-itadaki-masu".
1In this paper, sample Japanese sentences are written alphabetically and surrounded by double quotes, and the corresponding English words with usage modifiers follow in parenthesis.
('reservation-objective,' 'confirm-modest') (iv) "Go-dengon-wo o-t ut ae-moushiage-masu ".
('message-polite-objective,' 'inform-honorific') 3.3.3 Deterministic processing ConventionM MT methods provide multiple translation candidates but no information to use in selecting among them, or else just the first possible sentence that is generated.
On the contrary, EBMT generates all the possible candidates combining suitable phrases.
It also provides proper scores to each candidate using a similarity calculation.
The scores realize "deterministic" translation.
3.3.4 Speed
\[Furuse96\] has improved a matching mechanism over translation patterns.
By accepting input in left-to-right order and dealing with best-only substructures, the explosion of structural ambiguity is restrained and an efficient translation of a lengthy input sentence can be achieved, l)re liminary experimentation has shown that average translation times are reduced from 1.15 seconds to 0.55 seconds for input of 10 words in length and from 10.87 seconds to 2.04 seconds for input of 20 words in length.
The incorporation of incremental morphological analysis and generation \[Akamine95\] into the new-version TDMT, is promising for achieving incremental (simultaneous) translation for a practical spoken-language translation system.
If instantaneous response is required, the rest dominant process is retrieval of the closest translation patterns from bulk collection.
It is effectively solved by using a massively parallel algorithms and machines \[Sumita95-a, Snmita95-b, Oi93\].
3.3.5 Quality
First, a well-known difficult problem in Japanese to English translation was selected as a test.
The Japanese noun phrase of the form "noun + NO + noun" using the Japanese adnominM particle "NO" is an expression whose meaning is continuous.
A translation success rate of about 80% has been demonstrated in a Jacknife test \[Sumita92-a\].
Also, for other Japanese and English phrases, similar effectiveness in target word selection and structural dsiambiguation has been demonstrated\[Sumita92-b\].
We have evaluated a experimental TDMT system, with 825 model sentences about conference registration.
These sentences cover basic expressions in an inquiry dialogue.
The success rate is 71% for a test data set consisting of 1,050 unseen sentences in the same domain.
1075 target : "T would like to arrive at Las Vegas by nine o' clock at night" target : "If you get on the bus at nine fifteen, you ~ll arrive by e~ht o' clock at night" source : "AB~-CT~ ~" target : "At eight 0' clock 2" source : "L; ~ ~f~, ~?: ~ ~d--~r.'\]ff~;0~7~ AT~-n" target : "Well, it takes eleven hours approximately, r~ht "? source : % ~ ~,~'~ U ~-~'6-i--~l%"ffl\[;b ~ U ~-" target : "No . there is the time difference and it will take t~elve hours" Figure 1: JE translation snapshot by TDMT source : "C-~%T'~Pe~,gtCZSf~'8~9-~ ~'' (Hi is it possible to make hotel reservation from here)? target : "~1~ ~ ~ ~ + ~@~1~"? source : "C~fr(~-C'~ ~/~-c~'C-~,,~a)ZIat~*~Z~X-c'I~ bT~ ~ ~:~i~ ~" (OK, what we do is to give you all the ~nformation you need and then ~e ask you to go ahead and make the call yourself.
) target : ~,~ 7~ul\] o~o~ ~ ~o~ ~ ~ ~x\]~¢~.\]~h" source : "b+~ U~d~69~JU~/~U~< tZ~" (OL l'm looking for a central locatioi~ if possible.
) target : "~L~ ~ ~\]~ ~J~ ~ ~xj~\]~ ..
(Not too expensive, and it shouldn ~ t take too long to get to the major sights from there.
) target : "e~H17~ ~ HI~I ~ ~ ~l~ ~17~ ~gJL" Figure 2: JK translation snapshot by TDMT 4 JE 8¢ JK prototype systems The TDMT system is being expanded so as to handle travel arrangement dialogues including the topics of hotel reservation, room services, troubleshooting during hotel stays, various information queries, and various travel arrangements.
At present the JE system has about a 5,000-word vocabulary and a transfer knowledge from 2,000 training sentences.
The JK system is half this size.
While some modules, such as morphological analysis and generation, are language-specific, the transfer module is a common part of every language pair.
Through JE and JK implementation, we believe that the translation of every language pair can be achieved in the same framework using TDMT.
On the other hand, it has turned out that the linguistic distance between source and target languages reflects the variety of target expression patterns in the transfer knowledge.
Table 1 shows the number of target expression patterns corresponding a Japanese particles in JE and JK.
These numbers are counted from the current TDMT system's transfer knowledge, and the numbers of examples are token numbers (i.e., not including duplications).
5 Discussion
5.1 Integration of Speech and Language A mechanism for spontaneous speech translation must be consistent with a mechanism for handling associative knowledge, such as translation usage examples and word co-occurrence information for rnemory-b~ed processing, and with a mechanism for logical structure analysis according to detailed rules for each processing phase in the TransferDriven MT processing.
Under the process, a study should be carried out on building a stochastic language model using both syntactic and semantic information for speech understanding.
5.2 Related
Research On the other hand, some studies hope to build spoken language translation systems using a certain interlingua method.
A semantic parser is a typical example of this method.
In particular, "semantic pattern based parsing" in JANUS, CMU's speech to speech translation system \[Woszczyna93, Levin95\] uses frame based semantics with a semantic phrase grammar and the operation of the parser is viewed as "phrase spotting".
Another one is MIT's multilingual 1076 'Fable 1: Japanese particle translation in JE and,IK translation Japanese Pattern X w(J Y Xga Y Xno Y XoY Xni Y Xde Y JP Example Target patterns 224 30 140 15 226 36 147 15 154 22 120 25 Example Target patterns 66 1 40 1 88 2 41 1 55 5 33 5 GALAXY: a human-language interface to online travel information \[Goddean94\].
The system makes use of 'semantic frame representation' so as to paraphrase a recognized speech input utterance into a concrete and simple expression that contbrms with one of the system's internal representations and makes the utterance meaning easy to handle.
Itowever, in extracting the meaning of an inlmt sentence, many default values are required so as to execute heuristic inferences.
The inference is too powerful in explaining a speaker's intention and the propositional content of the utterance by one key word or phrase.
Such a method may work well in a certain domain, but less scalability may be revealed when making a larger prototype system.
VERBMOBIL is a typical translation system for face-to:face dialogue \[Wahlster93\].
This system adopts English as a dialogue language for human-machine interface and makes use of DRTbased semantic representation units.
6 Conclusion
'\['DMT has been proposed as a general technique for spoken-language translation.
We have applied TDMT to two language pairs, i.e., JapaneseEnglish, and Japanese-Korean, as a first step toward multi-lingual translation.
Also, we are planning to integrate speech recognition with TI)M'F for achieving effective and efficient speech translation.
References \[Akamine95\] Akamine, S.
and l!'uruse, O.: Einiehi-taiwabun-hon'yaku niokeru zenshintekinihongobml-seisei (incremental generation of Japanese Sentence in English to Japanese Dialogue Translation), in ProF.
of 1 st NLP convetion, pp.281-284 (1995), (in Japanese).
\[Furuse94\] Furuse, O.
and Iida, H.
: Constituent Boundary Parsing for EBMT, in ProF.
of COLING'94, pp.
105-111 (1994).
\[Furuse96\] Furnse, O.
and Iida, H.
: Incremental Translation Utilizing Constituent Boundary Pattern, in ProF.
of COLING'96 (1996).
\[Goddeau94\] Goddeau, D., et al.: GALAXY: A IIUMAN-LANGUAGE INTERFACE TO ONLINE 'I'RAVI!3; INFORMATION, in Poc.
of IC: SLP94, pp.707-710 (1994).
\[lida93\] 1ida, H.
: Prospects for Adwmced Spoken Dialogue Processing, \[EICE TRANS.
INF. and SYST., VOL.
E-76-D, No.l, pp.
2-8 (1993).
\[Levin95\] Levin, LL., et al.: Using Context in Machine Translation of Spoken Language, in ProF.
of TMI-95, pp.
173-187 (1995).
\[Nagao84\] Nagao, M.
: A Framework of a Machine Translation between Japanese and English by Analogy Principle, in Artitieial and Human Intelligence, eds.
A. Elithorn and R.
Banerji, Northllolhmd, pp.
173-180 (1984) . \[Oi93\] Oi, K.
et al.: Toward Massively Parallel Spoken Language Translation, in Proe.
of the Workshop on Parallel Processing for AI, IJCAI'93, pp.
36-39 (1993).
\[Sumita92-a\] Surnita, E.
and Iida, II.
: Example-Based Transfer of Japanese Adnominal Particles into English, IEICE TRANS.
INF. and SYST., VOL.
E-75-1), No.4, pp.
585-594 (1992).
\[Smnita92-b\] Sumita, E.
and Iida, 11.
: Example-Based NLP TechniquesA Case Study of Machine Translation -, Statistically-Based NLP TechniquesPapers from the 1992 Workshop, Technical Report W'92-01, AAAI Press (1992).
\[Sumita95-a\] Sumita, E.
and Iida, tt.
: Iteterogeneous Computing for Example-Based Translation of Spoken Language, in Proe.
of TMI-95, pp.
273-286 (1995).
\[Sumita95-b\] Sumita, g.
and Iida, H.
: Hetero~ geneous Computing for Example-Based Translation of Spoken Language, in ProF.
of TMI-95, pp.
273-286 (1995).
\[Wahlster93\] Wahlster, W.
: Verbmobil: Translation of Face-To-Face Dialogs, in ProF.
of MT-Sumnfit IV, pp.
127-135(1993). \[Wakita95\] Wakita, Y.
et al.: Phoneme Candidate Re-entry Modeling Using Recognition Error Characteristics over Multiple HMM States, in ProF.
of ESCA Workshop on Spoken Dialogue Systems, pp.
73-76 (1995).
\[Woszczyna93\] Woszczyna, M., et al.: RECCENT ADVANCES IN JANUS: A SPEECH TRANSLATION SYSTEM, in ProF.
of EUROSPEECH'93, pp.
1295-1298 (1993). 1077

