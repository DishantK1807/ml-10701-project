The lexical substitution (Glickman et al., 2006a) can be regarded as a subtask of the lexical entailment, in which for a given word in context the system is asked to select an alternative word that can be replaced in that context preserving the meaning.
W06-1621 W06-2907
Textual Entailment Recognition (RTE) (Dagan et al., 2006) has recently been proposed as an application independent task to capture such inferences.
P06-1057
There exists already many interesting approaches to this problem, see (Dagan et al., 2005; Bar-Haim et al., 2006) for various recent efforts and our paper wont try to fully reinvent the wheel.
P06-1057
Dagan. 2006b.
P06-1057
It is our first attempt to RTE and we have taken profit of an analysis of the approaches followed in previous challenges (see (Dagan et al., 2005), and (Bar-Haim et al., 2006) for overviews of RTE-1 and RTE-2).
P06-1057
Lexical Entailment, and in particular lexical reference (Glickman et al., 2006b)1, is in turn a subtask of textual entailment, which is formally de ned as a relationship between a coherent text T and a language expression, the hypothesis H.
W06-1621 W06-2907
Finding alternative words that can occur in given contexts would potentially be useful to many applications such as question answering, summarisation, paraphrase acquisition (Dagan et al., 2006), text simplification and lexical acquisition (McCarthy, 2002).
P06-1057
In previous RTE challenges (Dagan et al., 2006; Bar-Haimetal., 2006), severalmachine-learningapproaches appeared, but their results showed that significant improvements were still necessary.
P06-1057
The results obtained, using the accuracy measure that is the fraction of correct responses according to (Dagan et al., 2006), are shown in table 1.
P06-1057
1In the literature, slight variations of this problem have been also referred to as sense matching (Dagan et al., 2006).
P06-1057
To overcome this problem several approaches have been studied, being the Recognising Textual Entailment Challenge (RTE) (BarHaim et al., 2006; Dagan et al., 2006) the most referred source for determining which one is the most accurate.
P06-1057
References Bar-Haim, R., Dagan, I., Dolan, B., Ferro, L., Giampiccolo, D., Magnini, B., et al.(2006). The Second PASCAL Recognising Textual Entailment Challenge.
P06-1057
[Bar-Haim, Dagan, et al.2006] We do recognize that some of our metrics have already been employed by other teams [Jijkoun and Rijke, 2005] and that our results may be different because of the thesaurus corpus we employed and the classification strategy we used.
P06-1057
