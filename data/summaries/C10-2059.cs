Liu, Yang, Qun Liu, and Shouxun Lin. 2006. Tree-
P06-1077
(Klein and Manning, 2002; Klein and Manning,
P02-1017
Zhang, Yue and Stephen Clark. 2008. A tale of
D08-1059
al., 2008; Zhang and Clark, 2008; Huang, 2008),
D08-1059 P08-1067
the revised Chinese parser (Xiong et al., 2005)
I05-1007
Bod, Rens. 2006. An all-subtrees approach to unsu-
P06-1109
Collins, Michael. 2002. Discriminative training meth-
W02-1001
Och, Franz Joseph. 2003. Minimum error rate train-
P03-1021
Hwa et al., 2005; Ganchev et al., 2009; Smith
P09-1042
Seginer, Yoav. 2007. Fast unsupervised incremental
P07-1049
Huang, Liang, Kevin Knight, and Aravind Joshi. 2006.
W06-3601
Huang, Liang and David Chiang. 2005. Better k-best
W05-1506
Klein, Dan and Christopher D. Manning. 2002. A
P02-1017
based translation model (Liu et al., 2006), we
P06-1077
training (Och, 2003) to tune the feature weights
P03-1021
Liu, Yang, Tian Xia, Xinyan Xiao, and Qun Liu. 2009.
D09-1106
voted to dependency projection (Hwa et al., 2002;
P02-1050
Och, Franz J. and Hermann Ney. 2000. Improved
P00-1056
(Collins, 2002).
W02-1001
Smith, David and Jason Eisner. 2009. Parser adap-
D09-1086
(Papineni et al., 2002) with 4 references.
P02-1040
al., 2006; Huang et al., 2006). Such models use
W06-3601
Klein, Dan and Christopher D. Manning. 2004. Cor-
P04-1061
Sarkar, Anoop. 2001. Applying co-training methods
N01-1023
unannotated data (Sarkar, 2001; Steedman et al.,
N01-1023
Charniak, Eugene and Mark Johnson. 2005. Coarse-
P05-1022
vised Chinese parser (Xiong et al., 2005) trained
I05-1007
errors, multiple GIZA++ (Och and Ney, 2000) re-
P00-1056
Charniak, Eugene. 2000. A maximum-entropy-
A00-2018
Charniak, 2000; Petrov et al., 2006). Because
A00-2018 P06-1055
2003; McClosky et al., 2006).
P06-1043
2004; Bod, 2006; Seginer, 2007), and the semi-
P06-1109 P07-1049
GIZA++ according to (Liu et al., 2009).
D09-1106
Huang, Liang. 2008. Forest reranking: Discriminative
P08-1067
