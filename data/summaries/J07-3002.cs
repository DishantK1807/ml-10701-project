To generate word alignments we use GIZA++ (Och and Ney 2003), which im-
J03-1002 P03-1021
alignment at WPT03 (Mihalcea and Pederson 2003) and WPT05 (Martin, Mihalcea,
W03-0301
sets also have links which are not Sure links but are Possible links (Och and Ney 2003).
J03-1002 P03-1021
Och, Franz J. and Hermann Ney. 2003.
J03-1002 P03-1021
Fraser, Alexander and Daniel Marcu. 2006.
P06-1097
tion heuristics‚Äù described in Och and Ney (2003). We evaluate our approaches using
J03-1002 P03-1021
Automatic word alignment (Brown et al. 1993) is a vital component of all statistical
J93-2003
Cherry, Colin and Dekang Lin. 2003. A
P03-1012
plements both the IBM Models of Brown et al. (1993) and the HMM model (Vogel,
J93-2003
2003; Ayan, Dorr, and Monz 2005; Ittycheriah and Roukos 2005; Liu, Liu, and Lin 2005;
H05-1009 H05-1012 P05-1057
Och, Franz J. 2003. Minimum error rate
J03-1002 P03-1021
of its log-linear model to maximize BLEU (Och 2003). We work with data sets for three
J03-1002 P03-1021
Fraser and Marcu 2006; Lacoste-Julien et al. 2006; Moore, Yih, and Bode 2006).
N06-1015 P06-1065 P06-1097
In phrased-based SMT (Koehn, Och, and Marcu 2003) the knowledge sources which
J03-1002 N03-1017 P03-1021
Fraser, Alexander and Daniel Marcu. 2005.
W05-0814
system are trained using Maximum BLEU (Och 2003), which we run for 25 iterations
J03-1002 P03-1021
Mihalcea, Rada and Ted Pederson. 2003.
W03-0301
Hansard data set, from which the word aligned data (presented in Och and Ney 2003)
J03-1002 P03-1021
Goutte, Yamada, and Gaussier (2004) previously observed that AER could be un-
P04-1064
