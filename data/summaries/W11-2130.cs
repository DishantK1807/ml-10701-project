(Papineni et al., 2002). MERT training uses a par-
P02-1040
bilities of Moses (Koehn and Hoang, 2007).
D07-1091 W07-0733
2007; Chiang et al., 2008). SampleRank is used to
D08-1024
two operators is give in Arun et al. (2009).
W09-1114
Chiang et al. (2008) introduced an approximation to
D08-1024
Typically, either perceptron ((Liang et al., 2006),
P06-1096
this was explored in (Arun et al., 2009) and (Arun et
W09-1114
by Li and Eisner (2009) who were able to obtain
D09-1005
Abhishek Arun and Philipp Koehn. 2007. Online Learn-
D07-1091 W07-0733
from n-best lists or lattices (Smith and Eisner, 2006;
P06-2101
Ryan McDonald, Keith Hall, and Gideon Mann. 2010.
N10-1069
rate training) (Och, 2003), to maximise performance
P03-1021
ery sample. One novel feature of Arun et al. (2010)
W10-1756
tive method, such as MCMC (Arun et al., 2009).
W09-1114
Philipp Koehn and Josh Schroeder. 2007. Experiments
D07-1091 W07-0733
al., 2007), (Chiang et al., 2008)) is employed, but
D08-1024
(Arun and Koehn, 2007)) or MIRA ((Watanabe et
D07-1091 W07-0733
training (Liang et al., 2006) and MIRA (Chiang et
P06-1096
as well as its instability (Foster and Kuhn, 2009)
W09-0439
Arun et al. (2009) (explained shortly). Model scores
W09-1114
Franz J. Och. 2003. Minimum Error Rate Training
P03-1021
al., 2008; Watanabe et al., 2007) have also been
D07-1080
Zhifei Li and Jason Eisner. 2009. Firstand Second-
D09-1005
jective, Blunsom et al. (2008) trained their model to
P08-1024
Phil Blunsom, Trevor Cohn, and Miles Osborne. 2008.
P08-1024
George Foster and Roland Kuhn. 2009. Stabilizing
W09-0439
ated, analogously Chiang et al. (2008), by choosing
D08-1024
aged perceptron (McDonald et al., 2010).
N10-1069
David Chiang, Yuval Marton, and Philip Resnik. 2008.
D08-1024
Philipp Koehn and Hieu Hoang. 2007. Factored Transla-
D07-1091 W07-0733
Li and Eisner, 2009), or using sampling (Arun et al.,
D09-1005
David A. Smith and Jason Eisner. 2006. Minimum risk
P06-2101
Whilst MERT (Och, 2003) is still the dominant al-
P03-1021
non-convex error surface (Och, 2003). Furthermore
P03-1021
(Koehn and Schroeder, 2007). In the WMT-LARGE
D07-1091 W07-0733
ing for SMT, (Liang et al., 2006; Chiang et al.,
P06-1096
