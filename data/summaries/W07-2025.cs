Comparison with previous best results: KM01 (Kudoh and Matsumoto, 2001), CM03 (Carreras and Marquez, 2003), SP03 (Sha and Pereira, 2003), ZDJ02 (Zhang et al., 2002).
N01-1025
The highest score reported on Timebank achieved 62.5% accuracy when using gold-standard features as marked by humans (Mani et al., 2006).
P06-1095
Following Pradhan et al.(2003), we used tinySVM along with YamCha (Kudo and Matsumoto 2000, 2001) as the SVM training and test software.
N01-1025
We chose support vector machines3(SVMs) for our classifiers as they have shown good performance on a variety of natural language processing tasks (Kudo and Matsumoto, 2001; Pradhan et al., 2005).
N01-1025
The 2007 TempEval competition tries to address this question by establishing a common corpus on which research systems can compete to find temporal relations (Verhagen et al., 2007).
W07-2014
TRUE. These gold-standard event and time features are similar to those used by Mani and colleagues (2006).
P06-1095
TimeML and TimeBank have already been used as the basis for automatic time, event and temporal relation annotation tasks in a number of research projects in recent years (Mani et al., 2006; Boguraev et al., forthcoming).
P06-1095
Solely for comparison with Mani, we add the 73 documentOpinionCorpus(Manietal., 2006)tocreate a larger dataset called the OTC.
P06-1095
Therefore, we introduce a Support Vector Machine(below SVM)-based chunker (Kudo and Matsumoto, 2001) to cover the errors made by the segmenter.
N01-1025
Kudoh and Matsumoto (2001), Zhang and Johnson (2003)).
N01-1025
During the testing phase, we used automatically assigned POS and chunk tags by Tsuruoka?s tagger4(Tsuruoka and Tsujii, 2005) and YamCha chunker5(Kudo and Matsumoto, 2001).
N01-1025
