Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 121–126, Sydney, July 2006.
c©2006 Association for Computational Linguistics Extended cross-serial dependencies in Tree Adjoining Grammars Marco Kuhlmann and Mathias Möhl Programming Systems Lab Saarland University Saarbrücken, Germany {kuhlmann|mmohl}@ps.uni-sb.de Abstract The ability to represent cross-serial dependencies is one of the central features of Tree Adjoining Grammar (TAG).
The class of dependency structures representable by lexicalized TAG derivations can be captured by two graph-theoretic properties: a bound on the gap degree of the structures, and a constraint called well-nestedness.
In this paper, we compare formalisms from two strands of extensions to TAG in the context of the question, how they behave with respect to these constraints.
In particular, we show that multi-component TAG does not necessarily retain the well-nestedness constraint, while this constraint is inherent to Coupled Context-Free Grammar (Hotz and Pitsch, 1996).
1 Introduction
The ability to assign ‘limited cross-serial dependencies’ to the words in a sentence is a hallmark of mildly context-sensitive grammar formalisms (Joshi, 1985).
In the case of TAG, an exact definition of this ability can be given in terms of two graph-theoretic properties of the dependency structures induced by TAG derivations: the gap degree restriction and the well-nestedness constraint (Bodirsky et al., 2005).
Gap degree and well-nestedness can be seen as the formal correspondents of what Joshi (1985) refers to as ‘a limited amount of cross-serial dependencies’ and ‘the nesting properties as in the case of context-free grammars.’ More specifically, the gap degree of a dependency structure counts the number of discontinuities in a dependency subtree, while well-nestedness constrains the positions of disjoint subtrees relative to one another.
The dependency structures that correspond to the derivations in a lexicalized TAG are well-nested, and their gap degree is at most1.
In the present paper, we compare formalisms from two strands of extensions to TAG in the context of the question, what classes of dependency structures they are able to induce.
We are particularly interested in formalisms that induce only well-nested dependency structures.
This interest is motivated by two observations: First, well-nestedness is interesting as a generalization of projectivity (Marcus, 1967)—while more than 23% of the 73088 dependency structures in the Prague Dependency Treebank of Czech (Hajiˇc et al., 2001) are non-projective, only 0.11% are not well-nested (Kuhlmann and Nivre, 2006).
Second, well-nestedness is interesting for processing.
Specifically, parsers for well-nested grammar formalisms are not confronted with the ‘crossing configurations’ that make the universal recognition problem of Linear Context-Free Rewriting Systems NP-complete (Satta, 1992).
In summary, it appears that well-nestedness can strike a successful balance between empirical coverage and computational tractability.
If this is true, then a formalism that has the well-nestedness constraint hardwired is preferable over one that has not.
The results of this paper can be summarized as follows: Derivations in lexicalized multi-component TAGs (Weir, 1988; Kallmeyer, 2005), in which a single adjunction adds a set of elementary trees, either induce exactly the same dependency structures as TAG, or induce all structures of bounded gap degree, even non-well-nested ones.
This depends on the decision whether one takes ‘lexicalized’ to mean ‘one lexical anchor per tree’, or ‘one lexical anchor per tree set’.
In contrast, multi-foot extensions of TAG (Abe, 1988; Hotz and Pitsch, 1996), where a single elementary tree may have more than one foot node, only induce well-nested dependency structures of bounded gap degree.
Thus, from the dependency point of view, they constitute the structurally more conservative extension of TAG.
121 2 Dependency structures for TAG We start with a presentation of the dependency view on TAG that constitutes the basis for our work, and introduce the relevant terminology.
The main objective of this section is to provide intuitions; for the formal details, see Bodirsky et al.(2005). 2.1 The dependency view on TAG Let s D w1 SOHSOHSOHwn be a sentence (a sequence of tokens).
By a dependency structure fors, we mean a tuple.W;!RS/, whereW D fw1;:::;wng, and ! D f.wi;wj/2W STXW jwj depends onwi g RS D f.wi;wj/2W STXW ji <j g To interpret a grammar formalism as a specification for a set of dependency structures, we need to assign meaning to the relation ‘depends’ in terms of this formalism.
For TAG, this can be done based on the Fundamental Hypothesis that ‘every syntactic dependency is expressed locally within a single elementary tree’ (Frank, 2002).
More specifically, a derivation in a (strongly) lexicalized TAG can be viewed as a dependency structure as follows: The setW contains the (occurences of) lexical anchors involved in the derivation.
For two anchors wi;wj 2 W, wi ! wj if the elementary tree anchored atwj was substituted or adjoined into the tree anchored atwi.
We then havewi RSwj ifwi precedes wj in the yield of the derived tree corresponding to the derivation.
Notice that the relation ! in such a dependency structure is almost exactly the derivation tree of the underlying TAG derivation; the only difference is that elementary trees have been replaced by their lexical anchors.
Figure 1 shows a TAG grammar together with a dependency structure induced by a derivation of this grammar.
Tokens in the derived string are represented by labelled nodes; the solid arcs between the nodes represent the dependencies.
2.2 Gap
degree and well-nestedness An interesting feature of the dependency structure shown in Figure 1 is that it violates a standard constraint on dependency structures known as projectivity (Marcus, 1967).
We introduce some terminology for non-projective dependency structures: A set T DC2 W is convex, if for no two tokens w1;w2 2 T, there exists a token w from W NULT such that w1 RS w RS w2.
The cover of T, C.T/, is the smallest convex set that contains T.
For w 2 W, we write #w for the set of tokens in the S; a T D B C T; a T D B ? C B; b C; c D; d. a1 a2 b2 b1 c1 c2 d2 d1 Figure 1: TAG grammar for anbncndn, and a dependency structure induced by this grammar subtree rooted atw (includingw itself).
A gap in #wis a largest convex set inC.#w/NUL#w.
The gap degree ofw, gd.w/, is the number of gaps in #w.
The gaps in #wpartition #winto gd.w/NUL1largest convex blocks; we write #iw to refer to the i-th of these blocks, counted from left to right (with respect to RS).
The gap degree of a dependency structureisthemaximumoverthegapdegreesofits subtrees; we writeDg for the set of all dependency structures with a gap degree of at mostg.
The gap degree provides a quantitative measure for the non-projectivity of dependency structures.
Well-nestedness is a qualitative property: it constrains the relative positions of disjoint subtrees.
Let w1;w2 2 W such that #w1 and #w2 are disjoint.
Four tokensw11;w21 2 #w1,w12;w22 2 #w2 interleave, if w11 RS w12 RS w21 RS w22.
A dependency structure is well-nested, if it does not contain interleaving tokens.
We write Dwn for the set of all well-nested dependency structures.
For illustration, consider again the dependency structure shown in Figure 1.
It has gap degree 1: a2 is the only tokenw for which #w is not convex; the set fb1;c1g forms a gap in #a2.
The structure is also well-nested.
In contrast, the structure shown in the right half of Figure 2 is not well-nested; the tokensb;c;d;e interleave.
Bodirsky et al.(2005) show that TAG induces precisely the set Dwn \D1.
3 Multi-component extensions Multi-component TAG (MCTAG) extends TAG with the ability to adjoin a whole set of elementary trees (components) simultaneously.
To answer the question, whether this extension also leads to an extended class of dependency structures, we first need to decide how we want to transfer the Fundamental Hypothesis (Frank, 2002) to MCTAGs.
122 A; a B1 C1 B2 C2 8 < : B;1 b B;2 D 9> = >; 8 < : C;1 c C;2 E 9> = >; D; d E; e Figure 2: An MCTAG and a not well-nested dependency structure derived by it.
3.1 One
anchor per component If we commit to the view that each component of a tree set introduces a separate lexical anchor and its syntactic dependencies, the dependency structures induced by MCTAG are exactly the structures induced by TAG.
In particular, each node in the derivation tree, and therefore each token in the dependency tree, corresponds to a single elementary tree.
As Kallmeyer (2005) puts it, one can then consider an MCTAG as a TAG G ‘where certain derivation trees inG are disallowed since they do not satisfy certain constraints.’ The ability of MCTAG to perform multiple adjunctions simultaneously allows one to induce more complex sets of dependency structures—each individual structure is limited as in the case of standard TAG.
3.2 One
anchor per tree set If, on the other hand, we take a complete tree set as the level on which syntactic dependencies are specified, MCTAGs can induce a larger class of dependency structures.
Under this perspective, tokens in the dependency structure correspond not to individual components, but to tree sets (Weir, 1988).
For each tokenw, #w then contains the lexical anchors of all the subderivationsstartinginthetreeset corresponding tow.
As there can be a gap between each two of these subderivations, the gap degree of the induced dependency structures is bounded only by the maximal number of components per tree set.
At the same time, even non-well-nested structures can be induced; an example is shown in Figure 2.
Here, #b is distributed over the components rooted at B1 and B2, and #c is distributed overC1 andC2.
The elementary tree rooted atA arranges the substitution sites such thatb;c;d;einterleave.
Note that the MCTAG used in this example is heavily restricted: it is tree-local and does not even use adjunction.
This restricted form suffices to induce non-well-nested dependency structures.
4 Multi-foot extensions A second way to extend TAG, orthogonal to the multi-component approach, is to allow a single elementary tree to have more than one foot node.
For this kind of extension, the Fundamental Hypothesis does not need to be re-interpreted.
Probably the most prominent multi-foot extension of TAG is Ranked Node Rewriting Grammar (RNRG) (Abe, 1988); however, the properties that we are interested in here can be easier investigated in a notational variant of RNRG, Coupled Context-Free Grammar (Hotz and Pitsch, 1996).
Terminology Multi-foot formalisms require a means to specify which foot node gets what material in an adjunction.
To do so, they use ranked symbols.
A ranked alphabet is a pair˘ D.˙;SUB/, where˙ is an alphabet, andSUB2˙ !N is a total function that assigns every symbolESC 2˙ a (positive) rank.
Define˘Œrc141 WD fESC 2 ˙ j SUB.ESC/ D rg.
The components of ESC, comp.ESC/, are the elements of the set f.ESC;i/j1DC4i DC4SUB.ESC/g.
We writeESCi instead of.ESC;i/.
Let comp.˘/WDSESC2˘ comp.ESC/. 4.1 Coupled Context-Free Grammar Coupled Context-Free Grammar (CCFG) is a generalization of context-free grammar in which non-terminals come from a ranked alphabet, and components of a non-terminal can only be substituted simultaneously.
The ‘TAG-ness’ of CCFG is reflected in the requirement, that the RHS of productions must be words from a bracket-like language, and thus have the same hierarchical structure as elementary trees in a TAG.
As an example, the second elementary tree from Figure 1 can be linearized as hT1aT1B1;C1T2D1T2i; where each pair.T1;T2/of matching components corresponds to an inner node in the tree, and the boundary between the first and the second part of the tuple marks the position of the foot node.
The required structure of the RHS can be formalized as follows: Definition 1 Let ˘ be a ranked alphabet, and let ˙ be an unranked alphabet.
The extended semi-Dyck set over ˘ and ˙, ESD.˘;˙/, is the smallest set that satisfies the following properties: 123 (a) ˙ETX DC2 ESD.˘;˙/; (b) ˘Œ1c141 DC2 ESD.˘;˙/; (c) if s1;:::;sk 2 ESD.˘;˙/ and EM 2 ˘ŒkC1c141, then EM1s1EM2 SOHSOHSOHEMkskEMkC1 2 ESD.˘;˙/; (d) if s1;s2 2 ESD.˘;˙/, thens1s2 2 ESD.˘;˙/.
Definition 2 Let N be a ranked alphabet of nonterminals, and let T be an (unranked) alphabet of terminals.
A ranked rewriting system over ESD.N;T/is a finite, non-empty set of productions of the form X ! h˛1;:::;˛ri, where X 2 NŒrc141, and˛ WD˛1 SOHSOHSOH˛r 2 ESD.N;T/.
We writeSUB.p/to refer to the rank of the non-terminal on the LHS of a productionp.
RNRG and CCFG are notational variants because each RNRG elementary tree withr NUL1foot nodes can be linearized into the RHS of a production X ! h˛1;:::;˛ri in a ranked rewriting system, as indicated by the example above.
Definition 3 A coupled context-free grammar is a tuple G D .N;T;P;S/ where: N is a ranked alphabet of non-terminal symbols;T is an unranked alphabet of terminal symbols;P is a ranked rewriting system over ESD.N;T/; S 2 NŒ1c141 is a start symbol.
We say that a CCFGG is anr-CCFG, if the maximal rank among all non-terminals inG isr.
Definition 4 PutV WD comp.N/[T, and let RS 2VETX D u1X1u2 SOHSOHSOHurXrurC1 2VETX D u1˛1u2 SOHSOHSOHur˛rurC1 such thatu2;:::;ur 2 ESD.N;T/, andX 2 NŒrc141.
We say that can be derived fromRS in one step, and write RS )G, if G contains a production X ! h˛1;:::;˛ri.
The string language of G is the setL.G/WD fs 2TETX jS )ETXG sg.
Based on this definition, the notions of derivation tree and derived tree are defined in the usual way.
In particular, the nodes of the derivation tree are labelled with productions, while the nodes of the corresponding derived tree are labelled with components from comp.˘/(inner nodes) and terminal symbols (leaves).
We write .T];T[/ to refer to a derivation in CCFG: T] stands for the derivation tree,T[ for the corresponding derived tree.
4.2 The
dependency view on CCFG A CCFG G is strongly lexicalized, if each productionp contains exactly one terminal symbol, written as anchor.p/.
Just as in the case of TAG, a strongly lexicalized CCFG G can be interpreted as a dependency grammar: Let.T];T[/be a derivation in G.
Since G is strongly lexicalized, there is a one-to-one mapping between the nodes of the derivation treeT] (labelled with productions) and the leaves of the derived treeT[ (labelled with terminals); we refer to this mapping by the namefL.
Definition 5 A dependency structureD is induced by a derivation.T];T[/, written.T];T[/`D, if (a) anchor.p1/ ! anchor.p2/ in D if and only if p1 ! p2 in T]; (b) anchor.p1/ RS anchor.p2/ inD if and only iffL.p1/RSfL.p2/inT[.
We write D.G/for the set of all dependency structures induced by derivations inG.
Figure 3 shows a sample CCFG G, a derivation in G, and the dependency structure induced by this derivation.
4.3 Projections
To reason about the structural properties of the dependency languages induced by CCFGs, we need some additional definitions.
In the following, we use the notation .uWESC/ to refer to a node u with labelESC in some given labelled tree.
LetD 2 D.G/be a dependency structure such that.T];T[/`D, and let.uWp/2T] be a node.
Somewhere in the course of the derivation represented byT], theSUB.p/components of the non-terminal on the LHS of the productionp are simultaneously rewritten.
LetfI.u/be theSUB.p/-tuple of nodes inT[ that correspond to these components.
Note that, whilefL maps nodes in the derivation tree T] to leaves in the derived tree T[, fI takes nodes inT] to tuples of inner nodes inT[.
Define down.u/D fv ju!ETX v inT] g; proj.u;i/D fv jfI.u/i !ETX fL.v/inT[ g: The set down.u/contains the lexical anchors in the sub-derivation starting atu.
The set proj.u;i/identifies that part of this sub-derivation that is derived from thei-th component of the non-terminal at the LHS of the production corresponding tou.
For the derivation shown in Figure 3, we have fI.p2/D hB1;B2;B3i; proj.p2;1/D fp2g: Lemma 6 For all nodesu2T], down.u/DU1DC4iDC4SUB.p/ proj.u;i/: 4.4 Results In this section, we prove the main technical results of this paper: that all dependency structures 124 GrammarGETX: p1W A! hai; p2W B ! hb;D1;D1i; p3W C ! hA1B1cA1B2A1B3i; p4W D ! hdi p3 p1 p2 p1 p1 p4 p4 (a) Derivation tree (b) Derived tree a b c a d a d (c) Induced dependency structure Figure 3: A CCFG derivation and the dependency structure induced by it induced by an r-CCFG have a gap degree that is bounded by r; that they are all well-nested; and that each well-nested structure with a gap degree bounded byr can be induced by anr-CCFG.
In the following, letG be anr-CCFG, and writeGr for the set of allr-CCFGs.
Lemma 7 D.G/DC2 DrNUL1 Proof Let.T];T[/`D, and let.uWp/2T].
By definition of proj, for each 1 DC4 i DC4 SUB.p/, the set proj.u;i/ forms a contiguous region of the sentence derived by T].
Using Lemma 6, we then see that down.u/ is distributed over at most SUB.u/ contiguous regions of that sentence.
This means that the dependency subtree rooted at anchor.p/ has at mostSUB.p/NUL1gaps.
Lemma 8 D.G/DC2 Dwn Proof Choose aD 2 D.G/, and assume thatD is not well-nested.
Then there is a governor u 2 D with two distinct dependents v;w such that #v contains tokens v1;v2, and #w contains tokens w1;w2 such that v1 RS w1 RS v2 RS w2.
For the derivation.T];T[/that inducesD, this means that there is a node .uWp/ with children .vWpv/ and .wWpw/inT] such that 9.v1;v2 2 down.v//W 9.w1;w2 2 down.w//W fL.v1/RSfL.w1/RSfL.v2/RSfL.w2/ inT[: Sincedown.v/anddown.w/aredisjoint;v1 andv2 must come from distinct convex blocks in down.v/, and w1 and w2 must come from distinct convex blocks in down.w/.
Therefore, v1 2 proj.v;i1/; v2 2 proj.v;i2/; i1 <i2 and w1 2 proj.w;j1/; w2 2 proj.w;j2/; j1 <j2: By definition, proj.x;k/(x 2 fv;wg) is the projection of a nodefI.x/k inT[; the label of this node is LHS.px/k.
Assume now that the non-terminal on the LHS of pv is V, and that the non-terminal on the LHS ofpw isW.
Given thatpv andpw are used to rewrite p, RHS.p/ contains the substring Vi1 SOHSOHSOHWj1 SOHSOHSOHVi2 SOHSOHSOHWj2.
This contradicts the fact that RHS.p/2 ESD.N;T/.
Lemma 9 Dwn \DrNUL1 DC2SG2Gr D.G/ Proof LetD D.W;!RS/be a dependency structure from Dwn \DrNUL1.
We construct anr-CCFG G D .N;T;P;S/that inducesD.
For the ranked alphabetN of non-terminals, put N D fNw jw 2W g; SUB.Nw/D gd.w/C1: The setS of start symbols is fN>g, where > is the root ofD.
For the terminal alphabet, putT DW.
The setP consists of jWj productions of the form Nw ! E˛, where w 2 W, and E˛ is a tuple with arity gd.w/C1 that contains the terminal w and non-terminal components for all children ofw as follows.
Consider the following family of sets: Cw D ffwgg[f#iv jw !v;1DC4i DC4 gd.v/C1g: All sets in Cw are disjoint, and their union equals the set #w.
We define a functionŒSOHc141that interprets the elements of Cw as elements from N [T as follows: Œfwgc141 WD w, and Œ#ivc141 WD Nvi . Now the RHS of a rule Nw ! E˛ is fully specified by the following equivalences, whereC 2 Cw: ŒCc141occurs in˛i iff C DC2 #iw ŒC1c141precedesŒC2c141in E˛ iff C1 STXC2 DC2 RS Applied to the dependency structure of Figure 3c, this constructs the given grammarGETX.
Note that, due to the well-nestedness ofD, the RHS of each rule forms a valid extended semi-Dyck word.
125 5 Summary Starting from the fact that TAG is able to derive well-nested dependency structures with a gap degree of at most1, we have investigated how multicomponent and multi-foot extensions of TAG alter this expressivity.
Our results are as follows: SI For multi-component TAG, the notion of ‘induced dependency structures’ depends on the assumed notion of lexicalization.
Therefore, either the same structures as in TAG, or arbitrary gap-bounded dependency structures are derivable.
In the former case, MCTAG has the same structural limits as standard TAG; in the latter case, even non-well-nested dependency structures are induced.
SI The multi-foot extension CCFG (and its equivalent RNRG) is restricted to well-nested dependency structures, but in contrast to TAG, it can induce structures with any bounded gap degree.
The rank of a grammar is an upper bound on the gap degree of the dependency structures it induces.
Since the extensions inherent to MCTAG and CCFG are orthogonal, it is possible to combine them: Multi-Component Multi-Foot TAG (MMTAG) as described by Chiang (2001) allows to simultaneously adjoin sets of trees, where each tree may have multiple foot nodes.
The structural limitations of the dependency structures inducible by MCTAG and CCFG generalize to MMTAG as one would expect.
As in the case of MCTAG, there are two different understandings of how a dependency structure is induced by an MMTAG.
Under the ‘one anchor per component’ perspective, MMTAG, just like CCFG, derives well-nested structures of bounded gap-degree.
Under the ‘one anchor per tree set’ perspective, just like MCTAG, it also derives non-well-nested gap-bounded structures.
Acknowledgements We thank Jan Schwinghammer, Guido Tack, and Stefan Thater for fruitful discussions during the preparation of this paper, and three anonymous reviewers for their detailed comments on an earlier version.
The work of Marco Kuhlmann is funded by the Collaborative Research Centre ‘Resource-Adaptive Cognitive Processes’ of the Deutsche Forschungsgemeinschaft.
References Naoki Abe.
1988. Feasible learnability of formal grammars and the theory of natural language acquisition.
In 12th International Conference on Computational Linguistics, pages 1–6, Budapest, Hungary.
Manuel Bodirsky, Marco Kuhlmann, and Mathias Möhl.
2005. Well-nested drawings as models of syntactic structure.
In Tenth Conference on Formal Grammar and Ninth Meeting on Mathematics of Language (FG-MoL), Edinburgh, UK.
David Chiang.
2001. Constraints on strong generative power.
In 39th Annual Meeting and Tenth Conference of the European Chapter of the Association for Computational Linguistics, pages 124–131, Toulouse, France.
Robert Frank.
2002. Phrase Structure Composition and Syntactic Dependencies.
MIT Press.
Jan Hajiˇc, Barbora Vidova Hladka, Jarmila Panevová, Eva Hajiˇcová, Petr Sgall, and Petr Pajas.
2001. Prague Dependency Treebank 1.0.
LDC, 2001T10.
GüntherHotzandGiselaPitsch. 1996.
Onparsingcoupled-context-free languages.
Theoretical Computer Science, 161:205–233.
Aravind K.
Joshi. 1985.
Tree adjoining grammars: How much context-sensitivity is required to provide reasonable structural descriptions?
In David R.
Dowty, Lauri Karttunen, and Arnold M.
Zwicky, editors, Natural Language Parsing, pages 206–250.
Cambridge University Press, Cambridge, UK.
Laura Kallmeyer.
2005. A descriptive characterization of multicomponent tree adjoining grammars.
In Traitement Automatique des Langues Naturelles (TALN),volume1, pages457–462, Dourdan, France.
Marco Kuhlmann and Joakim Nivre.
2006. Mildly non-projective dependency structures.
In 22nd International Conference on Computational Linguistics and 43rd Annual Meeting of the Association for Computational Linguistics (COLING-ACL), Companion Volume, Sydney, Australia.
Solomon Marcus.
1967. Algebraic Linguistics: Analytical Models, volume 29 of Mathematics in Science and Engineering.
Academic Press, New York.
Giorgio Satta.
1992. Recognition of linear contextfree rewriting systems.
In 30th Meeting of the Association for Computational Linguistics (ACL), pages 89–95, Newark, Delaware, USA.
David J.
Weir. 1988.
Characterizing Mildly ContextSensitive Grammar Formalisms.
Ph.D. thesis, University of Pennsylvania, Philadelphia, USA .

