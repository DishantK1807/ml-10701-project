In fact, Yarowsky (1992) falls below the baseline for one of the twelve words (issue), although perhaps, we needn't be too concerned about this one deviation.
C92-2070
Yarowsky, David (1992), "Word-Sense Disambiguation Using Statistical Models of Roget's Categories Trained on Large-Corpora," Proceedings COLING-92.
C92-2070
In fact, both Black (1988) and Yarowsky (1992) report 72% performance on this very same word.
C92-2070
Table 1 shows the performance of Yarowsky (1992) on twelve words which have been previously discussed in the literature.
C92-2070
We originally designed the experiment in Gale et al.(1992) to test the hypothesis that multiple uses of a polysemous word tend to have the same sense within a common discourse.
H92-1045
Dagan, Ido, Alon Itai, and Ulrike Schwall (1991), "Two Languages are more Informative than One," ACL, pp.
P91-1017
hope. Table 2: The Baseline Word Baseline Yarowsky (1992) issue 96% 94% duty 87% 96% galley 83% 99% star 83% 96% taste 74% 93% bass 70% 99% slug 62% 97% sentence 62% 98% interest 60% 72% mole 59% 99% cone 51% 77% bow 48% 91% AVERAGE 70% 92% As mentioned previously, the test words in Tables 1 and 2 were selected from the literature on polysemy, and therefore, tend to focus on the more difficult cases.
C92-2070
Brown, Peter, Stephen Della Pietra, Vincent Delia Pietra, and Robert Mercer (1991), "Word Sense Disambiguation using Statistical Methods," ACL, pp.
P91-1034
Yarowsky (1992) inputs a 100-word context surrounding a polysemous word and scores each of the 1042 Roget Categories by: 1-\[ Pr(wlRoget Categoryi) w in context The program can also be run in a mode where it takes unrestricted text as input and tags each word with its most likely Roget Category.
C92-2070
Fortunately, we have found in (Gale et al., 1992) that the agreement rate can be very high (96.8%), which is well above the baseline, under very different experimental conditions.
H92-1045
Recently, Yarowsky (1992) has found a way to extend our use of the Bayesian techniques by training on the Roget's Thesaurus (Chapman, 1977) 2 and G-rolier's Encyclopedia (1991) instead of the Canadian Hansards, thus circumventing many of the objections to our use of the Hansards.
C92-2070
The recent interest in computational lexicography has fueled a large body of recent work on this 40-year-old problem, e.g., Black (1988), Brown et al.(1991), Choueka and Lusignan (1985), Clear (1989), Dagan et al.(1991), Gale et al.(to appear), Hearst (1991), Lesk (1986), Smadja and McKeown (1990), Walker (1987), Veronis and Ide (1990), Yarowsky (1992), Zemik (1990, 1991).
C90-2067 C92-2070 P90-1032 P91-1017 P91-1034
27) 251 Table 1: Comparison over Systems Word Yarowsky (1992) Previous Systems bow 91% < 67% (Clear, 1989) bass 99% 100% (Hearst, 1991) galley 99% 50-70% (Lesk, 1986) mole 99% N/A (Hirst, 1987) sentence 98% 90% (Gale et al).
C92-2070
Gale, William, Kenneth Church, and David Yarowsky (1992) "One Sense Per Discourse," Darpa Speech and Natural Language Workshop.
C92-2070 H92-1045
Much of this work offers the prospect that a disambiguation system might be able to input unrestricted text and tag each word with the most likely sense with fairly reasonable accuracy and efficiency, just as part of speech taggers (e.g., Church (1988)) can now input unrestricted text and assign each word with the most likely part of speech with fairly reasonable accuracy and efficiency.
A88-1019
Church, Kenneth (1988), "A Stochastic Parts Program an Noun Phrase Parser for Unrestricted Text," Applied ACL Conference, Austin, Texas.
A88-1019
Veronis, Jean and Nancy Ide (1990), "Word Sense Disambiguation with Very Large Neural Networks Extracted from Machine Readable Dictionaries," in Proceedings COLING-90, pp 389-394.
C90-2067
Many of the systems mentioned in Table 2 including Yarowsky (1992) do not currently take advantage of the prior probabilities of the senses, so they would be at a disadvantage relative to the baseline if one of the senses had a very high prior, as is the case for the test word issue.
C92-2070
