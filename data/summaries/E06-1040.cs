M.E.FosterandJ.Oberlander. 2006.
E06-1045
The BLEU metric (Papineni et al., 2002) in MT has been particularly successful; for example MT05, the 2005 NIST MT evaluation exercise, used BLEU-4 as the only method of evaluation.
P02-1040
Indeed NLG researchers are already starting to use BLEU (Habash, 2004; Belz, 2005) in their evaluations, as this is much cheaper and easier to organise than the human evaluations that have traditionally been used to evaluate NLG systems.
W05-1601
Corpus Linguistics 2003, pages 734–743.
N03-1020
Properly calculated BLEU scores have been shown to correlate reliably with human judgments (Papineni et al., 2002).
P02-1040
While studies have shown that ratings of MT systems by BLEU and similar metrics correlate well with human judgments (Papineni et al., 2002; Doddington, 2002), we are not aware of any studies that have shown that corpus-based evaluation metrics of NLG systems are correlated with human judgments; correlation studies have been made of individual components (Bangalore et al., 2000), but not of systems.
P02-1040 W00-1401
Some NLG researchers are impressed by the success of the BLEU evaluation metric (Papineni et al., 2002) in Machine Translation (MT), which has transformed the MT field by allowing researchers to quickly and cheaply evaluate the impact of new ideas, algorithms, and data sets.
P02-1040
FosterandOberlander (2006), intheirstudyof facial gestures, have also noted that humans do not mind and indeed in some cases prefer variation, whereas corpus-based evaluations give higher ratings to systems which follow corpus frequency.
E06-1045
The ROUGE metric (Lin and Hovy, 2003) was conceived asdocument summarisation’s answer to BLEU, but it does not appear to have met with the same degree of enthusiasm.
N03-1020
Similar evaluations have been used e.g. by Bangaloreetal.(2000) andMarciniak andStrube(2004).
W00-1401
BLEU’s ability to detect subtle but important differences in translation quality has been questioned, some research showing NIST to be more sensitive (Doddington, 2002; Riezler and Maxwell III, 2005).
W05-0908
We used approximate randomisation (AR) as our significance test, as recommended by Riezler and Maxwell III (2005).
W05-0908
Moreover, the only type of language model used in NLG are ngram models which have the additional disadvantage of a general preference for shorter realisations, which can be harmful in NLG (Belz, 2005).
W05-1601
Thismethodology was first used in NLG in the mid-1990s by Coch (1996) and Lester and Porter (1997), and continues to be popular today.
C96-1043 J97-1004
The greedy modes are deterministic and therefore considerably cheaper in computational terms than the equivalent n-gram method (Belz, 2005).
W05-1601
