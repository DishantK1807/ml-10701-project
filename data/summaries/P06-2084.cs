Several researchers also attempted to compare existing methods and suggest different evaluation schemes, e.g Kita (1994) and Evert (2001).
P01-1025
Preliminary results of our research were already published in Pecina (2005).
P05-2003
They have a wide spectrum of applications in the field of natural language processing and computational linguistics such as automatic collocation extraction (Manning and Schütze, 1999), bilingual word alignment (Mihalcea and Pedersen, 2003) or dependency parsing.
W03-0301
We, however, must agree with Moore (2004) arguing that these cases comprise majority of all the data (the Zipfian phenomenon) and thus should not be excluded from real-world applications.
W04-3243
Evert (2001), suggest using precision – fraction of positive predictions correct and recall – fraction of positives correctly predicted.
P01-1025
By determining the entropy of the immediate context of a word sequence (words immediately preceding or following the bigram), the association measures (56–60) rank collocations according to the assumption that they occur as (syntactic) units in a (information-theoretically) noisy environment (Shimohata et al., 1997).
P97-1061
Moore. 2004.
W04-3243
3.2 Precision-recall curves Since choosing a classification threshold depends primarily on the intended application and there is no principled way of finding it (Inkpen and Hirst, 2002), we can measure performance of association measures by precision–recall scores within the entire interval of possible threshold values.
W02-0909
