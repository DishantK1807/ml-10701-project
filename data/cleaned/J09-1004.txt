TheComplexityofRankingHypothesesin
OptimalityTheory
JasonRiggle
∗
UniversityofChicago
Given a constraint set with k constraints in the framework of Optimality Theory (OT), what is
its capacity as a classiﬁcation scheme for linguistic data? One useful measure of this capacity
is the size of the largest data set of which each subset is consistent with a different grammar
hypothesis.This measure is known as the Vapnik-Chervonenkis dimension (VCD) and is a
standard complexity measure for concept classes in computational learnability theory.In this
work, I use the three-valued logic of Elementary Ranking Conditions to show that the VCD of
Optimality Theory with k constraints is k−1.Analysis of OT in terms of the VCD establishes
that the complexity of OT is a well-behaved function of k and that the ‘hardness’ of learning in
OT is linear in k for a variety of frameworks that employ probabilistic deﬁnitions of learnability.
1.Introduction
Given a set CON of k constraints in the framework of Optimality Theory (OT; Prince
andSmolensky1993),whatisthecapacityofCONasaclassiﬁcationschemeforsamples
oflanguagedata?InOT,constraintsarefunctionsthatmapcandidatestonaturalnum-
bers,whereeachcandidateisamemberofthe(possiblyinﬁnite)setofpossiblederiva-
tions of an input form i supplied by the candidate generating function GEN(i). The
number that a constraint C
i
assigns to a candidate indicates how many times that
candidate violates C
i
. A grammar is a ranking of the constraints that imposes a total
ordering on CON, R
CON
(or simply R when CON is clear from the context), andthe
language that is generatedby grammar R is the set of candidates that are optimal
accordingtoRasinDeﬁnition1.
Deﬁnition1
a. Candidate a ismoreharmonicthancandidate b accordingtoR,written afollowsb,
iftheysharethesameinputand a isassignedfewerviolationsbythehighest-
rankedconstraintthatassignsdifferentnumbersofviolationsto a and b.
b. CandidateaisoptimalaccordingtorankingRiffnoothercandidategenerated
byGENismoreharmonicthan a.
Because each of the k! rankings of CON is a different grammar that generates a
potentiallyuniquelanguage,onenaturalmeasureoftheclassiﬁcatorycapacityofCON
∗ DepartmentofLinguistics,UniversityofChicago,1010E.59thSt.,Chicago,IL60637.
jriggle@uchicago.edu.ManythankstoAlanPrince,JeffHeinz,GregKobele,ColinWilson,andtwo
anonymous Computational Linguistics reviewersforhelpfulcommentsandsuggestions.Anyerrorsare,of
course,myown.
Submissionreceived:22December2006;revisedsubmissionreceived:9October2007;acceptedfor
publication:17December2007.
©2009AssociationforComputationalLinguistics
ComputationalLinguistics Volume35,Number1
istheupperboundof k!languagesinwhatPrinceandSmolensky(1993,page27)dub
thefactorialtypologyoftheconstraintset.Anothercomplexitymetricthatisusefulin
analyses of learnability (especially for non-ﬁnite concept classes) is the cardinality of
thelargestdatasetofwhicheachsubsetcorrespondstoadifferentrankinghypothesis.
The idea of measuring the complexity of a concept class (in the case at hand, a set of
grammars)inthiswaycomesfromtheworkofVapnikandChervonenkis(1971)andis
knownastheVapnik-Chervonenkis dimension(VCD).InOT,theVCDofaconstraint
set CON(i.e.,theconceptclassconsistingoflanguagesgeneratedbyrankingsof C ON)
isthesizeofthelargestsample(setofcandidates)thatisshatterableasinDeﬁnition2.
Deﬁnition2
AsampleSisshatterablebyaconstraintsetCONiff,foreverypartitioningofSintotwo
disjointsets T and F (includingthenull/wholepartition),thereisatleastoneranking
R
CON
thatmakesevery s ∈ T optimalbutno s ∈ F optimal.
VapnikandChervonenkis’sdeﬁnitionofshatterabilityhasinterestingimplications
for samples consisting of OT candidates. For instance, each candidate in a shatterable
sample S must be an input → output mapping for a unique input form because two
candidates a and b withthesameinputwouldeither tie withidenticalsetsofviolations
orshowharmonicinequality.Inthecaseofatie,norankingcouldrealizeapartitioning
thatseparates a and b and,inthecaseofharmonicinequality,norankingcouldrealize
a partitioning in which a and b are simultaneously optimal. More generally, the VCD
placesanupperboundonthenumberofdistinctgrammarhypothesesthatcanbereal-
izedoveranysampleoflinguisticdataconsistingofOTcandidates,andthusprovides
areadymeasureofthecomplexityofthehypothesisspaceinOptimalityTheory.
The VCD of a concept class is obviously not independent of its size. As Blumer
et al. (1989) point out, for any ﬁnite concept class C, the VCD is bounded at log
2
|C|
becauseittakesatleast2
d
hypothesestoassociateauniquehypothesiswitheverysub-
set of a sample of size d. Thus, because the number of grammars (hypotheses) over
k constraints is ﬁnite—one grammar for each of the k! rankings—the VCD of OT is
bounded at log
2
k!. Or, put more simply, because log
2
x!≤ xlog
2
x, this establishes
k log
2
k as an upper boundon the VCD of OT. In this article, I will show how the
structure of the hypothesis space in Optimality Theory provides a tighter bound on
the VCD of OT than the boundestablishedby the ﬁnitude of the hypothesis space. I
willimproveupontheinherentboundof k log
2
k byshowingthattheVCDofOTwith
k constraintsisactuallyboundedatk −1andthusgrowslinearlywiththesizeof |CON|.
ThecomplexitymeasuredbytheVCdimensionhasanumberoframiﬁcationsfor
learninginOptimalityTheory.Forinstance,theVCDofaconceptclassplacesanabso-
lutelowerboundonthenumberofmistakesthatanyerror-driven learningalgorithm
can be guaranteedof achieving (Littlestone 1988). This fact tells us that it may yet
be possible to improve upon the quadratic mistake bound of (k
2
− k)/2 for Recursive
Constraint Demotion (Tesar andSmolensky 1993, 2000; Tesar 1995, 1997, 1998), the
reigning mistake boundfor any OT learning algorithm. The VCD of a concept class
alsoprovidesaverygeneralboundonthenumberofdatasamplesthatarerequiredfor
learninginprobabilisticmodelsoflearningthatwillbediscussedinSection5.
2.ElementaryRankingConditions
The main result for the VC dimension of OT will be given in Section 4. First, some
supportingresultswillbeestablishedshowingthatthereisanupperboundof k −1on
48
Riggle RankingHypothesesinOT
shatterablesetsofstatementsaboutconstraintrankingsthatareexpressedwithPrince’s
(2002)ElementaryRankingConditions.
If our sample space X consists of candidates, then any x ∈ X can be described
in terms of the set of constraint rankings under which x is optimal. Prince (2002)
providesaschemeforencodingthiskindofrankinginformationcalledanElementary
RankingCondition(ERC).Inthissection,IwillreviewsomeformalpropertiesofERCs
that are relevant for establishing the VC dimension of OT. Prince demonstrates many
formalpropertiesofERCsbeyondthosecoveredhereandshowsthatERCSareequiv-
alenttotheimplication-negationfragmentofthethree-valuedrelevancelogicRM3(cf.
AndersonandBelnap1975).ThissectionwillreviewpropertiesofERCsthataremost
relevantfortheresultsathand.Forformalproofsandacompleteexpositionofthelogic
ofERCs,seePrince(2002).
For a constraint set CON containing k constraints, ERCs are k-length vectors that
use the symbols L, e,andW to encode logical statements about rankings. Each con-
straintisassignedanarbitrarynumericindex,andineachERC α,thei
th
coordinate α
i
refers to the constraint with i
th
index C
i
. The meaning of an ERC is that at least one
constraintwhosecorrespondingcoordinatecontainsa W outranks all oftheconstraints
whosecoordinates contain L’s.Thus, 〈W, e, L, L〉 meansthat C
1
outranksboth C
3
and
C
4, while 〈L, L, W, W〉 means that either C
3
or C
4
outranks both C
1
and C
2
. ERCs can
beconstructedbycomparingcandidatesasinDeﬁnition3.NotethatC
i
(a)denotesthe
numberoftimescandidate a violatestheconstraintwithindex i.
Deﬁnition3
Given a constraint set CON with k constraints indexed {1...k} and two candidates
that share the same input, the function erc
CON
(a,b) returns an ERC α =〈α
1,...,α
k
〉 that
describestherankingsunderwhich afollowsb.
1
erc(a,b)=〈α
1,...,α
k
〉where





α
i
= W ifC
i
(a) < C
i
(b)
α
i
= L ifC
i
(a) > C
i
(b)
α
i
= e ifC
i
(a)= C
i
(b)
The symbol W in α
i
of erc(a,b)= α is a mnemonic for the fact that C
i
favors a
(the winner), whereas an L in coordinate i is a mnemonic for the fact that C
i
favors b
(the loser).An e inα
i
indicatesthatthecandidatesare equivalent accordingtoC
i
.
Example1
input C
1
C
2
C
3
cand. a * ** * erc(b,a)=〈L,W, W〉= bfollowsa ifC
2
orC
3
outranksC
1
cand. b ** * erc(a,b)=〈W,L, L〉= afollowsb ifC
1
outranksC
2
andC
3
(*’sindicatenumberofviolations)
Note the symmetry between erc(a,b)=〈W,L, L〉, which says that candidate a is more
harmonic than b under any ranking where C
1
outranks both C
2
and C
3,anderc(b,a),
1 Thefunction
erc
CON
(a,b),orsimply erc(a,b)whenCONisclearfromcontext,isundeﬁnedforcandidate
input → output mappingswithdifferentinputsbecausetheycannotbemeaningfullycompared.
49
ComputationalLinguistics Volume35,Number1
which says that b is more harmonic than a under any ranking where either C
2
or C
3
outranksC
1
.Thissymmetryreﬂectsthefactthat erc(a,b)anderc(b,a)encodeantithetical
rankingconditions.TheoppositionbetweentheseERCsfollowsstraightforwardlyfrom
thefactthatonlyoneofthetwocandidatescanbeoptimalunderanygivenranking.
The illustrative tableaux presentedwith OT analyses can be turnedinto sets of
ERCs by making pairwise comparisons between the violations for one designated (or
observed)winnerandtheviolationsforeachothercandidate.
Example2
input C
1
C
2
C
3
cand.a * ** winner
cand. b ** * erc(a,b) =〈W,L, e〉 = afollowsb ifC
1
outranksC
2
cand. c * ** erc(a,c) =〈e, L,W〉 = afollowsc ifC
3
outranksC
2
cand. d * * * erc(a,d)=〈e, L,W〉 = afollowsd ifC
3
outranksC
2
cand. e ** ** erc(a,e) =〈W, e, e〉 = afollowse undereveryranking
cand. f *** * erc(a,f) =〈L,W,W〉= afollowsf ifC
2
orC
3
outranksC
1
The comparison of candidate a with candidate e in Example 2, erc(a,e)=〈W, e, e〉,
yieldsanoddrankingconditionthatdoesnotactuallyexpressaparticularranking(no
constrainthasan L),butinsteadindicatesthat C
1
favorscandidate a andnoconstraint
favors candidate e. In this case, candidate e is saidto be harmonically bounded by
candidate a because there can be no ranking under which e is more harmonic than
a. Conversely, if candidate e were designated the winner, then erc(e,a)=〈L, e, e〉.This
ERCalsodoesnotencodeaspeciﬁcranking,butratherindicatesthatthemereexistence
ofcandidate a asanalternativemeansthatnorankingcanmakecandidate e optimal.
LikemostOTtableaux,Example2isanillustrationofhowahandfulofcandidates
fare with respect to one another according to a particular set of constraints. To know
which rankings (if any) make candidate a globally optimal, it wouldbe necessary to
deﬁnethecandidategeneratingfunctionGENinordertoobtainarepresentationofthe
entire set of ERCs {erc(a,x)| x ∈ GEN(input)}= ERCS(a). This is not as daunting as it
mightappearbecause,eventhough|GEN(input)|maybeinﬁnite,thefactthatthenum-
berof k-lengthERCsisﬁniteguaranteesthateachofthecandidatesinGEN(input)will
maptooneofaﬁnitenumberofERCsets.Furthermore,asRiggle(2004)demonstrates,
the standard OT assumption of the universality of faithfulness constraints that pe-
nalize changes to the input guarantees that all but ﬁnitely many of the members of
GEN(input)willbeharmonicallybounded.Rigglealsopresentsanalgorithmforcom-
putingthisﬁnitesetofcontenders(i.e.,candidatesthatarenotharmonicallybounded)
that can be usedin cases where G EN is restrictedso that it is a rational function.
2
Regardless of how optimization is computed, what is relevant for the assessment of
theVCDofOTisthedeﬁnitionofoptimality.FollowingDeﬁnition1,arankingR
CON
can
be seen as a function from candidates to True (if they are optimal) or False (if they are
2GENisrationalifitisrepresentableasaﬁnitestatetransducer.Riggle’s(2004)CONTENDERSalgorithmis
anextensionofEllison’s(1994)applicationofDijkstra’s(1959)“shortestpaths”algorithmtooptimization
inOTthatoperatesoverﬁnite-staterepresentationsofGENandE VAL.Ellisonshowedthatifharmonyis
usedasthe“distance”tobeoptimized,thenoptimaloutputscanbeefﬁcientlyfound.TheCONTENDERS
algorithmfollowsasimilarstrategybut,insteadofﬁndingtheshortest(i.e.,mostharmonic)pathforone
ranking,thealgorithmﬁndsallnon-harmonically-boundedpathsandtherebyoptimizesforallrankings.
50
Riggle RankingHypothesesinOT
not). The entire ERC set for a candidate ERCS(a) describes exactly the rankings under
whichcandidate a isagloballyoptimalcandidate.
ThereductionofcandidatestoERCsetsmakesitpossibletousethelogicofERCs
toreasonaboutcandidates.Mostofthetime,theERCsofinterestarethosethatcontain
at least one L andone W—what Prince calls nontrivial ERCs. ERCs that contain W’s
butno L’saregeneratedwhenacandidateiscomparedwithanothercandidatethatit
harmonically bounds, such as erc(a,e)=〈W, e, e〉 in Example 2. This ERC reveals that
candidate e cannot be optimal but yields no information about what rankings make
candidate a optimal. Similarly, no ranking information can be gleanedfrom the alle
ERC that results from comparing “tied” candidates that have the same violations.
Finally,ERCslike erc(e,a)=〈L, e, e〉,withL’sbutno W’srevealnothingotherthanthe
factthatcandidate e cannotbeoptimalunderanyranking.
The most relevant logical relation for ERCs is that of entailment. The entailment
relation among nontrivial ERCs is given in Deﬁnition 4 (Prince 2002, page 6, Proposi-
tion1.1).
Deﬁnition4
FornontrivialERCsαandβ,α → βiffeachα
i
∈ αentailsβ
i
∈ βwhere L → e → W.
BecausenontrivialERCsencodedisjunctionsofconjunctions(i.e.,[C
1
or...C
n
]outranks
[C
1
prime and... C
n
prime]),entailmentsoftheform α → β lineupwiththelogicaloperationsof
disjunctionintroduction(wheneverβhas W whereαhasan L oran e)andconjunction
elimination(wheneverβhasan e whereαhasan L).
Example3
〈W,L,L,e〉→〈W,e,L,e〉 i.e.,IfC
1
outranksC
2
andC
3
thenC
1
outranksC
3
.
〈W,e,L,e〉→〈W,e,L,W〉 i.e.,IfC
1
outranksC
3
thenC
1
orC
4
outranksC
3
.
〈W,L,L,e〉→〈W,e,L,W〉 i.e.,IfC
1
outranksC
2
andC
3
thenC
1
orC
4
outranksC
3
.
Inadditiontorevealingentailmentsamongindividualrankingconditions,thelogic
of ERCs makes it possible to derive new ranking conditions that are entailed by the
combination of other ERCs. Prince (2002, page 8) provides a logical operation called
fusionthatderivesentailmentsfromsetsofERCs.
Deﬁnition5
ThefusionofERCsetΦisasingleERCφ thatisentailedby Φwhere:
φ
i
= L ifanyERCinΦhasan Linits i
th
coordinate,
φ
i
= e ifeveryERCinΦhasan e inits i
th
coordinate,
φ
i
= Wotherwise.
Every ERC entailedby Φ is entailedby the fusion of a subset of Φ (Prince 2002,
page14).Thus,theoperationoffusioncanrevealnonobviousentailmentsamongERCs.
ConsiderΦ={〈W,W,e,L〉,〈L,W,W,e〉,〈W,e,L,W〉}.TheERCsinΦdenote,respectively,
“C
1
orC
2
outranksC
4,”“C
2
orC
3
outranksC
1,”and“C
1
orC
4
outranksC
3
.”Thefusion
ofΦis〈L,W,L,L〉,whichencodestheinferencefromΦthatC
2
outranksC
1,C
3,andC
4
.
The operation of fusion can also reveal inconsistencies in ERC sets. Consider the
setΨ={〈W,L,W〉,〈L,W,W〉,〈W,W,L〉}.FusingΨyields 〈L,L,L〉.Aswithharmonically
bounded candidates, this ERC shows that no constraint ranking is consistent with
the statements in Ψ (in fact, they are circular). Prince refers to the class of ERCs with
51
ComputationalLinguistics Volume35,Number1
L’s but no W’s as L
+
. He shows that these ERCs arise from fusion if andonly if the
fusedsetcontainsincompatiblerankingconditions.
Deﬁnition6
An ERC set is consistent iff it has no subset that fuses to an ERC in L
+
(Prince 2002,
page11).
For any consistent ERC set there is a constraint ranking (often several) of which
all of its ERCs are true statements (Prince 2002, page 21). The ERCs in an inconsistent
set,ontheotherhand,canneverallbetrueofasingleranking.Inconsistencycanarise
fromasinglepairofcandidates(e.g., ERCS(e)inExample2contains erc(e,a)=〈L,e,e〉).
Inconsistency can also arise across multiple candidate comparisons (e.g., ERCS(d)in
Example 2 contains erc(d,a)=〈e,W,L〉 and erc(d,c)=〈e,L,W〉). This latter type of in-
consistency, where several of the ERCs associated with a candidate fuse to L
+,arises
from what Samek-Lodovici and Prince (1999) call collective harmonic bounding.
Finally, it is possible for inconsistencies to arise when ERCs for several candidates
with distinct inputs are combined. For example, if ERCS(x)={〈W,L,W〉}, ERCS(y)=
{〈L,W,W〉},andERCS(z)={〈W,W,L〉}then,eventhough x, y,andz maybecandidates
for distinct inputs (i.e., come from different tableaux), the union of their ERCs fuses
to 〈L,L,L〉∈L
+
andthereby reveals that there is no ranking under which all three
candidatesaresimultaneouslyoptimal.
InvertingtheW’sandL’sofanERCproducesitsantitheticalcounterpartthatistrue
whenevertheoriginalERCisfalseandviceversa.Thisoppositioncanbeexploitedin
describingtherangeofconsistentERCsets.
Deﬁnition7
Thenegationofαisαwhere:α
i
= Wifα
i
= L, α
i
= Lifα
i
= W,andα
i
= e ifα
i
= e.
Provided that α is not all e’s,every ranking isdescribed byeither α or α but not both
(Prince2002,page42).Inthisway,ERCnegationisjustthestandardnotionofnegation
in three-valuedlogics. The opposition between α and α makes a binary partition on
thespaceofrankings.Thisisintuitivelyobviousforsimplestatementslike〈W,L,e〉and
〈L,W,e〉.Theoppositionisabitlessintuitiveformorecomplexconditionslike〈W,L,L〉
and 〈L,W,W〉,butthefactthat erc(a,b)istheantithesisof erc(b,a)makesitabundantly
clear(i.e.,if a and b arenottied,theneveryrankingmustpreferoneortheother).The
antithetical relationship between an ERC andits negation is reﬂectedin the operation
offusionbythefactthatfusingantitheticalERCswillalwaysyieldanERCin L
+
.
3.TheVCDofElementaryRankingConditions
BeforeturningtothequestionoftheVCdimensionofthesamplespaceinOT,itwillbe
helpfultodeﬁneshatterabilitypurelyintermsofERCsandtherebytoestablishabound
ontheVCDofsetsofERCs.WewillsaythatanERC α istrueofagivenranking R if
the condition imposed by α is consistent with the linear ordering of the constraints
deﬁnedbyR.
Deﬁnition8
AnERCsetΩoverconstraintsCONisshatterableiffforeverysubset∆⊆Ω,thereisa
rankingR
CON
ofwhichallERCsinΩ–∆aretruewhilealltheERCsin∆arefalse.
52
Riggle RankingHypothesesinOT
FromthisdeﬁnitionofshatterabilityforsetsofERCs,itisimmediatelyclearthatonly
nontrivialERCscanoccurinshatterablesets.
Lemma1
EveryERCinashatterablesetmustcontainatleastone Landone W.
Proof:TheERCsofL
+
cannot occur in a shatterable set because there is no ranking
of which they are true. Conversely, ERCs with no L’s cannot occur in shatterable sets
becausethereisnorankingofwhichtheyarefalse. square
WithDeﬁnition8inhand,andhavingexcludedthetrivialERCsfromthepicture,
it will be possible to reduce shatterability for ERC sets to consistency under negation.
First,adeﬁnitionofnegationforsetsofERCs.
Deﬁnition9
A partial negation ofERCsetΩisobtainedbynegatingeveryERCinasubset ∆⊆Ω.
Forexample:Ω={〈W,L,L〉,〈e,W,L〉}hasfourpartialnegations:onepersubset.
braceleftBigg
α =〈W,L,L〉
γ =〈e,W,L〉
bracerightBiggbraceleftBigg
α =〈L,W,W〉
γ =〈e,W,L〉
bracerightBiggbraceleftBigg
α =〈W,L,L〉
γ =〈e,L,W〉
bracerightBiggbraceleftBigg
α =〈L,W,W〉
γ =〈e,L,W〉
bracerightBigg
Theorem1
AnERCsetΩisshatterableiffeverypartialnegationofΩisconsistent.
Proof:SupposeeverypartialnegationofΩisconsistent.Thus,foranypartialnegation
in which ∆ is the negatedsubset of Ω and Γ is the rest of Ω, it is the case that there
is a ranking R of which all the ERCs of ∆+Γare true. Because a nontrivial ERC and
its negation are never both true of the same ranking andtrivial ERCs cannot occur in
shatterablesets,theERCsinΩ−ΓarefalseofrankingRwhiletheERCsofΓaretrue.
Because ∆ was arbitrary, it is the case that for every subset of Ω, there is a ranking of
which the ERCs in that subset are false while the rest are true, andthus consistency
under partial negation is sufﬁcient for shatterability. If, on the other hand, there is a
partialnegationthatisnotconsistent,thenthereisasubsetofΩsuchthatiftheERCs
inthatsubsetarenegated,theresulting∆+Γisnotconsistent.However,becausethere
is no ranking of which the members of an inconsistent ERC set are all true, Ω is not
shatterablebecausethereisnorankingofwhichtheERCsinΓaretruewhiletheERCsin
Ω−Γarefalse.Thus,consistencyunderpartialnegationisbothnecessaryandsufﬁcient
forshatterability. square
Corollary1
EverysubsetofashatterableERCsetisitselfshatterable.
Proof: Because each partial negation of a shatterable ERC set must, by deﬁnition, be
consistentandbecauseeverysubsetofaconsistentsetmustalsobeconsistent,itisthe
casethateverysubsetofashatterablesetisconsistentundereverypartialnegationand
isthusshatterable. square
Deﬁningshatterabilityintermsofpartialnegationlinesupwiththecommonsense
observationthatnosetcontainingαandγwhereα → γisshatterablebecausetherecan
benorankingofwhichtheformeristruewhilethelatterisfalse.Thisisneatlycaptured
by the fact that if α → γ, no superset of {α,γ} can be shatteredbecause fusing {α,γ}
is guaranteedto yieldan ERC in L
+
. The requirement of consistency under partial
negationalsoshowswhyrelativelyweakconditionslike〈W,W,L〉and〈W,L,W〉cannot
co-occurinshatterablesetseventhoughneitherentailstheother.Inthiscase,fusingthe
53
ComputationalLinguistics Volume35,Number1
negationofbothERCsyields〈L,L,L〉∈L
+
.Thisfollowstransparentlyfromthefactthat
eitherthestatement”C
1
orC
2
outranksC
3
”orthestatement”C
1
orC
3
outranksC
2
”is
trueofanyrankingofthreeconstraints.
The deﬁnition of shatterability for ERC sets in terms of consistency under partial
negation makes it easy to demonstrate that for |CON|= k, there are shatterable ERC
setsofsize k −1.DiagonalERCsetsprovideaparticularlysimpleexampleofaclassof
shatterableERCsetsofthissize.
Deﬁnition10
ERCsetΩisdiagonalifitsmemberscanbegiven
as a list L
Ω
in which each n
th
ERC in the list has a
Winits n
th
coordinate,anLinits n +1
th
coordinate,
and e’severywhereelse.
E.g.,Ω=







〈W, L, e, e, e〉
〈e, W, L, e, e〉
〈e, e, W, L, e〉
〈e, e, e, W, L〉







Lemma2
DiagonalERCsetsareshatterable.
Proof:AssumethatΩisadiagonalERCsetandΩ
prime
isanarbitrarysubsetofanarbitrary
partialnegationofΩ.Ifn isthenumberofERCsinΩ
prime
then,bythedeﬁnitionofdiagonal
ERC sets, there must be at least n +1 coordinates (columns) in Ω
prime
that are ﬁlledwith
L or W forsomeERCinΩ
prime
(i.e.,arenotall-e columns).Becauseeachofthe n ERCshas
onlyone L,atmostn columnscontain L’s,thusthefusionofΩ
prime
containsatleastone W.
BecauseΩ
prime
wasanarbitrarysubset,nosubsetfusestoL
+
.Becausethepartialnegation
wasarbitrary,everypartialnegationisconsistentandthus Ωisshatterable. square
FromtheshatterabilityofdiagonalERCsets(with k −1membersif|CON|= k),we
obtain a lower boundof k −1 on the VCD of ERC sets. Having establishedthat there
areshatterablesetsof k-lengthERCswith k −1members,whatremainstobeshownis
thatnosetlargerthan k −1isshatterable.
Deﬁnition11
CoordinateC
i
is W-uniqueinERCsetΦifΦhasapartialnegationΦ
prime
suchthatinthe
fusionofΦ
prime,φ =〈φ
1,...,φ
k
〉,theonlycoordinatethatcontainsa Wisφ
i
.
Deﬁnition12
TheminorΩ
α,j
ofanERCsetΩisanewsetΩ
prime
inwhichERCαhasbeenremovedand
the j
th
coordinatehasbeenremovedfromtheremainingERCs.
Forexample,ifΩ=







α : 〈L, L, W, e, W〉
β : 〈e, e, e, L, W〉
γ : 〈e, e, W, L, e〉
δ : 〈L, W, e, e, e〉







thenΩ
γ,3
=



α : 〈L, L, e, W〉
β : 〈e, e, L, W〉
δ : 〈L, W, e, e〉



As illustratedin Deﬁnition 12, the term “minor” usedhere is analogous to the
standard notion of the minor of a matrix. It is straightforward to show that every
shatterableERCsetcontainsshatterableminorsthatcanbeobtainedbyremovingone
constraint’scoordinate(column)andoneERC(row).
Lemma3
Reduction Lemma.–IfΩisashatterableERCset,thenithasashatterableminorΩ
α,j
.
54
Riggle RankingHypothesesinOT
Proof: By Corollary 1, for any α ∈Ω, Ω−{α} is shatterable. In Ω−{α} there must
be at least one coordinate C
j
that is not W-unique. If this were not the case and every
coordinateinΩ−{α} was W-unique,thenoneofthe L’sin α wouldoccludetheonly
W in a partial negation of Ω, making it inconsistent contra the assumption that Ω is
shatterable (α must have at least one L by Lemma 1). Because C
j
is not W-unique, for
every partial negation of every subset of Ω−{α}, there is a coordinate other than C
j
thatfusesto W.Thisbeingthecase,shatterabilityispreservedif C
j
iseliminated.Thus,
theminorΩ
α,j
isshatterableasrequired. square
Theorem2
For k > 1,thelargestshatterablesetof k-lengthERCshas k −1members.
Proof:Ifx is the size of the largest shatterable set of k-length ERCs and y is the size of
the largest shatterable set of (k +1)-length ERCs, then y is not greater than x +1. This
must be so because if y ≥ x +2 then x couldnot be the size of the largest shatterable
set of k-length ERCs because a set of (k +1)-length ERCs wouldhave a shatterable
minor larger than x. Because 〈W,L〉 and 〈L,W〉 are the only nontrivial ERCs for k =2
andbecause they are antithetical andthus cannot co-occur in a shatterable set, the
largestshatterableERCsetat k =2consistsofasingleERC.Thisbasecaseestablishes
anupperboundof k −1onthesizeofshatterableERCsetsandthediagonalERCsets
provide a lower bound of k −1. Together these bounds place the cardinality of the
largestshatterablesetatexactly k −1. square
AlongwiththediagonalERCsets,therearemanyshatterableERCsetswith k −1
members,butnoshatterablesetswithmorethan k −1members.Whatremainsnowis
toconnectthisresultforERCsetsbacktotherealmofcandidates.
4.TheVCDofOptimalityTheory
The question posedat the outset of this article was: for a constraint set C ON with k
constraintsthatmapcandidatestonaturalnumbers,whatisthecardinalityofthelargest
set of candidates S such that, for each subset T ⊆ S, there is at least one ranking R
CON
under which every t in T is optimal, but no s in S − T is optimal? Clearly, the answer
to this question depends greatly on details of the constraints in CON. However, if we
reducecandidatestotheERCsetsassociatedwiththem,itispossibletoplaceanupper
boundonthesizeof S withoutknowinganythingaboutCONotherthanitssize k.
Recallthatacandidate c ismappedto True byranking R
CON
justincaseeveryERC
in ERCS(c)isconsistentwithR.Conversely, c ismappedto False byRifanyoftheERCs
in ERCS(c) is not consistent with R. Thisnotion can be extended to sets of candidates
asfollows.If S isasetofcandidates,then ERCS(S)istheunionofERCS(s)forall s ∈ S.
AsampleSisacceptedbyrankingRjustincaseeveryαinERCS(S)isconsistentwithR.
Conversely,SisrejectedbyRifanyαinERCS(S)isnotconsistentwithR.Furthermore,
if ERCS(S) is consistent, then there must be at least one ranking that accepts S.Inthis
case, we will refer to S as a consistent sample. The concepts of partial negation and
W-uniquenessalsohaveanalogsforcandidatesets.
Deﬁnition13
For a consistent sample S,apartial exclusion is a partial negation of ERCS(S)that
rejectssome F ⊆ S byrendering ercs(f)inconsistentforeach f ∈ F whilepreservingthe
consistencyof ercs(s)forevery s ∈ (S − F).
55
ComputationalLinguistics Volume35,Number1
Deﬁnition14
C
i
isw-uniquein S ifthereisapartitioningof S into T and F underwhichC
i
istheonly
coordinatethatfusestoWin ERCS(T)foreverypartialexclusionthatrejects F.
Thepropertyof W-uniquenessinsamplescruciallycontrastswithwhatonemightcall
beingsemi-unique—thecasewhereforatleastone,butnotall,ofthepartialexclusions
thatreject F,C
i
istheonlycolumnthatfusesto Win ERCS(T).
Deﬁnition15
Given a constraint set CON anda sample S, the minor S
x,j
is obtainedby removing
candidate x from S andremovingconstraint C
j
fromCON.
Byextendingpartialnegation,W-uniqueness,andtheconceptofminorstotherealmof
samples,itisstraightforwardtoshowthatshatterablesampleshaveshatterableminors.
Lemma4
Shatterablesampleshaveshatterableminors.
Proof:AssumethatSisashatterablesample.Becauseremovingcandidate x from S has
no effect on whether the remainder of S can be shattered, S −{x} is also shatterable.
Sample S −{x} must have at least one coordinate that is not W-unique. If this were
not the case, then, because ERCS(x) must contain at least one coordinate with an L
(elsetherewouldbenowaytoreject {x}),thepresenceof x in S wouldplacean L ina
W-uniquecoordinatein S −{x}.However,thiswouldmakeitimpossibletoassociatea
rankingwithatleastonepartitioningof S intoacceptedandrejectedsubsetscontrathe
assumption that S is shatterable. If C
j
is a coordinate in S −{x} that is not W-unique,
then, for every partial exclusion that rejects F, under each partitioning of S −{x} into
T and F, there is at least one other coordinate C
i
that fuses to W.Thus,C
j
couldbe
removedfrom C ON while preserving the shatterability of S −{x}. Therefore, S
x,j
is a
shatterableminorasrequired. square
The crucial piece of the proof in Section 3 that the VCD of ERC sets is k −1was
theillustrationofaone-to-onerelationshipbetween k andtheboundonshatterablesets
by showing that removing an ERC from a shatterable set makes it possible to remove
a coordinate from the remaining ERCs while preserving shatterability. If shatterable
ERCsetscouldbelargerthan k −1,thenitwouldhavebeennecessarytoremovesev-
eral ERCs before it was possible to safely remove a coordinate from the remaining
ERCs.BecauseERCsetsandcandidatesamplesbothhaveshatterableminors,asimilar
strategywillshowthatshatterablesamplesmustalsogrowataone-to-oneratewith k.
Theorem3
If|CON|= k,thenthesizeofshatterablesamplesetsisboundedat k −1.
Proof:Ifk =2,asampleconsisting ofasinglecandidate canbeshatteredif ERCS(s)is
{〈W,L〉}or{〈L,W〉},butnolargersamplecanbeshattered.Ifthereweresuchasample,
it would contain at least two candidates a and b andthere wouldbe a ranking under
which both candidates were optimal, a ranking under which neither candidate was
optimal, a ranking that made a but not b optimal, andanother ranking that made b
butnot a optimal.Thisstateofaffairsrequiresatleastfourdistinctrankings,whichis
impossible with only two constraints. Thus, it is establishedthat, at k =2, the largest
shatterablesamplesethasatmostonecandidate.
56
Riggle RankingHypothesesinOT
If S is the largest shatterable sample for k constraints, then, at k +1,thesizeof
the largest shatterable sample is |S|+1. If this were not the case, there wouldbe a
shatterable sample X such that |X|≥|S|+2fork +1 constraints. However, because
shatterable samples have shatterable minors (Lemma 4), this wouldmean that there
was a shatterable sample of size |S|+1fork constraints, contrary to the assumption
that S was largest. Given the base case that |S|=1 when k =2, the cardinality of
shatterablesamplesisthusboundedat k −1asrequired. square
Theboundof k −1deﬁnesthelimitingcasethatisobtainedwhentherecanbecan-
didates in the sample space for any ERC set. In actual practice, the speciﬁc details of
the constraints in CON andthe range of ways that they interact will determine which
elementsofthepowersetofthesetof k-lengthERCsareassociatedwithcandidatesin
the sample space. This means that the VC dimension of a speciﬁc constraint set CON
canbemuchlowerthan |CON|−1.Nonetheless,theresultthattheVCDofOTcanbe
atmost|CON|−1ispropitiousforthelearnabilityofOptimalityTheoreticgrammars.
5.Conclusions
BoundingtheVCdimensionofOTaccordingtothenumberofconstraintsin CONes-
tablishes a general property of the sets of ranking hypotheses that can be associated
withsetsofcandidates.Thisboundisindependentofanyassumptionsabouthowthe
ERC sets for candidates are computed, independent of any assumptions about how
optimizations are computed, and independent of any assumptions about the formal
propertiesofconstraintsotherthanthattheymapcandidatestoN.
The linear growth of the VCD with |CON|= k provides a very general positive
learnabilityresultforOT.Blumeretal.(1989),buildingonthelearningmodelofValiant
(1984),deﬁneaconceptclass C asuniformlylearnableifthereisalearningalgorithm
A such that, for any error threshold epsilon1 andconﬁdence level δ,ifA is given m training
samples randomly drawn according to a probability distribution π over the sample
space, then A has at least probability δ of generating a hypothesis whose likelihood
ofmisclassifyinganypointinthesamplespacedrawnrandomlyaccordingtoπ isless
than epsilon1. Blumer et al. link the VC dimension to learnability by showing that concept
classes are uniformly learnable if andonly if they have a ﬁnite VCD. Moreover, they
showthatupperboundson m canbeestablishedforlearningthatdependonlyonthe
VCdimensionoftheconceptclasstobelearned.Theboundon m accordingto d =VCD
fromBlumeretal.isgiveninEquation(1).
m ≤
ceilingleftBig
4
epsilon1
parenleftBig
dln
12
epsilon1
+ln
2
δ
parenrightBigceilingrightBig
(1)
Thisisaworst-caseboundthatholdsforthemostadversarialprobabilitydistributions
over the sample space andthe worst consistent learning algorithms (i.e., algorithms
that are consistent in that they correctly classify all data in the training set, but worst-
caseinthattheyerrmaximallyonallunobserveddata).SpeciﬁcOTlearningalgorithms
thathavetighterboundsandnon-worst-caseprobabilitydistributionsoversampleswill
certainlypresentadifferentpicture.
ForaconcreteexampleofOTlearning,consideraversionofPrinceandSmolensky’s
(1993)basicCVsyllabletheoryinwhichcandidatesaremappingsfrom {C,V}*to {C,
V, .}*,andforeachinput i ∈{C,V}*,thecandidatesetproducedbyGEN(i)represents
57
ComputationalLinguistics Volume35,Number1
allwaysofmodifying i throughdeletionandinsertionof.,C,andV.
3
IfCONcontains(i)
aconstraintagainstdeletion,(ii)aconstraintagainstVinsertion,(iii)aconstraintagainst
C insertion, (iv) a constraint against syllables with codas, and (v) a constraint against
syllables without onsets, then the range of possible rankings of these ﬁve constraints
allows for 120 different grammars which in turn deﬁne twelve different languages
(i.e.,twelvesubsetsofthesamplespace X ={C,V}*×{C,V,.}*).
Iflearnersaretrainedwithpositiveevidenceintheformofoptimal input → output
mappings,thentheprobabilitydistributionoverthesamplespacecanbecharacterized
intermsoftheprobabilitydistributionovertheinputstringsin {C,V}*.Eachoptimal
candidate a =(i → o) provides information about the teacher’s ranking in the form of
ERCS(a)={erc(a,b)|b =(i → x)∈ GEN(i)}.Riggle(2004)showsthat,becausethefunc-
tionsinthissystemareallrational(i.e.,ﬁnitestaterepresentable), theset ERCS(a)can
be derived via an algorithm called CONTENDERS.Inthissystem,ERCS(a) can contain
from zero to twelve ERCs. The zero-ERC cases arise for input strings that share the
sameoptimaloutputunderallrankings(i.e.,/CV/→[.CV.]).Thesetstopoutattwelve
becausetherearenevermorethantwelvecontenders(i.e.,non-harmonically-bounded
candidates)foranygiveninputstring.ThetwelveERCboundisaconsequenceofthe
factthe120rankingsonlyrealizetwelvedistinctlanguages.
4
AsnotedinSection1,candidateswiththesameinputcannotco-occurinshatterable
sets.Becauseofthis,theboundonshatterablesamplesestablishedinSection4carries
transparently over to the more general case where learners are trainedwith optimal
(i,o) mappings andthen testedwith novel inputs. Because the set of contenders is
determinedsolelyby GENandC ON(whichthelearnerispresumedtohaveaccessto)
if the learner can compute CONTENDERS(i), then testing on novel inputs reduces to
having the learner select one optimal candidate from the set of contenders, which
in turn reduces to binary questions of harmonic inequality between pairs a and b in
CONTENDERS(i),whichinturnreducestothequestionofwhichof erc(a,b)orerc(b,a)is
consistentwiththeERCsgleanedfrompreviousobservations.
This is merely one sketch of how the learning problem in OT can be formulated
sothattheVCdimensioncanpredictitssuccess.Thereareundoubtedlyotherpossible
formulations.Furthermore,asnoted,real-worldcaseswilloftencontaindetailsthatare
more relevant than the VC dimension in predicting learnability. For instance, in syl-
lable structure grammar just described, there are inputs for which the CONTENDERS
algorithm generates one candidate per language in the factorial typology. In such a
case, the ERC set for a single optimal candidate can serve as a “global trigger” that is
sufﬁcient to uniquely identify the teacher’s language. Further analysis with speciﬁc
constraintsandOTlearningalgorithmslikeRecursiveConstraintDemotion(Tesar1995,
1997,1998;TesarandSmolensky1993,2000),theGradualLearningAlgorithm(Boersma
1997, 1998; Boersma andHayes 2001), andthe ERC-Union learner (Riggle 2004) will
surelyyieldfurtherinsightsandalessabstractpictureoflearninginOptimalityTheory.
TheVCDisanextremelyrobustmetricthatcharacterizeshardnessinmanylearning
frameworks (Haussler, Kearns, andSchapire 1992) andis applicable without any as-
sumptionsotherthanthatthelearnerisconsistent.Anylearnerthatbasesitshypotheses
ontheunionoftheERCsassociatedwiththedataonwhichitistrainedisguaranteedto
beconsistent,andthusanextremelysimpleERC-unionlearnercanlearnOTgrammars
3 CandVrepresentconsonantsandvowelsrespectivelyand“ .”representsasyllableboundarymarker.
4 Riggle(2004)extendsPrinceandSmolensky’snine-wayfactorialtypologytotwelvewithaslightlylooser
GEN.Inthiscase,becauseceilingleftlog
2
12ceilingright=4,theERC-basedVCDboundisthesameasthatobtainedbythe
ﬁnitudeofthetypology.Usually,however,wedonothavetheluxuryofknowingthesizeof C.
58
Riggle RankingHypothesesinOT
from random training texts whose size m is linear in k. This linear boundon the re-
lationshipbetween k andsamplecomplexityisanicetighteningofthe k log
2
k bound
that follows from the ﬁnitude of k! andcontrasts starkly with pessimistic assessments
of learnability suggestedby the factorial relationship between k andthe number of
possiblegrammars.
References
Anderson,AlanR.andNuelD.Belnap,Jr.
1975. Entailment The Logic of Relevance and
Necessity.PrincetonUniversityPress.
Blumer,Anselm,AndrzejEhrenfeucht,
DavidHaussler,andManfredK.
Warmuth.1989.Learnabilityandthe
Vapnik-Chervonenkisdimension. Journal
of the ACM,36(4):929–965.
Boersma,Paul.1997.Howwelearnvariation,
optionality,andprobability. Proceedings of
the Institute of Phonetic Sciences,21:43–58.
Boersma,Paul.1998. Functional Phonology:
Formalizing the Interactions between
Articulatory and Perceptual Drives.Ph.D.
thesis,TheHague.
Boersma,PaulandBruceHayes.2001.
Empiricaltestsofthegraduallearning
algorithm. Linguistic Inquiry,32:45–86.
Dijkstra,Edsger.W.1959.Anoteon
twoproblemsinconnexionwithgraphs.
Numerische Mathematik,1:269–271.
Ellison,T.Mark.1994.Phonological
derivationinoptimalitytheory.In
Proceedings of the Fifteenth Conference on
Computational Linguistics,pages1007–1013,
Kyoto,Japan.doi:dx.doi.org/10.3115/
991250.991312.
Haussler,David,MichaelKearns,andRobert
Schapire.1992.Boundsonthesample
complexityofBayesianlearningusing
informationtheoryandtheVCdimension.
TechnicalReportUCSC-CRL-91-44.
Littlestone,Nick.1988.Learningquickly
whenirrelevantattributesabound:
Anewlinear-thresholdalgorithm. Machine
Learning,2(4):285–318.
Prince,Alan.2002.Entailedrankingarguments.
ROA500.Availableathttp://roa.rutgers.edu.
Prince,AlanandPaulSmolensky.1993.
Optimality Theory: Constraint Interaction in
Generative Grammar.Blackwell,Malden,
MA.
Riggle,Jason.2004. Generation, Recognition,
and Learning in Finite State Optimality
Theory.Ph.D.thesis,Universityof
California,LosAngeles.
Samek-Lodovici,VieriandAlanPrince.1999.
Optima.ROA785.Availableat
http://roa.rutgers.edu.
Tesar,Bruce.1995. Computational Optimality
Theory.Ph.D.thesis,Universityof
Colorado.
Tesar,Bruce.1997.Multi-recursiveconstraint
demotion.ROA197.Availableat
http://roa.rutgers.edu.
Tesar,Bruce.1998.Error-drivenlearningin
OptimalityTheoryviatheefﬁcient
computationofoptimalforms.In Is the
Best Good Enough? Optimality and
Competition in Syntax,ed.PilarBarbosa,
DannyFox,PaulHagstran,MarthaJ.
McGinnis,andDavidPesetsky.MITPress,
Cambridge,MA.
Tesar,BruceandPaulSmolensky.1993.
Thelearnabilityofoptimalitytheory:
Analgorithmandsomebasiccomplexity
results.Unpublishedmanuscript.
DepartmentofComputerScience
&InstituteofCognitiveScience,
UniversityofColoradoatBoulder.
Tesar,BruceandPaulSmolensky.2000.
Learnability in Optimality Theory.MITPress,
Cambridge,MA.
Valiant,LeslieG.1984.Atheoryofthe
learnable. Communications of the ACM,
27(11):1134–1142.
Vapnik,V.N.andA.Chervonenkis.1971.
Ontheuniformconvergenceofrelative
frequenciesofeventstotheirprobabilities.
Theory of Probability and its Applicaions,
16:264–280.
59


