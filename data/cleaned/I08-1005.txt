Semi-Supervised Learning for Relation Extraction  
 
ZHOU GuoDong    LI JunHui    QIAN LongHua    ZHU Qiaoming 
Jiangsu Provincial Key Lab for Computer Information Processing Technology 
School of Computer Science and Technology 
Soochow Univ., Suzhou, China 215006 
Email : {gdzhou, lijunhui, qianlonghua, qmzhu}@suda.edu.cn 
 
Abstract 
This paper proposes a semi-supervised learn-
ing method for relation extraction. Given a 
small amount of labeled data and a large 
amount of unlabeled data, it first bootstraps a 
moderate number of weighted support vectors 
via SVM through a co-training procedure with 
random feature projection and then applies a 
label propagation (LP) algorithm via the boot-
strapped support vectors. Evaluation on the 
ACE RDC 2003 corpus shows that our method 
outperforms the normal LP algorithm via all 
the available labeled data without SVM boot-
strapping. Moreover, our method can largely 
reduce the computational burden. This sug-
gests that our proposed method can integrate 
the advantages of both SVM bootstrapping 
and label propagation.  
1 Introduction

Relation extraction is to detect and classify various 
predefined semantic relations between two entities 
from text and can be very useful in many NLP ap-
plications such as question answering, e.g. to an-
swer the query “Who is the president of the United 
States?”, and information retrieval, e.g. to expand 
the query “George W. Bush” with “the president of 
the United States” via his relationship with “the 
United States”.  
During the last decade, many methods have 
been proposed in relation extraction, such as su-
pervised learning (Miller et al 2000; Zelenko et al.2003; Culota and Sorensen 2004; Zhao and Grish-
man 2005; Zhang et al 2006; Zhou et al 2005, 
2006), semi-supervised learning (Brin 1998; 
Agichtein and Gravano 2000; Zhang 2004; Chen et 
al 2006), and unsupervised learning (Hasegawa et 
al 2004; Zhang et al 2005). Among these methods, 
supervised learning-based methods perform much 
better than the other two alternatives. However, 
their performance much depends on the availability 
of a large amount of manually labeled data and it is 
normally difficult to adapt an existing system to 
other applications and domains. On the other hand, 
unsupervised learning-based methods do not need 
the definition of relation types and the availability 
of manually labeled data. However, they fail to 
classify exact relation types between two entities 
and their performance is normally very low. To 
achieve better portability and balance between hu-
man efforts and performance, semi-supervised 
learning has drawn more and more attention re-
cently in relation extraction and other NLP appli-
cations. 
This paper proposes a semi-supervised learning 
method for relation extraction. Given a small 
amount of labeled data and a large amount of unla-
beled data, our proposed method first bootstraps a 
moderate number of weighted support vectors from 
all the available data via SVM using a co-training 
procedure with random feature projection and then 
applies a label propagation (LP) algorithm to cap-
ture the manifold structure in both the labeled and 
unlabeled data via the bootstrapped support vectors. 
Compared with previous methods, our method can 
integrate the advantages of both SVM bootstrap-
ping in learning critical instances for the labeling 
function and label propagation in capturing the 
manifold structure in both the labeled and unla-
beled data to smooth the labeling function. 
The rest of this paper is as follows. In Section 2, 
we review related semi-supervised learning work 
in relation extraction. Then, the LP algorithm via 
bootstrapped support vectors is proposed in Sec-
tion 3 while Section 4 shows the experimental re-
sults. Finally, we conclude our work in Section 5.  
2 Related
Work 
Generally, supervised learning is preferable to un-
supervised learning due to prior knowledge in the 
32

