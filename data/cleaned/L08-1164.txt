<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>C Barras</author>
<author>E Geoffrois</author>
<author>Z Wu</author>
<author>M Liberman</author>
</authors>
<title>Transcriber: development and use of a tool for assisting speech corpora production. Speech Communication</title>
<date>2001</date>
<pages>33--1</pages>
<contexts>
<context>nned/spontaneous). In addition, the starting and ending of background noise, such as background music and sound from a news story, are indicated in transcriptions. We used a tool, called Transcriber (Barras et al., 2001), which utilizes the XML format to annotate the broadcast news structure. At present, only the portion of speech derived from professional announcers speaking in a studio is transcribed. Speech from </context>
</contexts>
<marker>Barras, Geoffrois, Wu, Liberman, 2001</marker>
<rawString>C. Barras, E. Geoffrois, Z. Wu, and M. Liberman. 2001. Transcriber: development and use of a tool for assisting speech corpora production. Speech Communication, 33(1–2):5–22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P R Dixon</author>
<author>D A Caseiro</author>
<author>T Oonishi</author>
<author>S Furui</author>
</authors>
<date>2007</date>
<contexts>
<context>ot selected to be included into the test set were used as a training corpus for language modeling. The dictionary size was about 18k words. The TITech large vocabulary WFST speech recognition system (Dixon et al., 2007) was used as a speech decoder. 6.3. Experimental results Some experiments were performed and the resulting word error rates (WER) are shown in Table 5. Perplexities and out-of-vocabulary (OOV) rates </context>
</contexts>
<marker>Dixon, Caseiro, Oonishi, Furui, 2007</marker>
<rawString>P. R. Dixon, D. A. Caseiro, T. Oonishi, and S. Furui. 2007.</rawString>
</citation>
<citation valid="true">
<title>The TITech large vocabulary WFST speech recognition system</title>
<date>2007</date>
<booktitle>In Proceedings of Automatic Speech Recognition and Understanding</booktitle>
<pages>443--448</pages>
<marker>2007</marker>
<rawString>The TITech large vocabulary WFST speech recognition system. In Proceedings of Automatic Speech Recognition and Understanding 2007, pages 443–448.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Federico</author>
<author>D Giordani</author>
<author>P Coletti</author>
</authors>
<title>Development and evaluation of an Italian broadcast news corpus</title>
<date>2000</date>
<contexts>
<context>state-of-the-art speech recognition system depends on large speech and text corpora, many collections of broadcast news corpora for various languages have already been created (Matsuoka et al., 1997; Federico et al., 2000; Graff, 2002; Wang, 2003). However, that is not the case for resource deficient languages, such as Thai (Wutiwiwatchai and Furui, 2007). Until several years ago, research on Thai automatic speech rec</context>
</contexts>
<marker>Federico, Giordani, Coletti, 2000</marker>
<rawString>M. Federico, D. Giordani, and P. Coletti. 2000. Development and evaluation of an Italian broadcast news corpus.</rawString>
</citation>
<citation valid="true">
<date>2000</date>
<booktitle>In Proceedings of the Second International Conference on Language Resources and Evaluation (LREC</booktitle>
<marker>2000</marker>
<rawString>In Proceedings of the Second International Conference on Language Resources and Evaluation (LREC) 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Graff</author>
</authors>
<title>An overview of broadcast news corpora. Speech Communication</title>
<date>2002</date>
<pages>37--1</pages>
<contexts>
<context> recognition system depends on large speech and text corpora, many collections of broadcast news corpora for various languages have already been created (Matsuoka et al., 1997; Federico et al., 2000; Graff, 2002; Wang, 2003). However, that is not the case for resource deficient languages, such as Thai (Wutiwiwatchai and Furui, 2007). Until several years ago, research on Thai automatic speech recognition (ASR</context>
</contexts>
<marker>Graff, 2002</marker>
<rawString>D. Graff. 2002. An overview of broadcast news corpora. Speech Communication, 37(1–2):15–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Jongtaveesataporn</author>
<author>I Thienlikit</author>
<author>C Wutiwiwatchai</author>
<author>S Furui</author>
</authors>
<title>Towards better language modeling for Thai LVCSR</title>
<date>2007</date>
<booktitle>In Proceedings of Interspeech</booktitle>
<pages>1553--1556</pages>
<contexts>
<context> papers reporting about the development of large vocabulary continuous speech recognition (LVCSR) for the Thai language (Tarsaku and Kanokphara, 2002; Kanokphara et al., 2003; Suebvisai et al., 2005; Jongtaveesataporn et al., 2007). A few speech corpora were constructed by these research activities (Kasuriya et al., 2003a; Kasuriya et al., 2003b; Schultz, 2002). They are all read speech corpora recorded in a clean environment.</context>
<context>y. The use of newspaper text and some interpolation techniques needs to be applied to improve the language model performance. We are also planning to apply our automatic word segmentation techniques (Jongtaveesataporn et al., 2007) for language modeling. 7. Conclusion This paper presented the construction of the first Thai broadcast news speech and text corpora. The speech corpus contains about 17 hours and the text corpus was</context>
</contexts>
<marker>Jongtaveesataporn, Thienlikit, Wutiwiwatchai, Furui, 2007</marker>
<rawString>M. Jongtaveesataporn, I. Thienlikit, C. Wutiwiwatchai, and S. Furui. 2007. Towards better language modeling for Thai LVCSR. In Proceedings of Interspeech 2007, pages 1553–1556.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kanokphara</author>
<author>V Tesprasit</author>
<author>R Thongprasirt</author>
</authors>
<title>Pronunciation variation speech recognition without dictionary modification on sparse database</title>
<date>2003</date>
<booktitle>In Proceedings of IEEE International conference on acoustics, speech, and signal processing (ICASSP</booktitle>
<pages>764--767</pages>
<contexts>
<context>systems for a specific task. There were also some papers reporting about the development of large vocabulary continuous speech recognition (LVCSR) for the Thai language (Tarsaku and Kanokphara, 2002; Kanokphara et al., 2003; Suebvisai et al., 2005; Jongtaveesataporn et al., 2007). A few speech corpora were constructed by these research activities (Kasuriya et al., 2003a; Kasuriya et al., 2003b; Schultz, 2002). They are </context>
</contexts>
<marker>Kanokphara, Tesprasit, Thongprasirt, 2003</marker>
<rawString>S. Kanokphara, V. Tesprasit, and R. Thongprasirt. 2003. Pronunciation variation speech recognition without dictionary modification on sparse database. In Proceedings of IEEE International conference on acoustics, speech, and signal processing (ICASSP) 2003, pages 764–767.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kasuriya</author>
<author>V Sornlertlamvanich</author>
<author>P Cotsomrong</author>
<author>T Jitsuhiro</author>
<author>G Kikui</author>
<author>Y Sagisaka</author>
</authors>
<title>NECTECATR Thai speech corpus</title>
<date>2003</date>
<booktitle>In Proceedings of International Conference on Speech Databases and Assessments (Oriental-COCOSDA</booktitle>
<contexts>
<context> the Thai language (Tarsaku and Kanokphara, 2002; Kanokphara et al., 2003; Suebvisai et al., 2005; Jongtaveesataporn et al., 2007). A few speech corpora were constructed by these research activities (Kasuriya et al., 2003a; Kasuriya et al., 2003b; Schultz, 2002). They are all read speech corpora recorded in a clean environment. Nevertheless, real-world speech data, such as broadcast news, always contains speech with b</context>
<context> of the test set separated by each F-condition. 6.2. Experimental setup Since the speech corpus was rather small, it was used only for evaluation. We employed two newspaper readspeech corpora, LOTUS (Kasuriya et al., 2003b) and a corpus collected by Tokyo Institute of Technology, to train the acoustic model. All speech data sets available in the LOTUS corpus that were recorded with a dynamic closetalk microphone were </context>
</contexts>
<marker>Kasuriya, Sornlertlamvanich, Cotsomrong, Jitsuhiro, Kikui, Sagisaka, 2003</marker>
<rawString>S. Kasuriya, V. Sornlertlamvanich, P. Cotsomrong, T. Jitsuhiro, G. Kikui, and Y. Sagisaka. 2003a. NECTECATR Thai speech corpus. In Proceedings of International Conference on Speech Databases and Assessments (Oriental-COCOSDA) 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kasuriya</author>
<author>V Sornlertlamvanich</author>
<author>P Cotsomrong</author>
<author>S Kanokphara</author>
<author>N Thatphithakkul</author>
</authors>
<title>Thai speech corpus for Thai speech recognition</title>
<date>2003</date>
<booktitle>In Proceedings of International Conference on Speech Databases and Assessments (Oriental-COCOSDA</booktitle>
<pages>54--61</pages>
<contexts>
<context> the Thai language (Tarsaku and Kanokphara, 2002; Kanokphara et al., 2003; Suebvisai et al., 2005; Jongtaveesataporn et al., 2007). A few speech corpora were constructed by these research activities (Kasuriya et al., 2003a; Kasuriya et al., 2003b; Schultz, 2002). They are all read speech corpora recorded in a clean environment. Nevertheless, real-world speech data, such as broadcast news, always contains speech with b</context>
<context> of the test set separated by each F-condition. 6.2. Experimental setup Since the speech corpus was rather small, it was used only for evaluation. We employed two newspaper readspeech corpora, LOTUS (Kasuriya et al., 2003b) and a corpus collected by Tokyo Institute of Technology, to train the acoustic model. All speech data sets available in the LOTUS corpus that were recorded with a dynamic closetalk microphone were </context>
</contexts>
<marker>Kasuriya, Sornlertlamvanich, Cotsomrong, Kanokphara, Thatphithakkul, 2003</marker>
<rawString>S. Kasuriya, V. Sornlertlamvanich, P. Cotsomrong, S. Kanokphara, and N. Thatphithakkul. 2003b. Thai speech corpus for Thai speech recognition. In Proceedings of International Conference on Speech Databases and Assessments (Oriental-COCOSDA) 2003, pages 54– 61, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Matsuoka</author>
<author>Y Taguchi</author>
<author>K Ohtsuki</author>
<author>S Furui</author>
<author>K Shirai</author>
</authors>
<title>Toward automatic recognition of Japanese broadcast news</title>
<date>1997</date>
<booktitle>In Proceedings of the European Conference on Speech Communication and Technology (EUROSPEECH</booktitle>
<volume>2</volume>
<pages>915--918</pages>
<contexts>
<context>s the development of a state-of-the-art speech recognition system depends on large speech and text corpora, many collections of broadcast news corpora for various languages have already been created (Matsuoka et al., 1997; Federico et al., 2000; Graff, 2002; Wang, 2003). However, that is not the case for resource deficient languages, such as Thai (Wutiwiwatchai and Furui, 2007). Until several years ago, research on Th</context>
</contexts>
<marker>Matsuoka, Taguchi, Ohtsuki, Furui, Shirai, 1997</marker>
<rawString>T. Matsuoka, Y. Taguchi, K. Ohtsuki, S. Furui, and K. Shirai. 1997. Toward automatic recognition of Japanese broadcast news. In Proceedings of the European Conference on Speech Communication and Technology (EUROSPEECH) 1997, volume 2, pages 915–918.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Schultz</author>
</authors>
<title>GlobalPhone: a multilingual speech and text database developed at Karlruhe university</title>
<date>2002</date>
<booktitle>In Proceedings of International Conference on Spoken Language Processing (ICSLP</booktitle>
<contexts>
<context>; Kanokphara et al., 2003; Suebvisai et al., 2005; Jongtaveesataporn et al., 2007). A few speech corpora were constructed by these research activities (Kasuriya et al., 2003a; Kasuriya et al., 2003b; Schultz, 2002). They are all read speech corpora recorded in a clean environment. Nevertheless, real-world speech data, such as broadcast news, always contains speech with background noise or spontaneity. Existing</context>
</contexts>
<marker>Schultz, 2002</marker>
<rawString>T. Schultz. 2002. GlobalPhone: a multilingual speech and text database developed at Karlruhe university. In Proceedings of International Conference on Spoken Language Processing (ICSLP) 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M Stern</author>
</authors>
<title>Specification of the 1996 Hub 4 broadcast news evaluation</title>
<date>1997</date>
<booktitle>In Proceedings of the</booktitle>
<contexts>
<context>em is one of the applications to fulfill this desire. The Defense Advanced Research Projects Agency of the United States (DARPA) started research on automatic transcription of broadcast news in 1995 (Stern, 1997). Since then, this research theme has become attractive to many research groups. As the development of a state-of-the-art speech recognition system depends on large speech and text corpora, many coll</context>
<context> the speech and text corpus was investigated and shown in Table 2. The speech corpus was partitioned according to the evaluation focus conditions (F-condition) employed in the DARPA Hub-4 evaluation (Stern, 1997). Information regarding the number of segments and the average length of segments categorized into each F-condition is shown in Table 3. F-Condition Number of Average length segments (seconds) Male F</context>
</contexts>
<marker>Stern, 1997</marker>
<rawString>R. M. Stern. 1997. Specification of the 1996 Hub 4 broadcast news evaluation. In Proceedings of the 1997 DARPA Speech Recognition Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Suebvisai</author>
<author>P Charoenpornsawat</author>
<author>A Black</author>
<author>M Woszczyna</author>
<author>T Schultz</author>
</authors>
<title>Thai automatic speech recognition</title>
<date>2005</date>
<booktitle>In Proceedings of IEEE International conference on Acoustics, Speech, and signal processing (ICASSP</booktitle>
<pages>857--860</pages>
<contexts>
<context>sk. There were also some papers reporting about the development of large vocabulary continuous speech recognition (LVCSR) for the Thai language (Tarsaku and Kanokphara, 2002; Kanokphara et al., 2003; Suebvisai et al., 2005; Jongtaveesataporn et al., 2007). A few speech corpora were constructed by these research activities (Kasuriya et al., 2003a; Kasuriya et al., 2003b; Schultz, 2002). They are all read speech corpora </context>
</contexts>
<marker>Suebvisai, Charoenpornsawat, Black, Woszczyna, Schultz, 2005</marker>
<rawString>S. Suebvisai, P. Charoenpornsawat, A. Black, M. Woszczyna, and T. Schultz. 2005. Thai automatic speech recognition. In Proceedings of IEEE International conference on Acoustics, Speech, and signal processing (ICASSP) 2005, pages 857–860.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Tarsaku</author>
<author>S Kanokphara</author>
</authors>
<title>A study of HMM-based automatic segmentation for Thai continuous speech recognition system</title>
<date>2002</date>
<booktitle>In Proceedings of the Joint International Conference of SNLP-Oriental COCOSDA</booktitle>
<pages>217--220</pages>
<contexts>
<context>conducted on small vocabulary systems for a specific task. There were also some papers reporting about the development of large vocabulary continuous speech recognition (LVCSR) for the Thai language (Tarsaku and Kanokphara, 2002; Kanokphara et al., 2003; Suebvisai et al., 2005; Jongtaveesataporn et al., 2007). A few speech corpora were constructed by these research activities (Kasuriya et al., 2003a; Kasuriya et al., 2003b; </context>
</contexts>
<marker>Tarsaku, Kanokphara, 2002</marker>
<rawString>P. Tarsaku and S. Kanokphara. 2002. A study of HMM-based automatic segmentation for Thai continuous speech recognition system. In Proceedings of the Joint International Conference of SNLP-Oriental COCOSDA 2002, pages 217–220. P. Tarsaku, V. Sornlertlamvanich, and R. Thongprasirt.</rawString>
</citation>
<citation valid="true">
<title>Thai grapheme-to-phoneme using probabilistic GLR parser</title>
<date>2001</date>
<booktitle>In Proceedings of the European Conference on Speech Communication and Technology ( EUROSPEECH</booktitle>
<pages>1057--1060</pages>
<marker>2001</marker>
<rawString>2001. Thai grapheme-to-phoneme using probabilistic GLR parser. In Proceedings of the European Conference on Speech Communication and Technology ( EUROSPEECH) 2001, pages 1057–1060.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Wang</author>
</authors>
<title>MATBN 2002: A Mandarin Chinese broadcast news corpus</title>
<date>2003</date>
<booktitle>In Proceedings of ISCA &amp; IEEE Workshop on Spontaneous Speech Processing and Recognition (SSPR</booktitle>
<contexts>
<context>system depends on large speech and text corpora, many collections of broadcast news corpora for various languages have already been created (Matsuoka et al., 1997; Federico et al., 2000; Graff, 2002; Wang, 2003). However, that is not the case for resource deficient languages, such as Thai (Wutiwiwatchai and Furui, 2007). Until several years ago, research on Thai automatic speech recognition (ASR) was conduc</context>
</contexts>
<marker>Wang, 2003</marker>
<rawString>H. Wang. 2003. MATBN 2002: A Mandarin Chinese broadcast news corpus. In Proceedings of ISCA &amp; IEEE Workshop on Spontaneous Speech Processing and Recognition (SSPR) 2003.</rawString>
</citation>
</citationList>
</algorithm>

