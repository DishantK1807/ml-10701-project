LastWords
WhatComputationalLinguistsCanLearn
fromPsychologists(andViceVersa)
EmielKrahmer
∗
Tilburg University
1.Introduction
Sometimes I am amazed by how much the ﬁeld of computational linguistics has
changedinthepast15to20years.Inthemid1990s,Iwasworkingataresearchinstitute
where language and speech technologists worked in relatively close quarters. Speech
technologyseemedonthevergeofamajorbreakthrough;thiswasaroundthetimethat
Bill Gates was quoted in Business Week as saying that speech was not just the future of
Windows, but the future of computing itself. At the same time, language technology
was, well, nowhere. Bill Gates certainly wasn’t championing language technology in
those days. And while the possible applications of speech technology seemed endless
(whowoulduseakeyboardin2010,whenspeech-drivenuserinterfaceswouldhavere-
placed traditional computers?), thelanguage people were thinking hard about possible
applications for their admittedly somewhat immature technologies.
Predicting the future is a tricky thing. No major breakthrough came for speech
technology—I am still typing this. However, language technology did change almost
beyond recognition. Perhaps one of the main reasons for this has been the explosive
growth of the Internet, which helped language technology in two different ways. On
the one hand it instigated the development and reﬁnement of techniques needed for
searching in document collections of unprecedented size, on the other it resulted in a
large increase of freely available text data. Recently, language technology has been par-
ticularly successful for tasks where huge amounts of textual data is available to which
statistical machine learning techniques can be applied (Halevy, Norvig, and Pereira
2009). As a result of these developments, mainstream computational linguistics is now
a successful, application-oriented discipline which is particularly good at extracting
information fromsequences of words.
But there is more to language than that. For speakers, words are the result of a
complex speech production process; for listeners, they are what starts off the similarly
complexcomprehensionprocess.However,inmanycurrentapplicationsnoattentionis
giventotheprocessesbywhichwordsareproducednortotheprocessesbywhichthey
canbeunderstood.Languageistreatedasaproductnotasaprocess,intheterminology
of Clark (1996). In addition, we use language not only as a vehicle for factual infor-
mation exchange; speakers may realise all sorts of other intentions with their words:
They may want to convince others to do or buy something, they may want to induce
a particular emotion in the addressee, and so forth. These days, most of computational
linguistics (with a few notable exceptions, more about which subsequently) has little to
∗ TilburgCentreforCreativeComputing(TiCC),Communicationand Cognitionresearch group,Tilburg
University, The Netherlands. E-mail:e.j.krahmer@uvt.nl.
©2010AssociationforComputationalLinguistics
ComputationalLinguistics Volume36,Number2
sayabouthowpeopleproduceandcomprehendlanguage,noraboutwhatthepossible
effects of language could be.
It wasn’t always like this; early work in computational linguistics took a different
(and more ambitious) perspective. Winograd (1980), to give one more or less ran-
dom example, explicitly treated language understanding and production as cognitive
processes, which interacted with other cognitive modules such as visual perception;
Hovy(1990),togiveanother,presentedacomputationalmodelthatgenerateddifferent
texts from the same underlying facts, depending on pragmatic, interpersonal con-
straints.ItisinterestingtoobservethatWinogradandHovybuiltonbothcomputational
andpsychologicalresearch,somethingwhichisincreasinglyrareintheﬁeldofcompu-
tational linguistics, a point made convincingly by Reiter (2007). By now, it is generally
accepted that the problems that Winograd, Hovy, and others tried to tackle are very
complex, and that the current emphasis on more well-delimited problems is probably
a good thing. However, it is not difﬁcult to come up with computational applications
for which a better understanding would be required of language as a process and the
effects language may have on a user (interactive virtual agents which try to persuade a
user to do something, for example). To learn more about how speakers and addressees
manage to accurately produce and comprehend complex and potentially ambiguous
sentencesinrealtime,andhowtheymayusethesesentencesforawholerangeofinten-
tions,wehavetoturntopsycholinguisticsandsocialpsychology,respectively.Soletus
samplesomeoftherecentﬁndingsintheseﬁelds,andseeifandhowtheymightbeneﬁt
computationallinguistics.Interestingly,wewillﬁndmanyplaceswheremoreattention
to what goes on in computational linguistics would beneﬁt psychologists as well.
2.LanguageUseandItsSocialImpact
Social psychologists study persons and the relations they have with others and
with groups. Various social psychologists have concentrated on language (although
perhaps not as many as you would expect given the importance of language for
social interactions). A number of different approaches can be discerned, one of which
concentrates on the psychological functions of function words (Chung and Pennebaker
2007). Function words are understood here to include pronouns, prepositions, articles,
conjunctions, and auxiliary verbs.
2.1OnthePsychologicalFunctionsofPronouns
Onereliableﬁndingofthisperspectiveisthatﬁrstpersonsingularpronounsareassoci-
atedwithnegativeaffectivestates.Forexample,inonestudyitwasfoundthatcurrently
depressed students used I and me more often than students who were not currently
depressed, and of the latter group those who had known periods of depression used
them more frequently than those who had never had such an episode (Rude, Gortner,
and Pennebaker 2004). Another study found that suicidal poets used ﬁrst person sin-
gular pronouns in their poems more frequently than non-suicidal poets (Stirman and
Pennebaker 2001). Of course, whether a speaker tends to use I or we more frequently
is also indicative of selfversus other-centeredness. An analysis of blogs following the
events of September 11 revealed that bloggers’ use of I and me dropped in the hours
followingtheattack,whilesimultaneouslytheiruseofweandusincreased(Cohn,Mehl,
andPennebaker2004);thisswitchisinterpretedbytheauthorsasindicatingthatpeople
286
Krahmer Last Words
werefocusinglessonthemselvesduringthisperiod,butinsteadfocusingmoreontheir
friends and families. In a completely different study of adult speakers (both male and
female) who underwent testosterone therapy, it was found that as testosterone levels
dropped,sodidtheiruseofIpronouns,whilesimultaneouslytheuseofnon-Ipronouns
increased (Pennebaker etal. 2004).
Pennebakerandcolleaguesreportcomparableeffectsofage,gender,status,andcul-
tureonpersonalpronounuse(ChungandPennebaker2007).Theircorpus(or“archive”,
astheycallit)containsover400,000textﬁles,frommanydifferentauthorsandcollected
over many years. It is interesting to observe that Pennebaker was an early adapter of
computers for his analyses, simply because performing them manually was too time-
consuming. The general approach in these analyses is to determine beforehand what
the“interesting”wordsareandthensimplytocountthemintherelevanttexts,without
taking the linguistic context into account. This obviously creates errors: The relative
frequency of ﬁrst-person pronouns may be indicative of depression, as we have just
seen,butasentencesuchasIlovelifeseemsasomewhatimplausiblecueforadepressed
state of mind. Chung and Pennebaker (2007, page 345) themselves give the example of
mad, which is counted as an anger and negative emotion word, and they point out that
this is wrong forI’mmadaboutmylover. Clearly, standard methods from computational
linguistics could be used to address this problem, for instance by looking at words in
context and n-grams. Another problem which Chung and Pennebaker mention, and
which will be familiar to many computational linguists, is the problem of deciding
which are the interesting words to count. Here techniques such as feature construction
and selection could be of help. As I will argue in what follows, the observations of
Pennebaker and colleagues are potentially interesting for computational linguistics as
well, but let us ﬁrst look at another relevant set of psychological ﬁndings.
2.2OnthePsychologicalFunctionsofInterpersonalLanguage
A different strand of research on language and social psychology focuses on inter-
personal verbs (a subset of what computational linguists more commonly refer to as
transitive verbs): verbs which express relations between people (Semin 2009). In their
model of interpersonal language (the Linguistic Categorization Model), Semin and
Fiedler (1988) make a distinction between different kinds of verbs and their position
on the concrete–abstract dimension. Descriptive action verbs (Romeo kisses Juliet)are
assumed to be the most concrete, since they refer to a single, observable event. This is
different for state verbs (RomeolovesJuliet), which describe psychological states instead
of single perceptual events, and are therefore more abstract. Most abstract, according
to Semin and Fiedler, are adjectives (Romeo is romantic), because they generalize over
speciﬁc events and objects and only refer to characteristics of the subject.
The thing to note is that the same event can, in principle, be referred to in all these
different forms; a speaker has the choice of using a more concrete or a more abstract
way to refer to an event (e.g., John can be described as, from more to less concrete,
hitting a person, hating a person, or being aggressive). Interestingly, the abstractness
level a speaker opts for tells us something about that speaker. This has been found,
for instance, in the communication of ingroup (think of people with the same cul-
tural identity or supporting the same soccer team) and outgroup (different identity,
differentteam)behavior.Thereisconsiderableevidencethatspeakersdescribenegative
ingroup and positive outgroup behavior in more concrete terms (e.g., using action
verbs),therebyindicatingthatthebehaviorismoreincidental,whereaspositiveingroup
287
ComputationalLinguistics Volume36,Number2
and negative outgroup behaviors are described in relatively abstract ways (e.g., more
frequentlyusingadjectives),suggestingamoreenduringcharacteristic(see,e.g.,Maass
et al. 1989). Maass and colleagues showed this phenomenon, which they dubbed the
Linguistic Intergroup Bias, for different Contrada (neighborhoods) participating in the
famous Palio di Siena horse races, reporting about their own performance and that of
the other neighborhoods. Moreover, Wigboldus, Semin, and Spears (2000) have shown
that addressees do indeed pick up these implications, and Douglas and Sutton (2006)
revealthatspeakerswhodescribethebehaviorofothersinrelativelyabstracttermsare
perceived to have biased attitudes and motives as opposed to speakers who describe
this behavior in more concrete ways.
It has been argued that concrete versus abstract language is not only relevant for,
for example, the communication of stereotypes, but also has more fundamental effects,
for instance inﬂuencing the way people perceive the world (Stapel and Semin 2007).
In a typical experiment, Stapel and Semin ﬁrst subtly prime participants with either
abstract or concrete language. This can be done using scrambled sentences, where
participants are given four words (romantic is lamp Romeo) with the instruction to form
a grammatical sentence from three of them, or by giving participants a word-search
puzzle where the words to search for are the primes. After this, participants perform a
seemingly unrelated task, where their perceptual focus (either on the global picture or
on the details) is measured. Stapel and Semin show that processing abstract language
(adjectives) results in a more global perception, whereas processing concrete language
(descriptive action verbs) leads to more perceptual attention to details.
At this point, a computational linguist (and probably other linguists as well) might
start to wonder about the comparison between verbs and adjectives, and by the claim
that adjectives are abstract. What about adjectives like blonde, young,andthin? These
seem to be much more concrete than adjectives such as aggressive or honest. And what
about nouns? There a distinction between concrete (ofﬁcechair) and abstract (hypothesis)
seems to exist as well. This raises the question whether it is the differences in inter-
personal language use or the more general distinction between concrete and abstract
languagewhichcausestheobservedeffectsonperception;arecentseriesofexperiments
suggests it is the latter (Krahmer and Stapel 2009).
2.3WhatCanComputationalLinguistsLearn?
The social psychological ﬁndings brieﬂy described here could have an impact on com-
putational linguistics, with potential applications for both text understanding and gen-
eration. So far, it seems fair to say that most computational linguists have concentrated
so much on trying to understand text or on generating coherent texts that the subtle
effects that language may have on the reader were virtually ignored. Function words
were originally not the words computational linguists found most interesting. They
were considered too frequent; early Information Retrieval applications listed function
words on “stop lists”—lists of words that should be ignored during processing—and
many IR applications still do. The work of Pennebaker and colleagues indicates that
pronouns (as well as other function words) do carry potentially relevant information,
for instance about the mental state of the author of a document. Interestingly, for com-
putational applications such as opinion mining and sentiment analysis (Pang and Lee
2008) as well as author attribution and stylometry (Holmes 1998), function words have
been argued to be relevant as well, but it seems that research on the social psychology
of language has made little or no impact on this ﬁeld.
288
Krahmer Last Words
Consider sentiment analysis, for instance, which is the automatic extraction of
“opinion-oriented”information(e.g.,whetheranauthorfeelspositiveornegativeabout
a certain product) from text. This is a prime example of an emerging research area in
computationallinguisticswhichmovesbeyondfactualinformationexchange(although
the preferred approach to this problem very much ﬁts with the paradigm sketched by
Halevy et al. [2009]: take a large set of data and apply machine learning to it). Pang
and Lee (2008) offer an extensive overview of research related to sentiment analysis,
but do not discuss any of the psychological studies mentioned herein (in fact, of the
332paperstheycite,onlyoneortwocouldconceivablybeinterpretedaspsychological
in the broadest interpretation). What is especially interesting is that their discussion
of why sentiment analysis is difﬁcult echoes the discussion of Chung and Pennebaker
(2007) on the problems of counting words (by sheer coincidence they even discuss
essentially the same example:madden).
Theseﬁndingsmayalsohaveramiﬁcationsforthegenerationofdocuments.Ifyou
develop an application which automatically produces texts from non-textual data, you
might want to avoid excessive use of the ﬁrst-person pronoun, lest your readers think
your computer is feeling down. If you want your readers to skim over the details of
whatisproposed inagenerated text,useabstract language. Inaddition,you maywant
touseactionverbswhendescribingyourownaccomplishments,andadjectivestorefer
to those of others (but do itin a subtle way, because people might notice).
3.LanguageComprehensionandProduction
While the link between computational linguistics and social psychology has seldom
been explored, there has been somewhat more interaction with psycholinguistics. Per-
haps most of this interaction has involved natural language understanding. Various
early parsing algorithms were inspired by human sentence processing, which is hardly
surprising: human listeners are remarkably efﬁcient in processing and adequately re-
sponding to potentially highly ambiguous sentences. Later, when large data sets of
parsed sentences became available, the focus in computational linguistics shifted to
developing statistical models of language processing. Interestingly, recent psycholin-
guistic sentence processing models are inspired in turn by statistical techniques from
computational linguistics (Chater and Manning 2006; Crocker in press; Jurafsky 2003;
Pado, Crocker, and Keller 2009).
3.1OnProducingReferringExpressions
The situation is somewhat different for natural language generation, although superﬁ-
cially the same kind of interaction can be observed here (albeit with a few years delay).
The seminal work by Dale and Reiter (1995) on the generation of referring expressions
was explicitly inspired by psycholinguistic work. Dale and Reiter concentrated on the
generation of distinguishing descriptions, such as the large black dog, which single out
one target object by ruling out the distractors (typically a set of other domestic animals
of different sizes and colors). Given that the number of distractors may be quite large
and given that each target can be referred to in multiple ways, one of the main issues
in this area is how to keep the search manageable. Current algorithms for referring
expression generation, building on the foundations laid by Dale and Reiter, are good
at quickly computing which set of properties uniquely characterizes a target among a
289
ComputationalLinguistics Volume36,Number2
set of distractors. Some of these algorithms are capable of generating distinguishing
descriptions that human judges ﬁnd more helpful and better formulated than human-
produced distinguishing descriptions for the same targets (Gatt,Belz, and Kow 2009).
To some this might suggest that the problem is solved. This conclusion, however,
would be too hasty. Most of the algorithms use some very unrealistic assumptions
which limit their applicability. Interestingly, these assumptions can be traced back
directly to classic psycholinguistic work on the production of referring expressions
(Olson1970).ClarkandBangerter(2004)criticizeanumberoftheunstatedassumptions
in Olson’s approach: Reference is treated as a one-step process (a speaker plans and
produces a complete description, and nothing else, in one go) and during that process
the speaker does not take the prior interaction with the addressee into account. By
merely substituting computer forspeaker these comments are directly applicable to most
current generation algorithms as well.
The problem, unfortunately, is that recent psycholinguistic research suggests that
these assumptions are wrong. Often this research looks at how speakers produce re-
ferring expressions while interacting with an addressee, and one thing that is often
found is that speakers adapt to their conversational partners while producing refer-
ring expressions (Clark and Wilkes-Gibbs 1986; Brennan and Clark 1996; Metzing and
Brennan2003).Thiskindof“entrainment”or“alignment”(PickeringandGarrod2004)
may apply at the level of lexical choice; if a speaker refers to a couch using the word
sofa instead of the more common couch, the addressee is more likely to use sofa instead
of couch as well later on in the dialogue (Branigan et al. in press). But the speaker and
addressee may also form a general “conceptual pact” on how to refer to some object,
deciding together, for instance, to refer to atangram ﬁgure asthetalliceskater.
Although adaptation itself is uncontroversial, psycholinguists argue about the
extent to which speakers are capable of taking the perspective of the addressee into
account (Kronm¨uller and Barr 2007; Brennan and Hanna 2009; Brown-Schmidt 2009),
with some researchers presenting evidence that speakers may have considerable
difﬁculty doing this (Horton and Keysar 1996; Keysar, Lin, and Barr 2003). In Wardlow
Laneetal.(2006)peopleareinstructedtorefertosimpletargets(geometricalﬁguresthat
maybesmallorlarger)inthecontextofthreedistractorobjects,twoofwhicharevisible
to both speaker and addressee (shared) whereas the other is visible to the speaker only
(privileged). If speakers would be able to take the addressees’ perspective into account
when referring, the privileged distractor should not play a role in determining which
properties to include in the distinguishing description. However, Wardlow Lane and
colleagues found that speakers do regularly take the privileged distractor into account
(for instance adding a modiﬁer small when referring to the target, even though all the
shared objects are small and only the privileged one is large). Interestingly, speakers
do this more often when explicitly told that they should not leak information about
the privileged object, which Wardlow Lane et al. interpret as an ironic processing
effect of the kind observed by Dostoevsky (“Try to pose for yourself this task: not to
think of a polar bear, and you will see that the cursed thing will come to mind every
minute”).
Another interesting psycholinguistic ﬁnding is that speakers often include more
information intheir referring expressions than is strictly needed for identiﬁcation (Arts
2004; Engelhardt, Bailey, and Ferreira 2006), for instance referring to a dog as the large
black curly haired dog in a situation where there is only one large black dog. Again,
that speakers are not always “Gricean” (“be as informative as required, but not more
informative”) is generally agreed upon, but there is an ongoing debate about why and
how speakers overspecify, some arguing that it simpliﬁes the search of the speaker
290
Krahmer Last Words
(Engelhardt, Bailey, and Ferreira 2006) whereas others suggest that overspeciﬁed refer-
encesareparticularlybeneﬁcialfortheaddressee(Paraboni,vanDeemter,andMasthoff
2007).
3.2WhatCanComputationalLinguistsLearn?
Why are these psycholinguistic ﬁndings about the way human speakers refer relevant
forgeneration algorithms? First ofall,human-likeness isan important evaluation crite-
rion,soalgorithmsthataregoodatemulatinghumanreferringexpressionsarelikelyto
outperformalgorithmsthatarenot.Moreover,itisinterestingtoobservethatgenerating
overspeciﬁed expressions is computationally cheaper than producing minimal ones
(DaleandReiter1995).Inasimilarvein,itcanbearguedthatalignmentandadaptation
mayreducethesearchspaceofthegenerationalgorithm,becausetheylimitthenumber
ofpossibilities that have to be considered.
It is worth emphasizing that psycholinguistic theories have little to say about how
speakers quickly decide which properties, from the large set of potential ones, to use in
areferringexpression.Inaddition,whereasnotionssuchasadaptation,alignment,and
overspeciﬁcation are intuitively appealing, it has turned out to be remarkably difﬁcult
to specify how these processes operate exactly. In fact, a common criticism is that they
would greatly beneﬁt from “explicit computational modeling” (Brown-Schmidt and
Tanenhaus 2004). Of course, solving choice problems and computational modeling are
preciselywhatcomputationallinguisticshastooffer.Soalthoughgenerationalgorithms
may beneﬁt a lot from incorporating insights from psycholinguistics, they in turn have
the potential to further research in psycholinguistics as well.
4.Discussion
In this brief, highly selective, and somewhat biased overview of work on language in
several areas of psychology, we have seen that words may give valuable information
about the person who produces them (but how to select and count them is tricky), that
abstract or concrete language may tell you something about the opinions and attitudes
a speaker has and may even inﬂuence how you perceive things (but the linguistic intu-
itionsaboutwhatisabstract,andwhatconcrete,needsomework),andthatspeakersare
remarkably efﬁcient when producing referring expressions, in part because they adapt
totheiraddresseeanddonotnecessarilytrytobeasbriefaspossible(butmakingthese
intuitivenotionspreciseisdifﬁcult).Psychologicalﬁndingssuchasthesearenotmerely
intriguing, but could be of real use for computational linguistic applications related to
document understanding or generation (and, conversely, techniques and insights from
computational linguistics could be helpful for psychologists as well). Of course, some
computationallinguistsdoextensivelyrelyonpsychologicalﬁndingsforbuildingtheir
applications (you know who you are), just as some psychologists use sophisticated
computational and statistical models rather than human participants for their studies
(this is especially true in psycholinguistics). But these are exceptions, and certainly do
not belong to mainstream computational linguistics or psychology. Which raises one
obvious question: Whyisn’t there more interaction between these two communities?
There seem to be at least three reasons for this. First, and most obvious, many
researchers are not aware of what happens outside their own specialized ﬁeld. The
articles in psychology are fairly accessible (usually no complex statistical models or
overformalized algorithms there), but many computational linguists may feel that it
291
ComputationalLinguistics Volume36,Number2
would be a better investment of their limited time to read some more of the 17,000
(and counting) journal, conference, and workshop papers they have not yet read in the
invaluableACLAnthology.Forpsychologistspresumablysimilarconsiderationsapply,
with the additional complication that many of the anthology papers require a substan-
tial amount of technical prior knowledge. In addition, it might be that the different
publicationculturesarealimitingfactorhereaswell:forpsychologists,journalsarethe
main publication outlet; for them most non-journal publications have a low status and
hence might be perceived as not worth exploring.
Another perhaps more interesting reason is that psychologists and computational
linguists have subtly different general objectives. Psychologists want to get a better
understanding of people; how their social context determines their language behavior,
how they produce and comprehend sentences, and so on. Their models are evaluated
in terms of whether there is statistical evidence for their predictions in actual human
behavior. Computational linguists evaluate their models (“algorithms”) on large col-
lections of human-produced data; one model is better than another if it accounts for
more ofthe data. Ofcourse, a model can perform wellwhen evaluated onhuman data,
but be completely unrealistic from a psychological point of view. If a computational
linguist develops a referring expression generation algorithm (or a machine translation
system or an automatic summarizer) which accounts for the data in a way which is
psychologically unrealistic, the work will generally not be of interest to psychologists.
Conversely, if psychological insights are difﬁcult to formalize or require complex algo-
rithmsordatastructures,computationallinguistsarelikelynottobeenthusiasticabout
applying them. Obviously, this hinders cross-pollination of ideas as well.
Third,andsomewhatrelatedtothepreviouspoint,itsometimesseemsthatcompu-
tational linguists see trees where psychologists see a forest. Psychologists appear to be
most interested in showing a general effect (and are particularly appreciative of clever
and elegant experimental designs which reveal these effects); if merely counting words
alreadygivesyouastatisticallyreliableeffect,thenwhybotherwithamorecomplicated
way of counting n-grams and worrying about back-off smoothing to deal with data
sparseness? Doing so would conceivably give you a better estimate of the signiﬁcance
and size of your effect, but would probably not change your story in any fundamental
way.Computationallinguists,bycontrast,evaluatetheirmodelson(oftenshared)data-
sets(andtendtobemoreimpressedbytechnicalprowess—e.g.,newstatisticalmachine
learningmodels—orbysmartwaysofautomaticallycollectinglargequantitiesofdata);
eachdatapointthatisprocessedincorrectlybytheirmodeloffersapotentialadvantage
for someone else’s model.
In view of observations such as these, it is perhaps not surprising that compu-
tational linguists and psychologists have remained largely unaware of each other’s
work so far. Predicting the future is a tricky thing, but it seems not unlikely that most
computational linguists and psychologists will continue going their own way in the
future. Nevertheless, I hope to have shown here that both communities could beneﬁt
fromtheoccasionalforayintotheothers’territory.Forpsychologists,thetoolsandtech-
niquesdevelopedbycomputationallinguistscouldfurthertheirresearch,byhelpingto
make their models and theories more explicit and hence easier to test and compare.
For computational linguists, insights from both the social psychology of language and
from psycholinguists could contribute to a range of applications, from opinion mining
to text understanding and generation. Obviously, this contribution could be on the
level of “words”, but a more substantial contribution is conceivable as well. As we
have seen, psychologists are particularly strong in explanatory theories (on affect, on
interaction, etc.) and perhaps taking these as starting points for our applications (e.g.,
292
Krahmer Last Words
onaffectiveandinteractivegeneration)couldmakethemtheoreticallymoreinteresting
and empirically more adequate.
Acknowledgments
ThankstoRobert Dale forinvitingmeto
writeaLast Words pieceonthistopicand
forhisusefulcommentsonanearlier
version.Thispiece grewout of discussions I
hadover theyearswithbothcomputational
linguistsand psychologists, including
MartijnBalsters, Kees van Deemter,Albert
Gatt,Roger van Gompel,ErwinMarsi,
DiederikStapel,Marc Swerts,Mari¨et
Theune,and Ad Vingerhoets.Needless
tosay, I aloneam responsiblefor the
simpliﬁcationsand opinionsinthiswork.
Ireceived ﬁnancialsupportfromthe
NetherlandsOrganizationfor Scientiﬁc
Research (NWO),viatheVici project
“Bridgingthegap betweencomputational
linguisticsandpsycholinguistics: Thecase
ofreferringexpressions” (277-70-007),
whichis gratefullyacknowledged.
References
Arts,Anja.2004.Overspeciﬁcationin
InstructiveTexts.Unpublished Ph.D.
thesis, TilburgUniversity.
Branigan,HollyP., MartinJ.Pickering,Jamie
Pearson,and JanetF. McLean.(in press).
Linguisticalignment betweenhumans
and computers.JournalofPragmatics.
Brennan,Susanand HerbertH.Clark.1996.
Conceptual pactsand lexical choicein
conversation.JournalofExperimental
Psychology, 22(6):1482–1493.
Brennan,SusanE.and JoyE.Hanna.2009.
Partner-speciﬁcadaptationindialog.
TopicsinCognitiveScience,1(2):274–291.
Brown-Schmidt,S.and M.Tanenhaus.2004.
Primingand alignment:Mechanism or
consequence? commentaryon Pickering
and Garrod2004.BehavioralandBrain
Sciences,27:193–194.
Brown-Schmidt,Sarah.2009.Partner-speciﬁc
interpretationof maintainedreferential
precedentsduringinteractivedialog.
JournalofMemoryandLanguage,
61:171–190.
Chater,Nickand ChristopherD.Manning.
2006. Probabilisticmodelsof language
processingand acquisition.Trends in
CognitiveScience,10:335–344.
Chung,C.K.andJamesW.Pennebaker.2007.
Thepsychologicalfunctionof function
words.InK. Fiedler,editor,Social
Communication:FrontiersofSocial
Psychology. PsychologyPress,NewYork,
pages343–359.
Clark,HerbertH.1996.UsingLanguage.
CambridgeUniversityPress,
Cambridge,UK.
Clark,HerbertH.andAdrianBangerter.
2004. Changingideas aboutreference.In
IraA. Noveckand Dan Sperber,editors,
ExperimentalPragmatics.Palgrave
Macmillan,Basingstoke, pages25–49.
Clark,HerbertH.andDeanna Wilkes-Gibbs.
1986. Referringas acollaborativeprocess.
Cognition,22:1–39.
Cohn,M.,M. Mehl,and JamesW.
Pennebaker.2004.Linguisticmarkers
of psychologicalchangesurrounding
September11, 2001.Psychological
Science,15:687–693.
Crocker,Matthew W. (inpress).
Computationalpsycholinguistics.In Alex
Clark,ChrisFox,and ShalomLappin,
editors,ComputationalLinguisticsand
NaturalLanguageProcessingHandbook.
WileyBlackwell,London,UK.
Dale,Robert and EhudReiter.1995.
Computationalinterpretationsof the
Griceanmaximsinthegenerationof
referringexpressions.CognitiveScience,
18:233–263.
Douglas,Karen and RobbieSutton.
2006. When whatyou say aboutothers
says somethingabout you:Language
abstraction andinferences about
describers’attitudesandgoals.Journal
ofExperimentalSocialPsychology,42:
500–508.
Engelhardt,PaulE.,KarlG.D.Bailey, and
FernandaFerreira.2006. Dospeakers and
listenersobservetheGricean Maxim of
Quantity?JournalofMemoryandLanguage,
54:554–573.
Gatt,Albert,AnjaBelz,and EricKow.2009.
Thetuna-regchallenge2009: Overview
and evaluationresults.InProceedings
ofthe12thEuropeanWorkshopon
NaturalLanguageGeneration(ENLG),
pages174–182, Athens.
Halevy,Alon,PeterNorvig,andFernando
Pereira.2009. Theunreasonable
effectiveness of data.IEEEIntelligent
Systems,24:8–12.
Holmes,David I.1998. Theevolutionof
stylometryinhumanitiesscholarship.
LiteraryandLinguisticComputing,
13:111–117.
293
ComputationalLinguistics Volume36,Number2
Horton,W. S.and B.Keysar. 1996.When
dospeakers takeintoaccount common
ground?Cognition,59:91–117.
Hovy,EduardH.1990. Pragmaticsand
naturallanguagegeneration.Artiﬁcial
Intelligence,43:153–197.
Jurafsky,Dan.2003. Probabilistic
modelinginpsycholinguistics: Linguistic
comprehension and production.In Rens
Bod,JenniferHay,and StefanieJannedy,
editors,ProbabilisticLinguistics.MIT Press,
Cambridge,MA, pages39–96.
Keysar, B.,S.Lin,andD. J.Barr.2003.
Limitsontheoryof minduseinadults.
Cognition,89:25–41.
Krahmer,Emieland DiederikStapel.2009.
Abstract language,global perception:
Howlanguageshapes what wesee. In
ProceedingsoftheAnnualMeetingofthe
CognitiveScienceSociety,pages286–291,
Amsterdam.
Kronm¨uller,E.and DaleBarr.2007.
Perspective-freepragmatics:Broken
precedents andtherecovery-from-
preemptionhypothesis.Journalof
MemoryandLanguage,56:436–455.
Maass, A.,D.Salvi,L.Arcuri,andG. Semin.
1989. Languageusein intergroupcontexts:
Thelinguisticintergroupbias.Journal
ofPersonalityandSocialPsychology,
57:981–993.
Metzing, CharlesA.and Susan E.Brennan.
2003. When conceptual pacts arebroken:
Partnereffects onthecomprehensionof
referringexpressions.JournalofMemory
andLanguage,49:201–213.
Olson,David R. 1970. Languageand
thought:Aspects of acognitivetheory
of semantics.PsychologicalReview,
77:257–273.
Pado,Ulrike,MatthewW.Crocker, and
FrankKeller.2009. Aprobabilisticmodel
of semantic plausibilityin sentence
processing.CognitiveScience,33:794–838.
Pang,B.and L.Lee. 2008.Opinionmining
and sentiment analysis.Foundationsand
TrendsinInformationRetrieval,2:1–135.
Paraboni,Ivandr´e,Kees van Deemter,
and JudithMasthoff.2007. Generating
referringexpressions: Makingreferents
easy toidentity.ComputationalLinguistics,
33:229–254.
Pennebaker,JamesW., C. Groom,D.Loew,
and J.Dabbs. 2004.Testosterone asa social
inhibitor:Twocase studiesof theeffect of
testosteronetreatmentonlanguage.Journal
ofAbnormalPsychology, 113:172–175.
Pickering,Martinand SimonGarrod.2004.
Towardsamechanistic psychologyof
dialogue.BehaviouralandBrainSciences,
27:169–226.
Reiter, Ehud.2007.Theshrinkinghorizonsof
computationallinguistics.Computational
Linguistics,33:283–287.
Rude,S., E.Gortner,and JamesW.
Pennebaker.2004. Languageuseof
depressed anddepression-vulnerable
college students.CognitionandEmotion,
18:1121–1133.
Semin,G¨un.2009.Languageand social
cognition.InF.StrackandJ.F¨orster,
editors,SocialCognition:TheBasisofHuman
Interaction.PsychologyPress,London,
pages 269–290.
Semin,G¨un andKlaus Fiedler.1988.The
cognitivefunctionsof linguisticcategories
in describingpersons:Social cognition and
language.JournalofPersonalityandSocial
Psychology, 34:558–568.
Stapel,DiederikandG¨un Semin.2007.
Themagicspell oflanguage.Journalof
PersonalityandSocialPsychology, 93:23–33.
Stirman,ShannonandJames W.Pennebaker.
2001. Word usein thepoetryof suicidal
and nonsuicidal poets.Psychosomatic
Medicine, 63:517–522.
WardlowLane,Liane,Michelle Groisman,
and Victor S.Ferreira.2006.Don’t talk
about pinkelephants!: Speakers’control
over leakingprivateinformationduring
languageproduction.PsychologicalScience,
17:273–277.
Wigboldus,Dani¨el,G¨un Semin,and Russell
Spears. 2000.Howdowecommunicate
stereotypes? linguisticbases and
inferential consequences.Journalof
PersonalityandSocialPsychology, 78:5–18.
Winograd,Terry.1980. What does itmeanto
understandlanguage?CognitiveScience,
4:209–241.
294

