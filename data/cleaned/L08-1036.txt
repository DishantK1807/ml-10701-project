<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>G Grefenstette</author>
<author>P Tapanainen</author>
</authors>
<title>What is a Word, what is a Sentence? Problems of Tokenization</title>
<date>1994</date>
<booktitle>International Conference on Computational Lexicography</booktitle>
<pages>79--87</pages>
<location>Budapest</location>
<contexts>
<context>gnificant improvement is obtained over a baseline system that tokenizes texts on every non-alphanumeric character. 1 Introduction Tokenization is the process of isolating word-like units from a text (Grefenstette and Tapanainen 1994); the process of mapping sentences from character strings into strings of words (Guo 1997). Even though we may think that tokenization is not very important, it can be a step that influences the fina</context>
</contexts>
<marker>Grefenstette, Tapanainen, 1994</marker>
<rawString>Grefenstette, G. and Tapanainen, P. (1994) What is a Word, what is a Sentence? Problems of Tokenization. International Conference on Computational Lexicography, Budapest, 79-87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J G Gil</author>
<author>M A Alonso</author>
<author>M V Ferro</author>
</authors>
<title>A Common Solution for Tokenization and Part-ofSpeech Tagging</title>
<date>2002</date>
<booktitle>Proceedings of the 5th International Conference on Text, Speech and Dialogue</booktitle>
<marker>Gil, Alonso, Ferro, 2002</marker>
<rawString>Gil, J. G., Alonso, M. A. and Ferro, M. V. (2002) A Common Solution for Tokenization and Part-ofSpeech Tagging. Proceedings of the 5th International Conference on Text, Speech and Dialogue.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Guo</author>
</authors>
<title>Critical Tokenization and its Properties</title>
<date>1997</date>
<journal>Computational Linguistic</journal>
<volume>23</volume>
<pages>569--596</pages>
<contexts>
<context> 1 Introduction Tokenization is the process of isolating word-like units from a text (Grefenstette and Tapanainen 1994); the process of mapping sentences from character strings into strings of words (Guo 1997). Even though we may think that tokenization is not very important, it can be a step that influences the final results of a more complex task. For example McNamee and Mayfield (2004) show that the re</context>
</contexts>
<marker>Guo, 1997</marker>
<rawString>Guo J. (1997) Critical Tokenization and its Properties, Computational Linguistic, 23(4), pp.569-596.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Loper</author>
<author>S Bird</author>
</authors>
<title>NLTK: The Natural Language Toolkit</title>
<date>2002</date>
<booktitle>ACL Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics</booktitle>
<location>New Jersey</location>
<contexts>
<context> tasks performed on medical domain texts. 2 Related Work The traditional approach to perform the tokenization task uses hand-crafted rules with regular expressions and/or finite state automata (NLTK (Loper and Bird 2002)). MtSeg, a system developed by P. di Cristo1 is a rule-based tokenization system that can be tuned for various languages. The system was enhanced with the corresponding resources for several Western</context>
</contexts>
<marker>Loper, Bird, 2002</marker>
<rawString>Loper, E. and Bird, S. (2002) NLTK: The Natural Language Toolkit. ACL Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics. New Jersey, US. McNamee, P., and Mayfield J. Character N-gram Tokenization for European Language Retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Information Retrieval</author>
</authors>
<date>2004</date>
<pages>7--1</pages>
<marker>Retrieval, 2004</marker>
<rawString>Information Retrieval, 7(1-2):73-97, 2004.</rawString>
</citation>
</citationList>
</algorithm>

