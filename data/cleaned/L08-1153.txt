<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>Basu</author>
<author>Raymond J Mooney</author>
</authors>
<title>Active semi-supervision for pairwise constrained clustering</title>
<date>2004</date>
<journal>Mikhail Bilenko, Sugato</journal>
<pages>333--344</pages>
<marker>Basu, Mooney, 2004</marker>
<rawString>2004. Active semi-supervision for pairwise constrained clustering. pages 333–344. Mikhail Bilenko, Sugato Basu, and Raymond J. Mooney.</rawString>
</citation>
<citation valid="true">
<title>Integrating Constraints and Metric Learning in Semi-Supervised Clustering</title>
<date>2004</date>
<booktitle>In ICML-2004</booktitle>
<pages>81--88</pages>
<marker>2004</marker>
<rawString>2004. Integrating Constraints and Metric Learning in Semi-Supervised Clustering. In ICML-2004, pages 81– 88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Cohn</author>
<author>Rich Caruana</author>
<author>Andrew McCallum</author>
</authors>
<date>2003</date>
<contexts>
<context>ty, which depends on the target word. Therefore, we use a semi-supervised clustering approach for this task. In this approach, a constraint on a pair of data, set by the user, is used for clustering (Cohn et al., 2003)(Basu et al., 2004)(Bilenko et al., 2004)(Klein et al., 2002). The system selects some pairs from the data set, and offers them to a user. The user enters the pair’s constraint (must-link or cannot-l</context>
</contexts>
<marker>Cohn, Caruana, McCallum, 2003</marker>
<rawString>David Cohn, Rich Caruana, and Andrew McCallum. 2003.</rawString>
</citation>
<citation valid="true">
<title>Semi-supervised Clustering with User Feedback</title>
<tech>Technical Report TR2003–1892</tech>
<institution>Cornell University</institution>
<marker></marker>
<rawString>Semi-supervised Clustering with User Feedback. Technical Report TR2003–1892, Cornell University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Hindle</author>
</authors>
<title>Noun classification from predicate argument structures</title>
<date>1990</date>
<booktitle>In Proceedings of the 28th annual meeting on Association for Computational Linguistics (ACL-90</booktitle>
<pages>268--275</pages>
<contexts>
<context>g Ma and Hitoshi Isahara, 2001). We can easily construct the case slot of a verb (Philip, 1992) using example sentences clustered based on the meaning of the verb. A thesaurus can easily be designed (Hindle, 1990) using example sentences clustered based on the meaning of a noun. Clustering of example sentences based on the meaning of a target word can be performed by distinguishing between the different sense</context>
</contexts>
<marker>Hindle, 1990</marker>
<rawString>Donald Hindle. 1990. Noun classification from predicate argument structures. In Proceedings of the 28th annual meeting on Association for Computational Linguistics (ACL-90), pages 268–275.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Sepandar D Kamvar</author>
<author>Christopher D Manning</author>
</authors>
<title>From Instance-level Constraints to Spacelevel Constraints: Making the Most of Prior Knowledge in Data Clustering</title>
<date>2002</date>
<booktitle>In ICML-2002</booktitle>
<pages>307--314</pages>
<contexts>
<context>mi-supervised clustering approach for this task. In this approach, a constraint on a pair of data, set by the user, is used for clustering (Cohn et al., 2003)(Basu et al., 2004)(Bilenko et al., 2004)(Klein et al., 2002). The system selects some pairs from the data set, and offers them to a user. The user enters the pair’s constraint (must-link or cannot-link) into the system. Must-link indicates that the two data i</context>
</contexts>
<marker>Klein, Kamvar, Manning, 2002</marker>
<rawString>Dan Klein, Sepandar D. Kamvar, and Christopher D. Manning. 2002. From Instance-level Constraints to Spacelevel Constraints: Making the Most of Prior Knowledge in Data Clustering. In ICML-2002, pages 307–314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masaki Murata</author>
</authors>
<title>Masao Utiyama and Kiyotaka Uchimoto and Qing Ma and Hitoshi Isahara</title>
<date>2001</date>
<booktitle>In Proceedings of the SENSEVAL-2</booktitle>
<pages>135--138</pages>
<marker>Murata, 2001</marker>
<rawString>Masaki Murata and Masao Utiyama and Kiyotaka Uchimoto and Qing Ma and Hitoshi Isahara. 2001. Japanese word sense disambiguation using the simple Bayes and support vector machine methods. In Proceedings of the SENSEVAL-2, pages 135–138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Resnik Philip</author>
</authors>
<title>WordNet and Distributional Analysis: A Class-based Approach to Lexical Discovery</title>
<date>1992</date>
<booktitle>In Proceedings of AAAI-92 Workshop on Statistically-Based NLP Techniques</booktitle>
<pages>48--56</pages>
<contexts>
<context>le sentences as training data during inductive learning (Masaki Murata and Masao Utiyama and Kiyotaka Uchimoto and Qing Ma and Hitoshi Isahara, 2001). We can easily construct the case slot of a verb (Philip, 1992) using example sentences clustered based on the meaning of the verb. A thesaurus can easily be designed (Hindle, 1990) using example sentences clustered based on the meaning of a noun. Clustering of </context>
</contexts>
<marker>Philip, 1992</marker>
<rawString>Resnik Philip. 1992. WordNet and Distributional Analysis: A Class-based Approach to Lexical Discovery. In Proceedings of AAAI-92 Workshop on Statistically-Based NLP Techniques, pages 48–56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroyuki Shinnou</author>
<author>Minoru Sasaki</author>
</authors>
<title>Unsupervised learning of word sense disambiguation rules by estimating an optimum iteration number in the EM algorithm</title>
<date>2003</date>
<contexts>
<context> our system. The system converts a sentence into a feature list. Using this feature list, the system measures similarities between sentences. Our system uses the following features used in the paper (Shinnou and Sasaki, 2003). Suppose the target word is DB BP DB CX , which is the CX-th word in the sentence. e1: the word DB CXA0BD e2: the word DB CXB7BD e3: two content words in front of DB CX e4: two content words behind </context>
</contexts>
<marker>Shinnou, Sasaki, 2003</marker>
<rawString>Hiroyuki Shinnou and Minoru Sasaki. 2003. Unsupervised learning of word sense disambiguation rules by estimating an optimum iteration number in the EM algorithm.</rawString>
</citation>
<citation valid="false">
<booktitle>In Proceedings of Seventh Conference on Natural Language Learning (CoNLL-2003</booktitle>
<pages>41--48</pages>
<marker></marker>
<rawString>In Proceedings of Seventh Conference on Natural Language Learning (CoNLL-2003), pages 41–48.</rawString>
</citation>
</citationList>
</algorithm>

