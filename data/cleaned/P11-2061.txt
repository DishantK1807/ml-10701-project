Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 351–356,
Portland, Oregon, June 19-24, 2011. c©2011 Association for Computational Linguistics
Temporal Evaluation 
 
Naushad UzZaman and James F. Alen 
Computer Science Department 
University of Rochester 
Rochester, NY, USA 
{naushad, james}@cs.rochester.edu 
 
Abstract 
In this paper we propose a new method for 
evaluating systems that extract temporal 
information from text. It uses teporal 
closure
1
 t reward relations that are 
equivalent but distinct. Our metric 
measures the overall performance of 
systems wi a single score, making 
comparison between different systems 
straightforward. Our approach is easy to 
implement, intuitive, acurate, scalable and 
computationally inexpensive. 
1 Introduction

The recent emergence of language procesing 
applications like question answering, information 
extraction, and document sumarization has 
motivated the ned for temporally-aware systems. 
This, along with the availability of the temporal 
annotation scheme TimeML (Pustejovsky et al., 
2003), a temporally annotated corpus, TimeBank 
(Pustejovsky et al., 203) and the temporal 
evaluation challenges TempEval-1 (Verhagen et 
al., 207) and TempEval-2 (Pustejovsky and 
Verhagen, 2010), has led to an explosion of 
research on temporal information processing (TIP). 
Prior evaluation methods (TempEval-1, 2) for 
different TIP subtasks have borrowed precision 
and recall measures from the information retrieval 
comunity. This has two problems: First, systems 
express temporal relations in different, yet 
equivalent, ways. Consider a scenario where the 
                                                             
1
 Temporal closure is a reasoning mechanism that derives new 
implied temporal relations, i.e. makes implicit temporal 
relations explicit. For example, if we know A before B, B 
before C, then using temporal closure we can derive A before 
C. Alen (1983) demonstrates the closure table for 13 Alen 
interval relations. 
reference annotation contains e
1
<e
2
 and e
2
<e
3
 and 
the system identifies the relation e
1
<e
3
. The 
traditional evaluation metric wil fail to identify 
e
1
<e
3
 as a correct relation, which is a logical 
consequence of the reference anotation. Second, 
traditional evaluations tel us how el a system 
performs in a particular task, but not the overall 
performance. For example, in TempEval-2 there 
were 6 subtasks (event extraction, temporal 
expression extraction and 4 subtasks on identifying 
temporal relations). Thus, different systems 
perform best is different subtasks, but we can’t 
compare overall performance of systems.  
We use temporal closure to identify equivalent 
temporal relations and produce a single score that 
measures the temporal awarenes of each system. 
We use Timegraph (Miler and Schubert, 190) for 
computing temporal closure, which makes our 
system scalable and computationally inexpensive.  
2 Related
Work 
To calculate the inter-annotator agreement between 
annotators in the temporal annotation task, some 
researchers have used semantic matching to reward 
distinct but equivalent temporal relations. Such 
techniques can equally well be applied to system 
evaluation. 
Setzer et al. (203) use temporal closure to 
reward equivalent but distinct relations. Consider 
the example in Figure 1 (due to Tanier and 
Muler, 208). Consider graph K as the reference 
annotation graph, and S
1, S
2
 and S
3
 as outputs of 
different systems. The bold edges are the extracted 
relations and the dotted edges are derived. The 
traditional matching aproach wil fail to verify 
B<D is a correct relation in S
2, since there is no 
explicit edge between B and D in reference 
annotation (K). But a metric using temporal 
closure would create all implicit edges and be able 
to reward B<D edge in S
2
.  
351
 
Figure 1: Examples of temporal graphs and relations 
Setzer et al.’s aproach works for this particular 
case, but as pointed by Tanier and Muler (2008), 
it gives the same importance to all relations, 
whereas some relations are not as crucial as others. 
For example, with K again as the reference 
annotation, S
2
 and S
3
 both identify two corect 
relations, so both should have a 100% precision, 
but in terms of recall, S
3
 identifed 2 explict 
relations and S
2
 identified one explicit and one 
implicit relation. With Setzer at al.’s technique, 
both S
2
 and S
3
 wil get the same score, which is not 
accurate. Tanier and Muler handle this problem 
by finding the core
2
 relations. For recall, they 
consider the refrence core relations found in the 
system core relations and for precision they 
consider the system core relations found in the 
reference core relations. They noted that core 
relations do not contain all information provided 
by closed graphs. Hence their measure is only an 
approximation of what should be asesed. 
Consider the previous example again. If we are 
evaluating graph S
2, they wil fail to verify that 
B<D is a correct edge. 
We have shown that both of these existing 
evaluation mechanism reward relations based on 
semantic matching, but stil fail in specific cases.  
3 Temporal
Evaluation 
We also use temporal closure to reward equivalent 
but distinct relations. However, we do not compare 
against the temporal closure of reference 
annotation and system output, like Setzer et al., but 
                                                             
2
 For relation R
A, B
 betwen A and B, derivations are R
A, C, R
B, 
C, R
A, D, R
B, D
. If the intersection of al these derived relations 
equals R
A, B, it means that R
A, B
 is not a core relation, since it 
can be obtained by composing some other relations. 
Otherwise, the relation is a core, since removing it tends to 
los of information.  
we use the temporal closure to verify if a temporal 
relation can be derived or not. Our precision and 
recall is defined as: 
Precision = (# of system temporal relations that can be 
verified from reference anotation temporal closure 
graph / # of temporal relations in system output) 
Recal = (# of refrence anotation temporal relations 
that can be verified from system output’s temporal 
closure graph / # of teporal relations in refrence 
annotation) 
The harmonic mean of precision and recal, i.e. 
fscore, wil give an evaluation of the temporal 
awareness of the system. 
As an example, consider again the examples in 
Figure 1, with K as reference anotation. S
1 
and S
3
 
clearly have 10% precision, ad S
2 
also gets 
100% precision, since the B<D edge can be 
verified through the temporal closure graph of K. 
Note, our recal measure doesn’t reward the B<D 
edge of S
2, but it is counted for precision. S
1 
and S
3 
both get a recall of 2/3, since 2 edges can be 
verified in the reference temporal closure graph. 
This scheme is similar to the MUC-6 scoring for 
coreference (Vilain et al., 195). Their scoring 
estimated the minmal number of mising links 
necessary to complete co-reference chain in order 
to make it match the human anotation. Here in 
both S
1 
and S
3, we are mising one edge to match 
with the reference annotation; hence 2/3 is the 
appropriate score. Precision, recall and fscore for 
all these system output are shown in Table 1. 
System Precision Recal Fscore 
S
1
 2/2=1 2/3=0.66 0.8 
S
2
 2/2=1 1/3=0.33 0.5 
S
3
 2/2=1 2/3=0.66 0.8 
Table 1: Precision, recal and fscore for systems in 
Figure 1 acording to our evaluation metric 
4 Implementation

Our proposed aproach is easy to implement with 
an existing temporal closure implementation. We 
prefered Timegraph (Miler and Schubert, 190) 
over Allen’s interval closure algorithm (Allen, 
1983) because Timegraph has been shown to be 
more scalable
3
 to larger problems (Yampratom 
                                                             
3
 Allen’s temporal closure takes O(n
2
) space for n intervals, 
whereas Timegraph takes O(n+e) space, where n is the 
number of time points
3
 and e is the number of relations 
betwen them. In terms of closure computation, without 
352
and Alen, 193). Furthermore, the aditional 
expressive power of interval disjunction in Allen 
(1983) does not appear to play a significant role in 
temporal extractions from text. 
A Timegraph G = (T, E) is an acyclic directed 
graph in which T is the set of vertices (nodes) and 
E is the set of edges (links). It is partitioned into 
chains, which are defined as sets of points in a 
linear order. Links between points in the same 
chain are in-chain links and links between points in 
different chains are cros-chain links. Each point 
has a numeric pseudo-time, which is arbitrary 
except that it maintains the ordering relationship 
betwen the points on the same chain. Chain and 
pseudo-time information are calculated when the 
point is first entered into the Timegraph. 
Determining relationship betwen any two points 
in the same chain can be done in constant time 
simply by comparing the pseudo-times, rather than 
folowing the in-chain links. On the other hand, 
relationship betwen points in different chains can 
be found with a search in cross-chain links, which 
is dependent on the number of edges (i.e. number 
of chains and number of cross-chain links). A 
metagraph keeps track of the cross-chain links 
effectively by maintaining a metanode for each 
chain, and using a cros-chain links between 
metanodes. More details about Timegraph can be 
found in Miler and Schubert (1990) and Taugher 
(1983). 
Timegraph only supports simple point relations 
(<, =, ≤), but we ned to evaluate systems based on 
TimeML, which is based on interval algebra. 
However, single (i.e., non-disjunctive) interval 
relations can be easily converted to point 
relations
4
. 
For eficiency, we want to minimize the number 
of chains constructed by Tiegraph, since with 
more chains our search in Timegraph wil take 
more time. If we arbitrarily chose TimeML 
TLINKs (temporal links) and add them we wil 
create some extra chains. To avoid this, we start 
with a node and traverse through its neighbors in a 
systematic fashion trying to add in chain order. 
                                                                                                
disjunction Alen’s algorithm computes in O(n
2
), whereas 
Timegraph takes O(n+e) time, n and e are same as before. 
4
 Interval relation betwen two intervals X and Y is 
represented with points x1, x2, y1 and y2, where x1 and y1 are 
start points and x2 and y2 are end points of X and Y. 
Temporal relations between interval X and Y is represented 
with point relation betwen x1,y1; x1,y2; x2,y1 and x2,y2. 
This aproach decreases number of nodes+edges 
by 2.3% in complete TimeBank corpus, which 
eventually afects searching in Timegraph. 
Next adition is to optimize Timegraph 
construction. For each relation we have to make 
sure all constraints are met. The easiest and best 
way to aproach this is to consider al relations 
together. For example, for interval relation X 
includes Y, th point relation constraints are: 
x1<y1, x1<y2, x2>y1, x2>y2, x1<x2 and y1<y2. 
We want to consider all constraints together as, x1 
< y1 < y2 < x2 and ad al together in the 
Timegraph. In Table 2, we show TimeML relations 
and equivalent Alen’s relation
5, then equivalent 
representation in point algebra and finally point 
algebra represented as a chain, which makes 
adding relations in Timegraph much easier with 
fewer chains. These additions make Timegraph 
more efective for TimeML corpus. 
TimeML 
relations 
Allen 
relations 
Equivalent in 
Point Algebra 
Point 
Algebra 
represented 
as a chain 
Before Before x1<y1, x1<y2, 
x2<y1, x2<y2 
x1 < x2 < 
y1 < y2 
After After x1>y1, x1>y2, 
x2>y1, x2>y2 
y1 < y2 < x1 
< x2 
IBefore Meet x1<y1, x1<y2, 
x2=y1, x2<y2 
x1 < x2 = y1 
< y2 
IAfter MetBy x1>y1, x1=y2, 
x2>y1, x2>y2 
y1 < y2 = x1 
< x2 
Begins Start x1=y1, x1<y2, 
x2>y1, x2<y2 
x1 = y1 < x2 
< y2 
BegunBy StartedBy x1=y1, x1<y2, 
x2>y1, x2>y2 
x1 = y1 < y2 
< x2 
Ends Finish x1>y1, x1<y2, 
x2>y1, x2=y2 
y1 < x1 < x2 
= y2 
EndedBy FinishedBy x1<y1, x1<y2, 
x2>y1, x2=y2 
x1 < y1 < y2 
= x2 
IsIncluded, 
During 
During x1>y1, x1<y2, 
x2>y1, x2<y2 
y1 < x1 < x2 
< y2 
Includes Contains x1<y1, x1<y2, 
x2>y1, x2>y2 
x1 < y1 < y2 
< x2 
Identity & 
Simultaneous 
(=) 
Equality x1=y1, x1<y2, 
x2>y1, x2=y2 
x1 = y1 < x2 
= y2 
Table 2: Interval algebra and equivalent point algebra 
                                                             
5
 We couldn’t find equivalent of Overlaps and OverlapedBy 
from Alen’s interval algebra in TimeML relations. 
353
5 Evaluation

Our proposed evaluation metric has some very 
good properties, which makes it very suitable as a 
standard metric. This section presents a few 
empirical tests to show the usefulness of our 
metric. 
Our precision and recal goes with the same 
spirit with traditional precision and recall, as a 
result, performance decreases with the decrease of 
information. Specificaly, 
i. if we remove relations from the reference 
annotation and then compare that against the full 
reference annotation, then recall decreases linearly. 
Shown in Figure 2. 
 
Figure 2: For 5 TimeBank documents, the graph shows 
performance drops linearly in recal by removing 
temporal relations one by one. 
ii. if we introduce noise by ading new relations, 
then precision decreases linearly (Figure 3). 
 
Figure 3: For 5 TimeBank documents, the graph shows 
performance drops linearly in precision by ading new 
(wrong) temporal relations one by one. 
iii. if we introduce noise by changing existing 
relations then fscore decreases linearly (Figure 4). 
 
Figure 4: For 5 TimeBank documents, the graph shows 
performance drops linearly in fscore by changing 
temporal relations one by one. 
iv. if we remove temporal entities (such as 
events or temporal expressions), performance 
decreases more for entities that are teporally 
related to more entities. This means, if the system 
fails to extract important temporal entities then the 
performance wil decrease more (Figure 5). 
 
Figure 5: For 5 TimeBank documents, performance 
drop in recal by removing temporal entities. 
Temporal entities related with a maximum 
number of entities are removed first. It is evident 
from the graph that performance decreased more 
for removing important entities (first few entities). 
These properties explain that our final fscore 
captures how well a system extacts events, 
temporal expressions and temporal relations. 
Therefore this single score captures al the scores 
of six subtasks in TempEval-2, making it very 
convenient and straightforward to compare 
different systems. 
Our implementation using Timegraph is also 
scalable. We ran our Timegraph construction 
algorithm on the complete TimeBank corpus and 
found that Timegraph construction time increases 
linearly with the increase of number of nodes and 
edges (= # of cros-chain links and # of chains) 
(Figure 6).  
The largest document, with 235 temporal 
relations (around 900 nodes+edges in Timegraph) 
354
only takes 0.2 seconds in a laptop computer with 
4GB RAM and 2.26 GHz Core 2 Duo processor. 
 
Figure 6: Number of nodes+edges (# of cros-chain 
links + # of chains) against time (in seconds) for 
Timegraph construction of al TimeBank documents. 
We also confirmed that the number of nodes + 
edges in Timegraph also increases linearly with 
number of temporal relations in TimeBank 
documents. , i.e. our Timegraph construction time 
correlates with the # of relations in TimeBank 
documents (Figure 7). 
 
Figure 7: Number of temporal relations in al TimeBank 
documents against the number of nodes and edges in 
Timegraph of those documents 
Searching in Timegraph, which we ned for 
temporal evaluation, also depends on number of 
nodes and edges, hence number of TimeBank 
relations. We ran a temporal evaluation on 
TimeBank corpus using the same document as 
system output. The operation included creating two 
Timegraphs and searching in the Timegraph. As 
expected, the searching time also increases linearly 
against the number of relations and is 
computationally inexpensive (Figure 8). 
 
Figure 8: Number of relation against time (in seconds) 
for al documents of TimeBank corpus. 
6 Conclusion

We proposed a temporal evaluation that considers 
semantically similar but distinct temporal relations 
and consequently gives a single score, which could 
be used for identifying the temporal awareness of a 
system. Our aproach is easy to implement, 
intuitive and acurate. We implemented it using 
Timegraph for handling temporal closure in 
TimeML derived corpora, which makes our 
implementation scalable and computationaly 
inexpensive. 
References 
James F. Allen. 1983. Maintaining knowledge 
about temporal intervals. Comunications of the 
ACM 26, 832-843. 
S. Miler and L. Schubert. 190. Time revisited. 
Computational Inteligence 6, 108-118. 
J. Pustejovsky, P. Hanks, R. Sauri, A. Se, R. 
Gaizauskas, A. Setzer, D. Radev, B. Sundheim, 
D. Day, L. Fero and M. Lazo. 2003. The 
TIMEBANK corpus. Procedings of the Corpus 
Linguistics, 647–656. 
James Pustejovsky, Jos M. Castao, Robert Ingria, 
Roser Sauri, Robert J. Gaizauskas, Andrea 
Setzer, Graham Katz and Dragomir R. Radev. 
2003. TimeML: Robust Specication of Event 
and Temporal Expressions in Text. . 
Procedings of the New Directions in Question 
Answering. 
James Pustejovsky and Marc Verhagen. 2010. 
SemEval-2010 task 13: evaluating events, time 
expressions, and temporal relations (TempEval-
2). Procedings of the Workshop on Semantic 
355
Evaluations: Recent Achievements and Future 
Directions. 
A Setzer, R Gaizauskas and M Heple. 203. 
Using semantic inferences for temporal 
annotation comparison. Proceedings of the 
Fourth International Workshop on Inference in 
Computational Semantics (ICOS-4), 25-26. 
X Tanier and P Muler. 208. Evaluation Metrics 
for Automatic Temporal Anotation of Texts. 
Procedings of the Proceedings of the Sixth 
International Language Resources and 
Evaluation (LREC'08). 
J. Taugher. 1983. An eficient representation for 
time information. Department of Computer 
Science. Edmonton, Canada: University of 
Alberta. 
Marc Verhagen, Robert Gaizauskas, Frank 
Schilder, Mark Heple, Graham Katz and James 
Pustejovsky. 207. SemEval-2007 Task 15: 
TempEval Temporal Relation Identification. 
Procedings of the 4th International Workshop 
on Semantic Evaluations (SemEval 2007). 
Marc Vilain, John Burger, John Aberden, Denis 
Conoly and Lynete Hirschman. 195. A 
model-theoretic coreference scoring scheme. 
Procedings of the MUC6 ’95: Procedings of 
the 6th conference on essage understanding. 
Ed Yampratom and James F. Allen. 193. 
Performance of Temporal Reasoning Systems. 
TRAINS Technical Note 93-1. Rochester, NY: 
University of Rochester. 
 
 
 
 
356

