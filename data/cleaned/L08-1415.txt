<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>T Baldwin</author>
<author>F Bond</author>
</authors>
<title>Learning the countability of english nouns from corpus data</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics</booktitle>
<pages>463--470</pages>
<marker>Baldwin, Bond, 2003</marker>
<rawString>T. Baldwin and F. Bond. 2003. Learning the countability of english nouns from corpus data. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, July 2003, pages 463–470.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Bel</author>
<author>S Espeja</author>
<author>Monserrat Marimon</author>
</authors>
<title>Automatic acquistion of grammatical types for nouns</title>
<date>2007</date>
<booktitle>In Proceedings of NAACL HLT</booktitle>
<pages>5--8</pages>
<publisher>ACL</publisher>
<location>Rochester, NY</location>
<marker>Bel, Espeja, Marimon, 2007</marker>
<rawString>N. Bel, S. Espeja, and Monserrat Marimon. 2007. Automatic acquistion of grammatical types for nouns. In Proceedings of NAACL HLT, April 2007, Companion Volume, pages 5–8, Rochester, NY. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Remo Bindi</author>
<author>Paola Baroni</author>
<author>Monica Monachini</author>
<author>Elisabetta Gola</author>
</authors>
<title>PAROLE-sottoinsieme. Internal report</title>
<date>2000</date>
<location>ILC-CNR, Pisa</location>
<contexts>
<context>ta we used a collection of Italian verb-noun contexts automatically extracted and analyzed (at chunking level) from a 3 million corpus of contemporary Italian newspaper article (the PAROLE subcorpus (Bindi et al., 2000)3). The training data consist of 847 noun types and 2321 tokens. Each noun token has been extracted from the corpus with its surrounding context. In order to normalize the context type and size for e</context>
</contexts>
<marker>Bindi, Baroni, Monachini, Gola, 2000</marker>
<rawString>Remo Bindi, Paola Baroni, Monica Monachini, and Elisabetta Gola. 2000. PAROLE-sottoinsieme. Internal report, ILC-CNR, Pisa.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Calderone</author>
<author>I Herreros</author>
<author>V Pirrelli</author>
</authors>
<title>Learning inflection: The importance of starting big. Lingue &amp; Linguaggio</title>
<date>2007</date>
<contexts>
<context>Ms have been previously used to model continuous and multidimensional semantic/pragmatic spaces (Ritter and Kohonen, 1989; Honkela et al., 1995) as well as morphology acquisition in a given language (Calderone et al., 2007). Li and colleagues (Li et al., 2004), moreover, have exploited SOMs for simulating the early lexical acquisition by children. 3.3. The Dataset: Feature Extraction and Representation As input trainin</context>
</contexts>
<marker>Calderone, Herreros, Pirrelli, 2007</marker>
<rawString>B. Calderone, I. Herreros, and V. Pirrelli. 2007. Learning inflection: The importance of starting big. Lingue &amp; Linguaggio, (2):175–200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Crof</author>
<author>A Cruse</author>
</authors>
<title>Cognitive Linguistics</title>
<date>2004</date>
<location>CUP, Cambridge</location>
<contexts>
<context>er context in which they occur, nouns or better noun phrases, may be used in different ways: to predicate, to refer to specific, individuated entities or they can be be more generally type referring (Crof and Cruse, 2004). Our aim in this work is to see whether, given a large set of (psychologically plausible) morpho-syntactic contextual features and an unsupervised learning method, (functional) similarities of nouns</context>
<context>t, contextual functions. Functions of noun phrases are to signal the countability, new vs. given status, generic or individuated character of the entity referred to, and its degree of referentiality (Crof and Cruse, 2004; Delfitto, 2002). In many languages, the type of determiner present in the NP and the number of the noun are the linguistic cues that are generally held responsible for signaling the function in cont</context>
<context>erence corresponds to the bound/unbound structural schematization in Cognitive Linguistics (Langacker, 1987). Countability may also construe an entity as of a specific type, e.g. chair vs. furniture (Crof and Cruse, 2004). Assuming that naming is categorizing and that categories are not neat, but have fuzzy boundaries, the meaning and function of nouns cannot be totally pre-established, but must be construed dynamica</context>
</contexts>
<marker>Crof, Cruse, 2004</marker>
<rawString>W. Crof and A. Cruse. 2004. Cognitive Linguistics. CUP, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Delfitto</author>
</authors>
<title>Genericity in language. Issues of syntax, logical form and interpretation</title>
<date>2002</date>
<location>Dell’Orso, Alessandria</location>
<contexts>
<context>s. Functions of noun phrases are to signal the countability, new vs. given status, generic or individuated character of the entity referred to, and its degree of referentiality (Crof and Cruse, 2004; Delfitto, 2002). In many languages, the type of determiner present in the NP and the number of the noun are the linguistic cues that are generally held responsible for signaling the function in context (countabilit</context>
</contexts>
<marker>Delfitto, 2002</marker>
<rawString>D. Delfitto. 2002. Genericity in language. Issues of syntax, logical form and interpretation. Dell’Orso, Alessandria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew S Dryer</author>
</authors>
<title>Noun phrases without nouns</title>
<date>2004</date>
<journal>Functions of Language</journal>
<volume>11</volume>
<contexts>
<context>therefore a kind of categorization. Assuming this, we will say that the primary cognitive function of nouns is to form a classification system of things in the world that we use in referring to them (Dryer, 2004, 50). Nouns, however, are seldom used in isolation; noun phrases (or more generally nominal chunks) may have different, contextual functions. Functions of noun phrases are to signal the countability,</context>
</contexts>
<marker>Dryer, 2004</marker>
<rawString>Matthew S. Dryer. 2004. Noun phrases without nouns. Functions of Language, 11:43–76(34).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Honkela</author>
<author>V Pulkki</author>
<author>T Kohonen</author>
</authors>
<title>Contextual relations of words in Grimm tales analyzed by selforganizing map</title>
<date>1995</date>
<booktitle>Proceedings of International Conference on Artificial Neural Networks, ICANN’95, volume II</booktitle>
<volume>3</volume>
<pages>pages</pages>
<editor>In F. Fogelman-Souli´e and P. Gallinari, editors</editor>
<location>Nanterre, France</location>
<contexts>
<context>sters, and white areas as chaotically reacting cluster separators. In NLP, SOMs have been previously used to model continuous and multidimensional semantic/pragmatic spaces (Ritter and Kohonen, 1989; Honkela et al., 1995) as well as morphology acquisition in a given language (Calderone et al., 2007). Li and colleagues (Li et al., 2004), moreover, have exploited SOMs for simulating the early lexical acquisition by chi</context>
</contexts>
<marker>Honkela, Pulkki, Kohonen, 1995</marker>
<rawString>T. Honkela, V. Pulkki, and T. Kohonen. 1995. Contextual relations of words in Grimm tales analyzed by selforganizing map. In F. Fogelman-Souli´e and P. Gallinari, editors, Proceedings of International Conference on Artificial Neural Networks, ICANN’95, volume II, pages 3– 7, Nanterre, France. EC2. Italian NLP tools. http://foxdrake.ilc.cnr.it/webtools/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kohonen</author>
</authors>
<title>Self Organizing Maps</title>
<date>2001</date>
<publisher>Springer Verlag</publisher>
<location>Berlin</location>
<contexts>
<context>tional properties of nouns. 3. Methodology For the investigation on the emergence of functional properties of nouns phrases we adopt an unsupervised connectionist approach using Self-Organizing Maps (Kohonen, 2001). 3.1. Self-Organizing Maps The Self-Organizing Map (SOM) (Kohonen, 2001) is an unsupervised neural network algorithm that is able to arrange complex and high-dimensional data space into lowdimension</context>
<context>i(t) is usually defined as a Gaussian function: hci = fi(t)¢exp ¡k rc ¡ri k 2 2 2(t) ¶ (3) where fi(t) is a learning rate and the parameter (t) defines the radius of Nc(t). In the original algorithm (Kohonen, 2001), both fi(t) and (t) are monotonically decreasing functions of time. x c hci Figure 1: A randomly initialized SOM after one learning step (left panel) and a fully trained SOM (right panel). The train</context>
</contexts>
<marker>Kohonen, 2001</marker>
<rawString>T. Kohonen. 2001. Self Organizing Maps. Springer Verlag, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Langacker</author>
</authors>
<title>Foundations of Cognitive Grammar I: Theoretical prerequisites</title>
<date>1987</date>
<institution>Stanford University., Stanford</institution>
<contexts>
<context>)). Countability is considered responsible for the construal of an entity as an individuated unit. This difference corresponds to the bound/unbound structural schematization in Cognitive Linguistics (Langacker, 1987). Countability may also construe an entity as of a specific type, e.g. chair vs. furniture (Crof and Cruse, 2004). Assuming that naming is categorizing and that categories are not neat, but have fuzz</context>
</contexts>
<marker>Langacker, 1987</marker>
<rawString>R. Langacker. 1987. Foundations of Cognitive Grammar I: Theoretical prerequisites. Stanford University., Stanford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R W Langacker</author>
</authors>
<title>Remarks on nominal grounding</title>
<date>2004</date>
<journal>Functions of Language</journal>
<volume>11</volume>
<contexts>
<context>a and Hudson (2005). In Cognitive Linguistics, instead, they are assigned a fundamental property, they signal the “grounding” of a noun phrase (its contextual identification within the speech event, (Langacker, 2004, 77-85)). Countability is considered responsible for the construal of an entity as an individuated unit. This difference corresponds to the bound/unbound structural schematization in Cognitive Lingui</context>
</contexts>
<marker>Langacker, 2004</marker>
<rawString>R. W. Langacker. 2004. Remarks on nominal grounding. Functions of Language, 11:77–113(37).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Lenci</author>
<author>S Montemagni</author>
<author>V Pirrelli</author>
</authors>
<title>Chunk-it. an italian shallow parser for robust syntactic annotation. In Computational Linguistics in Pisa Linguistica Computazionale a Pisa, volume XVI-XVII</title>
<date>2003</date>
<publisher>IEPI, Pisa-Roma</publisher>
<contexts>
<context>ases4. 2Unfortunately, the black and white pictures on the paper here do not allow a proper appreciation of the map. 3For text chunking we used the Italian NLP Tools developed at ILC-CNR (Ita, ) and (Lenci et al., 2003), in particular for details on the chunker. 4Except that it will occur in many support verb constructions. However, this should not pose problems to our results, rather it will be interesting to see </context>
</contexts>
<marker>Lenci, Montemagni, Pirrelli, 2003</marker>
<rawString>A. Lenci, S. Montemagni, and V. Pirrelli. 2003. Chunk-it. an italian shallow parser for robust syntactic annotation. In Computational Linguistics in Pisa Linguistica Computazionale a Pisa, volume XVI-XVII. IEPI, Pisa-Roma.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Li</author>
<author>I Farkas</author>
<author>B MacWhinney</author>
</authors>
<title>Early lexical development in a self-organizing neural network</title>
<date>2004</date>
<journal>Neural Networks</journal>
<volume>8</volume>
<contexts>
<context>uous and multidimensional semantic/pragmatic spaces (Ritter and Kohonen, 1989; Honkela et al., 1995) as well as morphology acquisition in a given language (Calderone et al., 2007). Li and colleagues (Li et al., 2004), moreover, have exploited SOMs for simulating the early lexical acquisition by children. 3.3. The Dataset: Feature Extraction and Representation As input training data we used a collection of Italia</context>
</contexts>
<marker>Li, Farkas, MacWhinney, 2004</marker>
<rawString>P. Li, I. Farkas, and B. MacWhinney. 2004. Early lexical development in a self-organizing neural network. Neural Networks, 8–9(17):1345–1362.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Peng</author>
<author>K Araki</author>
</authors>
<title>Detecting the countability of english compound nouns using web-based models</title>
<date>2005</date>
<booktitle>In Second International Joint Conference on Natural Language Processing, Jeju Island, Korea, October 11-13, 200. Companion Volume to the Proceedings of Conference</booktitle>
<pages>103--107</pages>
<marker>Peng, Araki, 2005</marker>
<rawString>J. Peng and K. Araki. 2005. Detecting the countability of english compound nouns using web-based models. In Second International Joint Conference on Natural Language Processing, Jeju Island, Korea, October 11-13, 200. Companion Volume to the Proceedings of Conference, pages 103–107. Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Ritter</author>
<author>T Kohonen</author>
</authors>
<title>Self-organizing semantic maps</title>
<date>1989</date>
<journal>Biological Cybernetics</journal>
<contexts>
<context>areas can be viewed as clusters, and white areas as chaotically reacting cluster separators. In NLP, SOMs have been previously used to model continuous and multidimensional semantic/pragmatic spaces (Ritter and Kohonen, 1989; Honkela et al., 1995) as well as morphology acquisition in a given language (Calderone et al., 2007). Li and colleagues (Li et al., 2004), moreover, have exploited SOMs for simulating the early lexi</context>
</contexts>
<marker>Ritter, Kohonen, 1989</marker>
<rawString>H. Ritter and T. Kohonen. 1989. Self-organizing semantic maps. Biological Cybernetics, (61):241–254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sugayama</author>
<author>R Hudson</author>
<author>editors</author>
</authors>
<title>Word Grammar. New Perspectives on a Theory of Language Structure</title>
<date>2005</date>
<publisher>Continuum, Kobe</publisher>
<marker>Sugayama, Hudson, editors, 2005</marker>
<rawString>K. Sugayama and R. Hudson, editors. 2005. Word Grammar. New Perspectives on a Theory of Language Structure. Continuum, Kobe.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ultsch</author>
<author>H P Siemon</author>
</authors>
<title>Kohonen’s self organizing feature maps for exploratory data analysis</title>
<date>1990</date>
<booktitle>In Proceedings of International Neural Network Conference</booktitle>
<pages>305--308</pages>
<location>Dordrecht, The Netherlands</location>
<contexts>
<context>eurons at the edges of the map have fewer neighbors. The average of the distance to the nearest neighbors is called unified distance and the matrix of these values for all neurons is called U-matrix (Ultsch and Siemon, 1990). In a U-matrix representation, the distance between adjacent neurons is calculated and presented with different colorings between adjacent positions on the map. Dark colorings highlight areas of the</context>
</contexts>
<marker>Ultsch, Siemon, 1990</marker>
<rawString>A. Ultsch and H. P. Siemon. 1990. Kohonen’s self organizing feature maps for exploratory data analysis. In Proceedings of International Neural Network Conference,, pages 305–308, Dordrecht, The Netherlands.</rawString>
</citation>
</citationList>
</algorithm>

