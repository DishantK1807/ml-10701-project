(Hakkani-Tur et al., 2000)), and Basque (Ezeiza et al., 1998), which pose quite different and in the end less severe problems, there have been attempts at solving this problem for some of the highly inflectional European languages, such as (Daelemans et al., 1996), (Erjavec et al., 1999) (Slovenian), (Hajiˇc and Hladk´a, 1997), (Hajiˇc and Hladk´a, 1998) (Czech) and (Hajiˇc, 2000) (five Central and Eastern European languages), but so far no system has reached in the absolute terms a performance comparable to English tagging (such as (Ratnaparkhi, 1996)), which stands around or above 97%.
P98-1063 W96-0102 W96-0213
Authors of such systems claim that handwritten systems can perform better than systems based on machine learning (Samuelsson and Voutilainen, 1997); however, except for the work cited, comparison is difficult to impossible due to the fact that they do not use the standard evaluation techniques (and not even the same data).
P97-1032
In the present study, we have chosen a different strategy (similar to the one described for other types of languages in (Tapanainen and Voutilainen, 1994), (Ezeiza et al., 1998) and (HakkaniTur et al., 2000)).
P98-1063
From languages we are acquainted with, the method has been applied on a larger scale only to English (Karlsson et al., 1995), (Samuelsson and Voutilainen, 1997), and French (Chanod and Tapanainen, 1995).
E95-1021 P97-1032
We use the usual equal-weight formula for F-measure: a3a5a4a7a6a9a8a11a10a13a12a15a14a17a16a18a8a7a19a21a20a18a22a24a23a26a25a28a27a30a29a32a31a34a33a35a31a37a36a24a38a39a22a18a40a41a27a35a29a35a42a24a43a34a43 a23a41a25a44a27a35a29a45a31a46a33a30a31a37a36a24a38a13a47a48a40a41a27a35a29a30a42a18a43a34a43a50a49 wherea51 a16a18a8a18a52a54a53a44a12a55a53a35a56a39a57a58a19a60a59 a61a63a62 a36a65a64a18a27a45a38a66a33a68a67a69a31a34a70a46a71a73a72a74a29a35a36a24a25a75a25a44a27a35a29a32a70a76a70a77a42a32a78a66a79 a59 a59 a61a63a62 a36a80a64a24a27a32a38a66a33a81a78a11a27a45a38a54a27a32a25a44a42a24a70a77a27a35a82a54a79 a59 anda83 a8a11a52a11a10a85a84a30a84a86a19 a59 a61a63a62 a36a65a64a18a27a45a38a66a33a68a67a69a31a46a70a34a71a73a72a74a29a35a36a24a25a75a25a44a27a35a29a32a70a81a70a87a42a65a78a88a79 a59 a59 a61a63a62 a36a80a64a24a27a32a38a66a33a86a31a46a38a89a82a18a42a18a70a87a42a54a79 a59 3 The Statistical Component 3.1 The HMM Tagger We have used an HMM tagger in the usual sourcechannel setting, fine-tuned to perfection using a2 a 3-gram tag language model a90a92a91a30a93a65a94a18a95 a93a32a94a30a96 a20 a49 a93a32a94a30a96a98a97a55a99, a2 a tag-to-word lexical (translation) model using bigram histories instead of just sameword conditioning a90a92a91a30a100a101a94a24a95 a93a65a94 a49 a93a65a94a30a96a98a97a55a99 5, 5First used in (Thede and Harper, 1999), as far as we know.
P99-1023
E.g., (Ngai and Yarowsky, 2000) and (Ngai, 2001) provide a thorough description of many experiments involving rule-based systems and statistical learners for NP bracketing.
P00-1016
