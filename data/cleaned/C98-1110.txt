Large Scale Collocation Data and Their Application 
to Japanese Word Processor Technology 
Yasuo Koyama, Masako Yasutake, Kenji Yoshimura and Kosho Shudo 
Institute for Information and Control Systems, Fukuoka University 
Nanahm~ Fukuoka, 814-0180 Japan 
koymna@~sofeco.jp, yasutake@helio.tl.fukuoka-u.ac.jp, yosimma@tlsu~fl.fukuoka-u.ac.jp, 
shudo@tlsun.tl.fida~ka-u.ac.jp 
abstract 
Word processors or computers used in Japan 
employ Japanese input method through key
board stroke combined with Kana (phonetic) 
character to Kanji (ideographic, Chinese) char
acter conversion technology. The key factor of 
Kana-to-Kanji conversion technology is how 
to raise the accuracy of the conversion through 
the homophone processing, since we have so 
many homophonic Kanjis. In this paper, we 
report the results of our Kana-to-Kanji conver
sion experiments which embody the homo
phone processing based on large scale colloca
tion data. It is shown that approximately 
135,000 collocations yield 9.1% raise of the 
conversion accuracy compared with the pro
totype system which has no collocation data, 
1. Introduction 
Word processors or computers used in Japan ordi
narily employ Japanese input method through key
board stroke combined with Kana (phonetic) to 
Kanji (ideographic, Chinese) character conversion 
teclmology. The Kana-to-Kanji conversion is per
formed by the morphological analysis on the input 
Kana string with no space between words. Wordor 
phrase-segmentation is carried out by the analysis to 
identify the substring of the input which has to be 
converted from Kana to Kanji. Kana-Kanji mixed 
string, which is the ordinary form of Japanese writ
ten text, is obtained as the final result. The major 
issue of this technology lies in raising the accuracy 
of the segmentation and the homophone processing 
to select the correct Kanji among many homophonic 
candidates. 
The conventional methodology for processing ho
mophones have used the function that gives the pri
ority to the word which was used lastly or to the 
high frequency word. In fact, however, this method 
sometimes tends to cause inadequate conversion due 
to the lack of consideration of the semantic consis
tency of the word concurrence. While it is difficult 
to employ the syntactic or semantic processing in 
earnest for the word processor from the cost vs. 
performance viewpoints, for example, the following 
trials to improve the conversion accuracy have been 
reported: Employing the case-frame to check the 
semantic consistency of combination of words 
\[Oshima, Y. et a1.,1986\]. Employing the neural net
work to describe the consistency of the concurrence 
of words \[Kobayashi,T. et al.,1992\], Making a con
cun'ence dictionary for the specific topic or field, 
and giving the priority to the word which is in the 
dictionary when the topic is identified \[Yamamoto, 
K. et al., 1992\]. In any of these studies, however, 
many problems are left unsolved in realizing its 
practical system. 
Besides these semantic or quasi-semantic gadgets, 
we think it much more practical and effective to use 
surface level resources, namely, to use extensively 
the collocation. But how many collocations contrib
ute to the accuracy of Kana-to-Kanji conversion is 
not known yet. 
In this paper, we present some results of our ex
periments of Kana-to-Kanji conversion, focusing on 
the usage of large scale collocation data. In chapter 
2, descriptions of the collocations used in our sys
tem and their classification are given. In chapter 3, 
the technological framework of our Kana-to-Kanji 
conversion systems is outlined. In chapter 4, the 
method and the results of the experhnents are given 
along with some discussions. In chapter 5, con
eluding remarks are given. 
2. Collocation Data 
Unlike the recent works on the automatic extraction 
of collocations from corpus \[Church, K. W, et al, 
1990, Ikehara, S. et al, 1996, etc.\], our data have 
been collected manually through the intensive in
vestigation of various texts, spending years on it. 
This is because no stochastic framework assures the 
694 
accuracy of the extraction, namely the necessity and 
sufficiency of the data set. The collocations which 
are used in our Kana-to-Kanji conversion system 
consist of two kinds: (1) idiomatic expressions, 
whose meanings seem to be difficult to compose 
fi:om the typical meaning of the individual compo
nent words \[Shudo, K. et al., 1988\]. (2) stereotypical 
expressions in which the concurrence of component 
words is seen in the texts with high frequency. The 
collocations are also classified into two classes by a 
grammatical criterion: one is a class of functional 
collocations, which work as functional words such 
as particles (postpositionals) or auxiliary verbs, the 
other is a class of conceptual collocations which 
work as nouns, verbs, adjectives, adverbs, etc. The 
latter is further classified into two kinds: uninter
ruptible collocations, whose concurrence relation
ship of words are so strong that they can be dealt 
with as single words, and interruptible collocations, 
which are occasionally used separately. 
In the following, the parenthesized number is the 
number of expressions adopted in the system. 
2.1 Functional
Collocations (2,174) 
We call expressions which work like a particle rela
tional collocation and expressions which work like 
an auxiliary verb at the end of the predicate auxili
ary predicative collocation \[Shudo, K. et al., 1980\]. 
relational collocations (760) 
ex. J=/'Dg~T2 ni/tuite (about) 
attxiliary predicative collocations (1,414) 
ex ~ I~f~ltg 6 tg I,~ " naliereba/naranai (must) 
2.2 Uninterruptible
Conceptual Col
locations (54,290) 
four-Kanji-compound (2,231) 
ex. ~1~t ~.1~. gqaenmsut 
(every miller draws water to his own mill) 
adverb + particle type (3,089) 
ex. ~tz,5,t: ~= ataJutato (disconcertedly) 
adverb + sum type (1,043) 
ex ~< t¢<-¢~ • aKusekusuru (toil and moil) 
noun type (21,128) 
ex. ~0~/~), a~no/tanm (perfect stranger) 
verb type (13,225) 
ex. ~'9 Lj ¢j~/~ otsuriga/~ru . 
(be enough to make the change) 
adjective type (2,394) 
ex. t~l,~, L, t,~ uraganasnii (mournful) 
adjective verb type (397) 
ex. c'~N03 gomgen/naname (in a bad mood) 
adverb and other type (8,185) 
ex. N I:-l~,~ 72 meni/miete (remarkably) 
proverb type (2,598) 
o~teha/koni/shitagae (when old, obey your children) 
2.3 Interruptible
Conceptual Colloca
tions (78,251) 
noun type (7,627) 
ex. ,1~2 03/ttt t, 
akugyouno/mukui (fruit of an evil deed) 
verb type (64,087) 
ex. ~ ~ ~?/N175~;h,~ ushirogamiwo/hikareru 
(feel as if one's heart were left behind) 
adjective type (3,617) 
ex. ~1~/.~-~ L~ taidOgasookii ( act in a lordly manner) 
adjective verb type (2,018) 
ex. ~¢0~/& yaliushaga/ue (be lnore able) 
others (902) 
ex. ~1:/,~ I t-~ga atoni/hikenu (can not give up) 
3. Kana-to-Kanji Conversion Systems 
We developed four different Kana-to-Kmlji conver
sion systems, phasing in the collocation data de
scribed in 2. The technological framework of the 
system is based on extended bunsetsu (e
bunsetsu) model \[Shudo, K. et al., 1980\] for the 
unit of the segmentation of the input Kana string, 
and on minimum cost method \[Yoshimura, K. et 
al., 1987\] combined with Viterbi's algorithn~ 
\[Viterbi, A,, J., 19671 for the reduction of the ambi
guity of the segmentation. 
A bunsetsu is the basic postpositional or predicative 
695 
phrase which composes Japanese sentences, and an 
e-bunsetsu, which is a natural extension of the bun
setsu, is defined roughly as follows: 
<e-bunsetsu>::= <prefix>* <conceptual word l 
uninterruptible conceptual collocation> 
<suffix>* <functional word l 
functional collocation>* 
The e-bunsetsu which includes no collocation is the 
bunsetsu. More refined rules are used in the actual 
segmentation process. The fllterruptible conceptual 
collocation is not treated as a single unit but as a 
string ofbunsetsus in the segmentation process. 
Each collocation in the dictionary which is com
posed of multiple number of bunsetsus is marked 
with the boundary between bunsetsus. The system 
first tries to segment the input Kana string into e
bunsetsus. Every possible segmentation is evaluated 
by its cost. A segmentation which is assigned the 
least cost is chosen as the solution. 
The boundary between e-bunsetsus in examples in 
this paper is denoted by "/". 
ex. two results of e-bunsetsu-segmentation: 
. hitolTa lagqtcikumtcositaxoto~aarimasen (there is nothing like being watchful) 
h i toha/ki gafkilcun i /k6s i ta/ko toha/arimasen 
In the above examples, ~$~/~11 ( kiga/kdku: is 
uninterruptible conceptual collocation and \[7-/i~ 1., 
7~z/\]~\[~,/;~ LJ ~'~ /v nL/kosita/kotoha/arimasen: is 
a functional collocation. In the first example, these 
collocations are dealt with a single words. The 
second example shows the conventional bunsetsu
segmentation. 
The cost for the segmentation candidate is the sum 
of three partial costs: b-cost, c-cost and d-cost 
shown below. 
(1)a segment cost is assigned to each segment. Sum 
of segment costs of all segments is the basic cost 
(b-cost) of a segmentation candidate. By this, the 
collocation tends to have priority over the ordi
nary word. The standard and initial value of each 
segment cost is 2, and it is increased by 1 for each 
occurrence of the prefix, suffix, etc. in the seg
ment. 
(2)a concatenation cost (c-cost) is assigned to speci
fic e-bunsetsu boundaries to revise the b-cost. 
The concatenation, such as adnominal-noun, ad
verb-verb, noun-noun, etc. is paid a bonus , 
namely a negative cost, 1. 
(3)a dependency cost (d-cost), which has a negative 
value, is assigned to the strong dependency rela
tionship between conceptual words in the candi
date, representing the consistency of concurrence 
of conceptual words. By this, the segmentation 
containing the interrupted conceptual collocation 
tends to have priority. The value of a d-cost varies 
fi'om -3 to -1, depending on the strength of the 
concurrence. The interruptible conceptual collo
cation is given the biggest bonus i.e.-3. 
The reduction of the homophonic ambiguity, which 
limits Kanji candidates, is carried out in the course 
of the segmentation and its evaluation by the cost. 
3.1 Prototype
System A 
We first developed a prototype Kana-to-Kanji con
version system which we call System A, revising 
Kana-to-Kanji conversion software on the market, 
WXG Ver2.05 for PC. 
System A has no collocation data but conventional 
texical resources, namely functional words (1,010) 
and conceptual words (131,661). 
3.2 System
B, C and D 
We reinforced System A to obtain System B, C and 
D by phasing in the following collocational re
sources. System B is System A equipped addition
ally with functional collocations (2,174) and unin
terruptible conceptual collocations except for four
Kanji-compound and proverb type collocations 
(49,461). System C is System B equipped addition
ally with four-Kanji-compound (2,231) and proverb 
type collocations (2,598). Further, System D is 
Systean C equipped additionally with interruptible 
conceptual collocations (78,251). 
4. Experiments 
4.1 Text
Data for Evaluation 
Prior to the experiments of Kana-to-Kanji conver
sion, we prepared a large volume of text data by 
hand which is formally a set of triples whose first 
component a is a Kana string (a sentence) with no 
space, The second component b is the correct seg
mentation result of a, indicating each boundary 
between bunsetsus with "/" or ".". "/" and .... 
means obligatory and optional boundary, respec
tively. The third component e is the correct conver
sion result of a, which is a Kana-Kanji mixed string. 
niwanioaragasaiteiru 
696 
(roses are in bloom in a garden) 
b: fZ.~fZ/lg6/3~/~ t,~Z'.t,~/-o niwani/baraga,/saite, iru 
e: I~l:l,~#J*,ll~l,~'~.l,~ } 
The introduction of the optional boundary assures 
the flexible evaluation. For example, each ofll~t,~ 
-C./L~ saite/iru (be in bloom) and I~L~-C'L~ 
saiteiru is accepted as a correct result. The data file 
is divided into two sub-files, fl and t2, depending 
on the number of bunsetsus in the Kana string a. fl 
has 10,733 triples, whose a has less than five 
bunsetsus and t2 has 12,192 triples, whose a has 
more than four bunsetsus. 
4.2 Method
of Evaluation 
Each a in the text data is fed to the conversion sys
tem. The system outputs two forms of the least cost 
result: b', Kana string segmented to bunsetsus by 
"/", and c', Kana-Kanji mixed string, corresponding 
to b and e of the correct data, respectively. Each of 
the following three cases is counted for the evalua
tion. 
SS (Segmentation Success): b TM b 
CS (Complete Success): b'-b and e '= e 
TS (Tolerative Success): b '= b and c'c 
There are mmly kinds of notational fluctuation in 
Japanese. For example, the conjugational suffLX of 
some kind of Japanese verb is not always necessi
tated, therefore,~tJ_Ir_PJ~,~.l:l~ and ~1are all 
acceptable results for input "St, J~\[-~ uriage (sales). 
Besides, a single word has sometimes more than 
one Kanji notations, e.g. ~ hama (beach) and 
hama (beach) are both acceptable, and so on. c'c 
in the case of TS means that e' coincides with c 
completely or excepting the part which is hetero
morphic in the above sense. For this, each of our 
conversion system has a dictionary which contains 
approximately 35,000 fluctuated notations of con
ceptual words. 
4.3 Results
of Experiments 
Results of the experhnents are given in Table 1 and 
Table 2 for input file fl and t2, respectively. 
Comparing the statistics of system A with D, we can 
conclude that the introduction of approximately 
135,000 collocation data causes 8.1% and 10.5 % 
raise of CS and TS rate, respectively, in case of re
latively short input strings (fl). The raise of SS rate 
for fl is 2.7%. In case of the longer input strings (12) 
whose average number of bunsetsus is approxi
mately 12.6, the raise ofCS, TS and SS rate is 2.4 %, 
5.2 % and 5.7 %, respectively. As a consequence, 
the raise of CS, TS mid SS rate is 6.2 %, 9.1% and 
3.8 % on the average, respectively. 
II 
SS(Se~entation Success) 
CS(Complete Success) 
TS(Tolerative Success).. 
STstem A S~¢stean B S~stem C 
I I 
9,656(90.0°/0) 9,9.12(92.4°,4) 9,927(92.5%) 
5,085(47.4%) 5,638(52.5%) .. 5,677(52.90/o) 
6,2.26(58.0%) 6,971(64.9°/0) 71024(65.4%) 
Table l:Result of the experiments for 10,733 short input strings data, fl. 
(average number of Kana characters per input is 13.7) 
STstem D 
9,954(92.7%) 
5,953(55.5%) 
7,355(68.5%) 
SS 
CS 
TS 
STstem A STstern B STstem C 
8,345(68.4%) 8,978(73.6%) 8,988(73.7%) 
2,422(19.9°/0) 2,660(2 !. 8%) 2,673 (21.9%) 
3,965.(32.5%) 4,555(37.4%) 4,56807.5°/0) 
Table 2: Result oflhe experiments for 12,192 long input strings data, t2. 
(average number of Kana characters per input is 42.7) 
S~¢stem D 
9,037(74.1%) 
2,717(22.3% ) 
4,601(37.7% ) 
System D' WXG 
i 
SS 9,949(92.7%) 9,804(91.3%) 
CS 6,180(57.6%) .5,877(54.8°/0) 
TS 7,646(71.2% ) 7,290(67.9%) 
Table 3 :Comparison of system D' with WXG for ft. 
S:~tc~n D' WXG 
SS 8,928(73.2%) 8,815(72.3%). 
CS 2,738(22.5%) 2,694(22.1%) 
TS 4,649(38.1%) 4,543(37.3%) 
Table 4: Comparison of system D' with WXG for f2. 
697 
4.4 Comparison
with a Software on the 
Market 
We compared System D with a Kana-to-Kanji conver
sion software for PC on the ~et, WXG Ver2.05 under 
the same condition except for the amount of installed 
collocation dat~ For this, syst~n D was reinforced and 
renamed D', by equipping with WXG's 10,000 items of 
word dependency description. Both systems were dis
abled for the learning function. WXG has approximately 
60,000 collocations (3,000 uninterruptible and 57,000 
intermptible collocations), whereas System D' has ap
proximately 135,000 collocations. The statistical results 
are given in Table 3 and Table 4 for the corpus fl and t2, 
respectively. 
The tables show that the raise of CS, TS and SS rate, 
which was obtained by System D' is 2.5 %, 4.5 % and 
3.9 % on the average, respectively. No further comps
son with the commercial products has been done, since 
we judge the performance ofWXG Ver.2.05 to be aver
age among thezn. 
4.5 Discussions

Table 1 "-" 4 show that the longer input the system is 
given, the more difficult for the system to make the cor
rect solution and the difference between accuracy rate of 
WXG and system D' is less for t2 than for fl. Further 
investigation clarified that the error of System D is 
mainly caused by missing words or expressions in the 
machine dictionary. Specifically, it was clarified that the 
dictionary does not have the sufficient number of Kata
Kana words and people's names. In addition, the number 
of fluctuafional variants installed in the dictionary men
fioned in 4.2 tumed out to be insufficient These problems 
should be remedied in ftm~e. 
5. Concluding Remarks 
In this paper, the effectiveness of the large scale colloca
tion data for the improvement of the conversion accuracy 
of Kana-to-Kanji conversion process used in Japanese 
word processors was clarified, by relatively large scale 
experiments. 
The extensive collection of the collocations has been 
carried out manually these ten years by the authors in 
order to realize not only high precision word processor 
but also more general Japanese language processing in 
future. A lot of resources, school textbooks, newspapers, 
novels, joumals, diction~es, etc. have been investigated 
by workers for the collection. The candidates for the col
location have been judged one after another by them. 
Among collocations described in this paper, the idiomatic 
expressions are quite burdensome in the development of 
NLP, since they do not follow the principle of composi
fionality of the meaning Generally speaking, the more 
extensive collocational data it deals with, the less the 
"rule systena" of the rule based NLP system is burdened. 
This means the great importance of the enrichment of 
collocational dat~ Whereas it is inevitable that the arbi
trariness lies in the hmnan judgment and selection of 
collocations, we believe that our collocation data is far 
more refined than the automatically extracted one from 
corpora which has been recently reported \[Church, F,2 W. 
et al, 1990, lkeli,~a, S. et al, 1996, etc.\]. 
We believe that the approach descnqxxl here is important 
for the evolution of NLP product in general as well. 

References 

Shudo, K. et al., 1980. Morphological Aspect of Japanese Language Processing~ in Proc. of 8 th Int~mtcon£ on 
Computational Linguistics(COLING80) 

Oshima, Y. et al., 1986. A Disambiguafion Method in 
Kana-to-Kanji Conversion Using Case Frame Gram
n~ar. in Trans. oflPSJ, 27-7. (in Japanese) 

Kobayashi, T. et al. ,1986. Realization of Kana-to-Kanji 
Conversion Using Neural Networks. in Toshiba 
Review, 47-11. (in Japanese) 

Yoshimura, K. et al., 1987. Morphological Analysis of Ja
panese Sentences using the Least Cost Method. in IPSJ 
SIG NL-60. (in Japanese) 

Shudo, K. et al. ,1988. On the Idiomatic Expressions in 
Japanese Language. in IPSJ SIG NL-66. (in Japanese) 

Church, K.W. et al, 1990. Word Association Norms, 
Mutual Information, and Lexicography. in Comput
atiorml Linguistics, 16. 

Yamamoto, K. et al. ,1992. Kana-to-Kanji Conversion 
Using Co-occurrence Groups. in Proc. of 44th Conf. of 
IPSJ. (in Japanese) 

Ikehara, S. et al. ,1996. A Statistical Method for 
Extracting Uninterrupted and Interrupted Collocations 
from Very Large Corpora. in Proc. of 16th Intemat. 
Conf. on Computational Linguistics (COLING 96) 

Viterbi, A.,J., 1967,Error Bounds for Convolutional Codes 
and an Asymptotically Optimal Decoding Algorithm. 
in IEEE Trans. on Information Theory 13.

