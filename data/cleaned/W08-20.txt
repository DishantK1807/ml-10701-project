1:229	Coling 2008 22nd International Conference on Computational Linguistics Proceedings of the 3rd Textgraphs workshop on Graph-based Algorithms for Natural Language Processing Workshop chairs: Irina Matveeva, Chris Biemann, Monojit Choudhury, Mona Diab 24 August 2008 Manchester, UK TextGraphs-3 Workshop at COLING 2008 was sponsored by Microsoft Research India c2008 The Coling 2008 Organizing Committee Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Nonported license http://creativecommons.org/licenses/by-nc-sa/3.0/ Some rights reserved Order copies of this and other Coling proceedings from: Association for Computational Linguistics (ACL) 209 N. Eighth Street Stroudsburg, PA 18360 USA Tel: +1-570-476-8006 Fax: +1-570-476-0860 acl@aclweb.org ISBN 978-1-905593-57-6 Design by Chimney Design, Brighton, UK Production and manufacture by One Digital, Brighton, UK ii Introduction Recent years have shown an increased interest in bringing the field of graph theory into Natural Language Processing.
2:229	In many NLP applications entities can be naturally represented as nodes in a graph and relations between them can be represented as edges.
3:229	Recent research has shown that graphbased representations of linguistic units as diverse as words, sentences and documents give rise to novel and efficient solutions in a variety of NLP tasks, ranging from part of speech tagging, word sense disambiguation and parsing to information extraction, semantic role assignment, summarization and sentiment analysis.
4:229	The contribution of the graph representation, in addition to its intuitiveness, resides in the possibility to relate linguistic entities beyond pairwise comparison.
5:229	This volume contains papers accepted for presentation at the TextGraphs-3 2008 Workshop on GraphBased Algorithms for Natural Language Processing.
6:229	This event took place on August 24, 2008, in Manchester, UK, immediately following COLING 2008, the 22nd International Conference on Computational Linguistics.
7:229	It was the third workshop on this topic, building on the success of the first and second TextGraphs workshop at HLT-NAACL 2006 and 2007.
8:229	The workshop aimed at bringing together researchers working on problems related to the use of graph-based algorithms for Natural Language Processing and on the theory of graph-based methods.
9:229	It addressed a broad spectrum of research areas to foster exchange of ideas and to help identify principles of using the graph notions that go beyond an ad-hoc usage.
10:229	We issued calls for both regular and short, late-breaking papers.
11:229	Six regular and three short papers were accepted for presentation, based on the careful reviews of our program committee.
12:229	We are indebted to all program committee members for their thoughtful, high quality and elaborate reviews, especially considering our extremely tight time frame for reviewing.
13:229	The papers appearing in this volume have surely benefited from their expert feedback.
14:229	This years workshop attracted papers employing graphs in a wide range of settings, so we are proud to present a very diverse program this year.
15:229	N. Hathout acquires morphological structure from a lexicon employing the bipartite graph between headwords formal semantic features.
16:229	Mapping of text to a graph-based meaning representation is conducted by S. Muresan, using a recent grammar formalism.
17:229	A. B. Masse et al. lay out a general theoretical framework for addressing the symbol grounding problem in digital dictionaries.
18:229	A. Moschitti and F.M. ZanzottouseKernelmethodsontreepairsforrecognizingtextualentailment.
19:229	Combiningco-occurrence and phonological similarity, K. Ichioka and F. Fukumoto semantically cluster onomatopoetic words in Japanese.
20:229	D. Rao et al. examine several random walk based approaches to measure word similarity.
21:229	B. McGillivray et al. address cluster overlapping with correspondence analysis and apply their method to cluster English and Italian verbs and nouns.
22:229	A domain-specific summarization method ranking nodes in a graph of concepts is introduced by L. Plaza Morales et al. The topology of associative concept dictionaries is modeled by H. Akama et al., who report interesting scale free properties of such networks.
23:229	Finally, having a prominent researcher as an invited speaker greatly contributes to the quality of the workshop.
24:229	We thank Dragomir Radev for his talk and for the support he provided for this as well as all the previous Textgraphs workshops.
25:229	We are also grateful to Microsoft Research India for sponsoring the travel and accomodation of the invited speaker.
26:229	Irina Matveeva, Chris Biemann, Monojit Choudhury and Mona Diab August 2008 iii  Organizers: Irina Matveeva, Accenture Technology Labs Chris Biemann, Powerset Monojit Choudhury, Microsoft Research India Mona Diab, Columbia University Programme Committee: Eneko Agirre, University of the Basque Country Edo Airoldi, Princeton University Regina Barzilay, MIT Fernando Diaz, Yahoo!
27:229	Montreal Gunes Erkan, Google Michael Gamon, Microsoft Research Redmond Andrew Goldberg, University of Wisconsin Hany Hassan, IBM Egypt Samer Hassan, University of North Texas Gina Levow, University of Chicago Rada Mihalcea, University of North Texas Animesh Mukherjee, IIT Kharagpur Dragomir Radev, University of Michigan Uwe Quasthoff, University of Leipzig Aitor Soroa, University of the Basque Country Hans Friedrich Witschel, University of Leipzig Fabio Massimo Zanzotto, University of Rome Tor Vergata Thorsten Zesch, University of Darmstadt Invited Speaker: Dragomir Radev, University of Michigan, Ann Arbor v  Table of Contents Acquistion of the Morphological Structure of the Lexicon Based on Lexical Similarity and Formal Analogy Nabil Hathout . . .
28:229	1 Learning to Map Text to Graph-Based Meaning Representations via Grammar Induction Smaranda Muresan.
29:229	.9 How is Meaning Grounded in Dictionary Definitions?
30:229	Alexandre Blondin Mass, Guillaume Chicoisne, Yassine Gargouri, Stevan Harnad, Odile Marcotte and Olivier Picard . . .
31:229	17 Encoding Tree Pair-Based Graphs in Learning Algorithms: The Textual Entailment Recognition Case Alessandro Moschitti and Fabio Massimo Zanzotto . . .
32:229	25 Graph-Based Clustering for Semantic Classification of Onomatopoetic Words Kenichi Ichioka and Fumiyo Fukumoto . . .
33:229	33 Affinity Measures Based on the Graph Laplacian Delip Rao, David Yarowsky and Chris Callison-Burch . . .
34:229	41 Semantic Structure from Correspondence Analysis Barbara McGillivray, Christer Johansson and Daniel Apollon . . .
35:229	49 Concept-Graph Based Biomedical Automatic Summarization Using Ontologies Laura Plaza, Alberto Daz and Pablo Gervs . . .
36:229	53 Random Graph Model Simulations of Semantic Networks for Associative Concept Dictionaries Hiroyuki Akama, Jaeyoung Jung, Terry Joyce and Maki Miyake . . .
37:229	57 vii  Conference Programme Sunday, August 24, 2008 9:209:25 Opening 9:3010:30 Invited Talk by Dragomir Radev on Lexical Affinity 10:3011:00 Break Session I: Full Papers 11:0011:30 Acquistion of the Morphological Structure of the Lexicon Based on Lexical Similarity and Formal Analogy Nabil Hathout 11:3012:00 Learning to Map Text to Graph-Based Meaning Representations via Grammar Induction Smaranda Muresan 12:0012:30 How is Meaning Grounded in Dictionary Definitions?
38:229	Alexandre Blondin Mass, Guillaume Chicoisne, Yassine Gargouri, Stevan Harnad, Odile Marcotte and Olivier Picard 12:3014:00 Lunch Session II: Full Papers 14:0014:30 Encoding Tree Pair-Based Graphs in Learning Algorithms: The Textual Entailment Recognition Case Alessandro Moschitti and Fabio Massimo Zanzotto 14:3015:00 Graph-Based Clustering for Semantic Classification of Onomatopoetic Words Kenichi Ichioka and Fumiyo Fukumoto 15:0015:30 Affinity Measures Based on the Graph Laplacian Delip Rao, David Yarowsky and Chris Callison-Burch 15:3016:00 Break ix Sunday, August 24, 2008 (continued) Session III: Short Papers 16:0016:20 Semantic Structure from Correspondence Analysis Barbara McGillivray, Christer Johansson and Daniel Apollon 16:2016:40 Concept-Graph Based Biomedical Automatic Summarization Using Ontologies Laura Plaza, Alberto Daz and Pablo Gervs 16:4017:00 Random Graph Model Simulations of Semantic Networks for Associative Concept Dictionaries Hiroyuki Akama, Jaeyoung Jung, Terry Joyce and Maki Miyake x Coling 2008: Proceedings of 3rd Textgraphs workshop on Graph-Based Algorithms in Natural Language Processing, pages 18 Manchester, August 2008 Acquistion of the morphological structure of the lexicon based on lexical similarity and formal analogy Nabil Hathout Universit de Toulouse Nabil.Hathout@univ-tlse2.fr Abstract The paper presents a computational model aiming at making the morphological structure of the lexicon emerge from the formal and semantic regularities of the words it contains.
39:229	The model is purely lexemebased.
40:229	The proposed morphological structure consists of (1) binary relations that connect each headword with words that are morphologically related, and especially with the members of its morphological family and its derivational series, and of (2) the analogies that hold between the words.
41:229	The model has been tested on the lexicon of French using the TLFi machine readable dictionary.
42:229	1 Lexeme-based morphology Morphology is traditionally considered to be the field of linguistics that studies the structure of words.
43:229	In this conception, words are made of morphemes which combine according to rules of inflexion, derivation and composition.
44:229	If the morpheme-based theoretical framework is both elegant and easy to implement, it suffers many drawbacks pointed out by several authors (Anderson, 1992; Aronoff, 1994).
45:229	The alternative theoretical models that have been proposed falls within lexeme-based or word-based morphology in which the minimal units are words instead of morphemes.
46:229	Words then do not have any structure at all and morphology becomes a level of organization of the lexicon based on the sharing of semantic and formal properties.
47:229	c2008.
48:229	Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
49:229	Some rights reserved.
50:229	The morpheme-based / lexeme-based distinction shows up on the computational level.
51:229	In the morpheme-based conception, the morphological analysis of a word aims at segmenting it into a sequence of morphemes (Djean, 1998; Goldsmith, 2001; Creutz and Lagus, 2002; Bernhard, 2006).
52:229	In a lexeme-based approach, it is to discover the relations between the word and the other lexical items.
53:229	These relations serve to identify the morphological family of the word, its derivational series, and the analogies in which it is involved.
54:229	For instance, the analysis of the French word drivation may be considered as satisfactory if it connects drivation with enough members of its family (driver derivate, drivationnel derivational, drivable, drive drift, driveur sailing dinghy, etc.) and of its derivational series (formation education, sduction, variation, mission, etc.).
55:229	Each of these relations is integrated into a large collection of analogies that characterizes it semantically and formally.
56:229	For instance, the relation between drivation and drivable is part of a series of analogies which includes drivation:drivable::variation:variable, drivation:drivable::modification:modifiable, etc. Similarly, drivation and variation participates in a series of analogies such as drivation:variation::driver:varier, drivation:variation::drivationnel:variationnel, drivation:variation::drivable:variable.
57:229	2 Computational modeling The paper describes a computational model aiming at making the morphological derivational structure of the lexicon emerge from the semantic and the formal regularities of the words it contains.
58:229	A first experiment is currently underway on the lexicon of French using the TLFi machine readable dictio1 nary.1 The main novelty of the paper is the combination of lexical proximity with formal analogy.
59:229	We first use lexical similarity in order to select a set of words that are likely to be morphologically related to each other.
60:229	Then, these candidates are checked by means of analogy.
61:229	The two techniques are complementary.
62:229	The first one brings closer the words that are morphologically close and especially the ones that are members of the same morphological families and the same derivational series.
63:229	It is able to deal with large number of words, but it is too coarse-grained to discriminate the words that are actually morphological related from the ones that are not.
64:229	The second technique, formal analogy, is then used to perform a fine-grained filtering.
65:229	Technically, our model joins: 1.
66:229	the representation of the lexicon as a graph and its exploration through random walks, along the line of (Gaume et al., 2002; Gaume et al., 2005; Muller et al., 2006), and 2.
67:229	formal analogies on words (Lepage, 1998; Stroppa and Yvon, 2005).
68:229	This approach does do not make use of morphemes.
69:229	Correspondence between words is calculated directly on their graphemic representations.
70:229	More generally, our approach is original in that: 1.
71:229	Our computational model is pure lexemebased.
72:229	The discovery of morphological relations between words do not involve the notions of morpheme, affix, morphological exponent, etc. nor any representation of these concepts.
73:229	2.
74:229	The membership to the families and series is gradient.
75:229	It accounts, for instance, for the fact that driveur is morphologically and semantically closer to drive than to drivationnellement, even if the three words belong to the same family.
76:229	The model connects the words that share semantic and / or formal features.
77:229	The more features are shared, the closer the words are.
78:229	Besides, the model integrates semantic and formal informations in a uniform manner.
79:229	All kind of semantic informations (lexicographic definitions, synonyms, synsets, etc.) and formal ones 1Trsor de la Langue Franaise (http://atilf.atilf.fr/).
80:229	(graphemic, phonological, etc.) can be used.
81:229	They can be cumulated easily in spite of the differences in nature and origin.
82:229	The model takes advantage of the redundancy of the features and is fairly insensitive to variation and exceptions.
83:229	3 Related work Many works in the field of computational morphology aim at the discovery of relations between lexical units.
84:229	All of them rely primarily on finding similarities between the word graphemic forms.
85:229	These relations are mainly prefixal or suffixal with two exceptions, (Yarowsky and Wicentowski, 2000) and (Baroni et al., 2002), who use string edit distances to estimate formal similarity.
86:229	As far as we know, all the other perform some sort of segmentation even when the goal is not to find morphemes as in (Neuvel and Fulop, 2002).
87:229	Our model differs from these approaches in that the graphemic similarities are determined solely on the basis of the sharing of graphemic features.
88:229	It is the main contribution of this paper.
89:229	Our model is also related to approaches that combine graphemic and semantic cues in order to identify morphemes or morphological relations between words.
90:229	Usually, these semantic informations are automatically acquired from corpora by means of various techniques as latent semantic analysis (Schone and Jurafsky, 2000), mutual information (Baroni et al., 2002) or co-occurrence in ann-word window (Xu and Croft, 1998; Zweigenbaum and Grabar, 2003).
91:229	In the experiment we present here, semantic informations are extracted from a machine readable dictionary and semantic similarity is calculated through random walks in a lexical graph.
92:229	Our approach can also be compared with (Hathout, 2002) where morphological knowledge is acquired by using semantic informations extracted from dictionaries of synonyms or from WordNet.
93:229	4 Lexeme Description In our model, the lexical units and their properties are represented in a bipartite graph with the vertices representing the lexemes in one sub-set and the vertices representing the formal and semantic features in the other.
94:229	Lexeme vertices are identified by the lemma and the grammatical category.
95:229	In the experiment reported in the paper, the formal properties are the n-grams of letters that occur in the lexemes lemma.
96:229	Figure 1 shows a sub-set of 2 $or; $ori; $orie;  $orientation; ori; orie;  orientation; orientation$;  tio; tion; tion$; ion; ion$; on$ Figure 1: Excerpt of the formal features associated with the noun orientation.
97:229	N.action; N.action X.de; N.action X.de V.orienter; X.de; X.de V.orienter; V.orienter; X.de V.sorienter; V.sorienter; N.rsultat; N.rsultat X.de; N.rsultat X.de X.ce; N.rsultat X.de X.ce N.action; X.de X.ce; X.de X.ce N.action; X.ce; X.ce N.action; N.action Figure 2: Semantic features induced by the definition Action dorienter, de sorienter ; rsultat de cette action. of the noun orientation the formal features associated with the word orientation.
98:229	The beginning and the end of the lemma are marked by the character $.
99:229	We impose a minimum size on the n-grams (n3).
100:229	The model is pure lexeme-based because this decomposition does not confer a special status to any of the individual n-grams which characterize the lexemes.
101:229	All n-grams play the same role and therefore no one has the status of morpheme.
102:229	These features are only used to bring closer the words that share the same sounds.
103:229	The semantic properties we have used are extracted from the TLFi definitions.
104:229	Each headword is provided with the n-grams of words that occur in its definitions.
105:229	The n-grams that contain punctuation marks are eliminated.
106:229	In other words, we only use n-grams of words that occur between two punctuation marks.
107:229	For instance, the semantic features induced by the definition Action dorienter, de sorienter ; rsultat de cette action.
108:229	(act of orienting, of finding ones way; result of this action) of the noun orientation are presented in figure 2.
109:229	The words in the definitions are POS tagged and lemmatized.
110:229	The tags are A for adjectives, N for nouns, R for adverbs, V for verbs and X for all other categories.
111:229	This is a very coarse semantic representation inspired from the repeated segments (Lebart et al., 1998).
112:229	It offers three advantages: (1) being heavily redundant, it can capture various levels of sim$or $ori orient entati N.action X.de N.rsultat X.de X.ce N.orientation V.orienter A.original N.fermentation N.pointage Figure 3: Excerpt of the bipartite graph which represents the lexicon.
113:229	Words are displayed in ovals, semantic feature in rectangles and formal features in octagons.
114:229	The graph is symmetric.
115:229	ilarity between the definitions; (2) it integrates informations of a syntagmatic nature without a deep syntactic analysis of the definitions; (3) it slightly reduces the strong variations in the lexicographical treatment of the headwords, especially in the division into sub-senses and in the definitions.
116:229	The bipartite graph is built up by symmetrically connecting each headword to its semantic and formal features.
117:229	For instance, the noun orientation is connected with the formal feature $or, $ori, $orie, $orien, etc. which are in turn connected with the words orienter, orientable, orientement orientation, orienteur orientor, etc. Likewise, orientation is connected with the semantic features N.action X.de, N.rsultat X.de X.ce N.action, etc. which are themselves connected with the nouns orientement, harmonisation synchronization, pointage checking, etc. The general schema is illustrated in figure 4.
118:229	This representation corresponds precisely to the Network Model of Bybee (1995).
119:229	We use a bipartite graph mainly for two reasons: (1) We can spread an activation synchronously into the formal and the semantic sub-graphs.
120:229	(2) It contains representations of the formal and the semantic properties of the lexemes which, for instance, could be used in order to describe the semantics of the -able suffixation or the characteristic endings of the boat names (-ier, -eur, etc.).
121:229	However, the bipartite structure is not essential and we only need 3 to be able to compute morphological distances between words.
122:229	5 Random walks The computational side of the method is based on the estimation of the proximity between words represented in a lexical graph (Gaume et al., 2002; Gaume et al., 2005; Muller et al., 2006).
123:229	The graphs used in this approach are slightly different from the ones presented above.
124:229	All their vertices represent words and the edges describe semantic relations such as synonymy.
125:229	The proximity is computed by simulating the spreading into the graph of an activation initiated at a vertice.
126:229	Following the spreading, the nodes which are most excited are regarded as being the closest to the initial vertice.
127:229	The same method can be used to estimate the morphological proximity between words that are described in a bipartite graph like the one we propose (see figure 4).
128:229	It then connects words that have the same semantic and formal features.
129:229	One has just to propagate the activation into the bipartite graph for an even number of times.
130:229	When the graph is heavily redundant, two steps of propagation are sufficient to obtain the intended proximity estimations.
131:229	In the example in figure 4, the morphological neighbors of the noun orientation are identified by activating the vertice which represents it.
132:229	In the first step, the activation is spread toward the vertices which represent its formal and semantic features.
133:229	In the second step, the activation located on the feature vertices is spread toward the headword vertices.
134:229	For instance, orienter becomes activated via the formal features $or, $ori, orien and fermentation through the formal feature entati and the semantic feature N.rsultat X.de X.ce.
135:229	The greater the number of features shared by a headword with orientation, the stronger the activation it receives.
136:229	The spreading of activation is simulated as a random walk in the lexical graph, classically computed as a multiplication of the stochastic adjacency matrix.
137:229	More precisely, let G = (V,E,w) be a weighted graph consisting of a set of vertices V = {v1,,vn}, a set of edges E  V2 and of a weight function w : E  R. Let A be the adjacency matrix of G, that is a nn matrix such that Aij = 0 if (vi,vj) negationslash E and Aij = w(vi,vj) if (vi,vj)  E.
138:229	(In the experiment, w(e) = 1,eE.) We normalize the rows of A in order to get a stochastic matrix M. Mnij is the probability of reaching node vj from the node vi through a walk of n steps.
139:229	This probability can also be regarded as an activation level of node vj following an n-step spreading initiated at vertice vi.
140:229	In the experiment presented in this paper, the activation is spread for one half toward the semantic feature and for the other toward the formal features.
141:229	The edges of the bipartite graph can be divided in three parts E =JKL where J contains the edges that connect a headword to a formal feature, K the edges that connect a headword to a semantic feature and L the edges that connect a formal or semantic feature to a headword.
142:229	The values of M are defined as follows:  if eij = (vi,vj) J, Mij = Aij2P eihJ Aih if vi is connected to a semantic feature and Mij = AijP eikJ Aik otherwise.
143:229	 if eik = (vi,vk)K, Mik = Aik2P eihK Aih if vi is connected to a formal feature and Mik = AikP eihK Aih otherwise.
144:229	 if eil = (vi,vl)L, Mil = AilP eihLAih . 6 Lexical neighborhood The graph used in the experiment has been built from the definitions of the TLFi.
145:229	We only removed the definitions of non standard uses (old, slang, etc.).
146:229	The extraction and cleaning-up of the definitions have been carried out in collaboration with Bruno Gaume and Philippe Muller.
147:229	The bipartite graph has been created from 225 529 definitions describing 75 024 headwords (lexemes).
148:229	We then removed all the features associated only with one headword.
149:229	This reduces the size of the graph significantly without changing the connections that hold between the headwords.
150:229	Table 1 shows that this reduction is stronger for the semantic feature (93%) than it is for the formal ones (69%).
151:229	Indeed, semantic descriptions show greater variability than formal ones.
152:229	The use of the graph is illustrated in figure 4.
153:229	It shows the 20 nearest neighbors of the verb fructifier for various propagation configurations.
154:229	The examples in (a) and (b) show clearly that formal features are the more predictive ones while semantic features are the less reliable ones.
155:229	The example in (c) illustrates the contribution of the semantic 4 (a) V.fructifier N.fructification A.fructificateur A.fructifiant A.fructifre V.sanctifier V.rectifier A.rectifier V.fructidoriser N.fructidorien N.fructidor N.fructuosit R.fructueusement A.fructueux N.rectifieur A.obstructif A.instructif A.destructif A.constructif N.infructuosit (b) V.fructifier V.trouver N.missionnaire N.mission A.missionnaire N.saisie N.police N.hangar N.dme N.ban V.affruiter N.melon N.saisonnement N.azdarach A.fruitier A.bifre V.saisonner N.roman N.troubadour V.contaminer (c) V.fructifier A.fructifiant N.fructification A.fructificateur V.trouver A.fructifre V.rectifier V.sanctifier A.rectifier V.fructidoriser N.fructidor N.fructidorien N.missionnaire N.mission A.missionnaire A.fructueux R.fructueusement N.fructuosit N.rectifieur N.saisie Figure 4: The 20 nearest neighbors of the verb fructifier when the activation is spread (a) only toward the formal features, (b) only toward the semantic ones, (c) toward both the semantic and formal features.
156:229	Words that do not belong to the family or series of fructifier are emphasized.
157:229	graph complete reduced formal features 1 306 497 400 915 semantic features 7 650 490 548 641 Table 1: Number of the semantic and formal features coming from TLFi.
158:229	features.
159:229	They reorder the formal neighbors and introduce among them the nearest semantic neighbors.
160:229	We see in the lists in (a) and (c) that the family members are the nearest neighbors and that the members of the series come next.
161:229	7 Analogy The members of the series and families are massively involved in the analogies which structure the lexicon.
162:229	A wordxbelonging to a familyFx participates in several analogies with a large number of other members of Fx.
163:229	The analogies that involve two words (x,y)  F2 include two other words (z,t) that belong to one same family Fprime.
164:229	On the other hand, if x is a complex word that belongs to a series Sx, then z  Sx, x  Sz, y  St and t  Sy.
165:229	For instance, the couple of words fructifier and fructification form analogies with of members of other families (rectifier, rectification), (certifier, certification), (plastifier, plastification), etc. Moreover, the first elements of these couples belong to series of fructifier and the second ones to the series of fructification.
166:229	In a dual manner, a word u belonging to a series S participates in a set of analogies with a large number of other members of S. The analogies that involve two elements of the same series are made up with words which themselves belong to a same series.
167:229	For instance, fructifier and sanctifier form analogies with the members of other series (fructificateur, sanctificateur), (fructification, sanctification) or (fructifiant, sanctifiant).
168:229	These couples are respectively made of members of the families of fructifier and sanctifier.
169:229	7.1 Analogies and neighborhoods The analogies that involve members of families and series can be used to efficiently filter the morphological neighbors that are identified by the method presented above.
170:229	If v is a correct morphological neighbor ofw, then it is either a member of the family of m or a member of its series.
171:229	Therefore, it exists another neighbor vprime of w (vprime belong to the family of w if v belongs to the series of w or vice versa) such that it exists a neighbor wprime of v and of vprime such that w : v :: vprime : wprime.2 Therefore, we have two configurations: 1.
172:229	ifvFw, thenvprime Sw,wprime SvFvprime,w : v ::vprime :wprime 2.
173:229	ifvSw, thenvprime Fw,wprime FvSvprime,w : v ::vprime :wprime The first case is illustrated by the above examples with w = fructifier and v = fructification, and the second one with w = fructifier et v = rectifier.
174:229	7.2 Formal analogy A formal or graphemic analogy is a relation a : b :: c : d that holds between four strings such that the graphemic differences between a 2The notation a : b :: c : d is used as a shorthand for the statement that (a,b,c,d) forms an analogical quadruplet, or in other words that a is to b as c is to d. 5 and b are the same as the ones between c and d. It can be exemplified with the four Arabic words kataba:maktoubon::fa3ala:maf3oulon which respectively are transcriptions of the verb write, the noun document, the verb do and the noun effect.3 The differences between the first two words and between the two last ones can be described as in figure 5.
175:229	They are identical for the two couples of words.
176:229	epsilon1 k a t a b a ma k epsilon1 t ou b on epsilon1 f a 3 a l a ma f epsilon1 3 ou l on Figure 5: Formal analogy kataba: maktoubon::fa3ala:maf3oulon.
177:229	The differences are locates in frame boxes.
178:229	More generally, formal analogies can be defined in terms of factorization (Stroppa and Yvon, 2005).
179:229	Let L be an alphabet and a  Lstar a string over L. A factorization of a is a sequence f = (f1,,fn)  Lstarn such that a = f1fn wheredenotes the concatenation.
180:229	For instance, (ma, k, epsilon1, t, ou, b, on) is a factorization of length 7 of maktoubon.
181:229	Morphological analogies can be defined as follows.
182:229	Let (a,b,c,d)  Lstar4 be for strings.
183:229	a : b :: c : d is a formal analogy iff there exists n  N and four factorizations of length n of the four strings (f(a),f(b),f(c),f(d))  Lstar4 such that, i  [1,n],(fi(b),fi(c))  {(fi(a),fi(d)),(fi(d),fi(a))}.
184:229	For the analogy kataba:maktoubon::fa3ala:maf3oulon, the property holds for n= 7 (see figure 5).
185:229	7.3 Implementation A formal analogy a : b :: c : d can be easily checked by comparing the sequences of string edit operations between (a,b) and between (c,d).
186:229	Both sequences must minimize Levenshtein edit distance (i.e. have a minimal cost).
187:229	Each sequence corresponds to a path in the edit lattices of the couple of words.
188:229	The lattice are represented by a matrix computed using the standard string edit algorithm (Jurafsky and Martin, 2000).
189:229	The path which describes the sequence of string edit operations starts at the last cell of the matrix and climbs 3This example is adapted from examples in (Lepage, 1998; Lepage, 2003).
190:229	to the first one.
191:229	Only three directions are allowed: upward (deletion), to the left (insertion) or in the upper left diagonal direction (substitution).
192:229	Figure 6 shows the sequence of edit operations for the couple fructueux:infructueusement.
193:229	Sequences of edit operations can be simplified by merging the series of identical character matchings.
194:229	The sequence in figure 6 then becomes ((I,epsilon1,i), (I,epsilon1,n), (M,fructueu,fructueu), (S,x,s), (I,epsilon1,e), (I,epsilon1,m), (I,epsilon1,e), (I,epsilon1,n), (I,epsilon1,t)).
195:229	This simplified sequence is identical to the one for the couple soucieux:insoucieusement except for the matching operation: ((I,epsilon1,i), (I,epsilon1,n), (M,soucieu,soucieu), (S,x,s), (I,epsilon1,e), (I,epsilon1,m), (I,epsilon1,e), (I,epsilon1,n), (I,epsilon1,t)).
196:229	The two sequences can be made identical if the matching sub-strings are not specified.
197:229	The resulting sequence can then be assigned to both couples as their edit signatures ().
198:229	The formal analogy fructueux:infructueusement:: soucieux:insoucieusement can be stated in terms of identity the edit signatures: (fructueux,infructueusement) = (soucieux,insoucieusement) = ((I,epsilon1,i), (I,epsilon1,n), (M,@,@), (S,x,s), (I,epsilon1,e), (I,epsilon1,m), (I,epsilon1,e), (I,epsilon1,n), (I,epsilon1,t)) More generally, four strings (a,b,c,d)Lstar4 form a formal analogy a : b :: c : d iff (a,b) = (c,d) or (a,c) =(b,d).
199:229	7.4 First results The computational model we have just presented has been implemented and a first experiment has been carried out.
200:229	It consists in determining the 100 closest neighbors of every headword for the three configurations presented in  6.
201:229	All the formal analogies that hold between these words have then been collected.
202:229	We have not been able to do a standard evaluation in terms of recall and precision because of the lack of morphological resources for French.
203:229	However, we have manually checked the analogies of 22 headwords belonging to 4 morphological families.
204:229	An analogy a : b :: c : d is accepted as correct if:  b belongs to the family of a, c belongs to the series of a, d belongs to series of b and to the family of c, or  b belongs to the series of a, c belongs to the family of a, d belongs to family of b and to the series of c. 6 I I M M M M M M M M S I I I I I epsilon1 epsilon1 f r u c t u e u x epsilon1 epsilon1 epsilon1 epsilon1 epsilon1 i n f r u c t u e u s e m e n t Figure 6: Sequence of edit operations that transform fructueux into infructueusement.
205:229	The type of each operation is indicated on the first line: D for deletion, I for insertion, M for matching and S for a substitution by a different character.
206:229	configuration analogies correct errors formal 169 163 3.6% semantics 5 5 0.0% sem + form 130 128 1.5% Table 2: Number of the analogies collected for a sample of 22 headwords and error rate.
207:229	The results are summarized in table 2.
208:229	Their quality is quite satisfactory.
209:229	However, the number of analogies strongly depends on the configuration of propagation.
210:229	The best trade-off is a simultaneous propagation toward the semantic and formal features.
211:229	Here are some of the correct and erroneous analogies collected:  R.fructueusement:R.affectueusement:: A.infructueux:A.inaffectueux  N.fructification:N.identification:: V.fructifier:V.identifier  N.fruiterie:N.fruitier::N.laiterie:N.laitier  * N.fruit:N.bruit::V.frusquer:V.brusquer The first example is particularly interesting because it involves on one side suffixed words and on the other prefixed ones.
212:229	The performance of the method strongly depends on the length of the headwords.
213:229	Table 3 presents the number of analogies and the error rate for 13 groups of 5 words.
214:229	The words of each group are of the same length.
215:229	Lengths range from 4 to 16 letters.
216:229	8 Conclusion We have presented a computational model that makes the morphological structure of the lexicon emerge from the formal and semantic regularities of the words it contains.
217:229	The model is radically lexeme-based.
218:229	It integrates the semantic and formal properties of the words in a uniform manner and represents them into a bipartite graph.
219:229	Random walks are used to simulate the spreading of length analogies correct errors 4 29 15 51.7% 5 22 8 36.4% 6 8 1 12.5% 7 10 2 20.0% 8 55 1 1.8% 9 29 2 6.9% 10 30 0 0.0% 11 32 0 0.0% 12 19 0 0.0% 13 11 0 0.0% 14 35 0 0.0% 15 63 0 0.0% 16 39 0 0.0% Table 3: Number of the analogies and error rate for headwords of length 4 to 16.
220:229	activations in this lexical network.
221:229	The level of activation obtained after the propagation indicates the lexical relatedness of the words.
222:229	The members of the morphological family and the derivational series of each word are then identified among its lexical neighbors by means of formal analogies.
223:229	This is work in progress and we still have to separate the members of the families from the members of the series.
224:229	We also intend to conduct a similar experiment on the English lexicon and to evaluate our results in a more classical manner by using the CELEX database (Baayen et al., 1995) as gold standard.
225:229	The evaluation should also be done with respect to well known systems like Linguistica (Goldsmith, 2001) or the morphological analyzer of Bernhard (2006).
226:229	Acknowledgments I would like to thank the ATILF laboratory and Jean-Marie Pierrel for making available to me the TLFi.
227:229	I am in debt to Bruno Gaume and Philippe Muller for the many discussions and exchanges we have had on the cleaning-up of the TFLi and its exploitation through random walks.
228:229	I am also grateful to Gilles Boy, Olivier Haute-Cur and Lu7 dovic Tanguy for their comments and suggestions.
229:229	All errors are mine.

