The donkey strikes back Extending the dynamic interpretation "constructively" Tim Fernando fernando@cwi, nl Centre for Mathematics and Computer Science P.O.
Box 4079, 1009 AB Amsterdam, The Netherlands Abstract The dynamic interpretation of a formula as a binary relation (inducing transitions) on states is extended by alternative treatments of implication, universal quantification, negation and disjunction that are more "dynamic" (in a precise sense) than the usual reductions to tests from quantified dynamic logic (which, nonetheless, can be recovered from the new connectives).
An analysis of the "donkey" sentence followed by the assertion "It will kick back" is provided.
1 Introduction
The line If a farmer owns a donkey he beats it (1) from Geach \[6\] is often cited as one of the success stories of the so-called "dynamic" approach to natural language semantics (by which is meant Kamp \[12\], Heim \[9\], Sarwise \[1\], and Groenendijk and Stokhof \[7\], among others).
But add the note It will kick back (2) and the picture turns sour: processing (1) may leave no beaten donkey active.
Accordingly, providing a referent for the pronoun it in (2) would appear to call for some non-compositional surgery (that may upset many a squeamish linguist).
The present paper offers, as a preventive, a "dynamic" form of implication =~ applied to (1).
Based on a "constructive" conception of discourse analysis, an overhaul of Groenendijk and Stokhof \[7\]'s Dynamic Predicate Logic (DPI).
is suggested, although :=~ can also be introduced less destructively so as to extend DPL conservatively.
Thus, the reader who prefers the old "static" interpretation of (1) can still make that choice, and declare the continuation (2) to be "semantically ill-formed".
On the other hand, Groenendijk and Stokhof \[7\] themselves concede that "at least in certain contexts, we need alternative externally dynamic interpretations of universal quantification, implication and negation; a both internally and externally dynamic treatment of disjunction".
A proposal for such connectives is made below, extending the dynamic interpretation in a manner analogous to the extension of classical logic by constructive logic (with its richer collection of primitive connectives), through a certain conjunctive notion of parallelism.
To put the problem in a somewhat general perspective, let us step back a bit and note that in assigning a natural language utterance a meaning, it is convenient to isolate an intermediate notion of (say) a formula.
By taking for granted a translation of the utterance to a formula, certain complexities in natural language can be abstracted away, and semantics can be understood rigorously as a map from formulas to meanings.
Characteristic of the dynamic approach mentioned above is the identification of the meaning of a formula A with a binary relation on states (or contexts) describing transitions A induces, rather than with a set of states validating A.
In the present paper, formulas are given by first-order formulas, and the target binary relations given by programs.
To provide an account of anaphora in natural language, DPL translates first-order formulas A r m DPL ro tiff 1 to p ogra s A f m (quan " ed) dynam'c logic (see, for example, Harel \[8\]) as follows A DPL A? for atomic A 130 (A&B) DPL = ADPL; BDPL (~A)DPL ---.., (A DPL) (:Ix A) DPL = :r "-'~ • A DPL The negation --,p of a program p is the dynamic logic test (\[p\] ±) ? with universal and static features (indicated respectively by \[p\] and ?),1 neither of which is intrinsic to the concept of negation.
Whereas some notion of universality is essential to universal quantification and implication (which are formulated through negation VzA = -~3z-~A A D B = -,(A&-~B) and accordingly inherit some properties of negation), our treatment of (2) will be based on a dynamic (rather than static) form =~ of implication.
Dynamic forms of negation ~, universal quantification and disjunction will also be proposed, but first we focus on implication.
2 The
idea in brief The semantics \[A\] assigned to a first-order formula A is that given to the program A DP\[ -i.e., a binary relation on states.
In dynamic logic, states are vab uations; more precisely, the set of states is defined, relative to a fixed first-order model M and a set X of variables (from which the free variables of formulas A are drawn), as the set \[M\[x of functions f,g,... from X to the universe IMI of M.
Atomic programs come in two flavors: tests A? where A is a formula in the signature of M with free variables from X, and random assignments x :=? where z E X.
These are analyzed semantically by a function p taking a X X program p to a binary relation p(p) C IMI x IMI according to fp(A?)g iff f=gandM~A\[f\] fp(x :=?)g iff f = g except possibly at x . The programs are then closed under sequential composition (interpreted as relational composition) fp(p;p')g iff fp(p)h and hp(p')g for some h, non-deterministic choice (interpreted as union) f p(p + p')g iff f p(p)g or hp(p')g, and Kleene star (interpreted as the reflexive transive closure).
Rather than extending ~ simultaneously to formulas built from modalites \[p\] and (p) labelled by programs p, it is sufficient to close the programs 1The semantics of dynamic logic is reviewed in the next section, where what exactly is meant, for example, by %tactic" is explained.
under a negation operation interpreted semantically as follows fP('~P)g iff f = g and fp(p)h for no h.
As previously noted, -~p is equivalent to (\[p\]_l.)?.
Returning to DP1, an implication A D B between formulas is interpreted in DP1 by equating it with -~ (A ~ -~B), which is in turn translated into the dynamic logic program -~ (ADPL ; -,(BDPL)).
Applying the semantic function p to this then yields s\[ADB\]t iff t=s and (Vs' such that s\[A\]s'),'\[Bit'.
(3) Now, given that a state is a single function from X to JMJ, it is hardly odd that implication is static (in the sense that the input and output states s and t must be the same), as any number of instantiations of s t (and t e) may be relevant to the right hand side of (3).
That is, in terms of (1), the difficulty is that there may be several farmer/donkey couples, whereas a state can accomodate only one such pair, rendering an interpretation of (2) problematic.
To overcome this predicament, the collection of states can be extended in at least two ways.
(P1) Borrowing and modifying an idea from Kleene \[14\] (and Brouwer, Kolmogorov,...), incorporate into the final state t a functional witness f to the V3-clause in the right hand side of (3) to obtain s\[Azc, B\]t iff t=(s,f) and f is a function with domain {s' \[s\[A\]s'}, and (Vs' E dom(f)) s'\[B\]f(s') . Or, to simplify the state t slightly, break the condition (in the righthand side) up into two mutually exclusive clauses depending on whether or not the domain of f is empty s\[A=~ Bit iff (t is a function with non-empty domain {s' J s\[A\]s'} and (Vs' e dom(/)) s'\[n\]t(s')) or (t = s and -,3s' s\[A\]s'), so that closing the notion of a state under a partial function space construct becomes sufficient.
131 i P2) Keep only the image of a functional witness so that the new (expanded) set of states consists simply of the old states (i.e, valuations) together with sets of valuations.
More precisely, define sEA~ Bit iff (3 a function f with non-empty domain {s' l s\[A\]s' } where t is the collapsed image of jr and (Vs' • dom(jr)) s'\[B\]jr(s')) or (t = s and ",3s' s\[A\]s').
(4) The "collapsed image of fl', {t' e IMI x I 3s' jr(s t) --t') U Ue c_ IMI x I _~s' jr(s') = e}), is simply the image of jr except that the sets of valuations in the image are "collapsed", so that the resulting set has only valuations as elements.
(The collapsing is "justified" by the associativity of conjunction).
Observe that, in either case, DPL's negation can be derived --A = A=~_L (whence D is also definable from => and &).
The first proposal, (P1), yields a dizzying tower of higherorder functions, in comparison to which, the second proposal is considerably simpler.
Behind the step from (3) to either proposal is the idea that implication can spawn processes running in parallel.
(Buried in (3) is the possibility of the input state s branching off to a multiplicity of states t').
The parallelism here is "conjunctive" in that a family of parallel processes proceeds along happily so long as every member of the family is well; all is lost as soon as one fails.
2 More
precisely, observe that, under (P2), a natural clause for s\[A\]t, where s is a set of valuations and A is an atomic formula, is 3 s\[A\]t iff B a function jr : s -*onto t such that (Vs' e s) s'\[Alf(s') . 2The notion of parallelism is thus not unlike that of concurrent dynamic logic (Peleg \[19\]).
By contrast, the non-empty) sets of valuations used (e.g., in Fernando \]) to bring out the eliminative character of information growth induced by tests A? live disjunctively (and die conjunctively).
3A (non-equivalent) alternative is s\[Alt iff (Vs' e s) (3t' e t) s'IAlt' and (Vt' e t) (3s' e s) s'\[AIt', yielding a more promiscuous ontology.
This is studied in Fernando \[5\], concerning which, the reader is referred to the next footnote.
(That is, in the case of (2), every donkey that a farmer beats according to (1) must kick back).
A similar clause must be added to (P1), although to make the details for (P1) obvious, it should be sufficient to focus (as we will) on the case of (P2), where the states are structurally simpler.
But then, a few words justifying the structural simplification in (P2) relative to (P1) might be in order.
4 3 A digression: forgetfulness and information growth If semantic analysis amounts abstractly to a mapping from syntactic objects (or formulas) to other mathematical objects (that we choose to call meanings), then what (speaking in the same abstract terms) is gained by the translation?
Beyond some vague hope that the meanings have more illuminating structure than have the formulas, a reason for carrying out the semantic analysis is to abstract away inessentim syntactic detail (with a view towards isolating the essential "core").
Thus, one might expect the semantic function not to be 1-1.
The more general point is that an essential feature of semantic analysis is the process of forgetting what can be forgotten.
More concretely, turning to dynamic logic and its semantic function p, observe that after executing a random assignment x :=?, the previous (-input state) value of x is overwritten (i.e., forgotten) in the output state, s Perhaps an even more helpful example is the semantic definition of a sequential composition p; p'.
The intermediate state arising after p but before p' is forgotten by p(p;p') (tracking, as it does, only input/output states).
Should such information be stored?
No doubt, recording state histories would not decrease the scope of the account that can then be developed.
It would almost surely increase it, but at what cost?
The simpler the semantic framework, the better -all other things being equal, that is (chief among which is explanatory power).
Otherwise, a delicate balance must be struck between the complexity of the framework and its scope.
Now, part of the computational intuition underlying dynamic logic is that at any point in time, a state (i.e., valuation) embodies all that is relevant about the past to what can happen in the future.
(In other words, the meaning of a program is specified simply by pairs of input/output states).
This same intuition underlies (P2), discarding (as it does) the wit4The discussion here will be confined to a somewhat intuitive and informal level.
A somewhat more technical mathematical account is developed at length in Fernando \[5\], where (P2) is presented as a reduction of (P1) to a disjunctive normal form (in the sense of the "conjunctive" and "disjunctive" notions of parallelism already mentioned).
5It should, in fairness, be pointed out that Vermeulen \[22\] presents a variant of dynamic logic directed towards revising this very feature.
132 ness function tracing processes back to their "roots".
(Forgetting that spawning record would seem to be akin to forgetting the intermediate state in a sequential composition p; p~).
Furthermore, for applications to natural language discourse, forgetfulness would appear quite innocuous if the information content of a state increases in the course of interpreting discourse (so that all past states have no more information content than has the current state).
And it is quite natural in discourse analysis to assume that information does grow.
Consider the following claim in an early paper (Karttunen \[13\]) pre-occupied with a problem (viz., that of presuppositions) that may appear peripheral to (1) or (2), but is nonetheless fundamental to the "constructive" outlook on which =¢, is based There are definitions of pragmatic presupposition ...
which suggest that there is something amiss in a discourse that does not proceed in \[an\] ideal orderly fashion ....
All things considered, this is an unreasonable view ....
People do make leaps and shortcuts by using sentences whose presuppositions are not satisfied in the conversational context.
This is the rule rather than the exception, and we should not base our notion of presupposition on the false premiss that it does not or should not happen.
But granting that ordinary discourse is not always fully explicit in the above sense, I think we can maintain that a sentence is always taken to be an increment to a conte~:t that satisfies its presuppositions.
\[p. 191, italics added\] To bring out an important dimension of "increment to a context", and at the same time get around the destruction of information in DPL by a random assignment, we will modify the translation .DPI.
(mapping first-order formulas into programs) slightly into a translation .~, over which (P2) will be worked out (though the reader should afterwards have no difficulty carrying out the similar extension to DPI.).
The modification is based (following Fernando \[4\], and, further back, Barwise \[1\]) on (i) a switch from valuations defined on all variables to valuations defined on only finitely many variables, and on (ii) the use of guarded assignments x := * (in place of random assignments), given by =z?
+ -~(z=z?); ~:=?, which has the effect of assigning a value to x precisely when initially z is unbound (in which ease the test z = z? fails).
Note that (i) spoils bivalence, which is to say that certain presuppositions may fail.
6 Accordingly, our translation R(~) ~ of an STo what extent an account of presuppositions can be based on the break down in bivalence resulting from atomic formula R(~) to a program must first attend to presuppositions by plugging truth gaps through guarded assignments, before testing R(~) = • := • ; (5) (where • :-• abbreviates xl := *;...z~ := • for = zl,...,xk).
To avoid clashes with variables bound by quantifiers, the latter variables might be marked (3x A) e = YA,z :-'* ; A\[yA,~/x\] e, (6) the idea being to sharpen (5) by translating atomic formulas R(~, y, ~) with unmarked variables 3, and marked variables y, ~ (for 3 and V respectively) as follows = := • ; (7) Note that to assert a formula A is not simply to test A, but also to establish A (if this is at all possible).
Establishing not A is (intuitively) different from testing (as in DPL) that A cannot be established.
7 A
negation,-, reflecting the former is described next, avoiding an appeal to a modal notion (hidden in -~ by writing --,p instead of (\[p\]_l_)?).
4 Working
out the idea formally Starting over and proceeding a bit more rigorously now, given a first-order signature L, throw in, for every n-ary predicate symbol R E L, a fresh n-ary predicate symbol/~ and extend the map : to these symbols by setting R = R.
Then, interpret/~ in an L-structure M as the complement of R /~M _ IMI'-R M.
So, without loss of generality, assume that we are working with a signature L equipped with such a map :, and let M be an L-model obeying the complementarity condition above (readily expressible in the first-order language).
Fix a countable set X0 of variables, and define two fresh (disjoint) sets Y and Z of "marked" variables inductively simultaneously with a set ~ of L-formulas (built from &, V, V, 3 and =~) as follows (i) T, _1_ and every atomic L-formula with free variables from Xo U Y U Z is in (ii) if A and B are in ~, then so are A&B, A V B and A ~ B (iii) for every ("unmarked") z E X0, if A E ¢, then Vz A and 3z A belong to uninitialized variables will not be taken up here.
The interested reader is referred to Fernando \[4\] for an internal notion of proposition as an initial step towards this end.
7As detailed in Fernando \[4\], this distinction c~n be exploited to provide an account of Veltman \[21\]'s might operator as -1--.
relative to an internal notion of proposition.
133 (iv) for every x E X0, if A E 4, then the fresh ("marked") variables YA,, and za,, belong to Y and Z respectively.
Next, define a "negation" map,-~ • on ~ by,-,T = 1.
~.L = T ~ R(~,~,-~) = R(~,~,-~) .~(A&B) =,,,A V,.,B,~(AVB) =,-~A &,,~B (VxA) = 3x,-~A -~(3xA) = Vx,,-A ~(A::# B) = A & NB . This approach, going back at least to Nelson \[17\] (a particularly appropriate reference, given its connection with Kleene \[14\]), treats positive and negative information in a nearly symmetric fashion; on formulas in ~ without an occurrence of ::~, the function,~N.
is the identity.
Furthermore, were it not for :V, our translation -~ would map formulas in (~ to programs interpreted as binary relations on So = {s \[ s is a function from a finite subset of X to IMI}, where X is the full set of marked an unmarked variables X = XoUYUZ.
All the same, the clauses for s\[A\]t can be formulated uniformly whether or not s E So, so long as it is understood that for a set s of valuations, u E X, and atomic A, sp(u :=,)t iff 3 a function f : s --*~,o t such that (Vs' e s) s' p(u := *)f(s') sp(A?)t iff ~ = s and (Ys' 6.
s) s'p(A?)s' . (These clauses are consistent with the intuition described in section 2 of a "conjunctive" family of processes running in parallel).
The translation .e is then given by (7), (A&B) e = A';B e (AVB) e = Ae+B e, (6) and (4), with IMI x replaced by So.
All that is missing is the clause for universal quantification Vx A, which (following Kleene \[14\]) can be interpreted essentially as zA,~ = ZA,~: ~ A\[ZA,x/X\], except that in the antecedent, ZA,,: is treated as unmarked s~/x Air iff t is the collapsed image of a function f with domain {s' I sp( A, :=,)s'} such that (Vs' e dom(f)) s'\[A\[zA,x/z\]\]f(s') . The reader seeking the definition of \[A\] spelled out in full is referred to the appendix.
Observe that non-deterministic choice + (for which DPL has no use) is essential for defining N.
Strong negation,,, is different from -% and lacks the universal force necessary to interpret implication (either as,,~ (.& ~ )).
or as -V,~ .).
On the other hand, --A can be recovered as A =~ .L, whence static implication D is also derivable.
Note also that an element s of So can be identified with {s}, yielding states of a homogeneous form.
5 A
few examples The present work does not rest on the claim that the disorderly character of discourse mentioned above by Karttunen \[13\] admits a compositional translation to a first-order formula.
The problem of translating a natural language utterance to a first-order formula (e.g., assigning a variable to a discourse marker) is essentially taken for granted, falling (as it does) outside the scope of formal semantics (conceived as a function from formulas to meanings).
This affords us considerable freedom to accomodate various interpretations.
The donkey sentence (1) can be formulated as _ srCx) o sCx, y) ao eyCy) beats(x, y) or given an alternative "weak" reading f~,-~er(z) a o~s(z, z) & do~key(z) ::> y) doPey(y) beat (x, y) so that not every donkey owned by a farmer need be beaten (Chierchia \[2\]).
In either case, the pay back (2) can be formulated as kicks-back(y, x) . A further alternative that avoids presupposing the existence of a donkey is to formulate (1) and (2) as o s(x, y) do sy(y) beat-(x, y) kick -baek(y, x), observing that \[(A=> B)&C\] ~ \[A => (B&C)\].
N ext, nendijk and Stokhof \[7\] If a client turns up, you treat him politely.
You offer him a cup of coffee and ask him to wait.
Every player chooses a pawn.
He puts it we consider a few examples from Groe(8) 134 on square one.
It is not true that John doesn't own a car.
It is red, and it is parked in front of his house.
Either there is no bathroom here, or it is a funny place.
In any case, it is not on the first floor.
Example (8) can be formulated as client(z) turns-up(z) treat-polit ely(y, x) (9) (10) (11) followed by o er-co ee(y,z) as -to-.ait(y,z), and (9) as player(z) ::~ ehoose(z,y) & pawn(y) followed by put-on-sqaare-on~x, y) . The double negation in (10) can be analyzed dynamically using -,~., and (11) can be treated as bathroom(z) :~ -here(x) V funny-place followed by ~on-first-floo~z), where, in this case, the difference between -,, and -~ is immaterial.
Groenendijk and Stokhof \[7\] suggest equating (not A) implies B, in its dynamic form, with A V B.
To allow not A to be dynamic, not should not be interpreted as ~.
But even (-~ A) =:~ B is different from A V B, as the non-determinism in A V B is lost in (,,~ A) :¢.
B, and :=~ may lead to structurally more complex states (¢ So).
What is true is that,,~,,~ ((NA) :=~ B) =,,, ((~A) & ~B) = (-,,~A) V,~,~B which reduces to A V B if ~ occurs neither in A nor B.
Whereas the translation -~-~.
yields a static approximation, the translation ~,-,-, applied recursively, projects to an approximation that is a binary relation on So.
Notice that quantifers do not appear in the translations above of natural language utterances into first-order formulas.
The necessary quantification is built into the semantic analysis of quantifier-free formulas, following the spirit (if not the letter) of Pagin and Westerst£hl \[18\].
(A crucial difference, of course, is that the universal quantification above arises from a dynamic =~).
The reader interested in compositionality should be pleased by this feature, insofar as quantifer-free formulas avoid the non-compositional relabelling of variables bound by quantifiers (in the semantic analysis above of quantified formulas).
6 Concerning
certain points The present paper is admittedly short on linguistic examples -a defect that the author hopes some sympathetic reader (better qualified than he) will correct.
Towards this end, it may be helpful to take up specific points (beyond the need for linguistic examples) raised in the review of the work (in the form it was originally submitted to EACL).
Referee 1.
What are the advantages over explanations of the anaphoric phenomenon in question in terms of discourse structure which do not require a change of the formal semantics apparatus?
The "anaphoric phenomenon in question" amounts, under the analysis of first-order formulas as programs, to the treatment of variables across sentential boundaries.
A variable can have existential force, as does the farmer in A farmer owns a donkey, or universal force, as does the farmer in Every farmer owns a donkey.
Taking the "the formal semantics apparatus" to be dynamic logic, DPL treats existential variables through random assignments.
The advantage of the proposal(s) above is the treatment of universal variables across sentential variables, based on an extension of dynamic logic with an implication connective (defined by (4), if A and B are understood as programs).
(Note that negation and disjunction can be analyzed dynamically already within dynamic logic).
Referee 2.
Suggestions for choosing between the static/dynamic versions would enhance the usefulness of the framework.
Choose the dynamic version.
Matching discourse items with variables is, afterall, done by magic, falling (as it does) outside the scope of DPL or Discourse Representation Theory (DRT, Kamp \[12\]).
But the reader may have good reason to object.
Programme Committee.
A comparison to a DRT-style semantics should be added.
Yes, the author would like to describe the discourse representation structures (DRS's) for the extension to higher-order states above.
Unfortunately, he does not (at present) know how to.
s Short of that, it may be helpful to present the passage to states that are conjunctive sets of valuations in a different light.
Given a state that is a set s of valuations sl, s~,..., let X, be the set of variables in the domain of some si Gs X, = U dom(si).
siEs SSome steps (related to footnote 4) towards that direction are taken in Fernando \[5\].
Another approacb, somewhat more syntactic in spirit, would be to build on K.
Fine's arbitrary objects (Meyer Viol \[15\]).
135 Now, s can be viewed as a set F, of functions f~ labelled by variables z E X, as follows.
Let f~ be the map with domain {si e s \[ z e dom(si)} that sends such an si to si(z).
In pictures, we pass from to I st :dl~ct 1 s = s2:d2--+c2 { f~l:{si~slzt~di}__+Cl } F, -f~2 : {si E s I z2 E di} -.-* c2, so that the step from states sl,s2,.., in So to the more complicated states s in Power(S0) amounts to a semantic analysis of variables as functions, rather than as fixed values from the underlying first-order model.
(But now what is the domain of such a function)?
The shift in point of view here is essentially the "ingenious little trick" that Muskens \[16\] (p.
418) traces back to Janssen \[11\] of swapping rows with columns.
We should be careful to note, however, that the preceding analysis of variables was carried out relative to a fixed state s -a state s that is to be supplied as an argument to the partial binary functions globally representing the variables.
Finally, A.
Visser and J.
van Eijck have suggested that a comparison with type-theoretic and gametheoretical semantics (e.g., Ranta \[20\] and Hintikka and Kulas \[10\]) is in order.
This again is no simple matter to discuss, and (alas) fails somewhat beyond the scope of the present paper.
For now, suffice it to say that (i) the translation • e above starts from first-order formulas, on which (according to Ranta \[20\], p.
378) the gametheoretic "truth definition is equivalent to the traditional Tarskian one", and that (ii) the use of constructive logic in Ranta \[20\] renders the reduction from the proposal (P1) to (P2) (described in section 2) implausible inasmuch as that represents a (constructively unsound) transformation to a disjunctive normal form (referred to in footnote 4).
But what about constructiveness? 7 Between construction and truth Having passed somewhat hastily from (P1) to (P2), the reader is entitled to ask why the present author has bothered mentioning realizability (alluding somewhat fashionably or unfashionably to "constructiveness") and has said nothing about (classical) modal logic-style formalizations (e.g., Van Eijck and De Vries \[3\]), building say on concurrent dynamic logic (Peleg \[19\]).
A short answer is that the connection with so-called and/or computations came to the author only after trying to understand the interpretation of implication in Kleene \[14\] (interpreting implication as a program construct being nowhere suggested in Peleg \[19\], which instead introduces a "conjunction" fl on programs).
A more serious answer would bring up his attitude towards the more interesting question does all talk about so-called dynamic semantics come to modal logic?
The crazy appeal dynamic semantics exerts on the author is the claim that a formula (normally conceived statically) is a program (i.e., something dynamic); showing how a program can be understood statically is less exciting.
Some may, of course, find the possibility of "going static" as well as "going dynamic" comforting (if not pleasing).
But if reducing dynamic semantics to static truth conditions is to complete that circle, then formulas must first be translated to programs.
And that step ought not to be taken completely for granted (or else why bother talking about "dynamic semantics").
Understanding a computer program in a precise (say "mathematical") sense is, in principle, to be expected insofar as the states through which the computer program evolves can be examined.
If a program can be implemented in a machine, then it has a well-defined operational semantics that, moreover, is subject (in some sense or another) to Church's thesis.
In that sense, understanding a computer program relative to a mathematical world of eternal truths and static formulas is not too problematic.
Not too problematic, that is, when compared to natural language, for which nothing like Church's thesis has gained acceptance.
To say that natural language is a programming language is outrageous (-perhaps deliberately so --), and those of us laboring under this slogan must admit that we do not know how to translate an English sentence into a FORTRAN program (whatever that may mean).
Nor, allowing for certain abstractions, formulas into programs.
Furthermore, a favorite toy translation, DPL, goes beyond ordinary computability (and FORTRAN) when interpreted over the natural numbers.
(The culprit is --).
Not that the idea of a program must necessarily be understood in the strict sense of ordinary recursion theory.
But some sensitivity to matters relating to computation ("broadly construed") is surely in order when speaking of programs.
It was the uncomputable character of DPL's negation and implication that, in fact, drove the present work.
Strong negation,~ is, from this standpoint, a mild improvement, but it would appear that the situation for implication has only been made more complicated.
This complication can be seen, however, as only a first step towards getting a handle on the computational character of the programs used in interpreting formulas dynamically.
Whether more effective forms of realizability (incorporating, as was 136 originally conceived, some notion of construction or proof into the witnessing by functions) can shed any helpful light on the idea of dynamic semantics is an open question.
That realizability should, crazily enough, have anything to say whatsoever about a linguistic problem might hearten those of us inclined to investigate the matter.
(Of course, one might take the easy way out, and simply restrict =~ to finite models).
Making certain features explicit that are typically buried in classical logic (such as the witness to the V3-clause in ::~) is a characteristic practice of constructive mathematics that just might prove fruitful in natural language semantics.
A feature that would seem particularly relevant to the intuition that discourse interpretation amounts to the construction of a context is information growth.
9 The
extension of the domain of a finite valuation is an important aspect of that growth (as shown in Fernando \[4\], appealing to Henkin witnesses, back-and-forth constructions, ...).
The custom in dynamic logic of reducing a finite valuation to the set of its total extensions (relative to which a static notion of truth is then defined) would appear to run roughshod over this feature -a feature carefully employed above to draw a distinction between establishing and testing a formula (mentioned back at the end of section 3).
But returning to the dynamic implication ::~ introduced above, observe that beyond the loss of structure (and information) in the step from (P1) to (P2), it is possible within (P2) (or, for that matter, within (P1)) to approximate =~ by more modest extensions.
There is, for instance, the translation -,~,,~ • (not to be confused with -----) which (in general) abstracts away structure with each application.
The interpretation of implication can be simplified further by noting that --Tr can be recovered as ~r =V .1_, and thus the static implication D of DPI.
can be derived from ::~.
Reflecting on these simplifications, it is natural to ask what structure can dynamic semantics afford to forget?
Is there more structure lurking behind construction than concerns truth?
With the benefit of the discussion above about the dual (establishing/testing) nature of asserting a proposition -or perhaps even without being subjected to all that babble --, surely we can agree that Story-telling requires more imagination than verifying facts.
9The idea that information grows during the run of a typical computer program is, by comparison, not so clear.
One difference is that whereas guarded assignments would seem sufficient for natural language applications, a typical computer program will repeatedly assign different values to the same variable.
To pursue the matter further, the reader may wish to (again) consult Vermeulen \[22\].
Acknowledgments My thanks to J.
van Eijck and J.
Ginzburg for criticisms of a draft, to K.
Vermeulen, W.
MeyerViol, A.
Visser, P.
Blackburn D.
Beaver, and M.
Kanazawa for helpful discussions, and to the conference's anonymous referees for various suggestions.
Appendix: (P2) fleshed out without prose Fix a first-order model M and a set X of variables partitioned between the unmarked (x,)... and marked (y,... and z,... for existential and universal quantification, respectively).
(It may be advisable to ignore the marking of variables, and quantified formulas; see section 5 for some examples).
Let So be the set of functions defined on a finite subset of X, ranging over the universe of M.
Given a sequence of variables ux,..., u,, in X, define the binary relation p(~ := *) on s and t E So U Power(So) by sp(~:=*)t iff (sESo, teSo, t_Dsand dom(t) = dom(s) U {ul,..., u,}) or (s ~ So and 3 a function f : s --'o,~to t such that (Vs r E s) s'p(~ := *)f(s~)) . L-formulas A from the set @ defined in section 3 are interpreted semantically by binary relations ~'A\] C (So U Power(so))x (So u Power(S0)) according to the following clauses, understood inductively sl\[n(~,y,~)\]t iff (s E So, sp('~ :.)t and M ~ nit\]) or (3 a function f from s onto t such that (Vs' e s) s'\[R(~,y,-~\]f(s')) s\[A&S\]t iff s\[A\]\]u and u\[B\]t for some u s\[A V B\]t iff s\[A\]\]t or s\[B\]t s~/x A\]\]t iff t is the collapsed image of a function f with domain {s' I sp(zA,.
:=,)s'} such that (Vs' e dom(/)) s'\[A\[za,o:/x\]\]f(s') s\[3x A\]t iff sp(YA,~ :=*)u and 137 u~A\[yA,~/x\]\]t for some u s\[A ~ B\]t iff (3 afunction f with non-empty domain {s' i s\[A\]s'} where t is the collapsed image of f and (Vs' e dora(f)) s'\[Blf(s')) or (t = s and -,Bs' s\[A\]s'), and, not to forget negation, s\[T\]t iff s=t s\[±\]t iff you're a donkey (in which case you are free to derive anything).
References \[1\] Jon Barwise.
Noun phrases, generalized quantifiers and anaphora.
In E.
Engdahl and P.
G~denfors, editors, Generalized Quantiflers, Studies in Language and Philosophy.
Dordrecht: Rediel, 1987.
\[2\] G.
Chierchia. Anaphora and dynamic logic.
ITLI Prepublication, University of Amsterdam, 1990.
\[3\] J.
van Eijck and F.J. de Vries.
Dynamic interpretation and Hoare deduction.
J. Logic, Language and Information, 1, 1992.
\[4\] Tim Fernando.
Transition systems and dynamic semantics.
In D.
Pearce and G.
Wagner, editors, Logics in AI, LNCS 633 (subseries LNAI).
Springer-Verlag, Berlin, 1992.
A slightly corrected version has appeared as CWI Report CSR9217, June 1992.
\[5\] Tim Fernando.
A higher-order extension of constraint programming in discourse analysis.
Position paper for the First Workshop on Principles and Practice of Constraint Programming (Rhode Island, April 1993).
\[6\] P.T.
Geach. Reference and Generality: an Examination of Some Medieval and Modern Theories.
Cornell University Press, Ithaca, 1962.
\[7\] J.
Groenendijk and M.
Stokhof. Dynamic predicate logic.
Linguistics and Philosophy, 14, 1991.
\[8\] David Hard.
Dynamic logic.
In D.
Gabbay and F.
Guenthner, editors, Handbook of Philosophical Logic, Volume 2.
D. Reidel, 1984.
\[9\] Irene Heim.
The semantics of definite and indefinite noun phrases.
Dissertation, University of Massachusetts, Amherst, 1982.
\[10\] J.
Hintikka and J.
Kulas. The Game of Language.
D. Reidel, Dordrecht, 1983.
\[11\] Theo Janssen.
Foundations and Applications of Montague Grammar.
Dissertation, University of Amsterdam (published in 1986 by CWI, Amsterdam), 1983.
\[12\] \].A.W.
Kamp. A theory of truth and semantic representation.
In J.
Groenendijk et.
al., editors, Formal Methods in the Study of Language.
Mathematical Centre Tracts 135, Amsterdam, 1981.
\[13\] Lauri Karttunen.
Presupposition and linguistic context.
Theoretical Linguistics, pages 181-194, 1973.
\[14\] S.C.
Kleene. On the interpretation of intuitionistic number theory.
J. Symbolic Logic, 10, 1945.
\[15\] W.P.M.
Meyer Viol.
Partial objects and DRT.
In P.
Dekker and M.
Stokhof, editors, Proceedings of the Eighth Amsterdam Colloquium.
Institute for Logic, Language and Computation, Amsterdam, 1992.
\[16\] Reinhard Muskens.
Anaphora and the logic of change.
In J.
van Eijck, editor, Logics in AI: Proc.
European Workshop JELIA '90.
SpringerVerlag, 1991.
\[17\] David Nelson.
Constructible falsity.
Y. Symbolic Logic, 14, 1949.
\[18\] P.
Pagin and D.
Westerst£hl. Predicate logic with flexibly binding operators and natural language semantics.
Preprint. \[19\] David Peleg.
Concurrent dynamic logic.
J. Assoc.
Computing Machinery, 34(2), 1987.
\[20\] Aarne Ranta.
Propositions as games as types.
Synthese, 76, 1988.
\[21\] Frank Veltman.
Defaults in update semantics.
In J.A.W.
Kamp, editor, Conditionals, Defaults and Belief Revision.
Edinburgh, Dyana deliverable R2.5.A, 1990.
\[22\] C.F.M.
Vermeulen. Sequence semantics for dynamic logic.
Technical report, Philosophy Department, Utrecht, 1991.
To appear in J.
Logic, Language and Information. 138

