In (Wu, 1997), these forbidden subsequences are called ’inside-out’ transpositions.
J97-3002
The remaining free parameters, i.e. pm and the model scaling factors (Och and Ney, 2002), were adjusted on the development corpus (Dev).
P02-1038
the parse trees of the simple grammar in (Wu, 1997).
J97-3002
Obviously, these productions are not in the normal form of an ITG, but with the method described in (Wu, 1997), they can be normalized.
J97-3002
of Word Graphs The generation of word graphs for a bottom-top search with the IBM constraints is described in (Ueffing et al., 2002).
W02-1021
The first constraints are based on inversion transduction grammars (ITG) (Wu, 1995; Wu, 1997).
J97-3002
For this purpose, we adopt the view of the ITG constraints as a bilingual grammar as, e.g., in (Wu, 1997).
J97-3002
3.1, but here, we use monotone translation hypotheses of the full IBM Model 4 as initialization, whereas in (Wu, 1996) a single-word based lexicon model is used.
P96-1021
In (Wu, 1996) the baseline ITG constraints were used for statistical machine translation.
P96-1021
2 is the so-called source-channel approach to statistical machine translation (Brown et al., 1990).
J90-2002
For this purpose, we compute the Viterbi alignment of IBM Model 5 with GIZA++ (Och and Ney, 2000).
P00-1056
If arbitrary word-reorderings are allowed, the search problem is NP-hard (Knight, 1999).
J99-4005
With this constraint, each of these binary trees is unique and equivalent to a parse tree of the ’canonical-form’ grammar in (Wu, 1997).
J97-3002
