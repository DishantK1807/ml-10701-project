work (Kumar and Byrne, 2005; Blackwood et al.,
H05-1021
the same as that described by Koehn et al. (2003), as
N03-1017
Riedel and Clarke (2009) have improved the effi-
N09-2002
Christoph Tillmann and Hermann Ney. 2003. Word re-
J03-1005
lief propagation (Smith and Eisner, 2008) is closely
D08-1016
Phrase-based models (Och et al., 1999; Koehn et
W99-0604
Christoph Tillmann. 2006. Efficient dynamic pro-
W06-3602
typically chosen using MERT training (Och, 2003).
P03-1021
et al., 1993) has been studied by Germann et al.(2001), with experiments using a bigram language
P01-1030
and Ney (2003) and Tillmann (2006).
W06-3602
implemented in MOSES (Koehn et al., 2007).
P07-2045
Roy W. Tromble and Jason Eisner. 2006. A fast
N06-1054
(e.g., see Koehn et al. (2003)).
N03-1017
method to MOSES (Koehn et al., 2007), and
P07-2045
an approximate algorithm for TSP. Och et al. (2001)
W01-1408
David A. Smith and Jason Eisner. 2008. Dependency
D08-1016
Sebastian Riedel and James Clarke. 2009. Revisiting
N09-2002
al., 2003; Koehn et al., 2007) are a widely-used
P07-2045
by MOSES (Koehn et al., 2007). The method
P07-2045
Alexander M. Rush and Michael Collins. 2011. Exact
P11-1008
Beam search stack decoders (Koehn et al., 2003)
N03-1017
see Koehn et al. (2003)). The bigram (w1,w2) is
N03-1017
Franz Josef Och. 2003. Minimum error rate training
P03-1021
same as that in Koehn et al. (2003), and is the same
N03-1017
(Koehn et al., 2007). However, a complicating fac-
P07-2045
state machines (Tromble and Eisner, 2006); and
N06-1054
(Papineni et al., 2002) for decoding using MOSES
P02-1040
Shankar Kumar and William Byrne. 2005. Local phrase
H05-1021
2003; Koehn et al., 2007), considered in this paper. Other vari-
P07-2045
rithm. We compare to MOSES (Koehn et al., 2007),
P07-2045
Sebastian Riedel and James Clarke. 2006. Incremental
W06-1616
