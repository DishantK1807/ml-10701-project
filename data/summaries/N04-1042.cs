Feature induction (McCallum, 2003) has been shown to provide significant improvements in CRFs performance.
W03-0430
McCallum. 2003.
W03-0430
Under a hyperbolic prior, LΛ = X i logPΛ(yi|xi) − X k log(e λk + e−λk 2 ) (5) which corresponds to satisfying X i fk(yt−1,yt,xi,t) − e |λk| − e−|λk| e|λk| + e−|λk| = X i PΛ(y|x)fi(yt−1,yt,xi,t) The hyperbolic prior was also tested with CRFs in McCallum and Li (2003).
W03-0430
CRFs have been previously applied to other tasks such as name entity extraction (McCallum and Li, 2003), table extraction (Pinto et al., 2003) and shallow parsing (Sha and Pereira, 2003).
N03-1028 W03-0430
These data sets have been used as standard benchmarks in several previous studies (Seymore et al., 1999; McCallum et al., 2000; Han et al., 2003).
W03-0430
Traditional maximum entropy learning algorithms, such as GIS and IIS (Pietra et al., 1995), can be used to train CRFs, however, it has been found that a quasi-Newton gradient-climber, BFGS, converges much faster (Malouf, 2002; Sha and Pereira, 2003).
N03-1028 W02-2018
Following previous research (Seymore et al., 1999; McCallum et al., 2000; Han et al., 2003), for each trial we randomly select 500 for training and the remaining 435 for testing.
W03-0430
