  
‘If you’ve heard it, you can say it’ 
Towards an Acount of Expresibility 
 
David D. McDonald 
Raytheon BBN Technologies 
Cambridge, MA USA 
dmcdonald@bbn.com 
Charles F. Grenbacker 
University of Delaware 
Newark, DE, USA 
charlieg@cis.udel.edu 
 
  
Abstract 
We have begun a project to automaticaly cre-
ate the lexico-syntactic resources for a mi-
croplanner as a side-effect of runing a do-
main-specific language understanding system. 
The resources are parameterized synchronous 
TAG Derivation Tres. Since the KB is as-
sembled from the information in the texts that 
these resources are abstracted from, it will de-
compose along those same lines when used for 
generation. As al posible ways of expresing 
each concept are pre-organized into general 
paterns known to be linguistically-valid (they 
were observed in natural text), we obtain an 
architectural account for expressibility. 
1. Expresibility 
People speak gramaticaly. They may stuter, 
restart, or make the ocasional spech eror, but 
all in all they are faithful to the gramar of the 
language dialects they use. One of the ways that 
a language generation system can account for 
this is through the use of gramar that defines 
all of the posible lexico-syntactic elements from 
which a text can be constructed and defines all 
their rules of composition, such as lexicalized 
Tre Adjoining Gramar (TAG). Without the 
ability to even forulate an ungramatical text, 
such a generator provides an account for human 
gramaticality based on its architecture rather 
than its programer. 
We propose a similar kind of acounting for 
the problem of expresibility: one based on 
architecture rather than acident. Expresibility, 
as defined by Meteer (192), is an isue for 
microplanners as they decide on which lexical 
and syntactic resources to employ. Not al of the 
options they might want to use are available in 
the language – they are not expresible. Consider 
the examples in Figure 1, adapted from Meteer 
1992 pg. 50. 
 
Expresion Construction (‘decide’) 
“quick decision” <result> + <quick> 
“decide quickly” <action> + <quick> 
“important decision” <result> + <important> 
* “decide importantly” <action> + <important> 
Figure 1: Constraints on expressibility: To say 
that there was a decision and it was important, 
you are forced to use the noun for because 
there is no adverbial form for important as 
there is for quick 
In this short paper, we discus our approach to 
expressibility. We describe in detail our novel 
method centered on how to use parser observa-
tions to guide generator decisions, and we pro-
vide a snapshot of the curent status of our 
system implementation. 
2. Related Work 
Natural language generation (NLG) systems 
must have some way of making sure that the 
mesages they build are actualy expresible. 
Template-based generators avoid problems with 
expressibility largely by anticipating all of the 
wording that will be neded and packaging it in 
chunks that are guaranteed to compose correctly. 
Becker (206), for example, does this via fuly 
lexicalized TAG tres.  
Among more general-purpose generators, one 
approach to expressibility is to lok ahead into 
the lexicon, avoiding contructins that are 
lexically incompatible. Look-ahead is expensive, 
however, and is only practical at smal abstrac-
tion distances such as Shaw’s re-writing sentence 
planner (198). 
Meter’s own aproach to expresibility 
started by interposing another level of represen-
tation betwen the microplaner and the surface 
realizer, an ‘abstract syntactic representation’ in 
the sense of RAGS (Cahil et al. 1999), that 
employed functional relationships (head, argu-
ment, matrix, adjunct) over semanticaly typed, 
  
lexicalized constiuents. This blocks *decide 
importantly beca ‘important’ only has a 
realization as a property and her composition 
rules prohibit using a property t mdify a 
action (‘decide’). Shifting the perspective from 
the action to its result allows the composition to 
go through. 
We are in sympathy with this aproach – a 
microplanner needs its own resentional 
level to serve as a scratch pad (if using a revi-
sion-based approach) or just as a scafold to hold 
intermediate results. However, Meter’s seman-
tic and lexical constraints do require operating 
with fine-grain details. We believe that we can 
work with larger chunks that have already ben 
veted for expresibility because we’ve observed 
someone use them, either in writing or spech.  
3. Method 
Our aproach is similar to that of Zhong & Stent 
(205) in that we use the analysis of a corpus as 
the basis for creating the resources for the reali-
zation component. Several diferences stand out. 
For one, we are working in specific domains 
rather than generic corpora like the WSJ. This 
enables the bigest diference: our analysi is 
performed by a completly acurate,
1
 domain-
specific NLU system (‘parser’)
2
 bsd o a 
semantic gramar (McDonald 1993). It is read-
ing for the benefit of a knowledge base, ading 
specific facts within instances of a highly struc-
tured, predefined prototypes. Such instances are 
used as the starting point for the geration 
proces. 
On the KB side, our present focus hapens to 
be on hurricanes and the proces they go through 
as they evolve. We have developed a semantic 
gramar for this domain, and it lets us analyze 
texts like these:
3
 
(1) “Later that day it made landfall near 
the Haitian town of Jacmel.” 
                                                             
1
 Parse acuracy and corect word sense interpretation is 
only possible if the semantic domain under analysis is 
restricted by topic and sublanguage. 
2
 Most systems refered to as “parsers” stop at a structural 
description. Ours stops at the level of a disambiguated 
conceptual model and is more integrated than most. 
3
 #1 and 2 are from the Wikipedia article on Huricane 
Gustav. #3 is from a New York Times article. 
(2) “… and remained at that intensity until 
landfall on the morning of September 1 
near Cocodrie, Louisiana.” 
(3) “By landfal on Monday morning …” 
Such texts tel us how people talk about huri-
canes, specifically her abut landfall events. 
They tel us what combinations of enties are 
reasonable to include within single clauses 
(intensity, time, location), and they tell us which 
particular ralizatis of the landfall concept 
have been used in which larger linguistic con-
texts. They also indicate what information can be 
left out under the discourse conditions defined by 
the larger texts they appear in.
4
 
As diferent texts are read, we acumulate dif-
ferent realization forms for the same content. In 
example #1, landfal is expresed via the idiom 
make landfal, the time is given in an inital 
adverbial, and the location as a trailing adjunct. 
In #2, the landfal stands by itself as the head of a 
time-adverbial and the time and location are 
adjuncts of of it. This set of alternative phras-
ings provides the raw material for the microplan-
ner to work with – a natural set of paraphrases. 
3.1 Derivation
Tres as templates 
As shown in Figure 3, to create resources for the 
microplanner, we start with the semantic analysis 
that the parser anchors to its referent when it 
instantiates the appropriate event type within the 
prototypical model of what hurricanes do, here a 
‘landfal event’, noting the specific time and 
location. Folowing Bateman (e.g. 2007) and 
Meter (192), we work with typed, structured 
objects organized under a foundational ontol-
ogy.
5
 Figure 2 shows the curent definition of the 
landfall clas in a local notation for OWL Full. 
(Class HurricaneLandfall 
  (restrict hurricane Hurricane) 
  (restrict intensity – Saffir-Simpson) 
  (restrict location – PhysEndurant) 
  (restrict time – Date&Time)) 
Figure 2. The Landfal clas 
 
                                                             
4
 For example, in #1 and #3 the precise date had been given 
already in earlier sentences. 
5
 An extension of Dolce (Gangemi et al. 2002). 
  
Figure 3. Overview 
The semantic analysis recursively maps con-
stituents’ referents to properties of a class in-
stance. Accompanying it is a syntactic analysis in 
the form of a TAG Derivation Tre
6
 (DT) where 
each of its nodes (initial tres, insertions or 
adjunctions) points both to its lexical anchor and 
its specific corespondence in the domain model. 
To create a reusable resource, we abstract 
away from the lexicalization in these DT/model-
anchored pairs, and replace it with the core-
sponding model classes as determined by the 
restrictions on the properties. For example, the 
day of the wek in #3, lexicaly given as Monday 
morning and then dereferenced to an object with 
the meaning ‘9/1/2008 before non’ is replaced 
in the resource with that object’s type. 
The result is a set of templates asociated with 
the combination of types that coresponds to the 
participants in its source text – the more com-
posed the type, the more insertions / adjunctions 
in the template derivation tre.  
3.2 Synchronous
TAGS 
This combination of derived tres and model-
levels clases and properties where the nodes of 
the two structures are linked is a synchronous 
TAG (ST). As observed by Shieber and Schabes 
(191) who introduced this notion, “[STs] make 
the fine-grained correspondences betwen ex-
presions of natural language and their meanings 
explicit by … node linking”. 
                                                             
6
 The primary analysis is phrase structure in a chart, but 
since every rule in the grammar coresponds to either a 
lexicalized insertion or adjunction, the pattern of rule 
application is read out as a TAG derivation tre. 
pp("by")
   insert: prep-comp("landfall")
   adjoin: pp ("on")
              insert: prep-comp("Monday")
(Individual HurricaneLandfall new-instance
 (hurricane #<>)
 (intensity #<>)
 (location #<>)
 (time #<DayOfWeek Monday>))
 
 
 
 
 
Figure 4. Synchronous TAG 
In particular, they observe that STs solve an 
otherwise arbitrary problem of ‘where does one 
start’ when faced with a bag of content to be 
realized as a text. Our STs identify natural 
‘slices’ of the content – those parts that have 
already been observed t have been realized 
together in a naturally occurring text. 
Because we have the luxury to be creating the 
knowledge base of our hurricane model by the 
accretion of relationships among individualy 
smal chunks of information (a triple store), we 
can take synchronous TAGS a step further and 
allow them to dictate the permited ways that 
information can be delimited within the KB for 
purposes of generation following the ideas in 
(Stone 202). 
If we can surmount the isues described be-
low, this stricture – that one can only selct for 
generation units of content of the types that have 
been observed to be used together (the model 
side of the STs) – is a clean architectural expla-
nation of how it is that the generator’s mesages 
are always expresible. 
4. State of Development 
We are at an early stage in our work. Everything 
we have described is implemented, but only on a 
  
‘thin slice’ to establish that our ideas were credi-
ble. There are many isues to work out as we 
‘bulk up’ the system and begin to actualy inte-
grate it in a in ‘tactical’ microplanner and begin 
to actually do the style of macro-planning (de-
termining the relevant portions of the domain 
model to use as content given the intent and 
affect) that our use of synchronous TAGS should 
allow. The most salient issues are how broadly 
we should generalize when we substitute domain 
types for lexicalizations in the templates, and 
what contextual information must be kept with 
the templates.  
The type generalizations ned to be broad 
enough to encompass as many substitutions as 
possible, while being strict enough to ensure that 
when the template is aplied to those objects the 
realizations available to them permit them to be 
expressed in that linguistic context.
7
 
The examples al have specific contexts in the 
sentences and recent discourse. Two of them (#2, 
#3) are using the landfal event as a time phrase. 
Can we move them and stil retain the natural-
nes of the original (e.g. from sentence initial to 
sentence final), or does this sort of information 
need to be encoded? 
Another isue is how to evaluate a system like 
this. Given the acuracy of the analysis, recreat-
ing the source text is trivial, so comparison to the 
source of the resources as a gold standard is 
meaningles. Some alternative must be found. 
While we work out these isues, we are ex-
tending the NLU domain model and gramar to 
cover more cases and thence create more syn-
chronized TAG templates. We then manually 
identify alternative domain content to ap hly to 
them to in order to explore the space of realiza-
tions and identify unforesen interactions. 
Our short-term goals are to vastly increase the 
gramar coverage for our motivating examples 
and to hand over all microplanning decisions to 
the system itself. Long-term goals include broad-
ening the coverage further stil, to as open a 
domain as is feasible, as wel as testing diferent 
macroplanners and applications with which to 
drive the entire proces. Among several possi-
bilities are automatic mergd-and-modified 
sumarization and a query-based discourse 
system. 
                                                             
7
 In our example, substituting diferent days and times is 
obvious (by landfall on the afternoon of August 22), but as 
we move away from that precise set of types (general-time-
of-day + date) we se that what had ben lexically fixed in 
the derivation tree (by landfall on) has to shift: … at 2:0 on 
August 2. 
5. Discusion 
Because the phrasal paterns observed in the 
corpus act as templates guiding the generation 
proces, and as the underlying NLU system and 
generator (McDonald 193, Meter et al. 1987) 
are mature and grounded in linguistic principles, 
our system combines template-based and theory-
based approaches. 
Van Deemter et al. (205) outlined thre crite-
ria for judging template-driven applications 
against "standard" (non-template) NLG systems. 
(1) Maintainability is adresed by the fact that 
our templates aren't hand-made. To extend the 
set of available realization forms we expose the 
NLU system to more text. The subject domain 
has to be one that has already been modeled, but 
we are operating from the premise that a NLG 
component would only bother to speak about 
things that the system as a whole understands. 
(2) Output quality and variability are determined 
by the corpus; using corpora containing high 
quality and varied constructions wil enable 
similar output from the generator. (3) Most 
crucially, our parser and generator components 
are linguistically wel-founded. Composition into 
our ‘templates’ is smoothly acommodated 
(extra modifiers, shifts in tense or aspect, apli-
cation of transformations over the DT to form 
questions, relative clauses, dropped constituents 
under conjunction). The fully-articulated syntac-
tic structure can be automatically anotated to 
facilitate prosody or to take information structure 
markup on the DT. 
The closest system to ours may be Marciniak 
& Strube (205) who also use an anotated 
corpus as a knowledge source for generation, 
geting their annotations via “a simple rule-based 
system tuned to the given types of text”. As far 
as we can tell, they are more concerned with 
discourse while we focus on the integration with 
the underlying knowledge base and how that KB 
is extended over time. 
Like them, we believe that one of the most 
promising aspects of this work going forward is 
that the use of a parser provides us with “self-
labeling data” to draw on for statistical analysis. 
Such training material would reduce the efort 
required to adapt a generator to a new domain, 
while simultaneously improving its output. 
 
Acknowledgments 
This work was suported in part by the BBN 
POIROT project: DARPA IPTO contract FA865 
0-06-C-7606. 
  
References 
John Bateman, Thora Tenbrink, and Scott Farar. 
2007. The Role of Conceptual and Linguistic On-
tologies in Interpreting Spatial Discourse. Dis-
course Processes, 44(3):175–213. 
Tilman Becker. 206. Natural Language Generation 
with Fuly Specified Templates. In W. Wahlster 
(Ed.), SmartKom: Foundations of Multimodal Dia-
log Systems, 401–410. Springer, Berlin Heidelberg. 
Lyne Cahil, Christy Doran, Roger Evans, Chris 
Melish, Daniel Paiva, Mike Reape, Donia Scot, & 
Neil Tiper. 199. Towards a Reference Architec-
ture for Natural Language Generation Systems, 
The RAGS project. ITRI technical report number 
ITRI-99-14, University of Brighton, March. 
Aldo Gangemi, Nicola Guarino, Claudio Masolo, 
Alesandro Oltramari, & Luc Schneider. 202. 
Swetening Ontologies with DOLCE. In Proced-
ings of the 13th International Cofern on 
Knowledge Acquisition, Modeling and Manage-
ment (EKAW), pages 16–181, Sigüenza, Spain, 
October 1–4. 
Tomasz Marciniak & Michael Strube. 205. Using an 
Annotated Corpus As a Knowledge Source For 
Language Generation. In Procedings of the Cor-
pus Linguistics 2005 Workshop on Using Corpora 
for Natural Language Generation (UCNLG), pages 
19–24, Birmingham, UK, July 14. 
David McDonald. 203. The Interplay of Syntactic 
and Semantic Node Labels in Partial Parsing, in the 
proceedings of the Third International Workshop 
on Parsing Technologies, August 10-13, 1993 Til-
burg, The Netherlands, pp. 171-186; revised ver-
sion in Bunt and Tomita (eds), Recent Advances in 
Parsing Technology, Kluwer Academic Publishers, 
pgs. 295-323. 
Marie W. Meteer. 192. Expresibility and the Prob-
lem of Efficient Text Planing. Pinter, London.  
Marie Meter, David McDonald, Scot Anderson, 
David Forster, Linda Gay, Alison Huettner & 
Penelope Sibun. 1987. Mumble-86: Design and 
Implementation, TR #87-87 Dept. Computer & 
Information Science, UMas., September 1987, 
174 pgs. 
James Shaw. 198. Clause Agregation Using Lin-
guistic Knowledge. In Procedings of the 9th In-
ternational Workshop on Natural Language Gen-
eration, pages 138–147, Niagara-on-the-Lake, On-
tario, August 5–7. 
Stuart Shieber & Yves Schabes. 191. Generation and 
synchronous tre-adjoining grammar. Computa-
tional Intelligence, 7(4):220–228. 
Matthew Stone. 203. Specifying Generation of 
Refering Expressions by Example. In Procedings 
of the AAI Spring Symposium on Natural Lan-
guage Generation in Spoken and Writen Dialogue, 
pages 133–140, Stanford, March. 
Kees van Deemter, Emiel Krahmer, & Mariët Theune. 
2005. Real versus Template-Based Natural Lan-
guage Generation: A False Opposition? Computa-
tional Linguistics, 31(1):15–24. 
Huvava Zhong & Amada Stent. 205. Building 
Surface Realizers Automatically From Corpora. In 
Procedings of the Corpus Linguistics 205 Work-
shop on Using Corpora for Natural Language 
Generation (UCNLG), pages 49–54, Birmingham, 
UK, July 14. 

