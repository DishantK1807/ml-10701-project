<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
<author>W Gale</author>
</authors>
<title>Inverse document frequency (idf): A measure of deviations from poisson</title>
<date>1995</date>
<booktitle>In Proc. Third Workshop on Very Large Corpora</booktitle>
<contexts>
<context>IDF, cf. equation 1. CCBYC1BWBY where C1BWBY BP D0D3CV BE C6 CSCU (1) Church argued that Poisson distributions or mixtures of Poisson distributions of words in texts are quite useful statistics (cf. (Church and Gale, 1995) and equation 2). APB4CZBNAIB5 BP CT A0AI AI CZ CZAX (2) While the distribution of e.g. function words like of, the, it is close to the expected distribution under the Poisson distribution model, goo</context>
</contexts>
<marker>Church, Gale, 1995</marker>
<rawString>Kenneth W. Church and W. Gale. 1995. Inverse document frequency (idf): A measure of deviations from poisson. In Proc. Third Workshop on Very Large Corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
<author>W Gale</author>
</authors>
<title>Poisson mixtures</title>
<date>1995</date>
<journal>Natural Language Engineering</journal>
<volume>1</volume>
<contexts>
<context>IDF, cf. equation 1. CCBYC1BWBY where C1BWBY BP D0D3CV BE C6 CSCU (1) Church argued that Poisson distributions or mixtures of Poisson distributions of words in texts are quite useful statistics (cf. (Church and Gale, 1995) and equation 2). APB4CZBNAIB5 BP CT A0AI AI CZ CZAX (2) While the distribution of e.g. function words like of, the, it is close to the expected distribution under the Poisson distribution model, goo</context>
</contexts>
<marker>Church, Gale, 1995</marker>
<rawString>K. Church and W. Gale. 1995a. Poisson mixtures. Natural Language Engineering, 1(2):163–190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Frank</author>
<author>G Paynter</author>
<author>I Witten</author>
<author>C Gutwin</author>
<author>C NevillManning</author>
</authors>
<title>Domain-specific Keyphrase Extraction</title>
<date>1999</date>
<booktitle>In Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence</booktitle>
<pages>668--673</pages>
<contexts>
<context>to detect salient words which are good keyword candidates. It should be noticed, however, that keyword and keyphrase extractors have been provided mainly for English, cf. (Sclano and Velardi, 2007), (Frank et al., 1999), (Wan et al., 2007),(Zha, 2002), (Witten et al., 1999), (Turney, 2000), (Mihalcea and Tarau, 2004), (Hulth, 2003). One innovative aspect of our project is that we provide this functionality for all </context>
</contexts>
<marker>Frank, Paynter, Witten, Gutwin, NevillManning, 1999</marker>
<rawString>E. Frank, G. Paynter, I. Witten, C. Gutwin, and C. NevillManning. 1999. Domain-specific Keyphrase Extraction. In Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence, pages 668–673.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kilem Gwet</author>
</authors>
<title>Handbook of Inter-Rater Reliability: How to Estimate the Level of Agreement Between Two or Multiple Raters</title>
<date>2001</date>
<contexts>
<context>the various languages To measure pairwise inter-annotator agreement, both between human annotators and between KWE and human annotators, we used the so-called AC1 measure proposed by Kilem Gwet, cf. (Gwet, 2001) and elaborated by Debra Haley, cf. (Haley, 2007). Gwet and Haley investigate Cohen’s kappa for inter-annotator agreement, which is normally applied to such tasks, and argue convincingly that under c</context>
</contexts>
<marker>Gwet, 2001</marker>
<rawString>Kilem Gwet. 2001. Handbook of Inter-Rater Reliability: How to Estimate the Level of Agreement Between Two or Multiple Raters.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Debra Trusso Haley</author>
</authors>
<title>Using a New Inter-rater Reliability Statistics</title>
<date>2007</date>
<tech>Ph.D. thesis</tech>
<institution>The Open University, Milton Keynes</institution>
<contexts>
<context>annotator agreement, both between human annotators and between KWE and human annotators, we used the so-called AC1 measure proposed by Kilem Gwet, cf. (Gwet, 2001) and elaborated by Debra Haley, cf. (Haley, 2007). Gwet and Haley investigate Cohen’s kappa for inter-annotator agreement, which is normally applied to such tasks, and argue convincingly that under certain conditions this formula leads to unreliabl</context>
</contexts>
<marker>Haley, 2007</marker>
<rawString>Debra Trusso Haley. 2007. Using a New Inter-rater Reliability Statistics. Ph.D. thesis, The Open University, Milton Keynes.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Hulth</author>
</authors>
<title>Improved automatic keyword extraction given more linguistic knowledge</title>
<date>2003</date>
<booktitle>In Proceedings of EMNLP2003</booktitle>
<contexts>
<context>actors have been provided mainly for English, cf. (Sclano and Velardi, 2007), (Frank et al., 1999), (Wan et al., 2007),(Zha, 2002), (Witten et al., 1999), (Turney, 2000), (Mihalcea and Tarau, 2004), (Hulth, 2003). One innovative aspect of our project is that we provide this functionality for all the eight languages represented in our project, that is Bulgarian, Czech, Dutch, English, German, Polish, Portugue</context>
</contexts>
<marker>Hulth, 2003</marker>
<rawString>A. Hulth. 2003. Improved automatic keyword extraction given more linguistic knowledge. In Proceedings of EMNLP2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Jones</author>
<author>G W Paynter</author>
</authors>
<title>An Evaluation of Document Keyphrase Sets</title>
<date>2006</date>
<journal>Journal of Digital Information</journal>
<volume>4</volume>
<contexts>
<context> in an eLearning context. Another salient feature is that keyphrases are extracted in addition to keywords. This responds to findings that users frequently use keyphrases to describe a document, cf. (Jones and Paynter, 2006). More generally, the main objective of the LT4eL project is to show that the integration of Language Technology based functionalities and Semantic Web techniques will enhance the management, distrib</context>
</contexts>
<marker>Jones, Paynter, 2006</marker>
<rawString>S. Jones and G. W. Paynter. 2006. An Evaluation of Document Keyphrase Sets. Journal of Digital Information, 4(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Lemnitzer</author>
<author>C Vertan</author>
<author>A Killing</author>
<author>K Simov</author>
<author>D Evans</author>
<author>D Cristea</author>
<author>P Monachesi</author>
</authors>
<title>Improving the search for learning objects with keywords and ontologies</title>
<date>2007</date>
<booktitle>In Proceedings of the ECTEL</booktitle>
<publisher>Springer Verlag</publisher>
<contexts>
<context>ages such as Polish, a sequence of base forms looks quite unnatural therefore we have decided that the selected multi-word keywords are represented by their most frequent attested forms. We refer to (Lemnitzer et al., 2007) for additional details on the use of the keyword extractor within the LT4eL project. 3. Evaluation of the keyword extractor The best way to validate the keyword extractor might be in the context of </context>
<context>agement System via Web Services. Figure 2 shows the major components of the integration setup. The language technology server on the left provides the keyword extractor and other NLP components (cf. (Lemnitzer et al., 2007) for more details). The functionalities can be accessed directly on the webserver for test purposes or they can be used by the learning management system through the web service interface. Figure 3 F</context>
</contexts>
<marker>Lemnitzer, Vertan, Killing, Simov, Evans, Cristea, Monachesi, 2007</marker>
<rawString>L. Lemnitzer, C. Vertan, A. Killing, K. Simov, D. Evans, D. Cristea, and P. Monachesi. 2007. Improving the search for learning objects with keywords and ontologies. In Proceedings of the ECTEL 2007 conference. Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>P Tarau</author>
</authors>
<title>TextRank: Bringing Order into Texts</title>
<date>2004</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2004</booktitle>
<location>Barcelona, Spain. Paola</location>
<contexts>
<context>t keyword and keyphrase extractors have been provided mainly for English, cf. (Sclano and Velardi, 2007), (Frank et al., 1999), (Wan et al., 2007),(Zha, 2002), (Witten et al., 1999), (Turney, 2000), (Mihalcea and Tarau, 2004), (Hulth, 2003). One innovative aspect of our project is that we provide this functionality for all the eight languages represented in our project, that is Bulgarian, Czech, Dutch, English, German, P</context>
<context>ies for building an automatic index for a document collection and have been used to classify texts. Keyword extraction has also been considered in combination with summarization ((Wan et al., 2007), (Mihalcea and Tarau, 2004), (Zha, 2002)). An additional use is to identify automatically relevant terms that can be employed in the construction of domain-specific dictionaries or more recently of domain ontologies ((Sclano a</context>
<context>sed on a frequency criterion to select the relevant keywords in a document which has been complemented with a linguistic processing step. This method was found to lead to poor results, as claimed in (Mihalcea and Tarau, 2004) and consequently alternative methods were explored in the literature. They are mainly based on supervised learning methods, where a system is trained to recognize keywords in a text, based on lexica</context>
</contexts>
<marker>Mihalcea, Tarau, 2004</marker>
<rawString>R. Mihalcea and P. Tarau. 2004. TextRank: Bringing Order into Texts. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2004), Barcelona, Spain. Paola Monachesi, Lothar Lemnitzer, and Kiril Simov.</rawString>
</citation>
<citation valid="true">
<title>Language Technology for eLearning</title>
<date>2006</date>
<booktitle>In Proceedings of EC-TEL</booktitle>
<publisher>Springer</publisher>
<location>Crete</location>
<marker>2006</marker>
<rawString>2006. Language Technology for eLearning. In Proceedings of EC-TEL, Crete 2006. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Sclano</author>
<author>P Velardi</author>
</authors>
<title>TermExtractor: a Web Application to Learn the Shared Terminology of Emergent Web Communities</title>
<date>2007</date>
<booktitle>In Proc. of the 3rd International Conference on Interoperability for Enterprise Software and Applications I-ESA 2007</booktitle>
<location>Funchal, Madeira Island, Portugali</location>
<contexts>
<context> with linguistic processing to detect salient words which are good keyword candidates. It should be noticed, however, that keyword and keyphrase extractors have been provided mainly for English, cf. (Sclano and Velardi, 2007), (Frank et al., 1999), (Wan et al., 2007),(Zha, 2002), (Witten et al., 1999), (Turney, 2000), (Mihalcea and Tarau, 2004), (Hulth, 2003). One innovative aspect of our project is that we provide this </context>
<context>au, 2004), (Zha, 2002)). An additional use is to identify automatically relevant terms that can be employed in the construction of domain-specific dictionaries or more recently of domain ontologies ((Sclano and Velardi, 2007)) . In the LT4eL project, we have adapted current techniques for term extraction in order to develop a keyword extractor which is employed for the semi-automatic metadata annotation of the learning o</context>
<context> are low. We ran a third experiment to test this assumption. 3.2.1. Assessing the adequacy of KWE-selected keywords An evaluation which is fairly standard and which is e.g. performed by Velardi (cf. (Sclano and Velardi, 2007)) on a similar task is to expose user to a) a given document and b) a set of automatically extracted keywords and let them 5For Bulgarian, the collected data were too sparse to yield adequate results</context>
<context>rage twice as probable to be marked as keyword as those words which do not bear these features. Therefore, we will use layout information as additional filter in proposing salient keywords (cf. also (Sclano and Velardi, 2007)). Currently, a userand scenario-oriented evaluation is being performed in order to evaluate the influence the impact of the keyword extractor and its results on the learning process. The scenarios</context>
</contexts>
<marker>Sclano, Velardi, 2007</marker>
<rawString>F. Sclano and P. Velardi. 2007. TermExtractor: a Web Application to Learn the Shared Terminology of Emergent Web Communities. In Proc. of the 3rd International Conference on Interoperability for Enterprise Software and Applications I-ESA 2007, Funchal, Madeira Island, Portugali.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P D Turney</author>
</authors>
<title>Learning algorithms for keyphrase extraction. Information Retrieval</title>
<date>2000</date>
<pages>2--303</pages>
<contexts>
<context>ed, however, that keyword and keyphrase extractors have been provided mainly for English, cf. (Sclano and Velardi, 2007), (Frank et al., 1999), (Wan et al., 2007),(Zha, 2002), (Witten et al., 1999), (Turney, 2000), (Mihalcea and Tarau, 2004), (Hulth, 2003). One innovative aspect of our project is that we provide this functionality for all the eight languages represented in our project, that is Bulgarian, Czec</context>
</contexts>
<marker>Turney, 2000</marker>
<rawString>P. D Turney. 2000. Learning algorithms for keyphrase extraction. Information Retrieval, 2:303–336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Wan</author>
<author>J Yang</author>
<author>J Xiao</author>
</authors>
<title>Towards an Iterative Reinforcement Approach for Simultaneous Document Summarization and Keyword Extraction</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics</booktitle>
<pages>552--559</pages>
<location>Prague</location>
<contexts>
<context>s which are good keyword candidates. It should be noticed, however, that keyword and keyphrase extractors have been provided mainly for English, cf. (Sclano and Velardi, 2007), (Frank et al., 1999), (Wan et al., 2007),(Zha, 2002), (Witten et al., 1999), (Turney, 2000), (Mihalcea and Tarau, 2004), (Hulth, 2003). One innovative aspect of our project is that we provide this functionality for all the eight languages </context>
<context>ify appropriate entries for building an automatic index for a document collection and have been used to classify texts. Keyword extraction has also been considered in combination with summarization ((Wan et al., 2007), (Mihalcea and Tarau, 2004), (Zha, 2002)). An additional use is to identify automatically relevant terms that can be employed in the construction of domain-specific dictionaries or more recently of </context>
</contexts>
<marker>Wan, Yang, Xiao, 2007</marker>
<rawString>X. Wan, J. Yang, and J. Xiao. 2007. Towards an Iterative Reinforcement Approach for Simultaneous Document Summarization and Keyword Extraction. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 552–559, Prague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I H Witten</author>
<author>G W Paynter</author>
<author>E Frank</author>
<author>C Gutwin</author>
<author>C G Nevill-Manning</author>
</authors>
<title>KEA: Practical automatic keyphrase extraction</title>
<date>1999</date>
<booktitle>In Proceedings of Digital Libraries 99 (DL’99</booktitle>
<pages>254--256</pages>
<contexts>
<context>tes. It should be noticed, however, that keyword and keyphrase extractors have been provided mainly for English, cf. (Sclano and Velardi, 2007), (Frank et al., 1999), (Wan et al., 2007),(Zha, 2002), (Witten et al., 1999), (Turney, 2000), (Mihalcea and Tarau, 2004), (Hulth, 2003). One innovative aspect of our project is that we provide this functionality for all the eight languages represented in our project, that is</context>
</contexts>
<marker>Witten, Paynter, Frank, Gutwin, Nevill-Manning, 1999</marker>
<rawString>I.H. Witten, G. W. Paynter, E. Frank, C. Gutwin, and C. G. Nevill-Manning. 1999. KEA: Practical automatic keyphrase extraction. In Proceedings of Digital Libraries 99 (DL’99), pages 254–256.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Yamamoto</author>
<author>Kenneth W Church</author>
</authors>
<title>Using suffix arrays to compute term frequency and document frequency for all substrings in a corpus</title>
<date>2001</date>
<journal>Computational Linguistics</journal>
<volume>27</volume>
<contexts>
<context> Documents: they represent the documents which constitute the corpus including their names and domains. Potentially interesting sequences of words are extracted using the suffix array data structure (Yamamoto and Church, 2001) but a condition is that they must appear at least twice in the document. Afterwards, filtering occurs on the basis of language specific information and sequences longer than a certain threshold are </context>
<context>tems and several tests have been carried out to detect the most appropriate length for multiword keywords and possible variation due to language. We followed the approach of Yamamoto and Church, cf. (Yamamoto and Church, 2001), to effectively identify and extract recurrent multi-word key phrases up to a predefined length. Additionally, we used linguistic information to further restrict this set of multiword key phrases, e</context>
</contexts>
<marker>Yamamoto, Church, 2001</marker>
<rawString>M. Yamamoto and Kenneth W. Church. 2001. Using suffix arrays to compute term frequency and document frequency for all substrings in a corpus. Computational Linguistics, 27(1):1–30.</rawString>
</citation>
</citationList>
</algorithm>

