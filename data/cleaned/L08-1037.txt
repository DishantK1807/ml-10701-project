<algorithm name="ParsCit" version="080917">
<citationList>
<citation valid="true">
<authors>
<author>D W Aha</author>
<author>D Kibler</author>
<author>M Albert</author>
</authors>
<title>Instance-based learning algorithms</title>
<date>1991</date>
<booktitle>Machine Learning</booktitle>
<pages>6--37</pages>
<contexts>
<context>http://lands.let.ru.nl/cgn/. We used the TIMBL (Daelemans and van den Bosch, 2005) software package that implements a version of the k nearest neighbour algorithm. It is an implementation of the IB1 (Aha et al., 1991) algorithm, with some additional features (such as different metrics for the calculation of the distances between two items). An MBL system consists of two components: a memory-based learning compone</context>
</contexts>
<marker>Aha, Kibler, Albert, 1991</marker>
<rawString>D.W. Aha, D. Kibler, and M. Albert. 1991. Instance-based learning algorithms. Machine Learning, 6:37–66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Ananiadou</author>
<author>J McNaught</author>
</authors>
<title>Text mining for biology and biomedicine</title>
<date>2006</date>
<publisher>Artech House, Inc</publisher>
<contexts>
<context>oth linguistic and statistical information have also emerged, e.g. (Maynard and Ananiadou, 1999), (Frantzi and Ananiadou, 1999). For an overview of the field, we refer to (Hirshman et al., 2002) and (Ananiadou and McNaught, 2006). Although most term extraction research in the biomedical domain is focused on recognizing gene and protein names, etc., the techniques developed in this domain are also useful for the specific prob</context>
</contexts>
<marker>Ananiadou, McNaught, 2006</marker>
<rawString>S. Ananiadou and J. McNaught. 2006. Text mining for biology and biomedicine. Artech House, Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Ananiadou</author>
</authors>
<title>A methodology for automatic term recognition</title>
<date>1994</date>
<booktitle>In Proceedings of the 15th conference on computational linguistics</booktitle>
<pages>1034--1038</pages>
<contexts>
<context> bases, etc. In research on automatic term extraction, two different directions mainly have been taken. On the one hand, the linguistic-based or rule-based approaches, e.g. (Dagan and Church, 1994), (Ananiadou, 1994), (Fukuda et al., 1998) make use of hand-coded rules and look for specific (mostly language-specific) linguistic structures that match a number of predefined syntactic patterns. On the other hand, th</context>
</contexts>
<marker>Ananiadou, 1994</marker>
<rawString>S. Ananiadou. 1994. A methodology for automatic term recognition. In Proceedings of the 15th conference on computational linguistics, pages 1034–1038.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Andrade</author>
<author>A Valencia</author>
</authors>
<title>Automatic extraction of keywords from scientific text: Application to the knowledge domain of protein families</title>
<date>1998</date>
<journal>BioInformatics</journal>
<volume>4</volume>
<contexts>
<context>pecific (mostly language-specific) linguistic structures that match a number of predefined syntactic patterns. On the other hand, the statistical corpus-based approaches, e.g (Pantel and Lin, 2001), (Andrade and Valencia, 1998), extract terms using different types of metrics tomeasure theinformationbetween words. Along thesame corpus-based line, different machine learning approaches have been proposed using learning techni</context>
</contexts>
<marker>Andrade, Valencia, 1998</marker>
<rawString>M. Andrade and A. Valencia. 1998. Automatic extraction of keywords from scientific text: Application to the knowledge domain of protein families. BioInformatics, 4(7).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Aubin</author>
<author>T Hamon</author>
</authors>
<title>Improving term extraction with terminological resources</title>
<date>2006</date>
<booktitle>In Advances in Natural Language Processing 5th International Conference on NLP, FinTAL</booktitle>
<contexts>
<context>res for English, but suffer from a low coverage, i.e. 95% precision versus 24% recall. These results are in line with earlier results on the low coverage of lexicon-based approaches (see for example (Aubin and Hamon, 2006)). For Dutch, however, these scores are much more balanced: 65% precision versus 63% recall, as also shown earlier in Figure 1. Finally, we can observe a highly beneficialeffectonprecisionofthemorpho</context>
</contexts>
<marker>Aubin, Hamon, 2006</marker>
<rawString>S. Aubin and T. Hamon. 2006. Improving term extraction with terminological resources. In Advances in Natural Language Processing 5th International Conference on NLP, FinTAL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G L Banay</author>
</authors>
<title>An introduction to medical terminology i. greek and latin derivations</title>
<date>1948</date>
<journal>Bulletin of the Medical Library Association</journal>
<volume>1</volume>
<contexts>
<context>ms to the general audience is low. Therefore, we incorporated Latin and Greek affixes as one of the criteria to detect scientific medical terms. A list of prefixes, suffixes and confixes compiled by (Banay, 1948) was completed during an experimental analysis of MeSH terms (Vanopstal and Van Wiele, 2007). For English, this list contains 745 prefixes and 17,520 terms. The corresponding figures for Dutch are 68</context>
</contexts>
<marker>Banay, 1948</marker>
<rawString>G.L. Banay. 1948. An introduction to medical terminology i. greek and latin derivations. Bulletin of the Medical Library Association, 1(36):1–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Berger</author>
<author>R Caruana</author>
<author>D Cohn</author>
<author>D Freitag</author>
<author>V Mittal</author>
</authors>
<title>Bridging the lexical chasm: Statistical approaches to answer finding</title>
<date>2000</date>
<booktitle>In Proc. Int. Conf. Research and Development in Information Retrieval</booktitle>
<pages>192--199</pages>
<contexts>
<context>idual document d ∈ D, Wd = fw,d ∗log(|D|/fw,D) (1) where fw,d equals the number of times w appears in d, |D| is the size of the corpus and fw,D equals the number of documents in which w appears in D (Berger et al., 2000). In order to determine the TF-IDF threshold for considering a term as being scientific, we performed 20-fold crossvalidation on the labeled EPAR corpus. These results are shown in Figure 1. Figure 1</context>
</contexts>
<marker>Berger, Caruana, Cohn, Freitag, Mittal, 2000</marker>
<rawString>A. Berger, R. Caruana, D. Cohn, D. Freitag, and V. Mittal. 2000. Bridging the lexical chasm: Statistical approaches to answer finding. In Proc. Int. Conf. Research and Development in Information Retrieval, pages 192–199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
<author>P Hanks</author>
</authors>
<title>Word association norms, mutual information, and lexicography</title>
<date>1990</date>
<journal>Computational Linguistics</journal>
<volume>16</volume>
<contexts>
<context>ng, 1993) and (Rayson and Garside, 2000), have explored the use of the Log-likelihood measure to discover keywords which differentiate between corpora. Next to that, techniques of Mutual Information (Church and Hanks, 1990) and hypergeometric distribution ( (Lafon, 1980), (Lebart and Salem, 1994)) have been explored for finding lexicon-specific terms. We considered both TF-IDF and Log-likelihood to expand our feature s</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>K. Church and P. Hanks. 1990. Word association norms, mutual information, and lexicography. Computational Linguistics, 16(1):22–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Collier</author>
<author>C Nobata</author>
<author>J Tsujii</author>
</authors>
<title>Extracting the names of genes and gene products with a hidden markov model</title>
<date>2000</date>
<booktitle>In Proceedings of COLING-2000</booktitle>
<pages>201--207</pages>
<contexts>
<context>pes of metrics tomeasure theinformationbetween words. Along thesame corpus-based line, different machine learning approaches have been proposed using learning techniques such as Hidden Markov Models (Collier et al., 2000) or Support Vector Machines (Kazama et al., 2002), and combination methods such as boosting (Vivaldi et al., 2001), etc. on feature sets encoding lexical, POS, orthographic, and other possibly releva</context>
</contexts>
<marker>Collier, Nobata, Tsujii, 2000</marker>
<rawString>N. Collier, C. Nobata, and J. Tsujii. 2000. Extracting the names of genes and gene products with a hidden markov model. In Proceedings of COLING-2000, pages 201– 207.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Daelemans</author>
<author>A van den Bosch</author>
</authors>
<title>Memorybased Language Processing</title>
<date>2005</date>
<publisher>Cambridge University Press</publisher>
<marker>Daelemans, van den Bosch, 2005</marker>
<rawString>W. Daelemans and A. van den Bosch. 2005. Memorybased Language Processing. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Daelemans</author>
<author>J Zavrel</author>
<author>A van den Bosch</author>
<author>K van der Sloot</author>
</authors>
<title>Memory based tagger, version 2.0, reference guide</title>
<date>2003</date>
<tech>Technical Report ILK Technical Report ILK 03-13</tech>
<institution>Tilburg University</institution>
<marker>Daelemans, Zavrel, van den Bosch, van der Sloot, 2003</marker>
<rawString>W. Daelemans, J. Zavrel, A. van den Bosch, and K. van der Sloot. 2003. Memory based tagger, version 2.0, reference guide. Technical Report ILK Technical Report ILK 03-13, Tilburg University.</rawString>
</citation>
</citationList>
</algorithm>

