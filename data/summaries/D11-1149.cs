K. Papineni, S. Roukos, T. Ward, and W. J. Zhu. 2002.
P02-1040
vised Berkeley aligner (Liang et al., 2006) with de-
N06-1014
Kneser-Ney smoothing (Chen and Goodman, 1996)
P96-1041
toolkit (Koehn et al., 2007)6, and a hierarchical
P07-2045
(2007a) and Lu et al. (2009). Similar to the tech-
D09-1042
J. Wang. 1980. On computational sentence generation
C80-1061
H. Shemtov. 1996. Generation of paraphrases from am-
C96-2155
L. Zettlemoyer and M. Collins. 2009. Learning context-
P09-1110
error rate training (MERT) (Och, 2003) algorithm to
P03-1021
be made (Lu et al., 2008); and 3) meaning repre-
D08-1082
P. Koehn. 2004. Statistical significance tests for machine
W04-3250
Of particular interest is our prior work Lu et al.(2008), in which we presented a joint generative pro-
D08-1082
In Lu et al. (2008), a generative model was pre-
D08-1082
S. Vogel, H. Ney, and C. Tillmann. 1996. HMM-based
C96-2141
previously used in Chiang (2007) for hierarchical
J07-2003
2007; 2009), Kate and Mooney (2006), Wong and
P06-1115
F. J. Och and H. Ney. 2004. The alignment template
J04-4002
rules written in Prolog. Shemtov (1996) presented a
C96-2155
Mooney (2007b), Lu et al. (2008), Ge and Mooney
D08-1082
2003; Chiang, 2005; Galley and Manning, 2010)
N10-1140 P05-1033
M. Galley and C. D. Manning. 2010. Accurate
N10-1140
W. Lu, H. T. Ng, W. S. Lee, and L. Zettlemoyer. 2008.
D08-1082
R. Ge and R. J. Mooney. 2009. Learning a compositional
P09-1069
R. J. Kate and R. J. Mooney. 2006. Using string-kernels
P06-1115
Lu et al. (2009) 62.20 6.9845 57.33 6.7459
D09-1042
(Brown et al., 1993)8, and run theλ-hybrid tree gen-
J93-2003
of Koehn (2004). We obtain p < 0.01 for all cases,
W04-3250
W. Lu, H. T. Ng, and W. S. Lee. 2009. Natural lan-
D09-1042
Following the work of Lu et al. (2008), the gener-
D08-1082
P. Koehn, F. J. Och, and D. Marcu. 2003. Statistical
N03-1017 P03-1021
IBM BLEU score (Papineni et al., 2002) (4-gram
P02-1040
tem WASP−1++ (Wong and Mooney, 2007a) sig-
N07-1022 P07-1121
Y. W. Wong and R. J. Mooney. 2007b. Learning syn-
N07-1022 P07-1121
2005; Chiang, 2007). The state-of-the-art unsuper-
J07-2003
L. Zettlemoyer and M. Collins. 2007. Online learning of
D07-1071
Inspired by the work of Chiang (2007), we in-
J07-2003
as that of Wong and Mooney (2007a) and Lu et
N07-1022 P07-1121
Y. W. Wong and R. J. Mooney. 2006. Learning for se-
N06-1056
tences. Lu et al. (2009) presented a language gener-
D09-1042
of rule-based methods (Wang, 1980; Shieber et al.,
C80-1061
resentation formalisms. Wong and Mooney (2007a)
N07-1022 P07-1121
and Shieber et al. (1990) made use of rule-based
J90-1004
Following the work of Chiang (2007), we assign
J07-2003
into meaning representations (Lu et al., 2008).
D08-1082
cedure as conducted in Galley and Manning (2010),
N10-1140
Lu et al. (2009) is also limited to handling tree-
D09-1042
probabilistic approaches. Wang (1980) presented an
C80-1061
and Ney, 2004; Chiang, 2005), we use the minimum
P05-1033
Chiang (2007) is not applicable to this work since
J07-2003
al., 1996; Liang et al., 2006). However, unlike texts,
N06-1014
P. Liang, B. Taskar, and D. Klein. 2006. Alignment by
N06-1014
simple counting, as was done in Lu et al. (2008).
D08-1082
(Koehn et al., 2003; Chiang, 2007), are rule-specific
J07-2003 N03-1017 P07-2045
of Chiang (2007) is used. In order to accommodate
J07-2003
F. J. Och. 2003. Minimum error rate training in statistical
P03-1021
in Chiang (2007), which makes the grammar a bi-
J07-2003
Y. W. Wong and R. J. Mooney. 2007a. Generation by in-
N07-1022 P07-1121
representations (Wong and Mooney, 2007a; Lu et
N07-1022 P07-1121
S. F. Chen and J. Goodman. 1996. An empirical study of
P96-1041
earlier approaches such as the work of Wang (1980)
C80-1061
Collins, 2005; Wong and Mooney, 2006; Zettle-
N06-1056
D. Chiang. 2005. A hierarchical phrase-based model for
P05-1033
ter performance as compared to Lu et al. (2009).
D09-1042
the model of Lu et al. (2008):
D08-1082
that the algorithm of Lu et al. (2009) is capable
D09-1042
D. Chiang. 2007. Hierarchical phrase-based translation.
J07-2003
