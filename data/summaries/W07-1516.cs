Brants, T., (2000).
A00-1031
They surpassed their earlier work in 2003 with a “cyclic dependency network tagger”, achieving 97.2%/89.05% (seen/unseen) (Toutanova et al., 2003).
N03-1033
Several efforts, notably the Alembic workbench (Day et al., 1997) and similar tools, have provided interfaces to aid annotators in the process.
A97-1051
Day, D., et al.(1997). “Mixed-Initiative Development of Language Processing Systems.” ANLP, Washington, D.C.
A97-1051
Very recent work by Mann and McCallum (2007) proposes an approach in which exact sequence entropy can be calculated efficiently.
N07-2028
Following Toutanova and Manning (2000) approximately, more information is defined for words that are considered rare (which we define here as words that occur fewer than fifteen times).
W00-1308
Engelson and Dagan (1996) experimented with QBC using HMMs for POS tagging and found that selective sampling of sentences can significantly reduce the number of samples required to achieve desirable tag accuracies.
P96-1042
More recent work has achieved state-of-the-art results with Maxi101 mum entropy conditional Markov models (MaxEnt CMMs, or MEMMs for short) (Ratnaparkhi, 1996; Toutanova & Manning, 2000; Toutanova et al., 2003).
N03-1033 W00-1308 W96-0213
Toutanova and Manning (2000) achieves 96.9% (on seen) and 86.9% (on unseen) with an MEMM.
W00-1308
Previous work demonstrates the suitability of Hidden Markov Models for POS tagging (Kupiec, 1992; Brants, 2000).
A00-1031
Related work includes learning ensembles of POS taggers, as in the work of Brill and Wu (1998), where an ensemble consisting of a unigram model, an N-gram model, a transformation-based model, and an MEMM for POS tagging achieves substantial results beyond the individual taggers.
P98-1029
